{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 按行数分类的覆盖率统计 ===\n",
      "\n",
      "Category: 0-100 (0~100 行), file_count=96\n",
      "[NoParent-All] static=13162, llm=14107, matched=10250 => Cov(st)=77.88%, Cov(llm)=72.66%\n",
      "[NoParent-Leaf] static=7376, llm=8609, matched=6135 => Cov(st)=83.18%, Cov(llm)=71.26%\n",
      "[FlexParent-All] static=13162, llm=14107, matched=7606 => Cov(st)=57.79%, Cov(llm)=53.92%\n",
      "[FlexParent-Leaf] static=7376, llm=8609, matched=4424 => Cov(st)=59.98%, Cov(llm)=51.39%\n",
      "\n",
      "Category: 101-200 (101~200 行), file_count=24\n",
      "[NoParent-All] static=13642, llm=12611, matched=9220 => Cov(st)=67.59%, Cov(llm)=73.11%\n",
      "[NoParent-Leaf] static=7755, llm=7674, matched=5439 => Cov(st)=70.14%, Cov(llm)=70.88%\n",
      "[FlexParent-All] static=13642, llm=12611, matched=7092 => Cov(st)=51.99%, Cov(llm)=56.24%\n",
      "[FlexParent-Leaf] static=7755, llm=7674, matched=4057 => Cov(st)=52.31%, Cov(llm)=52.87%\n",
      "\n",
      "Category: 201-300 (201~300 行), file_count=1\n",
      "[NoParent-All] static=1689, llm=1234, matched=918 => Cov(st)=54.35%, Cov(llm)=74.39%\n",
      "[NoParent-Leaf] static=895, llm=716, matched=523 => Cov(st)=58.44%, Cov(llm)=73.04%\n",
      "[FlexParent-All] static=1689, llm=1234, matched=726 => Cov(st)=42.98%, Cov(llm)=58.83%\n",
      "[FlexParent-Leaf] static=895, llm=716, matched=408 => Cov(st)=45.59%, Cov(llm)=56.98%\n",
      "\n",
      "Category: 301-9999999 (301~9999999 行), file_count=6\n",
      "[NoParent-All] static=13815, llm=10792, matched=7564 => Cov(st)=54.75%, Cov(llm)=70.09%\n",
      "[NoParent-Leaf] static=7794, llm=6483, matched=4401 => Cov(st)=56.47%, Cov(llm)=67.89%\n",
      "[FlexParent-All] static=13815, llm=10792, matched=5139 => Cov(st)=37.20%, Cov(llm)=47.62%\n",
      "[FlexParent-Leaf] static=7794, llm=6483, matched=3034 => Cov(st)=38.93%, Cov(llm)=46.80%\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "\n",
    "###############################################################################\n",
    "# 覆盖率比较逻辑 (与你已有的保持一致)\n",
    "###############################################################################\n",
    "def collect_node_ranges(ast_node: dict, only_leaves: bool=False) -> set:\n",
    "    result = set()\n",
    "    st = ast_node.get(\"start_token\", -1)\n",
    "    et = ast_node.get(\"end_token\", -1)\n",
    "    children = ast_node.get(\"children\", [])\n",
    "    is_leaf = (len(children) == 0)\n",
    "\n",
    "    if (not only_leaves) or (only_leaves and is_leaf):\n",
    "        if st >= 0 and et >= 0:\n",
    "            result.add((st, et))\n",
    "\n",
    "    for child in children:\n",
    "        result.update(collect_node_ranges(child, only_leaves))\n",
    "    return result\n",
    "\n",
    "def compare_ast_just_tokenRanges(ast_static: dict, ast_llm: dict, only_leaves: bool=False):\n",
    "    \"\"\"\n",
    "    不考虑父节点, 只看 (start_token, end_token) 一致即可。\n",
    "    可以只统计叶子(only_leaves=True)或全部节点。\n",
    "    \"\"\"\n",
    "    static_set = collect_node_ranges(ast_static, only_leaves)\n",
    "    llm_set = collect_node_ranges(ast_llm, only_leaves)\n",
    "    inter = static_set.intersection(llm_set)\n",
    "\n",
    "    total_static = len(static_set)\n",
    "    total_llm = len(llm_set)\n",
    "    matched = len(inter)\n",
    "\n",
    "    cov_static = (matched / total_static) if total_static else 0.0\n",
    "    cov_llm = (matched / total_llm) if total_llm else 0.0\n",
    "\n",
    "    return {\n",
    "        \"total_static\": total_static,\n",
    "        \"total_llm\": total_llm,\n",
    "        \"matched\": matched,\n",
    "        \"coverage_static\": cov_static,\n",
    "        \"coverage_llm\": cov_llm\n",
    "    }\n",
    "\n",
    "def collect_node_ancestors(ast_node: dict, ancestors: list, only_leaves: bool=False) -> dict:\n",
    "    results = {}\n",
    "    st = ast_node.get(\"start_token\", -1)\n",
    "    et = ast_node.get(\"end_token\", -1)\n",
    "    children = ast_node.get(\"children\", [])\n",
    "    node_is_leaf = (len(children)==0)\n",
    "\n",
    "    if (not only_leaves) or (only_leaves and node_is_leaf):\n",
    "        if st>=0 and et>=0:\n",
    "            results[(st, et)] = {\n",
    "                \"ancestors\": set(ancestors),\n",
    "                \"is_leaf\": node_is_leaf\n",
    "            }\n",
    "\n",
    "    new_ancestors = ancestors[:]\n",
    "    if st>=0 and et>=0:\n",
    "        new_ancestors.append((st,et))\n",
    "\n",
    "    for child in children:\n",
    "        submap = collect_node_ancestors(child, new_ancestors, only_leaves)\n",
    "        for k,v in submap.items():\n",
    "            results[k] = v\n",
    "\n",
    "    return results\n",
    "\n",
    "def build_static_parent_map(ast_node: dict, parent: dict, store: dict, only_leaves: bool=False):\n",
    "    st = ast_node.get(\"start_token\",-1)\n",
    "    et = ast_node.get(\"end_token\",-1)\n",
    "    children = ast_node.get(\"children\",[])\n",
    "    node_is_leaf = (len(children)==0)\n",
    "\n",
    "    if parent:\n",
    "        pst = parent.get(\"start_token\",-1)\n",
    "        pet = parent.get(\"end_token\",-1)\n",
    "    else:\n",
    "        pst, pet = -1, -1\n",
    "\n",
    "    if (not only_leaves) or (only_leaves and node_is_leaf):\n",
    "        if st>=0 and et>=0:\n",
    "            store[(st,et)] = (pst,pet)\n",
    "\n",
    "    for ch in children:\n",
    "        build_static_parent_map(ch, ast_node, store, only_leaves)\n",
    "\n",
    "def compare_ast_flexible_parent(ast_static: dict, ast_llm: dict, only_leaves: bool=False):\n",
    "    static_map = {}\n",
    "    build_static_parent_map(ast_static, None, static_map, only_leaves)\n",
    "    llm_map = collect_node_ancestors(ast_llm, [], only_leaves)\n",
    "\n",
    "    matched = 0\n",
    "    total_static = len(static_map)\n",
    "    total_llm = len(llm_map)\n",
    "\n",
    "    for (node_st,node_et), (pst,pet) in static_map.items():\n",
    "        if (node_st,node_et) in llm_map:\n",
    "            ancset = llm_map[(node_st,node_et)][\"ancestors\"]\n",
    "            if (pst,pet)==(-1,-1):\n",
    "                matched += 1\n",
    "            else:\n",
    "                if (pst,pet) in ancset:\n",
    "                    matched += 1\n",
    "\n",
    "    cov_static = (matched / total_static) if total_static>0 else 0\n",
    "    cov_llm = (matched / total_llm) if total_llm>0 else 0\n",
    "\n",
    "    return {\n",
    "        \"total_static\": total_static,\n",
    "        \"total_llm\": total_llm,\n",
    "        \"matched\": matched,\n",
    "        \"coverage_static\": cov_static,\n",
    "        \"coverage_llm\": cov_llm\n",
    "    }\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 2) main: 行数分类 + 覆盖率统计\n",
    "###############################################################################\n",
    "def main():\n",
    "    # Python 源文件目录\n",
    "    source_dir = \"../../dataset/ts\"\n",
    "    # LLM AST 目录\n",
    "    llm_json_dir = \"./llm_ast/chunk_block_processed\"\n",
    "    # 静态 AST 目录\n",
    "    static_json_dir = \"../../dataset/ts_ast\"\n",
    "\n",
    "    if not os.path.isdir(source_dir):\n",
    "        print(f\"[Error] Source dir not found: {source_dir}\")\n",
    "        return\n",
    "\n",
    "    # 定义行数范围\n",
    "    categories = [\n",
    "        # (\"all\", 0, 9999999),\n",
    "        (\"0-100\", 0, 100),\n",
    "        (\"101-200\", 101, 200),\n",
    "        (\"201-300\", 201, 300),\n",
    "        (\"301-9999999\", 301, 9999999)\n",
    "    ]\n",
    "\n",
    "    # 为每个分类，存储 4种统计\n",
    "    # np_all, np_leaf, fp_all, fp_leaf\n",
    "    # 每种统计包括 total_static_sum, total_llm_sum, matched_sum, file_count\n",
    "    stats_map = {}\n",
    "    for cat_name, low, high in categories:\n",
    "        stats_map[cat_name] = {\n",
    "            \"file_count\": 0,\n",
    "            # no-parent(all)\n",
    "            \"np_all_static\": 0, \"np_all_llm\":0, \"np_all_match\":0,\n",
    "            # no-parent(leaf)\n",
    "            \"np_leaf_static\": 0, \"np_leaf_llm\":0, \"np_leaf_match\":0,\n",
    "            # flex-parent(all)\n",
    "            \"fp_all_static\": 0, \"fp_all_llm\":0, \"fp_all_match\":0,\n",
    "            # flex-parent(leaf)\n",
    "            \"fp_leaf_static\": 0, \"fp_leaf_llm\":0, \"fp_leaf_match\":0\n",
    "        }\n",
    "\n",
    "    # 遍历 cangjie 源文件 => line_count => cat\n",
    "    for fname in os.listdir(source_dir):\n",
    "        if not fname.endswith(\".ts\"):\n",
    "            continue\n",
    "        py_path = os.path.join(source_dir, fname)\n",
    "\n",
    "        # 读取行数\n",
    "        try:\n",
    "            with open(py_path,\"r\",encoding=\"utf-8\") as f:\n",
    "                lines = f.readlines()\n",
    "            line_count = len(lines)\n",
    "        except Exception as e:\n",
    "            print(f\"[Error reading {py_path}]: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 判断分类\n",
    "        cat_name = None\n",
    "        for (cname, low, high) in categories:\n",
    "            if low <= line_count <= high:\n",
    "                cat_name = cname\n",
    "                break\n",
    "        if not cat_name:\n",
    "            continue  # 不在任何区间\n",
    "\n",
    "        # 找对应 json => <fname> + \".json\"\n",
    "        # e.g. \"1.cj\" => \"1.cj.json\"\n",
    "        json_name = fname + \".json\"\n",
    "        llm_file = os.path.join(llm_json_dir, json_name)\n",
    "        static_file = os.path.join(static_json_dir, json_name).replace(\".ts\", \"\")\n",
    "\n",
    "        if not os.path.exists(llm_file) or not os.path.exists(static_file):\n",
    "            # print(f\"[Warn] Missing AST for {fname}, skip.\")\n",
    "            continue\n",
    "\n",
    "        # 读取 JSON\n",
    "        try:\n",
    "            with open(llm_file,\"r\",encoding=\"utf-8\") as f1:\n",
    "                ast_llm = json.load(f1)\n",
    "            with open(static_file,\"r\",encoding=\"utf-8\") as f2:\n",
    "                ast_static = json.load(f2)\n",
    "        except Exception as e:\n",
    "            print(f\"[Error reading AST for {fname}]: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 计算4种覆盖率\n",
    "        # no-parent(all)\n",
    "        r_np_all = compare_ast_just_tokenRanges(ast_static, ast_llm, only_leaves=False)\n",
    "        # no-parent(leaf)\n",
    "        r_np_leaf = compare_ast_just_tokenRanges(ast_static, ast_llm, only_leaves=True)\n",
    "        # flex-parent(all)\n",
    "        r_fp_all = compare_ast_flexible_parent(ast_static, ast_llm, only_leaves=False)\n",
    "        # flex-parent(leaf)\n",
    "        r_fp_leaf = compare_ast_flexible_parent(ast_static, ast_llm, only_leaves=True)\n",
    "\n",
    "        # 累加到 stats_map[cat_name]\n",
    "        sdat = stats_map[cat_name]\n",
    "        sdat[\"file_count\"] += 1\n",
    "\n",
    "        # np_all\n",
    "        sdat[\"np_all_static\"] += r_np_all[\"total_static\"]\n",
    "        sdat[\"np_all_llm\"] += r_np_all[\"total_llm\"]\n",
    "        sdat[\"np_all_match\"] += r_np_all[\"matched\"]\n",
    "\n",
    "        # np_leaf\n",
    "        sdat[\"np_leaf_static\"] += r_np_leaf[\"total_static\"]\n",
    "        sdat[\"np_leaf_llm\"] += r_np_leaf[\"total_llm\"]\n",
    "        sdat[\"np_leaf_match\"] += r_np_leaf[\"matched\"]\n",
    "\n",
    "        # fp_all\n",
    "        sdat[\"fp_all_static\"] += r_fp_all[\"total_static\"]\n",
    "        sdat[\"fp_all_llm\"] += r_fp_all[\"total_llm\"]\n",
    "        sdat[\"fp_all_match\"] += r_fp_all[\"matched\"]\n",
    "\n",
    "        # fp_leaf\n",
    "        sdat[\"fp_leaf_static\"] += r_fp_leaf[\"total_static\"]\n",
    "        sdat[\"fp_leaf_llm\"] += r_fp_leaf[\"total_llm\"]\n",
    "        sdat[\"fp_leaf_match\"] += r_fp_leaf[\"matched\"]\n",
    "\n",
    "    # 输出每个分类结果\n",
    "    print(\"\\n=== 按行数分类的覆盖率统计 ===\")\n",
    "    for (cat_name, low, high) in categories:\n",
    "        sdat = stats_map[cat_name]\n",
    "        fcount = sdat[\"file_count\"]\n",
    "        if fcount==0:\n",
    "            print(f\"\\nCategory: {cat_name} ({low}~{high}) => 无文件。\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nCategory: {cat_name} ({low}~{high} 行), file_count={fcount}\")\n",
    "\n",
    "        # np_all\n",
    "        a_s = sdat[\"np_all_static\"]\n",
    "        a_l = sdat[\"np_all_llm\"]\n",
    "        a_m = sdat[\"np_all_match\"]\n",
    "        cov_s = (a_m/a_s)*100 if a_s>0 else 0\n",
    "        cov_l = (a_m/a_l)*100 if a_l>0 else 0\n",
    "        print(\"[NoParent-All] static=%d, llm=%d, matched=%d => Cov(st)=%.2f%%, Cov(llm)=%.2f%%\" % (a_s,a_l,a_m,cov_s,cov_l))\n",
    "\n",
    "        # np_leaf\n",
    "        b_s = sdat[\"np_leaf_static\"]\n",
    "        b_l = sdat[\"np_leaf_llm\"]\n",
    "        b_m = sdat[\"np_leaf_match\"]\n",
    "        cov_s = (b_m/b_s)*100 if b_s>0 else 0\n",
    "        cov_l = (b_m/b_l)*100 if b_l>0 else 0\n",
    "        print(\"[NoParent-Leaf] static=%d, llm=%d, matched=%d => Cov(st)=%.2f%%, Cov(llm)=%.2f%%\" % (b_s,b_l,b_m,cov_s,cov_l))\n",
    "\n",
    "        # fp_all\n",
    "        c_s = sdat[\"fp_all_static\"]\n",
    "        c_l = sdat[\"fp_all_llm\"]\n",
    "        c_m = sdat[\"fp_all_match\"]\n",
    "        cov_s = (c_m/c_s)*100 if c_s>0 else 0\n",
    "        cov_l = (c_m/c_l)*100 if c_l>0 else 0\n",
    "        print(\"[FlexParent-All] static=%d, llm=%d, matched=%d => Cov(st)=%.2f%%, Cov(llm)=%.2f%%\" % (c_s,c_l,c_m,cov_s,cov_l))\n",
    "\n",
    "        # fp_leaf\n",
    "        d_s = sdat[\"fp_leaf_static\"]\n",
    "        d_l = sdat[\"fp_leaf_llm\"]\n",
    "        d_m = sdat[\"fp_leaf_match\"]\n",
    "        cov_s = (d_m/d_s)*100 if d_s>0 else 0\n",
    "        cov_l = (d_m/d_l)*100 if d_l>0 else 0\n",
    "        print(\"[FlexParent-Leaf] static=%d, llm=%d, matched=%d => Cov(st)=%.2f%%, Cov(llm)=%.2f%%\" % (d_s,d_l,d_m,cov_s,cov_l))\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
