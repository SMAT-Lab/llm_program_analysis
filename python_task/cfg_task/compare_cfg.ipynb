{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy Generate CFG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "效果不太好，还是需要我们一步步进行处理！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step1 先将文件的嵌套类，方法给找到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 11.py\n",
      "Processing 60.py\n",
      "Processing 180.py\n",
      "Processing 195.py\n",
      "Processing 202.py\n",
      "Processing 208.py\n",
      "Processing 151.py\n",
      "Processing 176.py\n",
      "Processing 98.py\n",
      "Processing 13.py\n",
      "Processing 120.py\n",
      "Processing 71.py\n",
      "Processing 12.py\n",
      "Processing 167.py\n",
      "Processing 186.py\n",
      "Processing 62.py\n",
      "Processing 14.py\n",
      "Processing 6.py\n",
      "Processing 59.py\n",
      "Processing 107.py\n",
      "Processing 9.py\n",
      "Processing 163.py\n",
      "Processing 129.py\n",
      "Processing 139.py\n",
      "Processing 54.py\n",
      "Processing 184.py\n",
      "Processing 174.py\n",
      "Processing 138.py\n",
      "Processing 148.py\n",
      "Processing 201.py\n",
      "Processing 75.py\n",
      "Processing 159.py\n",
      "Processing 55.py\n",
      "Processing 123.py\n",
      "Processing 160.py\n",
      "Processing 29.py\n",
      "Processing 100.py\n",
      "Processing 45.py\n",
      "Processing 116.py\n",
      "Processing 25.py\n",
      "Processing 89.py\n",
      "Processing 28.py\n",
      "Processing 86.py\n",
      "Processing 99.py\n",
      "Processing 19.py\n",
      "Processing 90.py\n",
      "Processing 132.py\n",
      "Processing 77.py\n",
      "Processing 144.py\n",
      "Processing 93.py\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import cpu_count\n",
    "from llm import get_llm_answers\n",
    "import json\n",
    "\n",
    "def get_step1_prompt(code_text: str, program_language: str):\n",
    "    \"\"\"\n",
    "    生成第一步的Prompt\n",
    "    \"\"\"\n",
    "    code_lines = code_text.splitlines()\n",
    "    code_lines_json = [{\n",
    "        \"line\": i + 1,\n",
    "        \"code\": line\n",
    "    } for i, line in enumerate(code_lines)]\n",
    "\n",
    "    prompt = \"\"\"\n",
    "You are given a piece of \"\"\" +  program_language + \"\"\" code. Your goal is to find all the nested classes and methods in the code.\n",
    "\n",
    "Please return the result in JSON format, your output should be the following format:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"name\": \"example_script\",  // Name of the script or function\n",
    "    \"type\": \"CFG\",\n",
    "    \"start_line\": number,\n",
    "    \"end_line\": number,\n",
    "    \"functions\": [\n",
    "      {\n",
    "        \"name\": \"function_name\",\n",
    "        \"type\": \"function\",\n",
    "        \"start_line\": number,\n",
    "        \"end_line\": number,\n",
    "        \"functions\": [],         // Nested functions\n",
    "        \"classes\": []            // Nested classes\n",
    "      }\n",
    "    ],\n",
    "    \"classes\": [\n",
    "      {\n",
    "        \"name\": \"class_name\",\n",
    "        \"type\": \"class\",\n",
    "        \"start_line\": number,\n",
    "        \"end_line\": number,\n",
    "        \"functions\": [           // Methods of the class\n",
    "          {\n",
    "            \"name\": \"method_name\",\n",
    "            \"type\": \"function\",\n",
    "            \"start_line\": number,\n",
    "            \"end_line\": number,\n",
    "            \"functions\": [],     // Nested functions\n",
    "            \"classes\": []        // Nested classes\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "The code lines are:\n",
    "\"\"\" + json.dumps(code_lines_json, indent=2) + \"\"\"\n",
    "IMPORTANT: Make sure that the nested classes and methods are in the correct level. For example, if a function is nested in another class, the function should be in the nested class's functions list. \n",
    "Besides, if a class is nested in another class, the class should be in the nested class's classes list.\n",
    "\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def find_nested_classes_and_methods(code_text: str, program_language):\n",
    "    \"\"\"\n",
    "    找到文件中的嵌套类，方法\n",
    "    \"\"\"\n",
    "    prompt = get_step1_prompt(code_text, program_language)\n",
    "    response = get_llm_answers(prompt, model_name=\"gpt-4o\", require_json=True)\n",
    "    nested_classes_and_methods = json.loads(response)\n",
    "    return nested_classes_and_methods\n",
    "\n",
    "def process_file_with_chain_of_thought(input_file: str, program_language: str):\n",
    "    \"\"\"\n",
    "    读取 Python 文件 -> 生成’思维链’式Prompt -> 调用大模型 -> 写入结果JSON\n",
    "    \"\"\"\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        code_text = f.read()\n",
    "\n",
    "    # 找到文件中的嵌套类，方法\n",
    "    step1_result = find_nested_classes_and_methods(code_text, program_language)\n",
    "    # print(json.dumps(step1_result, indent=2))\n",
    "\n",
    "    return step1_result\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "\n",
    "def get_code_by_line_range(code_block, code):\n",
    "    code_lines = code.splitlines()\n",
    "    start_line = code_block[\"start_line\"]\n",
    "    end_line = code_block[\"end_line\"] + 1\n",
    "\n",
    "    ## start_line 到 end_line 之间的代码， 但是要减去自身class和function的代码\n",
    "    line_set = set(range(start_line, end_line))\n",
    "    for func in code_block.get(\"functions\", []):\n",
    "        func_start_line = func.get(\"start_line\", 0)\n",
    "        func_end_line = func.get(\"end_line\", 0)\n",
    "        line_set.difference_update(range(func_start_line, func_end_line))\n",
    "\n",
    "    for cls in code_block.get(\"classes\", []):\n",
    "        cls_start_line = cls.get(\"start_line\", 0)\n",
    "        cls_end_line = cls.get(\"end_line\", 0)\n",
    "        line_set.difference_update(range(cls_start_line, cls_end_line))\n",
    "\n",
    "    # 将line_set转换为有序列表并排序,确保按行号顺序\n",
    "    ordered_lines = sorted(list(line_set))\n",
    "    sum_code = \"\\n\".join([code_lines[i-1] for i in ordered_lines])\n",
    "\n",
    "    code_block[\"simplified_code\"] = sum_code\n",
    "\n",
    "def recursive_get_code_by_line_range(code_block, code):\n",
    "    get_code_by_line_range(code_block, code)\n",
    "    for func in code_block.get(\"functions\", []):\n",
    "        recursive_get_code_by_line_range(func, code)\n",
    "    for cls in code_block.get(\"classes\", []):\n",
    "        recursive_get_code_by_line_range(cls, code)\n",
    "\n",
    "\n",
    "def print_simplified_code(code_block: dict, indent=0):\n",
    "    \"\"\"\n",
    "    递归遍历并打印 simplified_code\n",
    "    \"\"\"\n",
    "    print(\" \" * indent + \"简化后的代码:\")\n",
    "    print(\" \" * indent + code_block.get(\"simplified_code\", \"\").strip())\n",
    "\n",
    "    # 递归处理嵌套的类\n",
    "    for class_block in code_block.get(\"classes\", []):\n",
    "        print(\" \" * indent + f\"\\n类 {class_block.get('name', '')}:\")\n",
    "        print_simplified_code(class_block, indent + 2)\n",
    "\n",
    "    # 递归处理嵌套的函数\n",
    "    for function_block in code_block.get(\"functions\", []):\n",
    "        print(\" \" * indent + f\"\\n函数 {function_block.get('name', '')}:\")\n",
    "        print_simplified_code(function_block, indent + 2)\n",
    "\n",
    "def get_code_cfg_prompt(code, program_language):\n",
    "    \"\"\"\n",
    "    生成代码的CFG的Prompt\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are given a piece of {program_language} code. Your goal is to generate a CFG for the code. You should find the basic blocks of the code and find the successors of each block.\n",
    "\n",
    "Attention to the following structure containing the branch:\n",
    "1. if-else\n",
    "2. for-while\n",
    "3. try-except-finally\n",
    "4. with-as\n",
    "5. match-case\n",
    "6. break-continue-return\n",
    "\n",
    "You should identify the basic blocks and the successors of each block(which means the blocks that may be executed after this block).\n",
    "\n",
    "Your output should follow the following json format:\n",
    "\"\"\" + \"\"\"\n",
    "```json\n",
    "{  \n",
    "  \"blocks\": [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"label\": \"if a > 2:\",\n",
    "      \"successors\": [\n",
    "        2,3\n",
    "      ], # which means that there are two successors of this block which may be executed after this block\n",
    "    },\n",
    "    {\n",
    "      \"id\": 2,\n",
    "      \"label\": \"print(a)\",\n",
    "      \"successors\": [\n",
    "        3\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"id\": 3,\n",
    "      \"label\": \"print(1)\",\n",
    "      \"successors\": [\n",
    "        \n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "+ id: 1, 2, 3, ...\n",
    "+ label: the entire code of the block (don't remove any code)\n",
    "+ successors: the ids of the blocks that may be executed after this block\n",
    "\n",
    "Make sure that the successors blocks exist in the blocks list before you finally output.\n",
    "!!!IMPORTANT: Each blocks represent a basic block, which is a single statement or a group of statements that can be executed as a unit without any branch. \n",
    "\n",
    "Following is the given code:\n",
    "\"\"\" + code\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def get_single_block_cfg(code_block, program_languge):\n",
    "    \"\"\"\n",
    "    获取每个代码块的CFG\n",
    "    \"\"\"\n",
    "    prompt = get_code_cfg_prompt(code_block[\"simplified_code\"], program_languge)\n",
    "    response = get_llm_answers(prompt, model_name=\"gpt-4o\", require_json=True)\n",
    "    blocks = json.loads(response)[\"blocks\"]\n",
    "    code_block[\"blocks\"] = blocks\n",
    "    \n",
    "def recursive_get_each_block_cfg(code_block, program_language):\n",
    "    \"\"\"\n",
    "    递归获取每个代码块的CFG\n",
    "    \"\"\"\n",
    "    get_single_block_cfg(code_block, program_language)\n",
    "    for block in code_block.get(\"classes\", []):\n",
    "        recursive_get_each_block_cfg(block, program_language)\n",
    "    for block in code_block.get(\"functions\", []):\n",
    "        recursive_get_each_block_cfg(block, program_language)\n",
    "\n",
    "import os\n",
    "def main():\n",
    "    from concurrent.futures import ThreadPoolExecutor\n",
    "    from functools import partial\n",
    "    os.makedirs(\"llm_cfg_gpt-4o_50\", exist_ok=True)\n",
    "    def process_single_file(file):\n",
    "        target_file = \"llm_cfg_gpt-4o_50/\" + file.replace(\".py\", \".json\")\n",
    "        if os.path.exists(target_file):\n",
    "            return\n",
    "        print(\"Processing \" + file)\n",
    "        step1_result = process_file_with_chain_of_thought(\"source_code/\" + file, \"python\")\n",
    "        with open(\"source_code/\" + file, 'r') as f:\n",
    "            code = f.read()\n",
    "        recursive_get_code_by_line_range(step1_result, code)\n",
    "        recursive_get_each_block_cfg(step1_result, \"python\")\n",
    "\n",
    "        def remove_duplicate_blocks(code_block):\n",
    "            \"\"\"\n",
    "            删除同一层级中start_line和end_line相同的重复块,仅保留最前面的一个\n",
    "            \"\"\"\n",
    "            if \"blocks\" in code_block:\n",
    "                # 用于记录已经出现过的(start_line, end_line)组合\n",
    "                seen = set()\n",
    "                # 用于存储不重复的blocks\n",
    "                unique_blocks = []\n",
    "                \n",
    "                for block in code_block[\"blocks\"]:\n",
    "                    # 如果block有start_line和end_line属性\n",
    "                    if \"start_line\" in block and \"end_line\" in block:\n",
    "                        key = (block[\"start_line\"], block[\"end_line\"])\n",
    "                        if key not in seen:\n",
    "                            seen.add(key)\n",
    "                            unique_blocks.append(block)\n",
    "                    else:\n",
    "                        # 如果没有这些属性,保留该block\n",
    "                        unique_blocks.append(block)\n",
    "                        \n",
    "                code_block[\"blocks\"] = unique_blocks\n",
    "            \n",
    "            # 递归处理子块\n",
    "            for sub_block in code_block.get(\"classes\", []):\n",
    "                remove_duplicate_blocks(sub_block)\n",
    "            for sub_block in code_block.get(\"functions\", []):\n",
    "                remove_duplicate_blocks(sub_block)\n",
    "                \n",
    "        # 处理整个CFG\n",
    "        remove_duplicate_blocks(step1_result)\n",
    "        \n",
    "        with open(target_file, \"w\") as f:\n",
    "            json.dump(step1_result, f, indent=2)\n",
    "\n",
    "    # 使用线程池并行处理文件\n",
    "    with ThreadPoolExecutor(max_workers=cpu_count()) as executor:\n",
    "        files = os.listdir(\"source_code\")[:50]\n",
    "        executor.map(process_single_file, files)\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM生成的代码可能可以合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging 160.json\n",
      "Merging 132.json\n",
      "Merging 116.json\n",
      "Merging 14.json\n",
      "Merging 167.json\n",
      "Merging 107.json\n",
      "Merging 89.json\n",
      "Merging 176.json\n",
      "Merging 98.json\n",
      "Merging 123.json\n",
      "Merging 28.json\n",
      "Merging 45.json\n",
      "Merging 13.json\n",
      "Merging 90.json\n",
      "Merging 138.json\n",
      "Merging 163.json\n",
      "Merging 54.json\n",
      "Merging 59.json\n",
      "Merging 71.json\n",
      "Merging 195.json\n",
      "Merging 201.json\n",
      "Merging 93.json\n",
      "Merging 184.json\n",
      "Merging 120.json\n",
      "Merging 151.json\n",
      "Merging 25.json\n",
      "Merging 144.json\n",
      "Merging 208.json\n",
      "Merging 75.json\n",
      "Merging 180.json\n",
      "Merging 86.json\n",
      "Merging 148.json\n",
      "Merging 11.json\n",
      "Merging 174.json\n",
      "Merging 29.json\n",
      "Merging 159.json\n",
      "Merging 19.json\n",
      "Merging 55.json\n",
      "Merging 6.json\n",
      "Merging 129.json\n",
      "Merging 60.json\n",
      "Merging 77.json\n",
      "Merging 202.json\n",
      "Merging 9.json\n",
      "Merging 99.json\n",
      "Merging 100.json\n",
      "Merging 62.json\n",
      "Merging 12.json\n"
     ]
    }
   ],
   "source": [
    "def process_cfg(cfg):\n",
    "    \"\"\"\n",
    "    Process a CFG to separate loop headers and bodies, merge non-loop blocks, and remove unreachable blocks.\n",
    "\n",
    "    Args:\n",
    "        cfg (dict): The CFG data structure.\n",
    "\n",
    "    Returns:\n",
    "        dict: Processed CFG.\n",
    "    \"\"\"\n",
    "    def filter_connected_blocks(blocks):\n",
    "        \"\"\"Keep only connected blocks reachable from the first block (ID = 1).\"\"\"\n",
    "        # 如果block中没有successors键,则设为空列表\n",
    "        for block in blocks:\n",
    "            if \"successors\" not in block:\n",
    "                block[\"successors\"] = []\n",
    "        adjacency_list = {block[\"id\"]: block[\"successors\"] for block in blocks}\n",
    "\n",
    "        # Perform DFS to find all reachable blocks\n",
    "        connected = set()\n",
    "        stack = [1]  # Start from block with ID = 1\n",
    "        while stack:\n",
    "            current = stack.pop()\n",
    "            if current not in connected:\n",
    "                connected.add(current)\n",
    "                stack.extend(adjacency_list.get(current, []))\n",
    "\n",
    "        return [block for block in blocks if block[\"id\"] in connected]\n",
    "\n",
    "    def find_loop_body(header_id, block_map):\n",
    "        \"\"\"Find all nodes in the loop body starting from the loop header.\"\"\"\n",
    "        loop_body = set()\n",
    "        stack = [header_id]\n",
    "        while stack:\n",
    "            current = stack.pop()\n",
    "            if current not in loop_body:\n",
    "                loop_body.add(current)\n",
    "                for succ in block_map[current][\"successors\"]:\n",
    "                    # Avoid re-adding the loop header itself\n",
    "                    if succ != header_id:\n",
    "                        stack.append(succ)\n",
    "        return loop_body\n",
    "\n",
    "    def merge_blocks(blocks):\n",
    "        \"\"\"Merge blocks by separating loop headers and combining loop bodies.\"\"\"\n",
    "        merged_blocks = []\n",
    "        visited = set()\n",
    "\n",
    "        block_map = {block[\"id\"]: block for block in blocks}\n",
    "        predecessors = {block[\"id\"]: set() for block in blocks}\n",
    "        for block in blocks:\n",
    "            for succ in block[\"successors\"]:\n",
    "                if succ in predecessors:\n",
    "                    predecessors[succ].add(block[\"id\"])\n",
    "\n",
    "        def is_loop_header(block):\n",
    "            \"\"\"Check if a block is a loop header (e.g., 'for', 'while').\"\"\"\n",
    "            return len(block[\"successors\"]) == 1 and block[\"successors\"][0] == block[\"id\"]\n",
    "\n",
    "        for block in blocks:\n",
    "            if block[\"id\"] in visited:\n",
    "                continue\n",
    "\n",
    "            if is_loop_header(block):\n",
    "                # Loop header: keep as a separate block\n",
    "                merged_blocks.append(block)\n",
    "                visited.add(block[\"id\"])\n",
    "\n",
    "                # Find and merge the loop body\n",
    "                loop_body = find_loop_body(block[\"id\"], block_map)\n",
    "                loop_body_nodes = [block_map[node_id] for node_id in loop_body if node_id not in visited]\n",
    "                if loop_body_nodes:\n",
    "                    merged_label = \"\\n\".join(node[\"label\"] for node in loop_body_nodes)\n",
    "                    merged_blocks.append({\n",
    "                        \"id\": min(loop_body),  # Use the smallest ID in the loop body\n",
    "                        \"label\": merged_label,\n",
    "                        \"successors\": list(loop_body_nodes[-1][\"successors\"]),  # Use the successors of the last node\n",
    "                    })\n",
    "                    visited.update(loop_body)\n",
    "\n",
    "            else:\n",
    "                # Attempt to merge blocks\n",
    "                current_block = block\n",
    "                merged_label = current_block[\"label\"]\n",
    "                visited.add(current_block[\"id\"])\n",
    "\n",
    "                while current_block[\"successors\"]:\n",
    "                    successor_id = current_block[\"successors\"][0]\n",
    "                    if (\n",
    "                        successor_id in visited or\n",
    "                        successor_id not in block_map or\n",
    "                        is_loop_header(block_map[successor_id])\n",
    "                    ):\n",
    "                        break\n",
    "\n",
    "                    next_block = block_map[successor_id]\n",
    "                    if len(predecessors[successor_id]) > 1:\n",
    "                        break  # Cannot merge due to multiple predecessors\n",
    "\n",
    "                    # Merge the block\n",
    "                    merged_label += f\"\\n{next_block['label']}\"\n",
    "                    visited.add(successor_id)\n",
    "                    current_block = next_block\n",
    "\n",
    "                merged_blocks.append({\n",
    "                    \"id\": block[\"id\"],\n",
    "                    \"label\": merged_label,\n",
    "                    \"successors\": current_block[\"successors\"]\n",
    "                })\n",
    "\n",
    "        return merged_blocks\n",
    "\n",
    "    # Process top-level blocks\n",
    "    if \"blocks\" in cfg:\n",
    "        cfg[\"blocks\"] = filter_connected_blocks(cfg[\"blocks\"])\n",
    "        cfg[\"blocks\"] = merge_blocks(cfg[\"blocks\"])\n",
    "\n",
    "    # Recursively process functions\n",
    "    if \"functions\" in cfg:\n",
    "        for func in cfg[\"functions\"]:\n",
    "            process_cfg(func)\n",
    "\n",
    "    # Recursively process classes\n",
    "    if \"classes\" in cfg:\n",
    "        for cls in cfg[\"classes\"]:\n",
    "            process_cfg(cls)\n",
    "\n",
    "    return cfg\n",
    "\n",
    "\n",
    "for i, file in enumerate(os.listdir(\"llm_cfg_gpt-4o_50\")):\n",
    "    with open(\"llm_cfg_gpt-4o_50/\" + file, \"r\") as f:\n",
    "        # if file != '98.json':\n",
    "        #     continue\n",
    "        print(\"Merging \" + file)\n",
    "        llm_cfg = json.load(f)\n",
    "        process_cfg(llm_cfg)\n",
    "        os.makedirs(\"merged_llm_cfg_50\", exist_ok=True)\n",
    "        with open(\"merged_llm_cfg_50/\" + file, \"w\") as f:\n",
    "            json.dump(llm_cfg, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### static analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scalpel.cfg import CFGBuilder\n",
    "\n",
    "def cfg_to_dict(cfg):\n",
    "    \"\"\"\n",
    "    遍历 CFG 和所有子 CFG，生成嵌套的 Python 字典\n",
    "    \"\"\"\n",
    "    visited = set()  # 防止重复访问\n",
    "\n",
    "    def traverse(block):\n",
    "        \"\"\"\n",
    "        遍历单个 CFG 块并生成节点和边的数据结构\n",
    "        \"\"\"\n",
    "        if block.id in visited:\n",
    "            return None\n",
    "        visited.add(block.id)\n",
    "    \n",
    "        # 获取当前块的源代码\n",
    "        block_label = block.get_source().strip() if not block.is_empty() else \"Empty Block\"\n",
    "    \n",
    "        # 按行拆分代码\n",
    "        lines = block_label.split('\\n')\n",
    "    \n",
    "        # 去掉包含 `...` 的行\n",
    "        filtered_lines = [line for line in lines if '...' not in line]\n",
    "    \n",
    "        # 将过滤后的行重新合并为块标签\n",
    "        block_label = '\\n'.join(filtered_lines).strip()\n",
    "    \n",
    "        block_dict = {\n",
    "            \"id\": block.id,\n",
    "            \"label\": block_label,\n",
    "            \"successors\": []\n",
    "        }\n",
    "    \n",
    "        # 遍历后继节点\n",
    "        for exit in block.exits:\n",
    "            successor = traverse(exit.target)\n",
    "            if successor:\n",
    "                block_dict[\"successors\"].append(successor)\n",
    "    \n",
    "        return block_dict\n",
    "\n",
    "\n",
    "    def process_cfg(cfg, prefix=\"Main\"):\n",
    "        \"\"\"\n",
    "        处理当前 CFG，包括其子 CFG（函数和类），并返回嵌套字典\n",
    "        \"\"\"\n",
    "        cfg_dict = {\n",
    "            \"name\": cfg.name,\n",
    "            \"type\": \"CFG\",\n",
    "            \"blocks\": []\n",
    "        }\n",
    "\n",
    "        # 处理当前 CFG 的入口块\n",
    "        if cfg.entryblock:\n",
    "            entry_block = traverse(cfg.entryblock)\n",
    "            if entry_block:\n",
    "                cfg_dict[\"blocks\"].append(entry_block)\n",
    "\n",
    "        # 递归处理函数的子 CFG\n",
    "        cfg_dict[\"functions\"] = []\n",
    "        for func_name, func_cfg in cfg.functioncfgs.items():\n",
    "            func_dict = process_cfg(func_cfg, prefix=f\"{prefix}_func_{func_name}\")\n",
    "            cfg_dict[\"functions\"].append(func_dict)\n",
    "\n",
    "        # 递归处理类的子 CFG\n",
    "        cfg_dict[\"classes\"] = []\n",
    "        for class_name, class_cfg in cfg.class_cfgs.items():\n",
    "            class_dict = process_cfg(class_cfg, prefix=f\"{prefix}_class_{class_name}\")\n",
    "            cfg_dict[\"classes\"].append(class_dict)\n",
    "\n",
    "        return cfg_dict\n",
    "\n",
    "    return process_cfg(cfg)\n",
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "os.makedirs(\"static_cfg\", exist_ok=True)\n",
    "\n",
    "for i, file in enumerate(os.listdir(\"source_code\")):\n",
    "    with open(\"source_code/\" + file, \"r\") as f:\n",
    "        source_code = f.read()\n",
    "\n",
    "    # 构建控制流图\n",
    "    cfg = CFGBuilder().build_from_src(file, source_code)\n",
    "\n",
    "    # 将 CFG 转换为字典数据结构\n",
    "    cfg_dict = cfg_to_dict(cfg)\n",
    "\n",
    "    # 保存到文件\n",
    "    with open(\"static_cfg/\" + file.replace(\".py\", \".json\"), \"w\") as f:\n",
    "        json.dump(cfg_dict, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件: 100%|██████████| 48/48 [00:18<00:00,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Automatic Evaluation Summary:\n",
      "Total CFGs compared: 48\n",
      "Average Edge Coverage: 0.52\n",
      "Average Content Similarity: 0.00\n",
      "Average Structure Similarity: 0.83\n",
      "\n",
      "LLM Evaluation Summary:\n",
      "Average Structure Similarity: 0.84\n",
      "Average Content Similarity: 0.86\n",
      "Average Total Similarity: 0.85\n",
      "Reasonable Percentage: 77.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from multiprocessing import cpu_count\n",
    "from typing import Dict, List, Tuple\n",
    "from dataclasses import dataclass\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from llm import get_llm_answers\n",
    "\n",
    "def compare_cfg_similarity(llm_cfg, static_cfg):\n",
    "    max_retries = 3\n",
    "    retry_count = 0\n",
    "    \n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            prompt = f\"\"\"\n",
    "You are a CFG evaluator to evaluate whether the generated CFG is correct based on the static CFG.\n",
    "\n",
    "You should first compare the structure of the CFG, then compare the content of the CFG. Focus on the flow of the CFG and ignore the details such as content and block_id, block_name.\n",
    "\n",
    "Your output should be a json with the following format:\n",
    "{{\n",
    "    \"reasonable\": true/false,\n",
    "    \"structure_similarity\": 0.8,\n",
    "    \"content_similarity\": 0.9,\n",
    "    \"total_similarity\": 0.85,\n",
    "    \"reason\": \"\"\n",
    "}}\n",
    "\n",
    "Ground truth:\n",
    "{static_cfg}\n",
    "\n",
    "Generated CFG:\n",
    "{llm_cfg}\n",
    "\"\"\"\n",
    "            similarity = json.loads(get_llm_answers(prompt, model_name=\"gpt-4o\", require_json=True))\n",
    "            return similarity\n",
    "            \n",
    "        except Exception as e:\n",
    "            retry_count += 1\n",
    "            if retry_count == max_retries:\n",
    "                raise e\n",
    "            print(f\"重试第{retry_count}次,错误信息:{str(e)}\")\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Union\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class CFGSimilarityResult:\n",
    "    \"\"\"存储CFG比较结果的数据类\"\"\"\n",
    "    filename: str\n",
    "    edge_coverage: float\n",
    "    content_similarity: float\n",
    "    structure_similarity: float\n",
    "    matched_edges: int\n",
    "    gt_edges: int\n",
    "    llm_edges: int\n",
    "    nested_results: Optional[Dict[str, 'CFGSimilarityResult']] = None\n",
    "    llm_similarity: Optional[Dict[str, Union[float, bool]]] = None\n",
    "\n",
    "class CFGComparator:\n",
    "    def __init__(self):\n",
    "        \"\"\"初始化CFG比较器\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def count_edges(cfg: Dict) -> int:\n",
    "        \"\"\"递归计算CFG中的边数量\"\"\"\n",
    "        edge_count = sum(\n",
    "            len(block.get(\"successors\", []))\n",
    "            for block in cfg.get(\"blocks\", [])\n",
    "        )\n",
    "        \n",
    "        # 递归计算嵌套CFG的边\n",
    "        for func in cfg.get(\"functions\", []):  # functions是列表\n",
    "            edge_count += CFGComparator.count_edges(func)\n",
    "        for cls in cfg.get(\"classes\", []):     # classes是列表\n",
    "            edge_count += CFGComparator.count_edges(cls)\n",
    "            \n",
    "        return edge_count\n",
    "\n",
    "    def structure_similarity(self, llm_cfg: Dict, static_cfg: Dict) -> float:\n",
    "        \"\"\"计算两个CFG的结构相似度\"\"\"\n",
    "        # 获取两个CFG的blocks\n",
    "        llm_blocks = llm_cfg.get(\"blocks\", [])\n",
    "        static_blocks = static_cfg.get(\"blocks\", [])\n",
    "        \n",
    "        # 如果两个CFG都没有blocks，返回1.0\n",
    "        if not llm_blocks and not static_blocks:\n",
    "            return 1.0\n",
    "        # 如果其中一个没有blocks，返回0.0\n",
    "        if not llm_blocks or not static_blocks:\n",
    "            return 0.0\n",
    "            \n",
    "        # 计算边的匹配度\n",
    "        llm_edges = sum(len(block.get(\"successors\", [])) for block in llm_blocks)\n",
    "        static_edges = sum(len(block.get(\"successors\", [])) for block in static_blocks)\n",
    "        \n",
    "        if llm_edges == 0 and static_edges == 0:\n",
    "            return 1.0\n",
    "        if llm_edges == 0 or static_edges == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        # 使用边数的比例计算相似度\n",
    "        return min(llm_edges, static_edges) / max(llm_edges, static_edges)\n",
    "\n",
    "    def content_similarity(self, llm_cfg: Dict, static_cfg: Dict) -> float:\n",
    "        \"\"\"计算两个CFG的内容相似度\"\"\"\n",
    "        # 获取简化的代码内容\n",
    "        llm_code = llm_cfg.get(\"simplified_code\", \"\")\n",
    "        static_code = static_cfg.get(\"simplified_code\", \"\")\n",
    "        \n",
    "        # 如果两个都为空，返回1.0\n",
    "        if not llm_code and not static_code:\n",
    "            return 1.0\n",
    "        # 如果其中一个为空，返回0.0\n",
    "        if not llm_code or not static_code:\n",
    "            return 0.0\n",
    "        \n",
    "        # 将代码分割成行并去除空白行\n",
    "        llm_lines = [line.strip() for line in llm_code.split(\"\\n\") if line.strip()]\n",
    "        static_lines = [line.strip() for line in static_code.split(\"\\n\") if line.strip()]\n",
    "        \n",
    "        # 计算行的匹配度\n",
    "        common_lines = set(llm_lines) & set(static_lines)\n",
    "        return len(common_lines) / max(len(llm_lines), len(static_lines))\n",
    "\n",
    "    def compare_cfgs(self, llm_cfg: Dict, static_cfg: Dict, name: str) -> CFGSimilarityResult:\n",
    "        \"\"\"递归比较两个CFG并返回相似度结果\"\"\"\n",
    "        # 计算当前层级的相似度\n",
    "        structure_sim = self.structure_similarity(llm_cfg, static_cfg)\n",
    "        content_sim = self.content_similarity(llm_cfg, static_cfg)\n",
    "        \n",
    "        # 计算边的统计信息\n",
    "        gt_edges = self.count_edges(static_cfg)\n",
    "        llm_edges = self.count_edges(llm_cfg)\n",
    "        matched_edges = int(structure_sim * min(gt_edges, llm_edges))\n",
    "        edge_coverage = matched_edges / gt_edges if gt_edges > 0 else 0\n",
    "        \n",
    "        # 递归比较嵌套的CFG\n",
    "        nested_results = {}\n",
    "        \n",
    "        # 比较函数CFG\n",
    "        llm_functions = {f[\"name\"]: f for f in llm_cfg.get(\"functions\", [])}\n",
    "        static_functions = {f[\"name\"]: f for f in static_cfg.get(\"functions\", [])}\n",
    "        common_functions = set(llm_functions.keys()) & set(static_functions.keys())\n",
    "        \n",
    "        for func_name in common_functions:\n",
    "            nested_results[f\"function_{func_name}\"] = self.compare_cfgs(\n",
    "                llm_functions[func_name],\n",
    "                static_functions[func_name],\n",
    "                func_name\n",
    "            )\n",
    "        \n",
    "        # 比较类CFG\n",
    "        llm_classes = {c[\"name\"]: c for c in llm_cfg.get(\"classes\", [])}\n",
    "        static_classes = {c[\"name\"]: c for c in static_cfg.get(\"classes\", [])}\n",
    "        common_classes = set(llm_classes.keys()) & set(static_classes.keys())\n",
    "        \n",
    "        for class_name in common_classes:\n",
    "            nested_results[f\"class_{class_name}\"] = self.compare_cfgs(\n",
    "                llm_classes[class_name],\n",
    "                static_classes[class_name],\n",
    "                class_name\n",
    "            )\n",
    "        \n",
    "        return CFGSimilarityResult(\n",
    "            filename=name,\n",
    "            edge_coverage=edge_coverage,\n",
    "            content_similarity=content_sim,\n",
    "            structure_similarity=structure_sim,\n",
    "            matched_edges=matched_edges,\n",
    "            gt_edges=gt_edges,\n",
    "            llm_edges=llm_edges,\n",
    "            nested_results=nested_results if nested_results else None,\n",
    "            llm_similarity=None  # 将在process_file中设置\n",
    "        )\n",
    "\n",
    "class CFGEvaluator:\n",
    "    def __init__(self, llm_cfg_dir: str, static_cfg_dir: str, result_file: str):\n",
    "        \"\"\"初始化评估器\n",
    "        \n",
    "        Args:\n",
    "            llm_cfg_dir: LLM生成的CFG文件目录\n",
    "            static_cfg_dir: 静态分析生成的CFG文件目录\n",
    "            result_file: 结果保存文件路径\n",
    "        \"\"\"\n",
    "        self.llm_cfg_dir = Path(llm_cfg_dir)\n",
    "        self.static_cfg_dir = Path(static_cfg_dir)\n",
    "        self.result_file = Path(result_file)\n",
    "        self.comparator = CFGComparator()\n",
    "        self.results = []  # 存储所有结果\n",
    "    \n",
    "    def process_file(self, llm_cfg_path: Path) -> Optional[CFGSimilarityResult]:\n",
    "        \"\"\"处理单个CFG文件对的比较\n",
    "        \n",
    "        Args:\n",
    "            llm_cfg_path: LLM生成的CFG文件路径\n",
    "            \n",
    "        Returns:\n",
    "            CFGSimilarityResult 或 None（如果没有对应的静态CFG文件）\n",
    "        \"\"\"\n",
    "        # 获取对应的静态CFG文件路径\n",
    "        static_cfg_path = self.static_cfg_dir / llm_cfg_path.name\n",
    "        if not static_cfg_path.exists():\n",
    "            return None\n",
    "            \n",
    "        # 读取CFG文件\n",
    "        with open(llm_cfg_path) as f:\n",
    "            llm_cfg = json.load(f)\n",
    "        with open(static_cfg_path) as f:\n",
    "            static_cfg = json.load(f)\n",
    "            \n",
    "        # 比较CFG\n",
    "        result = self.comparator.compare_cfgs(llm_cfg, static_cfg, llm_cfg_path.name)\n",
    "        llm_sim = compare_cfg_similarity(llm_cfg, static_cfg)\n",
    "        result.llm_similarity = llm_sim\n",
    "        \n",
    "        # 将结果添加到列表并保存\n",
    "        self.results.append(result)\n",
    "        self.save_results()\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def save_results(self):\n",
    "        \"\"\"保存当前所有结果到文件\"\"\"\n",
    "        with open(self.result_file, \"w\") as f:\n",
    "            json.dump(\n",
    "                [self._result_to_dict(r) for r in self.results],\n",
    "                f,\n",
    "                indent=2\n",
    "            )\n",
    "    \n",
    "    def evaluate_all(self) -> List[CFGSimilarityResult]:\n",
    "        \"\"\"评估所有CFG文件对\n",
    "        \n",
    "        Returns:\n",
    "            所有比较结果的列表\n",
    "        \"\"\"\n",
    "        # 处理每个LLM生成的CFG文件\n",
    "        llm_cfg_paths = list(self.llm_cfg_dir.glob(\"*.json\"))\n",
    "        \n",
    "        # 使用多线程并行处理\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = []\n",
    "            for llm_cfg_path in llm_cfg_paths:\n",
    "                future = executor.submit(self.process_file, llm_cfg_path)\n",
    "                futures.append(future)\n",
    "            \n",
    "            # 使用tqdm显示进度\n",
    "            for future in tqdm(as_completed(futures), total=len(futures), desc=\"处理CFG文件\"):\n",
    "                future.result()\n",
    "                \n",
    "        return self.results\n",
    "    \n",
    "    @staticmethod\n",
    "    def _result_to_dict(result: CFGSimilarityResult) -> Dict:\n",
    "        \"\"\"将CFGSimilarityResult转换为可JSON序列化的字典\"\"\"\n",
    "        return {\n",
    "            \"filename\": result.filename,\n",
    "            \"edge_coverage\": result.edge_coverage,\n",
    "            \"content_similarity\": result.content_similarity,\n",
    "            \"structure_similarity\": result.structure_similarity,\n",
    "            \"matched_edges\": result.matched_edges,\n",
    "            \"gt_edges\": result.gt_edges,\n",
    "            \"llm_edges\": result.llm_edges,\n",
    "            \"nested_results\": {\n",
    "                k: CFGEvaluator._result_to_dict(v)\n",
    "                for k, v in result.nested_results.items()\n",
    "            } if result.nested_results else None,\n",
    "            \"llm_similarity\": result.llm_similarity\n",
    "        }\n",
    "\n",
    "def calculate_aggregate_metrics(results: List[CFGSimilarityResult]) -> Dict:\n",
    "    \"\"\"计算聚合指标\n",
    "    \n",
    "    Args:\n",
    "        results: CFGSimilarityResult列表\n",
    "        \n",
    "    Returns:\n",
    "        包含聚合指标的字典\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        \"total_cfgs_compared\": len(results),\n",
    "        \"average_edge_coverage\": np.mean([r.edge_coverage for r in results]),\n",
    "        \"average_content_similarity\": np.mean([r.content_similarity for r in results]),\n",
    "        \"average_structure_similarity\": np.mean([r.structure_similarity for r in results]),\n",
    "        \"total_gt_edges\": sum(r.gt_edges for r in results),\n",
    "        \"total_llm_edges\": sum(r.llm_edges for r in results),\n",
    "        \"total_matched_edges\": sum(r.matched_edges for r in results)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def main():\n",
    "    evaluator = CFGEvaluator(\n",
    "        llm_cfg_dir=\"merged_llm_cfg_50\",\n",
    "        static_cfg_dir=\"static_cfg\",\n",
    "        result_file=\"evaluation_results_50.json\"\n",
    "    )\n",
    "    \n",
    "    # 评估所有CFG\n",
    "    results = evaluator.evaluate_all()\n",
    "    \n",
    "    # 计算统计指标\n",
    "    metrics = calculate_aggregate_metrics(results)\n",
    "    \n",
    "    # 计算LLM评估的平均值\n",
    "    llm_metrics = {\n",
    "        \"average_llm_structure_similarity\": np.mean([\n",
    "            r.llm_similarity[\"structure_similarity\"] \n",
    "            for r in results if r.llm_similarity\n",
    "        ]),\n",
    "        \"average_llm_content_similarity\": np.mean([\n",
    "            r.llm_similarity[\"content_similarity\"] \n",
    "            for r in results if r.llm_similarity\n",
    "        ]),\n",
    "        \"average_llm_total_similarity\": np.mean([\n",
    "            r.llm_similarity[\"total_similarity\"] \n",
    "            for r in results if r.llm_similarity\n",
    "        ]),\n",
    "        \"reasonable_percentage\": np.mean([\n",
    "            float(r.llm_similarity[\"reasonable\"]) \n",
    "            for r in results if r.llm_similarity\n",
    "        ]) * 100\n",
    "    }\n",
    "    \n",
    "    # 输出评估结果\n",
    "    print(\"\\nAutomatic Evaluation Summary:\")\n",
    "    print(f\"Total CFGs compared: {metrics['total_cfgs_compared']}\")\n",
    "    print(f\"Average Edge Coverage: {metrics['average_edge_coverage']:.2f}\")\n",
    "    print(f\"Average Content Similarity: {metrics['average_content_similarity']:.2f}\")\n",
    "    print(f\"Average Structure Similarity: {metrics['average_structure_similarity']:.2f}\")\n",
    "    \n",
    "    print(\"\\nLLM Evaluation Summary:\")\n",
    "    print(f\"Average Structure Similarity: {llm_metrics['average_llm_structure_similarity']:.2f}\")\n",
    "    print(f\"Average Content Similarity: {llm_metrics['average_llm_content_similarity']:.2f}\")\n",
    "    print(f\"Average Total Similarity: {llm_metrics['average_llm_total_similarity']:.2f}\")\n",
    "    print(f\"Reasonable Percentage: {llm_metrics['reasonable_percentage']:.1f}%\")\n",
    "    \n",
    "    # 保存完整的评估指标\n",
    "    metrics.update(llm_metrics)\n",
    "    with open(\"evaluation_metrics_50.json\", \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized Code Block Hierarchy:\n",
      "Block: GlobalBlock (lines 0-9)\n",
      "CFG Nodes: 1\n",
      "CFG Edges: 0\n",
      "Nodes (in order):\n",
      "  Node GlobalBlock_1 (order 0):\n",
      "    from prisma.models import User\n",
      "\n",
      "from backend.blocks.basic import AgentInputBlock, PrintToConsoleBlock\n",
      "from backend.blocks.text import FillTextTemplateBlock\n",
      "from backend.data import graph\n",
      "from backend.data.graph import create_graph\n",
      "from backend.data.user import get_or_create_user\n",
      "from backend.util.test import SpinTestServer, wait_execution\n",
      "Edges:\n",
      "\n",
      "Block: create_test_user (lines 10-17)\n",
      "CFG Nodes: 1\n",
      "CFG Edges: 0\n",
      "Nodes (in order):\n",
      "  Node create_test_user_1 (order 0):\n",
      "    async def create_test_user() -> User:\n",
      "\n",
      "    test_user_data = {\n",
      "        \"sub\": \"ef3b97d7-1161-4eb4-92b2-10c24fb154c1\",\n",
      "        \"email\": \"testuser#example.com\",\n",
      "        \"name\": \"Test User\",\n",
      "    }\n",
      "\n",
      "    user = await get_or_create_user(test_user_data)\n",
      "\n",
      "    return user\n",
      "Edges:\n",
      "\n",
      "Block: create_test_graph (lines 20-72)\n",
      "CFG Nodes: 1\n",
      "CFG Edges: 0\n",
      "Nodes (in order):\n",
      "  Node create_test_graph_1 (order 0):\n",
      "    def create_test_graph() -> graph.Graph:\n",
      "    \"\"\"\n",
      "    InputBlock\n",
      "               \\\n",
      "                 ---- FillTextTemplateBlock ---- PrintToConsoleBlock\n",
      "               /\n",
      "    InputBlock\n",
      "    \"\"\"\n",
      "\n",
      "    nodes = [\n",
      "        graph.Node(\n",
      "            block_id=AgentInputBlock().id,\n",
      "            input_default={\"name\": \"input_1\"},\n",
      "        ),\n",
      "        graph.Node(\n",
      "            block_id=AgentInputBlock().id,\n",
      "            input_default={\"name\": \"input_2\"},\n",
      "        ),\n",
      "        graph.Node(\n",
      "            block_id=FillTextTemplateBlock().id,\n",
      "            input_default={\n",
      "                \"format\": \"{a}, {b}{c}\",\n",
      "                \"values_#_c\": \"!!!\",\n",
      "            },\n",
      "        ),\n",
      "        graph.Node(block_id=PrintToConsoleBlock().id),\n",
      "    ]\n",
      "\n",
      "    links = [\n",
      "        graph.Link(\n",
      "            source_id=nodes[0].id,\n",
      "            sink_id=nodes[2].id,\n",
      "            source_name=\"result\",\n",
      "            sink_name=\"values_#_a\",\n",
      "        ),\n",
      "        graph.Link(\n",
      "            source_id=nodes[1].id,\n",
      "            sink_id=nodes[2].id,\n",
      "            source_name=\"result\",\n",
      "            sink_name=\"values_#_b\",\n",
      "        ),\n",
      "        graph.Link(\n",
      "            source_id=nodes[2].id,\n",
      "            sink_id=nodes[3].id,\n",
      "            source_name=\"output\",\n",
      "            sink_name=\"text\",\n",
      "        ),\n",
      "    ]\n",
      "\n",
      "    return graph.Graph(\n",
      "        name=\"TestGraph\",\n",
      "        description=\"Test graph\",\n",
      "        nodes=nodes,\n",
      "        links=links,\n",
      "    )\n",
      "Edges:\n",
      "\n",
      "Block: sample_agent (lines 75-85)\n",
      "CFG Nodes: 1\n",
      "CFG Edges: 0\n",
      "Nodes (in order):\n",
      "  Node sample_agent_1 (order 0):\n",
      "    async def sample_agent():\n",
      "    async with SpinTestServer() as server:\n",
      "\n",
      "        test_user = await create_test_user()\n",
      "        test_graph = await create_graph(create_test_graph(), test_user.id)\n",
      "        input_data = {\"input_1\": \"Hello\", \"input_2\": \"World\"}\n",
      "\n",
      "        response = await server.agent_server.test_execute_graph(\n",
      "            test_graph.id, input_data, test_user.id\n",
      "        )\n",
      "\n",
      "        print(response)\n",
      "\n",
      "        result = await wait_execution(test_user.id, test_graph.id, response[\"id\"], 10)\n",
      "        print(result)\n",
      "Edges:\n",
      "\n",
      "Block: GlobalBlock (lines 88-91)\n",
      "CFG Nodes: 1\n",
      "CFG Edges: 0\n",
      "Nodes (in order):\n",
      "  Node GlobalBlock_1 (order 0):\n",
      "    if __name__ == \"__main__\":\n",
      "\n",
      "    import asyncio\n",
      "\n",
      "    asyncio.run(sample_agent())\n",
      "Edges:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class CFGNode:\n",
    "    id: str\n",
    "    code: str\n",
    "    order: int  # 添加order来保持顺序\n",
    "    start_line: int = 0\n",
    "    end_line: int = 0\n",
    "\n",
    "@dataclass\n",
    "class CFGEdge:\n",
    "    from_node: str\n",
    "    to_node: str\n",
    "\n",
    "@dataclass\n",
    "class CFGData:\n",
    "    nodes: List[CFGNode]\n",
    "    edges: List[CFGEdge]\n",
    "\n",
    "@dataclass\n",
    "class CodeBlock:\n",
    "    decl_name: str\n",
    "    start_line: int\n",
    "    end_line: int\n",
    "    children: List['CodeBlock']\n",
    "    code: str\n",
    "    cfg: Optional[CFGData] = None\n",
    "\n",
    "def parse_json_to_cfg(json_data: dict) -> CodeBlock:\n",
    "    \"\"\"将JSON数据解析为CodeBlock对象\"\"\"\n",
    "    cfg = None\n",
    "    if 'cfg' in json_data:\n",
    "        cfg_data = json_data['cfg']\n",
    "        # 创建节点，添加order属性\n",
    "        nodes = [\n",
    "            CFGNode(\n",
    "                id=node['id'], \n",
    "                code=node['code'],\n",
    "                order=idx  # 使用索引作为顺序\n",
    "            )\n",
    "            for idx, node in enumerate(cfg_data['nodes'])\n",
    "        ]\n",
    "        # 创建边\n",
    "        edges = [\n",
    "            CFGEdge(\n",
    "                from_node=edge['from'], \n",
    "                to_node=edge['to']\n",
    "            )\n",
    "            for edge in cfg_data['edges']\n",
    "        ]\n",
    "        cfg = CFGData(nodes=nodes, edges=edges)\n",
    "\n",
    "    children = [\n",
    "        parse_json_to_cfg(child) \n",
    "        for child in json_data.get('children', [])\n",
    "    ]\n",
    "\n",
    "    return CodeBlock(\n",
    "        decl_name=json_data['decl_name'],\n",
    "        start_line=json_data['start_line'],\n",
    "        end_line=json_data['end_line'],\n",
    "        code=json_data['code'],\n",
    "        children=children,\n",
    "        cfg=cfg\n",
    "    )\n",
    "\n",
    "def can_merge_global_nodes(node1: CFGNode, node2: CFGNode, edges: List[CFGEdge]) -> bool:\n",
    "    \"\"\"判断全局作用域中的节点是否可以合并\"\"\"\n",
    "    # 检查是否都是全局作用域的节点\n",
    "    if not (node1.id.startswith(\"GlobalBlock_\") and node2.id.startswith(\"GlobalBlock_\")):\n",
    "        return False\n",
    "        \n",
    "    # 检查节点间是否有其他控制流（如if/else, try/except等）\n",
    "    node1_code = node1.code.strip()\n",
    "    node2_code = node2.code.strip()\n",
    "    \n",
    "    # 简单检查是否都是导入语句或简单的赋值语句\n",
    "    def is_simple_statement(code: str) -> bool:\n",
    "        lines = code.split('\\n')\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if not (line.startswith('from ') or \n",
    "                   line.startswith('import ') or \n",
    "                   '=' in line or \n",
    "                   line.startswith('#')):\n",
    "                return False\n",
    "        return True\n",
    "        \n",
    "    return is_simple_statement(node1_code) and is_simple_statement(node2_code)\n",
    "\n",
    "def merge_nodes(node1_id: str, node2_id: str, cfg_data: CFGData) -> CFGData:\n",
    "    \"\"\"合并两个节点，返回新的CFG数据\"\"\"\n",
    "    nodes_dict = {node.id: node for node in cfg_data.nodes}\n",
    "    \n",
    "    # 获取原始节点\n",
    "    node1 = nodes_dict[node1_id]\n",
    "    node2 = nodes_dict[node2_id]\n",
    "    \n",
    "    # 合并代码\n",
    "    merged_code = f\"{node1.code}\\n{node2.code}\"\n",
    "    \n",
    "    # 创建新节点，保持较小的order\n",
    "    merged_node = CFGNode(\n",
    "        id=node1_id,\n",
    "        code=merged_code,\n",
    "        order=min(node1.order, node2.order)\n",
    "    )\n",
    "    \n",
    "    # 更新节点列表，保持顺序\n",
    "    new_nodes = [node for node in cfg_data.nodes if node.id not in {node1_id, node2_id}]\n",
    "    new_nodes.append(merged_node)\n",
    "    new_nodes.sort(key=lambda x: x.order)\n",
    "    \n",
    "    # 更新边\n",
    "    new_edges = []\n",
    "    for edge in cfg_data.edges:\n",
    "        if edge.from_node == node2_id:\n",
    "            new_edges.append(CFGEdge(from_node=node1_id, to_node=edge.to_node))\n",
    "        elif edge.to_node == node2_id:\n",
    "            continue\n",
    "        elif edge.from_node != node1_id or edge.to_node != node2_id:\n",
    "            new_edges.append(edge)\n",
    "    \n",
    "    return CFGData(nodes=new_nodes, edges=new_edges)\n",
    "\n",
    "def can_merge_nodes(from_node_id: str, to_node_id: str, edges: List[CFGEdge], nodes_dict: Dict[str, CFGNode]) -> bool:\n",
    "    \"\"\"判断两个节点是否可以合并\n",
    "    条件：\n",
    "    1. from_node 必须直接连接到 to_node\n",
    "    2. to_node 只能有一个入边（来自 from_node）\n",
    "    3. from_node 只能有一个出边（到 to_node）\n",
    "    \"\"\"\n",
    "    # 检查 from_node -> to_node 的直接连接\n",
    "    is_directly_connected = any(\n",
    "        edge.from_node == from_node_id and edge.to_node == to_node_id\n",
    "        for edge in edges\n",
    "    )\n",
    "    if not is_directly_connected:\n",
    "        return False\n",
    "\n",
    "    # 检查 to_node 的入边数量\n",
    "    incoming_edges_to_node = sum(1 for edge in edges if edge.to_node == to_node_id)\n",
    "    if incoming_edges_to_node > 1:\n",
    "        return False\n",
    "\n",
    "    # 检查 from_node 的出边数量\n",
    "    outgoing_edges_from_node = sum(1 for edge in edges if edge.from_node == from_node_id)\n",
    "    if outgoing_edges_from_node > 1:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def optimize_cfg(cfg_data: CFGData) -> CFGData:\n",
    "    \"\"\"优化CFG，合并可以合并的节点\"\"\"\n",
    "    if not cfg_data or len(cfg_data.nodes) <= 1:\n",
    "        return cfg_data\n",
    "    \n",
    "    nodes_dict = {node.id: node for node in cfg_data.nodes}\n",
    "    changed = True\n",
    "    \n",
    "    while changed:\n",
    "        changed = False\n",
    "        nodes = sorted(cfg_data.nodes, key=lambda x: x.order)\n",
    "        \n",
    "        # 首先尝试合并全局节点\n",
    "        for i in range(len(nodes) - 1):\n",
    "            node1 = nodes[i]\n",
    "            node2 = nodes[i + 1]\n",
    "            if can_merge_global_nodes(node1, node2, cfg_data.edges):\n",
    "                cfg_data = merge_nodes(node1.id, node2.id, cfg_data)\n",
    "                nodes_dict = {node.id: node for node in cfg_data.nodes}\n",
    "                changed = True\n",
    "                break\n",
    "        \n",
    "        # 如果没有全局节点可以合并，再尝试常规的边合并\n",
    "        if not changed:\n",
    "            edges = sorted(cfg_data.edges, \n",
    "                         key=lambda e: (nodes_dict[e.from_node].order, nodes_dict[e.to_node].order))\n",
    "            for edge in edges:\n",
    "                if can_merge_nodes(edge.from_node, edge.to_node, cfg_data.edges, nodes_dict):\n",
    "                    cfg_data = merge_nodes(edge.from_node, edge.to_node, cfg_data)\n",
    "                    nodes_dict = {node.id: node for node in cfg_data.nodes}\n",
    "                    changed = True\n",
    "                    break\n",
    "    \n",
    "    return cfg_data\n",
    "\n",
    "def optimize_code_block(block: CodeBlock) -> CodeBlock:\n",
    "    \"\"\"优化单个代码块\"\"\"\n",
    "    if block.cfg:\n",
    "        block.cfg = optimize_cfg(block.cfg)\n",
    "    \n",
    "    # 递归优化子块\n",
    "    block.children = [optimize_code_block(child) for child in block.children]\n",
    "    return block\n",
    "\n",
    "def parse_and_optimize_json_to_cfg(json_data: List[dict]) -> List[CodeBlock]:\n",
    "    \"\"\"解析JSON并优化所有代码块\"\"\"\n",
    "    blocks = [parse_json_to_cfg(block_data) for block_data in json_data]\n",
    "    return [optimize_code_block(block) for block in blocks]\n",
    "\n",
    "def print_code_block_hierarchy(block: CodeBlock, indent: int = 0):\n",
    "    \"\"\"打印代码块层次结构\"\"\"\n",
    "    indent_str = \"  \" * indent\n",
    "    print(f\"{indent_str}Block: {block.decl_name} (lines {block.start_line}-{block.end_line})\")\n",
    "    if block.cfg:\n",
    "        print(f\"{indent_str}CFG Nodes: {len(block.cfg.nodes)}\")\n",
    "        print(f\"{indent_str}CFG Edges: {len(block.cfg.edges)}\")\n",
    "        print(f\"{indent_str}Nodes (in order):\")\n",
    "        for node in sorted(block.cfg.nodes, key=lambda x: x.order):\n",
    "            print(f\"{indent_str}  Node {node.id} (order {node.order}):\")\n",
    "            print(f\"{indent_str}    {node.code.strip()}\")\n",
    "        \n",
    "        # 打印边的关系\n",
    "        print(f\"{indent_str}Edges:\")\n",
    "        for edge in block.cfg.edges:\n",
    "            print(f\"{indent_str}  {edge.from_node} -> {edge.to_node}\")\n",
    "        print()  # 空行分隔\n",
    "        \n",
    "    for child in block.children:\n",
    "        print_code_block_hierarchy(child, indent + 1)\n",
    "\n",
    "llm_cfg_path = Path(\"llm_cfg/0.json\")\n",
    "with open(llm_cfg_path, 'r', encoding='utf-8') as f:\n",
    "    llm_cfg = json.load(f)\n",
    "\n",
    "# 解析和优化\n",
    "llm_blocks = parse_and_optimize_json_to_cfg(llm_cfg)\n",
    "\n",
    "# 打印结果\n",
    "print(\"\\nOptimized Code Block Hierarchy:\")\n",
    "for block in llm_blocks:\n",
    "    print_code_block_hierarchy(block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Code Block Hierarchy:\n",
      "Block:  (lines 1-92)\n",
      "Code:\n",
      "  from prisma.models import User\n",
      "  from backend.blocks.basic import AgentInputBlock, PrintToConsoleBlock\n",
      "  from backend.blocks.text import FillTextTemplateBlock\n",
      "  from backend.data import graph\n",
      "  from backend.data.graph import create_graph\n",
      "  from backend.data.user import get_or_create_user\n",
      "  from backend.util.test import SpinTestServer, wait_execution\n",
      "  async def create_test_user() -> User:\n",
      "      test_user_data = {'sub': 'ef3b97d7-1161-4eb4-92b2-10c24fb154c1', 'email': 'testuser#example.com', 'name': 'Test User'}\n",
      "      user = await get_or_create_user(test_user_data)\n",
      "      return user\n",
      "  def create_test_graph() -> graph.Graph:\n",
      "      \"\"\"\n",
      "      InputBlock\n",
      "                                  ---- FillTextTemplateBlock ---- PrintToConsoleBlock\n",
      "                 /\n",
      "      InputBlock\n",
      "      \"\"\"\n",
      "      nodes = [graph.Node(block_id=AgentInputBlock().id, input_default={'name': 'input_1'}), graph.Node(block_id=AgentInputBlock().id, input_default={'name': 'input_2'}), graph.Node(block_id=FillTextTemplateBlock().id, input_default={'format': '{a}, {b}{c}', 'values_#_c': '!!!'}), graph.Node(block_id=PrintToConsoleBlock().id)]\n",
      "      links = [graph.Link(source_id=nodes[0].id, sink_id=nodes[2].id, source_name='result', sink_name='values_#_a'), graph.Link(source_id=nodes[1].id, sink_id=nodes[2].id, source_name='result', sink_name='values_#_b'), graph.Link(source_id=nodes[2].id, sink_id=nodes[3].id, source_name='output', sink_name='text')]\n",
      "      return graph.Graph(name='TestGraph', description='Test graph', nodes=nodes, links=links)\n",
      "  async def sample_agent():\n",
      "      async with SpinTestServer() as server:\n",
      "          test_user = await create_test_user()\n",
      "          test_graph = await create_graph(create_test_graph(), test_user.id)\n",
      "          input_data = {'input_1': 'Hello', 'input_2': 'World'}\n",
      "          response = await server.agent_server.test_execute_graph(test_graph.id, input_data, test_user.id)\n",
      "          print(response)\n",
      "          result = await wait_execution(test_user.id, test_graph.id, response['id'], 10)\n",
      "          print(result)\n",
      "  if __name__ == '__main__':\n",
      "      import asyncio\n",
      "      asyncio.run(sample_agent())\n",
      "  import asyncio\n",
      "  asyncio.run(sample_agent())\n",
      "CFG Nodes: 2\n",
      "CFG Edges: 1\n",
      "Nodes (in order):\n",
      "  Node 1 (order 0)\n",
      "  Node 20 (order 1)\n",
      "Edges:\n",
      "  1 -> 20\n",
      "\n",
      "Block: (1, 'create_test_user') (lines 12-18)\n",
      "Code:\n",
      "  test_user_data = {'sub': 'ef3b97d7-1161-4eb4-92b2-10c24fb154c1', 'email': 'testuser#example.com', 'name': 'Test User'}\n",
      "  user = await get_or_create_user(test_user_data)\n",
      "  return user\n",
      "CFG Nodes: 2\n",
      "CFG Edges: 1\n",
      "Nodes (in order):\n",
      "  Node 3 (order 0)\n",
      "  Node 4 (order 1)\n",
      "Edges:\n",
      "  3 -> 4\n",
      "\n",
      "Block: (1, 'create_test_graph') (lines 22-73)\n",
      "Code:\n",
      "  '\\n    InputBlock\\n                                ---- FillTextTemplateBlock ---- PrintToConsoleBlock\\n               /\\n    InputBlock\\n    '\n",
      "  nodes = [graph.Node(block_id=AgentInputBlock().id, input_default={'name': 'input_1'}), graph.Node(block_id=AgentInputBlock().id, input_default={'name': 'input_2'}), graph.Node(block_id=FillTextTemplateBlock().id, input_default={'format': '{a}, {b}{c}', 'values_#_c': '!!!'}), graph.Node(block_id=PrintToConsoleBlock().id)]\n",
      "  links = [graph.Link(source_id=nodes[0].id, sink_id=nodes[2].id, source_name='result', sink_name='values_#_a'), graph.Link(source_id=nodes[1].id, sink_id=nodes[2].id, source_name='result', sink_name='values_#_b'), graph.Link(source_id=nodes[2].id, sink_id=nodes[3].id, source_name='output', sink_name='text')]\n",
      "  return graph.Graph(name='TestGraph', description='Test graph', nodes=nodes, links=links)\n",
      "CFG Nodes: 1\n",
      "CFG Edges: 0\n",
      "Nodes (in order):\n",
      "  Node 8 (order 0)\n",
      "Edges:\n",
      "\n",
      "Block: (1, 'sample_agent') (lines 77-86)\n",
      "Code:\n",
      "  async with SpinTestServer() as server:\n",
      "      test_user = await create_test_user()\n",
      "      test_graph = await create_graph(create_test_graph(), test_user.id)\n",
      "      input_data = {'input_1': 'Hello', 'input_2': 'World'}\n",
      "      response = await server.agent_server.test_execute_graph(test_graph.id, input_data, test_user.id)\n",
      "      print(response)\n",
      "      result = await wait_execution(test_user.id, test_graph.id, response['id'], 10)\n",
      "      print(result)\n",
      "  test_user = await create_test_user()\n",
      "  test_graph = await create_graph(create_test_graph(), test_user.id)\n",
      "  input_data = {'input_1': 'Hello', 'input_2': 'World'}\n",
      "  response = await server.agent_server.test_execute_graph(test_graph.id, input_data, test_user.id)\n",
      "  print(response)\n",
      "  result = await wait_execution(test_user.id, test_graph.id, response['id'], 10)\n",
      "  print(result)\n",
      "CFG Nodes: 6\n",
      "CFG Edges: 5\n",
      "Nodes (in order):\n",
      "  Node 12 (order 0)\n",
      "  Node 13 (order 1)\n",
      "  Node 15 (order 2)\n",
      "  Node 16 (order 3)\n",
      "  Node 17 (order 4)\n",
      "  Node 18 (order 5)\n",
      "Edges:\n",
      "  12 -> 13\n",
      "  13 -> 15\n",
      "  15 -> 16\n",
      "  16 -> 17\n",
      "  17 -> 18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class CFGNode:\n",
    "    id: str\n",
    "    code: str\n",
    "    order: int\n",
    "    start_line: int = 0\n",
    "    end_line: int = 0\n",
    "\n",
    "@dataclass\n",
    "class CFGEdge:\n",
    "    from_node: str\n",
    "    to_node: str\n",
    "\n",
    "@dataclass\n",
    "class CFGData:\n",
    "    nodes: List[CFGNode]\n",
    "    edges: List[CFGEdge]\n",
    "\n",
    "@dataclass\n",
    "class CodeBlock:\n",
    "    decl_name: str\n",
    "    start_line: int\n",
    "    end_line: int\n",
    "    children: List['CodeBlock']\n",
    "    code: str\n",
    "    cfg: Optional[CFGData] = None\n",
    "\n",
    "def parse_block(block):\n",
    "    \"\"\"解析基本块\"\"\"\n",
    "    # 获取块中语句的行号范围\n",
    "    start_line = min([stmt.lineno for stmt in block.statements if hasattr(stmt, 'lineno')] or [0])\n",
    "    end_line = max([getattr(stmt, 'end_lineno', stmt.lineno) for stmt in block.statements if hasattr(stmt, 'lineno')] or [0])\n",
    "    \n",
    "    statements = []\n",
    "    for stmt in block.statements:\n",
    "        if hasattr(stmt, 'lineno'):\n",
    "            try:\n",
    "                import ast\n",
    "                if hasattr(ast, 'unparse'):\n",
    "                    code = ast.unparse(stmt)\n",
    "                else:\n",
    "                    code = str(stmt)\n",
    "            except:\n",
    "                code = str(stmt)\n",
    "            statements.append(code)\n",
    "    \n",
    "    return {\n",
    "        \"id\": block.id,\n",
    "        \"code\": \"\\n\".join(statements),\n",
    "        \"start_line\": start_line,\n",
    "        \"end_line\": end_line,\n",
    "        \"order\": getattr(block, 'order', 0)\n",
    "    }\n",
    "\n",
    "def process_block(name, block_cfg):\n",
    "    \"\"\"处理单个代码块（可以是函数或类方法）\"\"\"\n",
    "    if not hasattr(block_cfg, 'entryblock'):\n",
    "        return [], []\n",
    "        \n",
    "    nodes = []\n",
    "    edges = []\n",
    "    visited = set()\n",
    "    block_order = 0\n",
    "    \n",
    "    # 使用广度优先搜索来保持正确的顺序\n",
    "    queue = [(block_cfg.entryblock, block_order)]\n",
    "    while queue:\n",
    "        current_block, order = queue.pop(0)\n",
    "        if current_block in visited:\n",
    "            continue\n",
    "            \n",
    "        visited.add(current_block)\n",
    "        \n",
    "        block_data = parse_block(current_block)\n",
    "        block_data[\"order\"] = order\n",
    "        nodes.append(block_data)\n",
    "        \n",
    "        # 添加所有出边\n",
    "        for link in current_block.exits:\n",
    "            if hasattr(link, \"target\"):\n",
    "                edges.append({\n",
    "                    \"from\": current_block.id,\n",
    "                    \"to\": link.target.id\n",
    "                })\n",
    "                if link.target not in visited:\n",
    "                    block_order += 1\n",
    "                    queue.append((link.target, block_order))\n",
    "    \n",
    "    # 按order排序节点\n",
    "    nodes.sort(key=lambda x: x[\"order\"])\n",
    "    return nodes, edges\n",
    "\n",
    "def process_cfg_recursively(cfg_obj, prefix=\"\", processed=None, context=None):\n",
    "    \"\"\"递归处理CFG对象，返回所有代码块\"\"\"\n",
    "    if processed is None:\n",
    "        processed = set()\n",
    "    if context is None:\n",
    "        context = {\"in_class\": False}\n",
    "    \n",
    "    blocks = []\n",
    "    \n",
    "    # 使用cfg_obj的id作为唯一标识\n",
    "    cfg_id = id(cfg_obj)\n",
    "    if cfg_id in processed:\n",
    "        return blocks\n",
    "    processed.add(cfg_id)\n",
    "    \n",
    "    # 处理当前层级的主体代码\n",
    "    if hasattr(cfg_obj, 'entryblock'):\n",
    "        nodes, edges = process_block(f\"{prefix}\", cfg_obj)\n",
    "        if nodes:  # 只有当有实际内容时才添加\n",
    "            block_type = \"GlobalBlock\"\n",
    "            if context.get(\"in_class\"):\n",
    "                if prefix.endswith(\".__init__\"):\n",
    "                    block_type = \"Constructor\"\n",
    "                elif \".\" in prefix:\n",
    "                    block_type = \"Method\"\n",
    "                else:\n",
    "                    block_type = \"ClassBody\"\n",
    "            elif prefix:\n",
    "                block_type = \"Function\"\n",
    "                \n",
    "            # 处理嵌套类名称\n",
    "            display_name = prefix\n",
    "            if \".\" in prefix and not context.get(\"in_class\"):\n",
    "                parts = prefix.split(\".\")\n",
    "                display_name = \".\".join([p if i == 0 else f\"Input\" if p == \"Input\" else p \n",
    "                                       for i, p in enumerate(parts)])\n",
    "            \n",
    "            blocks.append({\n",
    "                \"name\": f\"{block_type}: {display_name}\" if prefix else block_type,\n",
    "                \"nodes\": nodes,\n",
    "                \"edges\": edges,\n",
    "                \"type\": block_type,\n",
    "                \"original_name\": prefix,  # 保存原始名称用于排序\n",
    "                \"line_info\": (min([n.get(\"start_line\", 0) for n in nodes] or [0]),\n",
    "                            max([n.get(\"end_line\", 0) for n in nodes] or [0]))\n",
    "            })\n",
    "    \n",
    "    # 获取所有需要处理的项\n",
    "    all_items = []\n",
    "    \n",
    "    # 添加类\n",
    "    if hasattr(cfg_obj, 'class_cfgs'):\n",
    "        for class_name, class_cfg in cfg_obj.class_cfgs.items():\n",
    "            all_items.append(('class', class_name, class_cfg))\n",
    "    \n",
    "    # 添加方法\n",
    "    if hasattr(cfg_obj, 'methodcfgs'):\n",
    "        for method_name, method_cfg in cfg_obj.methodcfgs.items():\n",
    "            all_items.append(('method', method_name, method_cfg))\n",
    "    \n",
    "    # 添加函数\n",
    "    if hasattr(cfg_obj, 'functioncfgs'):\n",
    "        for func_name, func_cfg in cfg_obj.functioncfgs.items():\n",
    "            all_items.append(('function', func_name, func_cfg))\n",
    "    \n",
    "    # 按照源代码中的顺序排序\n",
    "    def get_first_line(item):\n",
    "        _, _, cfg = item\n",
    "        if hasattr(cfg, 'entryblock') and hasattr(cfg.entryblock, 'statements'):\n",
    "            statements = cfg.entryblock.statements\n",
    "            if statements and hasattr(statements[0], 'lineno'):\n",
    "                return statements[0].lineno\n",
    "        return float('inf')\n",
    "    \n",
    "    all_items.sort(key=get_first_line)\n",
    "    \n",
    "    # 按顺序处理所有项\n",
    "    for item_type, name, sub_cfg in all_items:\n",
    "        if id(sub_cfg) in processed:\n",
    "            continue\n",
    "        \n",
    "        new_prefix = f\"{prefix}.{name}\" if prefix else name\n",
    "        new_context = {\"in_class\": item_type == 'class'}\n",
    "        \n",
    "        # 递归处理\n",
    "        sub_blocks = process_cfg_recursively(\n",
    "            sub_cfg,\n",
    "            new_prefix,\n",
    "            processed,\n",
    "            new_context\n",
    "        )\n",
    "        blocks.extend(sub_blocks)\n",
    "    \n",
    "    return blocks\n",
    "\n",
    "def parse_cfg(cfg):\n",
    "    \"\"\"解析CFG为结构化数据\"\"\"\n",
    "    return process_cfg_recursively(cfg)\n",
    "\n",
    "def dedent_code(code: str) -> str:\n",
    "    \"\"\"处理代码缩进\"\"\"\n",
    "    lines = code.split('\\n')\n",
    "    if not lines:\n",
    "        return ''\n",
    "    \n",
    "    # 找到最小的非空行缩进\n",
    "    min_indent = float('inf')\n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            indent = len(line) - len(line.lstrip())\n",
    "            min_indent = min(min_indent, indent)\n",
    "    \n",
    "    if min_indent == float('inf'):\n",
    "        return code\n",
    "    \n",
    "    # 删除多余的缩进\n",
    "    result = []\n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            result.append(line[min_indent:])\n",
    "        else:\n",
    "            result.append(line)\n",
    "    \n",
    "    return '\\n'.join(result)\n",
    "\n",
    "def convert_parsed_cfg_to_codeblock(cfg_blocks) -> List[CodeBlock]:\n",
    "    \"\"\"将解析后的CFG转换为CodeBlock结构\"\"\"\n",
    "    def create_cfg_data(block) -> CFGData:\n",
    "        nodes = []\n",
    "        edges = []\n",
    "        \n",
    "        # 转换节点\n",
    "        for node in block[\"nodes\"]:\n",
    "            nodes.append(CFGNode(\n",
    "                id=node[\"id\"],\n",
    "                code=node[\"code\"],\n",
    "                order=node[\"order\"],\n",
    "                start_line=node.get(\"start_line\", 0),\n",
    "                end_line=node.get(\"end_line\", 0)\n",
    "            ))\n",
    "        \n",
    "        # 转换边\n",
    "        for edge in block[\"edges\"]:\n",
    "            edges.append(CFGEdge(\n",
    "                from_node=edge[\"from\"],\n",
    "                to_node=edge[\"to\"]\n",
    "            ))\n",
    "        \n",
    "        return CFGData(nodes=nodes, edges=edges)\n",
    "    \n",
    "    def get_block_code(nodes: List[dict]) -> str:\n",
    "        \"\"\"从节点列表中提取完整的代码\"\"\"\n",
    "        sorted_nodes = sorted(nodes, key=lambda x: x[\"order\"])\n",
    "        code_parts = []\n",
    "        for node in sorted_nodes:\n",
    "            if node[\"code\"]:\n",
    "                code_parts.append(dedent_code(node[\"code\"]))\n",
    "        return \"\\n\".join(code_parts)\n",
    "    \n",
    "    def build_block_hierarchy(blocks: List[dict]) -> List[CodeBlock]:\n",
    "        \"\"\"构建代码块层级结构\"\"\"\n",
    "        # 按照行号排序所有块\n",
    "        sorted_blocks = sorted(blocks, key=lambda x: x[\"line_info\"][0])\n",
    "        \n",
    "        # 创建一个映射来存储所有块\n",
    "        block_map = {}  # original_name -> CodeBlock\n",
    "        \n",
    "        # 第一遍：创建所有 CodeBlock 对象\n",
    "        for block in sorted_blocks:\n",
    "            name = block[\"original_name\"]\n",
    "            cfg_data = create_cfg_data(block)\n",
    "            code = get_block_code(block[\"nodes\"])\n",
    "            start_line, end_line = block[\"line_info\"]\n",
    "            \n",
    "            code_block = CodeBlock(\n",
    "                decl_name=name,\n",
    "                start_line=start_line,\n",
    "                end_line=end_line,\n",
    "                children=[],\n",
    "                code=code,\n",
    "                cfg=cfg_data\n",
    "            )\n",
    "            block_map[name] = code_block\n",
    "        \n",
    "        # 第二遍：构建层级关系\n",
    "        result = []\n",
    "        for block in sorted_blocks:\n",
    "            name = block[\"original_name\"]\n",
    "            code_block = block_map[name]\n",
    "            \n",
    "            # 检查是否是某个类的成员\n",
    "            if \".\" in name:\n",
    "                parent_name = name.split(\".\")[0]\n",
    "                if parent_name in block_map:\n",
    "                    block_map[parent_name].children.append(code_block)\n",
    "                    continue\n",
    "            \n",
    "            # 如果不是成员，添加到结果列表\n",
    "            result.append(code_block)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    return build_block_hierarchy(cfg_blocks)\n",
    "\n",
    "def visualize_cfg(code_blocks: List[CodeBlock], indent: str = \"\") -> str:\n",
    "    \"\"\"生成CFG的文本可视化\"\"\"\n",
    "    result = [\"Optimized Code Block Hierarchy:\"]\n",
    "    \n",
    "    def visualize_block(block: CodeBlock, level: int = 0):\n",
    "        \"\"\"递归可视化代码块及其子块\"\"\"\n",
    "        indent = \"  \" * level\n",
    "        lines = []\n",
    "        \n",
    "        # 添加块名称和行号范围\n",
    "        block_info = f\"{indent}Block: {block.decl_name}\"\n",
    "        if block.start_line > 0 and block.end_line > 0:\n",
    "            block_info += f\" (lines {block.start_line}-{block.end_line})\"\n",
    "        lines.append(block_info)\n",
    "        \n",
    "        # 添加代码内容\n",
    "        lines.append(f\"{indent}Code:\")\n",
    "        for line in block.code.split('\\n'):\n",
    "            if line.strip():\n",
    "                lines.append(f\"{indent}  {line}\")\n",
    "        \n",
    "        # 添加CFG信息（如果存在）\n",
    "        if block.cfg:\n",
    "            lines.append(f\"{indent}CFG Nodes: {len(block.cfg.nodes)}\")\n",
    "            lines.append(f\"{indent}CFG Edges: {len(block.cfg.edges)}\")\n",
    "            \n",
    "            # 按顺序显示节点\n",
    "            lines.append(f\"{indent}Nodes (in order):\")\n",
    "            sorted_nodes = sorted(block.cfg.nodes, key=lambda x: x.order)\n",
    "            for node in sorted_nodes:\n",
    "                lines.append(f\"{indent}  Node {node.id} (order {node.order})\")\n",
    "            \n",
    "            # 显示边\n",
    "            lines.append(f\"{indent}Edges:\")\n",
    "            for edge in block.cfg.edges:\n",
    "                lines.append(f\"{indent}  {edge.from_node} -> {edge.to_node}\")\n",
    "        \n",
    "        # 递归处理子块\n",
    "        if block.children:\n",
    "            lines.append(f\"{indent}Children:\")\n",
    "            for child in block.children:\n",
    "                lines.extend(visualize_block(child, level + 1))\n",
    "        \n",
    "        lines.append(\"\")  # 添加空行分隔不同的块\n",
    "        return lines\n",
    "    \n",
    "    # 处理所有顶层块\n",
    "    for block in code_blocks:\n",
    "        result.extend(visualize_block(block))\n",
    "    \n",
    "    return '\\n'.join(result)\n",
    "\n",
    "# 使用示例：\n",
    "if __name__ == \"__main__\":\n",
    "    from scalpel.cfg import CFGBuilder\n",
    "\n",
    "    file_path = \"source_code/0.py\"\n",
    "    src = open(file_path, 'r', encoding='utf-8').read()\n",
    "\n",
    "    cfg = CFGBuilder().build_from_src(\"1\", src)\n",
    "    parsed_cfg = parse_cfg(cfg)\n",
    "    static_blocks = convert_parsed_cfg_to_codeblock(parsed_cfg)\n",
    "    print(visualize_cfg(static_blocks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "代码块匹配结果\n",
      "==================================================\n",
      "\n",
      "1. 匹配的代码块对:\n",
      "create_test_user               <-> (1, 'create_test_user')        (相似度: 80.90%)\n",
      "sample_agent                   <-> (1, 'sample_agent')            (相似度: 80.13%)\n",
      "create_test_graph              <-> (1, 'create_test_graph')       (相似度: 77.09%)\n",
      "\n",
      "2. LLM代码块的拓扑排序:\n",
      "GlobalBlock -> run -> sample_agent -> SpinTestServer -> print -> test_execute_graph -> create_test_user -> create_graph -> create_test_graph -> wait_execution -> get_or_create_user -> AgentInputBlock -> Node -> Link -> FillTextTemplateBlock -> PrintToConsoleBlock -> Graph\n",
      "\n",
      "3. 静态分析代码块的拓扑排序:\n",
      "(1, 'create_test_user') -> (1, 'create_test_graph') -> (1, 'sample_agent')\n",
      "\n",
      "4. 覆盖率: 60.00%\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, deque\n",
    "\n",
    "\n",
    "def extract_calls_from_cfg(cfg_node: CFGNode) -> List[str]:\n",
    "    \"\"\"从CFG节点的代码中提取函数调用\"\"\"\n",
    "    import ast\n",
    "    \n",
    "    class CallVisitor(ast.NodeVisitor):\n",
    "        def __init__(self):\n",
    "            self.calls = []\n",
    "            \n",
    "        def visit_Call(self, node):\n",
    "            if isinstance(node.func, ast.Name):\n",
    "                self.calls.append(node.func.id)\n",
    "            elif isinstance(node.func, ast.Attribute):\n",
    "                self.calls.append(node.func.attr)\n",
    "            self.generic_visit(node)\n",
    "    \n",
    "    calls = []\n",
    "    try:\n",
    "        tree = ast.parse(cfg_node.code)\n",
    "        visitor = CallVisitor()\n",
    "        visitor.visit(tree)\n",
    "        calls = visitor.calls\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return calls\n",
    "\n",
    "@dataclass\n",
    "class BlockWithCalls:\n",
    "    \"\"\"包含调用信息的代码块\"\"\"\n",
    "    decl_name: str\n",
    "    code: str\n",
    "    calls: List[str]\n",
    "\n",
    "def convert_to_blocks_with_calls(code_blocks: List[CodeBlock]) -> List[BlockWithCalls]:\n",
    "    \"\"\"将CodeBlock转换为包含调用信息的BlockWithCalls\"\"\"\n",
    "    blocks_with_calls = []\n",
    "    \n",
    "    for block in code_blocks:\n",
    "        calls = []\n",
    "        if block.cfg:\n",
    "            # 从所有CFG节点中收集调用\n",
    "            for node in block.cfg.nodes:\n",
    "                calls.extend(extract_calls_from_cfg(node))\n",
    "        \n",
    "        # 去重调用\n",
    "        calls = list(set(calls))\n",
    "        \n",
    "        blocks_with_calls.append(BlockWithCalls(\n",
    "            decl_name=block.decl_name,\n",
    "            code=block.code,\n",
    "            calls=calls\n",
    "        ))\n",
    "    \n",
    "    return blocks_with_calls\n",
    "\n",
    "class TopologicalBlockMatcher:\n",
    "    def __init__(self):\n",
    "        self.similarity_threshold = 0.7\n",
    "\n",
    "    def blocks_to_graph(self, blocks: List[BlockWithCalls]) -> Dict[str, List[str]]:\n",
    "        \"\"\"将代码块列表转换为邻接表表示的图\"\"\"\n",
    "        graph = defaultdict(list)\n",
    "        for block in blocks:\n",
    "            graph[block.decl_name].extend(block.calls)\n",
    "        return dict(graph)\n",
    "\n",
    "    def get_block_by_name(self, blocks: List[BlockWithCalls], name: str) -> BlockWithCalls:\n",
    "        \"\"\"通过函数名获取代码块\"\"\"\n",
    "        for block in blocks:\n",
    "            if block.decl_name == name:\n",
    "                return block\n",
    "        return None\n",
    "\n",
    "    def topological_sort(self, blocks: List[BlockWithCalls]) -> List[str]:\n",
    "        \"\"\"\n",
    "        对代码块进行拓扑排序\n",
    "        Returns:\n",
    "            排序后的函数名列表\n",
    "        \"\"\"\n",
    "        if not blocks:\n",
    "            return []\n",
    "            \n",
    "        # 构建图\n",
    "        graph = self.blocks_to_graph(blocks)\n",
    "        \n",
    "        # 计算入度\n",
    "        in_degree = defaultdict(int)\n",
    "        for node in graph:\n",
    "            for successor in graph[node]:\n",
    "                if successor:  # 确保successor不是None\n",
    "                    in_degree[successor] += 1\n",
    "            if node not in in_degree:\n",
    "                in_degree[node] = 0\n",
    "    \n",
    "        # 初始化队列（入度为0的节点）\n",
    "        queue = deque([node for node, degree in in_degree.items() if degree == 0 and node])\n",
    "        result = []\n",
    "    \n",
    "        # BFS进行拓扑排序\n",
    "        while queue:\n",
    "            node = queue.popleft()\n",
    "            if node:  # 确保node不是None\n",
    "                result.append(node)\n",
    "                for successor in graph.get(node, []):\n",
    "                    if successor:  # 确保successor不是None\n",
    "                        in_degree[successor] -= 1\n",
    "                        if in_degree[successor] == 0:\n",
    "                            queue.append(successor)\n",
    "    \n",
    "        # 添加可能未被引用的节点\n",
    "        all_nodes = {block.decl_name for block in blocks if block.decl_name}\n",
    "        for node in all_nodes:\n",
    "            if node and node not in result:\n",
    "                result.append(node)\n",
    "    \n",
    "        return result\n",
    "\n",
    "\n",
    "    def calculate_code_similarity(self, code1: str, code2: str) -> float:\n",
    "        \"\"\"计算代码相似度\"\"\"\n",
    "        # 简化代码（移除空白字符和注释）\n",
    "        def clean_code(code: str) -> str:\n",
    "            import re\n",
    "            # 移除注释\n",
    "            code = re.sub(r'#.*$', '', code, flags=re.MULTILINE)\n",
    "            # 移除多余空白字符\n",
    "            code = ' '.join(code.split())\n",
    "            return code\n",
    "        \n",
    "        code1 = clean_code(code1)\n",
    "        code2 = clean_code(code2)\n",
    "        \n",
    "        if not code1 or not code2:\n",
    "            return 0.0\n",
    "        \n",
    "        if code1 == code2:\n",
    "            return 1.0\n",
    "            \n",
    "        # 使用最长公共子序列计算相似度\n",
    "        return self.lcs_similarity(code1, code2)\n",
    "\n",
    "    def lcs_similarity(self, s1: str, s2: str) -> float:\n",
    "        \"\"\"使用最长公共子序列计算相似度\"\"\"\n",
    "        m, n = len(s1), len(s2)\n",
    "        dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "        \n",
    "        for i in range(1, m + 1):\n",
    "            for j in range(1, n + 1):\n",
    "                if s1[i-1] == s2[j-1]:\n",
    "                    dp[i][j] = dp[i-1][j-1] + 1\n",
    "                else:\n",
    "                    dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n",
    "        \n",
    "        lcs_length = dp[m][n]\n",
    "        return 2.0 * lcs_length / (len(s1) + len(s2))\n",
    "\n",
    "    def calculate_structural_similarity(self, \n",
    "                                     block1: BlockWithCalls, \n",
    "                                     block2: BlockWithCalls, \n",
    "                                     position1: int, \n",
    "                                     position2: int,\n",
    "                                     max_pos: int) -> float:\n",
    "        \"\"\"计算结构相似度\"\"\"\n",
    "        # 位置相似度\n",
    "        pos_sim = 1.0 - abs(position1 - position2) / max_pos if max_pos > 0 else 1.0\n",
    "        \n",
    "        # 调用关系相似度\n",
    "        calls1 = set(block1.calls)\n",
    "        calls2 = set(block2.calls)\n",
    "        calls_sim = len(calls1 & calls2) / len(calls1 | calls2) if calls1 or calls2 else 1.0\n",
    "        \n",
    "        # 计算加权平均\n",
    "        return 0.4 * pos_sim + 0.6 * calls_sim\n",
    "\n",
    "    def match_blocks(self, \n",
    "                    llm_blocks: List[BlockWithCalls], \n",
    "                    static_blocks: List[BlockWithCalls]) -> Dict:\n",
    "        \"\"\"匹配两组代码块\"\"\"\n",
    "        # 1. 对两组代码块进行拓扑排序\n",
    "        sorted_llm = self.topological_sort(llm_blocks)\n",
    "        sorted_static = self.topological_sort(static_blocks)\n",
    "\n",
    "        # 2. 计算匹配\n",
    "        matches = []\n",
    "        max_pos = max(len(sorted_llm), len(sorted_static)) - 1\n",
    "        if max_pos < 0:\n",
    "            max_pos = 0\n",
    "\n",
    "        # 构建快速查找字典\n",
    "        llm_blocks_dict = {b.decl_name: b for b in llm_blocks}\n",
    "        static_blocks_dict = {b.decl_name: b for b in static_blocks}\n",
    "\n",
    "        for i, name1 in enumerate(sorted_llm):\n",
    "            block1 = llm_blocks_dict.get(name1)\n",
    "            if not block1:\n",
    "                continue\n",
    "\n",
    "            for j, name2 in enumerate(sorted_static):\n",
    "                block2 = static_blocks_dict.get(name2)\n",
    "                if not block2:\n",
    "                    continue\n",
    "\n",
    "                # 计算代码相似度\n",
    "                code_sim = self.calculate_code_similarity(block1.code, block2.code)\n",
    "                \n",
    "                # 计算结构相似度\n",
    "                struct_sim = self.calculate_structural_similarity(\n",
    "                    block1, block2, i, j, max_pos\n",
    "                )\n",
    "                \n",
    "                # 综合相似度\n",
    "                similarity = 0.6 * code_sim + 0.4 * struct_sim\n",
    "                \n",
    "                if similarity >= self.similarity_threshold:\n",
    "                    matches.append((name1, name2, similarity))\n",
    "\n",
    "        return {\n",
    "            'matches': sorted(matches, key=lambda x: x[2], reverse=True),\n",
    "            'topological_order_llm': sorted_llm,\n",
    "            'topological_order_static': sorted_static,\n",
    "            'coverage': len(set(m[0] for m in matches)) / len(llm_blocks) if llm_blocks else 0.0\n",
    "        }\n",
    "\n",
    "def format_match_line(block1: str, block2: str, similarity: float, width: int = 30) -> str:\n",
    "    \"\"\"格式化匹配结果行\"\"\"\n",
    "    block1_str = str(block1).ljust(width)\n",
    "    block2_str = str(block2).ljust(width)\n",
    "    return f\"{block1_str} <-> {block2_str} (相似度: {similarity:.2%})\"\n",
    "\n",
    "def print_match_results(result: Dict):\n",
    "    \"\"\"打印匹配结果\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"代码块匹配结果\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"\\n1. 匹配的代码块对:\")\n",
    "    if result['matches']:\n",
    "        for block1, block2, sim in result['matches']:\n",
    "            print(format_match_line(block1, block2, sim))\n",
    "    else:\n",
    "        print(\"未找到匹配的代码块\")\n",
    "    \n",
    "    print(\"\\n2. LLM代码块的拓扑排序:\")\n",
    "    llm_order = [str(x) for x in result['topological_order_llm'] if x is not None]\n",
    "    print(\" -> \".join(llm_order) if llm_order else \"空\")\n",
    "    \n",
    "    print(\"\\n3. 静态分析代码块的拓扑排序:\")\n",
    "    static_order = [str(x) for x in result['topological_order_static'] if x is not None]\n",
    "    print(\" -> \".join(static_order) if static_order else \"空\")\n",
    "    \n",
    "    print(f\"\\n4. 覆盖率: {result['coverage']:.2%}\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 转换为带调用信息的代码块\n",
    "    llm_blocks_with_calls = convert_to_blocks_with_calls(llm_blocks)\n",
    "    static_blocks_with_calls = convert_to_blocks_with_calls(static_blocks)\n",
    "    \n",
    "    # 进行匹配\n",
    "    matcher = TopologicalBlockMatcher()\n",
    "    result = matcher.match_blocks(llm_blocks_with_calls, static_blocks_with_calls)\n",
    "    print_match_results(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scalpel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
