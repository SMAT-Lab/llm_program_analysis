{
  "name": "example_script",
  "type": "CFG",
  "start_line": 1,
  "end_line": 264,
  "functions": [],
  "classes": [
    {
      "name": "SamplingMethod",
      "type": "class",
      "start_line": 10,
      "end_line": 18,
      "functions": [],
      "classes": [],
      "simplified_code": "class SamplingMethod(str, Enum):\n    RANDOM = \"random\"\n    SYSTEMATIC = \"systematic\"\n    TOP = \"top\"\n    BOTTOM = \"bottom\"\n    STRATIFIED = \"stratified\"\n    WEIGHTED = \"weighted\"\n    RESERVOIR = \"reservoir\"\n    CLUSTER = \"cluster\"",
      "blocks": [
        {
          "id": 1,
          "label": "class SamplingMethod(str, Enum):\n    RANDOM = \"random\"\n    SYSTEMATIC = \"systematic\"\n    TOP = \"top\"\n    BOTTOM = \"bottom\"\n    STRATIFIED = \"stratified\"\n    WEIGHTED = \"weighted\"\n    RESERVOIR = \"reservoir\"\n    CLUSTER = \"cluster\"",
          "successors": []
        }
      ]
    },
    {
      "name": "DataSamplingBlock",
      "type": "class",
      "start_line": 21,
      "end_line": 264,
      "functions": [
        {
          "name": "__init__",
          "type": "function",
          "start_line": 65,
          "end_line": 94,
          "functions": [],
          "classes": [],
          "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"4a448883-71fa-49cf-91cf-70d793bd7d87\",\n            description=\"This block samples data from a given dataset using various sampling methods.\",\n            categories={BlockCategory.LOGIC},\n            input_schema=DataSamplingBlock.Input,\n            output_schema=DataSamplingBlock.Output,\n            test_input={\n                \"data\": [\n                    {\"id\": i, \"value\": chr(97 + i), \"group\": i % 3} for i in range(10)\n                ],\n                \"sample_size\": 3,\n                \"sampling_method\": SamplingMethod.STRATIFIED,\n                \"accumulate\": False,\n                \"random_seed\": 42,\n                \"stratify_key\": \"group\",\n            },\n            test_output=[\n                (\n                    \"sampled_data\",\n                    [\n                        {\"id\": 0, \"value\": \"a\", \"group\": 0},\n                        {\"id\": 1, \"value\": \"b\", \"group\": 1},\n                        {\"id\": 8, \"value\": \"i\", \"group\": 2},\n                    ],\n                ),\n                (\"sample_indices\", [0, 1, 8]),\n            ],\n        )\n        self.accumulated_data = []",
          "blocks": [
            {
              "id": 1,
              "label": "def __init__(self):\nsuper().__init__(\n    id=\"4a448883-71fa-49cf-91cf-70d793bd7d87\",\n    description=\"This block samples data from a given dataset using various sampling methods.\",\n    categories={BlockCategory.LOGIC},\n    input_schema=DataSamplingBlock.Input,\n    output_schema=DataSamplingBlock.Output,\n    test_input={\n        \"data\": [\n            {\"id\": i, \"value\": chr(97 + i), \"group\": i % 3} for i in range(10)\n        ],\n        \"sample_size\": 3,\n        \"sampling_method\": SamplingMethod.STRATIFIED,\n        \"accumulate\": False,\n        \"random_seed\": 42,\n        \"stratify_key\": \"group\",\n    },\n    test_output=[\n        (\n            \"sampled_data\",\n            [\n                {\"id\": 0, \"value\": \"a\", \"group\": 0},\n                {\"id\": 1, \"value\": \"b\", \"group\": 1},\n                {\"id\": 8, \"value\": \"i\", \"group\": 2},\n            ],\n        ),\n        (\"sample_indices\", [0, 1, 8]),\n    ],\n)",
              "successors": [
                {
                  "id": 3,
                  "label": "self.accumulated_data = []",
                  "successors": []
                }
              ]
            }
          ]
        },
        {
          "name": "run",
          "type": "function",
          "start_line": 96,
          "end_line": 264,
          "functions": [],
          "classes": [],
          "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        if input_data.accumulate:\n            if isinstance(input_data.data, dict):\n                self.accumulated_data.append(input_data.data)\n            elif isinstance(input_data.data, list):\n                self.accumulated_data.extend(input_data.data)\n            else:\n                raise ValueError(f\"Unsupported data type: {type(input_data.data)}\")\n\n            # If we don't have enough data yet, return without sampling\n            if len(self.accumulated_data) < input_data.sample_size:\n                return\n\n            data_to_sample = self.accumulated_data\n        else:\n            # If not accumulating, use the input data directly\n            data_to_sample = (\n                input_data.data\n                if isinstance(input_data.data, list)\n                else [input_data.data]\n            )\n\n        if input_data.random_seed is not None:\n            random.seed(input_data.random_seed)\n\n        data_size = len(data_to_sample)\n\n        if input_data.sample_size > data_size:\n            raise ValueError(\n                f\"Sample size ({input_data.sample_size}) cannot be larger than the dataset size ({data_size}).\"\n            )\n\n        indices = []\n\n        if input_data.sampling_method == SamplingMethod.RANDOM:\n            indices = random.sample(range(data_size), input_data.sample_size)\n        elif input_data.sampling_method == SamplingMethod.SYSTEMATIC:\n            step = data_size // input_data.sample_size\n            start = random.randint(0, step - 1)\n            indices = list(range(start, data_size, step))[: input_data.sample_size]\n        elif input_data.sampling_method == SamplingMethod.TOP:\n            indices = list(range(input_data.sample_size))\n        elif input_data.sampling_method == SamplingMethod.BOTTOM:\n            indices = list(range(data_size - input_data.sample_size, data_size))\n        elif input_data.sampling_method == SamplingMethod.STRATIFIED:\n            if not input_data.stratify_key:\n                raise ValueError(\n                    \"Stratify key must be provided for stratified sampling.\"\n                )\n            strata = defaultdict(list)\n            for i, item in enumerate(data_to_sample):\n                if isinstance(item, dict):\n                    strata_value = item.get(input_data.stratify_key)\n                elif hasattr(item, input_data.stratify_key):\n                    strata_value = getattr(item, input_data.stratify_key)\n                else:\n                    raise ValueError(\n                        f\"Stratify key '{input_data.stratify_key}' not found in item {item}\"\n                    )\n\n                if strata_value is None:\n                    raise ValueError(\n                        f\"Stratify value for key '{input_data.stratify_key}' is None\"\n                    )\n\n                strata[str(strata_value)].append(i)\n\n            # Calculate the number of samples to take from each stratum\n            stratum_sizes = {\n                k: max(1, int(len(v) / data_size * input_data.sample_size))\n                for k, v in strata.items()\n            }\n\n            # Adjust sizes to ensure we get exactly sample_size samples\n            while sum(stratum_sizes.values()) != input_data.sample_size:\n                if sum(stratum_sizes.values()) < input_data.sample_size:\n                    stratum_sizes[\n                        max(stratum_sizes, key=lambda k: stratum_sizes[k])\n                    ] += 1\n                else:\n                    stratum_sizes[\n                        max(stratum_sizes, key=lambda k: stratum_sizes[k])\n                    ] -= 1\n\n            for stratum, size in stratum_sizes.items():\n                indices.extend(random.sample(strata[stratum], size))\n        elif input_data.sampling_method == SamplingMethod.WEIGHTED:\n            if not input_data.weight_key:\n                raise ValueError(\"Weight key must be provided for weighted sampling.\")\n            weights = []\n            for item in data_to_sample:\n                if isinstance(item, dict):\n                    weight = item.get(input_data.weight_key)\n                elif hasattr(item, input_data.weight_key):\n                    weight = getattr(item, input_data.weight_key)\n                else:\n                    raise ValueError(\n                        f\"Weight key '{input_data.weight_key}' not found in item {item}\"\n                    )\n\n                if weight is None:\n                    raise ValueError(\n                        f\"Weight value for key '{input_data.weight_key}' is None\"\n                    )\n                try:\n                    weights.append(float(weight))\n                except ValueError:\n                    raise ValueError(\n                        f\"Weight value '{weight}' cannot be converted to a number\"\n                    )\n\n            if not weights:\n                raise ValueError(\n                    f\"No valid weights found using key '{input_data.weight_key}'\"\n                )\n\n            indices = random.choices(\n                range(data_size), weights=weights, k=input_data.sample_size\n            )\n        elif input_data.sampling_method == SamplingMethod.RESERVOIR:\n            indices = list(range(input_data.sample_size))\n            for i in range(input_data.sample_size, data_size):\n                j = random.randint(0, i)\n                if j < input_data.sample_size:\n                    indices[j] = i\n        elif input_data.sampling_method == SamplingMethod.CLUSTER:\n            if not input_data.cluster_key:\n                raise ValueError(\"Cluster key must be provided for cluster sampling.\")\n            clusters = defaultdict(list)\n            for i, item in enumerate(data_to_sample):\n                if isinstance(item, dict):\n                    cluster_value = item.get(input_data.cluster_key)\n                elif hasattr(item, input_data.cluster_key):\n                    cluster_value = getattr(item, input_data.cluster_key)\n                else:\n                    raise TypeError(\n                        f\"Item {item} does not have the cluster key '{input_data.cluster_key}'\"\n                    )\n\n                clusters[str(cluster_value)].append(i)\n\n            # Randomly select clusters until we have enough samples\n            selected_clusters = []\n            while (\n                sum(len(clusters[c]) for c in selected_clusters)\n                < input_data.sample_size\n            ):\n                available_clusters = [c for c in clusters if c not in selected_clusters]\n                if not available_clusters:\n                    break\n                selected_clusters.append(random.choice(available_clusters))\n\n            for cluster in selected_clusters:\n                indices.extend(clusters[cluster])\n\n            # If we have more samples than needed, randomly remove some\n            if len(indices) > input_data.sample_size:\n                indices = random.sample(indices, input_data.sample_size)\n        else:\n            raise ValueError(f\"Unknown sampling method: {input_data.sampling_method}\")\n\n        sampled_data = [data_to_sample[i] for i in indices]\n\n        # Clear accumulated data after sampling if accumulation is enabled\n        if input_data.accumulate:\n            self.accumulated_data = []\n\n        yield \"sampled_data\", sampled_data\n        yield \"sample_indices\", indices",
          "blocks": [
            {
              "id": 1,
              "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:",
              "successors": [
                {
                  "id": 2,
                  "label": "if input_data.accumulate:",
                  "successors": [
                    {
                      "id": 3,
                      "label": "if isinstance(input_data.data, dict):\n    self.accumulated_data.append(input_data.data)",
                      "successors": []
                    },
                    {
                      "id": 4,
                      "label": "elif isinstance(input_data.data, list):\n    self.accumulated_data.extend(input_data.data)",
                      "successors": []
                    },
                    {
                      "id": 5,
                      "label": "else:\n    raise ValueError(f\"Unsupported data type: {type(input_data.data)}\")",
                      "successors": []
                    },
                    {
                      "id": 6,
                      "label": "if len(self.accumulated_data) < input_data.sample_size:\n    return",
                      "successors": []
                    },
                    {
                      "id": 7,
                      "label": "data_to_sample = self.accumulated_data",
                      "successors": []
                    }
                  ]
                },
                {
                  "id": 8,
                  "label": "else:\n    data_to_sample = (input_data.data if isinstance(input_data.data, list) else [input_data.data])",
                  "successors": []
                },
                {
                  "id": 9,
                  "label": "if input_data.random_seed is not None:\n    random.seed(input_data.random_seed)",
                  "successors": []
                },
                {
                  "id": 10,
                  "label": "data_size = len(data_to_sample)",
                  "successors": []
                },
                {
                  "id": 11,
                  "label": "if input_data.sample_size > data_size:\n    raise ValueError(f\"Sample size ({input_data.sample_size}) cannot be larger than the dataset size ({data_size}).\")",
                  "successors": []
                },
                {
                  "id": 12,
                  "label": "indices = []",
                  "successors": []
                },
                {
                  "id": 13,
                  "label": "if input_data.sampling_method == SamplingMethod.RANDOM:\n    indices = random.sample(range(data_size), input_data.sample_size)",
                  "successors": []
                },
                {
                  "id": 14,
                  "label": "elif input_data.sampling_method == SamplingMethod.SYSTEMATIC:\n    step = data_size // input_data.sample_size\n    start = random.randint(0, step - 1)\n    indices = list(range(start, data_size, step))[: input_data.sample_size]",
                  "successors": []
                },
                {
                  "id": 15,
                  "label": "elif input_data.sampling_method == SamplingMethod.TOP:\n    indices = list(range(input_data.sample_size))",
                  "successors": []
                },
                {
                  "id": 16,
                  "label": "elif input_data.sampling_method == SamplingMethod.BOTTOM:\n    indices = list(range(data_size - input_data.sample_size, data_size))",
                  "successors": []
                },
                {
                  "id": 17,
                  "label": "elif input_data.sampling_method == SamplingMethod.STRATIFIED:",
                  "successors": [
                    {
                      "id": 18,
                      "label": "if not input_data.stratify_key:\n    raise ValueError(\"Stratify key must be provided for stratified sampling.\")",
                      "successors": []
                    },
                    {
                      "id": 19,
                      "label": "strata = defaultdict(list)",
                      "successors": []
                    },
                    {
                      "id": 20,
                      "label": "for i, item in enumerate(data_to_sample):",
                      "successors": [
                        {
                          "id": 21,
                          "label": "if isinstance(item, dict):\n    strata_value = item.get(input_data.stratify_key)",
                          "successors": []
                        },
                        {
                          "id": 22,
                          "label": "elif hasattr(item, input_data.stratify_key):\n    strata_value = getattr(item, input_data.stratify_key)",
                          "successors": []
                        },
                        {
                          "id": 23,
                          "label": "else:\n    raise ValueError(f\"Stratify key '{input_data.stratify_key}' not found in item {item}\")",
                          "successors": []
                        }
                      ]
                    },
                    {
                      "id": 24,
                      "label": "if strata_value is None:\n    raise ValueError(f\"Stratify value for key '{input_data.stratify_key}' is None\")",
                      "successors": []
                    },
                    {
                      "id": 25,
                      "label": "strata[str(strata_value)].append(i)",
                      "successors": []
                    },
                    {
                      "id": 26,
                      "label": "stratum_sizes = {k: max(1, int(len(v) / data_size * input_data.sample_size)) for k, v in strata.items()}",
                      "successors": []
                    },
                    {
                      "id": 27,
                      "label": "while sum(stratum_sizes.values()) != input_data.sample_size:",
                      "successors": [
                        {
                          "id": 28,
                          "label": "if sum(stratum_sizes.values()) < input_data.sample_size:\n    stratum_sizes[max(stratum_sizes, key=lambda k: stratum_sizes[k])] += 1",
                          "successors": []
                        },
                        {
                          "id": 29,
                          "label": "else:\n    stratum_sizes[max(stratum_sizes, key=lambda k: stratum_sizes[k])] -= 1",
                          "successors": []
                        }
                      ]
                    },
                    {
                      "id": 30,
                      "label": "for stratum, size in stratum_sizes.items():\n    indices.extend(random.sample(strata[stratum], size))",
                      "successors": []
                    }
                  ]
                },
                {
                  "id": 31,
                  "label": "elif input_data.sampling_method == SamplingMethod.WEIGHTED:",
                  "successors": [
                    {
                      "id": 32,
                      "label": "if not input_data.weight_key:\n    raise ValueError(\"Weight key must be provided for weighted sampling.\")",
                      "successors": []
                    },
                    {
                      "id": 33,
                      "label": "weights = []",
                      "successors": []
                    },
                    {
                      "id": 34,
                      "label": "for item in data_to_sample:",
                      "successors": [
                        {
                          "id": 35,
                          "label": "if isinstance(item, dict):\n    weight = item.get(input_data.weight_key)",
                          "successors": []
                        },
                        {
                          "id": 36,
                          "label": "elif hasattr(item, input_data.weight_key):\n    weight = getattr(item, input_data.weight_key)",
                          "successors": []
                        },
                        {
                          "id": 37,
                          "label": "else:\n    raise ValueError(f\"Weight key '{input_data.weight_key}' not found in item {item}\")",
                          "successors": []
                        }
                      ]
                    },
                    {
                      "id": 38,
                      "label": "if weight is None:\n    raise ValueError(f\"Weight value for key '{input_data.weight_key}' is None\")",
                      "successors": []
                    },
                    {
                      "id": 39,
                      "label": "try:\n    weights.append(float(weight))\nexcept ValueError:\n    raise ValueError(f\"Weight value '{weight}' cannot be converted to a number\")",
                      "successors": []
                    },
                    {
                      "id": 41,
                      "label": "if not weights:\n    raise ValueError(f\"No valid weights found using key '{input_data.weight_key}'\")",
                      "successors": []
                    },
                    {
                      "id": 42,
                      "label": "indices = random.choices(range(data_size), weights=weights, k=input_data.sample_size)",
                      "successors": []
                    }
                  ]
                },
                {
                  "id": 43,
                  "label": "elif input_data.sampling_method == SamplingMethod.RESERVOIR:",
                  "successors": [
                    {
                      "id": 44,
                      "label": "indices = list(range(input_data.sample_size))",
                      "successors": []
                    },
                    {
                      "id": 45,
                      "label": "for i in range(input_data.sample_size, data_size):\n    j = random.randint(0, i)\n    if j < input_data.sample_size:\n        indices[j] = i",
                      "successors": []
                    }
                  ]
                },
                {
                  "id": 46,
                  "label": "elif input_data.sampling_method == SamplingMethod.CLUSTER:",
                  "successors": [
                    {
                      "id": 47,
                      "label": "if not input_data.cluster_key:\n    raise ValueError(\"Cluster key must be provided for cluster sampling.\")",
                      "successors": []
                    },
                    {
                      "id": 48,
                      "label": "clusters = defaultdict(list)",
                      "successors": []
                    },
                    {
                      "id": 49,
                      "label": "for i, item in enumerate(data_to_sample):",
                      "successors": [
                        {
                          "id": 50,
                          "label": "if isinstance(item, dict):\n    cluster_value = item.get(input_data.cluster_key)",
                          "successors": []
                        },
                        {
                          "id": 51,
                          "label": "elif hasattr(item, input_data.cluster_key):\n    cluster_value = getattr(item, input_data.cluster_key)",
                          "successors": []
                        },
                        {
                          "id": 52,
                          "label": "else:\n    raise TypeError(f\"Item {item} does not have the cluster key '{input_data.cluster_key}'\")",
                          "successors": []
                        }
                      ]
                    },
                    {
                      "id": 53,
                      "label": "clusters[str(cluster_value)].append(i)",
                      "successors": []
                    },
                    {
                      "id": 54,
                      "label": "selected_clusters = []",
                      "successors": []
                    },
                    {
                      "id": 55,
                      "label": "while (sum(len(clusters[c]) for c in selected_clusters) < input_data.sample_size):",
                      "successors": [
                        {
                          "id": 56,
                          "label": "available_clusters = [c for c in clusters if c not in selected_clusters]",
                          "successors": []
                        },
                        {
                          "id": 57,
                          "label": "if not available_clusters:\n    break",
                          "successors": []
                        },
                        {
                          "id": 58,
                          "label": "selected_clusters.append(random.choice(available_clusters))",
                          "successors": []
                        }
                      ]
                    },
                    {
                      "id": 59,
                      "label": "for cluster in selected_clusters:\n    indices.extend(clusters[cluster])",
                      "successors": []
                    },
                    {
                      "id": 60,
                      "label": "if len(indices) > input_data.sample_size:\n    indices = random.sample(indices, input_data.sample_size)",
                      "successors": []
                    }
                  ]
                },
                {
                  "id": 61,
                  "label": "else:\n    raise ValueError(f\"Unknown sampling method: {input_data.sampling_method}\")",
                  "successors": []
                },
                {
                  "id": 62,
                  "label": "sampled_data = [data_to_sample[i] for i in indices]",
                  "successors": []
                },
                {
                  "id": 63,
                  "label": "if input_data.accumulate:\n    self.accumulated_data = []",
                  "successors": []
                },
                {
                  "id": 64,
                  "label": "yield \"sampled_data\", sampled_data",
                  "successors": []
                },
                {
                  "id": 65,
                  "label": "yield \"sample_indices\", indices",
                  "successors": []
                }
              ]
            }
          ]
        }
      ],
      "classes": [
        {
          "name": "Input",
          "type": "class",
          "start_line": 22,
          "end_line": 55,
          "functions": [],
          "classes": [],
          "simplified_code": "    class Input(BlockSchema):\n        data: Union[Dict[str, Any], List[Union[dict, List[Any]]]] = SchemaField(\n            description=\"The dataset to sample from. Can be a single dictionary, a list of dictionaries, or a list of lists.\",\n            placeholder=\"{'id': 1, 'value': 'a'} or [{'id': 1, 'value': 'a'}, {'id': 2, 'value': 'b'}, ...]\",\n        )\n        sample_size: int = SchemaField(\n            description=\"The number of samples to take from the dataset.\",\n            placeholder=\"10\",\n            default=10,\n        )\n        sampling_method: SamplingMethod = SchemaField(\n            description=\"The method to use for sampling.\",\n            default=SamplingMethod.RANDOM,\n        )\n        accumulate: bool = SchemaField(\n            description=\"Whether to accumulate data before sampling.\",\n            default=False,\n        )\n        random_seed: Optional[int] = SchemaField(\n            description=\"Seed for random number generator (optional).\",\n            default=None,\n        )\n        stratify_key: Optional[str] = SchemaField(\n            description=\"Key to use for stratified sampling (required for stratified sampling).\",\n            default=None,\n        )\n        weight_key: Optional[str] = SchemaField(\n            description=\"Key to use for weighted sampling (required for weighted sampling).\",\n            default=None,\n        )\n        cluster_key: Optional[str] = SchemaField(\n            description=\"Key to use for cluster sampling (required for cluster sampling).\",\n            default=None,\n        )",
          "blocks": [
            {
              "id": 1,
              "label": "class Input(BlockSchema):\ndata: Union[Dict[str, Any], List[Union[dict, List[Any]]]] = SchemaField(description=\"The dataset to sample from. Can be a single dictionary, a list of dictionaries, or a list of lists.\", placeholder=\"{'id': 1, 'value': 'a'} or [{'id': 1, 'value': 'a'}, {'id': 2, 'value': 'b'}, ...]\")",
              "successors": [
                {
                  "id": 3,
                  "label": "sample_size: int = SchemaField(description=\"The number of samples to take from the dataset.\", placeholder=\"10\", default=10)\nsampling_method: SamplingMethod = SchemaField(description=\"The method to use for sampling.\", default=SamplingMethod.RANDOM)",
                  "successors": [
                    {
                      "id": 5,
                      "label": "accumulate: bool = SchemaField(description=\"Whether to accumulate data before sampling.\", default=False)\nrandom_seed: Optional[int] = SchemaField(description=\"Seed for random number generator (optional).\", default=None)",
                      "successors": [
                        {
                          "id": 7,
                          "label": "stratify_key: Optional[str] = SchemaField(description=\"Key to use for stratified sampling (required for stratified sampling).\", default=None)\nweight_key: Optional[str] = SchemaField(description=\"Key to use for weighted sampling (required for weighted sampling).\", default=None)",
                          "successors": [
                            {
                              "id": 9,
                              "label": "cluster_key: Optional[str] = SchemaField(description=\"Key to use for cluster sampling (required for cluster sampling).\", default=None)",
                              "successors": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "name": "Output",
          "type": "class",
          "start_line": 57,
          "end_line": 63,
          "functions": [],
          "classes": [],
          "simplified_code": "    class Output(BlockSchema):\n        sampled_data: List[Union[dict, List[Any]]] = SchemaField(\n            description=\"The sampled subset of the input data.\"\n        )\n        sample_indices: List[int] = SchemaField(\n            description=\"The indices of the sampled data in the original dataset.\"\n        )",
          "blocks": [
            {
              "id": 1,
              "label": "class Output(BlockSchema):\n    sampled_data: List[Union[dict, List[Any]]] = SchemaField(\n        description=\"The sampled subset of the input data.\"\n    )",
              "successors": [
                {
                  "id": 3,
                  "label": "    sample_indices: List[int] = SchemaField(\n        description=\"The indices of the sampled data in the original dataset.\"\n    )",
                  "successors": []
                }
              ]
            }
          ]
        }
      ],
      "simplified_code": "class DataSamplingBlock(Block):\n        )\n\n        )\n\n        self.accumulated_data = []\n\n        yield \"sample_indices\", indices",
      "blocks": [
        {
          "id": 1,
          "label": "class DataSamplingBlock(Block):\n    pass",
          "successors": []
        }
      ]
    }
  ],
  "simplified_code": "import random\nfrom collections import defaultdict\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Union\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\n\n    CLUSTER = \"cluster\"\n\n\n        yield \"sample_indices\", indices",
  "blocks": [
    {
      "id": 1,
      "label": "import random\nfrom collections import defaultdict\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Union\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField",
      "successors": []
    }
  ]
}