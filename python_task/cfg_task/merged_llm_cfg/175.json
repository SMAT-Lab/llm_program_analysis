{
  "name": "example_script",
  "type": "CFG",
  "start_line": 1,
  "end_line": 175,
  "functions": [
    {
      "name": "_extract_schema_from_url",
      "type": "function",
      "start_line": 21,
      "end_line": 37,
      "functions": [],
      "classes": [],
      "simplified_code": "def _extract_schema_from_url(database_url) -> tuple[str, str]:\n    \"\"\"\n    Extracts the schema from the DATABASE_URL and returns the schema and cleaned URL.\n    \"\"\"\n    parsed_url = urlparse(database_url)\n    query_params = parse_qs(parsed_url.query)\n\n    # Extract the 'schema' parameter\n    schema_list = query_params.pop(\"schema\", None)\n    schema = schema_list[0] if schema_list else \"public\"\n\n    # Reconstruct the query string without the 'schema' parameter\n    new_query = urlencode(query_params, doseq=True)\n    new_parsed_url = parsed_url._replace(query=new_query)\n    database_url_clean = str(urlunparse(new_parsed_url))\n\n    return schema, database_url_clean",
      "blocks": [
        {
          "id": 1,
          "label": "def _extract_schema_from_url(database_url) -> tuple[str, str]:\nparsed_url = urlparse(database_url)\nquery_params = parse_qs(parsed_url.query)",
          "successors": [
            {
              "id": 3,
              "label": "schema_list = query_params.pop(\"schema\", None)\nschema = schema_list[0] if schema_list else \"public\"\nnew_query = urlencode(query_params, doseq=True)\nnew_parsed_url = parsed_url._replace(query=new_query)\ndatabase_url_clean = str(urlunparse(new_parsed_url))",
              "successors": [
                {
                  "id": 5,
                  "label": "return schema, database_url_clean",
                  "successors": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "name": "log",
      "type": "function",
      "start_line": 44,
      "end_line": 45,
      "functions": [],
      "classes": [],
      "simplified_code": "def log(msg, **kwargs):\n    logger.info(\"[ExecutionScheduler] \" + msg, **kwargs)",
      "blocks": [
        {
          "id": 1,
          "label": "def log(msg, **kwargs):\nlogger.info(\"[ExecutionScheduler] \" + msg, **kwargs)",
          "successors": []
        }
      ]
    },
    {
      "name": "job_listener",
      "type": "function",
      "start_line": 48,
      "end_line": 53,
      "functions": [],
      "classes": [],
      "simplified_code": "def job_listener(event):\n    \"\"\"Logs job execution outcomes for better monitoring.\"\"\"\n    if event.exception:\n        log(f\"Job {event.job_id} failed.\")\n    else:\n        log(f\"Job {event.job_id} completed successfully.\")",
      "blocks": [
        {
          "id": 1,
          "label": "def job_listener(event):\nif event.exception:",
          "successors": [
            {
              "id": 3,
              "label": "    log(f\"Job {event.job_id} failed.\")",
              "successors": []
            },
            {
              "id": 4,
              "label": "    log(f\"Job {event.job_id} completed successfully.\")",
              "successors": []
            }
          ]
        }
      ]
    },
    {
      "name": "get_execution_client",
      "type": "function",
      "start_line": 57,
      "end_line": 58,
      "functions": [],
      "classes": [],
      "simplified_code": "def get_execution_client() -> ExecutionManager:\n    return get_service_client(ExecutionManager)",
      "blocks": [
        {
          "id": 1,
          "label": "def get_execution_client() -> ExecutionManager:\nreturn get_service_client(ExecutionManager)",
          "successors": []
        }
      ]
    },
    {
      "name": "execute_graph",
      "type": "function",
      "start_line": 61,
      "end_line": 69,
      "functions": [],
      "classes": [],
      "simplified_code": "def execute_graph(**kwargs):\n    args = JobArgs(**kwargs)\n    try:\n        log(f\"Executing recurring job for graph #{args.graph_id}\")\n        get_execution_client().add_execution(\n            args.graph_id, args.input_data, args.user_id\n        )\n    except Exception as e:\n        logger.exception(f\"Error executing graph {args.graph_id}: {e}\")",
      "blocks": [
        {
          "id": 1,
          "label": "def execute_graph(**kwargs):\nargs = JobArgs(**kwargs)",
          "successors": [
            {
              "id": 3,
              "label": "try:",
              "successors": [
                {
                  "id": 4,
                  "label": "log(f\"Executing recurring job for graph #{args.graph_id}\")\nget_execution_client().add_execution(\n    args.graph_id, args.input_data, args.user_id\n)",
                  "successors": []
                },
                {
                  "id": 5,
                  "label": "except Exception as e:\nlogger.exception(f\"Error executing graph {args.graph_id}: {e}\")",
                  "successors": []
                }
              ]
            }
          ]
        }
      ]
    }
  ],
  "classes": [
    {
      "name": "JobArgs",
      "type": "class",
      "start_line": 72,
      "end_line": 77,
      "functions": [],
      "classes": [],
      "simplified_code": "class JobArgs(BaseModel):\n    graph_id: str\n    input_data: BlockInput\n    user_id: str\n    graph_version: int\n    cron: str",
      "blocks": [
        {
          "id": 1,
          "label": "class JobArgs(BaseModel):\n    graph_id: str\n    input_data: BlockInput\n    user_id: str\n    graph_version: int\n    cron: str",
          "successors": []
        }
      ]
    },
    {
      "name": "JobInfo",
      "type": "class",
      "start_line": 80,
      "end_line": 92,
      "functions": [
        {
          "name": "from_db",
          "type": "function",
          "start_line": 86,
          "end_line": 92,
          "functions": [],
          "classes": [],
          "simplified_code": "    def from_db(job_args: JobArgs, job_obj: JobObj) -> \"JobInfo\":\n        return JobInfo(\n            id=job_obj.id,\n            name=job_obj.name,\n            next_run_time=job_obj.next_run_time.isoformat(),\n            **job_args.model_dump(),\n        )",
          "blocks": [
            {
              "id": 1,
              "label": "def from_db(job_args: JobArgs, job_obj: JobObj) -> \"JobInfo\":\nreturn JobInfo(id=job_obj.id, name=job_obj.name, next_run_time=job_obj.next_run_time.isoformat(), **job_args.model_dump(), )",
              "successors": []
            }
          ]
        }
      ],
      "classes": [],
      "simplified_code": "class JobInfo(JobArgs):\n    id: str\n    name: str\n    next_run_time: str\n\n    @staticmethod\n        )",
      "blocks": [
        {
          "id": 1,
          "label": "class JobInfo(JobArgs):\nid: str\nname: str\nnext_run_time: str",
          "successors": [
            {
              "id": 3,
              "label": "@staticmethod",
              "successors": []
            }
          ]
        }
      ]
    },
    {
      "name": "ExecutionScheduler",
      "type": "class",
      "start_line": 95,
      "end_line": 175,
      "functions": [
        {
          "name": "get_port",
          "type": "function",
          "start_line": 99,
          "end_line": 100,
          "functions": [],
          "classes": [],
          "simplified_code": "    def get_port(cls) -> int:\n        return config.execution_scheduler_port",
          "blocks": [
            {
              "id": 1,
              "label": "def get_port(cls) -> int:\n    return config.execution_scheduler_port",
              "successors": []
            }
          ]
        },
        {
          "name": "execution_client",
          "type": "function",
          "start_line": 104,
          "end_line": 105,
          "functions": [],
          "classes": [],
          "simplified_code": "    def execution_client(self) -> ExecutionManager:\n        return get_service_client(ExecutionManager)",
          "blocks": [
            {
              "id": 1,
              "label": "def execution_client(self) -> ExecutionManager:\n    return get_service_client(ExecutionManager)",
              "successors": []
            }
          ]
        },
        {
          "name": "run_service",
          "type": "function",
          "start_line": 107,
          "end_line": 119,
          "functions": [],
          "classes": [],
          "simplified_code": "    def run_service(self):\n        load_dotenv()\n        db_schema, db_url = _extract_schema_from_url(os.getenv(\"DATABASE_URL\"))\n        self.scheduler = BlockingScheduler(\n            jobstores={\n                \"default\": SQLAlchemyJobStore(\n                    engine=create_engine(db_url),\n                    metadata=MetaData(schema=db_schema),\n                )\n            }\n        )\n        self.scheduler.add_listener(job_listener, EVENT_JOB_EXECUTED | EVENT_JOB_ERROR)\n        self.scheduler.start()",
          "blocks": [
            {
              "id": 1,
              "label": "def run_service(self):\nload_dotenv()",
              "successors": [
                {
                  "id": 3,
                  "label": "db_schema, db_url = _extract_schema_from_url(os.getenv(\"DATABASE_URL\"))\nself.scheduler = BlockingScheduler(jobstores={\"default\": SQLAlchemyJobStore(engine=create_engine(db_url), metadata=MetaData(schema=db_schema),)})",
                  "successors": [
                    {
                      "id": 5,
                      "label": "self.scheduler.add_listener(job_listener, EVENT_JOB_EXECUTED | EVENT_JOB_ERROR)\nself.scheduler.start()",
                      "successors": []
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "name": "add_execution_schedule",
          "type": "function",
          "start_line": 122,
          "end_line": 144,
          "functions": [],
          "classes": [],
          "simplified_code": "    def add_execution_schedule(\n        self,\n        graph_id: str,\n        graph_version: int,\n        cron: str,\n        input_data: BlockInput,\n        user_id: str,\n    ) -> JobInfo:\n        job_args = JobArgs(\n            graph_id=graph_id,\n            input_data=input_data,\n            user_id=user_id,\n            graph_version=graph_version,\n            cron=cron,\n        )\n        job = self.scheduler.add_job(\n            execute_graph,\n            CronTrigger.from_crontab(cron),\n            kwargs=job_args.model_dump(),\n            replace_existing=True,\n        )\n        log(f\"Added job {job.id} with cron schedule '{cron}' input data: {input_data}\")\n        return JobInfo.from_db(job_args, job)",
          "blocks": [
            {
              "id": 1,
              "label": "def add_execution_schedule(\n    self,\n    graph_id: str,\n    graph_version: int,\n    cron: str,\n    input_data: BlockInput,\n    user_id: str,\n) -> JobInfo:\n    job_args = JobArgs(\n        graph_id=graph_id,\n        input_data=input_data,\n        user_id=user_id,\n        graph_version=graph_version,\n        cron=cron,\n    )",
              "successors": [
                {
                  "id": 3,
                  "label": "    job = self.scheduler.add_job(\n        execute_graph,\n        CronTrigger.from_crontab(cron),\n        kwargs=job_args.model_dump(),\n        replace_existing=True,\n    )\n    log(f\"Added job {job.id} with cron schedule '{cron}' input data: {input_data}\")",
                  "successors": [
                    {
                      "id": 5,
                      "label": "    return JobInfo.from_db(job_args, job)",
                      "successors": []
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "name": "delete_schedule",
          "type": "function",
          "start_line": 147,
          "end_line": 160,
          "functions": [],
          "classes": [],
          "simplified_code": "    def delete_schedule(self, schedule_id: str, user_id: str) -> JobInfo:\n        job = self.scheduler.get_job(schedule_id)\n        if not job:\n            log(f\"Job {schedule_id} not found.\")\n            raise ValueError(f\"Job #{schedule_id} not found.\")\n\n        job_args = JobArgs(**job.kwargs)\n        if job_args.user_id != user_id:\n            raise ValueError(\"User ID does not match the job's user ID.\")\n\n        log(f\"Deleting job {schedule_id}\")\n        job.remove()\n\n        return JobInfo.from_db(job_args, job)",
          "blocks": [
            {
              "id": 1,
              "label": "def delete_schedule(self, schedule_id: str, user_id: str) -> JobInfo:\njob = self.scheduler.get_job(schedule_id)",
              "successors": [
                {
                  "id": 3,
                  "label": "if not job:\nlog(f\"Job {schedule_id} not found.\")",
                  "successors": [
                    {
                      "id": 5,
                      "label": "raise ValueError(f\"Job #{schedule_id} not found.\")",
                      "successors": []
                    }
                  ]
                },
                {
                  "id": 6,
                  "label": "job_args = JobArgs(**job.kwargs)",
                  "successors": [
                    {
                      "id": 7,
                      "label": "if job_args.user_id != user_id:\nraise ValueError(\"User ID does not match the job's user ID.\")",
                      "successors": []
                    },
                    {
                      "id": 9,
                      "label": "log(f\"Deleting job {schedule_id}\")\njob.remove()",
                      "successors": [
                        {
                          "id": 11,
                          "label": "return JobInfo.from_db(job_args, job)",
                          "successors": []
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "name": "get_execution_schedules",
          "type": "function",
          "start_line": 163,
          "end_line": 175,
          "functions": [],
          "classes": [],
          "simplified_code": "    def get_execution_schedules(\n        self, graph_id: str | None = None, user_id: str | None = None\n    ) -> list[JobInfo]:\n        schedules = []\n        for job in self.scheduler.get_jobs():\n            job_args = JobArgs(**job.kwargs)\n            if (\n                job.next_run_time is not None\n                and (graph_id is None or job_args.graph_id == graph_id)\n                and (user_id is None or job_args.user_id == user_id)\n            ):\n                schedules.append(JobInfo.from_db(job_args, job))\n        return schedules",
          "blocks": [
            {
              "id": 1,
              "label": "def get_execution_schedules(\n    self, graph_id: str | None = None, user_id: str | None = None\n) -> list[JobInfo]:\nschedules = []",
              "successors": [
                {
                  "id": 3,
                  "label": "for job in self.scheduler.get_jobs():",
                  "successors": [
                    {
                      "id": 4,
                      "label": "job_args = JobArgs(**job.kwargs)",
                      "successors": [
                        {
                          "id": 5,
                          "label": "if (\n    job.next_run_time is not None\n    and (graph_id is None or job_args.graph_id == graph_id)\n    and (user_id is None or job_args.user_id == user_id)\n):",
                          "successors": [
                            {
                              "id": 6,
                              "label": "schedules.append(JobInfo.from_db(job_args, job))\nreturn schedules",
                              "successors": []
                            },
                            {
                              "id": 7,
                              "label": "return schedules",
                              "successors": []
                            }
                          ]
                        },
                        {
                          "id": 7,
                          "label": "return schedules",
                          "successors": []
                        }
                      ]
                    },
                    {
                      "id": 7,
                      "label": "return schedules",
                      "successors": []
                    }
                  ]
                },
                {
                  "id": 7,
                  "label": "return schedules",
                  "successors": []
                }
              ]
            }
          ]
        }
      ],
      "classes": [],
      "simplified_code": "class ExecutionScheduler(AppService):\n    scheduler: BlockingScheduler\n\n    @classmethod\n        return config.execution_scheduler_port\n\n    @property\n    @thread_cached\n        return get_service_client(ExecutionManager)\n\n        self.scheduler.start()\n\n    @expose\n        return JobInfo.from_db(job_args, job)\n\n    @expose\n        return JobInfo.from_db(job_args, job)\n\n    @expose\n        return schedules",
      "blocks": [
        {
          "id": 1,
          "label": "class ExecutionScheduler(AppService):\n    scheduler: BlockingScheduler",
          "successors": []
        }
      ]
    }
  ],
  "simplified_code": "import logging\nimport os\nfrom urllib.parse import parse_qs, urlencode, urlparse, urlunparse\n\nfrom apscheduler.events import EVENT_JOB_ERROR, EVENT_JOB_EXECUTED\nfrom apscheduler.job import Job as JobObj\nfrom apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore\nfrom apscheduler.schedulers.blocking import BlockingScheduler\nfrom apscheduler.triggers.cron import CronTrigger\nfrom autogpt_libs.utils.cache import thread_cached\nfrom dotenv import load_dotenv\nfrom pydantic import BaseModel\nfrom sqlalchemy import MetaData, create_engine\n\nfrom backend.data.block import BlockInput\nfrom backend.executor.manager import ExecutionManager\nfrom backend.util.service import AppService, expose, get_service_client\nfrom backend.util.settings import Config\n\n\n    return schema, database_url_clean\n\n\nlogger = logging.getLogger(__name__)\nconfig = Config()\n\n\n    logger.info(\"[ExecutionScheduler] \" + msg, **kwargs)\n\n\n        log(f\"Job {event.job_id} completed successfully.\")\n\n\n@thread_cached\n    return get_service_client(ExecutionManager)\n\n\n        logger.exception(f\"Error executing graph {args.graph_id}: {e}\")\n\n\n    cron: str\n\n\n        )\n\n\n        return schedules",
  "blocks": [
    {
      "id": 1,
      "label": "import logging\nimport os\nfrom urllib.parse import parse_qs, urlencode, urlparse, urlunparse\n\nfrom apscheduler.events import EVENT_JOB_ERROR, EVENT_JOB_EXECUTED\nfrom apscheduler.job import Job as JobObj\nfrom apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore\nfrom apscheduler.schedulers.blocking import BlockingScheduler\nfrom apscheduler.triggers.cron import CronTrigger\nfrom autogpt_libs.utils.cache import thread_cached\nfrom dotenv import load_dotenv\nfrom pydantic import BaseModel\nfrom sqlalchemy import MetaData, create_engine\n\nfrom backend.data.block import BlockInput\nfrom backend.executor.manager import ExecutionManager\nfrom backend.util.service import AppService, expose, get_service_client\nfrom backend.util.settings import Config\n\n\n    return schema, database_url_clean\n\n\nlogger = logging.getLogger(__name__)\nconfig = Config()\n\n\n    logger.info(\"[ExecutionScheduler] \" + msg, **kwargs)\n\n\n        log(f\"Job {event.job_id} completed successfully.\")\n\n\n@thread_cached\n    return get_service_client(ExecutionManager)\n\n\n        logger.exception(f\"Error executing graph {args.graph_id}: {e}\")\n\n\n    cron: str\n\n\n        )\n\n\n        return schedules",
      "successors": []
    }
  ]
}