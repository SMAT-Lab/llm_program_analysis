{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:   0%|          | 0/190 [00:00<?, ?it/s]/home/miniconda3/envs/llm_analysis/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "处理CFG文件: 100%|██████████| 190/190 [00:06<00:00, 27.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Automatic Evaluation Summary:\n",
      "Total CFGs compared: 190\n",
      "Average Edge Coverage: 0.54\n",
      "Average Content Similarity: 0.76\n",
      "Average Structure Similarity: 0.71\n",
      "Total GT edges: 856\n",
      "Total LLM edges: 938\n",
      "Total Matched edges: 570\n",
      "Precision: 0.6076759061833689\n",
      "Recall: 0.6658878504672897\n",
      "F1 Score: 0.6354515050167224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import Dict, List, Optional, Union\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CFGSimilarityResult:\n",
    "    \"\"\"存储CFG比较结果的数据类\"\"\"\n",
    "    filename: str\n",
    "    edge_coverage: float\n",
    "    content_similarity: float\n",
    "    structure_similarity: float\n",
    "    matched_edges: int\n",
    "    gt_edges: int\n",
    "    llm_edges: int\n",
    "    nested_results: Optional[Dict[str, 'CFGSimilarityResult']] = None\n",
    "\n",
    "\n",
    "class CFGComparator:\n",
    "    def __init__(self):\n",
    "        \"\"\"初始化CFG比较器\"\"\"\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def count_edges(cfg: Dict) -> int:\n",
    "        \"\"\"\n",
    "        递归计算CFG中的边数量，包括所有嵌套结构的边\n",
    "        \"\"\"\n",
    "        def count_edges_recursive(blocks):\n",
    "            edge_count = 0\n",
    "            for block in blocks:\n",
    "                successors = block.get(\"successors\", [])\n",
    "                edge_count += len(successors)  # 当前 block 的边数量\n",
    "                # 递归计算 successors 的边\n",
    "                for successor in successors:\n",
    "                    if isinstance(successor, dict):  # successor 也是一个带有 blocks 的嵌套结构\n",
    "                        edge_count += count_edges_recursive(successor.get(\"blocks\", []))\n",
    "            return edge_count\n",
    "\n",
    "        # 统计顶层 blocks 的边\n",
    "        edge_count = count_edges_recursive(cfg.get(\"blocks\", []))\n",
    "\n",
    "        # 递归统计嵌套函数和类的边\n",
    "        for func in cfg.get(\"functions\", []):\n",
    "            edge_count += CFGComparator.count_edges(func)\n",
    "        for cls in cfg.get(\"classes\", []):\n",
    "            edge_count += CFGComparator.count_edges(cls)\n",
    "\n",
    "        return edge_count\n",
    "\n",
    "    def structure_similarity(self, llm_cfg: Dict, static_cfg: Dict) -> float:\n",
    "        \"\"\"\n",
    "        计算两个CFG的结构相似度（基于边的数量）。\n",
    "        \"\"\"\n",
    "        llm_edges = self.count_edges(llm_cfg)\n",
    "        static_edges = self.count_edges(static_cfg)\n",
    "\n",
    "        # 如果两者都没有边，则结构上可以视为“极度简化”——按需设为 1.0\n",
    "        if llm_edges == 0 and static_edges == 0:\n",
    "            return 1.0\n",
    "        if llm_edges == 0 or static_edges == 0:\n",
    "            return 0.0\n",
    "\n",
    "        # 较简单的衡量：用最小/最大，值越接近1越表示边数接近\n",
    "        return min(llm_edges, static_edges) / max(llm_edges, static_edges)\n",
    "\n",
    "    def content_similarity(self, llm_cfg: Dict, static_cfg: Dict) -> float:\n",
    "        \"\"\"\n",
    "        计算两个CFG的内容相似度（基于 blocks 的内容）。\n",
    "        如果 label 是列表，则将其合并为一个字符串。\n",
    "        并在向量化前检查文本是否为空。\n",
    "        \"\"\"\n",
    "        llm_blocks = llm_cfg.get(\"blocks\", [])\n",
    "        static_blocks = static_cfg.get(\"blocks\", [])\n",
    "\n",
    "        # 如果两边都没有 blocks，视为内容相同\n",
    "        if not llm_blocks and not static_blocks:\n",
    "            return 1.0\n",
    "        # 如果一边没 blocks 则视为没有可比内容\n",
    "        if not llm_blocks or not static_blocks:\n",
    "            return 0.0\n",
    "\n",
    "        def unify_label(label_value: Union[str, List[str], None]) -> str:\n",
    "            \"\"\"将 label 统一成单一字符串。\"\"\"\n",
    "            if isinstance(label_value, list):\n",
    "                return \"\\n\".join(str(item) for item in label_value)\n",
    "            elif isinstance(label_value, str):\n",
    "                return label_value\n",
    "            else:\n",
    "                return \"\"\n",
    "\n",
    "        # 将 blocks 的 label 统一转换为字符串后再拼成大文本\n",
    "        llm_code = \"\\n\".join(unify_label(block.get(\"label\", \"\")) for block in llm_blocks)\n",
    "        static_code = \"\\n\".join(unify_label(block.get(\"label\", \"\")) for block in static_blocks)\n",
    "\n",
    "        # 进一步清洗空白字符\n",
    "        llm_code = llm_code.strip()\n",
    "        static_code = static_code.strip()\n",
    "\n",
    "        # 如果两个文本都空，视为相似度 1.0\n",
    "        if not llm_code and not static_code:\n",
    "            return 1.0\n",
    "        # 如果只有一方空，则相似度 0.0\n",
    "        if not llm_code or not static_code:\n",
    "            return 0.0\n",
    "\n",
    "        # ======== 以下为正常文本相似度计算 ========\n",
    "        def custom_tokenizer(text):\n",
    "            return re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "        def custom_preprocessor(text):\n",
    "            # 简单删除 # 开头的注释，可按需扩展\n",
    "            text = re.sub(r'#.*', '', text)\n",
    "            return text\n",
    "\n",
    "        vectorizer = CountVectorizer(\n",
    "            tokenizer=custom_tokenizer,\n",
    "            preprocessor=custom_preprocessor,\n",
    "            stop_words='english',\n",
    "            ngram_range=(1, 2)\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            vectors = vectorizer.fit_transform([llm_code, static_code])\n",
    "            similarity = cosine_similarity(vectors[0], vectors[1])[0][0]\n",
    "        except ValueError:\n",
    "            # 捕获 \"empty vocabulary\" 异常，如果文本过于短或只含停用词，fallback 为 0.0\n",
    "            similarity = 0.0\n",
    "\n",
    "        return similarity\n",
    "\n",
    "    def compare_cfgs(self, llm_cfg: Dict, static_cfg: Dict, name: str) -> CFGSimilarityResult:\n",
    "        \"\"\"递归比较两个CFG并返回相似度结果\"\"\"\n",
    "        structure_sim = self.structure_similarity(llm_cfg, static_cfg)\n",
    "        content_sim = self.content_similarity(llm_cfg, static_cfg)\n",
    "\n",
    "        gt_edges = self.count_edges(static_cfg)\n",
    "        llm_edges = self.count_edges(llm_cfg)\n",
    "\n",
    "        matched_edges = int(structure_sim * min(gt_edges, llm_edges))\n",
    "        edge_coverage = matched_edges / gt_edges if gt_edges > 0 else 0\n",
    "\n",
    "        nested_results = {}\n",
    "\n",
    "        # === 递归比较 methods (functions) ===\n",
    "        llm_functions = {f[\"name\"]: f for f in llm_cfg.get(\"functions\", [])}\n",
    "        static_functions = {f[\"name\"]: f for f in static_cfg.get(\"functions\", [])}\n",
    "        common_functions = set(llm_functions.keys()) & set(static_functions.keys())\n",
    "\n",
    "        for func_name in common_functions:\n",
    "            nested_results[f\"function_{func_name}\"] = self.compare_cfgs(\n",
    "                llm_functions[func_name],\n",
    "                static_functions[func_name],\n",
    "                func_name\n",
    "            )\n",
    "\n",
    "        # === 递归比较 classes ===\n",
    "        llm_classes = {c[\"name\"]: c for c in llm_cfg.get(\"classes\", [])}\n",
    "        static_classes = {c[\"name\"]: c for c in static_cfg.get(\"classes\", [])}\n",
    "        common_classes = set(llm_classes.keys()) & set(static_classes.keys())\n",
    "\n",
    "        for class_name in common_classes:\n",
    "            nested_results[f\"class_{class_name}\"] = self.compare_cfgs(\n",
    "                llm_classes[class_name],\n",
    "                static_classes[class_name],\n",
    "                class_name\n",
    "            )\n",
    "\n",
    "        return CFGSimilarityResult(\n",
    "            filename=name,\n",
    "            edge_coverage=edge_coverage,\n",
    "            content_similarity=content_sim,\n",
    "            structure_similarity=structure_sim,\n",
    "            matched_edges=matched_edges,\n",
    "            gt_edges=gt_edges,\n",
    "            llm_edges=llm_edges,\n",
    "            nested_results=nested_results if nested_results else None\n",
    "        )\n",
    "\n",
    "\n",
    "class CFGEvaluator:\n",
    "    def __init__(self, llm_cfg_dir: str, static_cfg_dir: str, result_file: str):\n",
    "        self.llm_cfg_dir = Path(llm_cfg_dir)\n",
    "        self.static_cfg_dir = Path(static_cfg_dir)\n",
    "        self.result_file = Path(result_file)\n",
    "        self.comparator = CFGComparator()\n",
    "        self.results: List[CFGSimilarityResult] = []\n",
    "\n",
    "    def process_file(self, llm_cfg_path: Path) -> Optional[CFGSimilarityResult]:\n",
    "        static_cfg_path = self.static_cfg_dir / llm_cfg_path.name\n",
    "        if not static_cfg_path.exists():\n",
    "            return None\n",
    "\n",
    "        with open(llm_cfg_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            llm_cfg = json.load(f)\n",
    "        with open(static_cfg_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            static_cfg = json.load(f)\n",
    "\n",
    "        result = self.comparator.compare_cfgs(llm_cfg, static_cfg, llm_cfg_path.name)\n",
    "        self.results.append(result)\n",
    "        self.save_results()\n",
    "        return result\n",
    "\n",
    "    def save_results(self):\n",
    "        with open(self.result_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(\n",
    "                [self._result_to_dict(r) for r in self.results],\n",
    "                f,\n",
    "                indent=2,\n",
    "                ensure_ascii=False\n",
    "            )\n",
    "\n",
    "    def evaluate_all(self) -> List[CFGSimilarityResult]:\n",
    "        llm_cfg_paths = list(self.llm_cfg_dir.glob(\"*.json\"))\n",
    "        for llm_cfg_path in tqdm(llm_cfg_paths, desc=\"处理CFG文件\"):\n",
    "            self.process_file(llm_cfg_path)\n",
    "        return self.results\n",
    "\n",
    "    @staticmethod\n",
    "    def _result_to_dict(result: CFGSimilarityResult) -> Dict:\n",
    "        return {\n",
    "            \"filename\": result.filename,\n",
    "            \"edge_coverage\": result.edge_coverage,\n",
    "            \"content_similarity\": result.content_similarity,\n",
    "            \"structure_similarity\": result.structure_similarity,\n",
    "            \"matched_edges\": result.matched_edges,\n",
    "            \"gt_edges\": result.gt_edges,\n",
    "            \"llm_edges\": result.llm_edges,\n",
    "            \"nested_results\": (\n",
    "                {\n",
    "                    k: CFGEvaluator._result_to_dict(v)\n",
    "                    for k, v in result.nested_results.items()\n",
    "                }\n",
    "                if result.nested_results\n",
    "                else None\n",
    "            )\n",
    "        }\n",
    "\n",
    "\n",
    "def calculate_aggregate_metrics(results: List[CFGSimilarityResult]) -> Dict[str, float]:\n",
    "    \"\"\"对比较结果做全局统计。\"\"\"\n",
    "    if not results:\n",
    "        return {\n",
    "            \"total_cfgs_compared\": 0,\n",
    "            \"average_edge_coverage\": 0.0,\n",
    "            \"average_content_similarity\": 0.0,\n",
    "            \"average_structure_similarity\": 0.0,\n",
    "            \"total_gt_edges\": 0,\n",
    "            \"total_llm_edges\": 0,\n",
    "            \"total_matched_edges\": 0\n",
    "        }\n",
    "\n",
    "    metrics = {\n",
    "        \"total_cfgs_compared\": len(results),\n",
    "        \"average_edge_coverage\": float(np.mean([r.edge_coverage for r in results])),\n",
    "        \"average_content_similarity\": float(np.mean([r.content_similarity for r in results])),\n",
    "        \"average_structure_similarity\": float(np.mean([r.structure_similarity for r in results])),\n",
    "        \"total_gt_edges\": sum(r.gt_edges for r in results),\n",
    "        \"total_llm_edges\": sum(r.llm_edges for r in results),\n",
    "        \"total_matched_edges\": sum(r.matched_edges for r in results)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def main():\n",
    "    evaluator = CFGEvaluator(\n",
    "        llm_cfg_dir=\"merged_llm_cfg_with_line_no\",\n",
    "        static_cfg_dir=\"../../dataset/python_cfg\",\n",
    "        result_file=\"evaluation_results.json\"\n",
    "    )\n",
    "\n",
    "    results = evaluator.evaluate_all()\n",
    "    metrics = calculate_aggregate_metrics(results)\n",
    "\n",
    "    print(\"\\nAutomatic Evaluation Summary:\")\n",
    "    print(f\"Total CFGs compared: {metrics['total_cfgs_compared']}\")\n",
    "    print(f\"Average Edge Coverage: {metrics['average_edge_coverage']:.2f}\")\n",
    "    print(f\"Average Content Similarity: {metrics['average_content_similarity']:.2f}\")\n",
    "    print(f\"Average Structure Similarity: {metrics['average_structure_similarity']:.2f}\")\n",
    "\n",
    "    print(f\"Total GT edges: {metrics['total_gt_edges']}\")\n",
    "    print(f\"Total LLM edges: {metrics['total_llm_edges']}\")\n",
    "    print(f\"Total Matched edges: {metrics['total_matched_edges']}\")\n",
    "    print(f\"Precision: {metrics['total_matched_edges'] / metrics['total_llm_edges']}\")\n",
    "    print(f\"Recall: {metrics['total_matched_edges'] / metrics['total_gt_edges']}\")\n",
    "    print(f\"F1 Score: {2 * metrics['total_matched_edges'] / (metrics['total_llm_edges'] + metrics['total_gt_edges'])}\")\n",
    "\n",
    "    with open(\"evaluation_metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metrics, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files for index 97: ['../../dataset/python/97.py', 'llm_cfg_with_line_no/97.json', '../../dataset/python_cfg/97.json']\n",
      "Missing files for index 101: ['llm_cfg_with_line_no/101.json']\n",
      "Missing files for index 120: ['llm_cfg_with_line_no/120.json']\n",
      "Missing files for index 133: ['llm_cfg_with_line_no/133.json']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CFGs: 100%|██████████| 200/200 [00:56<00:00,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON解析失败 186: Unterminated string starting at: line 64 column 7 (char 13675)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from multiprocessing import cpu_count\n",
    "from tqdm import tqdm\n",
    "# 假设 get_llm_answers 从您的 llm 模块导入\n",
    "from llm import get_llm_answers  \n",
    "\n",
    "from typing import Set, Tuple\n",
    "\n",
    "def convert_cfg_json_to_edges(cfg_json: dict) -> list[str]:\n",
    "    \"\"\"基于代码块内容生成控制流边，不依赖节点ID\"\"\"\n",
    "    edges = []\n",
    "    edge_counter = 0\n",
    "\n",
    "    def get_block_label(block: dict) -> str:\n",
    "        \"\"\"提取标准化的块标签\"\"\"\n",
    "        label = block.get('label', '')\n",
    "        # 确保label是字符串类型\n",
    "        if isinstance(label, list):\n",
    "            label = ' '.join(label)\n",
    "        elif not isinstance(label, str):\n",
    "            label = str(label)\n",
    "        # 清理换行和多余空格\n",
    "        return ' '.join(label.replace('\\n', '\\\\n').strip().split())\n",
    "\n",
    "    def process_entity(entity: dict):\n",
    "        \"\"\"递归处理各类实体（函数/类/块）\"\"\"\n",
    "        # 处理当前实体的直接blocks\n",
    "        for block in entity.get('blocks', []):\n",
    "            process_block(block)\n",
    "\n",
    "        # 递归处理嵌套结构\n",
    "        for key in ['functions', 'classes']:\n",
    "            for sub_entity in entity.get(key, []):\n",
    "                process_entity(sub_entity)\n",
    "\n",
    "    def process_block(block: dict):\n",
    "        \"\"\"处理单个代码块及其后继\"\"\"\n",
    "        nonlocal edge_counter\n",
    "        \n",
    "        # 获取当前块的规范化标签\n",
    "        source_label = get_block_label(block)\n",
    "        if not source_label:\n",
    "            return\n",
    "\n",
    "        # 处理直接后继\n",
    "        for succ in block.get('successors', []):\n",
    "            target_label = get_block_label(succ)\n",
    "            if target_label:\n",
    "                edges.append(\n",
    "                    f\"Edge {edge_counter}: [Source] {source_label} => \"\n",
    "                    f\"[Target] {target_label}\"\n",
    "                )\n",
    "                edge_counter += 1\n",
    "\n",
    "        # 递归处理嵌套blocks（如if/else内的块）\n",
    "        for key in ['blocks', 'successors']:\n",
    "            for sub_block in block.get(key, []):\n",
    "                process_block(sub_block)\n",
    "\n",
    "    # 从根节点开始处理\n",
    "    process_entity(cfg_json)\n",
    "    return edges\n",
    "\n",
    "def get_prompt(code: str, llm_cfg: dict, static_cfg: dict):\n",
    "    prompt = f\"\"\"\n",
    "Role: Control Flow Graph Validation Specialist\n",
    "Objective: Accurately compare CFG structures between static analysis (ground truth) and LLM generation\n",
    "\n",
    "### JSON Structure Definition\n",
    "Ground Truth (static_cfg) & LLM Output (llm_cfg) follow:\n",
    "[\n",
    "    \"Edge 0: [Source] node_A -> [Target] node_B\",\n",
    "    \"Edge 1: [Source] node_C -> [Target] node_D\",\n",
    "    ...\n",
    "]\n",
    "\n",
    "### Comparison Criteria\n",
    "1. Structure Matching:\n",
    "   Match edges when:\n",
    "   - Same branching pattern (sequential/conditional/loop)\n",
    "   - Equivalent depth in nested structure\n",
    "   - Matching control flow order\n",
    "\n",
    "2. Mismatch Conditions:\n",
    "   - Different number of successors in equivalent blocks\n",
    "   - Inconsistent branch types (e.g., true/false vs multiple)\n",
    "   - Missing/extra exception handling flows\n",
    "\n",
    "### Analysis Task\n",
    "1. For static_cfg:\n",
    "   - Count total edges (ground truth)\n",
    "   - Map control flow patterns\n",
    "\n",
    "2. For llm_cfg:\n",
    "   - Count total generated edges\n",
    "   - Identify structurally matched edges\n",
    "   - Traverse each edge and check if it corresponds to static analysis\n",
    "\n",
    "3. Output (JSON):\n",
    "{{\n",
    "  \"edge_analysis\": {{\n",
    "    \"static_total\": \"Number of edges from static analysis\",\n",
    "    \"llm_total\": \"Number of edges generated by LLM\",\n",
    "    \"matched_edges\": {{\n",
    "      \"exact_matches\": \"Number of exactly matched edges (type + position)\", \n",
    "      \"partial_matches\": \"Number of type-matched edges with different positions\"\n",
    "    }},\n",
    "    \"accuracy_metrics\": {{\n",
    "      \"precision\": \"exact_matches / llm_total\",\n",
    "      \"recall\": \"exact_matches / static_total\", \n",
    "      \"f1_score\": \"2*(precision*recall)/(precision+recall)\"\n",
    "    }}\n",
    "  }},\n",
    "  \"structure_validation\": {{\n",
    "    \"missing_blocks\": [\"Unmatched static block IDs\"],\n",
    "    \"extra_blocks\": [\"Extra LLM block IDs\"]\n",
    "  }}\n",
    "}}\n",
    "\n",
    "### Input Data\n",
    "TypeScript Code:\n",
    "{code}\n",
    "\n",
    "Static Analysis CFG (Ground Truth):\n",
    "{json.dumps(convert_cfg_json_to_edges(static_cfg), indent=2)}\n",
    "\n",
    "LLM Generated CFG:\n",
    "{json.dumps(convert_cfg_json_to_edges(llm_cfg), indent=2)}\n",
    "\n",
    "Output JSON analysis ONLY.\n",
    "\"\"\"\n",
    "    return prompt.strip()\n",
    "### Output Schema\n",
    "# {{\n",
    "#   \"total_gt_edges\": \"Count of all DOT edges\",\n",
    "#   \"total_llm_edges\": \"Count of all JSON edges\",\n",
    "#   \"total_matched_edges\": \"Structurally aligned edges\"\n",
    "# }}\n",
    "\n",
    "def process_file(i):\n",
    "    \"\"\"处理单个文件的CFG对比\"\"\"\n",
    "    # 路径配置\n",
    "    code_path = f\"../../dataset/python/{i}.py\"\n",
    "    llm_cfg_path = f\"llm_cfg_with_line_no/{i}.json\"\n",
    "    static_cfg_path = f\"../../dataset/python_cfg/{i}.json\"  # 改为JSON路径\n",
    "    result_path = f\"results/{i}.json\"\n",
    "\n",
    "    # 跳过已处理文件\n",
    "    if os.path.exists(result_path):\n",
    "        return\n",
    "\n",
    "    # 校验文件存在性\n",
    "    missing_files = [\n",
    "        p for p in [code_path, llm_cfg_path, static_cfg_path]\n",
    "        if not os.path.exists(p)\n",
    "    ]\n",
    "    if missing_files:\n",
    "        print(f\"Missing files for index {i}: {missing_files}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # 读取并解析输入数据\n",
    "        code = open(code_path).read()\n",
    "        with open(llm_cfg_path) as f:\n",
    "            llm_cfg = json.load(f)\n",
    "        with open(static_cfg_path) as f:  # 读取JSON格式的static_cfg\n",
    "            static_cfg = json.load(f)\n",
    "\n",
    "        # 生成prompt并获取结果\n",
    "        prompt = get_prompt(code, llm_cfg, static_cfg)\n",
    "        # print(prompt)\n",
    "        result = json.loads(get_llm_answers(prompt, model_name=\"gpt-4o\", require_json=True))\n",
    "\n",
    "        #print(json.dumps(result, indent=2))\n",
    "        \n",
    "        # 保存结果\n",
    "        with open(result_path, \"w\") as f:\n",
    "            json.dump(result, f, indent=2)\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON解析失败 {i}: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"处理文件 {i} 时出错: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    # 初始化结果目录\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "    # process_file(0)\n",
    "    \n",
    "    # 创建任务列表\n",
    "    file_indices = list(range(200))  # 根据实际文件数量调整\n",
    "    \n",
    "    # 并行处理\n",
    "    with ThreadPoolExecutor(max_workers=cpu_count()) as executor:\n",
    "        tasks = executor.map(process_file, file_indices)\n",
    "        list(tqdm(tasks, total=len(file_indices), desc=\"Processing CFGs\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CFG 评估报告\n",
      "==================================================\n",
      "分析文件总数: 193\n",
      "\n",
      "[边匹配分析]\n",
      "静态分析总边数: 2919\n",
      "LLM生成总边数: 3088\n",
      "精确匹配边数: 1388 (47.55%)\n",
      "部分匹配边数: 492 (16.86%)\n",
      "总匹配边数: 1880 (64.41%)\n",
      "精确率 (Precision): 0.6088\n",
      "召回率 (Recall): 0.6441\n",
      "F1 值: 0.6259\n",
      "\n",
      "[结构验证]\n",
      "缺失块总数: 941 (示例: #90\\nassert len(request.categories) == 2, Edge 4: [Source] #30\\nconnection_manager.subscriptions['test_graph'] = {mock_websocket}\\nawait connection_manager.unsubscribe('test_graph', mock_websocket) => [Target] #31\\nassert 'test_graph' not in connection_manager.subscriptions, Edge 2: [Source] #3\\n\"\"\"\\n Generate valid combinations of balanced parentheses using recursion.\\n\\n :param partial: A string representing the current combination.\\n :param open_count: An integer representing the count of open parentheses.\\n :param close_count: An integer representing the count of close parentheses.\\n :param n: An integer representing the total number of pairs.\\n :param result: A list to store valid combinations.\\n :return: None\\n\\n This function uses recursion to explore all possible combinations,\\n ensuring that at each step, the parentheses remain balanced.\\n\\n Example:\\n >>> result = []\\n >>> backtrack(\"\", 0, 0, 2, result)\\n >>> result\\n ['(())', '()()']\\n \"\"\"\\nif len(partial) == 2 * n: => [Target] #5\\nif open_count < n:, Edge 1: [Source] #13, Edge 33: [Source] #107)\n",
      "多余块总数: 921 (示例: Edge 3: [Source] headers = {\n",
      " \"Authorization\": f\"Bearer {api_key.get_secret_value()}\",\n",
      " \"Content-Type\": \"application/json\",\n",
      " \"Accept\": \"application/json\",\n",
      " }\n",
      "\n",
      " data = {\n",
      " \"title\": title,\n",
      " \"content\": content,\n",
      " \"contentFormat\": content_format,\n",
      " \"tags\": tags,\n",
      " \"canonicalUrl\": canonical_url,\n",
      " \"publishStatus\": publish_status,\n",
      " \"license\": license,\n",
      " \"notifyFollowers\": notify_followers,\n",
      " } => [Target] response = requests.post(\n",
      " f\"https://api.medium.com/v1/users/{author_id}/posts\",\n",
      " headers=headers,\n",
      " json=data,\n",
      " ), try: total_count = await prisma.models.AnalyticsTracker.prisma().count( where={agent: {is: {submissionStatus: submission_status}}} ), Edge 6: [Source] response = client.places(\\n query=query,\\n radius=radius,\\n page_token=next_page_token,\\n ) => [Target] next_page_token = response.get(\"next_page_token\")\\n if not next_page_token:, Edge 7: [Source] for level in self.levels:\\n if level.park_vehicle(vehicle):\\n return True => [Target] return False, async def validate_payload(cls, webhook: integrations.Webhook, request: Request) -> tuple[dict, str]:)\n",
      "\n",
      "[数据质量问题]\n",
      "错误文件数: 2\n",
      "示例错误:\n",
      "  - 69.json: 'extra_blocks'\n",
      "  - 161.json: unsupported operand type(s) for +=: 'int' and 'str'\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def calculate_global_metrics(results_dir: str) -> dict:\n",
    "    \"\"\"精确的全局指标统计\"\"\"\n",
    "    metrics = {\n",
    "        \"total_files\": 0,\n",
    "        \"gt_edges\": 0,\n",
    "        \"llm_edges\": 0,\n",
    "        \"exact_matches\": 0,\n",
    "        \"partial_matches\": 0,\n",
    "        \"missing_blocks\": set(),\n",
    "        \"extra_blocks\": set(),\n",
    "        \"file_errors\": []\n",
    "    }\n",
    "\n",
    "    # 遍历结果目录\n",
    "    for filename in os.listdir(results_dir):\n",
    "        if not filename.endswith(\".json\"):\n",
    "            continue\n",
    "\n",
    "        filepath = os.path.join(results_dir, filename)\n",
    "        try:\n",
    "            with open(filepath) as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # 核心指标累加\n",
    "            edge_analysis = data[\"edge_analysis\"]\n",
    "            metrics[\"gt_edges\"] += edge_analysis[\"static_total\"]\n",
    "            metrics[\"llm_edges\"] += edge_analysis[\"llm_total\"]\n",
    "            metrics[\"exact_matches\"] += edge_analysis[\"matched_edges\"][\"exact_matches\"]\n",
    "            metrics[\"partial_matches\"] += edge_analysis[\"matched_edges\"][\"partial_matches\"]\n",
    "\n",
    "            # 结构验证统计\n",
    "            structure = data[\"structure_validation\"]\n",
    "            metrics[\"missing_blocks\"].update(map(str, structure[\"missing_blocks\"]))\n",
    "            metrics[\"extra_blocks\"].update(map(str, structure[\"extra_blocks\"]))\n",
    "\n",
    "            metrics[\"total_files\"] += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            metrics[\"file_errors\"].append(f\"{filename}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # 计算衍生指标\n",
    "    total_matched = metrics[\"exact_matches\"] + metrics[\"partial_matches\"]\n",
    "    \n",
    "    precision = total_matched / metrics[\"llm_edges\"] if metrics[\"llm_edges\"] > 0 else 0\n",
    "    recall = total_matched / metrics[\"gt_edges\"] if metrics[\"gt_edges\"] > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"file_count\": metrics[\"total_files\"],\n",
    "        \"edge_metrics\": {\n",
    "            \"static_total\": metrics[\"gt_edges\"],\n",
    "            \"llm_total\": metrics[\"llm_edges\"],\n",
    "            \"exact_matches\": metrics[\"exact_matches\"],\n",
    "            \"partial_matches\": metrics[\"partial_matches\"],\n",
    "            \"total_matched\": total_matched,\n",
    "            \"precision\": round(precision, 4),\n",
    "            \"recall\": round(recall, 4),\n",
    "            \"f1_score\": round(f1, 4)\n",
    "        },\n",
    "        \"structure_metrics\": {\n",
    "            \"missing_blocks_count\": len(metrics[\"missing_blocks\"]),\n",
    "            \"extra_blocks_count\": len(metrics[\"extra_blocks\"]),\n",
    "            \"missing_block_samples\": list(metrics[\"missing_blocks\"])[:5],  # 示例显示前5个\n",
    "            \"extra_block_samples\": list(metrics[\"extra_blocks\"])[:5]\n",
    "        },\n",
    "        \"data_quality\": {\n",
    "            \"error_files\": len(metrics[\"file_errors\"]),\n",
    "            \"error_samples\": metrics[\"file_errors\"][:3]  # 示例显示前3个错误\n",
    "        }\n",
    "    }\n",
    "\n",
    "def print_report(metrics: dict):\n",
    "    \"\"\"格式化输出报告\"\"\"\n",
    "    print(\"CFG 评估报告\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"分析文件总数: {metrics['file_count']}\")\n",
    "    \n",
    "    print(\"\\n[边匹配分析]\")\n",
    "    em = metrics['edge_metrics']\n",
    "    print(f\"静态分析总边数: {em['static_total']}\")\n",
    "    print(f\"LLM生成总边数: {em['llm_total']}\")\n",
    "    print(f\"精确匹配边数: {em['exact_matches']} ({em['exact_matches']/em['static_total']:.2%})\")\n",
    "    print(f\"部分匹配边数: {em['partial_matches']} ({em['partial_matches']/em['static_total']:.2%})\")\n",
    "    print(f\"总匹配边数: {em['total_matched']} ({em['total_matched']/em['static_total']:.2%})\")\n",
    "    print(f\"精确率 (Precision): {em['precision']:.4f}\")\n",
    "    print(f\"召回率 (Recall): {em['recall']:.4f}\")\n",
    "    print(f\"F1 值: {em['f1_score']:.4f}\")\n",
    "\n",
    "    print(\"\\n[结构验证]\")\n",
    "    sm = metrics['structure_metrics']\n",
    "    print(f\"缺失块总数: {sm['missing_blocks_count']} (示例: {', '.join(sm['missing_block_samples'])})\")\n",
    "    print(f\"多余块总数: {sm['extra_blocks_count']} (示例: {', '.join(sm['extra_block_samples'])})\")\n",
    "\n",
    "    if metrics['data_quality']['error_files'] > 0:\n",
    "        print(\"\\n[数据质量问题]\")\n",
    "        print(f\"错误文件数: {metrics['data_quality']['error_files']}\")\n",
    "        print(\"示例错误:\")\n",
    "        for err in metrics['data_quality']['error_samples']:\n",
    "            print(f\"  - {err}\")\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "# 使用示例\n",
    "results_dir = \"results\"\n",
    "metrics = calculate_global_metrics(results_dir)\n",
    "print_report(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
