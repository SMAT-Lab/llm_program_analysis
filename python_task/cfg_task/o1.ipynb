{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 60.py ...\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import json\n",
    "import os\n",
    "from multiprocessing import cpu_count\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import re\n",
    "\n",
    "# 假设你有一个自定义的大模型接口\n",
    "from llm import get_llm_answers\n",
    "\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "###############################\n",
    "# 1) 第一步：解析类 & 函数行号\n",
    "###############################\n",
    "def get_structure_prompt(code_text: str, program_language: str) -> str:\n",
    "    \"\"\"\n",
    "    让大模型输出文件内的类、函数的嵌套结构和行号范围。\n",
    "    \"\"\"\n",
    "    # 把代码行打包成 JSON，方便 LLM 在回答时索引\n",
    "    lines = code_text.splitlines()\n",
    "    lines_json = [\n",
    "        {\"line\": i + 1, \"code\": line} for i, line in enumerate(lines)\n",
    "    ]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are given a piece of {program_language} code. \n",
    "Your task: find all the nested classes and methods in the code, \n",
    "including their exact start_line and end_line.\n",
    "\n",
    "Return a JSON with this structure:\n",
    "\n",
    "{{\n",
    "  \"name\": \"example_script\", \n",
    "  \"type\": \"CFG\",\n",
    "  \"start_line\": 1,\n",
    "  \"end_line\": {len(lines)},\n",
    "  \"functions\": [\n",
    "    {{\n",
    "      \"name\": \"function_name\",\n",
    "      \"type\": \"function\",\n",
    "      \"start_line\": 10,\n",
    "      \"end_line\": 20,\n",
    "      \"functions\": [],\n",
    "      \"classes\": []\n",
    "    }}\n",
    "  ],\n",
    "  \"classes\": [\n",
    "    {{\n",
    "      \"name\": \"class_name\",\n",
    "      \"type\": \"class\",\n",
    "      \"start_line\": 30,\n",
    "      \"end_line\": 50,\n",
    "      \"functions\": [\n",
    "        {{\n",
    "          \"name\": \"method_name\",\n",
    "          \"type\": \"function\",\n",
    "          \"start_line\": 35,\n",
    "          \"end_line\": 40,\n",
    "          \"functions\": [],\n",
    "          \"classes\": []\n",
    "        }}\n",
    "      ],\n",
    "      \"classes\": []\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "IMPORTANT:\n",
    "1) If a function is nested in a class, put it in the class's \"functions\".\n",
    "2) If a class is nested in another class, put it in \"classes\".\n",
    "3) start_line/end_line must reflect the actual lines in the original code.\n",
    "4) Do not omit or reorder fields. Use the exact structure above.\n",
    "\n",
    "Code lines:\n",
    "{json.dumps(lines_json, indent=2)}\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def find_structure(code_text: str, program_language=\"python\"):\n",
    "    \"\"\"\n",
    "    调用大模型获取文件中的类、函数及其行范围\n",
    "    \"\"\"\n",
    "    prompt = get_structure_prompt(code_text, program_language)\n",
    "    response = get_llm_answers(prompt, model_name=model_name, require_json=True)\n",
    "    structure = json.loads(response)\n",
    "    return structure\n",
    "\n",
    "\n",
    "###############################\n",
    "# 2) 第二步：为某段代码生成“树状”CFG\n",
    "###############################\n",
    "def get_tree_cfg_prompt(code: str, program_language: str, block_name: str) -> str:\n",
    "    \"\"\"\n",
    "    让大模型基于一段完整的代码生成“树状”CFG，保留完整代码行，不做简化。\n",
    "    successors 里直接嵌套 block 对象（非 ID）。\n",
    "    \"\"\"\n",
    "    lines = code.splitlines()\n",
    "    lines_json = [\n",
    "        {\"line\": i + 1, \"code\": line} for i, line in enumerate(lines)\n",
    "    ]\n",
    "    # 示例 JSON 的字符串，直接内嵌到 Prompt 中\n",
    "    example_json = \"\"\"{\n",
    "  \"name\": \"my_block\",\n",
    "  \"type\": \"CFG\",\n",
    "  \"blocks\": [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"start_line\": 1,\n",
    "      \"end_line\": 10,\n",
    "      \"successors\": [\n",
    "        {\n",
    "          \"id\": 2,\n",
    "          \"start_line\": 11,\n",
    "          \"end_line\": 20,\n",
    "          \"successors\": []\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"functions\": [\n",
    "    {\n",
    "      \"name\": \"my_function\",\n",
    "      \"type\": \"CFG\",\n",
    "      \"blocks\": [\n",
    "        {\n",
    "          \"id\": 1,\n",
    "          \"start_line\": 1,\n",
    "          \"end_line\": 10,\n",
    "          \"successors\": []\n",
    "        }\n",
    "      ],\n",
    "      \"functions\": [],\n",
    "      \"classes\": []\n",
    "    }\n",
    "  ],\n",
    "  \"classes\": []\n",
    "}\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are given a piece of {program_language} code, and you must produce a CFG in **tree style**:\n",
    "- The top-level JSON must be:\n",
    "  {{\n",
    "    \"name\": \"{block_name}\",\n",
    "    \"type\": \"CFG\",\n",
    "    \"blocks\": [...],\n",
    "    \"functions\": [...],\n",
    "    \"classes\": [...]\n",
    "  }}\n",
    "- \"blocks\" is an array of basic blocks. Each block is:\n",
    "  {{\n",
    "    \"id\": <int>,\n",
    "    \"start_line\": <int>,\n",
    "    \"end_line\": <int>,\n",
    "    \"successors\": [ <nested block objects> ]\n",
    "  }}\n",
    "  i.e., the \"successors\" array must be the actual nested blocks, not integer IDs.\n",
    "- \"functions\" is an array of nested function CFGs, each of which has the same structure \n",
    "  (with \"blocks\", \"functions\", \"classes\").\n",
    "- \"classes\" likewise.\n",
    "\n",
    "DO NOT remove or simplify any lines from the code. The label must keep the code exactly. \n",
    "If there's an 'if' or loop or branch, you can split it into multiple blocks, \n",
    "but the \"successors\" must be nested sub-blocks in tree form, \n",
    "and not references by ID.\n",
    "\n",
    "Attention to these situations which might produce multiple blocks:\n",
    "1) if/else/elif/else\n",
    "2) for/while/else\n",
    "3) try/except/else/finally\n",
    "4) with/else\n",
    "5) switch/case/default\n",
    "\n",
    "Example output (shortened):\n",
    "{example_json}\n",
    "\n",
    "Now, here is the code you should analyze:\n",
    "------------------------------------\n",
    "{json.dumps(lines_json, indent=2)}\n",
    "------------------------------------\n",
    "\n",
    "Follow the structure carefully. Output only JSON.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def get_code_by_line_range(code_block, code, block_type: str = \"block\"):\n",
    "    \"\"\"\n",
    "    从 code 中提取 [start_line, end_line] 这一段代码，\n",
    "    但会把本 block 内部子级的 class、function 的行号都排除掉，\n",
    "    最终得到 label。\n",
    "    \"\"\"\n",
    "    code_lines = code.splitlines()\n",
    "    start_line = code_block[\"start_line\"]\n",
    "    # 因为 range() 的特性，end_line+1 可以覆盖到 end_line 那行\n",
    "    end_line = code_block[\"end_line\"]\n",
    "\n",
    "    if block_type == \"class\" or block_type == \"function\":\n",
    "        start_line += 1\n",
    "\n",
    "    # 先构建所有行的集合\n",
    "    line_set = set(range(start_line, end_line + 1))\n",
    "\n",
    "    # 减去所有子函数行号范围\n",
    "    for func in code_block.get(\"functions\", []):\n",
    "        func_start_line = func.get(\"start_line\", 0)\n",
    "        func_end_line = func.get(\"end_line\", 0)\n",
    "        line_set.difference_update(range(func_start_line, func_end_line))\n",
    "\n",
    "    # 减去所有子类行号范围\n",
    "    for cls in code_block.get(\"classes\", []):\n",
    "        cls_start_line = cls.get(\"start_line\", 0)\n",
    "        cls_end_line = cls.get(\"end_line\", 0)\n",
    "        line_set.difference_update(range(cls_start_line, cls_end_line+1))\n",
    "\n",
    "    # 将剩下的行号排序\n",
    "    ordered_lines = sorted(list(line_set))\n",
    "    # 拼接\n",
    "    sum_code = \"\\n\".join([code_lines[i - 1] for i in ordered_lines])\n",
    "\n",
    "    sum_code = re.sub(r'\\n+', '\\n', sum_code).strip()\n",
    "\n",
    "    # 存到 code_block 里\n",
    "    code_block[\"label\"] = sum_code\n",
    "\n",
    "def build_tree_cfg_for_block(block_info: dict, code_text: str, program_language: str, block_type: str = \"block\") -> dict:\n",
    "    # 先对这个 block 做“行号剥离”操作\n",
    "    get_code_by_line_range(block_info, code_text, block_type)\n",
    "    full_code_segment = block_info[\"label\"]\n",
    "\n",
    "    # 让大模型生成 CFG\n",
    "    block_name = block_info.get(\"name\", \"anonymous_block\")\n",
    "    prompt = get_tree_cfg_prompt(full_code_segment, program_language, block_name)\n",
    "    response_text = get_llm_answers(prompt, model_name=model_name, require_json=True)\n",
    "    partial_cfg = json.loads(response_text)\n",
    "\n",
    "    # 递归处理 partial_cfg[\"blocks\"] 及其所有 successors\n",
    "    def update_block_tree(block: dict, local_code: str):\n",
    "        get_code_by_line_range(block, local_code)\n",
    "        for succ in block.get(\"successors\", []):\n",
    "            update_block_tree(succ, local_code)\n",
    "\n",
    "    for b in partial_cfg.get(\"blocks\", []):\n",
    "        update_block_tree(b, full_code_segment)\n",
    "\n",
    "    # 继续递归处理子函数、子类\n",
    "    final_functions = []\n",
    "    for func_info in block_info.get(\"functions\", []):\n",
    "        sub_cfg = build_tree_cfg_for_block(func_info, code_text, program_language, \"function\")\n",
    "        final_functions.append(sub_cfg)\n",
    "\n",
    "    final_classes = []\n",
    "    for cls_info in block_info.get(\"classes\", []):\n",
    "        sub_cfg = build_tree_cfg_for_block(cls_info, code_text, program_language, \"class\")\n",
    "        final_classes.append(sub_cfg)\n",
    "\n",
    "    partial_cfg[\"functions\"] = final_functions\n",
    "    partial_cfg[\"classes\"] = final_classes\n",
    "\n",
    "    return partial_cfg\n",
    "\n",
    "#########################\n",
    "# 3) 处理单个文件\n",
    "#########################\n",
    "def process_file(file_path: str, program_language=\"python\") -> dict:\n",
    "    \"\"\"\n",
    "    - 读取文件内容\n",
    "    - 第1步：解析嵌套结构(类 / 函数及其行号)\n",
    "    - 第2步：将顶层解析成 CFG，再递归处理子函数、子类，得到树状结果\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        code_text = f.read()\n",
    "\n",
    "    # (A) 获取文件整体结构\n",
    "    structure = find_structure(code_text, program_language)\n",
    "    # structure 里是最顶层 { name, type, start_line, end_line, functions, classes }\n",
    "\n",
    "    # (B) 构建树状 CFG\n",
    "    # 注意：最顶层也算一个 block_info\n",
    "    top_cfg = build_tree_cfg_for_block(structure, code_text, program_language)\n",
    "\n",
    "    return top_cfg\n",
    "\n",
    "\n",
    "#########################\n",
    "# 4) 批量处理\n",
    "#########################\n",
    "def main():\n",
    "    # 输出路径\n",
    "    output_dir = \"tree_cfg_output\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 假设源代码都在 source_code/ 下\n",
    "    source_dir = \"source_code\"\n",
    "    files = os.listdir(source_dir)\n",
    "\n",
    "    # 这里仅示例处理前 50 个 .py 文件\n",
    "    py_files = [f for f in files if f.endswith(\".py\")][:5]\n",
    "\n",
    "    def process_single_file(filename):\n",
    "        input_path = os.path.join(source_dir, filename)\n",
    "        output_path = os.path.join(output_dir, filename.replace(\".py\", \".json\"))\n",
    "        # if os.path.exists(output_path):\n",
    "        #     print(f\"Skipping {filename}, already processed.\")\n",
    "        #     return\n",
    "\n",
    "        print(f\"Processing {filename} ...\")\n",
    "\n",
    "        final_cfg = process_file(input_path, \"python\")\n",
    "        # 写入 JSON\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as wf:\n",
    "            json.dump(final_cfg, wf, indent=2)\n",
    "\n",
    "    process_single_file(\"60.py\")\n",
    "\n",
    "    # 并行处理\n",
    "    # with ThreadPoolExecutor(max_workers=cpu_count()) as executor:\n",
    "    #     executor.map(process_single_file, py_files)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 11.py ...\n",
      "Processing 60.py ...\n",
      "Processing 180.py ...\n",
      "Processing 195.py ...\n",
      "Processing 202.py ...\n",
      "Processing 208.py ...\n",
      "Processing 176.py ...\n",
      "Processing 151.py ...\n",
      "Processing 98.py ...\n",
      "Processing 13.py ...\n",
      "Processing 71.py ...\n",
      "Processing 120.py ...\n",
      "Processing 12.py ...\n",
      "Processing 167.py ...\n",
      "Processing 186.py ...\n",
      "Processing 62.py ...\n",
      "Processing 14.py ...\n",
      "Processing 6.py ...\n",
      "Processing 59.py ...\n",
      "Processing 107.py ...\n",
      "Processing 163.py ...\n",
      "Processing 9.py ...\n",
      "Processing 129.py ...\n",
      "Processing 139.py ...\n",
      "Processing 54.py ...\n",
      "Processing 184.py ...\n",
      "Processing 174.py ...\n",
      "Processing 138.py ...\n",
      "Processing 148.py ...\n",
      "Processing 201.py ...\n",
      "Processing 75.py ...\n",
      "Processing 55.py ...\n",
      "Processing 159.py ...\n",
      "Processing 160.py ...\n",
      "Processing 123.py ...\n",
      "Processing 29.py ...\n",
      "Processing 100.py ...\n",
      "Processing 45.py ...\n",
      "Processing 116.py ...\n",
      "Processing 25.py ...\n",
      "Processing 89.py ...\n",
      "Processing 28.py ...\n",
      "Processing 86.py ...\n",
      "Processing 99.py ...\n",
      "Processing 19.py ...\n",
      "Processing 90.py ...\n",
      "Processing 132.py ...\n",
      "Processing 77.py ...\n",
      "Processing 144.py ...\n",
      "Processing 93.py ...\n",
      "Processing 198.py ...\n",
      "Processing 8.py ...\n",
      "Processing 110.py ...\n",
      "Processing 82.py ...\n",
      "Processing 131.py ...\n",
      "Processing 102.py ...\n",
      "Processing 48.py ...\n",
      "Processing 183.py ...\n",
      "Processing 121.py ...\n",
      "Processing 112.py ...\n",
      "Processing 103.py ...\n",
      "Processing 210.py ...\n",
      "Processing 34.py ...\n",
      "Processing 30.py ...\n",
      "Processing 70.py ...\n",
      "Processing 141.py ...\n",
      "Processing 91.py ...\n",
      "Processing 72.py ...\n",
      "Processing 78.py ...\n",
      "Processing 136.py ...\n",
      "Processing 74.py ...\n",
      "Processing 44.py ...\n",
      "Processing 37.py ...\n",
      "Processing 58.py ...\n",
      "Processing 84.py ...\n",
      "Processing 125.py ...\n",
      "Processing 164.py ...\n",
      "Processing 171.py ...\n",
      "Processing 47.py ...\n",
      "Processing 104.py ...\n",
      "Processing 83.py ...\n",
      "Processing 196.py ...\n",
      "Processing 204.py ...\n",
      "Processing 41.py ...\n",
      "Processing 140.py ...\n",
      "Processing 154.py ...\n",
      "Processing 172.py ...\n",
      "Processing 40.py ...\n",
      "Processing 113.py ...\n",
      "Processing 43.py ...\n",
      "Processing 4.py ...\n",
      "Processing 94.py ...\n",
      "Processing 155.py ...\n",
      "Processing 57.py ...\n",
      "Processing 194.py ...\n",
      "Processing 18.py ...\n",
      "Processing 126.py ...\n",
      "Processing 158.py ...\n",
      "Processing 133.py ...\n",
      "Processing 117.py ...\n",
      "Processing 122.py ...\n",
      "Processing 156.py ...\n",
      "Processing 187.py ...\n",
      "Processing 87.py ...\n",
      "Processing 51.py ...\n",
      "Processing 96.py ...\n",
      "Processing 203.py ...\n",
      "Processing 52.py ...\n",
      "Processing 68.py ...\n",
      "Processing 142.py ...\n",
      "Processing 200.py ...\n",
      "Processing 169.py ...\n",
      "Processing 119.py ...\n",
      "Processing 50.py ...\n",
      "Processing 170.py ...\n",
      "Processing 145.py ...\n",
      "Processing 209.py ...\n",
      "Processing 109.py ...\n",
      "Processing 128.py ...\n",
      "Processing 33.py ...\n",
      "Processing 189.py ...\n",
      "Processing 81.py ...\n",
      "Processing 193.py ...\n",
      "Processing 79.py ...\n",
      "Processing 63.py ...\n",
      "Processing 42.py ...\n",
      "Processing 53.py ...\n",
      "Processing 181.py ...\n",
      "Processing 165.py ...\n",
      "Processing 36.py ...\n",
      "Processing 115.py ...\n",
      "Processing 199.py ...\n",
      "Processing 2.py ...\n",
      "Processing 26.py ...\n",
      "Processing 67.py ...\n",
      "Processing 1.py ...\n",
      "Processing 185.py ...\n",
      "Processing 147.py ...\n",
      "Processing 27.py ...\n",
      "Processing 118.py ...\n",
      "Processing 111.py ...\n",
      "Processing 24.py ...\n",
      "Processing 149.py ...\n",
      "Processing 177.py ...\n",
      "Processing 73.py ...\n",
      "Processing 92.py ...\n",
      "Processing 175.py ...\n",
      "Processing 190.py ...\n",
      "Processing 32.py ...\n",
      "Processing 46.py ...\n",
      "Processing 66.py ...\n",
      "Processing 35.py ...\n",
      "Processing 38.py ...\n",
      "Processing 69.py ...\n",
      "Processing 5.py ...\n",
      "Processing 108.py ...\n",
      "Processing 20.py ...\n",
      "Processing 152.py ...\n",
      "Processing 80.py ...\n",
      "Processing 56.py ...\n",
      "Processing 114.py ...\n",
      "Processing 188.py ...\n",
      "Processing 23.py ...\n",
      "Processing 64.py ...\n",
      "Processing 95.py ...\n",
      "Processing 166.py ...\n",
      "Processing 106.py ...\n",
      "Processing 161.py ...\n",
      "Processing 192.py ...\n",
      "Processing 101.py ...\n",
      "Processing 178.py ...\n",
      "Processing 15.py ...\n",
      "Processing 205.py ...\n",
      "Processing 207.py ...\n",
      "Processing 150.py ...\n",
      "Processing 197.py ...\n",
      "Processing 182.py ...\n",
      "Processing 65.py ...\n",
      "Processing 88.py ...\n",
      "Processing 157.py ...\n",
      "Processing 31.py ...\n",
      "Processing 21.py ...\n",
      "Processing 162.py ...\n",
      "Processing 22.py ...\n",
      "Processing 127.py ...\n",
      "Processing 135.py ...\n",
      "Processing 10.py ...\n",
      "Processing 130.py ...\n",
      "Processing 49.py ...\n",
      "Processing 153.py ...\n",
      "Processing 124.py ...\n",
      "Processing 191.py ...\n",
      "Processing 173.py ...\n",
      "Processing 39.py ...\n",
      "Processing 61.py ...\n",
      "Processing 16.py ...\n",
      "Processing 17.py ...\n",
      "Processing 137.py ...\n",
      "Processing 3.py ...\n",
      "Processing 179.py ...\n",
      "Processing 146.py ...\n",
      "Processing 134.py ...\n",
      "Processing 168.py ...\n",
      "Processing 7.py ...\n",
      "Processing 206.py ...\n",
      "Processing 105.py ...\n",
      "Processing 85.py ...\n",
      "Processing 76.py ...\n",
      "Processing 0.py ...\n",
      "Processing 143.py ...\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from multiprocessing import cpu_count\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# 假设你有一个自定义的大模型接口\n",
    "from llm import get_llm_answers\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "###############################\n",
    "# 1) 第一步：解析类 & 函数行号\n",
    "###############################\n",
    "def get_structure_prompt(code_text: str, program_language: str) -> str:\n",
    "    lines = code_text.splitlines()\n",
    "    lines_json = [{\"line\": i + 1, \"code\": line} for i, line in enumerate(lines)]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are given a piece of {program_language} code. \n",
    "Your task: find all the nested classes and methods in the code, \n",
    "including their exact start_line and end_line.\n",
    "\n",
    "Return a JSON with this structure:\n",
    "\n",
    "{{\n",
    "  \"name\": \"example_script\", \n",
    "  \"type\": \"CFG\",\n",
    "  \"start_line\": 1,\n",
    "  \"end_line\": {len(lines)},\n",
    "  \"functions\": [\n",
    "    {{\n",
    "      \"name\": \"function_name\",\n",
    "      \"type\": \"function\",\n",
    "      \"start_line\": 10,\n",
    "      \"end_line\": 20,\n",
    "      \"functions\": [],\n",
    "      \"classes\": []\n",
    "    }}\n",
    "  ],\n",
    "  \"classes\": [\n",
    "    {{\n",
    "      \"name\": \"class_name\",\n",
    "      \"type\": \"class\",\n",
    "      \"start_line\": 30,\n",
    "      \"end_line\": 50,\n",
    "      \"functions\": [\n",
    "        {{\n",
    "          \"name\": \"method_name\",\n",
    "          \"type\": \"function\",\n",
    "          \"start_line\": 35,\n",
    "          \"end_line\": 40,\n",
    "          \"functions\": [],\n",
    "          \"classes\": []\n",
    "        }}\n",
    "      ],\n",
    "      \"classes\": []\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "IMPORTANT:\n",
    "1) If a function is nested in a class, put it in the class's \"functions\".\n",
    "2) If a class is nested in another class, put it in \"classes\".\n",
    "3) start_line/end_line must reflect the actual lines in the original code (1-based).\n",
    "4) Do not omit or reorder fields. Use the exact structure above.\n",
    "\n",
    "Code lines:\n",
    "{json.dumps(lines_json, indent=2)}\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def find_structure(code_text: str, program_language=\"python\"):\n",
    "    prompt = get_structure_prompt(code_text, program_language)\n",
    "    response = get_llm_answers(prompt, model_name=model_name, require_json=True)\n",
    "    structure = json.loads(response)\n",
    "    return structure\n",
    "\n",
    "\n",
    "###############################\n",
    "# 2) 第二步：为某段代码生成“树状”CFG\n",
    "###############################\n",
    "def get_tree_cfg_prompt(code: str, program_language: str, block_name: str) -> str:\n",
    "    \"\"\"\n",
    "    让大模型基于一段完整的代码生成“树状”CFG，保留完整代码行，不做简化。\n",
    "    successors 里直接嵌套 block 对象（非 ID）。\n",
    "    \"\"\"\n",
    "    lines = code.splitlines()\n",
    "    lines_json = [{\"line\": i + 1, \"code\": line} for i, line in enumerate(lines)]\n",
    "\n",
    "    example_json = \"\"\"{\n",
    "  \"name\": \"my_block\",\n",
    "  \"type\": \"CFG\",\n",
    "  \"blocks\": [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"start_line\": 1,\n",
    "      \"end_line\": 10,\n",
    "      \"successors\": [\n",
    "        {\n",
    "          \"id\": 2,\n",
    "          \"start_line\": 11,\n",
    "          \"end_line\": 20,\n",
    "          \"successors\": []\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"functions\": [\n",
    "    {\n",
    "      \"name\": \"my_function\",\n",
    "      \"type\": \"CFG\",\n",
    "      \"blocks\": [\n",
    "        {\n",
    "          \"id\": 1,\n",
    "          \"start_line\": 1,\n",
    "          \"end_line\": 10,\n",
    "          \"successors\": []\n",
    "        }\n",
    "      ],\n",
    "      \"functions\": [],\n",
    "      \"classes\": []\n",
    "    }\n",
    "  ],\n",
    "  \"classes\": []\n",
    "}\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are given a piece of {program_language} code, and you must produce a CFG in **tree style**:\n",
    "- The top-level JSON must be:\n",
    "  {{\n",
    "    \"name\": \"{block_name}\",\n",
    "    \"type\": \"CFG\", \n",
    "    \"blocks\": [...],\n",
    "    \"functions\": [...],\n",
    "    \"classes\": [...]\n",
    "  }}\n",
    "- \"blocks\" is an array of basic blocks. Each block is:\n",
    "  {{\n",
    "    \"id\": <int>,\n",
    "    \"start_line\": <int>, \n",
    "    \"end_line\": <int>,\n",
    "    \"successors\": [ <nested block objects> ]\n",
    "  }}\n",
    "- \"functions\" is an array of nested function CFGs, each with the same structure.\n",
    "- \"classes\" likewise.\n",
    "\n",
    "Keep the code lines exactly as is.\n",
    "When splitting code into blocks, follow these rules:\n",
    "1) For if statements:\n",
    "   - The if condition in the block A\n",
    "   - The if body in the successors of the block A\n",
    "   - The elif/else bodies in the successors of the block A\n",
    "2) For loops:\n",
    "   - The loop header (for/while) in the block A\n",
    "   - The loop body in the successors of the block A\n",
    "   - The else clause in the successors of the block A\n",
    "3) For try/except:\n",
    "   - The try in the block A\n",
    "   - The try body in the successors of the block A\n",
    "   - The except clauses in the successors of the block A\n",
    "   - The else in the successors of the block A\n",
    "   - The finally in the successors of the block A\n",
    "4) For with statements:\n",
    "   - The with line in the block A\n",
    "   - The with body in the successors of the block A\n",
    "5) For switch/case:\n",
    "   - The switch in the block A\n",
    "   - The each case/default in the successors of the block A\n",
    "\n",
    "6) For yield statements and so on:\n",
    "   - The yield statement in the block A\n",
    "   - The yield body in the successors of the block A\n",
    "\n",
    "You must split the code into blocks exactly as described above.\n",
    "\n",
    "Example output (shortened):\n",
    "{example_json}\n",
    "\n",
    "Now, here is the code you should analyze:\n",
    "------------------------------------\n",
    "{json.dumps(lines_json, indent=2)}\n",
    "------------------------------------\n",
    "\n",
    "Follow the structure carefully. Output only JSON.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "##############################\n",
    "# 剥离子函数/子类范围的函数\n",
    "##############################\n",
    "def get_code_by_line_range(block_info: dict, code: str, block_type: str = \"block\"):\n",
    "    \"\"\"\n",
    "    从 code 中提取 [start_line..end_line] 行；移除所有子 class/function 的行；\n",
    "    并将连续空行合并为1行，然后存到 block_info[\"label\"]。\n",
    "    \"\"\"\n",
    "    code_lines = code.splitlines()\n",
    "\n",
    "    start_line = block_info[\"start_line\"]\n",
    "    end_line = block_info[\"end_line\"]\n",
    "\n",
    "    if block_type in (\"class\", \"function\"):\n",
    "        # 有时希望类或函数定义的第一行(如 'class XXX:' 或 'def yyy:')\n",
    "        # 不包含在 label 里，可加一些偏移\n",
    "        # 或者你想保留也行，看需求\n",
    "        start_line += 0\n",
    "\n",
    "    # 构建本块的行号集合\n",
    "    line_set = set(range(start_line, end_line + 1))\n",
    "\n",
    "    # 删去所有子函数行号范围\n",
    "    for func in block_info.get(\"functions\", []):\n",
    "        fs = set(range(func.get(\"start_line\", 0), func.get(\"end_line\", 0) + 1))\n",
    "        line_set.difference_update(fs)\n",
    "\n",
    "    # 删去所有子类行号范围\n",
    "    for cls in block_info.get(\"classes\", []):\n",
    "        cs = set(range(cls.get(\"start_line\", 0), cls.get(\"end_line\", 0) + 1))\n",
    "        line_set.difference_update(cs)\n",
    "\n",
    "    # 排序并拼成字符串\n",
    "    ordered_lines = sorted(list(line_set))\n",
    "    sum_code = \"\\n\".join([code_lines[i - 1] for i in ordered_lines])\n",
    "    # 合并多余空行\n",
    "    sum_code = re.sub(r\"\\n+\", \"\\n\", sum_code).strip()\n",
    "\n",
    "    block_info[\"label\"] = sum_code\n",
    "\n",
    "\n",
    "##############################\n",
    "# 更新 block 及其 successors\n",
    "##############################\n",
    "def update_block_tree(block: dict, local_code: str) -> set:\n",
    "    \"\"\"\n",
    "    递归地处理一个 block:\n",
    "    1) 先获取该 block 的行号集合 = [start_line..end_line].\n",
    "    2) 对所有 successors 做递归调用, 收集它们用到的行号 all_succ_lines.\n",
    "    3) 从本 block 的行号集合中剔除 all_succ_lines, 得到 exclusive_lines.\n",
    "    4) 拼接成 label, 存入 block[\"label\"].\n",
    "    5) 返回【本 block 及其 successors】共同使用的行号 (供上层再剔除).\n",
    "    \"\"\"\n",
    "    start_line = block.get(\"start_line\", 0)\n",
    "    end_line = block.get(\"end_line\", 0)\n",
    "    parent_lines = set(range(start_line, end_line + 1))\n",
    "\n",
    "    # 先收集所有后继的行号\n",
    "    all_succ_lines = set()\n",
    "    for succ in block.get(\"successors\", []):\n",
    "        child_lines = update_block_tree(succ, local_code)\n",
    "        all_succ_lines |= child_lines\n",
    "\n",
    "    # 现在 parent_lines - all_succ_lines 才是“父block专属”的行号\n",
    "    exclusive_lines = parent_lines - all_succ_lines\n",
    "\n",
    "    # 拼接 label\n",
    "    code_lines = local_code.splitlines()\n",
    "    # 排序\n",
    "    ordered = sorted(list(exclusive_lines))\n",
    "    label = \"\\n\".join(code_lines[i - 1] for i in ordered)\n",
    "    # 压缩空行\n",
    "    label = re.sub(r\"\\n+\", \"\\n\", label).strip()\n",
    "    block[\"label\"] = label\n",
    "\n",
    "    # 返回 “父 + 所有后继” 总共使用的行号\n",
    "    return parent_lines | all_succ_lines\n",
    "\n",
    "\n",
    "##############################\n",
    "# 3) 构造树状 CFG\n",
    "##############################\n",
    "def build_tree_cfg_for_block(block_info: dict, code_text: str, program_language: str, block_type: str = \"block\") -> dict:\n",
    "    \"\"\"\n",
    "    先用 get_code_by_line_range 剥离子class/function。然后调用大模型生成 CFG 结构。\n",
    "    再对 “partial_cfg[blocks]” 做 update_block_tree，以排除后继块使用的行号。\n",
    "    最后再递归处理子函数/子类，并写入 partial_cfg[\"functions\"], partial_cfg[\"classes\"].\n",
    "    \"\"\"\n",
    "    # 剥离子class/function\n",
    "    get_code_by_line_range(block_info, code_text, block_type)\n",
    "    local_segment = block_info[\"label\"]\n",
    "\n",
    "    block_name = block_info.get(\"name\", \"anonymous_block\")\n",
    "    prompt = get_tree_cfg_prompt(local_segment, program_language, block_name)\n",
    "    response_text = get_llm_answers(prompt, model_name=model_name, require_json=True)\n",
    "    partial_cfg = json.loads(response_text)\n",
    "\n",
    "    # 第一步：对 partial_cfg[\"blocks\"] 进行“父子行号去重”\n",
    "    for b in partial_cfg.get(\"blocks\", []):\n",
    "        update_block_tree(b, local_segment)\n",
    "\n",
    "    # 第二步：继续递归处理子函数、子类\n",
    "    final_functions = []\n",
    "    for func_info in block_info.get(\"functions\", []):\n",
    "        sub_cfg = build_tree_cfg_for_block(func_info, code_text, program_language, \"function\")\n",
    "        final_functions.append(sub_cfg)\n",
    "\n",
    "    final_classes = []\n",
    "    for cls_info in block_info.get(\"classes\", []):\n",
    "        sub_cfg = build_tree_cfg_for_block(cls_info, code_text, program_language, \"class\")\n",
    "        final_classes.append(sub_cfg)\n",
    "\n",
    "    partial_cfg[\"functions\"] = final_functions\n",
    "    partial_cfg[\"classes\"] = final_classes\n",
    "\n",
    "    return partial_cfg\n",
    "\n",
    "\n",
    "#########################\n",
    "# 处理单个文件\n",
    "#########################\n",
    "def process_file(file_path: str, program_language=\"python\") -> dict:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        code_text = f.read()\n",
    "\n",
    "    # 获取文件整体结构\n",
    "    structure = find_structure(code_text, program_language)\n",
    "    # 构建树状 CFG\n",
    "    top_cfg = build_tree_cfg_for_block(structure, code_text, program_language)\n",
    "    return top_cfg\n",
    "\n",
    "\n",
    "#########################\n",
    "# 批量处理\n",
    "#########################\n",
    "def main():\n",
    "    output_dir = f\"{model_name}_tree_cfg_output\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    source_dir = \"source_code\"\n",
    "    files = os.listdir(source_dir)\n",
    "    py_files = [f for f in files if f.endswith(\".py\")][:]\n",
    "\n",
    "    def process_single_file(filename):\n",
    "        input_path = os.path.join(source_dir, filename)\n",
    "        output_path = os.path.join(output_dir, filename.replace(\".py\", \".json\"))\n",
    "        print(f\"Processing {filename} ...\")\n",
    "\n",
    "        final_cfg = process_file(input_path, \"python\")\n",
    "        def add_label_after_end_line(cfg_dict):\n",
    "            # 处理当前层级的blocks\n",
    "            for block in cfg_dict.get(\"blocks\", []):\n",
    "                if \"label\" in block:\n",
    "                    # 保存并删除label\n",
    "                    code = block.pop(\"label\")\n",
    "                    \n",
    "                    # 重新按顺序构建字典\n",
    "                    new_block = {}\n",
    "                    for k, v in block.items():\n",
    "                        new_block[k] = v\n",
    "                        if k == \"end_line\":\n",
    "                            new_block[\"label\"] = code\n",
    "                    \n",
    "                    # 用重排后的字典替换原block\n",
    "                    block.clear()\n",
    "                    block.update(new_block)\n",
    "                \n",
    "                # 递归处理successors\n",
    "                for successor in block.get(\"successors\", []):\n",
    "                    add_label_after_end_line({\"blocks\": [successor]})\n",
    "            \n",
    "            # 递归处理functions\n",
    "            for func in cfg_dict.get(\"functions\", []):\n",
    "                add_label_after_end_line(func)\n",
    "                \n",
    "            # 递归处理classes  \n",
    "            for cls in cfg_dict.get(\"classes\", []):\n",
    "                add_label_after_end_line(cls)\n",
    "                \n",
    "        add_label_after_end_line(final_cfg)\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as wf:\n",
    "            json.dump(final_cfg, wf, indent=2)\n",
    "\n",
    "    from concurrent.futures import ThreadPoolExecutor\n",
    "    import multiprocessing\n",
    "\n",
    "    # 获取CPU核心数\n",
    "    num_workers = multiprocessing.cpu_count()\n",
    "    \n",
    "    # 使用线程池并行处理文件\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        executor.map(process_single_file, py_files)\n",
    "\n",
    "    # for fn in py_files:\n",
    "    #     process_single_file(\"60.py\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 总体评估结果 ===\n",
      "平均整体得分: 0.800\n",
      "\n",
      "=== 结构评估 ===\n",
      "类评估:\n",
      "  - Precision: 0.997\n",
      "  - Recall: 0.997\n",
      "  - F1: 0.997\n",
      "函数评估:\n",
      "  - Precision: 0.997\n",
      "  - Recall: 0.993\n",
      "  - F1: 0.995\n",
      "\n",
      "=== 基本块评估 ===\n",
      "Precision: 0.619\n",
      "Recall: 0.431\n",
      "F1: 0.407\n",
      "\n",
      "=== 边评估 ===\n",
      "Precision: 0.997\n",
      "Recall: 1.000\n",
      "F1: 0.997\n",
      "\n",
      "=== 子图统计 ===\n",
      "平均匹配子图数: 9.8\n",
      "平均额外子图数: 0.0\n",
      "平均缺失子图数: 0.1\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import json\n",
    "import difflib\n",
    "import re\n",
    "from typing import Dict, Any, List, Tuple, Set\n",
    "\n",
    "\n",
    "############################################\n",
    "# 1) 收集子图(顶层/class/function)\n",
    "############################################\n",
    "\n",
    "def collect_subgraphs(cfg: dict, prefix: str=\"\") -> Dict[str, dict]:\n",
    "    \"\"\"\n",
    "    递归收集子图:\n",
    "    - 每一层(顶层, class, function)变成一个subgraph\n",
    "    - subgraph包含: {\n",
    "         \"prefix\": prefix,\n",
    "         \"blocks\": [  # block结构保持原状\n",
    "            {\n",
    "              \"label\": \"...\",\n",
    "              \"successors\": [...],  # 仍然是block对象list\n",
    "              ...\n",
    "            },\n",
    "            ...\n",
    "         ]\n",
    "      }\n",
    "    - 并进一步递归function/classes\n",
    "    返回: { prefix -> subgraph }\n",
    "    \"\"\"\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    # 当前层 subgraph\n",
    "    sub = {\n",
    "        \"prefix\": prefix,\n",
    "        \"blocks\": cfg.get(\"blocks\", [])\n",
    "    }\n",
    "    result[prefix] = sub\n",
    "\n",
    "    # 递归 functions\n",
    "    for f in cfg.get(\"functions\", []):\n",
    "        fname = f.get(\"name\",\"\")\n",
    "        subpfx = prefix + \".\" + fname if prefix else fname\n",
    "        result.update( collect_subgraphs(f, subpfx) )\n",
    "\n",
    "    # 递归 classes\n",
    "    for c in cfg.get(\"classes\", []):\n",
    "        cname = c.get(\"name\",\"\")\n",
    "        subpfx = prefix + \".\" + cname if prefix else cname\n",
    "        result.update( collect_subgraphs(c, subpfx) )\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "############################################\n",
    "# 2) 工具: label 相似度 & blocks 匹配\n",
    "############################################\n",
    "\n",
    "def label_similarity(a: str, b: str) -> float:\n",
    "    \"\"\" difflib 计算字符串相似度 \"\"\"\n",
    "    return difflib.SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def match_blocks_by_label(blocksA: List[dict], blocksB: List[dict], threshold: float=0.6):\n",
    "    \"\"\"\n",
    "    用 label 相似度做贪心匹配:\n",
    "    - blocksA每个block, 在blocksB里找到相似度最高者,若>threshold,则匹配\n",
    "    - blocksB若被匹配一次后就不可再用\n",
    "    返回:\n",
    "      matched_pairs: List of (idxA, idxB)\n",
    "      matched_count\n",
    "      totalA = len(blocksA)\n",
    "      totalB = len(blocksB)\n",
    "    \"\"\"\n",
    "    matched_pairs = []\n",
    "    usedB = set()\n",
    "\n",
    "    for i, ba in enumerate(blocksA):\n",
    "        best_sim = 0\n",
    "        best_j = -1\n",
    "        for j, bb in enumerate(blocksB):\n",
    "            if j in usedB:\n",
    "                continue\n",
    "            sim = label_similarity(ba.get(\"label\",\"\"), bb.get(\"label\",\"\"))\n",
    "            if sim>best_sim:\n",
    "                best_sim = sim\n",
    "                best_j = j\n",
    "        if best_sim>=threshold and best_j!=-1:\n",
    "            matched_pairs.append( (i,best_j) )\n",
    "            usedB.add(best_j)\n",
    "\n",
    "    return matched_pairs, len(blocksA), len(blocksB)\n",
    "\n",
    "\n",
    "############################################\n",
    "# 3) 在已匹配的blocks对里 对比 edges\n",
    "############################################\n",
    "\n",
    "def collect_edges(blocks: List[dict]) -> List[Tuple[int,int]]:\n",
    "    \"\"\"\n",
    "    收集 edges: (i->j) 其中 i,j 是block的索引\n",
    "    - block i 的 successors 里面若出现 block j, 就 (i->j)\n",
    "    - 但这里 successors 是 block对象(带label等),\n",
    "      我们要知道 j 是 blocks 里的哪一个, 用 label匹配?\n",
    "      => 做一个 label->index(多对多?), 但若 label 不唯一就有歧义.\n",
    "    这里简化: 遍历 i 的 successors, 在 blocks 里做 label相等者.\n",
    "    \"\"\"\n",
    "\n",
    "    edges = []\n",
    "    # 预先把 blocks label -> possible indices\n",
    "    # 如果label不唯一，则是一对多\n",
    "    label_map = {}\n",
    "    for i, b in enumerate(blocks):\n",
    "        lbl = b.get(\"label\",\"\")\n",
    "        label_map.setdefault(lbl, []).append(i)\n",
    "\n",
    "    for i, blockA in enumerate(blocks):\n",
    "        succ_list = blockA.get(\"successors\", [])\n",
    "        # succ_list是一堆block\n",
    "        for sblock in succ_list:\n",
    "            slabel = sblock.get(\"label\",\"\")\n",
    "            # 在 label_map 里找 slabel\n",
    "            if slabel in label_map:\n",
    "                # 可能对应多个candidate, 全都视为后继?\n",
    "                for j in label_map[slabel]:\n",
    "                    edges.append( (i,j) )\n",
    "            else:\n",
    "                # 不匹配任何,忽略\n",
    "                pass\n",
    "\n",
    "    return edges\n",
    "\n",
    "\n",
    "def compare_edges(\n",
    "    blocksA: List[dict], \n",
    "    blocksB: List[dict], \n",
    "    matched_pairs: List[Tuple[int,int]]\n",
    ") -> Dict[str,float]:\n",
    "    \"\"\"\n",
    "    通过 matched_pairs (block i in A -> block j in B),\n",
    "    收集 edgesA, edgesB, 并做映射:\n",
    "      - 在 A: (i->x), 若 i->x & i,x 都匹配到 (j->y)\n",
    "      - 那就构成 (j->y) in B, check if B真有 (j->y).\n",
    "    计算 edge-level precision/recall/f1.\n",
    "    \"\"\"\n",
    "\n",
    "    def safe_div(a,b): return a/b if b else 1\n",
    "\n",
    "    # 先收集 A/B 的 edges( i->x )  / ( j->y ) indices\n",
    "    edgesA = set( collect_edges(blocksA) )  # set of (i,x)\n",
    "    edgesB = set( collect_edges(blocksB) )  # set of (j,y)\n",
    "\n",
    "    # 建立 matched_A->B\n",
    "    mapAtoB = dict(matched_pairs)  # i->j\n",
    "    # 同理, matched_BtoA = dict( (j,i) for i,j in matched_pairs )\n",
    "\n",
    "    # 对于 A 的一条 (i->x), 若 i,x 都在 matched_pairs, -> (j->y)\n",
    "    # 如果 (j->y) in edgesB,则此edge算 matched\n",
    "    matched_edges = 0\n",
    "    for (i,x) in edgesA:\n",
    "        if i in mapAtoB and x in mapAtoB:\n",
    "            j = mapAtoB[i]\n",
    "            y = mapAtoB[x]\n",
    "            if (j,y) in edgesB:\n",
    "                matched_edges+=1\n",
    "\n",
    "    # p/r\n",
    "    # #edges in A = len(edgesA), #edges in B= len(edgesB)\n",
    "    p = safe_div(matched_edges, len(edgesA))\n",
    "    r = safe_div(matched_edges, len(edgesB))\n",
    "    f1 = 2*p*r/(p+r) if (p+r)>0 else 0\n",
    "    return {\n",
    "      \"edge_precision\": p,\n",
    "      \"edge_recall\": r,\n",
    "      \"edge_f1\": f1\n",
    "    }\n",
    "\n",
    "\n",
    "############################################\n",
    "# 4) compare_single_subgraph: blocks + edges\n",
    "############################################\n",
    "\n",
    "def compare_single_subgraph(\n",
    "    subA: dict, \n",
    "    subB: dict, \n",
    "    threshold: float = 0.6\n",
    ") -> Dict[str,float]:\n",
    "    \"\"\"\n",
    "    对同一个 prefix 的子图:\n",
    "      1) match blocks by label\n",
    "      2) compute block-level p/r/f1\n",
    "      3) compute edge-level p/r/f1\n",
    "    返回: { block_precision, block_recall, block_f1, edge_precision, edge_recall, edge_f1}\n",
    "    \"\"\"\n",
    "\n",
    "    blocksA = subA[\"blocks\"]\n",
    "    blocksB = subB[\"blocks\"]\n",
    "\n",
    "    matched_pairs, totalA, totalB = match_blocks_by_label(blocksA, blocksB, threshold)\n",
    "    matched_count = len(matched_pairs)\n",
    "\n",
    "    def safe_div(a,b): return a/b if b else 1.0\n",
    "    block_precision = safe_div(matched_count, totalA)\n",
    "    block_recall = safe_div(matched_count, totalB)\n",
    "    block_f1 = 2*block_precision*block_recall/(block_precision+block_recall) if (block_precision+block_recall)>0 else 0\n",
    "\n",
    "    # edges\n",
    "    edge_result = compare_edges(blocksA, blocksB, matched_pairs)\n",
    "\n",
    "    return {\n",
    "      \"block_precision\": block_precision,\n",
    "      \"block_recall\": block_recall,\n",
    "      \"block_f1\": block_f1,\n",
    "      \"edge_precision\": edge_result[\"edge_precision\"],\n",
    "      \"edge_recall\": edge_result[\"edge_recall\"],\n",
    "      \"edge_f1\": edge_result[\"edge_f1\"],\n",
    "    }\n",
    "\n",
    "\n",
    "############################################\n",
    "# 5) compare_all_subgraphs: 挨个 prefix\n",
    "############################################\n",
    "\n",
    "def compare_all_subgraphs(cfg_llm: dict, cfg_static: dict, threshold: float=0.6) -> Dict[str,Any]:\n",
    "    \"\"\"\n",
    "    1) collect_subgraphs for LLM & static\n",
    "    2) for each prefix in LLM, see if exists in static\n",
    "       - if yes, compare_single_subgraph\n",
    "       - if no, record extra\n",
    "    3) record missing subgraphs\n",
    "    4) average the metrics\n",
    "    \"\"\"\n",
    "\n",
    "    subs_llm = collect_subgraphs(cfg_llm)\n",
    "    subs_stc = collect_subgraphs(cfg_static)\n",
    "\n",
    "    matched_results = []\n",
    "    extra_subgraphs = []\n",
    "    missing_subgraphs = []\n",
    "\n",
    "    for prefix, subA in subs_llm.items():\n",
    "        if prefix in subs_stc:\n",
    "            subB = subs_stc[prefix]\n",
    "            metrics = compare_single_subgraph(subA, subB, threshold=threshold)\n",
    "            matched_results.append( (prefix, metrics) )\n",
    "        else:\n",
    "            extra_subgraphs.append(prefix)\n",
    "\n",
    "    for prefix in subs_stc:\n",
    "        if prefix not in subs_llm:\n",
    "            missing_subgraphs.append(prefix)\n",
    "\n",
    "    # 统计平均\n",
    "    if matched_results:\n",
    "        block_p = sum(x[1][\"block_precision\"] for x in matched_results)/len(matched_results)\n",
    "        block_r = sum(x[1][\"block_recall\"] for x in matched_results)/len(matched_results)\n",
    "        block_f1= sum(x[1][\"block_f1\"] for x in matched_results)/len(matched_results)\n",
    "        edge_p  = sum(x[1][\"edge_precision\"] for x in matched_results)/len(matched_results)\n",
    "        edge_r  = sum(x[1][\"edge_recall\"] for x in matched_results)/len(matched_results)\n",
    "        edge_f1 = sum(x[1][\"edge_f1\"] for x in matched_results)/len(matched_results)\n",
    "    else:\n",
    "        block_p=block_r=block_f1=1\n",
    "        edge_p=edge_r=edge_f1=1\n",
    "\n",
    "    return {\n",
    "      \"matched_subgraphs_count\": len(matched_results),\n",
    "      \"extra_subgraphs_in_llm\": extra_subgraphs,\n",
    "      \"missing_subgraphs_in_static\": missing_subgraphs,\n",
    "\n",
    "      \"avg_block_precision_subgraphs\": block_p,\n",
    "      \"avg_block_recall_subgraphs\": block_r,\n",
    "      \"avg_block_f1_subgraphs\": block_f1,\n",
    "\n",
    "      \"avg_edge_precision_subgraphs\": edge_p,\n",
    "      \"avg_edge_recall_subgraphs\": edge_r,\n",
    "      \"avg_edge_f1_subgraphs\": edge_f1\n",
    "    }\n",
    "\n",
    "\n",
    "############################################\n",
    "# 6) 可选: compare_structure (类/函数命名)\n",
    "############################################\n",
    "\n",
    "def collect_defs(cfg: dict, prefix=\"\") -> (Set[str], Set[str]): # type: ignore\n",
    "    classes = set()\n",
    "    funcs   = set()\n",
    "    # classes\n",
    "    for c in cfg.get(\"classes\",[]):\n",
    "        cname = c.get(\"name\",\"\")\n",
    "        cfull = f\"{prefix}.{cname}\" if prefix else cname\n",
    "        classes.add(cfull)\n",
    "        sc, sf = collect_defs(c, cfull)\n",
    "        classes |= sc\n",
    "        funcs   |= sf\n",
    "    # functions\n",
    "    for f in cfg.get(\"functions\",[]):\n",
    "        fname = f[\"name\"]\n",
    "        ffull = f\"{prefix}.{fname}\" if prefix else fname\n",
    "        funcs.add(ffull)\n",
    "        sc, sf = collect_defs(f, ffull)\n",
    "        classes |= sc\n",
    "        funcs   |= sf\n",
    "    return classes, funcs\n",
    "\n",
    "def compare_structure(cfg_llm: dict, cfg_static: dict) -> Dict[str,float]:\n",
    "    def safe_div(a,b): return a/b if b else 1.0\n",
    "\n",
    "    llmC,llmF = collect_defs(cfg_llm)\n",
    "    stcC,stcF = collect_defs(cfg_static)\n",
    "\n",
    "    matchedC = llmC & stcC\n",
    "    matchedF = llmF & stcF\n",
    "\n",
    "    cp = safe_div(len(matchedC), len(llmC))\n",
    "    cr = safe_div(len(matchedC), len(stcC))\n",
    "    cf1= 2*cp*cr/(cp+cr) if (cp+cr)>0 else 0\n",
    "\n",
    "    fp = safe_div(len(matchedF), len(llmF))\n",
    "    fr = safe_div(len(matchedF), len(stcF))\n",
    "    ff1= 2*fp*fr/(fp+fr) if (fp+fr)>0 else 0\n",
    "\n",
    "    return {\n",
    "      \"class_precision\": cp,\n",
    "      \"class_recall\": cr,\n",
    "      \"class_f1\": cf1,\n",
    "      \"function_precision\": fp,\n",
    "      \"function_recall\": fr,\n",
    "      \"function_f1\": ff1\n",
    "    }\n",
    "\n",
    "\n",
    "############################################\n",
    "# 7) 主 compare_cfgs: 汇总子图 & 结构\n",
    "############################################\n",
    "\n",
    "def compare_cfgs(cfg_llm: dict, cfg_static: dict, threshold: float=0.6) -> Dict[str,Any]:\n",
    "    \"\"\"\n",
    "    1) compare structure (可选)\n",
    "    2) compare_all_subgraphs: blocks + edges\n",
    "    3) combine final\n",
    "    \"\"\"\n",
    "    structure = compare_structure(cfg_llm, cfg_static)\n",
    "\n",
    "    subgraph_metrics = compare_all_subgraphs(cfg_llm, cfg_static, threshold=threshold)\n",
    "\n",
    "    # 一个简单overall:\n",
    "    # structure f1\n",
    "    struct_f1 = (structure[\"class_f1\"] + structure[\"function_f1\"]) / 2\n",
    "    # subgraph block/edge f1\n",
    "    block_f1 = subgraph_metrics[\"avg_block_f1_subgraphs\"]\n",
    "    edge_f1  = subgraph_metrics[\"avg_edge_f1_subgraphs\"]\n",
    "    # overall\n",
    "    overall = (struct_f1 + block_f1 + edge_f1)/3\n",
    "\n",
    "    return {\n",
    "      \"structure_metrics\": structure,\n",
    "      \"subgraph_metrics\": subgraph_metrics,\n",
    "      \"overall_score\": overall\n",
    "    }\n",
    "\n",
    "\n",
    "############################################\n",
    "# 8) main\n",
    "############################################\n",
    "\n",
    "def main():\n",
    "    # 示例: 你可以改成 argparse\n",
    "    total_results = {\n",
    "        \"overall_scores\": [],\n",
    "        \"structure_metrics\": {\n",
    "            \"class_precision\": [],\n",
    "            \"class_recall\": [],\n",
    "            \"class_f1\": [],\n",
    "            \"function_precision\": [],\n",
    "            \"function_recall\": [],\n",
    "            \"function_f1\": []\n",
    "        },\n",
    "        \"block_metrics\": {\n",
    "            \"precision\": [],\n",
    "            \"recall\": [],\n",
    "            \"f1\": []\n",
    "        },\n",
    "        \"edge_metrics\": {\n",
    "            \"precision\": [],\n",
    "            \"recall\": [],\n",
    "            \"f1\": []\n",
    "        },\n",
    "        \"subgraph_stats\": {\n",
    "            \"matched_counts\": [],\n",
    "            \"extra_counts\": [],\n",
    "            \"missing_counts\": []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for i in range(200):\n",
    "        llm_cfg_path = f\"gpt-4o_tree_cfg_output/{i}.json\"\n",
    "        static_cfg_path = f\"static_cfg/{i}.json\"\n",
    "\n",
    "        if not os.path.exists(llm_cfg_path) or not os.path.exists(static_cfg_path):\n",
    "            continue\n",
    "\n",
    "        with open(llm_cfg_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            cfg_llm = json.load(f)\n",
    "        with open(static_cfg_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            cfg_static = json.load(f)\n",
    "\n",
    "        results = compare_cfgs(cfg_llm, cfg_static, threshold=0.6)\n",
    "        \n",
    "        # 收集所有指标\n",
    "        total_results[\"overall_scores\"].append(results[\"overall_score\"])\n",
    "        \n",
    "        # 结构指标\n",
    "        for metric in [\"class_precision\", \"class_recall\", \"class_f1\", \n",
    "                      \"function_precision\", \"function_recall\", \"function_f1\"]:\n",
    "            total_results[\"structure_metrics\"][metric].append(\n",
    "                results[\"structure_metrics\"][metric])\n",
    "        \n",
    "        # 基本块指标\n",
    "        total_results[\"block_metrics\"][\"precision\"].append(\n",
    "            results[\"subgraph_metrics\"][\"avg_block_precision_subgraphs\"])\n",
    "        total_results[\"block_metrics\"][\"recall\"].append(\n",
    "            results[\"subgraph_metrics\"][\"avg_block_recall_subgraphs\"])\n",
    "        total_results[\"block_metrics\"][\"f1\"].append(\n",
    "            results[\"subgraph_metrics\"][\"avg_block_f1_subgraphs\"])\n",
    "            \n",
    "        # 边指标\n",
    "        total_results[\"edge_metrics\"][\"precision\"].append(\n",
    "            results[\"subgraph_metrics\"][\"avg_edge_precision_subgraphs\"])\n",
    "        total_results[\"edge_metrics\"][\"recall\"].append(\n",
    "            results[\"subgraph_metrics\"][\"avg_edge_recall_subgraphs\"])\n",
    "        total_results[\"edge_metrics\"][\"f1\"].append(\n",
    "            results[\"subgraph_metrics\"][\"avg_edge_f1_subgraphs\"])\n",
    "            \n",
    "        # 子图统计\n",
    "        total_results[\"subgraph_stats\"][\"matched_counts\"].append(\n",
    "            results[\"subgraph_metrics\"][\"matched_subgraphs_count\"])\n",
    "        total_results[\"subgraph_stats\"][\"extra_counts\"].append(\n",
    "            len(results[\"subgraph_metrics\"][\"extra_subgraphs_in_llm\"]))\n",
    "        total_results[\"subgraph_stats\"][\"missing_counts\"].append(\n",
    "            len(results[\"subgraph_metrics\"][\"missing_subgraphs_in_static\"]))\n",
    "    \n",
    "    def avg(lst):\n",
    "        return sum(lst)/len(lst) if lst else 0\n",
    "    \n",
    "    # 打印详细的评估结果\n",
    "    print(\"\\n=== 总体评估结果 ===\")\n",
    "    print(f\"平均整体得分: {avg(total_results['overall_scores']):.3f}\")\n",
    "    \n",
    "    print(\"\\n=== 结构评估 ===\")\n",
    "    print(f\"类评估:\")\n",
    "    print(f\"  - Precision: {avg(total_results['structure_metrics']['class_precision']):.3f}\")\n",
    "    print(f\"  - Recall: {avg(total_results['structure_metrics']['class_recall']):.3f}\")\n",
    "    print(f\"  - F1: {avg(total_results['structure_metrics']['class_f1']):.3f}\")\n",
    "    print(f\"函数评估:\")\n",
    "    print(f\"  - Precision: {avg(total_results['structure_metrics']['function_precision']):.3f}\")\n",
    "    print(f\"  - Recall: {avg(total_results['structure_metrics']['function_recall']):.3f}\")\n",
    "    print(f\"  - F1: {avg(total_results['structure_metrics']['function_f1']):.3f}\")\n",
    "    \n",
    "    print(\"\\n=== 基本块评估 ===\")\n",
    "    print(f\"Precision: {avg(total_results['block_metrics']['precision']):.3f}\")\n",
    "    print(f\"Recall: {avg(total_results['block_metrics']['recall']):.3f}\")\n",
    "    print(f\"F1: {avg(total_results['block_metrics']['f1']):.3f}\")\n",
    "    \n",
    "    print(\"\\n=== 边评估 ===\")\n",
    "    print(f\"Precision: {avg(total_results['edge_metrics']['precision']):.3f}\")\n",
    "    print(f\"Recall: {avg(total_results['edge_metrics']['recall']):.3f}\")\n",
    "    print(f\"F1: {avg(total_results['edge_metrics']['f1']):.3f}\")\n",
    "    \n",
    "    print(\"\\n=== 子图统计 ===\")\n",
    "    print(f\"平均匹配子图数: {avg(total_results['subgraph_stats']['matched_counts']):.1f}\")\n",
    "    print(f\"平均额外子图数: {avg(total_results['subgraph_stats']['extra_counts']):.1f}\")\n",
    "    print(f\"平均缺失子图数: {avg(total_results['subgraph_stats']['missing_counts']):.1f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件:  62%|██████▏   | 123/200 [00:12<00:07, 10.18it/s]\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 8 column 1 (char 121)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 129\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 99\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mnum_workers) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     98\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200\u001b[39m)]\n\u001b[0;32m---> 99\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_single_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m处理文件\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     results \u001b[38;5;241m=\u001b[39m [r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# 计算总体分数\u001b[39;00m\n",
      "File \u001b[0;32m/home/miniconda3/envs/llm4cfg/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m/home/miniconda3/envs/llm4cfg/lib/python3.11/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m/home/miniconda3/envs/llm4cfg/lib/python3.11/concurrent/futures/_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/home/miniconda3/envs/llm4cfg/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/home/miniconda3/envs/llm4cfg/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/miniconda3/envs/llm4cfg/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[0;32mIn[1], line 81\u001b[0m, in \u001b[0;36mprocess_single_file\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     77\u001b[0m     cfg_static \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     79\u001b[0m prompt \u001b[38;5;241m=\u001b[39m get_evaluate_prompt(cfg_llm, cfg_static)\n\u001b[0;32m---> 81\u001b[0m llm_answers \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_llm_answers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire_json\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     84\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(llm_answers, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/home/miniconda3/envs/llm4cfg/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/home/miniconda3/envs/llm4cfg/lib/python3.11/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 8 column 1 (char 121)"
     ]
    }
   ],
   "source": [
    "def get_evaluate_prompt(llm_cfg, static_cfg):\n",
    "    prompt = f\"\"\"\n",
    "You are an expert in static analysis of Python code. I will provide you with two JSON representations of Control Flow Graphs (CFGs). One CFG is generated by a language model (LLM-based CFG), and the other CFG is generated by a static analyzer (Static-based CFG). I want you to compare them across multiple dimensions to see how closely they match. Specifically, please analyze:\n",
    "\t1.\tClasses and Functions Structure\n",
    "\t•\tCompare which classes and functions appear in each CFG.\n",
    "\t•\tCheck if they are nested consistently (e.g., whether a function is nested inside the same class in both CFGs).\n",
    "\t•\tPoint out any classes/functions missing or extra in one CFG vs. the other.\n",
    "\t2.\tBlocks\n",
    "\t•\tLook at each block in the CFG, focusing on how these blocks are formed. Compare their labels or relevant content.\n",
    "\t•\tAre the blocks subdivided in the same places (e.g., same if/else boundaries) or does one CFG merge multiple statements into a single block while the other splits them?\n",
    "\t•\tDiscuss any significant differences in how blocks are structured, labeled, or combined.\n",
    "\t3.\tEdges / Successors\n",
    "\t•\tCheck the connections or transitions between blocks (successors).\n",
    "\t•\tIdentify if the same control-flow edges appear in both CFGs. For instance, do they agree on the branching after an if-statement, or do they differ?\n",
    "\t•\tPoint out missing edges or extra edges.\n",
    "\t4.\tAny Additional Observations\n",
    "\t•\tNote any unusual merges/splits of blocks, or differences in how special constructs (try-except, for/while, etc.) are represented.\n",
    "\t•\tIf line numbers exist, mention whether they differ significantly.\n",
    "\t5.\tSummary and Recommendations\n",
    "\t•\tProvide an overall assessment: Are the CFGs mostly matching, or are there major discrepancies?\n",
    "\t•\tSuggest how accurate the LLM-based CFG is relative to the static-based CFG, potentially giving a numerical score or rating if you can.\n",
    "\n",
    "Instructions:\n",
    "\t•\tRead both CFGs carefully.\n",
    "    •\tTreat static CFG as the ground truth.\n",
    "\t•\tSummarize your findings for each dimension in a clear, structured way.\n",
    "\t•\tFinally, give a single consolidated assessment or score about how well the LLM CFG aligns with the static CFG across all these aspects.\n",
    "\n",
    "Output Format:\n",
    "\t•\tYou may respond in plain English, or use a structured JSON (or bullet points) that highlights each dimension's differences, plus an overall conclusion.\n",
    "\t•\tIf needed, give specific examples of discrepancies or matches, referencing the class/function/block labels where appropriate.\n",
    "\n",
    "I will now provide the two CFG JSON objects. Please follow the instructions above to perform a multi-dimensional comparison.\n",
    "\n",
    "static CFG:\n",
    "{static_cfg}\n",
    "\n",
    "LLM CFG:\n",
    "{llm_cfg}\n",
    "\n",
    "Your output should be in JSON format as follows: \"\"\" + \"\"\"\n",
    "{\n",
    "\t\"overall_scores\": number(0-100),\n",
    "    \"structure_similarity\": number(0-1),\n",
    "    \"block_similarity\": number(0-1),\n",
    "    \"edge_similarity\": number(0-1)\n",
    "}\n",
    "\"\"\" \n",
    "    return prompt\n",
    "\n",
    "from llm import get_llm_answers\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from multiprocessing import cpu_count\n",
    "import tqdm\n",
    "\n",
    "def process_single_file(i):\n",
    "    \n",
    "    # 创建输出目录\n",
    "    os.makedirs(\"results/gpt-4o/evaluate\", exist_ok=True)\n",
    "    \n",
    "    # 保存结果到对应文件\n",
    "    output_path = f\"results/gpt-4o/evaluate/{i}.json\"\n",
    "    llm_cfg_path = f\"gpt-4o_tree_cfg_output/{i}.json\"\n",
    "    static_cfg_path = f\"static_cfg/{i}.json\"\n",
    "\n",
    "    if os.path.exists(output_path):\n",
    "        return json.load(open(output_path, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "    if not os.path.exists(llm_cfg_path) or not os.path.exists(static_cfg_path):\n",
    "        return\n",
    "    with open(llm_cfg_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        cfg_llm = json.load(f)\n",
    "    with open(static_cfg_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        cfg_static = json.load(f)\n",
    "\n",
    "    prompt = get_evaluate_prompt(cfg_llm, cfg_static)\n",
    "\n",
    "    try:\n",
    "        llm_answers = json.loads(get_llm_answers(prompt, model_name=\"gpt-4o\", require_json=True))\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"overall_scores\": 0,\n",
    "            \"structure_similarity\": 0,\n",
    "            \"block_similarity\": 0,\n",
    "            \"edge_similarity\": 0\n",
    "        }\n",
    "    \n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(llm_answers, f, indent=2)\n",
    "    \n",
    "    return llm_answers\n",
    "\n",
    "def main():\n",
    "    # 使用ProcessPoolExecutor代替ThreadPoolExecutor以实现真正的并行\n",
    "    from concurrent.futures import ThreadPoolExecutor\n",
    "    import multiprocessing\n",
    "\n",
    "    # 获取CPU核心数\n",
    "    num_workers = multiprocessing.cpu_count()\n",
    "    \n",
    "    # 使用线程池并行处理文件\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        tasks = [i for i in range(200)]\n",
    "        results = list(tqdm.tqdm(\n",
    "            executor.map(process_single_file, tasks),\n",
    "            total=len(tasks),\n",
    "            desc=\"处理文件\"\n",
    "        ))\n",
    "        results = [r for r in results if r is not None]\n",
    "    \n",
    "    # 计算总体分数\n",
    "    total_scores = {\n",
    "        \"overall_scores\": [],\n",
    "        \"structure_similarity\": [],\n",
    "        \"block_similarity\": [], \n",
    "        \"edge_similarity\": []\n",
    "    }\n",
    "    \n",
    "    for result in results:\n",
    "        for key in total_scores:\n",
    "            if key in result:\n",
    "                total_scores[key].append(result[key])\n",
    "    \n",
    "    # 计算平均分数\n",
    "    avg_scores = {\n",
    "        key: np.mean(scores) for key, scores in total_scores.items() if scores\n",
    "    }\n",
    "    \n",
    "    print(\"总体评估分数:\")\n",
    "    for key, score in avg_scores.items():\n",
    "        print(f\"{key}: {score:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm4cfg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
