{"file_name": "0.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 92, "functions": [{"name": "create_test_user", "type": "function", "start_line": 11, "end_line": 18, "functions": [], "classes": [], "simplified_code": "async def create_test_user() -> User:\n    test_user_data = {\n        \"sub\": \"ef3b97d7-1161-4eb4-92b2-10c24fb154c1\",\n        \"email\": \"testuser#example.com\",\n        \"name\": \"Test User\",\n    }\n    user = await get_or_create_user(test_user_data)\n    return user", "blocks": [{"id": 1, "label": "async def create_test_user() -> User:\n    test_user_data = {'sub': 'ef3b97d7-1161-4eb4-92b2-10c24fb154c1', 'email': 'testuser#example.com', 'name': 'Test User'}", "successors": [{"id": 3, "label": "    user = await get_or_create_user(test_user_data)\n    return user", "successors": []}]}]}, {"name": "create_test_graph", "type": "function", "start_line": 21, "end_line": 73, "functions": [], "classes": [], "simplified_code": "def create_test_graph() -> graph.Graph:\n    \"\"\"\n    InputBlock\n               \\\n                 ---- FillTextTemplateBlock ---- PrintToConsoleBlock\n               /\n    InputBlock\n    \"\"\"\n    nodes = [\n        graph.Node(\n            block_id=AgentInputBlock().id,\n            input_default={\"name\": \"input_1\"},\n        ),\n        graph.Node(\n            block_id=AgentInputBlock().id,\n            input_default={\"name\": \"input_2\"},\n        ),\n        graph.Node(\n            block_id=FillTextTemplateBlock().id,\n            input_default={\n                \"format\": \"{a}, {b}{c}\",\n                \"values_#_c\": \"!!!\",\n            },\n        ),\n        graph.Node(block_id=PrintToConsoleBlock().id),\n    ]\n    links = [\n        graph.Link(\n            source_id=nodes[0].id,\n            sink_id=nodes[2].id,\n            source_name=\"result\",\n            sink_name=\"values_#_a\",\n        ),\n        graph.Link(\n            source_id=nodes[1].id,\n            sink_id=nodes[2].id,\n            source_name=\"result\",\n            sink_name=\"values_#_b\",\n        ),\n        graph.Link(\n            source_id=nodes[2].id,\n            sink_id=nodes[3].id,\n            source_name=\"output\",\n            sink_name=\"text\",\n        ),\n    ]\n\n    return graph.Graph(\n        name=\"TestGraph\",\n        description=\"Test graph\",\n        nodes=nodes,\n        links=links,\n    )", "blocks": [{"id": 1, "label": "def create_test_graph() -> graph.Graph:\n    \"\"\"\n    InputBlock\n               \\\n                 ---- FillTextTemplateBlock ---- PrintToConsoleBlock\n               /\n    InputBlock\n    \"\"\"", "successors": [{"id": 3, "label": "    nodes = [\n        graph.Node(\n            block_id=AgentInputBlock().id,\n            input_default={\"name\": \"input_1\"},\n        ),\n        graph.Node(\n            block_id=AgentInputBlock().id,\n            input_default={\"name\": \"input_2\"},\n        ),\n        graph.Node(\n            block_id=FillTextTemplateBlock().id,\n            input_default={\n                \"format\": \"{a}, {b}{c}\",\n                \"values_#_c\": \"!!!\",\n            },\n        ),\n        graph.Node(block_id=PrintToConsoleBlock().id),\n    ]\n    links = [\n        graph.Link(\n            source_id=nodes[0].id,\n            sink_id=nodes[2].id,\n            source_name=\"result\",\n            sink_name=\"values_#_a\",\n        ),\n        graph.Link(\n            source_id=nodes[1].id,\n            sink_id=nodes[2].id,\n            source_name=\"result\",\n            sink_name=\"values_#_b\",\n        ),\n        graph.Link(\n            source_id=nodes[2].id,\n            sink_id=nodes[3].id,\n            source_name=\"output\",\n            sink_name=\"text\",\n        ),\n    ]", "successors": [{"id": 5, "label": "    return graph.Graph(\n        name=\"TestGraph\",\n        description=\"Test graph\",\n        nodes=nodes,\n        links=links,\n    )", "successors": []}]}]}]}, {"name": "sample_agent", "type": "function", "start_line": 76, "end_line": 86, "functions": [], "classes": [], "simplified_code": "async def sample_agent():\n    async with SpinTestServer() as server:\n        test_user = await create_test_user()\n        test_graph = await create_graph(create_test_graph(), test_user.id)\n        input_data = {\"input_1\": \"Hello\", \"input_2\": \"World\"}\n        response = await server.agent_server.test_execute_graph(\n            test_graph.id, input_data, test_user.id\n        )\n        print(response)\n        result = await wait_execution(test_user.id, test_graph.id, response[\"id\"], 10)\n        print(result)", "blocks": [{"id": 1, "label": "async def sample_agent():\nasync with SpinTestServer() as server:", "successors": [{"id": 3, "label": "test_user = await create_test_user()\ntest_graph = await create_graph(create_test_graph(), test_user.id)\ninput_data = {\"input_1\": \"Hello\", \"input_2\": \"World\"}\nresponse = await server.agent_server.test_execute_graph(\n    test_graph.id, input_data, test_user.id\n)\nprint(response)\nresult = await wait_execution(test_user.id, test_graph.id, response[\"id\"], 10)\nprint(result)", "successors": []}]}]}], "classes": [], "simplified_code": "from prisma.models import User\n\nfrom backend.blocks.basic import AgentInputBlock, PrintToConsoleBlock\nfrom backend.blocks.text import FillTextTemplateBlock\nfrom backend.data import graph\nfrom backend.data.graph import create_graph\nfrom backend.data.user import get_or_create_user\nfrom backend.util.test import SpinTestServer, wait_execution\n\n\n    return user\n\n\n    )\n\n\n        print(result)\n\n\nif __name__ == \"__main__\":\n    import asyncio\n\n    asyncio.run(sample_agent())", "blocks": [{"id": 1, "label": "from prisma.models import User\n\nfrom backend.blocks.basic import AgentInputBlock, PrintToConsoleBlock\nfrom backend.blocks.text import FillTextTemplateBlock\nfrom backend.data import graph\nfrom backend.data.graph import create_graph\nfrom backend.data.user import get_or_create_user\nfrom backend.util.test import SpinTestServer, wait_execution", "successors": [{"id": 2, "label": "return user", "successors": []}, {"id": 3, "label": ")", "successors": []}, {"id": 4, "label": "print(result)", "successors": []}, {"id": 5, "label": "if __name__ == \"__main__\":\nimport asyncio", "successors": [{"id": 7, "label": "asyncio.run(sample_agent())", "successors": []}]}]}]}
{"file_name": "1.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 278, "functions": [], "classes": [{"name": "IdeogramModelName", "type": "class", "start_line": 31, "end_line": 35, "functions": [], "simplified_code": "class IdeogramModelName(str, Enum):\n    V2 = \"V_2\"\n    V1 = \"V_1\"\n    V1_TURBO = \"V_1_TURBO\"\n    V2_TURBO = \"V_2_TURBO\"", "blocks": [{"id": 1, "label": "class IdeogramModelName(str, Enum):\n    V2 = \"V_2\"\n    V1 = \"V_1\"\n    V1_TURBO = \"V_1_TURBO\"\n    V2_TURBO = \"V_2_TURBO\"", "successors": []}]}, {"name": "MagicPromptOption", "type": "class", "start_line": 38, "end_line": 41, "functions": [], "simplified_code": "class MagicPromptOption(str, Enum):\n    AUTO = \"AUTO\"\n    ON = \"ON\"\n    OFF = \"OFF\"", "blocks": [{"id": 1, "label": "class MagicPromptOption(str, Enum):", "successors": [{"id": 2, "label": "    AUTO = \"AUTO\"", "successors": []}, {"id": 3, "label": "    ON = \"ON\"", "successors": []}, {"id": 4, "label": "    OFF = \"OFF\"", "successors": []}]}]}, {"name": "StyleType", "type": "class", "start_line": 44, "end_line": 50, "functions": [], "simplified_code": "class StyleType(str, Enum):\n    AUTO = \"AUTO\"\n    GENERAL = \"GENERAL\"\n    REALISTIC = \"REALISTIC\"\n    DESIGN = \"DESIGN\"\n    RENDER_3D = \"RENDER_3D\"\n    ANIME = \"ANIME\"", "blocks": [{"id": 1, "label": "class StyleType(str, Enum):", "successors": [{"id": 2, "label": "    AUTO = \"AUTO\"", "successors": []}, {"id": 3, "label": "    GENERAL = \"GENERAL\"", "successors": []}, {"id": 4, "label": "    REALISTIC = \"REALISTIC\"", "successors": []}, {"id": 5, "label": "    DESIGN = \"DESIGN\"", "successors": []}, {"id": 6, "label": "    RENDER_3D = \"RENDER_3D\"", "successors": []}, {"id": 7, "label": "    ANIME = \"ANIME\"", "successors": []}]}]}, {"name": "ColorPalettePreset", "type": "class", "start_line": 53, "end_line": 62, "functions": [], "simplified_code": "class ColorPalettePreset(str, Enum):\n    NONE = \"NONE\"\n    EMBER = \"EMBER\"\n    FRESH = \"FRESH\"\n    JUNGLE = \"JUNGLE\"\n    MAGIC = \"MAGIC\"\n    MELON = \"MELON\"\n    MOSAIC = \"MOSAIC\"\n    PASTEL = \"PASTEL\"\n    ULTRAMARINE = \"ULTRAMARINE\"", "blocks": [{"id": 1, "label": "class ColorPalettePreset(str, Enum):\n    NONE = \"NONE\"\n    EMBER = \"EMBER\"\n    FRESH = \"FRESH\"\n    JUNGLE = \"JUNGLE\"\n    MAGIC = \"MAGIC\"\n    MELON = \"MELON\"\n    MOSAIC = \"MOSAIC\"\n    PASTEL = \"PASTEL\"\n    ULTRAMARINE = \"ULTRAMARINE\"", "successors": []}]}, {"name": "AspectRatio", "type": "class", "start_line": 65, "end_line": 76, "functions": [], "simplified_code": "class AspectRatio(str, Enum):\n    ASPECT_10_16 = \"ASPECT_10_16\"\n    ASPECT_16_10 = \"ASPECT_16_10\"\n    ASPECT_9_16 = \"ASPECT_9_16\"\n    ASPECT_16_9 = \"ASPECT_16_9\"\n    ASPECT_3_2 = \"ASPECT_3_2\"\n    ASPECT_2_3 = \"ASPECT_2_3\"\n    ASPECT_4_3 = \"ASPECT_4_3\"\n    ASPECT_3_4 = \"ASPECT_3_4\"\n    ASPECT_1_1 = \"ASPECT_1_1\"\n    ASPECT_1_3 = \"ASPECT_1_3\"\n    ASPECT_3_1 = \"ASPECT_3_1\"", "blocks": [{"id": 1, "label": "class AspectRatio(str, Enum):\n    ASPECT_10_16 = \"ASPECT_10_16\"\n    ASPECT_16_10 = \"ASPECT_16_10\"\n    ASPECT_9_16 = \"ASPECT_9_16\"\n    ASPECT_16_9 = \"ASPECT_16_9\"\n    ASPECT_3_2 = \"ASPECT_3_2\"\n    ASPECT_2_3 = \"ASPECT_2_3\"\n    ASPECT_4_3 = \"ASPECT_4_3\"\n    ASPECT_3_4 = \"ASPECT_3_4\"\n    ASPECT_1_1 = \"ASPECT_1_1\"\n    ASPECT_1_3 = \"ASPECT_1_3\"\n    ASPECT_3_1 = \"ASPECT_3_1\"", "successors": []}]}, {"name": "UpscaleOption", "type": "class", "start_line": 79, "end_line": 81, "functions": [], "simplified_code": "class UpscaleOption(str, Enum):\n    AI_UPSCALE = \"AI Upscale\"\n    NO_UPSCALE = \"No Upscale\"", "blocks": [{"id": 1, "label": "class UpscaleOption(str, Enum):\n    AI_UPSCALE = \"AI Upscale\"\n    NO_UPSCALE = \"No Upscale\"", "successors": []}]}, {"name": "IdeogramModelBlock", "type": "class", "start_line": 84, "end_line": 278, "functions": [{"name": "__init__", "type": "function", "start_line": 149, "end_line": 179, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"6ab085e2-20b3-4055-bc3e-08036e01eca6\",\n            description=\"This block runs Ideogram models with both simple and advanced settings.\",\n            categories={BlockCategory.AI},\n            input_schema=IdeogramModelBlock.Input,\n            output_schema=IdeogramModelBlock.Output,\n            test_input={\n                \"ideogram_model_name\": IdeogramModelName.V2,\n                \"prompt\": \"A futuristic cityscape at sunset\",\n                \"aspect_ratio\": AspectRatio.ASPECT_1_1,\n                \"upscale\": UpscaleOption.NO_UPSCALE,\n                \"magic_prompt_option\": MagicPromptOption.AUTO,\n                \"seed\": None,\n                \"style_type\": StyleType.AUTO,\n                \"negative_prompt\": None,\n                \"color_palette_name\": ColorPalettePreset.NONE,\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_output=[\n                (\n                    \"result\",\n                    \"https://ideogram.ai/api/images/test-generated-image-url.png\",\n                ),\n            ],\n            test_mock={\n                \"run_model\": lambda api_key, model_name, prompt, seed, aspect_ratio, magic_prompt_option, style_type, negative_prompt, color_palette_name: \"https://ideogram.ai/api/images/test-generated-image-url.png\",\n                \"upscale_image\": lambda api_key, image_url: \"https://ideogram.ai/api/images/test-upscaled-image-url.png\",\n            },\n            test_credentials=TEST_CREDENTIALS,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"6ab085e2-20b3-4055-bc3e-08036e01eca6\",\n    description=\"This block runs Ideogram models with both simple and advanced settings.\",\n    categories={BlockCategory.AI},\n    input_schema=IdeogramModelBlock.Input,\n    output_schema=IdeogramModelBlock.Output,\n    test_input={\n        \"ideogram_model_name\": IdeogramModelName.V2,\n        \"prompt\": \"A futuristic cityscape at sunset\",\n        \"aspect_ratio\": AspectRatio.ASPECT_1_1,\n        \"upscale\": UpscaleOption.NO_UPSCALE,\n        \"magic_prompt_option\": MagicPromptOption.AUTO,\n        \"seed\": None,\n        \"style_type\": StyleType.AUTO,\n        \"negative_prompt\": None,\n        \"color_palette_name\": ColorPalettePreset.NONE,\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_output=[\n        (\n            \"result\",\n            \"https://ideogram.ai/api/images/test-generated-image-url.png\",\n        ),\n    ],\n    test_mock={\n        \"run_model\": lambda api_key, model_name, prompt, seed, aspect_ratio, magic_prompt_option, style_type, negative_prompt, color_palette_name: \"https://ideogram.ai/api/images/test-generated-image-url.png\",\n        \"upscale_image\": lambda api_key, image_url: \"https://ideogram.ai/api/images/test-upscaled-image-url.png\",\n    },\n    test_credentials=TEST_CREDENTIALS,\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 181, "end_line": 206, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        seed = input_data.seed\n\n        # Step 1: Generate the image\n        result = self.run_model(\n            api_key=credentials.api_key,\n            model_name=input_data.ideogram_model_name.value,\n            prompt=input_data.prompt,\n            seed=seed,\n            aspect_ratio=input_data.aspect_ratio.value,\n            magic_prompt_option=input_data.magic_prompt_option.value,\n            style_type=input_data.style_type.value,\n            negative_prompt=input_data.negative_prompt,\n            color_palette_name=input_data.color_palette_name.value,\n        )\n\n        # Step 2: Upscale the image if requested\n        if input_data.upscale == UpscaleOption.AI_UPSCALE:\n            result = self.upscale_image(\n                api_key=credentials.api_key,\n                image_url=result,\n            )\n\n        yield \"result\", result", "blocks": [{"id": 1, "label": "def run( self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs ) -> BlockOutput:\n    seed = input_data.seed\n\n    # Step 1: Generate the image\n    result = self.run_model(\n        api_key=credentials.api_key,\n        model_name=input_data.ideogram_model_name.value,\n        prompt=input_data.prompt,\n        seed=seed,\n        aspect_ratio=input_data.aspect_ratio.value,\n        magic_prompt_option=input_data.magic_prompt_option.value,\n        style_type=input_data.style_type.value,\n        negative_prompt=input_data.negative_prompt,\n        color_palette_name=input_data.color_palette_name.value,\n    )", "successors": [{"id": 2, "label": "if input_data.upscale == UpscaleOption.AI_UPSCALE:\n    result = self.upscale_image(\n        api_key=credentials.api_key,\n        image_url=result,\n    )", "successors": [{"id": 4, "label": "yield \"result\", result", "successors": []}]}, {"id": 4, "label": "yield \"result\", result", "successors": []}]}]}, {"name": "run_model", "type": "function", "start_line": 208, "end_line": 249, "functions": [], "classes": [], "simplified_code": "    def run_model(\n        self,\n        api_key: SecretStr,\n        model_name: str,\n        prompt: str,\n        seed: Optional[int],\n        aspect_ratio: str,\n        magic_prompt_option: str,\n        style_type: str,\n        negative_prompt: Optional[str],\n        color_palette_name: str,\n    ):\n        url = \"https://api.ideogram.ai/generate\"\n        headers = {\n            \"Api-Key\": api_key.get_secret_value(),\n            \"Content-Type\": \"application/json\",\n        }\n\n        data: Dict[str, Any] = {\n            \"image_request\": {\n                \"prompt\": prompt,\n                \"model\": model_name,\n                \"aspect_ratio\": aspect_ratio,\n                \"magic_prompt_option\": magic_prompt_option,\n                \"style_type\": style_type,\n            }\n        }\n\n        if seed is not None:\n            data[\"image_request\"][\"seed\"] = seed\n\n        if negative_prompt:\n            data[\"image_request\"][\"negative_prompt\"] = negative_prompt\n\n        if color_palette_name != \"NONE\":\n            data[\"image_request\"][\"color_palette\"] = {\"name\": color_palette_name}\n\n        try:\n            response = requests.post(url, json=data, headers=headers)\n            return response.json()[\"data\"][0][\"url\"]\n        except RequestException as e:\n            raise Exception(f\"Failed to fetch image: {str(e)}\")", "blocks": [{"id": 1, "label": "url = \"https://api.ideogram.ai/generate\"\nheaders = {\n    \"Api-Key\": api_key.get_secret_value(),\n    \"Content-Type\": \"application/json\",\n}\n\ndata: Dict[str, Any] = {\n    \"image_request\": {\n        \"prompt\": prompt,\n        \"model\": model_name,\n        \"aspect_ratio\": aspect_ratio,\n        \"magic_prompt_option\": magic_prompt_option,\n        \"style_type\": style_type,\n    }\n}", "successors": [{"id": 2, "label": "if seed is not None:", "successors": [{"id": 3, "label": "    data[\"image_request\"][\"seed\"] = seed\nif negative_prompt:", "successors": [{"id": 6, "label": "    data[\"image_request\"][\"negative_prompt\"] = negative_prompt\nif color_palette_name != \"NONE\":", "successors": [{"id": 9, "label": "    data[\"image_request\"][\"color_palette\"] = {\"name\": color_palette_name}\ntry:", "successors": [{"id": 12, "label": "    response = requests.post(url, json=data, headers=headers)\n    return response.json()[\"data\"][0][\"url\"]", "successors": []}, {"id": 13, "label": "except RequestException as e:\n    raise Exception(f\"Failed to fetch image: {str(e)}\")", "successors": []}]}, {"id": 11, "label": "try:", "successors": [{"id": 12, "label": "    response = requests.post(url, json=data, headers=headers)\n    return response.json()[\"data\"][0][\"url\"]", "successors": []}, {"id": 13, "label": "except RequestException as e:\n    raise Exception(f\"Failed to fetch image: {str(e)}\")", "successors": []}]}]}, {"id": 8, "label": "if color_palette_name != \"NONE\":", "successors": [{"id": 9, "label": "    data[\"image_request\"][\"color_palette\"] = {\"name\": color_palette_name}\ntry:", "successors": [{"id": 12, "label": "    response = requests.post(url, json=data, headers=headers)\n    return response.json()[\"data\"][0][\"url\"]", "successors": []}, {"id": 13, "label": "except RequestException as e:\n    raise Exception(f\"Failed to fetch image: {str(e)}\")", "successors": []}]}, {"id": 11, "label": "try:", "successors": [{"id": 12, "label": "    response = requests.post(url, json=data, headers=headers)\n    return response.json()[\"data\"][0][\"url\"]", "successors": []}, {"id": 13, "label": "except RequestException as e:\n    raise Exception(f\"Failed to fetch image: {str(e)}\")", "successors": []}]}]}]}, {"id": 5, "label": "if negative_prompt:", "successors": [{"id": 6, "label": "    data[\"image_request\"][\"negative_prompt\"] = negative_prompt\nif color_palette_name != \"NONE\":", "successors": [{"id": 9, "label": "    data[\"image_request\"][\"color_palette\"] = {\"name\": color_palette_name}\ntry:", "successors": [{"id": 12, "label": "    response = requests.post(url, json=data, headers=headers)\n    return response.json()[\"data\"][0][\"url\"]", "successors": []}, {"id": 13, "label": "except RequestException as e:\n    raise Exception(f\"Failed to fetch image: {str(e)}\")", "successors": []}]}, {"id": 11, "label": "try:", "successors": [{"id": 12, "label": "    response = requests.post(url, json=data, headers=headers)\n    return response.json()[\"data\"][0][\"url\"]", "successors": []}, {"id": 13, "label": "except RequestException as e:\n    raise Exception(f\"Failed to fetch image: {str(e)}\")", "successors": []}]}]}, {"id": 8, "label": "if color_palette_name != \"NONE\":", "successors": [{"id": 9, "label": "    data[\"image_request\"][\"color_palette\"] = {\"name\": color_palette_name}\ntry:", "successors": [{"id": 12, "label": "    response = requests.post(url, json=data, headers=headers)\n    return response.json()[\"data\"][0][\"url\"]", "successors": []}, {"id": 13, "label": "except RequestException as e:\n    raise Exception(f\"Failed to fetch image: {str(e)}\")", "successors": []}]}, {"id": 11, "label": "try:", "successors": [{"id": 12, "label": "    response = requests.post(url, json=data, headers=headers)\n    return response.json()[\"data\"][0][\"url\"]", "successors": []}, {"id": 13, "label": "except RequestException as e:\n    raise Exception(f\"Failed to fetch image: {str(e)}\")", "successors": []}]}]}]}]}, {"id": 5, "label": "if negative_prompt:", "successors": [{"id": 6, "label": "    data[\"image_request\"][\"negative_prompt\"] = negative_prompt\nif color_palette_name != \"NONE\":", "successors": [{"id": 9, "label": "    data[\"image_request\"][\"color_palette\"] = {\"name\": color_palette_name}\ntry:", "successors": [{"id": 12, "label": "    response = requests.post(url, json=data, headers=headers)\n    return response.json()[\"data\"][0][\"url\"]", "successors": []}, {"id": 13, "label": "except RequestException as e:\n    raise Exception(f\"Failed to fetch image: {str(e)}\")", "successors": []}]}, {"id": 11, "label": "try:", "successors": [{"id": 12, "label": "    response = requests.post(url, json=data, headers=headers)\n    return response.json()[\"data\"][0][\"url\"]", "successors": []}, {"id": 13, "label": "except RequestException as e:\n    raise Exception(f\"Failed to fetch image: {str(e)}\")", "successors": []}]}]}, {"id": 8, "label": "if color_palette_name != \"NONE\":", "successors": [{"id": 9, "label": "    data[\"image_request\"][\"color_palette\"] = {\"name\": color_palette_name}\ntry:", "successors": [{"id": 12, "label": "    response = requests.post(url, json=data, headers=headers)\n    return response.json()[\"data\"][0][\"url\"]", "successors": []}, {"id": 13, "label": "except RequestException as e:\n    raise Exception(f\"Failed to fetch image: {str(e)}\")", "successors": []}]}, {"id": 11, "label": "try:", "successors": [{"id": 12, "label": "    response = requests.post(url, json=data, headers=headers)\n    return response.json()[\"data\"][0][\"url\"]", "successors": []}, {"id": 13, "label": "except RequestException as e:\n    raise Exception(f\"Failed to fetch image: {str(e)}\")", "successors": []}]}]}]}, {"id": 8, "label": "if color_palette_name != \"NONE\":", "successors": [{"id": 9, "label": "    data[\"image_request\"][\"color_palette\"] = {\"name\": color_palette_name}\ntry:", "successors": [{"id": 12, "label": "    response = requests.post(url, json=data, headers=headers)\n    return response.json()[\"data\"][0][\"url\"]", "successors": []}, {"id": 13, "label": "except RequestException as e:\n    raise Exception(f\"Failed to fetch image: {str(e)}\")", "successors": []}]}, {"id": 11, "label": "try:", "successors": [{"id": 12, "label": "    response = requests.post(url, json=data, headers=headers)\n    return response.json()[\"data\"][0][\"url\"]", "successors": []}, {"id": 13, "label": "except RequestException as e:\n    raise Exception(f\"Failed to fetch image: {str(e)}\")", "successors": []}]}]}, {"id": 11, "label": "try:", "successors": [{"id": 12, "label": "    response = requests.post(url, json=data, headers=headers)\n    return response.json()[\"data\"][0][\"url\"]", "successors": []}, {"id": 13, "label": "except RequestException as e:\n    raise Exception(f\"Failed to fetch image: {str(e)}\")", "successors": []}]}]}]}, {"name": "upscale_image", "type": "function", "start_line": 251, "end_line": 278, "functions": [], "classes": [], "simplified_code": "    def upscale_image(self, api_key: SecretStr, image_url: str):\n        url = \"https://api.ideogram.ai/upscale\"\n        headers = {\n            \"Api-Key\": api_key.get_secret_value(),\n        }\n\n        try:\n            # Step 1: Download the image from the provided URL\n            image_response = requests.get(image_url)\n\n            # Step 2: Send the downloaded image to the upscale API\n            files = {\n                \"image_file\": (\"image.png\", image_response.content, \"image/png\"),\n            }\n\n            response = requests.post(\n                url,\n                headers=headers,\n                data={\n                    \"image_request\": \"{}\",  # Empty JSON object\n                },\n                files=files,\n            )\n\n            return response.json()[\"data\"][0][\"url\"]\n\n        except RequestException as e:\n            raise Exception(f\"Failed to upscale image: {str(e)}\")", "blocks": [{"id": 1, "label": "url = \"https://api.ideogram.ai/upscale\"\nheaders = {\n    \"Api-Key\": api_key.get_secret_value(),\n}\ntry:", "successors": [{"id": 3, "label": "# Step 1: Download the image from the provided URL\nimage_response = requests.get(image_url)\n# Step 2: Send the downloaded image to the upscale API\nfiles = {\n    \"image_file\": (\"image.png\", image_response.content, \"image/png\"),\n}\n\nresponse = requests.post(\n    url,\n    headers=headers,\n    data={\n        \"image_request\": \"{}\",  # Empty JSON object\n    },\n    files=files,\n)", "successors": [{"id": 5, "label": "return response.json()[\"data\"][0][\"url\"]", "successors": []}]}, {"id": 6, "label": "except RequestException as e:\nraise Exception(f\"Failed to upscale image: {str(e)}\")", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 85, "end_line": 143, "functions": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: CredentialsMetaInput[\n            Literal[ProviderName.IDEOGRAM], Literal[\"api_key\"]\n        ] = CredentialsField(\n            description=\"The Ideogram integration can be used with any API key with sufficient permissions for the blocks it is used on.\",\n        )\n        prompt: str = SchemaField(\n            description=\"Text prompt for image generation\",\n            placeholder=\"e.g., 'A futuristic cityscape at sunset'\",\n            title=\"Prompt\",\n        )\n        ideogram_model_name: IdeogramModelName = SchemaField(\n            description=\"The name of the Image Generation Model, e.g., V_2\",\n            default=IdeogramModelName.V2,\n            title=\"Image Generation Model\",\n            advanced=False,\n        )\n        aspect_ratio: AspectRatio = SchemaField(\n            description=\"Aspect ratio for the generated image\",\n            default=AspectRatio.ASPECT_1_1,\n            title=\"Aspect Ratio\",\n            advanced=False,\n        )\n        upscale: UpscaleOption = SchemaField(\n            description=\"Upscale the generated image\",\n            default=UpscaleOption.NO_UPSCALE,\n            title=\"Upscale Image\",\n            advanced=False,\n        )\n        magic_prompt_option: MagicPromptOption = SchemaField(\n            description=\"Whether to use MagicPrompt for enhancing the request\",\n            default=MagicPromptOption.AUTO,\n            title=\"Magic Prompt Option\",\n            advanced=True,\n        )\n        seed: Optional[int] = SchemaField(\n            description=\"Random seed. Set for reproducible generation\",\n            default=None,\n            title=\"Seed\",\n            advanced=True,\n        )\n        style_type: StyleType = SchemaField(\n            description=\"Style type to apply, applicable for V_2 and above\",\n            default=StyleType.AUTO,\n            title=\"Style Type\",\n            advanced=True,\n        )\n        negative_prompt: Optional[str] = SchemaField(\n            description=\"Description of what to exclude from the image\",\n            default=None,\n            title=\"Negative Prompt\",\n            advanced=True,\n        )\n        color_palette_name: ColorPalettePreset = SchemaField(\n            description=\"Color palette preset name, choose 'None' to skip\",\n            default=ColorPalettePreset.NONE,\n            title=\"Color Palette Preset\",\n            advanced=True,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: CredentialsMetaInput[\n        Literal[ProviderName.IDEOGRAM], Literal[\"api_key\"]\n    ] = CredentialsField(\n        description=\"The Ideogram integration can be used with any API key with sufficient permissions for the blocks it is used on.\",\n    )", "successors": [{"id": 3, "label": "    prompt: str = SchemaField(\n        description=\"Text prompt for image generation\",\n        placeholder=\"e.g., 'A futuristic cityscape at sunset'\",\n        title=\"Prompt\",\n    )\n    ideogram_model_name: IdeogramModelName = SchemaField(\n        description=\"The name of the Image Generation Model, e.g., V_2\",\n        default=IdeogramModelName.V2,\n        title=\"Image Generation Model\",\n        advanced=False,\n    )", "successors": [{"id": 5, "label": "    aspect_ratio: AspectRatio = SchemaField(\n        description=\"Aspect ratio for the generated image\",\n        default=AspectRatio.ASPECT_1_1,\n        title=\"Aspect Ratio\",\n        advanced=False,\n    )\n    upscale: UpscaleOption = SchemaField(\n        description=\"Upscale the generated image\",\n        default=UpscaleOption.NO_UPSCALE,\n        title=\"Upscale Image\",\n        advanced=False,\n    )", "successors": [{"id": 7, "label": "    magic_prompt_option: MagicPromptOption = SchemaField(\n        description=\"Whether to use MagicPrompt for enhancing the request\",\n        default=MagicPromptOption.AUTO,\n        title=\"Magic Prompt Option\",\n        advanced=True,\n    )\n    seed: Optional[int] = SchemaField(\n        description=\"Random seed. Set for reproducible generation\",\n        default=None,\n        title=\"Seed\",\n        advanced=True,\n    )", "successors": [{"id": 9, "label": "    style_type: StyleType = SchemaField(\n        description=\"Style type to apply, applicable for V_2 and above\",\n        default=StyleType.AUTO,\n        title=\"Style Type\",\n        advanced=True,\n    )\n    negative_prompt: Optional[str] = SchemaField(\n        description=\"Description of what to exclude from the image\",\n        default=None,\n        title=\"Negative Prompt\",\n        advanced=True,\n    )", "successors": [{"id": 11, "label": "    color_palette_name: ColorPalettePreset = SchemaField(\n        description=\"Color palette preset name, choose 'None' to skip\",\n        default=ColorPalettePreset.NONE,\n        title=\"Color Palette Preset\",\n        advanced=True,\n    )", "successors": []}]}]}]}]}]}]}, {"name": "Output", "type": "class", "start_line": 145, "end_line": 147, "functions": [], "simplified_code": "    class Output(BlockSchema):\n        result: str = SchemaField(description=\"Generated image URL\")\n        error: str = SchemaField(description=\"Error message if the model run failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "    result: str = SchemaField(description=\"Generated image URL\")", "successors": []}, {"id": 3, "label": "    error: str = SchemaField(description=\"Error message if the model run failed\")", "successors": []}]}]}], "simplified_code": "class IdeogramModelBlock(Block):\n        )\n\n        error: str = SchemaField(description=\"Error message if the model run failed\")\n\n        )\n\n        yield \"result\", result\n\n            raise Exception(f\"Failed to fetch image: {str(e)}\")\n\n            raise Exception(f\"Failed to upscale image: {str(e)}\")", "blocks": [{"id": 1, "label": "class IdeogramModelBlock(Block):\nerror: str = SchemaField(description=\"Error message if the model run failed\")", "successors": [{"id": 3, "label": "yield \"result\", result", "successors": []}, {"id": 4, "label": "raise Exception(f\"Failed to fetch image: {str(e)}\")", "successors": []}, {"id": 5, "label": "raise Exception(f\"Failed to upscale image: {str(e)}\")", "successors": []}]}]}], "simplified_code": "from enum import Enum\nfrom typing import Any, Dict, Literal, Optional\n\nfrom pydantic import SecretStr\nfrom requests.exceptions import RequestException\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\nfrom backend.util.request import requests\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"ideogram\",\n    api_key=SecretStr(\"mock-ideogram-api-key\"),\n    title=\"Mock Ideogram API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.type,\n}\n\n    V2_TURBO = \"V_2_TURBO\"\n\n\n    OFF = \"OFF\"\n\n\n    ANIME = \"ANIME\"\n\n\n    ULTRAMARINE = \"ULTRAMARINE\"\n\n\n    ASPECT_3_1 = \"ASPECT_3_1\"\n\n\n    NO_UPSCALE = \"No Upscale\"\n\n\n            raise Exception(f\"Failed to upscale image: {str(e)}\")", "blocks": []}
{"file_name": "2.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 43, "functions": [], "classes": [{"name": "JinaEmbeddingBlock", "type": "class", "start_line": 11, "end_line": 43, "functions": [{"name": "__init__", "type": "function", "start_line": 23, "end_line": 30, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"7c56b3ab-62e7-43a2-a2dc-4ec4245660b6\",\n            description=\"Generates embeddings using Jina AI\",\n            categories={BlockCategory.AI},\n            input_schema=JinaEmbeddingBlock.Input,\n            output_schema=JinaEmbeddingBlock.Output,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(id=\"7c56b3ab-62e7-43a2-a2dc-4ec4245660b6\", description=\"Generates embeddings using Jina AI\", categories={BlockCategory.AI}, input_schema=JinaEmbeddingBlock.Input, output_schema=JinaEmbeddingBlock.Output, )", "successors": []}]}, {"name": "run", "type": "function", "start_line": 32, "end_line": 43, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: JinaCredentials, **kwargs\n    ) -> BlockOutput:\n        url = \"https://api.jina.ai/v1/embeddings\"\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {credentials.api_key.get_secret_value()}\",\n        }\n        data = {\"input\": input_data.texts, \"model\": input_data.model}\n        response = requests.post(url, headers=headers, json=data)\n        embeddings = [e[\"embedding\"] for e in response.json()[\"data\"]]\n        yield \"embeddings\", embeddings", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: JinaCredentials, **kwargs) -> BlockOutput:\nurl = \"https://api.jina.ai/v1/embeddings\"\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": f\"Bearer {credentials.api_key.get_secret_value()}\",\n}\ndata = {\"input\": input_data.texts, \"model\": input_data.model}\nresponse = requests.post(url, headers=headers, json=data)\nembeddings = [e[\"embedding\"] for e in response.json()[\"data\"]]\nyield \"embeddings\", embeddings", "successors": []}]}], "classes": [{"name": "Input", "type": "class", "start_line": 12, "end_line": 18, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        texts: list = SchemaField(description=\"List of texts to embed\")\n        credentials: JinaCredentialsInput = JinaCredentialsField()\n        model: str = SchemaField(\n            description=\"Jina embedding model to use\",\n            default=\"jina-embeddings-v2-base-en\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "texts: list = SchemaField(description=\"List of texts to embed\")", "successors": []}, {"id": 3, "label": "credentials: JinaCredentialsInput = JinaCredentialsField()", "successors": []}, {"id": 4, "label": "model: str = SchemaField(\n description=\"Jina embedding model to use\",\n default=\"jina-embeddings-v2-base-en\",\n )", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 20, "end_line": 21, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        embeddings: list = SchemaField(description=\"List of embeddings\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    embeddings: list = SchemaField(description=\"List of embeddings\")", "successors": []}]}], "simplified_code": "class JinaEmbeddingBlock(Block):\n        )\n\n        embeddings: list = SchemaField(description=\"List of embeddings\")\n\n        )\n\n        yield \"embeddings\", embeddings", "blocks": [{"id": 1, "label": "class JinaEmbeddingBlock(Block):\nembeddings: list = SchemaField(description=\"List of embeddings\")", "successors": [{"id": 3, "label": "yield \"embeddings\", embeddings", "successors": []}]}]}], "simplified_code": "from backend.blocks.jina._auth import (\n    JinaCredentials,\n    JinaCredentialsField,\n    JinaCredentialsInput,\n)\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\nfrom backend.util.request import requests\n\n\n        yield \"embeddings\", embeddings", "blocks": [{"id": 1, "label": "from backend.blocks.jina._auth import ( JinaCredentials, JinaCredentialsField, JinaCredentialsInput, )\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema", "successors": [{"id": 3, "label": "from backend.data.model import SchemaField\nfrom backend.util.request import requests", "successors": [{"id": 5, "label": "yield \"embeddings\", embeddings", "successors": []}]}]}]}
{"file_name": "3.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 264, "functions": [], "classes": [], "simplified_code": "from typing import Type\n\nfrom backend.blocks.ai_music_generator import AIMusicGeneratorBlock\nfrom backend.blocks.ai_shortform_video_block import AIShortformVideoCreatorBlock\nfrom backend.blocks.ideogram import IdeogramModelBlock\nfrom backend.blocks.jina.embeddings import JinaEmbeddingBlock\nfrom backend.blocks.jina.search import ExtractWebsiteContentBlock, SearchTheWebBlock\nfrom backend.blocks.llm import (\n    MODEL_METADATA,\n    AIConversationBlock,\n    AIListGeneratorBlock,\n    AIStructuredResponseGeneratorBlock,\n    AITextGeneratorBlock,\n    AITextSummarizerBlock,\n    LlmModel,\n)\nfrom backend.blocks.replicate_flux_advanced import ReplicateFluxAdvancedModelBlock\nfrom backend.blocks.talking_head import CreateTalkingAvatarVideoBlock\nfrom backend.blocks.text_to_speech_block import UnrealTextToSpeechBlock\nfrom backend.data.block import Block\nfrom backend.data.cost import BlockCost, BlockCostType\nfrom backend.integrations.credentials_store import (\n    anthropic_credentials,\n    did_credentials,\n    groq_credentials,\n    ideogram_credentials,\n    jina_credentials,\n    open_router_credentials,\n    openai_credentials,\n    replicate_credentials,\n    revid_credentials,\n    unreal_credentials,\n)\n\n# =============== Configure the cost for each LLM Model call =============== #\n\nMODEL_COST: dict[LlmModel, int] = {\n    LlmModel.O1_PREVIEW: 16,\n    LlmModel.O1_MINI: 4,\n    LlmModel.GPT4O_MINI: 1,\n    LlmModel.GPT4O: 3,\n    LlmModel.GPT4_TURBO: 10,\n    LlmModel.GPT3_5_TURBO: 1,\n    LlmModel.CLAUDE_3_5_SONNET: 4,\n    LlmModel.CLAUDE_3_HAIKU: 1,\n    LlmModel.LLAMA3_8B: 1,\n    LlmModel.LLAMA3_70B: 1,\n    LlmModel.MIXTRAL_8X7B: 1,\n    LlmModel.GEMMA_7B: 1,\n    LlmModel.GEMMA2_9B: 1,\n    LlmModel.LLAMA3_1_405B: 1,\n    LlmModel.LLAMA3_1_70B: 1,\n    LlmModel.LLAMA3_1_8B: 1,\n    LlmModel.OLLAMA_LLAMA3_8B: 1,\n    LlmModel.OLLAMA_LLAMA3_405B: 1,\n    LlmModel.OLLAMA_DOLPHIN: 1,\n    LlmModel.GEMINI_FLASH_1_5_8B: 1,\n    LlmModel.GROK_BETA: 5,\n    LlmModel.MISTRAL_NEMO: 1,\n    LlmModel.COHERE_COMMAND_R_08_2024: 1,\n    LlmModel.COHERE_COMMAND_R_PLUS_08_2024: 3,\n    LlmModel.EVA_QWEN_2_5_32B: 1,\n    LlmModel.DEEPSEEK_CHAT: 2,\n    LlmModel.PERPLEXITY_LLAMA_3_1_SONAR_LARGE_128K_ONLINE: 1,\n    LlmModel.QWEN_QWQ_32B_PREVIEW: 2,\n    LlmModel.NOUSRESEARCH_HERMES_3_LLAMA_3_1_405B: 1,\n    LlmModel.NOUSRESEARCH_HERMES_3_LLAMA_3_1_70B: 1,\n    LlmModel.AMAZON_NOVA_LITE_V1: 1,\n    LlmModel.AMAZON_NOVA_MICRO_V1: 1,\n    LlmModel.AMAZON_NOVA_PRO_V1: 1,\n    LlmModel.MICROSOFT_WIZARDLM_2_8X22B: 1,\n    LlmModel.GRYPHE_MYTHOMAX_L2_13B: 1,\n}\n\nfor model in LlmModel:\n    if model not in MODEL_COST:\n        raise ValueError(f\"Missing MODEL_COST for model: {model}\")\n\n\nLLM_COST = (\n    # Anthropic Models\n    [\n        BlockCost(\n            cost_type=BlockCostType.RUN,\n            cost_filter={\n                \"model\": model,\n                \"credentials\": {\n                    \"id\": anthropic_credentials.id,\n                    \"provider\": anthropic_credentials.provider,\n                    \"type\": anthropic_credentials.type,\n                },\n            },\n            cost_amount=cost,\n        )\n        for model, cost in MODEL_COST.items()\n        if MODEL_METADATA[model].provider == \"anthropic\"\n    ]\n    # OpenAI Models\n    + [\n        BlockCost(\n            cost_type=BlockCostType.RUN,\n            cost_filter={\n                \"model\": model,\n                \"credentials\": {\n                    \"id\": openai_credentials.id,\n                    \"provider\": openai_credentials.provider,\n                    \"type\": openai_credentials.type,\n                },\n            },\n            cost_amount=cost,\n        )\n        for model, cost in MODEL_COST.items()\n        if MODEL_METADATA[model].provider == \"openai\"\n    ]\n    # Groq Models\n    + [\n        BlockCost(\n            cost_type=BlockCostType.RUN,\n            cost_filter={\n                \"model\": model,\n                \"credentials\": {\"id\": groq_credentials.id},\n            },\n            cost_amount=cost,\n        )\n        for model, cost in MODEL_COST.items()\n        if MODEL_METADATA[model].provider == \"groq\"\n    ]\n    # Open Router Models\n    + [\n        BlockCost(\n            cost_type=BlockCostType.RUN,\n            cost_filter={\n                \"model\": model,\n                \"credentials\": {\n                    \"id\": open_router_credentials.id,\n                    \"provider\": open_router_credentials.provider,\n                    \"type\": open_router_credentials.type,\n                },\n            },\n            cost_amount=cost,\n        )\n        for model, cost in MODEL_COST.items()\n        if MODEL_METADATA[model].provider == \"open_router\"\n    ]\n)\n\n# =============== This is the exhaustive list of cost for each Block =============== #\n\nBLOCK_COSTS: dict[Type[Block], list[BlockCost]] = {\n    AIConversationBlock: LLM_COST,\n    AITextGeneratorBlock: LLM_COST,\n    AIStructuredResponseGeneratorBlock: LLM_COST,\n    AITextSummarizerBlock: LLM_COST,\n    AIListGeneratorBlock: LLM_COST,\n    CreateTalkingAvatarVideoBlock: [\n        BlockCost(\n            cost_amount=15,\n            cost_filter={\n                \"credentials\": {\n                    \"id\": did_credentials.id,\n                    \"provider\": did_credentials.provider,\n                    \"type\": did_credentials.type,\n                }\n            },\n        )\n    ],\n    SearchTheWebBlock: [\n        BlockCost(\n            cost_amount=1,\n            cost_filter={\n                \"credentials\": {\n                    \"id\": jina_credentials.id,\n                    \"provider\": jina_credentials.provider,\n                    \"type\": jina_credentials.type,\n                }\n            },\n        )\n    ],\n    ExtractWebsiteContentBlock: [\n        BlockCost(\n            cost_amount=1,\n            cost_filter={\n                \"raw_content\": False,\n                \"credentials\": {\n                    \"id\": jina_credentials.id,\n                    \"provider\": jina_credentials.provider,\n                    \"type\": jina_credentials.type,\n                },\n            },\n        )\n    ],\n    IdeogramModelBlock: [\n        BlockCost(\n            cost_amount=16,\n            cost_filter={\n                \"credentials\": {\n                    \"id\": ideogram_credentials.id,\n                    \"provider\": ideogram_credentials.provider,\n                    \"type\": ideogram_credentials.type,\n                }\n            },\n        )\n    ],\n    AIShortformVideoCreatorBlock: [\n        BlockCost(\n            cost_amount=50,\n            cost_filter={\n                \"credentials\": {\n                    \"id\": revid_credentials.id,\n                    \"provider\": revid_credentials.provider,\n                    \"type\": revid_credentials.type,\n                }\n            },\n        )\n    ],\n    ReplicateFluxAdvancedModelBlock: [\n        BlockCost(\n            cost_amount=10,\n            cost_filter={\n                \"credentials\": {\n                    \"id\": replicate_credentials.id,\n                    \"provider\": replicate_credentials.provider,\n                    \"type\": replicate_credentials.type,\n                }\n            },\n        )\n    ],\n    AIMusicGeneratorBlock: [\n        BlockCost(\n            cost_amount=11,\n            cost_filter={\n                \"credentials\": {\n                    \"id\": replicate_credentials.id,\n                    \"provider\": replicate_credentials.provider,\n                    \"type\": replicate_credentials.type,\n                }\n            },\n        )\n    ],\n    JinaEmbeddingBlock: [\n        BlockCost(\n            cost_amount=12,\n            cost_filter={\n                \"credentials\": {\n                    \"id\": jina_credentials.id,\n                    \"provider\": jina_credentials.provider,\n                    \"type\": jina_credentials.type,\n                }\n            },\n        )\n    ],\n    UnrealTextToSpeechBlock: [\n        BlockCost(\n            cost_amount=5,\n            cost_filter={\n                \"credentials\": {\n                    \"id\": unreal_credentials.id,\n                    \"provider\": unreal_credentials.provider,\n                    \"type\": unreal_credentials.type,\n                }\n            },\n        )\n    ],\n}", "blocks": [{"id": 1, "label": "from typing import Type\n\nfrom backend.blocks.ai_music_generator import AIMusicGeneratorBlock\nfrom backend.blocks.ai_shortform_video_block import AIShortformVideoCreatorBlock\nfrom backend.blocks.ideogram import IdeogramModelBlock\nfrom backend.blocks.jina.embeddings import JinaEmbeddingBlock\nfrom backend.blocks.jina.search import ExtractWebsiteContentBlock, SearchTheWebBlock\nfrom backend.blocks.llm import (\n    MODEL_METADATA,\n    AIConversationBlock,\n    AIListGeneratorBlock,\n    AIStructuredResponseGeneratorBlock,\n    AITextGeneratorBlock,\n    AITextSummarizerBlock,\n    LlmModel,\n)\nfrom backend.blocks.replicate_flux_advanced import ReplicateFluxAdvancedModelBlock\nfrom backend.blocks.talking_head import CreateTalkingAvatarVideoBlock\nfrom backend.blocks.text_to_speech_block import UnrealTextToSpeechBlock\nfrom backend.data.block import Block\nfrom backend.data.cost import BlockCost, BlockCostType\nfrom backend.integrations.credentials_store import (\n    anthropic_credentials,\n    did_credentials,\n    groq_credentials,\n    ideogram_credentials,\n    jina_credentials,\n    open_router_credentials,\n    openai_credentials,\n    replicate_credentials,\n    revid_credentials,\n    unreal_credentials,\n)\n\n# =============== Configure the cost for each LLM Model call =============== #\n\nMODEL_COST: dict[LlmModel, int] = {\n    LlmModel.O1_PREVIEW: 16,\n    LlmModel.O1_MINI: 4,\n    LlmModel.GPT4O_MINI: 1,\n    LlmModel.GPT4O: 3,\n    LlmModel.GPT4_TURBO: 10,\n    LlmModel.GPT3_5_TURBO: 1,\n    LlmModel.CLAUDE_3_5_SONNET: 4,\n    LlmModel.CLAUDE_3_HAIKU: 1,\n    LlmModel.LLAMA3_8B: 1,\n    LlmModel.LLAMA3_70B: 1,\n    LlmModel.MIXTRAL_8X7B: 1,\n    LlmModel.GEMMA_7B: 1,\n    LlmModel.GEMMA2_9B: 1,\n    LlmModel.LLAMA3_1_405B: 1,\n    LlmModel.LLAMA3_1_70B: 1,\n    LlmModel.LLAMA3_1_8B: 1,\n    LlmModel.OLLAMA_LLAMA3_8B: 1,\n    LlmModel.OLLAMA_LLAMA3_405B: 1,\n    LlmModel.OLLAMA_DOLPHIN: 1,\n    LlmModel.GEMINI_FLASH_1_5_8B: 1,\n    LlmModel.GROK_BETA: 5,\n    LlmModel.MISTRAL_NEMO: 1,\n    LlmModel.COHERE_COMMAND_R_08_2024: 1,\n    LlmModel.COHERE_COMMAND_R_PLUS_08_2024: 3,\n    LlmModel.EVA_QWEN_2_5_32B: 1,\n    LlmModel.DEEPSEEK_CHAT: 2,\n    LlmModel.PERPLEXITY_LLAMA_3_1_SONAR_LARGE_128K_ONLINE: 1,\n    LlmModel.QWEN_QWQ_32B_PREVIEW: 2,\n    LlmModel.NOUSRESEARCH_HERMES_3_LLAMA_3_1_405B: 1,\n    LlmModel.NOUSRESEARCH_HERMES_3_LLAMA_3_1_70B: 1,\n    LlmModel.AMAZON_NOVA_LITE_V1: 1,\n    LlmModel.AMAZON_NOVA_MICRO_V1: 1,\n    LlmModel.AMAZON_NOVA_PRO_V1: 1,\n    LlmModel.MICROSOFT_WIZARDLM_2_8X22B: 1,\n    LlmModel.GRYPHE_MYTHOMAX_L2_13B: 1,\n}", "successors": [{"id": 2, "label": "for model in LlmModel:\n    if model not in MODEL_COST:\n        raise ValueError(f\"Missing MODEL_COST for model: {model}\")", "successors": []}, {"id": 3, "label": "LLM_COST = (\n    # Anthropic Models\n    [\n        BlockCost(\n            cost_type=BlockCostType.RUN,\n            cost_filter={\n                \"model\": model,\n                \"credentials\": {\n                    \"id\": anthropic_credentials.id,\n                    \"provider\": anthropic_credentials.provider,\n                    \"type\": anthropic_credentials.type,\n                },\n            },\n            cost_amount=cost,\n        )\n        for model, cost in MODEL_COST.items()\n        if MODEL_METADATA[model].provider == \"anthropic\"\n    ]\n    # OpenAI Models\n    + [\n        BlockCost(\n            cost_type=BlockCostType.RUN,\n            cost_filter={\n                \"model\": model,\n                \"credentials\": {\n                    \"id\": openai_credentials.id,\n                    \"provider\": openai_credentials.provider,\n                    \"type\": openai_credentials.type,\n                },\n            },\n            cost_amount=cost,\n        )\n        for model, cost in MODEL_COST.items()\n        if MODEL_METADATA[model].provider == \"openai\"\n    ]\n    # Groq Models\n    + [\n        BlockCost(\n            cost_type=BlockCostType.RUN,\n            cost_filter={\n                \"model\": model,\n                \"credentials\": {\"id\": groq_credentials.id},\n            },\n            cost_amount=cost,\n        )\n        for model, cost in MODEL_COST.items()\n        if MODEL_METADATA[model].provider == \"groq\"\n    ]\n    # Open Router Models\n    + [\n        BlockCost(\n            cost_type=BlockCostType.RUN,\n            cost_filter={\n                \"model\": model,\n                \"credentials\": {\n                    \"id\": open_router_credentials.id,\n                    \"provider\": open_router_credentials.provider,\n                    \"type\": open_router_credentials.type,\n                },\n            },\n            cost_amount=cost,\n        )\n        for model, cost in MODEL_COST.items()\n        if MODEL_METADATA[model].provider == \"open_router\"\n    ]\n)\n# =============== This is the exhaustive list of cost for each Block =============== #\n\nBLOCK_COSTS: dict[Type[Block], list[BlockCost]] = {\n    AIConversationBlock: LLM_COST,\n    AITextGeneratorBlock: LLM_COST,\n    AIStructuredResponseGeneratorBlock: LLM_COST,\n    AITextSummarizerBlock: LLM_COST,\n    AIListGeneratorBlock: LLM_COST,\n    CreateTalkingAvatarVideoBlock: [\n        BlockCost(\n            cost_amount=15,\n            cost_filter={\n                \"credentials\": {\n                    \"id\": did_credentials.id,\n                    \"provider\": did_credentials.provider,\n                    \"type\": did_credentials.type,\n                }\n            },\n        )\n    ],\n    SearchTheWebBlock: [\n        BlockCost(\n            cost_amount=1,\n            cost_filter={\n                \"credentials\": {\n                    \"id\": jina_credentials.id,\n                    \"provider\": jina_credentials.provider,\n                    \"type\": jina_credentials.type,\n                }\n            },\n        )\n    ],\n    ExtractWebsiteContentBlock: [\n        BlockCost(\n            cost_amount=1,\n            cost_filter={\n                \"raw_content\": False,\n                \"credentials\": {\n                    \"id\": jina_credentials.id,\n                    \"provider\": jina_credentials.provider,\n                    \"type\": jina_credentials.type,\n                },\n            },\n        )\n    ],\n    IdeogramModelBlock: [\n        BlockCost(\n            cost_amount=16,\n            cost_filter={\n                \"credentials\": {\n                    \"id\": ideogram_credentials.id,\n                    \"provider\": ideogram_credentials.provider,\n                    \"type\": ideogram_credentials.type,\n                }\n            },\n        )\n    ],\n    AIShortformVideoCreatorBlock: [\n        BlockCost(\n            cost_amount=50,\n            cost_filter={\n                \"credentials\": {\n                    \"id\": revid_credentials.id,\n                    \"provider\": revid_credentials.provider,\n                    \"type\": revid_credentials.type,\n                }\n            },\n        )\n    ],\n    ReplicateFluxAdvancedModelBlock: [\n        BlockCost(\n            cost_amount=10,\n            cost_filter={\n                \"credentials\": {\n                    \"id\": replicate_credentials.id,\n                    \"provider\": replicate_credentials.provider,\n                    \"type\": replicate_credentials.type,\n                }\n            },\n        )\n    ],\n    AIMusicGeneratorBlock: [\n        BlockCost(\n            cost_amount=11,\n            cost_filter={\n                \"credentials\": {\n                    \"id\": replicate_credentials.id,\n                    \"provider\": replicate_credentials.provider,\n                    \"type\": replicate_credentials.type,\n                }\n            },\n        )\n    ],\n    JinaEmbeddingBlock: [\n        BlockCost(\n            cost_amount=12,\n            cost_filter={\n                \"credentials\": {\n                    \"id\": jina_credentials.id,\n                    \"provider\": jina_credentials.provider,\n                    \"type\": jina_credentials.type,\n                }\n            },\n        )\n    ],\n    UnrealTextToSpeechBlock: [\n        BlockCost(\n            cost_amount=5,\n            cost_filter={\n                \"credentials\": {\n                    \"id\": unreal_credentials.id,\n                    \"provider\": unreal_credentials.provider,\n                    \"type\": unreal_credentials.type,\n                }\n            },\n        )\n    ],\n}", "successors": []}]}]}
{"file_name": "4.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 960, "functions": [{"name": "execute_node", "type": "function", "start_line": 102, "end_line": 245, "functions": [{"name": "update_execution", "type": "function", "start_line": 127, "end_line": 130, "functions": [], "classes": [], "simplified_code": "    def update_execution(status: ExecutionStatus) -> ExecutionResult:\n        exec_update = db_client.update_execution_status(node_exec_id, status)\n        db_client.send_execution_update(exec_update)\n        return exec_update", "blocks": [{"id": 1, "label": "def update_execution(status: ExecutionStatus) -> ExecutionResult:\n    exec_update = db_client.update_execution_status(node_exec_id, status)\n    db_client.send_execution_update(exec_update)", "successors": [{"id": 3, "label": "    return exec_update", "successors": []}]}]}], "classes": [], "simplified_code": "def execute_node(\n    db_client: \"DatabaseManager\",\n    creds_manager: IntegrationCredentialsManager,\n    data: NodeExecutionEntry,\n    execution_stats: dict[str, Any] | None = None,\n) -> ExecutionStream:\n    \"\"\"\n    Execute a node in the graph. This will trigger a block execution on a node,\n    persist the execution result, and return the subsequent node to be executed.\n\n    Args:\n        db_client: The client to send execution updates to the server.\n        creds_manager: The manager to acquire and release credentials.\n        data: The execution data for executing the current node.\n        execution_stats: The execution statistics to be updated.\n\n    Returns:\n        The subsequent node to be enqueued, or None if there is no subsequent node.\n    \"\"\"\n    user_id = data.user_id\n    graph_exec_id = data.graph_exec_id\n    graph_id = data.graph_id\n    node_exec_id = data.node_exec_id\n    node_id = data.node_id\n\n        return exec_update\n\n    node = db_client.get_node(node_id)\n\n    node_block = get_block(node.block_id)\n    if not node_block:\n        logger.error(f\"Block {node.block_id} not found.\")\n        return\n\n    log_metadata = LogMetadata(\n        user_id=user_id,\n        graph_eid=graph_exec_id,\n        graph_id=graph_id,\n        node_eid=node_exec_id,\n        node_id=node_id,\n        block_name=node_block.name,\n    )\n\n    # Sanity check: validate the execution input.\n    input_data, error = validate_exec(node, data.data, resolve_input=False)\n    if input_data is None:\n        log_metadata.error(f\"Skip execution, input validation error: {error}\")\n        db_client.upsert_execution_output(node_exec_id, \"error\", error)\n        update_execution(ExecutionStatus.FAILED)\n        return\n\n    # Re-shape the input data for agent block.\n    # AgentExecutorBlock specially separate the node input_data & its input_default.\n    if isinstance(node_block, AgentExecutorBlock):\n        input_data = {**node.input_default, \"data\": input_data}\n\n    # Execute the node\n    input_data_str = json.dumps(input_data)\n    input_size = len(input_data_str)\n    log_metadata.info(\"Executed node with input\", input=input_data_str)\n    update_execution(ExecutionStatus.RUNNING)\n\n    extra_exec_kwargs = {}\n    # Last-minute fetch credentials + acquire a system-wide read-write lock to prevent\n    # changes during execution. \u26a0\ufe0f This means a set of credentials can only be used by\n    # one (running) block at a time; simultaneous execution of blocks using same\n    # credentials is not supported.\n    creds_lock = None\n    if CREDENTIALS_FIELD_NAME in input_data:\n        credentials_meta = CredentialsMetaInput(**input_data[CREDENTIALS_FIELD_NAME])\n        credentials, creds_lock = creds_manager.acquire(user_id, credentials_meta.id)\n        extra_exec_kwargs[\"credentials\"] = credentials\n\n    output_size = 0\n    end_status = ExecutionStatus.COMPLETED\n    credit = db_client.get_or_refill_credit(user_id)\n    if credit < 0:\n        raise ValueError(f\"Insufficient credit: {credit}\")\n\n    try:\n        for output_name, output_data in node_block.execute(\n            input_data, **extra_exec_kwargs\n        ):\n            output_size += len(json.dumps(output_data))\n            log_metadata.info(\"Node produced output\", **{output_name: output_data})\n            db_client.upsert_execution_output(node_exec_id, output_name, output_data)\n\n            for execution in _enqueue_next_nodes(\n                db_client=db_client,\n                node=node,\n                output=(output_name, output_data),\n                user_id=user_id,\n                graph_exec_id=graph_exec_id,\n                graph_id=graph_id,\n                log_metadata=log_metadata,\n            ):\n                yield execution\n\n    except Exception as e:\n        end_status = ExecutionStatus.FAILED\n        error_msg = str(e)\n        log_metadata.exception(f\"Node execution failed with error {error_msg}\")\n        db_client.upsert_execution_output(node_exec_id, \"error\", error_msg)\n\n        for execution in _enqueue_next_nodes(\n            db_client=db_client,\n            node=node,\n            output=(\"error\", error_msg),\n            user_id=user_id,\n            graph_exec_id=graph_exec_id,\n            graph_id=graph_id,\n            log_metadata=log_metadata,\n        ):\n            yield execution\n\n        raise e\n    finally:\n        # Ensure credentials are released even if execution fails\n        if creds_lock:\n            try:\n                creds_lock.release()\n            except Exception as e:\n                log_metadata.error(f\"Failed to release credentials lock: {e}\")\n\n        # Update execution status and spend credits\n        res = update_execution(end_status)\n        if end_status == ExecutionStatus.COMPLETED:\n            s = input_size + output_size\n            t = (\n                (res.end_time - res.start_time).total_seconds()\n                if res.end_time and res.start_time\n                else 0\n            )\n            db_client.spend_credits(user_id, credit, node_block.id, input_data, s, t)\n\n        # Update execution stats\n        if execution_stats is not None:\n            execution_stats.update(node_block.execution_stats)\n            execution_stats[\"input_size\"] = input_size\n            execution_stats[\"output_size\"] = output_size\n", "blocks": [{"id": 1, "label": "def execute_node(\n    db_client: \"DatabaseManager\",\n    creds_manager: IntegrationCredentialsManager,\n    data: NodeExecutionEntry,\n    execution_stats: dict[str, Any] | None = None,\n) -> ExecutionStream:\n    user_id = data.user_id\n    graph_exec_id = data.graph_exec_id\n    graph_id = data.graph_id\n    node_exec_id = data.node_exec_id\n    node_id = data.node_id", "successors": [{"id": 3, "label": "    node = db_client.get_node(node_id)\n    node_block = get_block(node.block_id)\n    if not node_block:", "successors": [{"id": 5, "label": "        logger.error(f\"Block {node.block_id} not found.\")\n        return", "successors": []}, {"id": 6, "label": "    log_metadata = LogMetadata(\n        user_id=user_id,\n        graph_eid=graph_exec_id,\n        graph_id=graph_id,\n        node_eid=node_exec_id,\n        node_id=node_id,\n        block_name=node_block.name,\n    )\n    input_data, error = validate_exec(node, data.data, resolve_input=False)\n    if input_data is None:", "successors": [{"id": 8, "label": "        log_metadata.error(f\"Skip execution, input validation error: {error}\")\n        db_client.upsert_execution_output(node_exec_id, \"error\", error)\n        update_execution(ExecutionStatus.FAILED)\n        return", "successors": []}, {"id": 9, "label": "    if isinstance(node_block, AgentExecutorBlock):\n        input_data = {**node.input_default, \"data\": input_data}\n    input_data_str = json.dumps(input_data)\n    input_size = len(input_data_str)\n    log_metadata.info(\"Executed node with input\", input=input_data_str)\n    update_execution(ExecutionStatus.RUNNING)", "successors": [{"id": 11, "label": "    extra_exec_kwargs = {}\n    creds_lock = None\n    if CREDENTIALS_FIELD_NAME in input_data:", "successors": [{"id": 12, "label": "        credentials_meta = CredentialsMetaInput(**input_data[CREDENTIALS_FIELD_NAME])\n        credentials, creds_lock = creds_manager.acquire(user_id, credentials_meta.id)\n        extra_exec_kwargs[\"credentials\"] = credentials", "successors": []}, {"id": 13, "label": "    output_size = 0\n    end_status = ExecutionStatus.COMPLETED\n    credit = db_client.get_or_refill_credit(user_id)\n    if credit < 0:", "successors": [{"id": 14, "label": "        raise ValueError(f\"Insufficient credit: {credit}\")", "successors": []}, {"id": 15, "label": "    try:", "successors": [{"id": 16, "label": "        for output_name, output_data in node_block.execute(\n            input_data, **extra_exec_kwargs\n        ):", "successors": [{"id": 17, "label": "            output_size += len(json.dumps(output_data))\n            log_metadata.info(\"Node produced output\", **{output_name: output_data})\n            db_client.upsert_execution_output(node_exec_id, output_name, output_data)\n\n            for execution in _enqueue_next_nodes(\n                db_client=db_client,\n                node=node,\n                output=(output_name, output_data),\n                user_id=user_id,\n                graph_exec_id=graph_exec_id,\n                graph_id=graph_id,\n                log_metadata=log_metadata,\n            ):\n                yield execution", "successors": []}]}, {"id": 18, "label": "    except Exception as e:\n        end_status = ExecutionStatus.FAILED\n        error_msg = str(e)\n        log_metadata.exception(f\"Node execution failed with error {error_msg}\")\n        db_client.upsert_execution_output(node_exec_id, \"error\", error_msg)\n\n        for execution in _enqueue_next_nodes(\n            db_client=db_client,\n            node=node,\n            output=(\"error\", error_msg),\n            user_id=user_id,\n            graph_exec_id=graph_exec_id,\n            graph_id=graph_id,\n            log_metadata=log_metadata,\n        ):\n            yield execution\n\n        raise e", "successors": []}, {"id": 20, "label": "    finally:\n        if creds_lock:", "successors": [{"id": 22, "label": "            try:\n                creds_lock.release()\n            except Exception as e:\n                log_metadata.error(f\"Failed to release credentials lock: {e}\")", "successors": []}, {"id": 23, "label": "        res = update_execution(end_status)\n        if end_status == ExecutionStatus.COMPLETED:\n            s = input_size + output_size\n            t = (\n                (res.end_time - res.start_time).total_seconds()\n                if res.end_time and res.start_time\n                else 0\n            )\n            db_client.spend_credits(user_id, credit, node_block.id, input_data, s, t)", "successors": []}, {"id": 25, "label": "        if execution_stats is not None:\n            execution_stats.update(node_block.execution_stats)\n            execution_stats[\"input_size\"] = input_size\n            execution_stats[\"output_size\"] = output_size", "successors": []}]}]}]}]}]}]}]}]}]}, {"name": "_enqueue_next_nodes", "type": "function", "start_line": 247, "end_line": 360, "functions": [{"name": "add_enqueued_execution", "type": "function", "start_line": 256, "end_line": 270, "functions": [], "classes": [], "simplified_code": "    def add_enqueued_execution(\n        node_exec_id: str, node_id: str, data: BlockInput\n    ) -> NodeExecutionEntry:\n        exec_update = db_client.update_execution_status(\n            node_exec_id, ExecutionStatus.QUEUED, data\n        )\n        db_client.send_execution_update(exec_update)\n        return NodeExecutionEntry(\n            user_id=user_id,\n            graph_exec_id=graph_exec_id,\n            graph_id=graph_id,\n            node_exec_id=node_exec_id,\n            node_id=node_id,\n            data=data,\n        )", "blocks": [{"id": 1, "label": "def add_enqueued_execution(\n    node_exec_id: str, node_id: str, data: BlockInput\n) -> NodeExecutionEntry:\n    exec_update = db_client.update_execution_status(\n        node_exec_id, ExecutionStatus.QUEUED, data\n    )", "successors": [{"id": 3, "label": "    db_client.send_execution_update(exec_update)\n    return NodeExecutionEntry(\n        user_id=user_id,\n        graph_exec_id=graph_exec_id,\n        graph_id=graph_id,\n        node_exec_id=node_exec_id,\n        node_id=node_id,\n        data=data,\n    )", "successors": []}]}]}, {"name": "register_next_executions", "type": "function", "start_line": 272, "end_line": 354, "functions": [], "classes": [], "simplified_code": "    def register_next_executions(node_link: Link) -> list[NodeExecutionEntry]:\n        enqueued_executions = []\n        next_output_name = node_link.source_name\n        next_input_name = node_link.sink_name\n        next_node_id = node_link.sink_id\n\n        next_data = parse_execution_output(output, next_output_name)\n        if next_data is None:\n            return enqueued_executions\n\n        next_node = db_client.get_node(next_node_id)\n\n        # Multiple node can register the same next node, we need this to be atomic\n        # To avoid same execution to be enqueued multiple times,\n        # Or the same input to be consumed multiple times.\n        with synchronized(f\"upsert_input-{next_node_id}-{graph_exec_id}\"):\n            # Add output data to the earliest incomplete execution, or create a new one.\n            next_node_exec_id, next_node_input = db_client.upsert_execution_input(\n                node_id=next_node_id,\n                graph_exec_id=graph_exec_id,\n                input_name=next_input_name,\n                input_data=next_data,\n            )\n\n            # Complete missing static input pins data using the last execution input.\n            static_link_names = {\n                link.sink_name\n                for link in next_node.input_links\n                if link.is_static and link.sink_name not in next_node_input\n            }\n            if static_link_names and (\n                latest_execution := db_client.get_latest_execution(\n                    next_node_id, graph_exec_id\n                )\n            ):\n                for name in static_link_names:\n                    next_node_input[name] = latest_execution.input_data.get(name)\n\n            # Validate the input data for the next node.\n            next_node_input, validation_msg = validate_exec(next_node, next_node_input)\n            suffix = f\"{next_output_name}>{next_input_name}~{next_node_exec_id}:{validation_msg}\"\n\n            # Incomplete input data, skip queueing the execution.\n            if not next_node_input:\n                log_metadata.warning(f\"Skipped queueing {suffix}\")\n                return enqueued_executions\n\n            # Input is complete, enqueue the execution.\n            log_metadata.info(f\"Enqueued {suffix}\")\n            enqueued_executions.append(\n                add_enqueued_execution(next_node_exec_id, next_node_id, next_node_input)\n            )\n\n            # Next execution stops here if the link is not static.\n            if not node_link.is_static:\n                return enqueued_executions\n\n            # If link is static, there could be some incomplete executions waiting for it.\n            # Load and complete the input missing input data, and try to re-enqueue them.\n            for iexec in db_client.get_incomplete_executions(\n                next_node_id, graph_exec_id\n            ):\n                idata = iexec.input_data\n                ineid = iexec.node_exec_id\n\n                static_link_names = {\n                    link.sink_name\n                    for link in next_node.input_links\n                    if link.is_static and link.sink_name not in idata\n                }\n                for input_name in static_link_names:\n                    idata[input_name] = next_node_input[input_name]\n\n                idata, msg = validate_exec(next_node, idata)\n                suffix = f\"{next_output_name}>{next_input_name}~{ineid}:{msg}\"\n                if not idata:\n                    log_metadata.info(f\"Enqueueing static-link skipped: {suffix}\")\n                    continue\n                log_metadata.info(f\"Enqueueing static-link execution {suffix}\")\n                enqueued_executions.append(\n                    add_enqueued_execution(iexec.node_exec_id, next_node_id, idata)\n                )\n            return enqueued_executions", "blocks": [{"id": 1, "label": "def register_next_executions(node_link: Link) -> list[NodeExecutionEntry]:\n    enqueued_executions = []\n    next_output_name = node_link.source_name\n    next_input_name = node_link.sink_name\n    next_node_id = node_link.sink_id\n\n    next_data = parse_execution_output(output, next_output_name)\nif next_data is None:", "successors": [{"id": 3, "label": "    return enqueued_executions", "successors": []}, {"id": 4, "label": "next_node = db_client.get_node(next_node_id)\n\n# Multiple node can register the same next node, we need this to be atomic\n# To avoid same execution to be enqueued multiple times,\n# Or the same input to be consumed multiple times.\nwith synchronized(f\"upsert_input-{next_node_id}-{graph_exec_id}\"):\n    # Add output data to the earliest incomplete execution, or create a new one.\n    next_node_exec_id, next_node_input = db_client.upsert_execution_input(\n        node_id=next_node_id,\n        graph_exec_id=graph_exec_id,\n        input_name=next_input_name,\n        input_data=next_data,\n    )", "successors": [{"id": 5, "label": "static_link_names = {\n    link.sink_name\n    for link in next_node.input_links\n    if link.is_static and link.sink_name not in next_node_input\n}\nif static_link_names and (\n    latest_execution := db_client.get_latest_execution(\n        next_node_id, graph_exec_id\n    )\n):", "successors": [{"id": 6, "label": "    for name in static_link_names:\n        next_node_input[name] = latest_execution.input_data.get(name)", "successors": []}]}, {"id": 7, "label": "next_node_input, validation_msg = validate_exec(next_node, next_node_input)\nsuffix = f\"{next_output_name}>{next_input_name}~{next_node_exec_id}:{validation_msg}\"\n\n# Incomplete input data, skip queueing the execution.\nif not next_node_input:\n    log_metadata.warning(f\"Skipped queueing {suffix}\")\n    return enqueued_executions\nlog_metadata.info(f\"Enqueued {suffix}\")\nenqueued_executions.append(\n    add_enqueued_execution(next_node_exec_id, next_node_id, next_node_input)\n)\n\n# Next execution stops here if the link is not static.\nif not node_link.is_static:\n    return enqueued_executions", "successors": [{"id": 9, "label": "for iexec in db_client.get_incomplete_executions(\n    next_node_id, graph_exec_id\n):\n    idata = iexec.input_data\n    ineid = iexec.node_exec_id\n\n    static_link_names = {\n        link.sink_name\n        for link in next_node.input_links\n        if link.is_static and link.sink_name not in idata\n    }\n    for input_name in static_link_names:\n        idata[input_name] = next_node_input[input_name]\n\n    idata, msg = validate_exec(next_node, idata)\n    suffix = f\"{next_output_name}>{next_input_name}~{ineid}:{msg}\"\n    if not idata:\n        log_metadata.info(f\"Enqueueing static-link skipped: {suffix}\")\n        continue\n    log_metadata.info(f\"Enqueueing static-link execution {suffix}\")\n    enqueued_executions.append(\n        add_enqueued_execution(iexec.node_exec_id, next_node_id, idata)\n    )", "successors": []}]}]}]}]}], "classes": [], "simplified_code": "def _enqueue_next_nodes(\n    db_client: \"DatabaseManager\",\n    node: Node,\n    output: BlockData,\n    user_id: str,\n    graph_exec_id: str,\n    graph_id: str,\n    log_metadata: LogMetadata,\n) -> list[NodeExecutionEntry]:\n        )\n\n            return enqueued_executions\n\n    return [\n        execution\n        for link in node.output_links\n        for execution in register_next_executions(link)\n    ]", "blocks": [{"id": 1, "label": "def _enqueue_next_nodes(\n    db_client: \"DatabaseManager\",\n    node: Node,\n    output: BlockData,\n    user_id: str,\n    graph_exec_id: str,\n    graph_id: str,\n    log_metadata: LogMetadata,\n) -> list[NodeExecutionEntry]:", "successors": [{"id": 2, "label": "def register_next_executions(link):\nif not link.is_active():\n    return []", "successors": [{"id": 4, "label": "try:\nenqueued_executions = []\nwith db_client.session_context() as session:", "successors": [{"id": 6, "label": "todo_entry = create_todo_entry(session, link)\nenqueued_executions.append(todo_entry)\nexcept Exception as e:\nlog_error(e, log_metadata=log_metadata)", "successors": []}]}, {"id": 8, "label": "return enqueued_executions", "successors": []}]}, {"id": 9, "label": "return [\n    execution\n    for link in node.output_links\n    for execution in register_next_executions(link)\n]", "successors": []}]}]}, {"name": "validate_exec", "type": "function", "start_line": 363, "end_line": 430, "functions": [], "classes": [], "simplified_code": "def validate_exec(\n    node: Node,\n    data: BlockInput,\n    resolve_input: bool = True,\n) -> tuple[BlockInput | None, str]:\n    \"\"\"\n    Validate the input data for a node execution.\n\n    Args:\n        node: The node to execute.\n        data: The input data for the node execution.\n        resolve_input: Whether to resolve dynamic pins into dict/list/object.\n\n    Returns:\n        A tuple of the validated data and the block name.\n        If the data is invalid, the first element will be None, and the second element\n        will be an error message.\n        If the data is valid, the first element will be the resolved input data, and\n        the second element will be the block name.\n    \"\"\"\n    node_block: Block | None = get_block(node.block_id)\n    if not node_block:\n        return None, f\"Block for {node.block_id} not found.\"\n\n    if isinstance(node_block, AgentExecutorBlock):\n        # Validate the execution metadata for the agent executor block.\n        try:\n            exec_data = AgentExecutorBlock.Input(**node.input_default)\n        except Exception as e:\n            return None, f\"Input data doesn't match {node_block.name}: {str(e)}\"\n\n        # Validation input\n        input_schema = exec_data.input_schema\n        required_fields = set(input_schema[\"required\"])\n        input_default = exec_data.data\n    else:\n        # Convert non-matching data types to the expected input schema.\n        for name, data_type in node_block.input_schema.__annotations__.items():\n            if (value := data.get(name)) and (type(value) is not data_type):\n                data[name] = convert(value, data_type)\n\n        # Validation input\n        input_schema = node_block.input_schema.jsonschema()\n        required_fields = node_block.input_schema.get_required_fields()\n        input_default = node.input_default\n\n    # Input data (without default values) should contain all required fields.\n    error_prefix = f\"Input data missing or mismatch for `{node_block.name}`:\"\n    input_fields_from_nodes = {link.sink_name for link in node.input_links}\n    if not input_fields_from_nodes.issubset(data):\n        return None, f\"{error_prefix} {input_fields_from_nodes - set(data)}\"\n\n    # Merge input data with default values and resolve dynamic dict/list/object pins.\n    data = {**input_default, **data}\n    if resolve_input:\n        data = merge_execution_input(data)\n\n    # Input data post-merge should contain all required fields from the schema.\n    if not required_fields.issubset(data):\n        return None, f\"{error_prefix} {required_fields - set(data)}\"\n\n    # Last validation: Validate the input values against the schema.\n    if error := json.validate_with_jsonschema(schema=input_schema, data=data):\n        error_message = f\"{error_prefix} {error}\"\n        logger.error(error_message)\n        return None, error_message\n\n    return data, node_block.name", "blocks": [{"id": 1, "label": "def validate_exec(\n    node: Node,\n    data: BlockInput,\n    resolve_input: bool = True,\n) -> tuple[BlockInput | None, str]:\nnode_block: Block | None = get_block(node.block_id)", "successors": [{"id": 3, "label": "if not node_block:\nreturn None, f\"Block for {node.block_id} not found.\"", "successors": []}, {"id": 5, "label": "if isinstance(node_block, AgentExecutorBlock):\ntry:\n    exec_data = AgentExecutorBlock.Input(**node.input_default)", "successors": [{"id": 7, "label": "except Exception as e:\n    return None, f\"Input data doesn't match {node_block.name}: {str(e)}\"", "successors": []}, {"id": 8, "label": "input_schema = exec_data.input_schema\nrequired_fields = set(input_schema[\"required\"])\ninput_default = exec_data.data", "successors": []}]}, {"id": 9, "label": "else:", "successors": [{"id": 10, "label": "for name, data_type in node_block.input_schema.__annotations__.items():\n    if (value := data.get(name)) and (type(value) is not data_type):\n        data[name] = convert(value, data_type)", "successors": []}, {"id": 11, "label": "input_schema = node_block.input_schema.jsonschema()\nrequired_fields = node_block.input_schema.get_required_fields()\ninput_default = node.input_default", "successors": []}]}, {"id": 12, "label": "error_prefix = f\"Input data missing or mismatch for `{node_block.name}`:\"\ninput_fields_from_nodes = {link.sink_name for link in node.input_links}\nif not input_fields_from_nodes.issubset(data):\nreturn None, f\"{error_prefix} {input_fields_from_nodes - set(data)}\"", "successors": []}, {"id": 14, "label": "data = {**input_default, **data}\nif resolve_input:\n    data = merge_execution_input(data)\nif not required_fields.issubset(data):", "successors": [{"id": 16, "label": "return None, f\"{error_prefix} {required_fields - set(data)}\"", "successors": []}]}, {"id": 17, "label": "if error := json.validate_with_jsonschema(schema=input_schema, data=data):\nerror_message = f\"{error_prefix} {error}\"\nlogger.error(error_message)\nreturn None, error_message", "successors": []}, {"id": 19, "label": "return data, node_block.name", "successors": []}]}]}, {"name": "get_db_client", "type": "function", "start_line": 937, "end_line": 940, "functions": [], "classes": [], "simplified_code": "def get_db_client() -> \"DatabaseManager\":\n    from backend.executor import DatabaseManager\n\n    return get_service_client(DatabaseManager)", "blocks": [{"id": 1, "label": "from backend.executor import DatabaseManager\nreturn get_service_client(DatabaseManager)", "successors": []}]}, {"name": "synchronized", "type": "function", "start_line": 943, "end_line": 951, "functions": [], "classes": [], "simplified_code": "@contextmanager\ndef synchronized(key: str, timeout: int = 60):\n    lock: RedisLock = redis.get_redis().lock(f\"lock:{key}\", timeout=timeout)\n    try:\n        lock.acquire()\n        yield\n    finally:\n        if lock.locked():\n            lock.release()", "blocks": [{"id": 1, "label": "@contextmanager\ndef synchronized(key: str, timeout: int = 60):\n    lock: RedisLock = redis.get_redis().lock(f\"lock:{key}\", timeout=timeout)", "successors": [{"id": 3, "label": "try:\n    lock.acquire()", "successors": [{"id": 5, "label": "    yield\nfinally:", "successors": [{"id": 7, "label": "    if lock.locked():\n        lock.release()", "successors": []}]}]}]}]}, {"name": "llprint", "type": "function", "start_line": 954, "end_line": 960, "functions": [], "classes": [], "simplified_code": "def llprint(message: str):\n    \"\"\"\n    Low-level print/log helper function for use in signal handlers.\n    Regular log/print statements are not allowed in signal handlers.\n    \"\"\"\n    if logger.getEffectiveLevel() == logging.DEBUG:\n        os.write(sys.stdout.fileno(), (message + \"\\n\").encode())", "blocks": [{"id": 1, "label": "def llprint(message: str):\n\"\"\"\nLow-level print/log helper function for use in signal handlers.\nRegular log/print statements are not allowed in signal handlers.\n\"\"\"", "successors": [{"id": 3, "label": "if logger.getEffectiveLevel() == logging.DEBUG:\n    os.write(sys.stdout.fileno(), (message + \"\\n\").encode())", "successors": []}]}]}], "classes": [{"name": "LogMetadata", "type": "class", "start_line": 53, "end_line": 95, "functions": [{"name": "__init__", "type": "function", "start_line": 54, "end_line": 72, "functions": [], "classes": [], "simplified_code": "    def __init__(\n        self,\n        user_id: str,\n        graph_eid: str,\n        graph_id: str,\n        node_eid: str,\n        node_id: str,\n        block_name: str,\n    ):\n        self.metadata = {\n            \"component\": \"ExecutionManager\",\n            \"user_id\": user_id,\n            \"graph_eid\": graph_eid,\n            \"graph_id\": graph_id,\n            \"node_eid\": node_eid,\n            \"node_id\": node_id,\n            \"block_name\": block_name,\n        }\n        self.prefix = f\"[ExecutionManager|uid:{user_id}|gid:{graph_id}|nid:{node_id}]|geid:{graph_eid}|nid:{node_eid}|{block_name}]\"", "blocks": [{"id": 1, "label": "def __init__(\n    self,\n    user_id: str,\n    graph_eid: str,\n    graph_id: str,\n    node_eid: str,\n    node_id: str,\n    block_name: str,\n):\n    self.metadata = {\n        \"component\": \"ExecutionManager\",\n        \"user_id\": user_id,\n        \"graph_eid\": graph_eid,\n        \"graph_id\": graph_id,\n        \"node_eid\": node_eid,\n        \"node_id\": node_id,\n        \"block_name\": block_name,\n    }", "successors": [{"id": 3, "label": "    self.prefix = f\"[ExecutionManager|uid:{user_id}|gid:{graph_id}|nid:{node_id}]|geid:{graph_eid}|nid:{node_eid}|{block_name}]\"", "successors": []}]}]}, {"name": "info", "type": "function", "start_line": 74, "end_line": 76, "functions": [], "classes": [], "simplified_code": "    def info(self, msg: str, **extra):\n        msg = self._wrap(msg, **extra)\n        logger.info(msg, extra={\"json_fields\": {**self.metadata, **extra}})", "blocks": [{"id": 1, "label": "def info(self, msg: str, **extra):\n    msg = self._wrap(msg, **extra)", "successors": [{"id": 3, "label": "    logger.info(msg, extra={\"json_fields\": {**self.metadata, **extra}})", "successors": []}]}]}, {"name": "warning", "type": "function", "start_line": 78, "end_line": 80, "functions": [], "classes": [], "simplified_code": "    def warning(self, msg: str, **extra):\n        msg = self._wrap(msg, **extra)\n        logger.warning(msg, extra={\"json_fields\": {**self.metadata, **extra}})", "blocks": [{"id": 1, "label": "def warning(self, msg: str, **extra):\n    msg = self._wrap(msg, **extra)\n    logger.warning(msg, extra={\"json_fields\": {**self.metadata, **extra}})", "successors": []}]}, {"name": "error", "type": "function", "start_line": 82, "end_line": 84, "functions": [], "classes": [], "simplified_code": "    def error(self, msg: str, **extra):\n        msg = self._wrap(msg, **extra)\n        logger.error(msg, extra={\"json_fields\": {**self.metadata, **extra}})", "blocks": [{"id": 1, "label": "def error(self, msg: str, **extra):\n    msg = self._wrap(msg, **extra)", "successors": [{"id": 3, "label": "    logger.error(msg, extra={\"json_fields\": {**self.metadata, **extra}})", "successors": []}]}]}, {"name": "debug", "type": "function", "start_line": 86, "end_line": 88, "functions": [], "classes": [], "simplified_code": "    def debug(self, msg: str, **extra):\n        msg = self._wrap(msg, **extra)\n        logger.debug(msg, extra={\"json_fields\": {**self.metadata, **extra}})", "blocks": [{"id": 1, "label": "def debug(self, msg: str, **extra):\nmsg = self._wrap(msg, **extra)", "successors": [{"id": 3, "label": "logger.debug(msg, extra={\"json_fields\": {**self.metadata, **extra}})", "successors": []}]}]}, {"name": "exception", "type": "function", "start_line": 90, "end_line": 92, "functions": [], "classes": [], "simplified_code": "    def exception(self, msg: str, **extra):\n        msg = self._wrap(msg, **extra)\n        logger.exception(msg, extra={\"json_fields\": {**self.metadata, **extra}})", "blocks": [{"id": 1, "label": "msg = self._wrap(msg, **extra)\nlogger.exception(msg, extra={\"json_fields\": {**self.metadata, **extra}})", "successors": []}]}, {"name": "_wrap", "type": "function", "start_line": 94, "end_line": 95, "functions": [], "classes": [], "simplified_code": "    def _wrap(self, msg: str, **extra):\n        return f\"{self.prefix} {msg} {extra}\"", "blocks": [{"id": 1, "label": "def _wrap(self, msg: str, **extra):\n    return f\"{self.prefix} {msg} {extra}\"", "successors": []}]}], "classes": [], "simplified_code": "class LogMetadata:\n        self.prefix = f\"[ExecutionManager|uid:{user_id}|gid:{graph_id}|nid:{node_id}]|geid:{graph_eid}|nid:{node_eid}|{block_name}]\"\n\n        logger.info(msg, extra={\"json_fields\": {**self.metadata, **extra}})\n\n        logger.warning(msg, extra={\"json_fields\": {**self.metadata, **extra}})\n\n        logger.error(msg, extra={\"json_fields\": {**self.metadata, **extra}})\n\n        logger.debug(msg, extra={\"json_fields\": {**self.metadata, **extra}})\n\n        logger.exception(msg, extra={\"json_fields\": {**self.metadata, **extra}})\n\n        return f\"{self.prefix} {msg} {extra}\"", "blocks": [{"id": 1, "label": "class LogMetadata:\n    def some_method(self, user_id, graph_id, node_id, graph_eid, node_eid, block_name, msg, extra):\n    self.prefix = f\"[ExecutionManager|uid:{user_id}|gid:{graph_id}|nid:{node_id}]|geid:{graph_eid}|nid:{node_eid}|{block_name}]\"", "successors": [{"id": 3, "label": "    logger.info(msg, extra={\"json_fields\": {**self.metadata, **extra}})\n    logger.warning(msg, extra={\"json_fields\": {**self.metadata, **extra}})", "successors": [{"id": 5, "label": "    logger.error(msg, extra={\"json_fields\": {**self.metadata, **extra}})\n    logger.debug(msg, extra={\"json_fields\": {**self.metadata, **extra}})", "successors": [{"id": 7, "label": "    logger.exception(msg, extra={\"json_fields\": {**self.metadata, **extra}})\n    return f\"{self.prefix} {msg} {extra}\"", "successors": []}]}]}]}]}, {"name": "Executor", "type": "class", "start_line": 433, "end_line": 712, "functions": [{"name": "on_node_executor_start", "type": "function", "start_line": 459, "end_line": 472, "functions": [], "classes": [], "simplified_code": "    def on_node_executor_start(cls):\n        configure_logging()\n        set_service_name(\"NodeExecutor\")\n        redis.connect()\n        cls.pid = os.getpid()\n        cls.db_client = get_db_client()\n        cls.creds_manager = IntegrationCredentialsManager()\n\n        # Set up shutdown handlers\n        cls.shutdown_lock = threading.Lock()\n        atexit.register(cls.on_node_executor_stop)  # handle regular shutdown\n        signal.signal(  # handle termination\n            signal.SIGTERM, lambda _, __: cls.on_node_executor_sigterm()\n        )", "blocks": [{"id": 1, "label": "def on_node_executor_start(cls):\nconfigure_logging()\nset_service_name(\"NodeExecutor\")\nredis.connect()\ncls.pid = os.getpid()\ncls.db_client = get_db_client()\ncls.creds_manager = IntegrationCredentialsManager()\ncls.shutdown_lock = threading.Lock()", "successors": [{"id": 3, "label": "atexit.register(cls.on_node_executor_stop)\nsignal.signal(\n    signal.SIGTERM, lambda _, __: cls.on_node_executor_sigterm()\n)", "successors": []}]}]}, {"name": "on_node_executor_stop", "type": "function", "start_line": 475, "end_line": 485, "functions": [], "classes": [], "simplified_code": "    def on_node_executor_stop(cls):\n        if not cls.shutdown_lock.acquire(blocking=False):\n            return  # already shutting down\n\n        logger.info(f\"[on_node_executor_stop {cls.pid}] \u23f3 Releasing locks...\")\n        cls.creds_manager.release_all_locks()\n        logger.info(f\"[on_node_executor_stop {cls.pid}] \u23f3 Disconnecting Redis...\")\n        redis.disconnect()\n        logger.info(f\"[on_node_executor_stop {cls.pid}] \u23f3 Disconnecting DB manager...\")\n        close_service_client(cls.db_client)\n        logger.info(f\"[on_node_executor_stop {cls.pid}] \u2705 Finished cleanup\")", "blocks": [{"id": 1, "label": "def on_node_executor_stop(cls):\nif not cls.shutdown_lock.acquire(blocking=False):", "successors": [{"id": 3, "label": "return  # already shutting down", "successors": []}, {"id": 4, "label": "logger.info(f\"[on_node_executor_stop {cls.pid}] \u23f3 Releasing locks...\")\ncls.creds_manager.release_all_locks()\nlogger.info(f\"[on_node_executor_stop {cls.pid}] \u23f3 Disconnecting Redis...\")\nredis.disconnect()\nlogger.info(f\"[on_node_executor_stop {cls.pid}] \u23f3 Disconnecting DB manager...\")\nclose_service_client(cls.db_client)\nlogger.info(f\"[on_node_executor_stop {cls.pid}] \u2705 Finished cleanup\")", "successors": []}]}]}, {"name": "on_node_executor_sigterm", "type": "function", "start_line": 488, "end_line": 498, "functions": [], "classes": [], "simplified_code": "    def on_node_executor_sigterm(cls):\n        llprint(f\"[on_node_executor_sigterm {cls.pid}] \u26a0\ufe0f SIGTERM received\")\n        if not cls.shutdown_lock.acquire(blocking=False):\n            return  # already shutting down\n\n        llprint(f\"[on_node_executor_stop {cls.pid}] \u23f3 Releasing locks...\")\n        cls.creds_manager.release_all_locks()\n        llprint(f\"[on_node_executor_stop {cls.pid}] \u23f3 Disconnecting Redis...\")\n        redis.disconnect()\n        llprint(f\"[on_node_executor_stop {cls.pid}] \u2705 Finished cleanup\")\n        sys.exit(0)", "blocks": [{"id": 1, "label": "def on_node_executor_sigterm(cls):\nllprint(f\"[on_node_executor_sigterm {cls.pid}] \u26a0\ufe0f SIGTERM received\")", "successors": [{"id": 3, "label": "if not cls.shutdown_lock.acquire(blocking=False):", "successors": [{"id": 4, "label": "return  # already shutting down", "successors": []}, {"id": 5, "label": "llprint(f\"[on_node_executor_stop {cls.pid}] \u23f3 Releasing locks...\")\ncls.creds_manager.release_all_locks()", "successors": [{"id": 7, "label": "llprint(f\"[on_node_executor_stop {cls.pid}] \u23f3 Disconnecting Redis...\")\nredis.disconnect()", "successors": [{"id": 9, "label": "llprint(f\"[on_node_executor_stop {cls.pid}] \u2705 Finished cleanup\")\nsys.exit(0)", "successors": []}]}]}]}]}]}, {"name": "on_node_execution", "type": "function", "start_line": 502, "end_line": 526, "functions": [], "classes": [], "simplified_code": "    def on_node_execution(\n        cls,\n        q: ExecutionQueue[NodeExecutionEntry],\n        node_exec: NodeExecutionEntry,\n    ) -> dict[str, Any]:\n        log_metadata = LogMetadata(\n            user_id=node_exec.user_id,\n            graph_eid=node_exec.graph_exec_id,\n            graph_id=node_exec.graph_id,\n            node_eid=node_exec.node_exec_id,\n            node_id=node_exec.node_id,\n            block_name=\"-\",\n        )\n\n        execution_stats = {}\n        timing_info, _ = cls._on_node_execution(\n            q, node_exec, log_metadata, execution_stats\n        )\n        execution_stats[\"walltime\"] = timing_info.wall_time\n        execution_stats[\"cputime\"] = timing_info.cpu_time\n\n        cls.db_client.update_node_execution_stats(\n            node_exec.node_exec_id, execution_stats\n        )\n        return execution_stats", "blocks": [{"id": 1, "label": "def on_node_execution(cls, q: ExecutionQueue[NodeExecutionEntry], node_exec: NodeExecutionEntry) -> dict[str, Any]:\nlog_metadata = LogMetadata(user_id=node_exec.user_id, graph_eid=node_exec.graph_exec_id, graph_id=node_exec.graph_id, node_eid=node_exec.node_exec_id, node_id=node_exec.node_id, block_name=\"-\")", "successors": [{"id": 3, "label": "execution_stats = {}\ntiming_info, _ = cls._on_node_execution(q, node_exec, log_metadata, execution_stats)", "successors": [{"id": 5, "label": "execution_stats[\"walltime\"] = timing_info.wall_time\nexecution_stats[\"cputime\"] = timing_info.cpu_time", "successors": [{"id": 7, "label": "cls.db_client.update_node_execution_stats(node_exec.node_exec_id, execution_stats)\nreturn execution_stats", "successors": []}]}]}]}]}, {"name": "_on_node_execution", "type": "function", "start_line": 530, "end_line": 547, "functions": [], "classes": [], "simplified_code": "    def _on_node_execution(\n        cls,\n        q: ExecutionQueue[NodeExecutionEntry],\n        node_exec: NodeExecutionEntry,\n        log_metadata: LogMetadata,\n        stats: dict[str, Any] | None = None,\n    ):\n        try:\n            log_metadata.info(f\"Start node execution {node_exec.node_exec_id}\")\n            for execution in execute_node(\n                cls.db_client, cls.creds_manager, node_exec, stats\n            ):\n                q.add(execution)\n            log_metadata.info(f\"Finished node execution {node_exec.node_exec_id}\")\n        except Exception as e:\n            log_metadata.exception(\n                f\"Failed node execution {node_exec.node_exec_id}: {e}\"\n            )", "blocks": [{"id": 1, "label": "def _on_node_execution(cls, q: ExecutionQueue[NodeExecutionEntry], node_exec: NodeExecutionEntry, log_metadata: LogMetadata, stats: dict[str, Any] | None = None):\ntry:", "successors": [{"id": 3, "label": "log_metadata.info(f\"Start node execution {node_exec.node_exec_id}\")", "successors": [{"id": 4, "label": "for execution in execute_node(cls.db_client, cls.creds_manager, node_exec, stats):", "successors": [{"id": 5, "label": "q.add(execution)\nlog_metadata.info(f\"Finished node execution {node_exec.node_exec_id}\")", "successors": []}]}]}, {"id": 7, "label": "except Exception as e:\nlog_metadata.exception(f\"Failed node execution {node_exec.node_exec_id}: {e}\")", "successors": []}]}]}, {"name": "on_graph_executor_start", "type": "function", "start_line": 550, "end_line": 563, "functions": [], "classes": [], "simplified_code": "    def on_graph_executor_start(cls):\n        configure_logging()\n        set_service_name(\"GraphExecutor\")\n\n        cls.db_client = get_db_client()\n        cls.pool_size = settings.config.num_node_workers\n        cls.pid = os.getpid()\n        cls._init_node_executor_pool()\n        logger.info(\n            f\"Graph executor {cls.pid} started with {cls.pool_size} node workers\"\n        )\n\n        # Set up shutdown handler\n        atexit.register(cls.on_graph_executor_stop)", "blocks": [{"id": 1, "label": "def on_graph_executor_start(cls):\nconfigure_logging()\nset_service_name(\"GraphExecutor\")\n\ncls.db_client = get_db_client()\ncls.pool_size = settings.config.num_node_workers\ncls.pid = os.getpid()\ncls._init_node_executor_pool()\nlogger.info(\n    f\"Graph executor {cls.pid} started with {cls.pool_size} node workers\"\n)\n\n# Set up shutdown handler\natexit.register(cls.on_graph_executor_stop)", "successors": []}]}, {"name": "on_graph_executor_stop", "type": "function", "start_line": 566, "end_line": 572, "functions": [], "classes": [], "simplified_code": "    def on_graph_executor_stop(cls):\n        prefix = f\"[on_graph_executor_stop {cls.pid}]\"\n        logger.info(f\"{prefix} \u23f3 Terminating node executor pool...\")\n        cls.executor.terminate()\n        logger.info(f\"{prefix} \u23f3 Disconnecting DB manager...\")\n        close_service_client(cls.db_client)\n        logger.info(f\"{prefix} \u2705 Finished cleanup\")", "blocks": [{"id": 1, "label": "prefix = f\"[on_graph_executor_stop {cls.pid}]\"\nlogger.info(f\"{prefix} \u23f3 Terminating node executor pool...\")", "successors": [{"id": 3, "label": "cls.executor.terminate()\nlogger.info(f\"{prefix} \u23f3 Disconnecting DB manager...\")", "successors": [{"id": 5, "label": "close_service_client(cls.db_client)\nlogger.info(f\"{prefix} \u2705 Finished cleanup\")", "successors": []}]}]}]}, {"name": "_init_node_executor_pool", "type": "function", "start_line": 575, "end_line": 579, "functions": [], "classes": [], "simplified_code": "    def _init_node_executor_pool(cls):\n        cls.executor = Pool(\n            processes=cls.pool_size,\n            initializer=cls.on_node_executor_start,\n        )", "blocks": [{"id": 1, "label": "def _init_node_executor_pool(cls):\ncls.executor = Pool(", "successors": [{"id": 3, "label": "processes=cls.pool_size,\ninitializer=cls.on_node_executor_start,", "successors": []}]}]}, {"name": "on_graph_execution", "type": "function", "start_line": 583, "end_line": 604, "functions": [], "classes": [], "simplified_code": "    def on_graph_execution(\n        cls, graph_exec: GraphExecutionEntry, cancel: threading.Event\n    ):\n        log_metadata = LogMetadata(\n            user_id=graph_exec.user_id,\n            graph_eid=graph_exec.graph_exec_id,\n            graph_id=graph_exec.graph_id,\n            node_id=\"*\",\n            node_eid=\"*\",\n            block_name=\"-\",\n        )\n        timing_info, (exec_stats, error) = cls._on_graph_execution(\n            graph_exec, cancel, log_metadata\n        )\n        exec_stats[\"walltime\"] = timing_info.wall_time\n        exec_stats[\"cputime\"] = timing_info.cpu_time\n        exec_stats[\"error\"] = str(error) if error else None\n        result = cls.db_client.update_graph_execution_stats(\n            graph_exec_id=graph_exec.graph_exec_id,\n            stats=exec_stats,\n        )\n        cls.db_client.send_execution_update(result)", "blocks": [{"id": 1, "label": "log_metadata = LogMetadata(user_id=graph_exec.user_id, graph_eid=graph_exec.graph_exec_id, graph_id=graph_exec.graph_id, node_id=\"*\", node_eid=\"*\", block_name=\"-\")\ntiming_info, (exec_stats, error) = cls._on_graph_execution(graph_exec, cancel, log_metadata)", "successors": [{"id": 3, "label": "exec_stats[\"walltime\"] = timing_info.wall_time\nexec_stats[\"cputime\"] = timing_info.cpu_time\nexec_stats[\"error\"] = str(error) if error else None\nresult = cls.db_client.update_graph_execution_stats(graph_exec_id=graph_exec.graph_exec_id, stats=exec_stats)", "successors": [{"id": 5, "label": "cls.db_client.send_execution_update(result)", "successors": []}]}]}]}, {"name": "_on_graph_execution", "type": "function", "start_line": 608, "end_line": 712, "functions": [], "classes": [], "simplified_code": "    def _on_graph_execution(\n        cls,\n        graph_exec: GraphExecutionEntry,\n        cancel: threading.Event,\n        log_metadata: LogMetadata,\n    ) -> tuple[dict[str, Any], Exception | None]:\n        \"\"\"\n        Returns:\n            The execution statistics of the graph execution.\n            The error that occurred during the execution.\n        \"\"\"\n        log_metadata.info(f\"Start graph execution {graph_exec.graph_exec_id}\")\n        exec_stats = {\n            \"nodes_walltime\": 0,\n            \"nodes_cputime\": 0,\n            \"node_count\": 0,\n        }\n        error = None\n        finished = False\n\n        def cancel_handler():\n            while not cancel.is_set():\n                cancel.wait(1)\n            if finished:\n                return\n            cls.executor.terminate()\n            log_metadata.info(f\"Terminated graph execution {graph_exec.graph_exec_id}\")\n            cls._init_node_executor_pool()\n\n        cancel_thread = threading.Thread(target=cancel_handler)\n        cancel_thread.start()\n\n        try:\n            queue = ExecutionQueue[NodeExecutionEntry]()\n            for node_exec in graph_exec.start_node_execs:\n                queue.add(node_exec)\n\n            running_executions: dict[str, AsyncResult] = {}\n\n            def make_exec_callback(exec_data: NodeExecutionEntry):\n                node_id = exec_data.node_id\n\n                def callback(result: object):\n                    running_executions.pop(node_id)\n                    nonlocal exec_stats\n                    if isinstance(result, dict):\n                        exec_stats[\"node_count\"] += 1\n                        exec_stats[\"nodes_cputime\"] += result.get(\"cputime\", 0)\n                        exec_stats[\"nodes_walltime\"] += result.get(\"walltime\", 0)\n\n                return callback\n\n            while not queue.empty():\n                if cancel.is_set():\n                    error = RuntimeError(\"Execution is cancelled\")\n                    return exec_stats, error\n\n                exec_data = queue.get()\n\n                # Avoid parallel execution of the same node.\n                execution = running_executions.get(exec_data.node_id)\n                if execution and not execution.ready():\n                    # TODO (performance improvement):\n                    #   Wait for the completion of the same node execution is blocking.\n                    #   To improve this we need a separate queue for each node.\n                    #   Re-enqueueing the data back to the queue will disrupt the order.\n                    execution.wait()\n\n                log_metadata.debug(\n                    f\"Dispatching node execution {exec_data.node_exec_id} \"\n                    f\"for node {exec_data.node_id}\",\n                )\n                running_executions[exec_data.node_id] = cls.executor.apply_async(\n                    cls.on_node_execution,\n                    (queue, exec_data),\n                    callback=make_exec_callback(exec_data),\n                )\n\n                # Avoid terminating graph execution when some nodes are still running.\n                while queue.empty() and running_executions:\n                    log_metadata.debug(\n                        f\"Queue empty; running nodes: {list(running_executions.keys())}\"\n                    )\n                    for node_id, execution in list(running_executions.items()):\n                        if cancel.is_set():\n                            error = RuntimeError(\"Execution is cancelled\")\n                            return exec_stats, error\n\n                        if not queue.empty():\n                            break  # yield to parent loop to execute new queue items\n\n                        log_metadata.debug(f\"Waiting on execution of node {node_id}\")\n                        execution.wait(3)\n\n            log_metadata.info(f\"Finished graph execution {graph_exec.graph_exec_id}\")\n        except Exception as e:\n            log_metadata.exception(\n                f\"Failed graph execution {graph_exec.graph_exec_id}: {e}\"\n            )\n            error = e\n        finally:\n            if not cancel.is_set():\n                finished = True\n                cancel.set()\n            cancel_thread.join()", "blocks": [{"id": 1, "label": "def _on_graph_execution(cls, graph_exec: GraphExecutionEntry, cancel: threading.Event, log_metadata: LogMetadata) -> tuple[dict[str, Any], Exception | None]:\nlog_metadata.info(f\"Start graph execution {graph_exec.graph_exec_id}\")\nexec_stats = {\n    \"nodes_walltime\": 0,\n    \"nodes_cputime\": 0,\n    \"node_count\": 0,\n}\nerror = None\nfinished = False", "successors": [{"id": 3, "label": "def cancel_handler():", "successors": [{"id": 4, "label": "while not cancel.is_set():", "successors": [{"id": 5, "label": "cancel.wait(1)\nif finished:\n    return\ncls.executor.terminate()\nlog_metadata.info(f\"Terminated graph execution {graph_exec.graph_exec_id}\")\ncls._init_node_executor_pool()", "successors": []}]}]}, {"id": 7, "label": "cancel_thread = threading.Thread(target=cancel_handler)\ncancel_thread.start()", "successors": [{"id": 8, "label": "try:", "successors": [{"id": 9, "label": "queue = ExecutionQueue[NodeExecutionEntry]()\nfor node_exec in graph_exec.start_node_execs:\n    queue.add(node_exec)\nrunning_executions: dict[str, AsyncResult] = {}\ndef make_exec_callback(exec_data: NodeExecutionEntry):", "successors": [{"id": 11, "label": "node_id = exec_data.node_id\ndef callback(result: object):\n    running_executions.pop(node_id)\n    nonlocal exec_stats\n    if isinstance(result, dict):\n        exec_stats[\"node_count\"] += 1\n        exec_stats[\"nodes_cputime\"] += result.get(\"cputime\", 0)\n        exec_stats[\"nodes_walltime\"] += result.get(\"walltime\", 0)\nreturn callback", "successors": [{"id": 12, "label": "while not queue.empty():", "successors": [{"id": 13, "label": "if cancel.is_set():\n    error = RuntimeError(\"Execution is cancelled\")\n    return exec_stats, error\nexec_data = queue.get()\nexecution = running_executions.get(exec_data.node_id)\nif execution and not execution.ready():\n    execution.wait()", "successors": [{"id": 15, "label": "log_metadata.debug(f\"Dispatching node execution {exec_data.node_exec_id} \"\n                    f\"for node {exec_data.node_id}\",)\nrunning_executions[exec_data.node_id] = cls.executor.apply_async(\n    cls.on_node_execution,\n    (queue, exec_data),\n    callback=make_exec_callback(exec_data),\n)", "successors": [{"id": 16, "label": "while queue.empty() and running_executions:", "successors": [{"id": 17, "label": "log_metadata.debug(f\"Queue empty; running nodes: {list(running_executions.keys())}\")\nfor node_id, execution in list(running_executions.items()):\n    if cancel.is_set():\n        error = RuntimeError(\"Execution is cancelled\")\n        return exec_stats, error\n    if not queue.empty():\n        break\n    log_metadata.debug(f\"Waiting on execution of node {node_id}\")\n    execution.wait(3)", "successors": []}]}]}]}]}]}]}, {"id": 18, "label": "log_metadata.info(f\"Finished graph execution {graph_exec.graph_exec_id}\")", "successors": []}]}, {"id": 19, "label": "except Exception as e:\nlog_metadata.exception(f\"Failed graph execution {graph_exec.graph_exec_id}: {e}\")\nerror = e", "successors": []}, {"id": 21, "label": "finally:\nif not cancel.is_set():\n    finished = True\n    cancel.set()\ncancel_thread.join()", "successors": []}]}]}]}], "classes": [], "simplified_code": "class Executor:\n    \"\"\"\n    This class contains event handlers for the process pool executor events.\n\n    The main events are:\n        on_node_executor_start: Initialize the process that executes the node.\n        on_node_execution: Execution logic for a node.\n\n        on_graph_executor_start: Initialize the process that executes the graph.\n        on_graph_execution: Execution logic for a graph.\n\n    The execution flow:\n        1. Graph execution request is added to the queue.\n        2. Graph executor loop picks the request from the queue.\n        3. Graph executor loop submits the graph execution request to the executor pool.\n      [on_graph_execution]\n        4. Graph executor initialize the node execution queue.\n        5. Graph executor adds the starting nodes to the node execution queue.\n        6. Graph executor waits for all nodes to be executed.\n      [on_node_execution]\n        7. Node executor picks the node execution request from the queue.\n        8. Node executor executes the node.\n        9. Node executor enqueues the next executed nodes to the node execution queue.\n    \"\"\"\n\n    @classmethod\n        )\n\n    @classmethod\n        logger.info(f\"[on_node_executor_stop {cls.pid}] \u2705 Finished cleanup\")\n\n    @classmethod\n        sys.exit(0)\n\n    @classmethod\n    @error_logged\n        return execution_stats\n\n    @classmethod\n    @time_measured\n            )\n\n    @classmethod\n        atexit.register(cls.on_graph_executor_stop)\n\n    @classmethod\n        logger.info(f\"{prefix} \u2705 Finished cleanup\")\n\n    @classmethod\n        )\n\n    @classmethod\n    @error_logged\n        cls.db_client.send_execution_update(result)\n\n    @classmethod\n    @time_measured\n            cancel_thread.join()", "blocks": [{"id": 1, "label": "class Executor:", "successors": [{"id": 2, "label": "\"\"\"\n    This class contains event handlers for the process pool executor events.\n\n    The main events are:\n        on_node_executor_start: Initialize the process that executes the node.\n        on_node_execution: Execution logic for a node.\n\n        on_graph_executor_start: Initialize the process that executes the graph.\n        on_graph_execution: Execution logic for a graph.\n\n    The execution flow:\n        1. Graph execution request is added to the queue.\n        2. Graph executor loop picks the request from the queue.\n        3. Graph executor loop submits the graph execution request to the executor pool.\n      [on_graph_execution]\n        4. Graph executor initialize the node execution queue.\n        5. Graph executor adds the starting nodes to the node execution queue.\n        6. Graph executor waits for all nodes to be executed.\n      [on_node_execution]\n        7. Node executor picks the node execution request from the queue.\n        8. Node executor executes the node.\n        9. Node executor enqueues the next executed nodes to the node execution queue.\n    \"\"\"\n\n    @classmethod\n    def on_node_executor_start(cls):\n        logger.info(f\"[on_node_executor_start {cls.pid}] \u2705 Starting...\")\n\n        return", "successors": []}, {"id": 3, "label": "@classmethod\n    def on_node_executor_stop(cls):\n        logger.info(f\"[on_node_executor_stop {cls.pid}] \u2705 Finished cleanup\")\n\n        return", "successors": []}, {"id": 4, "label": "@classmethod\n    def on_graph_executor_stop(cls):\n        logger.error(f\"[on_graph_executor_stop {cls.pid}] \u274c Unexpected graph abort\")\n        sys.exit(0)\n\n        return", "successors": []}, {"id": 5, "label": "@classmethod\n    @error_logged\n    def execute_graph(cls, graph):\n        execution_stats = cls.graph_executor.run(graph)\n\n        return execution_stats", "successors": []}, {"id": 6, "label": "@classmethod\n    @time_measured\n    def measure_node_execution_time(cls):\n        start_time = time.time()\n        ...\n        cancel_thread = threading.Thread(target=target_function)\n        cancel_thread.start()\n        cancel_thread.join()\n\n        return time.time() - start_time", "successors": []}, {"id": 7, "label": "@classmethod\n    def setup_executor(cls):\n        atexit.register(cls.on_graph_executor_stop)\n\n        return", "successors": []}, {"id": 8, "label": "@classmethod\n    def cleanup_node_executor(cls, prefix):\n        logger.info(f\"{prefix} \u2705 Finished cleanup\")\n\n        return", "successors": []}, {"id": 9, "label": "@classmethod\n    @error_logged\n    def send_execution_update(cls, result):\n        cls.db_client.send_execution_update(result)\n\n        return", "successors": []}]}]}, {"name": "ExecutionManager", "type": "class", "start_line": 716, "end_line": 930, "functions": [{"name": "__init__", "type": "function", "start_line": 717, "end_line": 723, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__()\n        self.use_redis = True\n        self.use_supabase = True\n        self.pool_size = settings.config.num_graph_workers\n        self.queue = ExecutionQueue[GraphExecutionEntry]()\n        self.active_graph_runs: dict[str, tuple[Future, threading.Event]] = {}", "blocks": [{"id": 1, "label": "def __init__(self):\n    super().__init__()", "successors": [{"id": 3, "label": "    self.use_redis = True\n    self.use_supabase = True", "successors": [{"id": 5, "label": "    self.pool_size = settings.config.num_graph_workers\n    self.queue = ExecutionQueue[GraphExecutionEntry]()", "successors": [{"id": 7, "label": "    self.active_graph_runs: dict[str, tuple[Future, threading.Event]] = {}", "successors": []}]}]}]}]}, {"name": "get_port", "type": "function", "start_line": 726, "end_line": 727, "functions": [], "classes": [], "simplified_code": "    def get_port(cls) -> int:\n        return settings.config.execution_manager_port", "blocks": [{"id": 1, "label": "def get_port(cls) -> int:\nreturn settings.config.execution_manager_port", "successors": []}]}, {"name": "run_service", "type": "function", "start_line": 729, "end_line": 848, "functions": [], "classes": [], "simplified_code": "    def run_service(self):\n        from backend.integrations.credentials_store import IntegrationCredentialsStore\n\n        self.credentials_store = IntegrationCredentialsStore()\n        self.executor = ProcessPoolExecutor(\n            max_workers=self.pool_size,\n            initializer=Executor.on_graph_executor_start,\n        )\n        sync_manager = multiprocessing.Manager()\n        logger.info(\n            f\"[{self.service_name}] Started with max-{self.pool_size} graph workers\"\n        )\n        while True:\n            graph_exec_data = self.queue.get()\n            graph_exec_id = graph_exec_data.graph_exec_id\n            logger.debug(\n                f\"[ExecutionManager] Dispatching graph execution {graph_exec_id}\"\n            )\n            cancel_event = sync_manager.Event()\n            future = self.executor.submit(\n                Executor.on_graph_execution, graph_exec_data, cancel_event\n            )\n            self.active_graph_runs[graph_exec_id] = (future, cancel_event)\n            future.add_done_callback(\n                lambda _: self.active_graph_runs.pop(graph_exec_id, None)\n            )\n\n    def cleanup(self):\n        logger.info(f\"[{__class__.__name__}] \u23f3 Shutting down graph executor pool...\")\n        self.executor.shutdown(cancel_futures=True)\n\n        super().cleanup()\n\n    @property\n    def db_client(self) -> \"DatabaseManager\":\n        return get_db_client()\n\n    @expose\n    def add_execution(\n        self,\n        graph_id: str,\n        data: BlockInput,\n        user_id: str,\n        graph_version: int | None = None,\n    ) -> GraphExecutionEntry:\n        graph: GraphModel | None = self.db_client.get_graph(\n            graph_id=graph_id, user_id=user_id, version=graph_version\n        )\n        if not graph:\n            raise ValueError(f\"Graph #{graph_id} not found.\")\n\n        graph.validate_graph(for_run=True)\n        self._validate_node_input_credentials(graph, user_id)\n\n        nodes_input = []\n        for node in graph.starting_nodes:\n            input_data = {}\n            block = get_block(node.block_id)\n\n            # Invalid block & Note block should never be executed.\n            if not block or block.block_type == BlockType.NOTE:\n                continue\n\n            # Extract request input data, and assign it to the input pin.\n            if block.block_type == BlockType.INPUT:\n                name = node.input_default.get(\"name\")\n                if name and name in data:\n                    input_data = {\"value\": data[name]}\n\n            # Extract webhook payload, and assign it to the input pin\n            webhook_payload_key = f\"webhook_{node.webhook_id}_payload\"\n            if (\n                block.block_type in (BlockType.WEBHOOK, BlockType.WEBHOOK_MANUAL)\n                and node.webhook_id\n            ):\n                if webhook_payload_key not in data:\n                    raise ValueError(\n                        f\"Node {block.name} #{node.id} webhook payload is missing\"\n                    )\n                input_data = {\"payload\": data[webhook_payload_key]}\n\n            input_data, error = validate_exec(node, input_data)\n            if input_data is None:\n                raise ValueError(error)\n            else:\n                nodes_input.append((node.id, input_data))\n\n        graph_exec_id, node_execs = self.db_client.create_graph_execution(\n            graph_id=graph_id,\n            graph_version=graph.version,\n            nodes_input=nodes_input,\n            user_id=user_id,\n        )\n\n        starting_node_execs = []\n        for node_exec in node_execs:\n            starting_node_execs.append(\n                NodeExecutionEntry(\n                    user_id=user_id,\n                    graph_exec_id=node_exec.graph_exec_id,\n                    graph_id=node_exec.graph_id,\n                    node_exec_id=node_exec.node_exec_id,\n                    node_id=node_exec.node_id,\n                    data=node_exec.input_data,\n                )\n            )\n            exec_update = self.db_client.update_execution_status(\n                node_exec.node_exec_id, ExecutionStatus.QUEUED, node_exec.input_data\n            )\n            self.db_client.send_execution_update(exec_update)\n\n        graph_exec = GraphExecutionEntry(\n            user_id=user_id,\n            graph_id=graph_id,\n            graph_exec_id=graph_exec_id,\n            start_node_execs=starting_node_execs,\n        )\n        self.queue.add(graph_exec)\n\n        return graph_exec", "blocks": [{"id": 1, "label": "def run_service(self):\nfrom backend.integrations.credentials_store import IntegrationCredentialsStore\nself.credentials_store = IntegrationCredentialsStore()\nself.executor = ProcessPoolExecutor(\n    max_workers=self.pool_size,\n    initializer=Executor.on_graph_executor_start,\n)\nsync_manager = multiprocessing.Manager()\nlogger.info(f\"[{self.service_name}] Started with max-{self.pool_size} graph workers\")", "successors": [{"id": 3, "label": "while True:", "successors": [{"id": 4, "label": "graph_exec_data = self.queue.get()\ngraph_exec_id = graph_exec_data.graph_exec_id\nlogger.debug(f\"[ExecutionManager] Dispatching graph execution {graph_exec_id}\")\ncancel_event = sync_manager.Event()\nfuture = self.executor.submit(\n    Executor.on_graph_execution, graph_exec_data, cancel_event\n)\nself.active_graph_runs[graph_exec_id] = (future, cancel_event)\nfuture.add_done_callback(\n    lambda _: self.active_graph_runs.pop(graph_exec_id, None)\n)", "successors": [{"id": 3, "label": "while True:", "successors": []}]}]}]}]}, {"name": "cleanup", "type": "function", "start_line": 756, "end_line": 760, "functions": [], "classes": [], "simplified_code": "    def cleanup(self):\n        logger.info(f\"[{__class__.__name__}] \u23f3 Shutting down graph executor pool...\")\n        self.executor.shutdown(cancel_futures=True)\n\n        super().cleanup()", "blocks": [{"id": 1, "label": "def cleanup(self):\nlogger.info(f\"[{__class__.__name__}] \u23f3 Shutting down graph executor pool...\")", "successors": [{"id": 3, "label": "self.executor.shutdown(cancel_futures=True)\nsuper().cleanup()", "successors": []}]}]}, {"name": "db_client", "type": "function", "start_line": 763, "end_line": 764, "functions": [], "classes": [], "simplified_code": "    def db_client(self) -> \"DatabaseManager\":\n        return get_db_client()", "blocks": [{"id": 1, "label": "return get_db_client()", "successors": []}]}, {"name": "add_execution", "type": "function", "start_line": 767, "end_line": 848, "functions": [], "classes": [], "simplified_code": "    def add_execution(\n        self,\n        graph_id: str,\n        data: BlockInput,\n        user_id: str,\n        graph_version: int | None = None,\n    ) -> GraphExecutionEntry:\n        graph: GraphModel | None = self.db_client.get_graph(\n            graph_id=graph_id, user_id=user_id, version=graph_version\n        )\n        if not graph:\n            raise ValueError(f\"Graph #{graph_id} not found.\")\n\n        graph.validate_graph(for_run=True)\n        self._validate_node_input_credentials(graph, user_id)\n\n        nodes_input = []\n        for node in graph.starting_nodes:\n            input_data = {}\n            block = get_block(node.block_id)\n\n            # Invalid block & Note block should never be executed.\n            if not block or block.block_type == BlockType.NOTE:\n                continue\n\n            # Extract request input data, and assign it to the input pin.\n            if block.block_type == BlockType.INPUT:\n                name = node.input_default.get(\"name\")\n                if name and name in data:\n                    input_data = {\"value\": data[name]}\n\n            # Extract webhook payload, and assign it to the input pin\n            webhook_payload_key = f\"webhook_{node.webhook_id}_payload\"\n            if (\n                block.block_type in (BlockType.WEBHOOK, BlockType.WEBHOOK_MANUAL)\n                and node.webhook_id\n            ):\n                if webhook_payload_key not in data:\n                    raise ValueError(\n                        f\"Node {block.name} #{node.id} webhook payload is missing\"\n                    )\n                input_data = {\"payload\": data[webhook_payload_key]}\n\n            input_data, error = validate_exec(node, input_data)\n            if input_data is None:\n                raise ValueError(error)\n            else:\n                nodes_input.append((node.id, input_data))\n\n        graph_exec_id, node_execs = self.db_client.create_graph_execution(\n            graph_id=graph_id,\n            graph_version=graph.version,\n            nodes_input=nodes_input,\n            user_id=user_id,\n        )\n\n        starting_node_execs = []\n        for node_exec in node_execs:\n            starting_node_execs.append(\n                NodeExecutionEntry(\n                    user_id=user_id,\n                    graph_exec_id=node_exec.graph_exec_id,\n                    graph_id=node_exec.graph_id,\n                    node_exec_id=node_exec.node_exec_id,\n                    node_id=node_exec.node_id,\n                    data=node_exec.input_data,\n                )\n            )\n            exec_update = self.db_client.update_execution_status(\n                node_exec.node_exec_id, ExecutionStatus.QUEUED, node_exec.input_data\n            )\n            self.db_client.send_execution_update(exec_update)\n\n        graph_exec = GraphExecutionEntry(\n            user_id=user_id,\n            graph_id=graph_id,\n            graph_exec_id=graph_exec_id,\n            start_node_execs=starting_node_execs,\n        )\n        self.queue.add(graph_exec)\n\n        return graph_exec", "blocks": [{"id": 1, "label": "def add_execution(self, graph_id: str, data: BlockInput, user_id: str, graph_version: int | None = None) -> GraphExecutionEntry:\ngraph: GraphModel | None = self.db_client.get_graph(graph_id=graph_id, user_id=user_id, version=graph_version)", "successors": [{"id": 3, "label": "if not graph:\nraise ValueError(f\"Graph #{graph_id} not found.\")", "successors": []}, {"id": 5, "label": "graph.validate_graph(for_run=True)\nself._validate_node_input_credentials(graph, user_id)\nnodes_input = []", "successors": [{"id": 6, "label": "for node in graph.starting_nodes:", "successors": [{"id": 7, "label": "input_data = {}\nblock = get_block(node.block_id)\nif not block or block.block_type == BlockType.NOTE:", "successors": [{"id": 9, "label": "continue\n# Extract request input data, and assign it to the input pin.\nif block.block_type == BlockType.INPUT:\n    name = node.input_default.get(\"name\")\n    if name and name in data:\n        input_data = {\"value\": data[name]}", "successors": [{"id": 11, "label": "webhook_payload_key = f\"webhook_{node.webhook_id}_payload\"\nif (block.block_type in (BlockType.WEBHOOK, BlockType.WEBHOOK_MANUAL) and node.webhook_id):", "successors": [{"id": 12, "label": "if webhook_payload_key not in data:\n    raise ValueError(f\"Node {block.name} #{node.id} webhook payload is missing\")\ninput_data = {\"payload\": data[webhook_payload_key]}", "successors": []}, {"id": 13, "label": "input_data, error = validate_exec(node, input_data)\nif input_data is None:\n    raise ValueError(error)\nelse:\n    nodes_input.append((node.id, input_data))", "successors": []}]}]}]}]}, {"id": 14, "label": "graph_exec_id, node_execs = self.db_client.create_graph_execution(graph_id=graph_id, graph_version=graph.version, nodes_input=nodes_input, user_id=user_id)\nstarting_node_execs = []", "successors": [{"id": 16, "label": "for node_exec in node_execs:", "successors": [{"id": 17, "label": "starting_node_execs.append(NodeExecutionEntry(user_id=user_id, graph_exec_id=node_exec.graph_exec_id, graph_id=node_exec.graph_id, node_exec_id=node_exec.node_exec_id, node_id=node_exec.node_id, data=node_exec.input_data))\nexec_update = self.db_client.update_execution_status(node_exec.node_exec_id, ExecutionStatus.QUEUED, node_exec.input_data)\nself.db_client.send_execution_update(exec_update)", "successors": []}]}, {"id": 19, "label": "graph_exec = GraphExecutionEntry(user_id=user_id, graph_id=graph_id, graph_exec_id=graph_exec_id, start_node_execs=starting_node_execs)\nself.queue.add(graph_exec)\nreturn graph_exec", "successors": []}]}]}]}]}, {"name": "cancel_execution", "type": "function", "start_line": 851, "end_line": 885, "functions": [], "classes": [], "simplified_code": "    def cancel_execution(self, graph_exec_id: str) -> None:\n        \"\"\"\n        Mechanism:\n        1. Set the cancel event\n        2. Graph executor's cancel handler thread detects the event, terminates workers,\n           reinitializes worker pool, and returns.\n        3. Update execution statuses in DB and set `error` outputs to `\"TERMINATED\"`.\n        \"\"\"\n        if graph_exec_id not in self.active_graph_runs:\n            raise Exception(\n                f\"Graph execution #{graph_exec_id} not active/running: \"\n                \"possibly already completed/cancelled.\"\n            )\n\n        future, cancel_event = self.active_graph_runs[graph_exec_id]\n        if cancel_event.is_set():\n            return\n\n        cancel_event.set()\n        future.result()\n\n        # Update the status of the unfinished node executions\n        node_execs = self.db_client.get_execution_results(graph_exec_id)\n        for node_exec in node_execs:\n            if node_exec.status not in (\n                ExecutionStatus.COMPLETED,\n                ExecutionStatus.FAILED,\n            ):\n                self.db_client.upsert_execution_output(\n                    node_exec.node_exec_id, \"error\", \"TERMINATED\"\n                )\n                exec_update = self.db_client.update_execution_status(\n                    node_exec.node_exec_id, ExecutionStatus.FAILED\n                )\n                self.db_client.send_execution_update(exec_update)", "blocks": [{"id": 1, "label": "def cancel_execution(self, graph_exec_id: str) -> None:\nif graph_exec_id not in self.active_graph_runs:", "successors": [{"id": 3, "label": "raise Exception( f\"Graph execution #{graph_exec_id} not active/running: \" \"possibly already completed/cancelled.\")", "successors": []}, {"id": 4, "label": "future, cancel_event = self.active_graph_runs[graph_exec_id]\nif cancel_event.is_set():", "successors": [{"id": 6, "label": "return", "successors": []}, {"id": 7, "label": "cancel_event.set()\nfuture.result()", "successors": [{"id": 9, "label": "node_execs = self.db_client.get_execution_results(graph_exec_id)", "successors": [{"id": 10, "label": "for node_exec in node_execs:", "successors": [{"id": 11, "label": "if node_exec.status not in ( ExecutionStatus.COMPLETED, ExecutionStatus.FAILED, ):\nself.db_client.upsert_execution_output( node_exec.node_exec_id, \"error\", \"TERMINATED\" )", "successors": [{"id": 13, "label": "exec_update = self.db_client.update_execution_status( node_exec.node_exec_id, ExecutionStatus.FAILED )\nself.db_client.send_execution_update(exec_update)", "successors": []}]}]}]}]}]}]}]}, {"name": "_validate_node_input_credentials", "type": "function", "start_line": 887, "end_line": 930, "functions": [], "classes": [], "simplified_code": "    def _validate_node_input_credentials(self, graph: GraphModel, user_id: str):\n        \"\"\"Checks all credentials for all nodes of the graph\"\"\"\n\n        for node in graph.nodes:\n            block = get_block(node.block_id)\n            if not block:\n                raise ValueError(f\"Unknown block {node.block_id} for node #{node.id}\")\n\n            # Find any fields of type CredentialsMetaInput\n            model_fields = cast(type[BaseModel], block.input_schema).model_fields\n            if CREDENTIALS_FIELD_NAME not in model_fields:\n                continue\n\n            field = model_fields[CREDENTIALS_FIELD_NAME]\n\n            # The BlockSchema class enforces that a `credentials` field is always a\n            # `CredentialsMetaInput`, so we can safely assume this here.\n            credentials_meta_type = cast(CredentialsMetaInput, field.annotation)\n            credentials_meta = credentials_meta_type.model_validate(\n                node.input_default[CREDENTIALS_FIELD_NAME]\n            )\n            # Fetch the corresponding Credentials and perform sanity checks\n            credentials = self.credentials_store.get_creds_by_id(\n                user_id, credentials_meta.id\n            )\n            if not credentials:\n                raise ValueError(\n                    f\"Unknown credentials #{credentials_meta.id} \"\n                    f\"for node #{node.id}\"\n                )\n            if (\n                credentials.provider != credentials_meta.provider\n                or credentials.type != credentials_meta.type\n            ):\n                logger.warning(\n                    f\"Invalid credentials #{credentials.id} for node #{node.id}: \"\n                    \"type/provider mismatch: \"\n                    f\"{credentials_meta.type}<>{credentials.type};\"\n                    f\"{credentials_meta.provider}<>{credentials.provider}\"\n                )\n                raise ValueError(\n                    f\"Invalid credentials #{credentials.id} for node #{node.id}: \"\n                    \"type/provider mismatch\"\n                )", "blocks": [{"id": 1, "label": "def _validate_node_input_credentials(self, graph: GraphModel, user_id: str):", "successors": [{"id": 2, "label": "for node in graph.nodes:", "successors": [{"id": 3, "label": "block = get_block(node.block_id)", "successors": [{"id": 4, "label": "if not block:\nraise ValueError(f\"Unknown block {node.block_id} for node #{node.id}\")", "successors": []}, {"id": 6, "label": "model_fields = cast(type[BaseModel], block.input_schema).model_fields", "successors": [{"id": 7, "label": "if CREDENTIALS_FIELD_NAME not in model_fields:\ncontinue", "successors": [{"id": 3, "label": "block = get_block(node.block_id)", "successors": []}]}, {"id": 9, "label": "field = model_fields[CREDENTIALS_FIELD_NAME]\ncredentials_meta_type = cast(CredentialsMetaInput, field.annotation)", "successors": [{"id": 11, "label": "credentials_meta = credentials_meta_type.model_validate(node.input_default[CREDENTIALS_FIELD_NAME])\ncredentials = self.credentials_store.get_creds_by_id(user_id, credentials_meta.id)", "successors": [{"id": 13, "label": "if not credentials:\nraise ValueError(f\"Unknown credentials #{credentials_meta.id} for node #{node.id}\")", "successors": []}, {"id": 15, "label": "if (credentials.provider != credentials_meta.provider or credentials.type != credentials_meta.type):\nlogger.warning(f\"Invalid credentials #{credentials.id} for node #{node.id}: type/provider mismatch: {credentials_meta.type}<>{credentials.type};{credentials_meta.provider}<>{credentials.provider}\")", "successors": [{"id": 17, "label": "raise ValueError(f\"Invalid credentials #{credentials.id} for node #{node.id}: type/provider mismatch\")", "successors": []}]}]}]}]}]}]}]}]}], "classes": [], "simplified_code": "class ExecutionManager(AppService):\n        self.active_graph_runs: dict[str, tuple[Future, threading.Event]] = {}\n\n    @classmethod\n        return settings.config.execution_manager_port\n\n        return graph_exec\n\n    @expose\n                self.db_client.send_execution_update(exec_update)\n\n                )", "blocks": [{"id": 1, "label": "class ExecutionManager(AppService):\nself.active_graph_runs: dict[str, tuple[Future, threading.Event]] = {}", "successors": [{"id": 3, "label": "@classmethod\nreturn settings.config.execution_manager_port", "successors": [{"id": 5, "label": "return graph_exec\n@expose", "successors": [{"id": 7, "label": "self.db_client.send_execution_update(exec_update)", "successors": []}]}]}]}]}], "simplified_code": "import atexit\nimport logging\nimport multiprocessing\nimport os\nimport signal\nimport sys\nimport threading\nfrom concurrent.futures import Future, ProcessPoolExecutor\nfrom contextlib import contextmanager\nfrom multiprocessing.pool import AsyncResult, Pool\nfrom typing import TYPE_CHECKING, Any, Generator, TypeVar, cast\n\nfrom pydantic import BaseModel\nfrom redis.lock import Lock as RedisLock\n\nif TYPE_CHECKING:\n    from backend.executor import DatabaseManager\n\nfrom autogpt_libs.utils.cache import thread_cached\n\nfrom backend.blocks.agent import AgentExecutorBlock\nfrom backend.data import redis\nfrom backend.data.block import Block, BlockData, BlockInput, BlockType, get_block\nfrom backend.data.execution import (\n    ExecutionQueue,\n    ExecutionResult,\n    ExecutionStatus,\n    GraphExecutionEntry,\n    NodeExecutionEntry,\n    merge_execution_input,\n    parse_execution_output,\n)\nfrom backend.data.graph import GraphModel, Link, Node\nfrom backend.data.model import CREDENTIALS_FIELD_NAME, CredentialsMetaInput\nfrom backend.integrations.creds_manager import IntegrationCredentialsManager\nfrom backend.util import json\nfrom backend.util.decorator import error_logged, time_measured\nfrom backend.util.logging import configure_logging\nfrom backend.util.process import set_service_name\nfrom backend.util.service import (\n    AppService,\n    close_service_client,\n    expose,\n    get_service_client,\n)\nfrom backend.util.settings import Settings\nfrom backend.util.type import convert\n\nlogger = logging.getLogger(__name__)\nsettings = Settings()\n\n\n        return f\"{self.prefix} {msg} {extra}\"\n\n\nT = TypeVar(\"T\")\nExecutionStream = Generator[NodeExecutionEntry, None, None]\n\n\n\n\n    ]\n\n\n    return data, node_block.name\n\n\n            cancel_thread.join()\n            return exec_stats, error\n\n\n                )\n\n\n# ------- UTILITIES ------- #\n\n\n@thread_cached\n    return get_service_client(DatabaseManager)\n\n\n            lock.release()\n\n\n        os.write(sys.stdout.fileno(), (message + \"\\n\").encode())", "blocks": [{"id": 1, "label": "import atexit\nimport logging\nimport multiprocessing\nimport os\nimport signal\nimport sys\nimport threading\nfrom concurrent.futures import Future, ProcessPoolExecutor\nfrom contextlib import contextmanager\nfrom multiprocessing.pool import AsyncResult, Pool\nfrom typing import TYPE_CHECKING, Any, Generator, TypeVar, cast\n\nfrom pydantic import BaseModel\nfrom redis.lock import Lock as RedisLock\n\nif TYPE_CHECKING:\n    from backend.executor import DatabaseManager\n\nfrom autogpt_libs.utils.cache import thread_cached\n\nfrom backend.blocks.agent import AgentExecutorBlock\nfrom backend.data import redis\nfrom backend.data.block import Block, BlockData, BlockInput, BlockType, get_block\nfrom backend.data.execution import (\n    ExecutionQueue,\n    ExecutionResult,\n    ExecutionStatus,\n    GraphExecutionEntry,\n    NodeExecutionEntry,\n    merge_execution_input,\n    parse_execution_output,\n)\nfrom backend.data.graph import GraphModel, Link, Node\nfrom backend.data.model import CREDENTIALS_FIELD_NAME, CredentialsMetaInput\nfrom backend.integrations.creds_manager import IntegrationCredentialsManager\nfrom backend.util import json\nfrom backend.util.decorator import error_logged, time_measured\nfrom backend.util.logging import configure_logging\nfrom backend.util.process import set_service_name\nfrom backend.util.service import (\n    AppService,\n    close_service_client,\n    expose,\n    get_service_client,\n)\nfrom backend.util.settings import Settings\nfrom backend.util.type import convert\n\nlogger = logging.getLogger(__name__)\nsettings = Settings()\nreturn f\"{self.prefix} {msg} {extra}\"", "successors": []}]}
{"file_name": "5.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 66, "functions": [{"name": "generate_sum_of_subsets_soln", "type": "function", "start_line": 13, "end_line": 19, "functions": [], "classes": [], "simplified_code": "def generate_sum_of_subsets_soln(nums: list[int], max_sum: int) -> list[list[int]]:\n    result: list[list[int]] = []\n    path: list[int] = []\n    num_index = 0\n    remaining_nums_sum = sum(nums)\n    create_state_space_tree(nums, max_sum, num_index, path, result, remaining_nums_sum)\n    return result", "blocks": [{"id": 1, "label": "def generate_sum_of_subsets_soln(nums: list[int], max_sum: int) -> list[list[int]]:\n    result: list[list[int]] = []\n    path: list[int] = []\n    num_index = 0\n    remaining_nums_sum = sum(nums)", "successors": [{"id": 3, "label": "    create_state_space_tree(nums, max_sum, num_index, path, result, remaining_nums_sum)\n    return result", "successors": []}]}]}, {"name": "create_state_space_tree", "type": "function", "start_line": 22, "end_line": 51, "functions": [], "classes": [], "simplified_code": "def create_state_space_tree(\n    nums: list[int],\n    max_sum: int,\n    num_index: int,\n    path: list[int],\n    result: list[list[int]],\n    remaining_nums_sum: int,\n) -> None:\n    \"\"\"\n    Creates a state space tree to iterate through each branch using DFS.\n    It terminates the branching of a node when any of the two conditions\n    given below satisfy.\n    This algorithm follows depth-fist-search and backtracks when the node is not\n    branchable.\n\n    \"\"\"\n    if sum(path) > max_sum or (remaining_nums_sum + sum(path)) < max_sum:\n        return\n    if sum(path) == max_sum:\n        result.append(path)\n        return\n    for index in range(num_index, len(nums)):\n        create_state_space_tree(\n            nums,\n            max_sum,\n            index + 1,\n            [*path, nums[index]],\n            result,\n            remaining_nums_sum - nums[index],\n        )", "blocks": [{"id": 1, "label": "def create_state_space_tree(\n    nums: list[int],\n    max_sum: int,\n    num_index: int,\n    path: list[int],\n    result: list[list[int]],\n    remaining_nums_sum: int,\n) -> None:\n    \"\"\"\n    Creates a state space tree to iterate through each branch using DFS.\n    It terminates the branching of a node when any of the two conditions\n    given below satisfy.\n    This algorithm follows depth-fist-search and backtracks when the node is not\n    branchable.\n\n    \"\"\"", "successors": [{"id": 3, "label": "    if sum(path) > max_sum or (remaining_nums_sum + sum(path)) < max_sum:\n        return", "successors": []}, {"id": 5, "label": "    if sum(path) == max_sum:\n        result.append(path)", "successors": [{"id": 7, "label": "        return", "successors": []}]}, {"id": 8, "label": "    for index in range(num_index, len(nums)):", "successors": [{"id": 9, "label": "        create_state_space_tree(\n            nums,\n            max_sum,\n            index + 1,\n            [*path, nums[index]],\n            result,\n            remaining_nums_sum - nums[index],\n        )", "successors": []}]}]}]}], "classes": [], "simplified_code": "\"\"\"\nThe sum-of-subsetsproblem states that a set of non-negative integers, and a\nvalue M, determine all possible subsets of the given set whose summation sum\nequal to given M.\n\nSummation of the chosen numbers must be equal to given number M and one number\ncan be used only once.\n\"\"\"\n\nfrom __future__ import annotations\n\n\n    return result\n\n\n        )\n\n\n\"\"\"\nremove the comment to take an input from the user\n\nprint(\"Enter the elements\")\nnums = list(map(int, input().split()))\nprint(\"Enter max_sum sum\")\nmax_sum = int(input())\n\n\"\"\"\nnums = [3, 34, 4, 12, 5, 2]\nmax_sum = 9\nresult = generate_sum_of_subsets_soln(nums, max_sum)\nprint(*result)", "blocks": [{"id": 1, "label": "nums = [3, 34, 4, 12, 5, 2]\nmax_sum = 9", "successors": [{"id": 3, "label": "result = generate_sum_of_subsets_soln(nums, max_sum)\nprint(*result)", "successors": []}]}]}
{"file_name": "6.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 59, "functions": [], "classes": [{"name": "FactCheckerBlock", "type": "class", "start_line": 14, "end_line": 59, "functions": [{"name": "__init__", "type": "function", "start_line": 29, "end_line": 36, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"d38b6c5e-9968-4271-8423-6cfe60d6e7e6\",\n            description=\"This block checks the factuality of a given statement using Jina AI's Grounding API.\",\n            categories={BlockCategory.SEARCH},\n            input_schema=FactCheckerBlock.Input,\n            output_schema=FactCheckerBlock.Output,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"d38b6c5e-9968-4271-8423-6cfe60d6e7e6\",\n    description=\"This block checks the factuality of a given statement using Jina AI's Grounding API.\",\n    categories={BlockCategory.SEARCH},\n    input_schema=FactCheckerBlock.Input,\n    output_schema=FactCheckerBlock.Output,\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 38, "end_line": 59, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: JinaCredentials, **kwargs\n    ) -> BlockOutput:\n        encoded_statement = quote(input_data.statement)\n        url = f\"https://g.jina.ai/{encoded_statement}\"\n\n        headers = {\n            \"Accept\": \"application/json\",\n            \"Authorization\": f\"Bearer {credentials.api_key.get_secret_value()}\",\n        }\n\n        response = requests.get(url, headers=headers)\n        response.raise_for_status()\n        data = response.json()\n\n        if \"data\" in data:\n            data = data[\"data\"]\n            yield \"factuality\", data[\"factuality\"]\n            yield \"result\", data[\"result\"]\n            yield \"reason\", data[\"reason\"]\n        else:\n            raise RuntimeError(f\"Expected 'data' key not found in response: {data}\")", "blocks": [{"id": 1, "label": "encoded_statement = quote(input_data.statement)\nurl = f\"https://g.jina.ai/{encoded_statement}\"\n\nheaders = {\n    \"Accept\": \"application/json\",\n    \"Authorization\": f\"Bearer {credentials.api_key.get_secret_value()}\",\n}\n\nresponse = requests.get(url, headers=headers)\nresponse.raise_for_status()\ndata = response.json()\nif \"data\" in data:", "successors": [{"id": 3, "label": "    data = data[\"data\"]\n    yield \"factuality\", data[\"factuality\"]\n    yield \"result\", data[\"result\"]\n    yield \"reason\", data[\"reason\"]", "successors": []}, {"id": 4, "label": "else:\n    raise RuntimeError(f\"Expected 'data' key not found in response: {data}\")", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 15, "end_line": 19, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        statement: str = SchemaField(\n            description=\"The statement to check for factuality\"\n        )\n        credentials: JinaCredentialsInput = JinaCredentialsField()", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    statement: str = SchemaField(description=\"The statement to check for factuality\")", "successors": []}, {"id": 3, "label": "    credentials: JinaCredentialsInput = JinaCredentialsField()", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 21, "end_line": 27, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        factuality: float = SchemaField(\n            description=\"The factuality score of the statement\"\n        )\n        result: bool = SchemaField(description=\"The result of the factuality check\")\n        reason: str = SchemaField(description=\"The reason for the factuality result\")\n        error: str = SchemaField(description=\"Error message if the check fails\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "factuality: float = SchemaField(description=\"The factuality score of the statement\")", "successors": []}, {"id": 3, "label": "result: bool = SchemaField(description=\"The result of the factuality check\")", "successors": []}, {"id": 4, "label": "reason: str = SchemaField(description=\"The reason for the factuality result\")", "successors": []}, {"id": 5, "label": "error: str = SchemaField(description=\"Error message if the check fails\")", "successors": []}]}]}], "simplified_code": "class FactCheckerBlock(Block):\n        credentials: JinaCredentialsInput = JinaCredentialsField()\n\n        error: str = SchemaField(description=\"Error message if the check fails\")\n\n        )\n\n            raise RuntimeError(f\"Expected 'data' key not found in response: {data}\")", "blocks": [{"id": 1, "label": "class FactCheckerBlock(Block):\n    credentials: JinaCredentialsInput = JinaCredentialsField()", "successors": [{"id": 3, "label": "    error: str = SchemaField(description=\"Error message if the check fails\")\nraise RuntimeError(f\"Expected 'data' key not found in response: {data}\")", "successors": []}]}]}], "simplified_code": "from urllib.parse import quote\n\nimport requests\n\nfrom backend.blocks.jina._auth import (\n    JinaCredentials,\n    JinaCredentialsField,\n    JinaCredentialsInput,\n)\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\n\n            raise RuntimeError(f\"Expected 'data' key not found in response: {data}\")", "blocks": [{"id": 1, "label": "from urllib.parse import quote\nimport requests", "successors": [{"id": 3, "label": "from backend.blocks.jina._auth import ( JinaCredentials, JinaCredentialsField, JinaCredentialsInput, )\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema", "successors": [{"id": 5, "label": "from backend.data.model import SchemaField\nraise RuntimeError(f\"Expected 'data' key not found in response: {data}\")", "successors": []}]}]}]}
{"file_name": "7.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 234, "functions": [{"name": "get_user_credit_model", "type": "function", "start_line": 226, "end_line": 230, "functions": [], "classes": [], "simplified_code": "def get_user_credit_model() -> UserCreditBase:\n    if config.enable_credit.lower() == \"true\":\n        return UserCredit(config.num_user_credits_refill)\n    else:\n        return DisabledUserCredit(0)", "blocks": [{"id": 1, "label": "def get_user_credit_model() -> UserCreditBase:\nif config.enable_credit.lower() == \"true\":", "successors": [{"id": 3, "label": "return UserCredit(config.num_user_credits_refill)", "successors": []}, {"id": 4, "label": "return DisabledUserCredit(0)", "successors": []}]}]}, {"name": "get_block_costs", "type": "function", "start_line": 233, "end_line": 234, "functions": [], "classes": [], "simplified_code": "def get_block_costs() -> dict[str, list[BlockCost]]:\n    return {block().id: costs for block, costs in BLOCK_COSTS.items()}", "blocks": [{"id": 1, "label": "def get_block_costs() -> dict[str, list[BlockCost]]:\nreturn {block().id: costs for block, costs in BLOCK_COSTS.items()}", "successors": []}]}], "classes": [{"name": "UserCreditBase", "type": "class", "start_line": 17, "end_line": 66, "functions": [{"name": "__init__", "type": "function", "start_line": 18, "end_line": 19, "functions": [], "classes": [], "simplified_code": "    def __init__(self, num_user_credits_refill: int):\n        self.num_user_credits_refill = num_user_credits_refill", "blocks": [{"id": 1, "label": "def __init__(self, num_user_credits_refill: int):\n    self.num_user_credits_refill = num_user_credits_refill", "successors": []}]}, {"name": "get_or_refill_credit", "type": "function", "start_line": 22, "end_line": 29, "functions": [], "classes": [], "simplified_code": "    async def get_or_refill_credit(self, user_id: str) -> int:\n        \"\"\"\n        Get the current credit for the user and refill if no transaction has been made in the current cycle.\n\n        Returns:\n            int: The current credit for the user.\n        \"\"\"\n        pass", "blocks": [{"id": 1, "label": "async def get_or_refill_credit(self, user_id: str) -> int:\n\"\"\"\nGet the current credit for the user and refill if no transaction has been made in the current cycle.\n\nReturns:\n    int: The current credit for the user.\n\"\"\"", "successors": [{"id": 3, "label": "pass", "successors": []}]}]}, {"name": "spend_credits", "type": "function", "start_line": 32, "end_line": 55, "functions": [], "classes": [], "simplified_code": "    async def spend_credits(\n        self,\n        user_id: str,\n        user_credit: int,\n        block_id: str,\n        input_data: BlockInput,\n        data_size: float,\n        run_time: float,\n    ) -> int:\n        \"\"\"\n        Spend the credits for the user based on the block usage.\n\n        Args:\n            user_id (str): The user ID.\n            user_credit (int): The current credit for the user.\n            block_id (str): The block ID.\n            input_data (BlockInput): The input data for the block.\n            data_size (float): The size of the data being processed.\n            run_time (float): The time taken to run the block.\n\n        Returns:\n            int: amount of credit spent\n        \"\"\"\n        pass", "blocks": [{"id": 1, "label": "async def spend_credits(\n    self,\n    user_id: str,\n    user_credit: int,\n    block_id: str,\n    input_data: BlockInput,\n    data_size: float,\n    run_time: float,\n) -> int:\n\"\"\"\nSpend the credits for the user based on the block usage.\n\nArgs:\n    user_id (str): The user ID.\n    user_credit (int): The current credit for the user.\n    block_id (str): The block ID.\n    input_data (BlockInput): The input data for the block.\n    data_size (float): The size of the data being processed.\n    run_time (float): The time taken to run the block.\n\nReturns:\n    int: amount of credit spent\n\"\"\"", "successors": [{"id": 3, "label": "pass", "successors": []}]}]}, {"name": "top_up_credits", "type": "function", "start_line": 58, "end_line": 66, "functions": [], "classes": [], "simplified_code": "    async def top_up_credits(self, user_id: str, amount: int):\n        \"\"\"\n        Top up the credits for the user.\n\n        Args:\n            user_id (str): The user ID.\n            amount (int): The amount to top up.\n        \"\"\"\n        pass", "blocks": [{"id": 1, "label": "async def top_up_credits(self, user_id: str, amount: int):\n\"\"\"\nTop up the credits for the user.\n\nArgs:\n    user_id (str): The user ID.\n    amount (int): The amount to top up.\n\"\"\"", "successors": [{"id": 3, "label": "pass", "successors": []}]}]}], "simplified_code": "class UserCreditBase(ABC):\n        self.num_user_credits_refill = num_user_credits_refill\n\n    @abstractmethod\n        pass\n\n    @abstractmethod\n        pass\n\n    @abstractmethod\n        pass", "blocks": [{"id": 1, "label": "class UserCreditBase(ABC):", "successors": [{"id": 2, "label": "    self.num_user_credits_refill = num_user_credits_refill", "successors": []}, {"id": 3, "label": "    @abstractmethod\n    pass", "successors": []}, {"id": 5, "label": "    @abstractmethod\n    pass", "successors": []}, {"id": 7, "label": "    @abstractmethod\n    pass", "successors": []}]}]}, {"name": "UserCredit", "type": "class", "start_line": 69, "end_line": 212, "functions": [{"name": "get_or_refill_credit", "type": "function", "start_line": 70, "end_line": 108, "functions": [], "classes": [], "simplified_code": "    async def get_or_refill_credit(self, user_id: str) -> int:\n        cur_time = self.time_now()\n        cur_month = cur_time.replace(day=1, hour=0, minute=0, second=0, microsecond=0)\n        nxt_month = (\n            cur_month.replace(month=cur_month.month + 1)\n            if cur_month.month < 12\n            else cur_month.replace(year=cur_month.year + 1, month=1)\n        )\n\n        user_credit = await CreditTransaction.prisma().group_by(\n            by=[\"userId\"],\n            sum={\"amount\": True},\n            where={\n                \"userId\": user_id,\n                \"createdAt\": {\"gte\": cur_month, \"lt\": nxt_month},\n                \"isActive\": True,\n            },\n        )\n\n        if user_credit:\n            credit_sum = user_credit[0].get(\"_sum\") or {}\n            return credit_sum.get(\"amount\", 0)\n\n        key = f\"MONTHLY-CREDIT-TOP-UP-{cur_month}\"\n\n        try:\n            await CreditTransaction.prisma().create(\n                data={\n                    \"amount\": self.num_user_credits_refill,\n                    \"type\": CreditTransactionType.TOP_UP,\n                    \"userId\": user_id,\n                    \"transactionKey\": key,\n                    \"createdAt\": self.time_now(),\n                }\n            )\n        except UniqueViolationError:\n            pass  # Already refilled this month\n\n        return self.num_user_credits_refill", "blocks": [{"id": 1, "label": "async def get_or_refill_credit(self, user_id: str) -> int:\n    cur_time = self.time_now()\n    cur_month = cur_time.replace(day=1, hour=0, minute=0, second=0, microsecond=0)\n    nxt_month = (\n        cur_month.replace(month=cur_month.month + 1)\n        if cur_month.month < 12\n        else cur_month.replace(year=cur_month.year + 1, month=1)\n    )\n\n    user_credit = await CreditTransaction.prisma().group_by(\n        by=[\"userId\"],\n        sum={\"amount\": True},\n        where={\n            \"userId\": user_id,\n            \"createdAt\": {\"gte\": cur_month, \"lt\": nxt_month},\n            \"isActive\": True,\n        },\n    )\nif user_credit:", "successors": [{"id": 3, "label": "    credit_sum = user_credit[0].get(\"_sum\") or {}\n    return credit_sum.get(\"amount\", 0)", "successors": []}, {"id": 4, "label": "key = f\"MONTHLY-CREDIT-TOP-UP-{cur_month}\"\ntry:\n    await CreditTransaction.prisma().create(\n        data={\n            \"amount\": self.num_user_credits_refill,\n            \"type\": CreditTransactionType.TOP_UP,\n            \"userId\": user_id,\n            \"transactionKey\": key,\n            \"createdAt\": self.time_now(),\n        }\n    )", "successors": [{"id": 6, "label": "except UniqueViolationError:\n    pass  # Already refilled this month", "successors": []}, {"id": 7, "label": "return self.num_user_credits_refill", "successors": []}]}]}]}, {"name": "time_now", "type": "function", "start_line": 111, "end_line": 112, "functions": [], "classes": [], "simplified_code": "    def time_now():\n        return datetime.now(timezone.utc)", "blocks": [{"id": 1, "label": "def time_now():\n    return datetime.now(timezone.utc)", "successors": []}]}, {"name": "_block_usage_cost", "type": "function", "start_line": 114, "end_line": 144, "functions": [], "classes": [], "simplified_code": "    def _block_usage_cost(\n        self,\n        block: Block,\n        input_data: BlockInput,\n        data_size: float,\n        run_time: float,\n    ) -> tuple[int, BlockInput]:\n        block_costs = BLOCK_COSTS.get(type(block))\n        if not block_costs:\n            return 0, {}\n\n        for block_cost in block_costs:\n            if not self._is_cost_filter_match(block_cost.cost_filter, input_data):\n                continue\n\n            if block_cost.cost_type == BlockCostType.RUN:\n                return block_cost.cost_amount, block_cost.cost_filter\n\n            if block_cost.cost_type == BlockCostType.SECOND:\n                return (\n                    int(run_time * block_cost.cost_amount),\n                    block_cost.cost_filter,\n                )\n\n            if block_cost.cost_type == BlockCostType.BYTE:\n                return (\n                    int(data_size * block_cost.cost_amount),\n                    block_cost.cost_filter,\n                )\n\n        return 0, {}", "blocks": [{"id": 1, "label": "block_costs = BLOCK_COSTS.get(type(block))\nif not block_costs:", "successors": [{"id": 3, "label": "return 0, {}", "successors": []}, {"id": 4, "label": "for block_cost in block_costs:", "successors": [{"id": 5, "label": "if not self._is_cost_filter_match(block_cost.cost_filter, input_data):\ncontinue", "successors": [{"id": 7, "label": "if block_cost.cost_type == BlockCostType.RUN:", "successors": [{"id": 8, "label": "return block_cost.cost_amount, block_cost.cost_filter", "successors": []}, {"id": 9, "label": "if block_cost.cost_type == BlockCostType.SECOND:", "successors": [{"id": 10, "label": "return (\n    int(run_time * block_cost.cost_amount),\n    block_cost.cost_filter,\n)", "successors": []}, {"id": 11, "label": "if block_cost.cost_type == BlockCostType.BYTE:", "successors": [{"id": 12, "label": "return (\n    int(data_size * block_cost.cost_amount),\n    block_cost.cost_filter,\n)", "successors": []}, {"id": 13, "label": "return 0, {}", "successors": []}]}]}]}]}]}]}]}, {"name": "_is_cost_filter_match", "type": "function", "start_line": 146, "end_line": 162, "functions": [], "classes": [], "simplified_code": "    def _is_cost_filter_match(\n        self, cost_filter: BlockInput, input_data: BlockInput\n    ) -> bool:\n        \"\"\"\n        Filter rules:\n          - If costFilter is an object, then check if costFilter is the subset of inputValues\n          - Otherwise, check if costFilter is equal to inputValues.\n          - Undefined, null, and empty string are considered as equal.\n        \"\"\"\n        if not isinstance(cost_filter, dict) or not isinstance(input_data, dict):\n            return cost_filter == input_data\n\n        return all(\n            (not input_data.get(k) and not v)\n            or (input_data.get(k) and self._is_cost_filter_match(v, input_data[k]))\n            for k, v in cost_filter.items()\n        )", "blocks": [{"id": 1, "label": "if not isinstance(cost_filter, dict) or not isinstance(input_data, dict):", "successors": [{"id": 2, "label": "    return cost_filter == input_data", "successors": []}, {"id": 3, "label": "return all(\n    (not input_data.get(k) and not v)\n    or (input_data.get(k) and self._is_cost_filter_match(v, input_data[k]))\n    for k, v in cost_filter.items()\n)", "successors": []}]}]}, {"name": "spend_credits", "type": "function", "start_line": 164, "end_line": 202, "functions": [], "classes": [], "simplified_code": "    async def spend_credits(\n        self,\n        user_id: str,\n        user_credit: int,\n        block_id: str,\n        input_data: BlockInput,\n        data_size: float,\n        run_time: float,\n        validate_balance: bool = True,\n    ) -> int:\n        block = get_block(block_id)\n        if not block:\n            raise ValueError(f\"Block not found: {block_id}\")\n\n        cost, matching_filter = self._block_usage_cost(\n            block=block, input_data=input_data, data_size=data_size, run_time=run_time\n        )\n        if cost <= 0:\n            return 0\n\n        if validate_balance and user_credit < cost:\n            raise ValueError(f\"Insufficient credit: {user_credit} < {cost}\")\n\n        await CreditTransaction.prisma().create(\n            data={\n                \"userId\": user_id,\n                \"amount\": -cost,\n                \"type\": CreditTransactionType.USAGE,\n                \"blockId\": block.id,\n                \"metadata\": Json(\n                    {\n                        \"block\": block.name,\n                        \"input\": matching_filter,\n                    }\n                ),\n                \"createdAt\": self.time_now(),\n            }\n        )\n        return cost", "blocks": [{"id": 1, "label": "block = get_block(block_id)\nif not block:", "successors": [{"id": 3, "label": "raise ValueError(f\"Block not found: {block_id}\")", "successors": []}, {"id": 4, "label": "cost, matching_filter = self._block_usage_cost(block=block, input_data=input_data, data_size=data_size, run_time=run_time)\nif cost <= 0:", "successors": [{"id": 6, "label": "return 0", "successors": []}, {"id": 7, "label": "if validate_balance and user_credit < cost:", "successors": [{"id": 8, "label": "raise ValueError(f\"Insufficient credit: {user_credit} < {cost}\")", "successors": []}, {"id": 9, "label": "await CreditTransaction.prisma().create(data={\"userId\": user_id, \"amount\": -cost, \"type\": CreditTransactionType.USAGE, \"blockId\": block.id, \"metadata\": Json({\"block\": block.name, \"input\": matching_filter}), \"createdAt\": self.time_now()})\nreturn cost", "successors": []}]}]}]}]}, {"name": "top_up_credits", "type": "function", "start_line": 204, "end_line": 212, "functions": [], "classes": [], "simplified_code": "    async def top_up_credits(self, user_id: str, amount: int):\n        await CreditTransaction.prisma().create(\n            data={\n                \"userId\": user_id,\n                \"amount\": amount,\n                \"type\": CreditTransactionType.TOP_UP,\n                \"createdAt\": self.time_now(),\n            }\n        )", "blocks": [{"id": 1, "label": "async def top_up_credits(self, user_id: str, amount: int):\n    await CreditTransaction.prisma().create(\n        data={\n            \"userId\": user_id,\n            \"amount\": amount,\n            \"type\": CreditTransactionType.TOP_UP,\n            \"createdAt\": self.time_now(),\n        }\n    )", "successors": []}]}], "simplified_code": "class UserCredit(UserCreditBase):\n        return self.num_user_credits_refill\n\n    @staticmethod\n        return datetime.now(timezone.utc)\n\n        return 0, {}\n\n        )\n\n        return cost\n\n        )", "blocks": [{"id": 1, "label": "class UserCredit(UserCreditBase):\n    def get_refill_credits(self):\n        return self.num_user_credits_refill", "successors": []}]}, {"name": "DisabledUserCredit", "type": "class", "start_line": 215, "end_line": 223, "functions": [{"name": "get_or_refill_credit", "type": "function", "start_line": 216, "end_line": 217, "functions": [], "classes": [], "simplified_code": "    async def get_or_refill_credit(self, *args, **kwargs) -> int:\n        return 0", "blocks": [{"id": 1, "label": "async def get_or_refill_credit(self, *args, **kwargs) -> int:\n    return 0", "successors": []}]}, {"name": "spend_credits", "type": "function", "start_line": 219, "end_line": 220, "functions": [], "classes": [], "simplified_code": "    async def spend_credits(self, *args, **kwargs) -> int:\n        return 0", "blocks": [{"id": 1, "label": "async def spend_credits(self, *args, **kwargs) -> int:\nreturn 0", "successors": []}]}, {"name": "top_up_credits", "type": "function", "start_line": 222, "end_line": 223, "functions": [], "classes": [], "simplified_code": "    async def top_up_credits(self, *args, **kwargs):\n        pass", "blocks": [{"id": 1, "label": "async def top_up_credits(self, *args, **kwargs):\npass", "successors": []}]}], "simplified_code": "class DisabledUserCredit(UserCreditBase):\n        return 0\n\n        return 0\n\n        pass", "blocks": [{"id": 1, "label": "class DisabledUserCredit(UserCreditBase):", "successors": [{"id": 2, "label": "    return 0", "successors": []}, {"id": 3, "label": "    return 0", "successors": []}, {"id": 4, "label": "    pass", "successors": []}]}]}], "simplified_code": "from abc import ABC, abstractmethod\nfrom datetime import datetime, timezone\n\nfrom prisma import Json\nfrom prisma.enums import CreditTransactionType\nfrom prisma.errors import UniqueViolationError\nfrom prisma.models import CreditTransaction\n\nfrom backend.data.block import Block, BlockInput, get_block\nfrom backend.data.block_cost_config import BLOCK_COSTS\nfrom backend.data.cost import BlockCost, BlockCostType\nfrom backend.util.settings import Config\n\nconfig = Config()\n\n\n        pass\n\n\n        )\n\n\n        pass\n\n\n        return DisabledUserCredit(0)\n\n\n    return {block().id: costs for block, costs in BLOCK_COSTS.items()}", "blocks": []}
{"file_name": "8.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 100, "functions": [{"name": "get_executor_manager_client", "type": "function", "start_line": 21, "end_line": 25, "functions": [], "classes": [], "simplified_code": "def get_executor_manager_client():\n    from backend.executor import ExecutionManager\n    from backend.util.service import get_service_client\n\n    return get_service_client(ExecutionManager)", "blocks": [{"id": 1, "label": "def get_executor_manager_client():\n    from backend.executor import ExecutionManager\n    from backend.util.service import get_service_client\n    return get_service_client(ExecutionManager)", "successors": []}]}, {"name": "get_event_bus", "type": "function", "start_line": 29, "end_line": 32, "functions": [], "classes": [], "simplified_code": "def get_event_bus():\n    from backend.data.execution import RedisExecutionEventBus\n\n    return RedisExecutionEventBus()", "blocks": [{"id": 1, "label": "def get_event_bus():\nfrom backend.data.execution import RedisExecutionEventBus", "successors": [{"id": 3, "label": "return RedisExecutionEventBus()", "successors": []}]}]}], "classes": [{"name": "AgentExecutorBlock", "type": "class", "start_line": 35, "end_line": 100, "functions": [{"name": "__init__", "type": "function", "start_line": 48, "end_line": 56, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"e189baac-8c20-45a1-94a7-55177ea42565\",\n            description=\"Executes an existing agent inside your agent\",\n            input_schema=AgentExecutorBlock.Input,\n            output_schema=AgentExecutorBlock.Output,\n            block_type=BlockType.AGENT,\n            categories={BlockCategory.AGENT},\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"e189baac-8c20-45a1-94a7-55177ea42565\",\n    description=\"Executes an existing agent inside your agent\",\n    input_schema=AgentExecutorBlock.Input,\n    output_schema=AgentExecutorBlock.Output,\n    block_type=BlockType.AGENT,\n    categories={BlockCategory.AGENT},\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 58, "end_line": 100, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        executor_manager = get_executor_manager_client()\n        event_bus = get_event_bus()\n\n        graph_exec = executor_manager.add_execution(\n            graph_id=input_data.graph_id,\n            graph_version=input_data.graph_version,\n            user_id=input_data.user_id,\n            data=input_data.data,\n        )\n        log_id = f\"Graph #{input_data.graph_id}-V{input_data.graph_version}, exec-id: {graph_exec.graph_exec_id}\"\n        logger.info(f\"Starting execution of {log_id}\")\n\n        for event in event_bus.listen(\n            graph_id=graph_exec.graph_id, graph_exec_id=graph_exec.graph_exec_id\n        ):\n            logger.info(\n                f\"Execution {log_id} produced input {event.input_data} output {event.output_data}\"\n            )\n\n            if not event.node_id:\n                if event.status in [ExecutionStatus.COMPLETED, ExecutionStatus.FAILED]:\n                    logger.info(f\"Execution {log_id} ended with status {event.status}\")\n                    break\n                else:\n                    continue\n\n            if not event.block_id:\n                logger.warning(f\"{log_id} received event without block_id {event}\")\n                continue\n\n            block = get_block(event.block_id)\n            if not block or block.block_type != BlockType.OUTPUT:\n                continue\n\n            output_name = event.input_data.get(\"name\")\n            if not output_name:\n                logger.warning(f\"{log_id} produced an output with no name {event}\")\n                continue\n\n            for output_data in event.output_data.get(\"output\", []):\n                logger.info(f\"Execution {log_id} produced {output_name}: {output_data}\")\n                yield output_name, output_data", "blocks": [{"id": 1, "label": "executor_manager = get_executor_manager_client()\nevent_bus = get_event_bus()\n\ngraph_exec = executor_manager.add_execution(\n    graph_id=input_data.graph_id,\n    graph_version=input_data.graph_version,\n    user_id=input_data.user_id,\n    data=input_data.data,\n)\nlog_id = f\"Graph #{input_data.graph_id}-V{input_data.graph_version}, exec-id: {graph_exec.graph_exec_id}\"\nlogger.info(f\"Starting execution of {log_id}\")", "successors": [{"id": 2, "label": "for event in event_bus.listen(\n    graph_id=graph_exec.graph_id, graph_exec_id=graph_exec.graph_exec_id\n):", "successors": [{"id": 3, "label": "logger.info(\n    f\"Execution {log_id} produced input {event.input_data} output {event.output_data}\"\n)", "successors": [{"id": 4, "label": "if not event.node_id:", "successors": [{"id": 5, "label": "if event.status in [ExecutionStatus.COMPLETED, ExecutionStatus.FAILED]:\nlogger.info(f\"Execution {log_id} ended with status {event.status}\")", "successors": [{"id": 7, "label": "break", "successors": []}]}, {"id": 8, "label": "else:\ncontinue", "successors": []}]}, {"id": 10, "label": "if not event.block_id:\nlogger.warning(f\"{log_id} received event without block_id {event}\")", "successors": [{"id": 12, "label": "continue", "successors": []}]}, {"id": 13, "label": "block = get_block(event.block_id)\nif not block or block.block_type != BlockType.OUTPUT:\ncontinue", "successors": []}, {"id": 15, "label": "output_name = event.input_data.get(\"name\")\nif not output_name:\nlogger.warning(f\"{log_id} produced an output with no name {event}\")", "successors": [{"id": 17, "label": "continue", "successors": []}]}, {"id": 18, "label": "for output_data in event.output_data.get(\"output\", []):", "successors": [{"id": 19, "label": "logger.info(f\"Execution {log_id} produced {output_name}: {output_data}\")\nyield output_name, output_data", "successors": []}]}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 36, "end_line": 43, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        user_id: str = SchemaField(description=\"User ID\")\n        graph_id: str = SchemaField(description=\"Graph ID\")\n        graph_version: int = SchemaField(description=\"Graph Version\")\n\n        data: BlockInput = SchemaField(description=\"Input data for the graph\")\n        input_schema: dict = SchemaField(description=\"Input schema for the graph\")\n        output_schema: dict = SchemaField(description=\"Output schema for the graph\")", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    user_id: str = SchemaField(description=\"User ID\")\n    graph_id: str = SchemaField(description=\"Graph ID\")\n    graph_version: int = SchemaField(description=\"Graph Version\")\n\n    data: BlockInput = SchemaField(description=\"Input data for the graph\")\n    input_schema: dict = SchemaField(description=\"Input schema for the graph\")\n    output_schema: dict = SchemaField(description=\"Output schema for the graph\")", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 45, "end_line": 46, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        pass", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    pass", "successors": []}]}], "simplified_code": "class AgentExecutorBlock(Block):\n        output_schema: dict = SchemaField(description=\"Output schema for the graph\")\n\n        pass\n\n        )\n\n                yield output_name, output_data", "blocks": [{"id": 1, "label": "class AgentExecutorBlock(Block):\n    output_schema: dict = SchemaField(description=\"Output schema for the graph\")", "successors": []}]}], "simplified_code": "import logging\n\nfrom autogpt_libs.utils.cache import thread_cached\n\nfrom backend.data.block import (\n    Block,\n    BlockCategory,\n    BlockInput,\n    BlockOutput,\n    BlockSchema,\n    BlockType,\n    get_block,\n)\nfrom backend.data.execution import ExecutionStatus\nfrom backend.data.model import SchemaField\n\nlogger = logging.getLogger(__name__)\n\n\n@thread_cached\n    return get_service_client(ExecutionManager)\n\n\n@thread_cached\n    return RedisExecutionEventBus()\n\n\n                yield output_name, output_data", "blocks": [{"id": 1, "label": "import logging\nfrom autogpt_libs.utils.cache import thread_cached", "successors": [{"id": 3, "label": "from backend.data.block import ( Block, BlockCategory, BlockInput, BlockOutput, BlockSchema, BlockType, get_block, )\nfrom backend.data.execution import ExecutionStatus", "successors": [{"id": 5, "label": "from backend.data.model import SchemaField\nlogger = logging.getLogger(__name__)", "successors": [{"id": 7, "label": "@thread_cached\nreturn get_service_client(ExecutionManager)", "successors": [{"id": 9, "label": "@thread_cached\nreturn RedisExecutionEventBus()", "successors": [{"id": 11, "label": "yield output_name, output_data", "successors": []}]}]}]}]}]}]}
{"file_name": "9.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 20, "functions": [{"name": "thread_cached", "type": "function", "start_line": 8, "end_line": 20, "functions": [{"name": "wrapper", "type": "function", "start_line": 11, "end_line": 18, "functions": [], "classes": [], "simplified_code": "    def wrapper(*args: P.args, **kwargs: P.kwargs) -> R:\n        cache = getattr(thread_local, \"cache\", None)\n        if cache is None:\n            cache = thread_local.cache = {}\n        key = (args, tuple(sorted(kwargs.items())))\n        if key not in cache:\n            cache[key] = func(*args, **kwargs)\n        return cache[key]", "blocks": [{"id": 1, "label": "def wrapper(*args: P.args, **kwargs: P.kwargs) -> R:\n    cache = getattr(thread_local, \"cache\", None)", "successors": [{"id": 3, "label": "if cache is None:", "successors": [{"id": 4, "label": "    cache = thread_local.cache = {}\nkey = (args, tuple(sorted(kwargs.items())))", "successors": [{"id": 6, "label": "if key not in cache:\n    cache[key] = func(*args, **kwargs)", "successors": [{"id": 8, "label": "return cache[key]", "successors": []}]}, {"id": 8, "label": "return cache[key]", "successors": []}]}, {"id": 5, "label": "key = (args, tuple(sorted(kwargs.items())))", "successors": [{"id": 6, "label": "if key not in cache:\n    cache[key] = func(*args, **kwargs)", "successors": [{"id": 8, "label": "return cache[key]", "successors": []}]}, {"id": 8, "label": "return cache[key]", "successors": []}]}]}]}]}], "classes": [], "simplified_code": "def thread_cached(func: Callable[P, R]) -> Callable[P, R]:\n    thread_local = threading.local()\n\n        return cache[key]\n\n    return wrapper", "blocks": [{"id": 1, "label": "def thread_cached(func: Callable[P, R]) -> Callable[P, R]:\nthread_local = threading.local()", "successors": [{"id": 3, "label": "cache = getattr(thread_local, \"cache\", None)\nargs_key = (func.__module__, func.__qualname__)", "successors": [{"id": 5, "label": "key = ThreadCacheKey(args_key, args, frozenset(kwargs.items()))", "successors": [{"id": 6, "label": "if cache is None:\ncache = {}", "successors": [{"id": 9, "label": "setattr(thread_local, \"cache\", cache)", "successors": [{"id": 10, "label": "return cache[key]", "successors": []}, {"id": 8, "label": "if key not in cache:\ncache[key] = func(*args, **kwargs)", "successors": [{"id": 10, "label": "return cache[key]", "successors": []}]}]}]}, {"id": 8, "label": "if key not in cache:\ncache[key] = func(*args, **kwargs)", "successors": [{"id": 10, "label": "return cache[key]", "successors": []}]}]}]}]}]}], "classes": [], "simplified_code": "import threading\nfrom typing import Callable, ParamSpec, TypeVar\n\nP = ParamSpec(\"P\")\nR = TypeVar(\"R\")\n\n\n    return wrapper", "blocks": [{"id": 1, "label": "import threading\nfrom typing import Callable, ParamSpec, TypeVar\n\nP = ParamSpec(\"P\")\nR = TypeVar(\"R\")\ndef run_threadsafe_function(func: Callable[P, R]) -> Callable[P, R]:", "successors": [{"id": 3, "label": "    def wrapper(*args: P.args, **kwargs: P.kwargs) -> R:\n        result = None", "successors": [{"id": 5, "label": "        def call_function():\n            nonlocal result\n            result = func(*args, **kwargs)", "successors": [{"id": 7, "label": "        thread = threading.Thread(target=call_function)\n        thread.start()\n        thread.join()", "successors": [{"id": 9, "label": "        return result", "successors": []}]}]}]}, {"id": 10, "label": "    return wrapper", "successors": []}]}]}
{"file_name": "10.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 116, "functions": [{"name": "get_environment_variables", "type": "function", "start_line": 11, "end_line": 32, "functions": [], "classes": [], "simplified_code": "def get_environment_variables() -> Tuple[str, str, str, str, str]:\n    \"\"\"Retrieve and return necessary environment variables.\"\"\"\n    try:\n        with open(os.environ[\"GITHUB_EVENT_PATH\"]) as f:\n            event = json.load(f)\n\n        # Handle both PR and merge group events\n        if \"pull_request\" in event:\n            sha = event[\"pull_request\"][\"head\"][\"sha\"]\n        else:\n            sha = os.environ[\"GITHUB_SHA\"]\n\n        return (\n            os.environ[\"GITHUB_API_URL\"],\n            os.environ[\"GITHUB_REPOSITORY\"],\n            sha,\n            os.environ[\"GITHUB_TOKEN\"],\n            os.environ[\"GITHUB_RUN_ID\"],\n        )\n    except KeyError as e:\n        print(f\"Error: Missing required environment variable or event data: {e}\")\n        sys.exit(1)", "blocks": [{"id": 1, "label": "def get_environment_variables() -> Tuple[str, str, str, str, str]:", "successors": [{"id": 2, "label": "try:\nwith open(os.environ[\"GITHUB_EVENT_PATH\"]) as f:", "successors": [{"id": 4, "label": "event = json.load(f)\nif \"pull_request\" in event:", "successors": [{"id": 6, "label": "sha = event[\"pull_request\"][\"head\"][\"sha\"]\nreturn (\n    os.environ[\"GITHUB_API_URL\"],\n    os.environ[\"GITHUB_REPOSITORY\"],\n    sha,\n    os.environ[\"GITHUB_TOKEN\"],\n    os.environ[\"GITHUB_RUN_ID\"],\n)", "successors": []}, {"id": 7, "label": "sha = os.environ[\"GITHUB_SHA\"]\nreturn (\n    os.environ[\"GITHUB_API_URL\"],\n    os.environ[\"GITHUB_REPOSITORY\"],\n    sha,\n    os.environ[\"GITHUB_TOKEN\"],\n    os.environ[\"GITHUB_RUN_ID\"],\n)", "successors": []}]}]}, {"id": 9, "label": "except KeyError as e:\nprint(f\"Error: Missing required environment variable or event data: {e}\")", "successors": [{"id": 11, "label": "sys.exit(1)", "successors": []}]}]}]}, {"name": "make_api_request", "type": "function", "start_line": 35, "end_line": 44, "functions": [], "classes": [], "simplified_code": "def make_api_request(url: str, headers: Dict[str, str]) -> Dict:\n    \"\"\"Make an API request and return the JSON response.\"\"\"\n    try:\n        print(\"Making API request to:\", url)\n        response = requests.get(url, headers=headers, timeout=10)\n        response.raise_for_status()\n        return response.json()\n    except requests.RequestException as e:\n        print(f\"Error: API request failed. {e}\")\n        sys.exit(1)", "blocks": [{"id": 1, "label": "def make_api_request(url: str, headers: Dict[str, str]) -> Dict:\n    \"\"\"Make an API request and return the JSON response.\"\"\"", "successors": [{"id": 3, "label": "try:", "successors": [{"id": 4, "label": "    print(\"Making API request to:\", url)\n    response = requests.get(url, headers=headers, timeout=10)\n    response.raise_for_status()\n    return response.json()", "successors": []}, {"id": 5, "label": "except requests.RequestException as e:\n    print(f\"Error: API request failed. {e}\")\n    sys.exit(1)", "successors": []}]}]}]}, {"name": "process_check_runs", "type": "function", "start_line": 47, "end_line": 72, "functions": [], "classes": [], "simplified_code": "def process_check_runs(check_runs: List[Dict]) -> Tuple[bool, bool]:\n    \"\"\"Process check runs and return their status.\"\"\"\n    runs_in_progress = False\n    all_others_passed = True\n\n    for run in check_runs:\n        if str(run[\"name\"]) != \"Check PR Status\":\n            status = run[\"status\"]\n            conclusion = run[\"conclusion\"]\n\n            if status == \"completed\":\n                if conclusion not in [\"success\", \"skipped\", \"neutral\"]:\n                    all_others_passed = False\n                    print(\n                        f\"Check run {run['name']} (ID: {run['id']}) has conclusion: {conclusion}\"\n                    )\n            else:\n                runs_in_progress = True\n                print(f\"Check run {run['name']} (ID: {run['id']}) is still {status}.\")\n                all_others_passed = False\n        else:\n            print(\n                f\"Skipping check run {run['name']} (ID: {run['id']}) as it is the current run.\"\n            )\n\n    return runs_in_progress, all_others_passed", "blocks": [{"id": 1, "label": "def process_check_runs(check_runs: List[Dict]) -> Tuple[bool, bool]:\n\"\"\"Process check runs and return their status.\"\"\"", "successors": [{"id": 3, "label": "runs_in_progress = False\nall_others_passed = True", "successors": [{"id": 4, "label": "for run in check_runs:", "successors": [{"id": 5, "label": "if str(run[\"name\"]) != \"Check PR Status\":\nstatus = run[\"status\"]\nconclusion = run[\"conclusion\"]", "successors": [{"id": 7, "label": "if status == \"completed\":", "successors": [{"id": 8, "label": "if conclusion not in [\"success\", \"skipped\", \"neutral\"]:\nall_others_passed = False\nprint(f\"Check run {run['name']} (ID: {run['id']}) has conclusion: {conclusion}\")", "successors": [{"id": 14, "label": "return runs_in_progress, all_others_passed", "successors": []}]}, {"id": 14, "label": "return runs_in_progress, all_others_passed", "successors": []}]}, {"id": 10, "label": "runs_in_progress = True\nprint(f\"Check run {run['name']} (ID: {run['id']}) is still {status}.\")\nall_others_passed = False\nreturn runs_in_progress, all_others_passed", "successors": []}]}, {"id": 11, "label": "print(f\"Skipping check run {run['name']} (ID: {run['id']}) as it is the current run.\")\nreturn runs_in_progress, all_others_passed", "successors": []}]}, {"id": 14, "label": "return runs_in_progress, all_others_passed", "successors": []}]}]}]}, {"name": "main", "type": "function", "start_line": 75, "end_line": 112, "functions": [], "classes": [], "simplified_code": "def main():\n    api_url, repo, sha, github_token, current_run_id = get_environment_variables()\n\n    endpoint = f\"{api_url}/repos/{repo}/commits/{sha}/check-runs\"\n    headers = {\n        \"Accept\": \"application/vnd.github.v3+json\",\n    }\n    if github_token:\n        headers[\"Authorization\"] = f\"token {github_token}\"\n\n    print(f\"Current run ID: {current_run_id}\")\n\n    while True:\n        data = make_api_request(endpoint, headers)\n\n        check_runs = data[\"check_runs\"]\n\n        print(\"Processing check runs...\")\n\n        print(check_runs)\n\n        runs_in_progress, all_others_passed = process_check_runs(check_runs)\n\n        if not runs_in_progress:\n            break\n\n        print(\n            \"Some check runs are still in progress. \"\n            f\"Waiting {CHECK_INTERVAL} seconds before checking again...\"\n        )\n        time.sleep(CHECK_INTERVAL)\n\n    if all_others_passed:\n        print(\"All other completed check runs have passed. This check passes.\")\n        sys.exit(0)\n    else:\n        print(\"Some check runs have failed or have not completed. This check fails.\")\n        sys.exit(1)", "blocks": [{"id": 1, "label": "api_url, repo, sha, github_token, current_run_id = get_environment_variables()\nendpoint = f\"{api_url}/repos/{repo}/commits/{sha}/check-runs\"\nheaders = {\n    \"Accept\": \"application/vnd.github.v3+json\",\n}", "successors": [{"id": 3, "label": "if github_token:", "successors": [{"id": 4, "label": "    headers[\"Authorization\"] = f\"token {github_token}\"\nprint(f\"Current run ID: {current_run_id}\")", "successors": [{"id": 6, "label": "while True:", "successors": [{"id": 7, "label": "    data = make_api_request(endpoint, headers)\n    check_runs = data[\"check_runs\"]\n    print(\"Processing check runs...\")\n    print(check_runs)\n    runs_in_progress, all_others_passed = process_check_runs(check_runs)\n    if not runs_in_progress:\n        break\n    print(\n        \"Some check runs are still in progress. \"\n        f\"Waiting {CHECK_INTERVAL} seconds before checking again...\"\n    )\n    time.sleep(CHECK_INTERVAL)", "successors": [{"id": 9, "label": "if all_others_passed:\n    print(\"All other completed check runs have passed. This check passes.\")\n    sys.exit(0)\nelse:\n    print(\"Some check runs have failed or have not completed. This check fails.\")\n    sys.exit(1)", "successors": []}]}]}]}, {"id": 5, "label": "print(f\"Current run ID: {current_run_id}\")", "successors": [{"id": 6, "label": "while True:", "successors": [{"id": 7, "label": "    data = make_api_request(endpoint, headers)\n    check_runs = data[\"check_runs\"]\n    print(\"Processing check runs...\")\n    print(check_runs)\n    runs_in_progress, all_others_passed = process_check_runs(check_runs)\n    if not runs_in_progress:\n        break\n    print(\n        \"Some check runs are still in progress. \"\n        f\"Waiting {CHECK_INTERVAL} seconds before checking again...\"\n    )\n    time.sleep(CHECK_INTERVAL)", "successors": [{"id": 9, "label": "if all_others_passed:\n    print(\"All other completed check runs have passed. This check passes.\")\n    sys.exit(0)\nelse:\n    print(\"Some check runs have failed or have not completed. This check fails.\")\n    sys.exit(1)", "successors": []}]}]}]}]}]}]}], "classes": [], "simplified_code": "import json\nimport os\nimport requests\nimport sys\nimport time\nfrom typing import Dict, List, Tuple\n\nCHECK_INTERVAL = 30\n\n\n        sys.exit(1)\n\n\n        sys.exit(1)\n\n\n    return runs_in_progress, all_others_passed\n\n\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()", "blocks": [{"id": 1, "label": "import json\nimport os\nimport requests\nimport sys\nimport time\nfrom typing import Dict, List, Tuple\n\nCHECK_INTERVAL = 30\n\n\ndef main():\nsys.exit(1)", "successors": []}]}
{"file_name": "11.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 67, "functions": [{"name": "_start_measurement", "type": "function", "start_line": 15, "end_line": 16, "functions": [], "classes": [], "simplified_code": "def _start_measurement() -> Tuple[float, float]:\n    return time.time(), os.times()[0] + os.times()[1]", "blocks": [{"id": 1, "label": "def _start_measurement() -> Tuple[float, float]:\n    return time.time(), os.times()[0] + os.times()[1]", "successors": []}]}, {"name": "_end_measurement", "type": "function", "start_line": 19, "end_line": 24, "functions": [], "classes": [], "simplified_code": "def _end_measurement(\n    start_wall_time: float, start_cpu_time: float\n) -> Tuple[float, float]:\n    end_wall_time = time.time()\n    end_cpu_time = os.times()[0] + os.times()[1]\n    return end_wall_time - start_wall_time, end_cpu_time - start_cpu_time", "blocks": [{"id": 1, "label": "end_wall_time = time.time()\nend_cpu_time = os.times()[0] + os.times()[1]", "successors": [{"id": 3, "label": "return end_wall_time - start_wall_time, end_cpu_time - start_cpu_time", "successors": []}]}]}, {"name": "time_measured", "type": "function", "start_line": 33, "end_line": 50, "functions": [{"name": "wrapper", "type": "function", "start_line": 39, "end_line": 48, "functions": [], "classes": [], "simplified_code": "    def wrapper(*args: P.args, **kwargs: P.kwargs) -> Tuple[TimingInfo, T]:\n        start_wall_time, start_cpu_time = _start_measurement()\n        try:\n            result = func(*args, **kwargs)\n        finally:\n            wall_duration, cpu_duration = _end_measurement(\n                start_wall_time, start_cpu_time\n            )\n            timing_info = TimingInfo(cpu_time=cpu_duration, wall_time=wall_duration)\n        return timing_info, result", "blocks": [{"id": 1, "label": "start_wall_time, start_cpu_time = _start_measurement()\ntry:", "successors": [{"id": 3, "label": "result = func(*args, **kwargs)\nreturn timing_info, result", "successors": []}, {"id": 4, "label": "finally:\nwall_duration, cpu_duration = _end_measurement(start_wall_time, start_cpu_time)", "successors": [{"id": 7, "label": "timing_info = TimingInfo(cpu_time=cpu_duration, wall_time=wall_duration)\nreturn timing_info, result", "successors": []}]}]}]}], "classes": [], "simplified_code": "def time_measured(func: Callable[P, T]) -> Callable[P, Tuple[TimingInfo, T]]:\n    \"\"\"\n    Decorator to measure the time taken by a function to execute.\n    \"\"\"\n\n    @functools.wraps(func)\n        return timing_info, result\n\n    return wrapper", "blocks": [{"id": 1, "label": "def time_measured(func: Callable[P, T]) -> Callable[P, Tuple[TimingInfo, T]]:\n\"\"\"\nDecorator to measure the time taken by a function to execute.\n\"\"\"", "successors": [{"id": 3, "label": "@functools.wraps(func)", "successors": [{"id": 4, "label": "def wrapper(*args: P.args, **kwargs: P.kwargs) -> Tuple[TimingInfo, T]:\nstart_time = time.monotonic()", "successors": [{"id": 6, "label": "result = func(*args, **kwargs)\nend_time = time.monotonic()", "successors": [{"id": 8, "label": "elapsed_time = end_time - start_time\ntiming_info = TimingInfo(start_time, end_time, elapsed_time)", "successors": [{"id": 10, "label": "return timing_info, result", "successors": []}]}]}]}, {"id": 11, "label": "return wrapper", "successors": []}]}]}]}, {"name": "error_logged", "type": "function", "start_line": 53, "end_line": 67, "functions": [{"name": "wrapper", "type": "function", "start_line": 59, "end_line": 65, "functions": [], "classes": [], "simplified_code": "    def wrapper(*args: P.args, **kwargs: P.kwargs) -> T | None:\n        try:\n            return func(*args, **kwargs)\n        except Exception as e:\n            logger.exception(\n                f\"Error when calling function {func.__name__} with arguments {args} {kwargs}: {e}\"\n            )", "blocks": [{"id": 1, "label": "def wrapper(*args: P.args, **kwargs: P.kwargs) -> T | None:\ntry:", "successors": [{"id": 3, "label": "    return func(*args, **kwargs)", "successors": []}, {"id": 4, "label": "except Exception as e:\n    logger.exception(f\"Error when calling function {func.__name__} with arguments {args} {kwargs}: {e}\")", "successors": []}]}]}], "classes": [], "simplified_code": "def error_logged(func: Callable[P, T]) -> Callable[P, T | None]:\n    \"\"\"\n    Decorator to suppress and log any exceptions raised by a function.\n    \"\"\"\n\n    @functools.wraps(func)\n            )\n\n    return wrapper", "blocks": [{"id": 1, "label": "def error_logged(func: Callable[P, T]) -> Callable[P, T | None]:\n\"\"\"\\nDecorator to suppress and log any exceptions raised by a function.\\n\"\"\"", "successors": [{"id": 3, "label": "@functools.wraps(func)\ndef wrapper(*args: P.args, **kwargs: P.kwargs) -> T | None:", "successors": [{"id": 5, "label": "try:", "successors": [{"id": 6, "label": "return func(*args, **kwargs)\nreturn wrapper", "successors": []}, {"id": 7, "label": "except Exception as e:\nlogger.error(\"An error occurred: %s\", e)\nreturn None", "successors": [{"id": 9, "label": "return wrapper", "successors": []}]}]}]}]}]}], "classes": [{"name": "TimingInfo", "type": "class", "start_line": 10, "end_line": 12, "functions": [], "classes": [], "simplified_code": "class TimingInfo(BaseModel):\n    cpu_time: float\n    wall_time: float", "blocks": [{"id": 1, "label": "class TimingInfo(BaseModel):\n    cpu_time: float\n    wall_time: float", "successors": []}]}], "simplified_code": "import functools\nimport logging\nimport os\nimport time\nfrom typing import Callable, ParamSpec, Tuple, TypeVar\n\nfrom pydantic import BaseModel\n\n\n    wall_time: float\n\n\n    return time.time(), os.times()[0] + os.times()[1]\n\n\n    return end_wall_time - start_wall_time, end_cpu_time - start_cpu_time\n\n\nP = ParamSpec(\"P\")\nT = TypeVar(\"T\")\n\nlogger = logging.getLogger(__name__)\n\n\n    return wrapper\n\n\n    return wrapper", "blocks": [{"id": 1, "label": "import functools\nimport logging", "successors": [{"id": 3, "label": "import os\nimport time", "successors": [{"id": 5, "label": "from typing import Callable, ParamSpec, Tuple, TypeVar\nfrom pydantic import BaseModel", "successors": [{"id": 7, "label": "def timer() -> Tuple[float, float]:\n    start_wall_time, start_cpu_time = time.time(), os.times()[0] + os.times()[1]", "successors": [{"id": 9, "label": "    def decorator(func: Callable[P, T]) -> Callable[P, T]:", "successors": [{"id": 10, "label": "        def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:", "successors": [{"id": 11, "label": "            result = func(*args, **kwargs)", "successors": []}, {"id": 12, "label": "            end_wall_time, end_cpu_time = time.time(), os.times()[0] + os.times()[1]", "successors": []}, {"id": 13, "label": "            logger.info(\"Elapsed wall time: %f\", end_wall_time - start_wall_time)", "successors": []}, {"id": 14, "label": "            logger.info(\"Elapsed CPU time: %f\", end_cpu_time - start_cpu_time)", "successors": []}, {"id": 15, "label": "            return result", "successors": []}]}, {"id": 16, "label": "        return wrapper", "successors": []}]}, {"id": 17, "label": "    return decorator", "successors": []}]}, {"id": 18, "label": "", "successors": []}]}]}]}]}
{"file_name": "12.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 701, "functions": [], "classes": [{"name": "GithubListTagsBlock", "type": "class", "start_line": 18, "end_line": 97, "functions": [{"name": "__init__", "type": "function", "start_line": 36, "end_line": 65, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"358924e7-9a11-4d1a-a0f2-13c67fe59e2e\",\n            description=\"This block lists all tags for a specified GitHub repository.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubListTagsBlock.Input,\n            output_schema=GithubListTagsBlock.Output,\n            test_input={\n                \"repo_url\": \"https://github.com/owner/repo\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\n                    \"tag\",\n                    {\n                        \"name\": \"v1.0.0\",\n                        \"url\": \"https://github.com/owner/repo/tree/v1.0.0\",\n                    },\n                )\n            ],\n            test_mock={\n                \"list_tags\": lambda *args, **kwargs: [\n                    {\n                        \"name\": \"v1.0.0\",\n                        \"url\": \"https://github.com/owner/repo/tree/v1.0.0\",\n                    }\n                ]\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\n    super().__init__(\n        id=\"358924e7-9a11-4d1a-a0f2-13c67fe59e2e\",\n        description=\"This block lists all tags for a specified GitHub repository.\",\n        categories={BlockCategory.DEVELOPER_TOOLS},\n        input_schema=GithubListTagsBlock.Input,\n        output_schema=GithubListTagsBlock.Output,\n        test_input={\n            \"repo_url\": \"https://github.com/owner/repo\",\n            \"credentials\": TEST_CREDENTIALS_INPUT,\n        },\n        test_credentials=TEST_CREDENTIALS,\n        test_output=[\n            (\n                \"tag\",\n                {\n                    \"name\": \"v1.0.0\",\n                    \"url\": \"https://github.com/owner/repo/tree/v1.0.0\",\n                },\n            )\n        ],\n        test_mock={\n            \"list_tags\": lambda *args, **kwargs: [\n                {\n                    \"name\": \"v1.0.0\",\n                    \"url\": \"https://github.com/owner/repo/tree/v1.0.0\",\n                }\n            ]\n        },\n    )", "successors": []}]}, {"name": "list_tags", "type": "function", "start_line": 68, "end_line": 83, "functions": [], "classes": [], "simplified_code": "    def list_tags(\n        credentials: GithubCredentials, repo_url: str\n    ) -> list[Output.TagItem]:\n        api = get_api(credentials)\n        tags_url = repo_url + \"/tags\"\n        response = api.get(tags_url)\n        data = response.json()\n        repo_path = repo_url.replace(\"https://github.com/\", \"\")\n        tags: list[GithubListTagsBlock.Output.TagItem] = [\n            {\n                \"name\": tag[\"name\"],\n                \"url\": f\"https://github.com/{repo_path}/tree/{tag['name']}\",\n            }\n            for tag in data\n        ]\n        return tags", "blocks": [{"id": 1, "label": "def list_tags(credentials: GithubCredentials, repo_url: str) -> list[Output.TagItem]:\napi = get_api(credentials)\ntags_url = repo_url + \"/tags\"\nresponse = api.get(tags_url)\ndata = response.json()\nrepo_path = repo_url.replace(\"https://github.com/\", \"\")\ntags: list[GithubListTagsBlock.Output.TagItem] = [\n    {\n        \"name\": tag[\"name\"],\n        \"url\": f\"https://github.com/{repo_path}/tree/{tag['name']}\"\n    }\n    for tag in data\n]\nreturn tags", "successors": []}]}, {"name": "run", "type": "function", "start_line": 85, "end_line": 96, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        tags = self.list_tags(\n            credentials,\n            input_data.repo_url,\n        )\n        yield from ((\"tag\", tag) for tag in tags)", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: GithubCredentials, **kwargs) -> BlockOutput:\ntags = self.list_tags(credentials, input_data.repo_url)", "successors": [{"id": 3, "label": "yield from (('tag', tag) for tag in tags)", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 19, "end_line": 24, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        repo_url: str = SchemaField(\n            description=\"URL of the GitHub repository\",\n            placeholder=\"https://github.com/owner/repo\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")", "successors": []}, {"id": 3, "label": "    repo_url: str = SchemaField(description=\"URL of the GitHub repository\", placeholder=\"https://github.com/owner/repo\")", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 26, "end_line": 34, "functions": [], "classes": [{"name": "TagItem", "type": "class", "start_line": 27, "end_line": 29, "functions": [], "classes": [], "simplified_code": "        class TagItem(TypedDict):\n            name: str\n            url: str", "blocks": [{"id": 1, "label": "class TagItem(TypedDict):\n    name: str\n    url: str", "successors": []}]}], "simplified_code": "    class Output(BlockSchema):\n            url: str\n\n        tag: TagItem = SchemaField(\n            title=\"Tag\", description=\"Tags with their name and file tree browser URL\"\n        )\n        error: str = SchemaField(description=\"Error message if listing tags failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\nurl: str", "successors": []}]}], "simplified_code": "class GithubListTagsBlock(Block):\n        )\n\n        error: str = SchemaField(description=\"Error message if listing tags failed\")\n\n        )\n\n    @staticmethod\n        return tags\n\n        yield from ((\"tag\", tag) for tag in tags)\n", "blocks": [{"id": 1, "label": "class GithubListTagsBlock(Block):\n    error: str = SchemaField(description=\"Error message if listing tags failed\")", "successors": [{"id": 3, "label": "    @staticmethod\n        return tags", "successors": [{"id": 5, "label": "        yield from ((\"tag\", tag) for tag in tags)", "successors": []}]}]}]}, {"name": "GithubListBranchesBlock", "type": "class", "start_line": 99, "end_line": 179, "functions": [{"name": "__init__", "type": "function", "start_line": 118, "end_line": 147, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"74243e49-2bec-4916-8bf4-db43d44aead5\",\n            description=\"This block lists all branches for a specified GitHub repository.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubListBranchesBlock.Input,\n            output_schema=GithubListBranchesBlock.Output,\n            test_input={\n                \"repo_url\": \"https://github.com/owner/repo\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\n                    \"branch\",\n                    {\n                        \"name\": \"main\",\n                        \"url\": \"https://github.com/owner/repo/tree/main\",\n                    },\n                )\n            ],\n            test_mock={\n                \"list_branches\": lambda *args, **kwargs: [\n                    {\n                        \"name\": \"main\",\n                        \"url\": \"https://github.com/owner/repo/tree/main\",\n                    }\n                ]\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"74243e49-2bec-4916-8bf4-db43d44aead5\",\n    description=\"This block lists all branches for a specified GitHub repository.\",\n    categories={BlockCategory.DEVELOPER_TOOLS},\n    input_schema=GithubListBranchesBlock.Input,\n    output_schema=GithubListBranchesBlock.Output,\n    test_input={\n        \"repo_url\": \"https://github.com/owner/repo\",\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\n            \"branch\",\n            {\n                \"name\": \"main\",\n                \"url\": \"https://github.com/owner/repo/tree/main\",\n            },\n        )\n    ],\n    test_mock={\n        \"list_branches\": lambda *args, **kwargs: [\n            {\n                \"name\": \"main\",\n                \"url\": \"https://github.com/owner/repo/tree/main\",\n            }\n        ]\n    },\n)", "successors": []}]}, {"name": "list_branches", "type": "function", "start_line": 150, "end_line": 165, "functions": [], "classes": [], "simplified_code": "    def list_branches(\n        credentials: GithubCredentials, repo_url: str\n    ) -> list[Output.BranchItem]:\n        api = get_api(credentials)\n        branches_url = repo_url + \"/branches\"\n        response = api.get(branches_url)\n        data = response.json()\n        repo_path = repo_url.replace(\"https://github.com/\", \"\")\n        branches: list[GithubListBranchesBlock.Output.BranchItem] = [\n            {\n                \"name\": branch[\"name\"],\n                \"url\": f\"https://github.com/{repo_path}/tree/{branch['name']}\",\n            }\n            for branch in data\n        ]\n        return branches", "blocks": [{"id": 1, "label": "def list_branches(credentials: GithubCredentials, repo_url: str) -> list[Output.BranchItem]:\napi = get_api(credentials)\nbranches_url = repo_url + \"/branches\"\nresponse = api.get(branches_url)\ndata = response.json()\nrepo_path = repo_url.replace(\"https://github.com/\", \"\")", "successors": [{"id": 3, "label": "branches: list[GithubListBranchesBlock.Output.BranchItem] = [\n    {\n        \"name\": branch[\"name\"],\n        \"url\": f\"https://github.com/{repo_path}/tree/{branch['name']}\"\n    }\n    for branch in data\n]\nreturn branches", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 167, "end_line": 178, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        branches = self.list_branches(\n            credentials,\n            input_data.repo_url,\n        )\n        yield from ((\"branch\", branch) for branch in branches)", "blocks": [{"id": 1, "label": "def run(\n    self,\n    input_data: Input,\n    *,\n    credentials: GithubCredentials,\n    **kwargs,\n) -> BlockOutput:\nbranches = self.list_branches(\n    credentials,\n    input_data.repo_url,\n)", "successors": [{"id": 3, "label": "yield from ((\"branch\", branch) for branch in branches)", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 100, "end_line": 105, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        repo_url: str = SchemaField(\n            description=\"URL of the GitHub repository\",\n            placeholder=\"https://github.com/owner/repo\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n    repo_url: str = SchemaField(\n        description=\"URL of the GitHub repository\",\n        placeholder=\"https://github.com/owner/repo\",\n    )", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 107, "end_line": 116, "functions": [], "classes": [{"name": "BranchItem", "type": "class", "start_line": 108, "end_line": 110, "functions": [], "classes": [], "simplified_code": "        class BranchItem(TypedDict):\n            name: str\n            url: str", "blocks": [{"id": 1, "label": "class BranchItem(TypedDict):\n    name: str\n    url: str", "successors": []}]}], "simplified_code": "    class Output(BlockSchema):\n            url: str\n\n        branch: BranchItem = SchemaField(\n            title=\"Branch\",\n            description=\"Branches with their name and file tree browser URL\",\n        )\n        error: str = SchemaField(description=\"Error message if listing branches failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    url: str", "successors": [{"id": 3, "label": "branch: BranchItem = SchemaField(title=\"Branch\", description=\"Branches with their name and file tree browser URL\")\nerror: str = SchemaField(description=\"Error message if listing branches failed\")", "successors": []}]}]}], "simplified_code": "class GithubListBranchesBlock(Block):\n        )\n\n        error: str = SchemaField(description=\"Error message if listing branches failed\")\n\n        )\n\n    @staticmethod\n        return branches\n\n        yield from ((\"branch\", branch) for branch in branches)\n", "blocks": [{"id": 1, "label": "class GithubListBranchesBlock(Block):", "successors": [{"id": 2, "label": "error: str = SchemaField(description=\"Error message if listing branches failed\")", "successors": []}, {"id": 3, "label": "@staticmethod", "successors": [{"id": 4, "label": "return branches", "successors": []}, {"id": 5, "label": "yield from ((\"branch\", branch) for branch in branches)", "successors": []}]}]}]}, {"name": "GithubListDiscussionsBlock", "type": "class", "start_line": 181, "end_line": 280, "functions": [{"name": "__init__", "type": "function", "start_line": 204, "end_line": 234, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"3ef1a419-3d76-4e07-b761-de9dad4d51d7\",\n            description=\"This block lists recent discussions for a specified GitHub repository.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubListDiscussionsBlock.Input,\n            output_schema=GithubListDiscussionsBlock.Output,\n            test_input={\n                \"repo_url\": \"https://github.com/owner/repo\",\n                \"num_discussions\": 3,\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\n                    \"discussion\",\n                    {\n                        \"title\": \"Discussion 1\",\n                        \"url\": \"https://github.com/owner/repo/discussions/1\",\n                    },\n                )\n            ],\n            test_mock={\n                \"list_discussions\": lambda *args, **kwargs: [\n                    {\n                        \"title\": \"Discussion 1\",\n                        \"url\": \"https://github.com/owner/repo/discussions/1\",\n                    }\n                ]\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"3ef1a419-3d76-4e07-b761-de9dad4d51d7\",\n    description=\"This block lists recent discussions for a specified GitHub repository.\",\n    categories={BlockCategory.DEVELOPER_TOOLS},\n    input_schema=GithubListDiscussionsBlock.Input,\n    output_schema=GithubListDiscussionsBlock.Output,\n    test_input={\n        \"repo_url\": \"https://github.com/owner/repo\",\n        \"num_discussions\": 3,\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\n            \"discussion\",\n            {\n                \"title\": \"Discussion 1\",\n                \"url\": \"https://github.com/owner/repo/discussions/1\",\n            },\n        )\n    ],\n    test_mock={\n        \"list_discussions\": lambda *args, **kwargs: [\n            {\n                \"title\": \"Discussion 1\",\n                \"url\": \"https://github.com/owner/repo/discussions/1\",\n            }\n        ]\n    },\n)", "successors": []}]}, {"name": "list_discussions", "type": "function", "start_line": 237, "end_line": 266, "functions": [], "classes": [], "simplified_code": "    def list_discussions(\n        credentials: GithubCredentials, repo_url: str, num_discussions: int\n    ) -> list[Output.DiscussionItem]:\n        api = get_api(credentials)\n        # GitHub GraphQL API endpoint is different; we'll use api.post with custom URL\n        repo_path = repo_url.replace(\"https://github.com/\", \"\")\n        owner, repo = repo_path.split(\"/\")\n        query = \"\"\"\n        query($owner: String!, $repo: String!, $num: Int!) {\n            repository(owner: $owner, name: $repo) {\n                discussions(first: $num) {\n                    nodes {\n                        title\n                        url\n                    }\n                }\n            }\n        }\n        \"\"\"\n        variables = {\"owner\": owner, \"repo\": repo, \"num\": num_discussions}\n        response = api.post(\n            \"https://api.github.com/graphql\",\n            json={\"query\": query, \"variables\": variables},\n        )\n        data = response.json()\n        discussions: list[GithubListDiscussionsBlock.Output.DiscussionItem] = [\n            {\"title\": discussion[\"title\"], \"url\": discussion[\"url\"]}\n            for discussion in data[\"data\"][\"repository\"][\"discussions\"][\"nodes\"]\n        ]\n        return discussions", "blocks": [{"id": 1, "label": "def list_discussions(\n    credentials: GithubCredentials, repo_url: str, num_discussions: int\n) -> list[Output.DiscussionItem]:\napi = get_api(credentials)", "successors": [{"id": 3, "label": "repo_path = repo_url.replace(\"https://github.com/\", \"\")\nowner, repo = repo_path.split(\"/\")", "successors": [{"id": 5, "label": "query = \"\"\"\n        query($owner: String!, $repo: String!, $num: Int!) {\n            repository(owner: $owner, name: $repo) {\n                discussions(first: $num) {\n                    nodes {\n                        title\n                        url\n                    }\n                }\n            }\n        }\n        \"\"\"\nvariables = {\"owner\": owner, \"repo\": repo, \"num\": num_discussions}", "successors": [{"id": 7, "label": "response = api.post(\n    \"https://api.github.com/graphql\",\n    json={\"query\": query, \"variables\": variables},\n)\ndata = response.json()", "successors": [{"id": 9, "label": "discussions: list[GithubListDiscussionsBlock.Output.DiscussionItem] = [\n    {\"title\": discussion[\"title\"], \"url\": discussion[\"url\"]}\n    for discussion in data[\"data\"][\"repository\"][\"discussions\"][\"nodes\"]\n]\nreturn discussions", "successors": []}]}]}]}]}]}, {"name": "run", "type": "function", "start_line": 268, "end_line": 278, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        discussions = self.list_discussions(\n            credentials, input_data.repo_url, input_data.num_discussions\n        )\n        yield from ((\"discussion\", discussion) for discussion in discussions)", "blocks": [{"id": 1, "label": "def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\ndiscussions = self.list_discussions(\n            credentials, input_data.repo_url, input_data.num_discussions\n        )", "successors": [{"id": 3, "label": "yield from ((\"discussion\", discussion) for discussion in discussions)", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 182, "end_line": 190, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        repo_url: str = SchemaField(\n            description=\"URL of the GitHub repository\",\n            placeholder=\"https://github.com/owner/repo\",\n        )\n        num_discussions: int = SchemaField(\n            description=\"Number of discussions to fetch\", default=5\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n    repo_url: str = SchemaField(\n        description=\"URL of the GitHub repository\",\n        placeholder=\"https://github.com/owner/repo\",\n    )\n    num_discussions: int = SchemaField(\n        description=\"Number of discussions to fetch\", default=5\n    )", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 192, "end_line": 202, "functions": [], "classes": [{"name": "DiscussionItem", "type": "class", "start_line": 193, "end_line": 195, "functions": [], "classes": [], "simplified_code": "        class DiscussionItem(TypedDict):\n            title: str\n            url: str", "blocks": [{"id": 1, "label": "class DiscussionItem(TypedDict):\n    title: str\n    url: str", "successors": []}]}], "simplified_code": "    class Output(BlockSchema):\n            url: str\n\n        discussion: DiscussionItem = SchemaField(\n            title=\"Discussion\", description=\"Discussions with their title and URL\"\n        )\n        error: str = SchemaField(\n            description=\"Error message if listing discussions failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\nurl: str", "successors": []}]}], "simplified_code": "class GithubListDiscussionsBlock(Block):\n        )\n\n        )\n\n        )\n\n    @staticmethod\n        return discussions\n\n        yield from ((\"discussion\", discussion) for discussion in discussions)\n\n", "blocks": [{"id": 1, "label": "class GithubListDiscussionsBlock(Block):\n@staticmethod", "successors": [{"id": 3, "label": "return discussions", "successors": []}]}]}, {"name": "GithubListReleasesBlock", "type": "class", "start_line": 281, "end_line": 357, "functions": [{"name": "__init__", "type": "function", "start_line": 300, "end_line": 329, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"3460367a-6ba7-4645-8ce6-47b05d040b92\",\n            description=\"This block lists all releases for a specified GitHub repository.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubListReleasesBlock.Input,\n            output_schema=GithubListReleasesBlock.Output,\n            test_input={\n                \"repo_url\": \"https://github.com/owner/repo\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\n                    \"release\",\n                    {\n                        \"name\": \"v1.0.0\",\n                        \"url\": \"https://github.com/owner/repo/releases/tag/v1.0.0\",\n                    },\n                )\n            ],\n            test_mock={\n                \"list_releases\": lambda *args, **kwargs: [\n                    {\n                        \"name\": \"v1.0.0\",\n                        \"url\": \"https://github.com/owner/repo/releases/tag/v1.0.0\",\n                    }\n                ]\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"3460367a-6ba7-4645-8ce6-47b05d040b92\",\n    description=\"This block lists all releases for a specified GitHub repository.\",\n    categories={BlockCategory.DEVELOPER_TOOLS},\n    input_schema=GithubListReleasesBlock.Input,\n    output_schema=GithubListReleasesBlock.Output,\n    test_input={\n        \"repo_url\": \"https://github.com/owner/repo\",\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\n            \"release\",\n            {\n                \"name\": \"v1.0.0\",\n                \"url\": \"https://github.com/owner/repo/releases/tag/v1.0.0\",\n            },\n        )\n    ],\n    test_mock={\n        \"list_releases\": lambda *args, **kwargs: [\n            {\n                \"name\": \"v1.0.0\",\n                \"url\": \"https://github.com/owner/repo/releases/tag/v1.0.0\",\n            }\n        ]\n    },\n)", "successors": []}]}, {"name": "list_releases", "type": "function", "start_line": 332, "end_line": 342, "functions": [], "classes": [], "simplified_code": "    def list_releases(\n        credentials: GithubCredentials, repo_url: str\n    ) -> list[Output.ReleaseItem]:\n        api = get_api(credentials)\n        releases_url = repo_url + \"/releases\"\n        response = api.get(releases_url)\n        data = response.json()\n        releases: list[GithubListReleasesBlock.Output.ReleaseItem] = [\n            {\"name\": release[\"name\"], \"url\": release[\"html_url\"]} for release in data\n        ]\n        return releases", "blocks": [{"id": 1, "label": "def list_releases( credentials: GithubCredentials, repo_url: str ) -> list[Output.ReleaseItem]:\napi = get_api(credentials)", "successors": [{"id": 3, "label": "releases_url = repo_url + \"/releases\"\nresponse = api.get(releases_url)", "successors": [{"id": 5, "label": "data = response.json()\nreleases: list[GithubListReleasesBlock.Output.ReleaseItem] = [ {\"name\": release[\"name\"], \"url\": release[\"html_url\"]} for release in data ]", "successors": [{"id": 7, "label": "return releases", "successors": []}]}]}]}]}, {"name": "run", "type": "function", "start_line": 344, "end_line": 355, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        releases = self.list_releases(\n            credentials,\n            input_data.repo_url,\n        )\n        yield from ((\"release\", release) for release in releases)", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: GithubCredentials, **kwargs) -> BlockOutput:\nreleases = self.list_releases(credentials, input_data.repo_url)", "successors": [{"id": 3, "label": "yield from ((\"release\", release) for release in releases)", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 282, "end_line": 287, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        repo_url: str = SchemaField(\n            description=\"URL of the GitHub repository\",\n            placeholder=\"https://github.com/owner/repo\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n    repo_url: str = SchemaField(\n        description=\"URL of the GitHub repository\",\n        placeholder=\"https://github.com/owner/repo\",\n    )", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 289, "end_line": 298, "functions": [], "classes": [{"name": "ReleaseItem", "type": "class", "start_line": 290, "end_line": 292, "functions": [], "classes": [], "simplified_code": "        class ReleaseItem(TypedDict):\n            name: str\n            url: str", "blocks": [{"id": 1, "label": "class ReleaseItem(TypedDict):", "successors": [{"id": 2, "label": "    name: str", "successors": []}, {"id": 3, "label": "    url: str", "successors": []}]}]}], "simplified_code": "    class Output(BlockSchema):\n            url: str\n\n        release: ReleaseItem = SchemaField(\n            title=\"Release\",\n            description=\"Releases with their name and file tree browser URL\",\n        )\n        error: str = SchemaField(description=\"Error message if listing releases failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    url: str\nrelease: ReleaseItem = SchemaField(\n    title=\"Release\",\n    description=\"Releases with their name and file tree browser URL\",\n)", "successors": [{"id": 3, "label": "error: str = SchemaField(description=\"Error message if listing releases failed\")", "successors": []}]}]}], "simplified_code": "class GithubListReleasesBlock(Block):\n        )\n\n        error: str = SchemaField(description=\"Error message if listing releases failed\")\n\n        )\n\n    @staticmethod\n        return releases\n\n        yield from ((\"release\", release) for release in releases)\n\n", "blocks": [{"id": 1, "label": "class GithubListReleasesBlock(Block):\n)", "successors": [{"id": 3, "label": "error: str = SchemaField(description=\"Error message if listing releases failed\")\n)", "successors": [{"id": 5, "label": "@staticmethod\nreturn releases", "successors": [{"id": 7, "label": "yield from ((\"release\", release) for release in releases)", "successors": []}]}]}]}]}, {"name": "GithubReadFileBlock", "type": "class", "start_line": 358, "end_line": 444, "functions": [{"name": "__init__", "type": "function", "start_line": 385, "end_line": 405, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"87ce6c27-5752-4bbc-8e26-6da40a3dcfd3\",\n            description=\"This block reads the content of a specified file from a GitHub repository.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubReadFileBlock.Input,\n            output_schema=GithubReadFileBlock.Output,\n            test_input={\n                \"repo_url\": \"https://github.com/owner/repo\",\n                \"file_path\": \"path/to/file\",\n                \"branch\": \"master\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\"raw_content\", \"RmlsZSBjb250ZW50\"),\n                (\"text_content\", \"File content\"),\n                (\"size\", 13),\n            ],\n            test_mock={\"read_file\": lambda *args, **kwargs: (\"RmlsZSBjb250ZW50\", 13)},\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"87ce6c27-5752-4bbc-8e26-6da40a3dcfd3\",\n    description=\"This block reads the content of a specified file from a GitHub repository.\",\n    categories={BlockCategory.DEVELOPER_TOOLS},\n    input_schema=GithubReadFileBlock.Input,\n    output_schema=GithubReadFileBlock.Output,\n    test_input={\n        \"repo_url\": \"https://github.com/owner/repo\",\n        \"file_path\": \"path/to/file\",\n        \"branch\": \"master\",\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\"raw_content\", \"RmlsZSBjb250ZW50\"),\n        (\"text_content\", \"File content\"),\n        (\"size\", 13),\n    ],\n    test_mock={\"read_file\": lambda *args, **kwargs: (\"RmlsZSBjb250ZW50\", 13)},\n)", "successors": []}]}, {"name": "read_file", "type": "function", "start_line": 408, "end_line": 425, "functions": [], "classes": [], "simplified_code": "    def read_file(\n        credentials: GithubCredentials, repo_url: str, file_path: str, branch: str\n    ) -> tuple[str, int]:\n        api = get_api(credentials)\n        content_url = repo_url + f\"/contents/{file_path}?ref={branch}\"\n        response = api.get(content_url)\n        content = response.json()\n\n        if isinstance(content, list):\n            # Multiple entries of different types exist at this path\n            if not (file := next((f for f in content if f[\"type\"] == \"file\"), None)):\n                raise TypeError(\"Not a file\")\n            content = file\n\n        if content[\"type\"] != \"file\":\n            raise TypeError(\"Not a file\")\n\n        return content[\"content\"], content[\"size\"]", "blocks": [{"id": 1, "label": "def read_file(credentials: GithubCredentials, repo_url: str, file_path: str, branch: str) -> tuple[str, int]:\napi = get_api(credentials)\ncontent_url = repo_url + f\"/contents/{file_path}?ref={branch}\"\nresponse = api.get(content_url)\ncontent = response.json()", "successors": [{"id": 3, "label": "if isinstance(content, list):\nif not (file := next((f for f in content if f[\"type\"] == \"file\"), None)):\n    raise TypeError(\"Not a file\")\ncontent = file", "successors": []}, {"id": 5, "label": "if content[\"type\"] != \"file\":\n    raise TypeError(\"Not a file\")", "successors": []}, {"id": 6, "label": "return content[\"content\"], content[\"size\"]", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 427, "end_line": 442, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        raw_content, size = self.read_file(\n            credentials,\n            input_data.repo_url,\n            input_data.file_path.lstrip(\"/\"),\n            input_data.branch,\n        )\n        yield \"raw_content\", raw_content\n        yield \"text_content\", base64.b64decode(raw_content).decode(\"utf-8\")\n        yield \"size\", size", "blocks": [{"id": 1, "label": "def run( self, input_data: Input, *, credentials: GithubCredentials, **kwargs, ) -> BlockOutput:\n    raw_content, size = self.read_file( credentials, input_data.repo_url, input_data.file_path.lstrip(\"/\"), input_data.branch, )", "successors": [{"id": 3, "label": "    yield \"raw_content\", raw_content\n    yield \"text_content\", base64.b64decode(raw_content).decode(\"utf-8\")", "successors": [{"id": 5, "label": "    yield \"size\", size", "successors": []}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 359, "end_line": 373, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        repo_url: str = SchemaField(\n            description=\"URL of the GitHub repository\",\n            placeholder=\"https://github.com/owner/repo\",\n        )\n        file_path: str = SchemaField(\n            description=\"Path to the file in the repository\",\n            placeholder=\"path/to/file\",\n        )\n        branch: str = SchemaField(\n            description=\"Branch to read from\",\n            placeholder=\"branch_name\",\n            default=\"master\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")", "successors": []}, {"id": 3, "label": "repo_url: str = SchemaField(description=\"URL of the GitHub repository\", placeholder=\"https://github.com/owner/repo\")", "successors": []}, {"id": 4, "label": "file_path: str = SchemaField(description=\"Path to the file in the repository\", placeholder=\"path/to/file\")", "successors": []}, {"id": 5, "label": "branch: str = SchemaField(description=\"Branch to read from\", placeholder=\"branch_name\", default=\"master\")", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 375, "end_line": 383, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        text_content: str = SchemaField(\n            description=\"Content of the file (decoded as UTF-8 text)\"\n        )\n        raw_content: str = SchemaField(\n            description=\"Raw base64-encoded content of the file\"\n        )\n        size: int = SchemaField(description=\"The size of the file (in bytes)\")\n        error: str = SchemaField(description=\"Error message if the file reading failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\ntext_content: str = SchemaField(\n    description=\"Content of the file (decoded as UTF-8 text)\"\n)", "successors": [{"id": 3, "label": "raw_content: str = SchemaField(\n    description=\"Raw base64-encoded content of the file\"\n)\nsize: int = SchemaField(description=\"The size of the file (in bytes)\")", "successors": [{"id": 5, "label": "error: str = SchemaField(description=\"Error message if the file reading failed\")", "successors": []}]}]}]}], "simplified_code": "class GithubReadFileBlock(Block):\n        )\n\n        error: str = SchemaField(description=\"Error message if the file reading failed\")\n\n        )\n\n    @staticmethod\n        return content[\"content\"], content[\"size\"]\n\n        yield \"size\", size\n\n", "blocks": [{"id": 1, "label": "class GithubReadFileBlock(Block):\nerror: str = SchemaField(description=\"Error message if the file reading failed\")", "successors": [{"id": 3, "label": "@staticmethod\nreturn content[\"content\"], content[\"size\"]", "successors": [{"id": 5, "label": "yield \"size\", size", "successors": []}]}]}]}, {"name": "GithubReadFolderBlock", "type": "class", "start_line": 445, "end_line": 565, "functions": [{"name": "__init__", "type": "function", "start_line": 478, "end_line": 515, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"1355f863-2db3-4d75-9fba-f91e8a8ca400\",\n            description=\"This block reads the content of a specified folder from a GitHub repository.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubReadFolderBlock.Input,\n            output_schema=GithubReadFolderBlock.Output,\n            test_input={\n                \"repo_url\": \"https://github.com/owner/repo\",\n                \"folder_path\": \"path/to/folder\",\n                \"branch\": \"master\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\n                    \"file\",\n                    {\n                        \"name\": \"file1.txt\",\n                        \"path\": \"path/to/folder/file1.txt\",\n                        \"size\": 1337,\n                    },\n                ),\n                (\"dir\", {\"name\": \"dir2\", \"path\": \"path/to/folder/dir2\"}),\n            ],\n            test_mock={\n                \"read_folder\": lambda *args, **kwargs: (\n                    [\n                        {\n                            \"name\": \"file1.txt\",\n                            \"path\": \"path/to/folder/file1.txt\",\n                            \"size\": 1337,\n                        }\n                    ],\n                    [{\"name\": \"dir2\", \"path\": \"path/to/folder/dir2\"}],\n                )\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"1355f863-2db3-4d75-9fba-f91e8a8ca400\",\n    description=\"This block reads the content of a specified folder from a GitHub repository.\",\n    categories={BlockCategory.DEVELOPER_TOOLS},\n    input_schema=GithubReadFolderBlock.Input,\n    output_schema=GithubReadFolderBlock.Output,\n    test_input={\n        \"repo_url\": \"https://github.com/owner/repo\",\n        \"folder_path\": \"path/to/folder\",\n        \"branch\": \"master\",\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\n            \"file\",\n            {\n                \"name\": \"file1.txt\",\n                \"path\": \"path/to/folder/file1.txt\",\n                \"size\": 1337,\n            },\n        ),\n        (\"dir\", {\"name\": \"dir2\", \"path\": \"path/to/folder/dir2\"}),\n    ],\n    test_mock={\n        \"read_folder\": lambda *args, **kwargs: (\n            [\n                {\n                    \"name\": \"file1.txt\",\n                    \"path\": \"path/to/folder/file1.txt\",\n                    \"size\": 1337,\n                }\n            ],\n            [{\"name\": \"dir2\", \"path\": \"path/to/folder/dir2\"}],\n        )\n    },\n)", "successors": []}]}, {"name": "read_folder", "type": "function", "start_line": 518, "end_line": 547, "functions": [], "classes": [], "simplified_code": "    def read_folder(\n        credentials: GithubCredentials, repo_url: str, folder_path: str, branch: str\n    ) -> tuple[list[Output.FileEntry], list[Output.DirEntry]]:\n        api = get_api(credentials)\n        contents_url = repo_url + f\"/contents/{folder_path}?ref={branch}\"\n        response = api.get(contents_url)\n        content = response.json()\n\n        if not isinstance(content, list):\n            raise TypeError(\"Not a folder\")\n\n        files = [\n            GithubReadFolderBlock.Output.FileEntry(\n                name=entry[\"name\"],\n                path=entry[\"path\"],\n                size=entry[\"size\"],\n            )\n            for entry in content\n            if entry[\"type\"] == \"file\"\n        ]\n        dirs = [\n            GithubReadFolderBlock.Output.DirEntry(\n                name=entry[\"name\"],\n                path=entry[\"path\"],\n            )\n            for entry in content\n            if entry[\"type\"] == \"dir\"\n        ]\n\n        return files, dirs", "blocks": [{"id": 1, "label": "def read_folder(\n    credentials: GithubCredentials, repo_url: str, folder_path: str, branch: str\n) -> tuple[list[Output.FileEntry], list[Output.DirEntry]]:\n    api = get_api(credentials)\n    contents_url = repo_url + f\"/contents/{folder_path}?ref={branch}\"\n    response = api.get(contents_url)\n    content = response.json()\nif not isinstance(content, list):\n    raise TypeError(\"Not a folder\")", "successors": [{"id": 3, "label": "files = [\n    GithubReadFolderBlock.Output.FileEntry(\n        name=entry[\"name\"],\n        path=entry[\"path\"],\n        size=entry[\"size\"],\n    )\n    for entry in content\n    if entry[\"type\"] == \"file\"\n]\ndirs = [\n    GithubReadFolderBlock.Output.DirEntry(\n        name=entry[\"name\"],\n        path=entry[\"path\"],\n    )\n    for entry in content\n    if entry[\"type\"] == \"dir\"\n]", "successors": [{"id": 5, "label": "return files, dirs", "successors": []}]}]}]}, {"name": "run", "type": "function", "start_line": 549, "end_line": 563, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        files, dirs = self.read_folder(\n            credentials,\n            input_data.repo_url,\n            input_data.folder_path.lstrip(\"/\"),\n            input_data.branch,\n        )\n        yield from ((\"file\", file) for file in files)\n        yield from ((\"dir\", dir) for dir in dirs)", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: GithubCredentials, **kwargs) -> BlockOutput:\nfiles, dirs = self.read_folder(credentials, input_data.repo_url, input_data.folder_path.lstrip(\"/\"), input_data.branch)", "successors": [{"id": 3, "label": "yield from ((\"file\", file) for file in files)\nyield from ((\"dir\", dir) for dir in dirs)", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 446, "end_line": 460, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        repo_url: str = SchemaField(\n            description=\"URL of the GitHub repository\",\n            placeholder=\"https://github.com/owner/repo\",\n        )\n        folder_path: str = SchemaField(\n            description=\"Path to the folder in the repository\",\n            placeholder=\"path/to/folder\",\n        )\n        branch: str = SchemaField(\n            description=\"Branch name to read from (defaults to master)\",\n            placeholder=\"branch_name\",\n            default=\"master\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")", "successors": [{"id": 3, "label": "    repo_url: str = SchemaField(description=\"URL of the GitHub repository\", placeholder=\"https://github.com/owner/repo\")\n    folder_path: str = SchemaField(description=\"Path to the folder in the repository\", placeholder=\"path/to/folder\")", "successors": [{"id": 5, "label": "    branch: str = SchemaField(description=\"Branch name to read from (defaults to master)\", placeholder=\"branch_name\", default=\"master\")", "successors": []}]}]}]}, {"name": "Output", "type": "class", "start_line": 462, "end_line": 476, "functions": [], "classes": [{"name": "DirEntry", "type": "class", "start_line": 463, "end_line": 465, "functions": [], "classes": [], "simplified_code": "        class DirEntry(TypedDict):\n            name: str\n            path: str", "blocks": [{"id": 1, "label": "class DirEntry(TypedDict):\n    name: str\n    path: str", "successors": []}]}, {"name": "FileEntry", "type": "class", "start_line": 467, "end_line": 470, "functions": [], "classes": [], "simplified_code": "        class FileEntry(TypedDict):\n            name: str\n            path: str\n            size: int", "blocks": [{"id": 1, "label": "class FileEntry(TypedDict):\n    name: str\n    path: str\n    size: int", "successors": []}]}], "simplified_code": "    class Output(BlockSchema):\n            path: str\n\n            size: int\n\n        file: FileEntry = SchemaField(description=\"Files in the folder\")\n        dir: DirEntry = SchemaField(description=\"Directories in the folder\")\n        error: str = SchemaField(\n            description=\"Error message if reading the folder failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    path: str", "successors": [{"id": 3, "label": "    size: int\nfile: FileEntry = SchemaField(description=\"Files in the folder\")", "successors": [{"id": 5, "label": "dir: DirEntry = SchemaField(description=\"Directories in the folder\")\nerror: str = SchemaField(description=\"Error message if reading the folder failed\")", "successors": []}]}]}]}], "simplified_code": "class GithubReadFolderBlock(Block):\n        )\n\n        )\n\n        )\n\n    @staticmethod\n        return files, dirs\n\n        yield from ((\"dir\", dir) for dir in dirs)\n\n", "blocks": [{"id": 1, "label": "class GithubReadFolderBlock(Block):", "successors": [{"id": 2, "label": "", "successors": []}, {"id": 3, "label": "", "successors": []}, {"id": 4, "label": "", "successors": []}]}]}, {"name": "GithubMakeBranchBlock", "type": "class", "start_line": 566, "end_line": 642, "functions": [{"name": "__init__", "type": "function", "start_line": 588, "end_line": 606, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"944cc076-95e7-4d1b-b6b6-b15d8ee5448d\",\n            description=\"This block creates a new branch from a specified source branch.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubMakeBranchBlock.Input,\n            output_schema=GithubMakeBranchBlock.Output,\n            test_input={\n                \"repo_url\": \"https://github.com/owner/repo\",\n                \"new_branch\": \"new_branch_name\",\n                \"source_branch\": \"source_branch_name\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[(\"status\", \"Branch created successfully\")],\n            test_mock={\n                \"create_branch\": lambda *args, **kwargs: \"Branch created successfully\"\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"944cc076-95e7-4d1b-b6b6-b15d8ee5448d\",\n    description=\"This block creates a new branch from a specified source branch.\",\n    categories={BlockCategory.DEVELOPER_TOOLS},\n    input_schema=GithubMakeBranchBlock.Input,\n    output_schema=GithubMakeBranchBlock.Output,\n    test_input={\n        \"repo_url\": \"https://github.com/owner/repo\",\n        \"new_branch\": \"new_branch_name\",\n        \"source_branch\": \"source_branch_name\",\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[(\"status\", \"Branch created successfully\")],\n    test_mock={\n        \"create_branch\": lambda *args, **kwargs: \"Branch created successfully\"\n    },\n)", "successors": []}]}, {"name": "create_branch", "type": "function", "start_line": 609, "end_line": 625, "functions": [], "classes": [], "simplified_code": "    def create_branch(\n        credentials: GithubCredentials,\n        repo_url: str,\n        new_branch: str,\n        source_branch: str,\n    ) -> str:\n        api = get_api(credentials)\n        # Get the SHA of the source branch\n        ref_url = repo_url + f\"/git/refs/heads/{source_branch}\"\n        response = api.get(ref_url)\n        sha = response.json()[\"object\"][\"sha\"]\n\n        # Create the new branch\n        create_ref_url = repo_url + \"/git/refs\"\n        data = {\"ref\": f\"refs/heads/{new_branch}\", \"sha\": sha}\n        response = api.post(create_ref_url, json=data)\n        return \"Branch created successfully\"", "blocks": [{"id": 1, "label": "def create_branch(\n    credentials: GithubCredentials,\n    repo_url: str,\n    new_branch: str,\n    source_branch: str,\n) -> str:\n    api = get_api(credentials)", "successors": [{"id": 3, "label": "    ref_url = repo_url + f\"/git/refs/heads/{source_branch}\"\n    response = api.get(ref_url)", "successors": [{"id": 5, "label": "    sha = response.json()[\"object\"][\"sha\"]\n    create_ref_url = repo_url + \"/git/refs\"", "successors": [{"id": 7, "label": "    data = {\"ref\": f\"refs/heads/{new_branch}\", \"sha\": sha}\n    response = api.post(create_ref_url, json=data)", "successors": [{"id": 9, "label": "    return \"Branch created successfully\"", "successors": []}]}]}]}]}]}, {"name": "run", "type": "function", "start_line": 627, "end_line": 640, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        status = self.create_branch(\n            credentials,\n            input_data.repo_url,\n            input_data.new_branch,\n            input_data.source_branch,\n        )\n        yield \"status\", status", "blocks": [{"id": 1, "label": "def run(\n    self,\n    input_data: Input,\n    *,\n    credentials: GithubCredentials,\n    **kwargs,\n) -> BlockOutput:\nstatus = self.create_branch(\n    credentials,\n    input_data.repo_url,\n    input_data.new_branch,\n    input_data.source_branch,\n)", "successors": [{"id": 3, "label": "yield \"status\", status", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 567, "end_line": 580, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        repo_url: str = SchemaField(\n            description=\"URL of the GitHub repository\",\n            placeholder=\"https://github.com/owner/repo\",\n        )\n        new_branch: str = SchemaField(\n            description=\"Name of the new branch\",\n            placeholder=\"new_branch_name\",\n        )\n        source_branch: str = SchemaField(\n            description=\"Name of the source branch\",\n            placeholder=\"source_branch_name\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")", "successors": []}, {"id": 3, "label": "    repo_url: str = SchemaField(\n        description=\"URL of the GitHub repository\",\n        placeholder=\"https://github.com/owner/repo\",\n    )", "successors": []}, {"id": 4, "label": "    new_branch: str = SchemaField(\n        description=\"Name of the new branch\",\n        placeholder=\"new_branch_name\",\n    )", "successors": []}, {"id": 5, "label": "    source_branch: str = SchemaField(\n        description=\"Name of the source branch\",\n        placeholder=\"source_branch_name\",\n    )", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 582, "end_line": 586, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        status: str = SchemaField(description=\"Status of the branch creation operation\")\n        error: str = SchemaField(\n            description=\"Error message if the branch creation failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "    status: str = SchemaField(description=\"Status of the branch creation operation\")", "successors": []}, {"id": 3, "label": "    error: str = SchemaField(description=\"Error message if the branch creation failed\")", "successors": []}]}]}], "simplified_code": "class GithubMakeBranchBlock(Block):\n        )\n\n        )\n\n        )\n\n    @staticmethod\n        return \"Branch created successfully\"\n\n        yield \"status\", status\n\n", "blocks": [{"id": 1, "label": "class GithubMakeBranchBlock(Block):\n@staticmethod", "successors": [{"id": 3, "label": "return \"Branch created successfully\"", "successors": []}]}]}, {"name": "GithubDeleteBranchBlock", "type": "class", "start_line": 643, "end_line": 701, "functions": [{"name": "__init__", "type": "function", "start_line": 661, "end_line": 678, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"0d4130f7-e0ab-4d55-adc3-0a40225e80f4\",\n            description=\"This block deletes a specified branch.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubDeleteBranchBlock.Input,\n            output_schema=GithubDeleteBranchBlock.Output,\n            test_input={\n                \"repo_url\": \"https://github.com/owner/repo\",\n                \"branch\": \"branch_name\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[(\"status\", \"Branch deleted successfully\")],\n            test_mock={\n                \"delete_branch\": lambda *args, **kwargs: \"Branch deleted successfully\"\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"0d4130f7-e0ab-4d55-adc3-0a40225e80f4\",\n    description=\"This block deletes a specified branch.\",\n    categories={BlockCategory.DEVELOPER_TOOLS},\n    input_schema=GithubDeleteBranchBlock.Input,\n    output_schema=GithubDeleteBranchBlock.Output,\n    test_input={\n        \"repo_url\": \"https://github.com/owner/repo\",\n        \"branch\": \"branch_name\",\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[(\"status\", \"Branch deleted successfully\")],\n    test_mock={\n        \"delete_branch\": lambda *args, **kwargs: \"Branch deleted successfully\"\n    },\n)", "successors": []}]}, {"name": "delete_branch", "type": "function", "start_line": 681, "end_line": 687, "functions": [], "classes": [], "simplified_code": "    def delete_branch(\n        credentials: GithubCredentials, repo_url: str, branch: str\n    ) -> str:\n        api = get_api(credentials)\n        ref_url = repo_url + f\"/git/refs/heads/{branch}\"\n        api.delete(ref_url)\n        return \"Branch deleted successfully\"", "blocks": [{"id": 1, "label": "def delete_branch(\n    credentials: GithubCredentials, repo_url: str, branch: str\n) -> str:\napi = get_api(credentials)\nref_url = repo_url + f\"/git/refs/heads/{branch}\"\napi.delete(ref_url)\nreturn \"Branch deleted successfully\"", "successors": []}]}, {"name": "run", "type": "function", "start_line": 689, "end_line": 700, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        status = self.delete_branch(\n            credentials,\n            input_data.repo_url,\n            input_data.branch,\n        )", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: GithubCredentials, **kwargs) -> BlockOutput:\nstatus = self.delete_branch(credentials, input_data.repo_url, input_data.branch)", "successors": []}]}], "classes": [{"name": "Input", "type": "class", "start_line": 644, "end_line": 653, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        repo_url: str = SchemaField(\n            description=\"URL of the GitHub repository\",\n            placeholder=\"https://github.com/owner/repo\",\n        )\n        branch: str = SchemaField(\n            description=\"Name of the branch to delete\",\n            placeholder=\"branch_name\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")", "successors": [{"id": 3, "label": "    repo_url: str = SchemaField(\n        description=\"URL of the GitHub repository\",\n        placeholder=\"https://github.com/owner/repo\",\n    )\n    branch: str = SchemaField(\n        description=\"Name of the branch to delete\",\n        placeholder=\"branch_name\",\n    )", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 655, "end_line": 659, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        status: str = SchemaField(description=\"Status of the branch deletion operation\")\n        error: str = SchemaField(\n            description=\"Error message if the branch deletion failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    status: str = SchemaField(description=\"Status of the branch deletion operation\")", "successors": [{"id": 3, "label": "    error: str = SchemaField(description=\"Error message if the branch deletion failed\")", "successors": []}]}]}], "simplified_code": "class GithubDeleteBranchBlock(Block):\n        )\n\n        )\n\n        )\n\n    @staticmethod\n        return \"Branch deleted successfully\"\n\n        )\n        yield \"status\", status", "blocks": [{"id": 1, "label": "class GithubDeleteBranchBlock(Block):", "successors": [{"id": 2, "label": "@staticmethod\nreturn \"Branch deleted successfully\"", "successors": []}, {"id": 4, "label": "yield \"status\", status", "successors": []}]}]}], "simplified_code": "import base64\n\nfrom typing_extensions import TypedDict\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\nfrom ._api import get_api\nfrom ._auth import (\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    GithubCredentials,\n    GithubCredentialsField,\n    GithubCredentialsInput,\n)\n\n\n\n\n\n\n\n\n\n\n\n        yield \"status\", status", "blocks": [{"id": 1, "label": "import base64\n\nfrom typing_extensions import TypedDict\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\nfrom ._api import get_api\nfrom ._auth import (\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    GithubCredentials,\n    GithubCredentialsField,\n    GithubCredentialsInput,\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    yield \"status\", status", "successors": []}]}
{"file_name": "13.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 102, "functions": [], "classes": [{"name": "UnrealTextToSpeechBlock", "type": "class", "start_line": 30, "end_line": 102, "functions": [{"name": "__init__", "type": "function", "start_line": 52, "end_line": 71, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"4ff1ff6d-cc40-4caa-ae69-011daa20c378\",\n            description=\"Converts text to speech using the Unreal Speech API\",\n            categories={BlockCategory.AI, BlockCategory.TEXT},\n            input_schema=UnrealTextToSpeechBlock.Input,\n            output_schema=UnrealTextToSpeechBlock.Output,\n            test_input={\n                \"text\": \"This is a test of the text to speech API.\",\n                \"voice_id\": \"Scarlett\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_output=[(\"mp3_url\", \"https://example.com/test.mp3\")],\n            test_mock={\n                \"call_unreal_speech_api\": lambda *args, **kwargs: {\n                    \"OutputUri\": \"https://example.com/test.mp3\"\n                }\n            },\n            test_credentials=TEST_CREDENTIALS,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"4ff1ff6d-cc40-4caa-ae69-011daa20c378\",\n    description=\"Converts text to speech using the Unreal Speech API\",\n    categories={BlockCategory.AI, BlockCategory.TEXT},\n    input_schema=UnrealTextToSpeechBlock.Input,\n    output_schema=UnrealTextToSpeechBlock.Output,\n    test_input={\n        \"text\": \"This is a test of the text to speech API.\",\n        \"voice_id\": \"Scarlett\",\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_output=[(\"mp3_url\", \"https://example.com/test.mp3\")],\n    test_mock={\n        \"call_unreal_speech_api\": lambda *args, **kwargs: {\n            \"OutputUri\": \"https://example.com/test.mp3\"\n        }\n    },\n    test_credentials=TEST_CREDENTIALS,\n)", "successors": []}]}, {"name": "call_unreal_speech_api", "type": "function", "start_line": 74, "end_line": 92, "functions": [], "classes": [], "simplified_code": "    def call_unreal_speech_api(\n        api_key: SecretStr, text: str, voice_id: str\n    ) -> dict[str, Any]:\n        url = \"https://api.v7.unrealspeech.com/speech\"\n        headers = {\n            \"Authorization\": f\"Bearer {api_key.get_secret_value()}\",\n            \"Content-Type\": \"application/json\",\n        }\n        data = {\n            \"Text\": text,\n            \"VoiceId\": voice_id,\n            \"Bitrate\": \"192k\",\n            \"Speed\": \"0\",\n            \"Pitch\": \"1\",\n            \"TimestampType\": \"sentence\",\n        }\n\n        response = requests.post(url, headers=headers, json=data)\n        return response.json()", "blocks": [{"id": 1, "label": "def call_unreal_speech_api( api_key: SecretStr, text: str, voice_id: str ) -> dict[str, Any]:\nurl = \"https://api.v7.unrealspeech.com/speech\"\nheaders = {\n    \"Authorization\": f\"Bearer {api_key.get_secret_value()}\",\n    \"Content-Type\": \"application/json\",\n}\ndata = {\n    \"Text\": text,\n    \"VoiceId\": voice_id,\n    \"Bitrate\": \"192k\",\n    \"Speed\": \"0\",\n    \"Pitch\": \"1\",\n    \"TimestampType\": \"sentence\",\n}\n\nresponse = requests.post(url, headers=headers, json=data)", "successors": [{"id": 3, "label": "return response.json()", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 94, "end_line": 102, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        api_response = self.call_unreal_speech_api(\n            credentials.api_key,\n            input_data.text,\n            input_data.voice_id,\n        )\n        yield \"mp3_url\", api_response[\"OutputUri\"]", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs) -> BlockOutput:\napi_response = self.call_unreal_speech_api(credentials.api_key, input_data.text, input_data.voice_id,)", "successors": [{"id": 3, "label": "yield \"mp3_url\", api_response[\"OutputUri\"]", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 31, "end_line": 46, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        text: str = SchemaField(\n            description=\"The text to be converted to speech\",\n            placeholder=\"Enter the text you want to convert to speech\",\n        )\n        voice_id: str = SchemaField(\n            description=\"The voice ID to use for text-to-speech conversion\",\n            placeholder=\"Scarlett\",\n            default=\"Scarlett\",\n        )\n        credentials: CredentialsMetaInput[\n            Literal[ProviderName.UNREAL_SPEECH], Literal[\"api_key\"]\n        ] = CredentialsField(\n            description=\"The Unreal Speech integration can be used with \"\n            \"any API key with sufficient permissions for the blocks it is used on.\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "text: str = SchemaField(\n description=\"The text to be converted to speech\",\n placeholder=\"Enter the text you want to convert to speech\",\n )", "successors": []}, {"id": 3, "label": "voice_id: str = SchemaField(\n description=\"The voice ID to use for text-to-speech conversion\",\n placeholder=\"Scarlett\",\n default=\"Scarlett\",\n )", "successors": []}, {"id": 4, "label": "credentials: CredentialsMetaInput[\n Literal[ProviderName.UNREAL_SPEECH], Literal[\"api_key\"]\n ] = CredentialsField(\n description=\"The Unreal Speech integration can be used with \"\n \"any API key with sufficient permissions for the blocks it is used on.\",\n )", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 48, "end_line": 50, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        mp3_url: str = SchemaField(description=\"The URL of the generated MP3 file\")\n        error: str = SchemaField(description=\"Error message if the API call failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "    mp3_url: str = SchemaField(description=\"The URL of the generated MP3 file\")", "successors": []}, {"id": 3, "label": "    error: str = SchemaField(description=\"Error message if the API call failed\")", "successors": []}]}]}], "simplified_code": "class UnrealTextToSpeechBlock(Block):\n        )\n\n        error: str = SchemaField(description=\"Error message if the API call failed\")\n\n        )\n\n    @staticmethod\n        return response.json()\n\n        yield \"mp3_url\", api_response[\"OutputUri\"]", "blocks": [{"id": 1, "label": "class UnrealTextToSpeechBlock(Block):", "successors": [{"id": 2, "label": "error: str = SchemaField(description=\"Error message if the API call failed\")", "successors": []}, {"id": 3, "label": "@staticmethod", "successors": [{"id": 4, "label": "return response.json()", "successors": []}, {"id": 5, "label": "yield \"mp3_url\", api_response[\"OutputUri\"]", "successors": []}]}]}]}], "simplified_code": "from typing import Any, Literal\n\nfrom pydantic import SecretStr\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\nfrom backend.util.request import requests\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"unreal_speech\",\n    api_key=SecretStr(\"mock-unreal-speech-api-key\"),\n    title=\"Mock Unreal Speech API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.type,\n}\n\n\n        yield \"mp3_url\", api_response[\"OutputUri\"]", "blocks": [{"id": 1, "label": "from typing import Any, Literal\n\nfrom pydantic import SecretStr\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\nfrom backend.util.request import requests\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"unreal_speech\",\n    api_key=SecretStr(\"mock-unreal-speech-api-key\"),\n    title=\"Mock Unreal Speech API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.type,\n}\n\n\nyield \"mp3_url\", api_response[\"OutputUri\"]", "successors": []}]}
{"file_name": "14.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 22, "functions": [], "classes": [{"name": "TextFormatter", "type": "class", "start_line": 7, "end_line": 22, "functions": [{"name": "__init__", "type": "function", "start_line": 8, "end_line": 15, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        # Create a sandboxed environment\n        self.env = SandboxedEnvironment(loader=BaseLoader(), autoescape=True)\n\n        # Clear any registered filters, tests, and globals to minimize attack surface\n        self.env.filters.clear()\n        self.env.tests.clear()\n        self.env.globals.clear()", "blocks": [{"id": 1, "label": "def __init__(self):\n    self.env = SandboxedEnvironment(loader=BaseLoader(), autoescape=True)", "successors": [{"id": 3, "label": "    self.env.filters.clear()\n    self.env.tests.clear()", "successors": [{"id": 5, "label": "    self.env.globals.clear()", "successors": []}]}]}]}, {"name": "format_string", "type": "function", "start_line": 17, "end_line": 22, "functions": [], "classes": [], "simplified_code": "    def format_string(self, template_str: str, values=None, **kwargs) -> str:\n        # For python.format compatibility: replace all {...} with {{..}}.\n        # But avoid replacing {{...}} to {{{...}}}.\n        template_str = re.sub(r\"(?<!{){[ a-zA-Z0-9_]+}\", r\"{\\g<0>}\", template_str)\n        template = self.env.from_string(template_str)\n        return template.render(values or {}, **kwargs)", "blocks": [{"id": 1, "label": "def format_string(self, template_str: str, values=None, **kwargs) -> str:\n    template_str = re.sub(r\"(?<!{){[ a-zA-Z0-9_]+}\", r\"{\\g<0>}\", template_str)", "successors": [{"id": 3, "label": "    template = self.env.from_string(template_str)\n    return template.render(values or {}, **kwargs)", "successors": []}]}]}], "simplified_code": "class TextFormatter:\n        self.env.globals.clear()\n\n        return template.render(values or {}, **kwargs)", "blocks": [{"id": 1, "label": "class TextFormatter:\nself.env.globals.clear()", "successors": [{"id": 3, "label": "return template.render(values or {}, **kwargs)", "successors": []}]}]}], "simplified_code": "import re\n\nfrom jinja2 import BaseLoader\nfrom jinja2.sandbox import SandboxedEnvironment\n\n\n        return template.render(values or {}, **kwargs)", "blocks": [{"id": 1, "label": "import re\nfrom jinja2 import BaseLoader", "successors": [{"id": 3, "label": "from jinja2.sandbox import SandboxedEnvironment\nreturn template.render(values or {}, **kwargs)", "successors": []}]}]}
{"file_name": "15.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 100, "functions": [], "classes": [{"name": "IIRFilter", "type": "class", "start_line": 4, "end_line": 100, "functions": [{"name": "__init__", "type": "function", "start_line": 26, "end_line": 37, "functions": [], "classes": [], "simplified_code": "    def __init__(self, order: int) -> None:\n        self.order = order\n\n        # a_{0} ... a_{k}\n        self.a_coeffs = [1.0] + [0.0] * order\n        # b_{0} ... b_{k}\n        self.b_coeffs = [1.0] + [0.0] * order\n\n        # x[n-1] ... x[n-k]\n        self.input_history = [0.0] * self.order\n        # y[n-1] ... y[n-k]\n        self.output_history = [0.0] * self.order", "blocks": [{"id": 1, "label": "def __init__(self, order: int) -> None:\nself.order = order\n\n# a_{0} ... a_{k}\nself.a_coeffs = [1.0] + [0.0] * order\n# b_{0} ... b_{k}\nself.b_coeffs = [1.0] + [0.0] * order\n\n# x[n-1] ... x[n-k]\nself.input_history = [0.0] * self.order\n# y[n-1] ... y[n-k]\nself.output_history = [0.0] * self.order", "successors": []}]}, {"name": "set_coefficients", "type": "function", "start_line": 39, "end_line": 73, "functions": [], "classes": [], "simplified_code": "    def set_coefficients(self, a_coeffs: list[float], b_coeffs: list[float]) -> None:\n        \"\"\"\n        Set the coefficients for the IIR filter.\n        These should both be of size `order` + 1.\n        :math:`a_0` may be left out, and it will use 1.0 as default value.\n\n        This method works well with scipy's filter design functions\n\n        >>> # Make a 2nd-order 1000Hz butterworth lowpass filter\n        >>> import scipy.signal\n        >>> b_coeffs, a_coeffs = scipy.signal.butter(2, 1000,\n        ...                                          btype='lowpass',\n        ...                                          fs=48000)\n        >>> filt = IIRFilter(2)\n        >>> filt.set_coefficients(a_coeffs, b_coeffs)\n        \"\"\"\n        if len(a_coeffs) < self.order:\n            a_coeffs = [1.0, *a_coeffs]\n\n        if len(a_coeffs) != self.order + 1:\n            msg = (\n                f\"Expected a_coeffs to have {self.order + 1} elements \"\n                f\"for {self.order}-order filter, got {len(a_coeffs)}\"\n            )\n            raise ValueError(msg)\n\n        if len(b_coeffs) != self.order + 1:\n            msg = (\n                f\"Expected b_coeffs to have {self.order + 1} elements \"\n                f\"for {self.order}-order filter, got {len(a_coeffs)}\"\n            )\n            raise ValueError(msg)\n\n        self.a_coeffs = a_coeffs\n        self.b_coeffs = b_coeffs", "blocks": [{"id": 1, "label": "def set_coefficients(self, a_coeffs: list[float], b_coeffs: list[float]) -> None:", "successors": [{"id": 2, "label": "if len(a_coeffs) < self.order:", "successors": [{"id": 3, "label": "a_coeffs = [1.0, *a_coeffs]", "successors": [{"id": 4, "label": "if len(a_coeffs) != self.order + 1:", "successors": [{"id": 5, "label": "msg = (f\"Expected a_coeffs to have {self.order + 1} elements \" f\"for {self.order}-order filter, got {len(a_coeffs)}\")\nraise ValueError(msg)", "successors": []}, {"id": 7, "label": "if len(b_coeffs) != self.order + 1:", "successors": [{"id": 8, "label": "msg = (f\"Expected b_coeffs to have {self.order + 1} elements \" f\"for {self.order}-order filter, got {len(a_coeffs)}\")\nraise ValueError(msg)", "successors": []}, {"id": 10, "label": "self.a_coeffs = a_coeffs\nself.b_coeffs = b_coeffs", "successors": []}]}]}, {"id": 7, "label": "if len(b_coeffs) != self.order + 1:", "successors": [{"id": 8, "label": "msg = (f\"Expected b_coeffs to have {self.order + 1} elements \" f\"for {self.order}-order filter, got {len(a_coeffs)}\")\nraise ValueError(msg)", "successors": []}, {"id": 10, "label": "self.a_coeffs = a_coeffs\nself.b_coeffs = b_coeffs", "successors": []}]}]}, {"id": 4, "label": "if len(a_coeffs) != self.order + 1:", "successors": [{"id": 5, "label": "msg = (f\"Expected a_coeffs to have {self.order + 1} elements \" f\"for {self.order}-order filter, got {len(a_coeffs)}\")\nraise ValueError(msg)", "successors": []}, {"id": 7, "label": "if len(b_coeffs) != self.order + 1:", "successors": [{"id": 8, "label": "msg = (f\"Expected b_coeffs to have {self.order + 1} elements \" f\"for {self.order}-order filter, got {len(a_coeffs)}\")\nraise ValueError(msg)", "successors": []}, {"id": 10, "label": "self.a_coeffs = a_coeffs\nself.b_coeffs = b_coeffs", "successors": []}]}]}]}, {"id": 7, "label": "if len(b_coeffs) != self.order + 1:", "successors": [{"id": 8, "label": "msg = (f\"Expected b_coeffs to have {self.order + 1} elements \" f\"for {self.order}-order filter, got {len(a_coeffs)}\")\nraise ValueError(msg)", "successors": []}, {"id": 10, "label": "self.a_coeffs = a_coeffs\nself.b_coeffs = b_coeffs", "successors": []}]}]}]}, {"name": "process", "type": "function", "start_line": 75, "end_line": 100, "functions": [], "classes": [], "simplified_code": "    def process(self, sample: float) -> float:\n        \"\"\"\n        Calculate :math:`y[n]`\n\n        >>> filt = IIRFilter(2)\n        >>> filt.process(0)\n        0.0\n        \"\"\"\n        result = 0.0\n\n        # Start at index 1 and do index 0 at the end.\n        for i in range(1, self.order + 1):\n            result += (\n                self.b_coeffs[i] * self.input_history[i - 1]\n                - self.a_coeffs[i] * self.output_history[i - 1]\n            )\n\n        result = (result + self.b_coeffs[0] * sample) / self.a_coeffs[0]\n\n        self.input_history[1:] = self.input_history[:-1]\n        self.output_history[1:] = self.output_history[:-1]\n\n        self.input_history[0] = sample\n        self.output_history[0] = result\n\n        return result", "blocks": [{"id": 1, "label": "def process(self, sample: float) -> float:\nresult = 0.0", "successors": [{"id": 3, "label": "for i in range(1, self.order + 1):", "successors": [{"id": 4, "label": "result += (\n    self.b_coeffs[i] * self.input_history[i - 1]\n    - self.a_coeffs[i] * self.output_history[i - 1]\n)\nresult = (result + self.b_coeffs[0] * sample) / self.a_coeffs[0]", "successors": [{"id": 6, "label": "self.input_history[1:] = self.input_history[:-1]\nself.output_history[1:] = self.output_history[:-1]\nself.input_history[0] = sample\nself.output_history[0] = result", "successors": [{"id": 8, "label": "return result", "successors": []}]}]}, {"id": 5, "label": "result = (result + self.b_coeffs[0] * sample) / self.a_coeffs[0]\nself.input_history[1:] = self.input_history[:-1]\nself.output_history[1:] = self.output_history[:-1]", "successors": [{"id": 7, "label": "self.input_history[0] = sample\nself.output_history[0] = result\nreturn result", "successors": []}]}]}]}]}], "classes": [], "simplified_code": "class IIRFilter:\n    r\"\"\"\n    N-Order IIR filter\n    Assumes working with float samples normalized on [-1, 1]\n\n    ---\n\n    Implementation details:\n    Based on the 2nd-order function from\n    https://en.wikipedia.org/wiki/Digital_biquad_filter,\n    this generalized N-order function was made.\n\n    Using the following transfer function\n        .. math:: H(z)=\\frac{b_{0}+b_{1}z^{-1}+b_{2}z^{-2}+...+b_{k}z^{-k}}\n                  {a_{0}+a_{1}z^{-1}+a_{2}z^{-2}+...+a_{k}z^{-k}}\n\n    we can rewrite this to\n        .. math:: y[n]={\\frac{1}{a_{0}}}\n                  \\left(\\left(b_{0}x[n]+b_{1}x[n-1]+b_{2}x[n-2]+...+b_{k}x[n-k]\\right)-\n                  \\left(a_{1}y[n-1]+a_{2}y[n-2]+...+a_{k}y[n-k]\\right)\\right)\n    \"\"\"\n\n        self.output_history = [0.0] * self.order\n\n        self.b_coeffs = b_coeffs\n\n        return result", "blocks": [{"id": 1, "label": "class IIRFilter:", "successors": [{"id": 2, "label": "self.output_history = [0.0] * self.order", "successors": []}, {"id": 3, "label": "self.b_coeffs = b_coeffs", "successors": []}, {"id": 4, "label": "return result", "successors": []}]}]}], "simplified_code": "from __future__ import annotations\n\n\n        return result", "blocks": [{"id": 1, "label": "from __future__ import annotations\nreturn result", "successors": []}]}
{"file_name": "16.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 106, "functions": [], "classes": [{"name": "HubSpotContactBlock", "type": "class", "start_line": 11, "end_line": 106, "functions": [{"name": "__init__", "type": "function", "start_line": 28, "end_line": 35, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"5267326e-c4c1-4016-9f54-4e72ad02f813\",\n            description=\"Manages HubSpot contacts - create, update, and retrieve contact information\",\n            categories={BlockCategory.CRM},\n            input_schema=HubSpotContactBlock.Input,\n            output_schema=HubSpotContactBlock.Output,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"5267326e-c4c1-4016-9f54-4e72ad02f813\",\n    description=\"Manages HubSpot contacts - create, update, and retrieve contact information\",\n    categories={BlockCategory.CRM},\n    input_schema=HubSpotContactBlock.Input,\n    output_schema=HubSpotContactBlock.Output,\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 37, "end_line": 106, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: HubSpotCredentials, **kwargs\n    ) -> BlockOutput:\n        base_url = \"https://api.hubapi.com/crm/v3/objects/contacts\"\n        headers = {\n            \"Authorization\": f\"Bearer {credentials.api_key.get_secret_value()}\",\n            \"Content-Type\": \"application/json\",\n        }\n\n        if input_data.operation == \"create\":\n            response = requests.post(\n                base_url, headers=headers, json={\"properties\": input_data.contact_data}\n            )\n            result = response.json()\n            yield \"contact\", result\n            yield \"status\", \"created\"\n\n        elif input_data.operation == \"get\":\n            # Search for contact by email\n            search_url = f\"{base_url}/search\"\n            search_data = {\n                \"filterGroups\": [\n                    {\n                        \"filters\": [\n                            {\n                                \"propertyName\": \"email\",\n                                \"operator\": \"EQ\",\n                                \"value\": input_data.email,\n                            }\n                        ]\n                    }\n                ]\n            }\n            response = requests.post(search_url, headers=headers, json=search_data)\n            result = response.json()\n            yield \"contact\", result.get(\"results\", [{}])[0]\n            yield \"status\", \"retrieved\"\n\n        elif input_data.operation == \"update\":\n            search_response = requests.post(\n                f\"{base_url}/search\",\n                headers=headers,\n                json={\n                    \"filterGroups\": [\n                        {\n                            \"filters\": [\n                                {\n                                    \"propertyName\": \"email\",\n                                    \"operator\": \"EQ\",\n                                    \"value\": input_data.email,\n                                }\n                            ]\n                        }\n                    ]\n                },\n            )\n            contact_id = search_response.json().get(\"results\", [{}])[0].get(\"id\")\n\n            if contact_id:\n                response = requests.patch(\n                    f\"{base_url}/{contact_id}\",\n                    headers=headers,\n                    json={\"properties\": input_data.contact_data},\n                )\n                result = response.json()\n                yield \"contact\", result\n                yield \"status\", \"updated\"\n            else:\n                yield \"contact\", {}\n                yield \"status\", \"contact_not_found\"", "blocks": [{"id": 1, "label": "def run(\n    self, input_data: Input, *, credentials: HubSpotCredentials, **kwargs\n) -> BlockOutput:\n    base_url = \"https://api.hubapi.com/crm/v3/objects/contacts\"\n    headers = {\n        \"Authorization\": f\"Bearer {credentials.api_key.get_secret_value()}\",\n        \"Content-Type\": \"application/json\",\n    }\n\n    if input_data.operation == \"create\":", "successors": [{"id": 2, "label": "response = requests.post(\n    base_url, headers=headers, json={\"properties\": input_data.contact_data}\n)\nresult = response.json()\nyield \"contact\", result\nyield \"status\", \"created\"", "successors": []}, {"id": 3, "label": "elif input_data.operation == \"get\":", "successors": [{"id": 4, "label": "search_url = f\"{base_url}/search\"\nsearch_data = {\n    \"filterGroups\": [\n        {\n            \"filters\": [\n                {\n                    \"propertyName\": \"email\",\n                    \"operator\": \"EQ\",\n                    \"value\": input_data.email,\n                }\n            ]\n        }\n    ]\n}\nresponse = requests.post(search_url, headers=headers, json=search_data)\nresult = response.json()\nyield \"contact\", result.get(\"results\", [{}])[0]\nyield \"status\", \"retrieved\"", "successors": []}, {"id": 5, "label": "elif input_data.operation == \"update\":\nsearch_response = requests.post(\n    f\"{base_url}/search\",\n    headers=headers,\n    json={\n        \"filterGroups\": [\n            {\n                \"filters\": [\n                    {\n                        \"propertyName\": \"email\",\n                        \"operator\": \"EQ\",\n                        \"value\": input_data.email,\n                    }\n                ]\n            }\n        ]\n    },\n)\ncontact_id = search_response.json().get(\"results\", [{}])[0].get(\"id\")\n\nif contact_id:", "successors": [{"id": 7, "label": "response = requests.patch(\n    f\"{base_url}/{contact_id}\",\n    headers=headers,\n    json={\"properties\": input_data.contact_data},\n)\nresult = response.json()\nyield \"contact\", result\nyield \"status\", \"updated\"", "successors": []}, {"id": 8, "label": "else:\nyield \"contact\", {}\nyield \"status\", \"contact_not_found\"", "successors": []}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 12, "end_line": 22, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: HubSpotCredentialsInput = HubSpotCredentialsField()\n        operation: str = SchemaField(\n            description=\"Operation to perform (create, update, get)\", default=\"get\"\n        )\n        contact_data: dict = SchemaField(\n            description=\"Contact data for create/update operations\", default={}\n        )\n        email: str = SchemaField(\n            description=\"Email address for get/update operations\", default=\"\"\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    credentials: HubSpotCredentialsInput = HubSpotCredentialsField()", "successors": []}, {"id": 3, "label": "    operation: str = SchemaField(description=\"Operation to perform (create, update, get)\", default=\"get\")", "successors": []}, {"id": 4, "label": "    contact_data: dict = SchemaField(description=\"Contact data for create/update operations\", default={})", "successors": []}, {"id": 5, "label": "    email: str = SchemaField(description=\"Email address for get/update operations\", default=\"\")", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 24, "end_line": 26, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        contact: dict = SchemaField(description=\"Contact information\")\n        status: str = SchemaField(description=\"Operation status\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    contact: dict = SchemaField(description=\"Contact information\")", "successors": [{"id": 3, "label": "    status: str = SchemaField(description=\"Operation status\")", "successors": []}]}]}], "simplified_code": "class HubSpotContactBlock(Block):\n        )\n\n        status: str = SchemaField(description=\"Operation status\")\n\n        )\n\n                yield \"status\", \"contact_not_found\"", "blocks": [{"id": 1, "label": "class HubSpotContactBlock(Block):\nstatus: str = SchemaField(description=\"Operation status\")", "successors": [{"id": 3, "label": "yield \"status\", \"contact_not_found\"", "successors": []}]}]}], "simplified_code": "from backend.blocks.hubspot._auth import (\n    HubSpotCredentials,\n    HubSpotCredentialsField,\n    HubSpotCredentialsInput,\n)\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\nfrom backend.util.request import requests\n\n\n                yield \"status\", \"contact_not_found\"", "blocks": [{"id": 1, "label": "from backend.blocks.hubspot._auth import (\n    HubSpotCredentials,\n    HubSpotCredentialsField,\n    HubSpotCredentialsInput,\n)\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\nfrom backend.util.request import requests\nyield \"status\", \"contact_not_found\"", "successors": []}]}
{"file_name": "17.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 162, "functions": [{"name": "get_point_key", "type": "function", "start_line": 36, "end_line": 44, "functions": [], "classes": [], "simplified_code": "def get_point_key(len_board: int, len_board_column: int, row: int, column: int) -> int:\n    \"\"\"\n    Returns the hash key of matrix indexes.\n\n    >>> get_point_key(10, 20, 1, 0)\n    200\n    \"\"\"\n\n    return len_board * len_board_column * row + column", "blocks": [{"id": 1, "label": "def get_point_key(len_board: int, len_board_column: int, row: int, column: int) -> int:\n\"\"\"\n    Returns the hash key of matrix indexes.\n\n    >>> get_point_key(10, 20, 1, 0)\n    200\n    \"\"\"", "successors": [{"id": 3, "label": "return len_board * len_board_column * row + column", "successors": []}]}]}, {"name": "exits_word", "type": "function", "start_line": 47, "end_line": 88, "functions": [], "classes": [], "simplified_code": "def exits_word(\n    board: list[list[str]],\n    word: str,\n    row: int,\n    column: int,\n    word_index: int,\n    visited_points_set: set[int],\n) -> bool:\n    \"\"\"\n    Return True if it's possible to search the word suffix\n    starting from the word_index.\n\n    >>> exits_word([[\"A\"]], \"B\", 0, 0, 0, set())\n    False\n    \"\"\"\n\n    if board[row][column] != word[word_index]:\n        return False\n\n    if word_index == len(word) - 1:\n        return True\n\n    traverts_directions = [(0, 1), (0, -1), (-1, 0), (1, 0)]\n    len_board = len(board)\n    len_board_column = len(board[0])\n    for direction in traverts_directions:\n        next_i = row + direction[0]\n        next_j = column + direction[1]\n        if not (0 <= next_i < len_board and 0 <= next_j < len_board_column):\n            continue\n\n        key = get_point_key(len_board, len_board_column, next_i, next_j)\n        if key in visited_points_set:\n            continue\n\n        visited_points_set.add(key)\n        if exits_word(board, word, next_i, next_j, word_index + 1, visited_points_set):\n            return True\n\n        visited_points_set.remove(key)\n\n    return False", "blocks": [{"id": 1, "label": "if board[row][column] != word[word_index]:\n    return False", "successors": []}]}, {"name": "word_exists", "type": "function", "start_line": 91, "end_line": 156, "functions": [], "classes": [], "simplified_code": "def word_exists(board: list[list[str]], word: str) -> bool:\n    \"\"\"\n    >>> word_exists([[\"A\",\"B\",\"C\",\"E\"],[\"S\",\"F\",\"C\",\"S\"],[\"A\",\"D\",\"E\",\"E\"]], \"ABCCED\")\n    True\n    >>> word_exists([[\"A\",\"B\",\"C\",\"E\"],[\"S\",\"F\",\"C\",\"S\"],[\"A\",\"D\",\"E\",\"E\"]], \"SEE\")\n    True\n    >>> word_exists([[\"A\",\"B\",\"C\",\"E\"],[\"S\",\"F\",\"C\",\"S\"],[\"A\",\"D\",\"E\",\"E\"]], \"ABCB\")\n    False\n    >>> word_exists([[\"A\"]], \"A\")\n    True\n    >>> word_exists([[\"B\", \"A\", \"A\"], [\"A\", \"A\", \"A\"], [\"A\", \"B\", \"A\"]], \"ABB\")\n    False\n    >>> word_exists([[\"A\"]], 123)\n    Traceback (most recent call last):\n        ...\n    ValueError: The word parameter should be a string of length greater than 0.\n    >>> word_exists([[\"A\"]], \"\")\n    Traceback (most recent call last):\n        ...\n    ValueError: The word parameter should be a string of length greater than 0.\n    >>> word_exists([[]], \"AB\")\n    Traceback (most recent call last):\n        ...\n    ValueError: The board should be a non empty matrix of single chars strings.\n    >>> word_exists([], \"AB\")\n    Traceback (most recent call last):\n        ...\n    ValueError: The board should be a non empty matrix of single chars strings.\n    >>> word_exists([[\"A\"], [21]], \"AB\")\n    Traceback (most recent call last):\n        ...\n    ValueError: The board should be a non empty matrix of single chars strings.\n    \"\"\"\n\n    # Validate board\n    board_error_message = (\n        \"The board should be a non empty matrix of single chars strings.\"\n    )\n\n    len_board = len(board)\n    if not isinstance(board, list) or len(board) == 0:\n        raise ValueError(board_error_message)\n\n    for row in board:\n        if not isinstance(row, list) or len(row) == 0:\n            raise ValueError(board_error_message)\n\n        for item in row:\n            if not isinstance(item, str) or len(item) != 1:\n                raise ValueError(board_error_message)\n\n    # Validate word\n    if not isinstance(word, str) or len(word) == 0:\n        raise ValueError(\n            \"The word parameter should be a string of length greater than 0.\"\n        )\n\n    len_board_column = len(board[0])\n    for i in range(len_board):\n        for j in range(len_board_column):\n            if exits_word(\n                board, word, i, j, 0, {get_point_key(len_board, len_board_column, i, j)}\n            ):\n                return True\n\n    return False", "blocks": [{"id": 1, "label": "def word_exists(board: list[list[str]], word: str) -> bool:\nboard_error_message = \"The board should be a non empty matrix of single chars strings.\"", "successors": [{"id": 3, "label": "len_board = len(board)", "successors": [{"id": 4, "label": "if not isinstance(board, list) or len(board) == 0:\nraise ValueError(board_error_message)", "successors": []}, {"id": 6, "label": "for row in board:", "successors": [{"id": 7, "label": "if not isinstance(row, list) or len(row) == 0:\nraise ValueError(board_error_message)", "successors": []}, {"id": 9, "label": "for item in row:", "successors": [{"id": 10, "label": "if not isinstance(item, str) or len(item) != 1:\nraise ValueError(board_error_message)", "successors": []}]}]}, {"id": 12, "label": "if not isinstance(word, str) or len(word) == 0:\nraise ValueError(\"The word parameter should be a string of length greater than 0.\")", "successors": []}, {"id": 14, "label": "len_board_column = len(board[0])", "successors": [{"id": 15, "label": "for i in range(len_board):", "successors": [{"id": 16, "label": "for j in range(len_board_column):", "successors": [{"id": 17, "label": "if exits_word(board, word, i, j, 0, {get_point_key(len_board, len_board_column, i, j)}):\nreturn True", "successors": []}]}]}, {"id": 19, "label": "return False", "successors": []}]}]}]}]}], "classes": [], "simplified_code": "\"\"\"\nAuthor  : Alexander Pantyukhin\nDate    : November 24, 2022\n\nTask:\nGiven an m x n grid of characters board and a string word,\nreturn true if word exists in the grid.\n\nThe word can be constructed from letters of sequentially adjacent cells,\nwhere adjacent cells are horizontally or vertically neighboring.\nThe same letter cell may not be used more than once.\n\nExample:\n\nMatrix:\n---------\n|A|B|C|E|\n|S|F|C|S|\n|A|D|E|E|\n---------\n\nWord:\n\"ABCCED\"\n\nResult:\nTrue\n\nImplementation notes: Use backtracking approach.\nAt each point, check all neighbors to try to find the next letter of the word.\n\nleetcode: https://leetcode.com/problems/word-search/\n\n\"\"\"\n\n\n    return len_board * len_board_column * row + column\n\n\n    return False\n\n\n    return False\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()", "blocks": [{"id": 1, "label": "if __name__ == \"__main__\":\nimport doctest", "successors": [{"id": 3, "label": "doctest.testmod()", "successors": []}]}]}
{"file_name": "18.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 113, "functions": [{"name": "valid_coloring", "type": "function", "start_line": 10, "end_line": 33, "functions": [], "classes": [], "simplified_code": "def valid_coloring(\n    neighbours: list[int], colored_vertices: list[int], color: int\n) -> bool:\n    \"\"\"\n    For each neighbour check if the coloring constraint is satisfied\n    If any of the neighbours fail the constraint return False\n    If all neighbours validate the constraint return True\n\n    >>> neighbours = [0,1,0,1,0]\n    >>> colored_vertices = [0, 2, 1, 2, 0]\n\n    >>> color = 1\n    >>> valid_coloring(neighbours, colored_vertices, color)\n    True\n\n    >>> color = 2\n    >>> valid_coloring(neighbours, colored_vertices, color)\n    False\n    \"\"\"\n    # Does any neighbour not satisfy the constraints\n    return not any(\n        neighbour == 1 and colored_vertices[i] == color\n        for i, neighbour in enumerate(neighbours)\n    )", "blocks": [{"id": 1, "label": "def valid_coloring(neighbours: list[int], colored_vertices: list[int], color: int) -> bool:\n\"\"\"\n    For each neighbour check if the coloring constraint is satisfied\n    If any of the neighbours fail the constraint return False\n    If all neighbours validate the constraint return True\n\n    >>> neighbours = [0,1,0,1,0]\n    >>> colored_vertices = [0, 2, 1, 2, 0]\n\n    >>> color = 1\n    >>> valid_coloring(neighbours, colored_vertices, color)\n    True\n\n    >>> color = 2\n    >>> valid_coloring(neighbours, colored_vertices, color)\n    False\n    \"\"\"", "successors": [{"id": 3, "label": "return not any(neighbour == 1 and colored_vertices[i] == color for i, neighbour in enumerate(neighbours))", "successors": []}]}]}, {"name": "util_color", "type": "function", "start_line": 36, "end_line": 85, "functions": [], "classes": [], "simplified_code": "def util_color(\n    graph: list[list[int]], max_colors: int, colored_vertices: list[int], index: int\n) -> bool:\n    \"\"\"\n    Pseudo-Code\n\n    Base Case:\n    1. Check if coloring is complete\n        1.1 If complete return True (meaning that we successfully colored the graph)\n\n    Recursive Step:\n    2. Iterates over each color:\n        Check if the current coloring is valid:\n            2.1. Color given vertex\n            2.2. Do recursive call, check if this coloring leads to a solution\n            2.4. if current coloring leads to a solution return\n            2.5. Uncolor given vertex\n\n    >>> graph = [[0, 1, 0, 0, 0],\n    ...          [1, 0, 1, 0, 1],\n    ...          [0, 1, 0, 1, 0],\n    ...          [0, 1, 1, 0, 0],\n    ...          [0, 1, 0, 0, 0]]\n    >>> max_colors = 3\n    >>> colored_vertices = [0, 1, 0, 0, 0]\n    >>> index = 3\n\n    >>> util_color(graph, max_colors, colored_vertices, index)\n    True\n\n    >>> max_colors = 2\n    >>> util_color(graph, max_colors, colored_vertices, index)\n    False\n    \"\"\"\n\n    # Base Case\n    if index == len(graph):\n        return True\n\n    # Recursive Step\n    for i in range(max_colors):\n        if valid_coloring(graph[index], colored_vertices, i):\n            # Color current vertex\n            colored_vertices[index] = i\n            # Validate coloring\n            if util_color(graph, max_colors, colored_vertices, index + 1):\n                return True\n            # Backtrack\n            colored_vertices[index] = -1\n    return False", "blocks": [{"id": 1, "label": "def util_color(\n    graph: list[list[int]], max_colors: int, colored_vertices: list[int], index: int\n) -> bool:\n    \"\"\"\n    Pseudo-Code\n\n    Base Case:\n    1. Check if coloring is complete\n        1.1 If complete return True (meaning that we successfully colored the graph)\n\n    Recursive Step:\n    2. Iterates over each color:\n        Check if the current coloring is valid:\n            2.1. Color given vertex\n            2.2. Do recursive call, check if this coloring leads to a solution\n            2.4. if current coloring leads to a solution return\n            2.5. Uncolor given vertex\n\n    >>> graph = [[0, 1, 0, 0, 0],\n    ...          [1, 0, 1, 0, 1],\n    ...          [0, 1, 0, 1, 0],\n    ...          [0, 1, 1, 0, 0],\n    ...          [0, 1, 0, 0, 0]]\n    >>> max_colors = 3\n    >>> colored_vertices = [0, 1, 0, 0, 0]\n    >>> index = 3\n\n    >>> util_color(graph, max_colors, colored_vertices, index)\n    True\n\n    >>> max_colors = 2\n    >>> util_color(graph, max_colors, colored_vertices, index)\n    False\n    \"\"\"\n\n    # Base Case\n    if index == len(graph):\n        return True", "successors": [{"id": 3, "label": "# Recursive Step\n    for i in range(max_colors):", "successors": [{"id": 4, "label": "        if valid_coloring(graph[index], colored_vertices, i):", "successors": [{"id": 5, "label": "            # Color current vertex\n            colored_vertices[index] = i\n            # Validate coloring\n            if util_color(graph, max_colors, colored_vertices, index + 1):\n                return True", "successors": [{"id": 7, "label": "# Backtrack\n            colored_vertices[index] = -1\n    return False", "successors": []}]}, {"id": 7, "label": "# Backtrack\n            colored_vertices[index] = -1\n    return False", "successors": []}]}, {"id": 8, "label": "    return False", "successors": []}]}]}]}, {"name": "color", "type": "function", "start_line": 88, "end_line": 113, "functions": [], "classes": [], "simplified_code": "def color(graph: list[list[int]], max_colors: int) -> list[int]:\n    \"\"\"\n    Wrapper function to call subroutine called util_color\n    which will either return True or False.\n    If True is returned colored_vertices list is filled with correct colorings\n\n    >>> graph = [[0, 1, 0, 0, 0],\n    ...          [1, 0, 1, 0, 1],\n    ...          [0, 1, 0, 1, 0],\n    ...          [0, 1, 1, 0, 0],\n    ...          [0, 1, 0, 0, 0]]\n\n    >>> max_colors = 3\n    >>> color(graph, max_colors)\n    [0, 1, 0, 2, 0]\n\n    >>> max_colors = 2\n    >>> color(graph, max_colors)\n    []\n    \"\"\"\n    colored_vertices = [-1] * len(graph)\n\n    if util_color(graph, max_colors, colored_vertices, 0):\n        return colored_vertices\n\n    return []", "blocks": [{"id": 1, "label": "def color(graph: list[list[int]], max_colors: int) -> list[int]:\n    colored_vertices = [-1] * len(graph)\nif util_color(graph, max_colors, colored_vertices, 0):", "successors": [{"id": 3, "label": "    return colored_vertices", "successors": []}, {"id": 4, "label": "return []", "successors": []}]}]}], "classes": [], "simplified_code": "\"\"\"\nGraph Coloring also called \"m coloring problem\"\nconsists of coloring a given graph with at most m colors\nsuch that no adjacent vertices are assigned the same color\n\nWikipedia: https://en.wikipedia.org/wiki/Graph_coloring\n\"\"\"\n\n\n    )\n\n\n    return False\n\n\n    return []", "blocks": [{"id": 1, "label": "# Example input code\n\"\"\"\nGraph Coloring also called \"m coloring problem\"\nconsists of coloring a given graph with at most m colors\nsuch that no adjacent vertices are assigned the same color\n\nWikipedia: https://en.wikipedia.org/wiki/Graph_coloring\n\"\"\"\n)", "successors": [{"id": 3, "label": "return False\nreturn []", "successors": []}]}]}
{"file_name": "19.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 122, "functions": [], "classes": [{"name": "DateTimeEncoder", "type": "class", "start_line": 17, "end_line": 21, "functions": [{"name": "default", "type": "function", "start_line": 18, "end_line": 21, "functions": [], "classes": [], "simplified_code": "    def default(self, o):\n        if isinstance(o, datetime):\n            return o.isoformat()\n        return super().default(o)", "blocks": [{"id": 1, "label": "def default(self, o):\nif isinstance(o, datetime):", "successors": [{"id": 3, "label": "    return o.isoformat()", "successors": []}, {"id": 4, "label": "return super().default(o)", "successors": []}]}]}], "simplified_code": "class DateTimeEncoder(json.JSONEncoder):\n        return super().default(o)", "blocks": [{"id": 1, "label": "class DateTimeEncoder(json.JSONEncoder):\n        return super().default(o)", "successors": []}]}, {"name": "BaseRedisEventBus", "type": "class", "start_line": 27, "end_line": 57, "functions": [{"name": "event_bus_name", "type": "function", "start_line": 32, "end_line": 33, "functions": [], "classes": [], "simplified_code": "    def event_bus_name(self) -> str:\n        pass", "blocks": [{"id": 1, "label": "def event_bus_name(self) -> str:\n    pass", "successors": []}]}, {"name": "_serialize_message", "type": "function", "start_line": 35, "end_line": 39, "functions": [], "classes": [], "simplified_code": "    def _serialize_message(self, item: M, channel_key: str) -> tuple[str, str]:\n        message = json.dumps(item.model_dump(), cls=DateTimeEncoder)\n        channel_name = f\"{self.event_bus_name}/{channel_key}\"\n        logger.info(f\"[{channel_name}] Publishing an event to Redis {message}\")\n        return message, channel_name", "blocks": [{"id": 1, "label": "def _serialize_message(self, item: M, channel_key: str) -> tuple[str, str]:\n    message = json.dumps(item.model_dump(), cls=DateTimeEncoder)\n    channel_name = f\"{self.event_bus_name}/{channel_key}\"\n    logger.info(f\"[{channel_name}] Publishing an event to Redis {message}\")\n    return message, channel_name", "successors": []}]}, {"name": "_deserialize_message", "type": "function", "start_line": 41, "end_line": 50, "functions": [], "classes": [], "simplified_code": "    def _deserialize_message(self, msg: Any, channel_key: str) -> M | None:\n        message_type = \"pmessage\" if \"*\" in channel_key else \"message\"\n        if msg[\"type\"] != message_type:\n            return None\n        try:\n            data = json.loads(msg[\"data\"])\n            logger.info(f\"Consuming an event from Redis {data}\")\n            return self.Model(**data)\n        except Exception as e:\n            logger.error(f\"Failed to parse event result from Redis {msg} {e}\")", "blocks": [{"id": 1, "label": "message_type = \"pmessage\" if \"*\" in channel_key else \"message\"\nif msg[\"type\"] != message_type:", "successors": [{"id": 3, "label": "    return None", "successors": []}, {"id": 4, "label": "try:", "successors": [{"id": 5, "label": "    data = json.loads(msg[\"data\"])\n    logger.info(f\"Consuming an event from Redis {data}\")", "successors": [{"id": 7, "label": "    return self.Model(**data)", "successors": []}]}, {"id": 8, "label": "except Exception as e:\n    logger.error(f\"Failed to parse event result from Redis {msg} {e}\")", "successors": []}]}]}]}, {"name": "_get_pubsub_channel", "type": "function", "start_line": 52, "end_line": 57, "functions": [], "classes": [], "simplified_code": "    def _get_pubsub_channel(\n        self, connection: redis.Redis | redis.AsyncRedis, channel_key: str\n    ) -> tuple[PubSub | AsyncPubSub, str]:\n        full_channel_name = f\"{self.event_bus_name}/{channel_key}\"\n        pubsub = connection.pubsub()\n        return pubsub, full_channel_name", "blocks": [{"id": 1, "label": "def _get_pubsub_channel(\n    self, connection: redis.Redis | redis.AsyncRedis, channel_key: str\n) -> tuple[PubSub | AsyncPubSub, str]:\n    full_channel_name = f\"{self.event_bus_name}/{channel_key}\"\n    pubsub = connection.pubsub()\n    return pubsub, full_channel_name", "successors": []}]}], "simplified_code": "class BaseRedisEventBus(Generic[M], ABC):\n    Model: type[M]\n\n    @property\n    @abstractmethod\n        pass\n\n        return message, channel_name\n\n            logger.error(f\"Failed to parse event result from Redis {msg} {e}\")\n\n        return pubsub, full_channel_name", "blocks": [{"id": 1, "label": "class BaseRedisEventBus(Generic[M], ABC):\nModel: type[M]", "successors": [{"id": 3, "label": "@property\n@abstractmethod", "successors": [{"id": 5, "label": "pass", "successors": []}]}]}]}, {"name": "RedisEventBus", "type": "class", "start_line": 60, "end_line": 84, "functions": [{"name": "connection", "type": "function", "start_line": 64, "end_line": 65, "functions": [], "classes": [], "simplified_code": "    def connection(self) -> redis.Redis:\n        return redis.get_redis()", "blocks": [{"id": 1, "label": "def connection(self) -> redis.Redis:\n    return redis.get_redis()", "successors": []}]}, {"name": "publish_event", "type": "function", "start_line": 67, "end_line": 69, "functions": [], "classes": [], "simplified_code": "    def publish_event(self, event: M, channel_key: str):\n        message, full_channel_name = self._serialize_message(event, channel_key)\n        self.connection.publish(full_channel_name, message)", "blocks": [{"id": 1, "label": "def publish_event(self, event: M, channel_key: str):\nmessage, full_channel_name = self._serialize_message(event, channel_key)", "successors": [{"id": 3, "label": "self.connection.publish(full_channel_name, message)", "successors": []}]}]}, {"name": "listen_events", "type": "function", "start_line": 71, "end_line": 84, "functions": [], "classes": [], "simplified_code": "    def listen_events(self, channel_key: str) -> Generator[M, None, None]:\n        pubsub, full_channel_name = self._get_pubsub_channel(\n            self.connection, channel_key\n        )\n        assert isinstance(pubsub, PubSub)\n\n        if \"*\" in channel_key:\n            pubsub.psubscribe(full_channel_name)\n        else:\n            pubsub.subscribe(full_channel_name)\n\n        for message in pubsub.listen():\n            if event := self._deserialize_message(message, channel_key):\n                yield event", "blocks": [{"id": 1, "label": "pubsub, full_channel_name = self._get_pubsub_channel(\n    self.connection, channel_key\n)\nassert isinstance(pubsub, PubSub)\nif \"*\" in channel_key:", "successors": [{"id": 3, "label": "    pubsub.psubscribe(full_channel_name)", "successors": [{"id": 5, "label": "for message in pubsub.listen():", "successors": [{"id": 6, "label": "    if event := self._deserialize_message(message, channel_key):\n        yield event", "successors": [{"id": 5, "label": "for message in pubsub.listen():", "successors": [{"id": 6, "label": "    if event := self._deserialize_message(message, channel_key):\n        yield event", "successors": []}]}]}]}]}, {"id": 4, "label": "    pubsub.subscribe(full_channel_name)", "successors": [{"id": 5, "label": "for message in pubsub.listen():", "successors": [{"id": 6, "label": "    if event := self._deserialize_message(message, channel_key):\n        yield event", "successors": [{"id": 5, "label": "for message in pubsub.listen():", "successors": [{"id": 6, "label": "    if event := self._deserialize_message(message, channel_key):\n        yield event", "successors": []}]}]}]}]}]}]}], "simplified_code": "class RedisEventBus(BaseRedisEventBus[M], ABC):\n    Model: type[M]\n\n    @property\n        return redis.get_redis()\n\n        self.connection.publish(full_channel_name, message)\n\n                yield event", "blocks": [{"id": 1, "label": "class RedisEventBus(BaseRedisEventBus[M], ABC):", "successors": [{"id": 2, "label": "Model: type[M]", "successors": []}, {"id": 3, "label": "@property", "successors": []}, {"id": 4, "label": "def get_connection(self):\nreturn redis.get_redis()", "successors": []}, {"id": 6, "label": "def publish(self, full_channel_name, message):\nself.connection.publish(full_channel_name, message)", "successors": []}, {"id": 8, "label": "def listen(self):\nyield event", "successors": []}]}]}, {"name": "AsyncRedisEventBus", "type": "class", "start_line": 87, "end_line": 122, "functions": [{"name": "connection", "type": "function", "start_line": 91, "end_line": 92, "functions": [], "classes": [], "simplified_code": "    async def connection(self) -> redis.AsyncRedis:\n        return await redis.get_redis_async()", "blocks": [{"id": 1, "label": "async def connection(self) -> redis.AsyncRedis:\nreturn await redis.get_redis_async()", "successors": []}]}, {"name": "publish_event", "type": "function", "start_line": 94, "end_line": 97, "functions": [], "classes": [], "simplified_code": "    async def publish_event(self, event: M, channel_key: str):\n        message, full_channel_name = self._serialize_message(event, channel_key)\n        connection = await self.connection\n        await connection.publish(full_channel_name, message)", "blocks": [{"id": 1, "label": "async def publish_event(self, event: M, channel_key: str):", "successors": [{"id": 2, "label": "    message, full_channel_name = self._serialize_message(event, channel_key)", "successors": []}, {"id": 3, "label": "    connection = await self.connection", "successors": []}, {"id": 4, "label": "    await connection.publish(full_channel_name, message)", "successors": []}]}]}, {"name": "listen_events", "type": "function", "start_line": 99, "end_line": 112, "functions": [], "classes": [], "simplified_code": "    async def listen_events(self, channel_key: str) -> AsyncGenerator[M, None]:\n        pubsub, full_channel_name = self._get_pubsub_channel(\n            await self.connection, channel_key\n        )\n        assert isinstance(pubsub, AsyncPubSub)\n\n        if \"*\" in channel_key:\n            await pubsub.psubscribe(full_channel_name)\n        else:\n            await pubsub.subscribe(full_channel_name)\n\n        async for message in pubsub.listen():\n            if event := self._deserialize_message(message, channel_key):\n                yield event", "blocks": [{"id": 1, "label": "async def listen_events(self, channel_key: str) -> AsyncGenerator[M, None]:\npubsub, full_channel_name = self._get_pubsub_channel( await self.connection, channel_key )", "successors": [{"id": 3, "label": "assert isinstance(pubsub, AsyncPubSub)", "successors": [{"id": 4, "label": "if \"*\" in channel_key:\n    await pubsub.psubscribe(full_channel_name)", "successors": [{"id": 7, "label": "async for message in pubsub.listen():\nif event := self._deserialize_message(message, channel_key):", "successors": [{"id": 9, "label": "    yield event", "successors": []}]}]}, {"id": 6, "label": "    await pubsub.subscribe(full_channel_name)\nasync for message in pubsub.listen():", "successors": [{"id": 8, "label": "if event := self._deserialize_message(message, channel_key):\n    yield event", "successors": []}]}]}]}]}, {"name": "wait_for_event", "type": "function", "start_line": 114, "end_line": 122, "functions": [], "classes": [], "simplified_code": "    async def wait_for_event(\n        self, channel_key: str, timeout: Optional[float] = None\n    ) -> M | None:\n        try:\n            return await asyncio.wait_for(\n                anext(aiter(self.listen_events(channel_key))), timeout\n            )\n        except TimeoutError:\n            return None", "blocks": [{"id": 1, "label": "async def wait_for_event(self, channel_key: str, timeout: Optional[float] = None) -> M | None:\ntry:", "successors": [{"id": 3, "label": "return await asyncio.wait_for(anext(aiter(self.listen_events(channel_key))), timeout)", "successors": []}, {"id": 4, "label": "except TimeoutError:\nreturn None", "successors": []}]}]}], "simplified_code": "class AsyncRedisEventBus(BaseRedisEventBus[M], ABC):\n    Model: type[M]\n\n    @property\n        return await redis.get_redis_async()\n\n        await connection.publish(full_channel_name, message)\n\n                yield event\n\n            return None", "blocks": [{"id": 1, "label": "class AsyncRedisEventBus(BaseRedisEventBus[M], ABC):\n    Model: type[M]", "successors": []}]}], "simplified_code": "import asyncio\nimport json\nimport logging\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom typing import Any, AsyncGenerator, Generator, Generic, Optional, TypeVar\n\nfrom pydantic import BaseModel\nfrom redis.asyncio.client import PubSub as AsyncPubSub\nfrom redis.client import PubSub\n\nfrom backend.data import redis\n\nlogger = logging.getLogger(__name__)\n\n\n        return super().default(o)\n\n\nM = TypeVar(\"M\", bound=BaseModel)\n\n\n        return pubsub, full_channel_name\n\n\n                yield event\n\n\n            return None", "blocks": [{"id": 1, "label": "import asyncio\nimport json\nimport logging\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom typing import Any, AsyncGenerator, Generator, Generic, Optional, TypeVar\n\nfrom pydantic import BaseModel\nfrom redis.asyncio.client import PubSub as AsyncPubSub\nfrom redis.client import PubSub\n\nfrom backend.data import redis\n\nlogger = logging.getLogger(__name__)\n\n\nreturn super().default(o)", "successors": []}]}
{"file_name": "20.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 55, "functions": [{"name": "bitwise_addition_recursive", "type": "function", "start_line": 7, "end_line": 49, "functions": [], "classes": [], "simplified_code": "def bitwise_addition_recursive(number: int, other_number: int) -> int:\n    \"\"\"\n    >>> bitwise_addition_recursive(4, 5)\n    9\n    >>> bitwise_addition_recursive(8, 9)\n    17\n    >>> bitwise_addition_recursive(0, 4)\n    4\n    >>> bitwise_addition_recursive(4.5, 9)\n    Traceback (most recent call last):\n        ...\n    TypeError: Both arguments MUST be integers!\n    >>> bitwise_addition_recursive('4', 9)\n    Traceback (most recent call last):\n        ...\n    TypeError: Both arguments MUST be integers!\n    >>> bitwise_addition_recursive('4.5', 9)\n    Traceback (most recent call last):\n        ...\n    TypeError: Both arguments MUST be integers!\n    >>> bitwise_addition_recursive(-1, 9)\n    Traceback (most recent call last):\n        ...\n    ValueError: Both arguments MUST be non-negative!\n    >>> bitwise_addition_recursive(1, -9)\n    Traceback (most recent call last):\n        ...\n    ValueError: Both arguments MUST be non-negative!\n    \"\"\"\n\n    if not isinstance(number, int) or not isinstance(other_number, int):\n        raise TypeError(\"Both arguments MUST be integers!\")\n\n    if number < 0 or other_number < 0:\n        raise ValueError(\"Both arguments MUST be non-negative!\")\n\n    bitwise_sum = number ^ other_number\n    carry = number & other_number\n\n    if carry == 0:\n        return bitwise_sum\n\n    return bitwise_addition_recursive(bitwise_sum, carry << 1)", "blocks": [{"id": 1, "label": "def bitwise_addition_recursive(number: int, other_number: int) -> int:", "successors": [{"id": 2, "label": "if not isinstance(number, int) or not isinstance(other_number, int):\nraise TypeError(\"Both arguments MUST be integers!\")", "successors": []}, {"id": 4, "label": "if number < 0 or other_number < 0:\nraise ValueError(\"Both arguments MUST be non-negative!\")", "successors": []}, {"id": 6, "label": "bitwise_sum = number ^ other_number\ncarry = number & other_number", "successors": [{"id": 7, "label": "if carry == 0:\nreturn bitwise_sum", "successors": []}, {"id": 9, "label": "return bitwise_addition_recursive(bitwise_sum, carry << 1)", "successors": []}]}]}]}], "classes": [], "simplified_code": "\"\"\"\nCalculates the sum of two non-negative integers using bitwise operators\nWikipedia explanation: https://en.wikipedia.org/wiki/Binary_number\n\"\"\"\n\n\n    return bitwise_addition_recursive(bitwise_sum, carry << 1)\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()", "blocks": [{"id": 1, "label": "def bitwise_addition_recursive(a, b):\nif b == 0:", "successors": [{"id": 3, "label": "return a", "successors": []}, {"id": 4, "label": "bitwise_sum = a ^ b\ncarry = a & b\nreturn bitwise_addition_recursive(bitwise_sum, carry << 1)", "successors": []}]}]}
{"file_name": "21.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 670, "functions": [{"name": "execution_manager_client", "type": "function", "start_line": 55, "end_line": 56, "functions": [], "classes": [], "simplified_code": "def execution_manager_client() -> ExecutionManager:\n    return get_service_client(ExecutionManager)", "blocks": [{"id": 1, "label": "def execution_manager_client() -> ExecutionManager:\n    return get_service_client(ExecutionManager)", "successors": []}]}, {"name": "execution_scheduler_client", "type": "function", "start_line": 60, "end_line": 61, "functions": [], "classes": [], "simplified_code": "def execution_scheduler_client() -> ExecutionScheduler:\n    return get_service_client(ExecutionScheduler)", "blocks": [{"id": 1, "label": "def execution_scheduler_client() -> ExecutionScheduler:\n    return get_service_client(ExecutionScheduler)", "successors": []}]}, {"name": "get_or_create_user_route", "type": "function", "start_line": 94, "end_line": 96, "functions": [], "classes": [], "simplified_code": "async def get_or_create_user_route(user_data: dict = Depends(auth_middleware)):\n    user = await get_or_create_user(user_data)\n    return user.model_dump()", "blocks": [{"id": 1, "label": "async def get_or_create_user_route(user_data: dict = Depends(auth_middleware)):\nuser = await get_or_create_user(user_data)", "successors": [{"id": 3, "label": "return user.model_dump()", "successors": []}]}]}, {"name": "get_graph_blocks", "type": "function", "start_line": 105, "end_line": 108, "functions": [], "classes": [], "simplified_code": "def get_graph_blocks() -> Sequence[dict[Any, Any]]:\n    blocks = [block() for block in backend.data.block.get_blocks().values()]\n    costs = get_block_costs()\n    return [{**b.to_dict(), \"costs\": costs.get(b.id, [])} for b in blocks]", "blocks": [{"id": 1, "label": "def get_graph_blocks() -> Sequence[dict[Any, Any]]:\n    blocks = [block() for block in backend.data.block.get_blocks().values()]\n    costs = get_block_costs()\n    return [{**b.to_dict(), \"costs\": costs.get(b.id, [])} for b in blocks]", "successors": []}]}, {"name": "execute_graph_block", "type": "function", "start_line": 116, "end_line": 124, "functions": [], "classes": [], "simplified_code": "def execute_graph_block(block_id: str, data: BlockInput) -> CompletedBlockOutput:\n    obj = backend.data.block.get_block(block_id)\n    if not obj:\n        raise HTTPException(status_code=404, detail=f\"Block #{block_id} not found.\")\n\n    output = defaultdict(list)\n    for name, data in obj.execute(data):\n        output[name].append(data)\n    return output", "blocks": [{"id": 1, "label": "def execute_graph_block(block_id: str, data: BlockInput) -> CompletedBlockOutput:\nobj = backend.data.block.get_block(block_id)", "successors": [{"id": 3, "label": "if not obj:", "successors": [{"id": 4, "label": "raise HTTPException(status_code=404, detail=f\"Block #{block_id} not found.\")", "successors": []}, {"id": 5, "label": "output = defaultdict(list)", "successors": [{"id": 6, "label": "for name, data in obj.execute(data):", "successors": [{"id": 7, "label": "output[name].append(data)\nreturn output", "successors": []}]}]}]}]}]}, {"name": "get_user_credits", "type": "function", "start_line": 133, "end_line": 137, "functions": [], "classes": [], "simplified_code": "async def get_user_credits(\n    user_id: Annotated[str, Depends(get_user_id)],\n) -> dict[str, int]:\n    # Credits can go negative, so ensure it's at least 0 for user to see.\n    return {\"credits\": max(await _user_credit_model.get_or_refill_credit(user_id), 0)}", "blocks": [{"id": 1, "label": "async def get_user_credits( user_id: Annotated[str, Depends(get_user_id)], ) -> dict[str, int]:\n    return {\"credits\": max(await _user_credit_model.get_or_refill_credit(user_id), 0)}", "successors": []}]}, {"name": "get_graphs", "type": "function", "start_line": 150, "end_line": 153, "functions": [], "classes": [], "simplified_code": "async def get_graphs(\n    user_id: Annotated[str, Depends(get_user_id)]\n) -> Sequence[graph_db.GraphModel]:\n    return await graph_db.get_graphs(filter_by=\"active\", user_id=user_id)", "blocks": [{"id": 1, "label": "async def get_graphs(user_id: Annotated[str, Depends(get_user_id)]) -> Sequence[graph_db.GraphModel]:\nreturn await graph_db.get_graphs(filter_by=\"active\", user_id=user_id)", "successors": []}]}, {"name": "get_graph", "type": "function", "start_line": 164, "end_line": 175, "functions": [], "classes": [], "simplified_code": "async def get_graph(\n    graph_id: str,\n    user_id: Annotated[str, Depends(get_user_id)],\n    version: int | None = None,\n    hide_credentials: bool = False,\n) -> graph_db.GraphModel:\n    graph = await graph_db.get_graph(\n        graph_id, version, user_id=user_id, for_export=hide_credentials\n    )\n    if not graph:\n        raise HTTPException(status_code=404, detail=f\"Graph #{graph_id} not found.\")\n    return graph", "blocks": [{"id": 1, "label": "async def get_graph(\n    graph_id: str,\n    user_id: Annotated[str, Depends(get_user_id)],\n    version: int | None = None,\n    hide_credentials: bool = False,\n) -> graph_db.GraphModel:\n    graph = await graph_db.get_graph(\n        graph_id, version, user_id=user_id, for_export=hide_credentials\n    )", "successors": [{"id": 3, "label": "    if not graph:", "successors": [{"id": 4, "label": "        raise HTTPException(status_code=404, detail=f\"Graph #{graph_id} not found.\")", "successors": []}, {"id": 5, "label": "    return graph", "successors": []}]}]}]}, {"name": "get_graph_all_versions", "type": "function", "start_line": 188, "end_line": 194, "functions": [], "classes": [], "simplified_code": "async def get_graph_all_versions(\n    graph_id: str, user_id: Annotated[str, Depends(get_user_id)]\n) -> Sequence[graph_db.GraphModel]:\n    graphs = await graph_db.get_graph_all_versions(graph_id, user_id=user_id)\n    if not graphs:\n        raise HTTPException(status_code=404, detail=f\"Graph #{graph_id} not found.\")\n    return graphs", "blocks": [{"id": 1, "label": "async def get_graph_all_versions(\n    graph_id: str, user_id: Annotated[str, Depends(get_user_id)]\n) -> Sequence[graph_db.GraphModel]:\n    graphs = await graph_db.get_graph_all_versions(graph_id, user_id=user_id)", "successors": [{"id": 3, "label": "    if not graphs:\n        raise HTTPException(status_code=404, detail=f\"Graph #{graph_id} not found.\")", "successors": []}, {"id": 5, "label": "    return graphs", "successors": []}]}]}, {"name": "create_new_graph", "type": "function", "start_line": 200, "end_line": 203, "functions": [], "classes": [], "simplified_code": "async def create_new_graph(\n    create_graph: CreateGraph, user_id: Annotated[str, Depends(get_user_id)]\n) -> graph_db.GraphModel:\n    return await do_create_graph(create_graph, is_template=False, user_id=user_id)", "blocks": [{"id": 1, "label": "async def create_new_graph(\n    create_graph: CreateGraph, user_id: Annotated[str, Depends(get_user_id)]\n) -> graph_db.GraphModel:\nreturn await do_create_graph(create_graph, is_template=False, user_id=user_id)", "successors": []}]}, {"name": "do_create_graph", "type": "function", "start_line": 206, "end_line": 242, "functions": [], "classes": [], "simplified_code": "async def do_create_graph(\n    create_graph: CreateGraph,\n    is_template: bool,\n    # user_id doesn't have to be annotated like on other endpoints,\n    # because create_graph isn't used directly as an endpoint\n    user_id: str,\n) -> graph_db.GraphModel:\n    if create_graph.graph:\n        graph = graph_db.make_graph_model(create_graph.graph, user_id)\n    elif create_graph.template_id:\n        # Create a new graph from a template\n        graph = await graph_db.get_graph(\n            create_graph.template_id,\n            create_graph.template_version,\n            template=True,\n            user_id=user_id,\n        )\n        if not graph:\n            raise HTTPException(\n                400, detail=f\"Template #{create_graph.template_id} not found\"\n            )\n        graph.version = 1\n    else:\n        raise HTTPException(\n            status_code=400, detail=\"Either graph or template_id must be provided.\"\n        )\n\n    graph.is_template = is_template\n    graph.is_active = not is_template\n    graph.reassign_ids(user_id=user_id, reassign_graph_id=True)\n\n    graph = await graph_db.create_graph(graph, user_id=user_id)\n    graph = await on_graph_activate(\n        graph,\n        get_credentials=lambda id: integration_creds_manager.get(user_id, id),\n    )\n    return graph", "blocks": [{"id": 1, "label": "async def do_create_graph(create_graph: CreateGraph, is_template: bool, user_id: str) -> graph_db.GraphModel:", "successors": [{"id": 2, "label": "if create_graph.graph:\ngraph = graph_db.make_graph_model(create_graph.graph, user_id)", "successors": []}, {"id": 4, "label": "elif create_graph.template_id:\ngraph = await graph_db.get_graph(create_graph.template_id, create_graph.template_version, template=True, user_id=user_id)", "successors": [{"id": 6, "label": "if not graph:\nraise HTTPException(400, detail=f\"Template #{create_graph.template_id} not found\")", "successors": []}, {"id": 8, "label": "graph.version = 1", "successors": []}]}, {"id": 9, "label": "else:\nraise HTTPException(status_code=400, detail=\"Either graph or template_id must be provided.\")", "successors": []}]}]}, {"name": "delete_graph", "type": "function", "start_line": 248, "end_line": 258, "functions": [{"name": "get_credentials", "type": "function", "start_line": 253, "end_line": 254, "functions": [], "classes": [], "simplified_code": "        def get_credentials(credentials_id: str) -> \"Credentials | None\":\n            return integration_creds_manager.get(user_id, credentials_id)", "blocks": [{"id": 1, "label": "def get_credentials(credentials_id: str) -> \"Credentials | None\":\n    return integration_creds_manager.get(user_id, credentials_id)", "successors": []}]}], "classes": [], "simplified_code": "async def delete_graph(\n    graph_id: str, user_id: Annotated[str, Depends(get_user_id)]\n) -> DeleteGraphResponse:\n    if active_version := await graph_db.get_graph(graph_id, user_id=user_id):\n\n            return integration_creds_manager.get(user_id, credentials_id)\n\n        await on_graph_deactivate(active_version, get_credentials)\n\n    return {\"version_counts\": await graph_db.delete_graph(graph_id, user_id=user_id)}", "blocks": [{"id": 1, "label": "async def delete_graph(\n    graph_id: str, user_id: Annotated[str, Depends(get_user_id)]\n) -> DeleteGraphResponse:", "successors": [{"id": 2, "label": "if active_version := await graph_db.get_graph(graph_id, user_id=user_id):", "successors": [{"id": 3, "label": "return integration_creds_manager.get(user_id, credentials_id)", "successors": []}, {"id": 4, "label": "await on_graph_deactivate(active_version, get_credentials)\nreturn {\"version_counts\": await graph_db.delete_graph(graph_id, user_id=user_id)}", "successors": []}]}, {"id": 5, "label": "return {\"version_counts\": await graph_db.delete_graph(graph_id, user_id=user_id)}", "successors": []}]}]}, {"name": "update_graph", "type": "function", "start_line": 269, "end_line": 320, "functions": [{"name": "get_credentials", "type": "function", "start_line": 301, "end_line": 302, "functions": [], "classes": [], "simplified_code": "        def get_credentials(credentials_id: str) -> \"Credentials | None\":\n            return integration_creds_manager.get(user_id, credentials_id)", "blocks": [{"id": 1, "label": "def get_credentials(credentials_id: str) -> \"Credentials | None\":\nreturn integration_creds_manager.get(user_id, credentials_id)", "successors": []}]}], "classes": [], "simplified_code": "async def update_graph(\n    graph_id: str,\n    graph: graph_db.Graph,\n    user_id: Annotated[str, Depends(get_user_id)],\n) -> graph_db.GraphModel:\n    # Sanity check\n    if graph.id and graph.id != graph_id:\n        raise HTTPException(400, detail=\"Graph ID does not match ID in URI\")\n\n    # Determine new version\n    existing_versions = await graph_db.get_graph_all_versions(graph_id, user_id=user_id)\n    if not existing_versions:\n        raise HTTPException(404, detail=f\"Graph #{graph_id} not found\")\n    latest_version_number = max(g.version for g in existing_versions)\n    graph.version = latest_version_number + 1\n\n    latest_version_graph = next(\n        v for v in existing_versions if v.version == latest_version_number\n    )\n    current_active_version = next((v for v in existing_versions if v.is_active), None)\n    if latest_version_graph.is_template != graph.is_template:\n        raise HTTPException(\n            400, detail=\"Changing is_template on an existing graph is forbidden\"\n        )\n    graph.is_active = not graph.is_template\n    graph = graph_db.make_graph_model(graph, user_id)\n    graph.reassign_ids(user_id=user_id)\n\n    new_graph_version = await graph_db.create_graph(graph, user_id=user_id)\n\n    if new_graph_version.is_active:\n\n            return integration_creds_manager.get(user_id, credentials_id)\n\n        # Handle activation of the new graph first to ensure continuity\n        new_graph_version = await on_graph_activate(\n            new_graph_version,\n            get_credentials=get_credentials,\n        )\n        # Ensure new version is the only active version\n        await graph_db.set_graph_active_version(\n            graph_id=graph_id, version=new_graph_version.version, user_id=user_id\n        )\n        if current_active_version:\n            # Handle deactivation of the previously active version\n            await on_graph_deactivate(\n                current_active_version,\n                get_credentials=get_credentials,\n            )\n\n    return new_graph_version", "blocks": [{"id": 1, "label": "async def update_graph(\n    graph_id: str,\n    graph: graph_db.Graph,\n    user_id: Annotated[str, Depends(get_user_id)],\n) -> graph_db.GraphModel:\n    if graph.id and graph.id != graph_id:", "successors": [{"id": 3, "label": "        raise HTTPException(400, detail=\"Graph ID does not match ID in URI\")\n# Determine new version", "successors": [{"id": 5, "label": "    existing_versions = await graph_db.get_graph_all_versions(graph_id, user_id=user_id)\n    if not existing_versions:\n        raise HTTPException(404, detail=f\"Graph #{graph_id} not found\")", "successors": [{"id": 7, "label": "    latest_version_number = max(g.version for g in existing_versions)\n    graph.version = latest_version_number + 1\n\n    latest_version_graph = next(\n        v for v in existing_versions if v.version == latest_version_number\n    )\n    current_active_version = next((v for v in existing_versions if v.is_active), None)\n    if latest_version_graph.is_template != graph.is_template:\n        raise HTTPException(\n            400, detail=\"Changing is_template on an existing graph is forbidden\"\n        )", "successors": [{"id": 9, "label": "    graph.is_active = not graph.is_template\n    graph = graph_db.make_graph_model(graph, user_id)\n    graph.reassign_ids(user_id=user_id)\n\n    new_graph_version = await graph_db.create_graph(graph, user_id=user_id)\n    if new_graph_version.is_active:", "successors": [{"id": 11, "label": "        return integration_creds_manager.get(user_id, credentials_id)", "successors": []}, {"id": 12, "label": "# Handle activation of the new graph first to ensure continuity\n        new_graph_version = await on_graph_activate(\n            new_graph_version,\n            get_credentials=get_credentials,\n        )\n        # Ensure new version is the only active version\n        await graph_db.set_graph_active_version(\n            graph_id=graph_id, version=new_graph_version.version, user_id=user_id\n        )\n        if current_active_version:\n            # Handle deactivation of the previously active version\n            await on_graph_deactivate(\n                current_active_version,\n                get_credentials=get_credentials,\n            )\n    return new_graph_version", "successors": []}]}]}]}]}]}]}, {"name": "set_graph_active_version", "type": "function", "start_line": 328, "end_line": 361, "functions": [{"name": "get_credentials", "type": "function", "start_line": 342, "end_line": 343, "functions": [], "classes": [], "simplified_code": "    def get_credentials(credentials_id: str) -> \"Credentials | None\":\n        return integration_creds_manager.get(user_id, credentials_id)", "blocks": [{"id": 1, "label": "def get_credentials(credentials_id: str) -> \"Credentials | None\":\n    return integration_creds_manager.get(user_id, credentials_id)", "successors": []}]}], "classes": [], "simplified_code": "async def set_graph_active_version(\n    graph_id: str,\n    request_body: SetGraphActiveVersion,\n    user_id: Annotated[str, Depends(get_user_id)],\n):\n    new_active_version = request_body.active_graph_version\n    new_active_graph = await graph_db.get_graph(\n        graph_id, new_active_version, user_id=user_id\n    )\n    if not new_active_graph:\n        raise HTTPException(404, f\"Graph #{graph_id} v{new_active_version} not found\")\n\n    current_active_graph = await graph_db.get_graph(graph_id, user_id=user_id)\n\n        return integration_creds_manager.get(user_id, credentials_id)\n\n    # Handle activation of the new graph first to ensure continuity\n    await on_graph_activate(\n        new_active_graph,\n        get_credentials=get_credentials,\n    )\n    # Ensure new version is the only active version\n    await graph_db.set_graph_active_version(\n        graph_id=graph_id,\n        version=new_active_version,\n        user_id=user_id,\n    )\n    if current_active_graph and current_active_graph.version != new_active_version:\n        # Handle deactivation of the previously active version\n        await on_graph_deactivate(\n            current_active_graph,\n            get_credentials=get_credentials,\n        )", "blocks": [{"id": 1, "label": "async def set_graph_active_version(\n    graph_id: str,\n    request_body: SetGraphActiveVersion,\n    user_id: Annotated[str, Depends(get_user_id)],\n):\n    new_active_version = request_body.active_graph_version\n    new_active_graph = await graph_db.get_graph(\n        graph_id, new_active_version, user_id=user_id\n    )\nif not new_active_graph:", "successors": [{"id": 3, "label": "raise HTTPException(404, f\"Graph #{graph_id} v{new_active_version} not found\")", "successors": []}, {"id": 4, "label": "current_active_graph = await graph_db.get_graph(graph_id, user_id=user_id)\nawait on_graph_activate(\n    new_active_graph,\n    get_credentials=get_credentials,\n)", "successors": [{"id": 8, "label": "await graph_db.set_graph_active_version(\n    graph_id=graph_id,\n    version=new_active_version,\n    user_id=user_id,\n)\nif current_active_graph and current_active_graph.version != new_active_version:", "successors": [{"id": 10, "label": "await on_graph_deactivate(\n    current_active_graph,\n    get_credentials=get_credentials,\n)", "successors": []}]}]}]}]}, {"name": "execute_graph", "type": "function", "start_line": 369, "end_line": 381, "functions": [], "classes": [], "simplified_code": "def execute_graph(\n    graph_id: str,\n    node_input: dict[Any, Any],\n    user_id: Annotated[str, Depends(get_user_id)],\n) -> dict[str, Any]:  # FIXME: add proper return type\n    try:\n        graph_exec = execution_manager_client().add_execution(\n            graph_id, node_input, user_id=user_id\n        )\n        return {\"id\": graph_exec.graph_exec_id}\n    except Exception as e:\n        msg = e.__str__().encode().decode(\"unicode_escape\")\n        raise HTTPException(status_code=400, detail=msg)", "blocks": [{"id": 1, "label": "def execute_graph(\n    graph_id: str,\n    node_input: dict[Any, Any],\n    user_id: Annotated[str, Depends(get_user_id)],\n) -> dict[str, Any]:  # FIXME: add proper return type\ntry:", "successors": [{"id": 3, "label": "    graph_exec = execution_manager_client().add_execution(\n        graph_id, node_input, user_id=user_id\n    )\n    return {\"id\": graph_exec.graph_exec_id}", "successors": []}, {"id": 4, "label": "except Exception as e:\n    msg = e.__str__().encode().decode(\"unicode_escape\")\n    raise HTTPException(status_code=400, detail=msg)", "successors": []}]}]}, {"name": "stop_graph_run", "type": "function", "start_line": 389, "end_line": 400, "functions": [], "classes": [], "simplified_code": "async def stop_graph_run(\n    graph_exec_id: str, user_id: Annotated[str, Depends(get_user_id)]\n) -> Sequence[execution_db.ExecutionResult]:\n    if not await graph_db.get_execution(user_id=user_id, execution_id=graph_exec_id):\n        raise HTTPException(404, detail=f\"Agent execution #{graph_exec_id} not found\")\n\n    await asyncio.to_thread(\n        lambda: execution_manager_client().cancel_execution(graph_exec_id)\n    )\n\n    # Retrieve & return canceled graph execution in its final state\n    return await execution_db.get_execution_results(graph_exec_id)", "blocks": [{"id": 1, "label": "async def stop_graph_run(\n    graph_exec_id: str, user_id: Annotated[str, Depends(get_user_id)]\n) -> Sequence[execution_db.ExecutionResult]:\nif not await graph_db.get_execution(user_id=user_id, execution_id=graph_exec_id):", "successors": [{"id": 3, "label": "raise HTTPException(404, detail=f\"Agent execution #{graph_exec_id} not found\")", "successors": []}, {"id": 4, "label": "await asyncio.to_thread(\n    lambda: execution_manager_client().cancel_execution(graph_exec_id)\n)\nreturn await execution_db.get_execution_results(graph_exec_id)", "successors": []}]}]}, {"name": "get_executions", "type": "function", "start_line": 408, "end_line": 411, "functions": [], "classes": [], "simplified_code": "async def get_executions(\n    user_id: Annotated[str, Depends(get_user_id)],\n) -> list[graph_db.GraphExecution]:\n    return await graph_db.get_executions(user_id=user_id)", "blocks": [{"id": 1, "label": "async def get_executions(\n    user_id: Annotated[str, Depends(get_user_id)],\n) -> list[graph_db.GraphExecution]:\nreturn await graph_db.get_executions(user_id=user_id)", "successors": []}]}, {"name": "get_graph_run_node_execution_results", "type": "function", "start_line": 419, "end_line": 428, "functions": [], "classes": [], "simplified_code": "async def get_graph_run_node_execution_results(\n    graph_id: str,\n    graph_exec_id: str,\n    user_id: Annotated[str, Depends(get_user_id)],\n) -> Sequence[execution_db.ExecutionResult]:\n    graph = await graph_db.get_graph(graph_id, user_id=user_id)\n    if not graph:\n        raise HTTPException(status_code=404, detail=f\"Graph #{graph_id} not found.\")\n\n    return await execution_db.get_execution_results(graph_exec_id)", "blocks": [{"id": 1, "label": "graph = await graph_db.get_graph(graph_id, user_id=user_id)\nif not graph:", "successors": [{"id": 3, "label": "raise HTTPException(status_code=404, detail=f\"Graph #{graph_id} not found.\")", "successors": []}, {"id": 4, "label": "return await execution_db.get_execution_results(graph_exec_id)", "successors": []}]}]}, {"name": "get_templates", "type": "function", "start_line": 441, "end_line": 444, "functions": [], "classes": [], "simplified_code": "async def get_templates(\n    user_id: Annotated[str, Depends(get_user_id)]\n) -> Sequence[graph_db.GraphModel]:\n    return await graph_db.get_graphs(filter_by=\"template\", user_id=user_id)", "blocks": [{"id": 1, "label": "async def get_templates(user_id: Annotated[str, Depends(get_user_id)]) -> Sequence[graph_db.GraphModel]:\nreturn await graph_db.get_graphs(filter_by=\"template\", user_id=user_id)", "successors": []}]}, {"name": "get_template", "type": "function", "start_line": 452, "end_line": 458, "functions": [], "classes": [], "simplified_code": "async def get_template(\n    graph_id: str, version: int | None = None\n) -> graph_db.GraphModel:\n    graph = await graph_db.get_graph(graph_id, version, template=True)\n    if not graph:\n        raise HTTPException(status_code=404, detail=f\"Template #{graph_id} not found.\")\n    return graph", "blocks": [{"id": 1, "label": "async def get_template(\n    graph_id: str, version: int | None = None\n) -> graph_db.GraphModel:", "successors": [{"id": 2, "label": "graph = await graph_db.get_graph(graph_id, version, template=True)\nif not graph:", "successors": [{"id": 4, "label": "    raise HTTPException(status_code=404, detail=f\"Template #{graph_id} not found.\")", "successors": []}]}, {"id": 5, "label": "return graph", "successors": []}]}]}, {"name": "create_new_template", "type": "function", "start_line": 466, "end_line": 469, "functions": [], "classes": [], "simplified_code": "async def create_new_template(\n    create_graph: CreateGraph, user_id: Annotated[str, Depends(get_user_id)]\n) -> graph_db.GraphModel:\n    return await do_create_graph(create_graph, is_template=True, user_id=user_id)", "blocks": [{"id": 1, "label": "return await do_create_graph(create_graph, is_template=True, user_id=user_id)", "successors": []}]}, {"name": "create_schedule", "type": "function", "start_line": 488, "end_line": 506, "functions": [], "classes": [], "simplified_code": "async def create_schedule(\n    user_id: Annotated[str, Depends(get_user_id)],\n    schedule: ScheduleCreationRequest,\n) -> scheduler.JobInfo:\n    graph = await graph_db.get_graph(schedule.graph_id, user_id=user_id)\n    if not graph:\n        raise HTTPException(\n            status_code=404, detail=f\"Graph #{schedule.graph_id} not found.\"\n        )\n\n    return await asyncio.to_thread(\n        lambda: execution_scheduler_client().add_execution_schedule(\n            graph_id=schedule.graph_id,\n            graph_version=graph.version,\n            cron=schedule.cron,\n            input_data=schedule.input_data,\n            user_id=user_id,\n        )\n    )", "blocks": [{"id": 1, "label": "graph = await graph_db.get_graph(schedule.graph_id, user_id=user_id)\nif not graph:", "successors": [{"id": 3, "label": "raise HTTPException(status_code=404, detail=f\"Graph #{schedule.graph_id} not found.\")", "successors": []}, {"id": 4, "label": "return await asyncio.to_thread(lambda: execution_scheduler_client().add_execution_schedule(graph_id=schedule.graph_id, graph_version=graph.version, cron=schedule.cron, input_data=schedule.input_data, user_id=user_id,))", "successors": []}]}]}, {"name": "delete_schedule", "type": "function", "start_line": 514, "end_line": 519, "functions": [], "classes": [], "simplified_code": "def delete_schedule(\n    schedule_id: str,\n    user_id: Annotated[str, Depends(get_user_id)],\n) -> dict[Any, Any]:\n    execution_scheduler_client().delete_schedule(schedule_id, user_id=user_id)\n    return {\"id\": schedule_id}", "blocks": [{"id": 1, "label": "def delete_schedule(\n    schedule_id: str,\n    user_id: Annotated[str, Depends(get_user_id)],\n) -> dict[Any, Any]:\nexecution_scheduler_client().delete_schedule(schedule_id, user_id=user_id)", "successors": [{"id": 3, "label": "return {\"id\": schedule_id}", "successors": []}]}]}, {"name": "get_execution_schedules", "type": "function", "start_line": 527, "end_line": 534, "functions": [], "classes": [], "simplified_code": "def get_execution_schedules(\n    user_id: Annotated[str, Depends(get_user_id)],\n    graph_id: str | None = None,\n) -> list[scheduler.JobInfo]:\n    return execution_scheduler_client().get_execution_schedules(\n        user_id=user_id,\n        graph_id=graph_id,\n    )", "blocks": [{"id": 1, "label": "def get_execution_schedules(\n    user_id: Annotated[str, Depends(get_user_id)],\n    graph_id: str | None = None,\n) -> list[scheduler.JobInfo]:\nreturn execution_scheduler_client().get_execution_schedules(\n    user_id=user_id,\n    graph_id=graph_id,\n)", "successors": []}]}, {"name": "create_api_key", "type": "function", "start_line": 549, "end_line": 563, "functions": [], "classes": [], "simplified_code": "async def create_api_key(\n    request: CreateAPIKeyRequest, user_id: Annotated[str, Depends(get_user_id)]\n) -> CreateAPIKeyResponse:\n    \"\"\"Create a new API key\"\"\"\n    try:\n        api_key, plain_text = await generate_api_key(\n            name=request.name,\n            user_id=user_id,\n            permissions=request.permissions,\n            description=request.description,\n        )\n        return CreateAPIKeyResponse(api_key=api_key, plain_text_key=plain_text)\n    except APIKeyError as e:\n        logger.error(f\"Failed to create API key: {str(e)}\")\n        raise HTTPException(status_code=400, detail=str(e))", "blocks": [{"id": 1, "label": "\"\"\"Create a new API key\"\"\"\ntry:", "successors": [{"id": 2, "label": "    api_key, plain_text = await generate_api_key(\n        name=request.name,\n        user_id=user_id,\n        permissions=request.permissions,\n        description=request.description,\n    )\n    return CreateAPIKeyResponse(api_key=api_key, plain_text_key=plain_text)", "successors": []}, {"id": 3, "label": "except APIKeyError as e:\n    logger.error(f\"Failed to create API key: {str(e)}\")\n    raise HTTPException(status_code=400, detail=str(e))", "successors": []}]}]}, {"name": "get_api_keys", "type": "function", "start_line": 573, "end_line": 581, "functions": [], "classes": [], "simplified_code": "async def get_api_keys(\n    user_id: Annotated[str, Depends(get_user_id)]\n) -> list[APIKeyWithoutHash]:\n    \"\"\"List all API keys for the user\"\"\"\n    try:\n        return await list_user_api_keys(user_id)\n    except APIKeyError as e:\n        logger.error(f\"Failed to list API keys: {str(e)}\")\n        raise HTTPException(status_code=400, detail=str(e))", "blocks": [{"id": 1, "label": "async def get_api_keys(\n    user_id: Annotated[str, Depends(get_user_id)]\n) -> list[APIKeyWithoutHash]:\n    \"\"\"List all API keys for the user\"\"\"\n    try:", "successors": [{"id": 2, "label": "return await list_user_api_keys(user_id)", "successors": []}, {"id": 3, "label": "except APIKeyError as e:\n    logger.error(f\"Failed to list API keys: {str(e)}\")\n    raise HTTPException(status_code=400, detail=str(e))", "successors": []}]}]}, {"name": "get_api_key", "type": "function", "start_line": 591, "end_line": 602, "functions": [], "classes": [], "simplified_code": "async def get_api_key(\n    key_id: str, user_id: Annotated[str, Depends(get_user_id)]\n) -> APIKeyWithoutHash:\n    \"\"\"Get a specific API key\"\"\"\n    try:\n        api_key = await get_api_key_by_id(key_id, user_id)\n        if not api_key:\n            raise HTTPException(status_code=404, detail=\"API key not found\")\n        return api_key\n    except APIKeyError as e:\n        logger.error(f\"Failed to get API key: {str(e)}\")\n        raise HTTPException(status_code=400, detail=str(e))", "blocks": [{"id": 1, "label": "async def get_api_key(\n    key_id: str, user_id: Annotated[str, Depends(get_user_id)]\n) -> APIKeyWithoutHash:\ntry:", "successors": [{"id": 3, "label": "api_key = await get_api_key_by_id(key_id, user_id)\nif not api_key:", "successors": [{"id": 5, "label": "raise HTTPException(status_code=404, detail=\"API key not found\")", "successors": []}, {"id": 6, "label": "return api_key", "successors": []}]}, {"id": 7, "label": "except APIKeyError as e:\nlogger.error(f\"Failed to get API key: {str(e)}\")", "successors": [{"id": 9, "label": "raise HTTPException(status_code=400, detail=str(e))", "successors": []}]}]}]}, {"name": "delete_api_key", "type": "function", "start_line": 612, "end_line": 624, "functions": [], "classes": [], "simplified_code": "async def delete_api_key(\n    key_id: str, user_id: Annotated[str, Depends(get_user_id)]\n) -> Optional[APIKeyWithoutHash]:\n    \"\"\"Revoke an API key\"\"\"\n    try:\n        return await revoke_api_key(key_id, user_id)\n    except APIKeyNotFoundError:\n        raise HTTPException(status_code=404, detail=\"API key not found\")\n    except APIKeyPermissionError:\n        raise HTTPException(status_code=403, detail=\"Permission denied\")\n    except APIKeyError as e:\n        logger.error(f\"Failed to revoke API key: {str(e)}\")\n        raise HTTPException(status_code=400, detail=str(e))", "blocks": [{"id": 1, "label": "async def delete_api_key(\n    key_id: str, user_id: Annotated[str, Depends(get_user_id)]\n) -> Optional[APIKeyWithoutHash]:\n    \"\"\"Revoke an API key\"\"\"\ntry:", "successors": [{"id": 3, "label": "    return await revoke_api_key(key_id, user_id)", "successors": []}, {"id": 4, "label": "except APIKeyNotFoundError:\n    raise HTTPException(status_code=404, detail=\"API key not found\")", "successors": []}, {"id": 6, "label": "except APIKeyPermissionError:\n    raise HTTPException(status_code=403, detail=\"Permission denied\")", "successors": []}, {"id": 8, "label": "except APIKeyError as e:\n    logger.error(f\"Failed to revoke API key: {str(e)}\")\n    raise HTTPException(status_code=400, detail=str(e))", "successors": []}]}]}, {"name": "suspend_key", "type": "function", "start_line": 634, "end_line": 646, "functions": [], "classes": [], "simplified_code": "async def suspend_key(\n    key_id: str, user_id: Annotated[str, Depends(get_user_id)]\n) -> Optional[APIKeyWithoutHash]:\n    \"\"\"Suspend an API key\"\"\"\n    try:\n        return await suspend_api_key(key_id, user_id)\n    except APIKeyNotFoundError:\n        raise HTTPException(status_code=404, detail=\"API key not found\")\n    except APIKeyPermissionError:\n        raise HTTPException(status_code=403, detail=\"Permission denied\")\n    except APIKeyError as e:\n        logger.error(f\"Failed to suspend API key: {str(e)}\")\n        raise HTTPException(status_code=400, detail=str(e))", "blocks": [{"id": 1, "label": "async def suspend_key(\n    key_id: str, user_id: Annotated[str, Depends(get_user_id)]\n) -> Optional[APIKeyWithoutHash]:\n    \"\"\"Suspend an API key\"\"\"", "successors": [{"id": 3, "label": "    try:", "successors": [{"id": 4, "label": "        return await suspend_api_key(key_id, user_id)", "successors": []}, {"id": 5, "label": "    except APIKeyNotFoundError:\n        raise HTTPException(status_code=404, detail=\"API key not found\")", "successors": []}, {"id": 7, "label": "    except APIKeyPermissionError:\n        raise HTTPException(status_code=403, detail=\"Permission denied\")", "successors": []}, {"id": 9, "label": "    except APIKeyError as e:\n        logger.error(f\"Failed to suspend API key: {str(e)}\")", "successors": [{"id": 11, "label": "        raise HTTPException(status_code=400, detail=str(e))", "successors": []}]}]}]}]}, {"name": "update_permissions", "type": "function", "start_line": 656, "end_line": 670, "functions": [], "classes": [], "simplified_code": "async def update_permissions(\n    key_id: str,\n    request: UpdatePermissionsRequest,\n    user_id: Annotated[str, Depends(get_user_id)],\n) -> Optional[APIKeyWithoutHash]:\n    \"\"\"Update API key permissions\"\"\"\n    try:\n        return await update_api_key_permissions(key_id, user_id, request.permissions)\n    except APIKeyNotFoundError:\n        raise HTTPException(status_code=404, detail=\"API key not found\")\n    except APIKeyPermissionError:\n        raise HTTPException(status_code=403, detail=\"Permission denied\")\n    except APIKeyError as e:\n        logger.error(f\"Failed to update API key permissions: {str(e)}\")\n        raise HTTPException(status_code=400, detail=str(e))", "blocks": [{"id": 1, "label": "async def update_permissions(    key_id: str,    request: UpdatePermissionsRequest,    user_id: Annotated[str, Depends(get_user_id)],) -> Optional[APIKeyWithoutHash]:\n\"\"\"Update API key permissions\"\"\"", "successors": [{"id": 3, "label": "try:", "successors": [{"id": 4, "label": "return await update_api_key_permissions(key_id, user_id, request.permissions)", "successors": []}, {"id": 5, "label": "except APIKeyNotFoundError:\nraise HTTPException(status_code=404, detail=\"API key not found\")", "successors": []}, {"id": 7, "label": "except APIKeyPermissionError:\nraise HTTPException(status_code=403, detail=\"Permission denied\")", "successors": []}, {"id": 9, "label": "except APIKeyError as e:\nlogger.error(f\"Failed to update API key permissions: {str(e)}\")", "successors": [{"id": 11, "label": "raise HTTPException(status_code=400, detail=str(e))", "successors": []}]}]}]}]}], "classes": [{"name": "DeleteGraphResponse", "type": "class", "start_line": 145, "end_line": 146, "functions": [], "classes": [], "simplified_code": "class DeleteGraphResponse(TypedDict):\n    version_counts: int", "blocks": [{"id": 1, "label": "class DeleteGraphResponse(TypedDict):\n    version_counts: int", "successors": []}]}, {"name": "ScheduleCreationRequest", "type": "class", "start_line": 477, "end_line": 480, "functions": [], "classes": [], "simplified_code": "class ScheduleCreationRequest(pydantic.BaseModel):\n    cron: str\n    input_data: dict[Any, Any]\n    graph_id: str", "blocks": [{"id": 1, "label": "class ScheduleCreationRequest(pydantic.BaseModel):", "successors": [{"id": 2, "label": "    cron: str", "successors": []}, {"id": 3, "label": "    input_data: dict[Any, Any]", "successors": []}, {"id": 4, "label": "    graph_id: str", "successors": []}]}]}], "simplified_code": "import asyncio\nimport logging\nfrom collections import defaultdict\nfrom typing import TYPE_CHECKING, Annotated, Any, Sequence\n\nimport pydantic\nfrom autogpt_libs.auth.middleware import auth_middleware\nfrom autogpt_libs.feature_flag.client import feature_flag\nfrom autogpt_libs.utils.cache import thread_cached\nfrom fastapi import APIRouter, Depends, HTTPException\nfrom typing_extensions import Optional, TypedDict\n\nimport backend.data.block\nimport backend.server.integrations.router\nimport backend.server.routers.analytics\nfrom backend.data import execution as execution_db\nfrom backend.data import graph as graph_db\nfrom backend.data.api_key import (\n    APIKeyError,\n    APIKeyNotFoundError,\n    APIKeyPermissionError,\n    APIKeyWithoutHash,\n    generate_api_key,\n    get_api_key_by_id,\n    list_user_api_keys,\n    revoke_api_key,\n    suspend_api_key,\n    update_api_key_permissions,\n)\nfrom backend.data.block import BlockInput, CompletedBlockOutput\nfrom backend.data.credit import get_block_costs, get_user_credit_model\nfrom backend.data.user import get_or_create_user\nfrom backend.executor import ExecutionManager, ExecutionScheduler, scheduler\nfrom backend.integrations.creds_manager import IntegrationCredentialsManager\nfrom backend.integrations.webhooks.graph_lifecycle_hooks import (\n    on_graph_activate,\n    on_graph_deactivate,\n)\nfrom backend.server.model import (\n    CreateAPIKeyRequest,\n    CreateAPIKeyResponse,\n    CreateGraph,\n    SetGraphActiveVersion,\n    UpdatePermissionsRequest,\n)\nfrom backend.server.utils import get_user_id\nfrom backend.util.service import get_service_client\nfrom backend.util.settings import Settings\n\nif TYPE_CHECKING:\n    from backend.data.model import Credentials\n\n\n@thread_cached\n    return get_service_client(ExecutionManager)\n\n\n@thread_cached\n    return get_service_client(ExecutionScheduler)\n\n\nsettings = Settings()\nlogger = logging.getLogger(__name__)\nintegration_creds_manager = IntegrationCredentialsManager()\n\n\n_user_credit_model = get_user_credit_model()\n\n# Define the API routes\nv1_router = APIRouter()\n\nv1_router.include_router(\n    backend.server.integrations.router.router,\n    prefix=\"/integrations\",\n    tags=[\"integrations\"],\n)\n\nv1_router.include_router(\n    backend.server.routers.analytics.router,\n    prefix=\"/analytics\",\n    tags=[\"analytics\"],\n    dependencies=[Depends(auth_middleware)],\n)\n\n\n########################################################\n##################### Auth #############################\n########################################################\n\n\n@v1_router.post(\"/auth/user\", tags=[\"auth\"], dependencies=[Depends(auth_middleware)])\n    return user.model_dump()\n\n\n########################################################\n##################### Blocks ###########################\n########################################################\n\n\n@v1_router.get(path=\"/blocks\", tags=[\"blocks\"], dependencies=[Depends(auth_middleware)])\n    return [{**b.to_dict(), \"costs\": costs.get(b.id, [])} for b in blocks]\n\n\n@v1_router.post(\n    path=\"/blocks/{block_id}/execute\",\n    tags=[\"blocks\"],\n    dependencies=[Depends(auth_middleware)],\n)\n    return output\n\n\n########################################################\n##################### Credits ##########################\n########################################################\n\n\n@v1_router.get(path=\"/credits\", dependencies=[Depends(auth_middleware)])\n    return {\"credits\": max(await _user_credit_model.get_or_refill_credit(user_id), 0)}\n\n\n########################################################\n##################### Graphs ###########################\n########################################################\n\n\n    version_counts: int\n\n\n@v1_router.get(path=\"/graphs\", tags=[\"graphs\"], dependencies=[Depends(auth_middleware)])\n    return await graph_db.get_graphs(filter_by=\"active\", user_id=user_id)\n\n\n@v1_router.get(\n    path=\"/graphs/{graph_id}\", tags=[\"graphs\"], dependencies=[Depends(auth_middleware)]\n)\n@v1_router.get(\n    path=\"/graphs/{graph_id}/versions/{version}\",\n    tags=[\"graphs\"],\n    dependencies=[Depends(auth_middleware)],\n)\n    return graph\n\n\n@v1_router.get(\n    path=\"/graphs/{graph_id}/versions\",\n    tags=[\"graphs\"],\n    dependencies=[Depends(auth_middleware)],\n)\n@v1_router.get(\n    path=\"/templates/{graph_id}/versions\",\n    tags=[\"templates\", \"graphs\"],\n    dependencies=[Depends(auth_middleware)],\n)\n    return graphs\n\n\n@v1_router.post(\n    path=\"/graphs\", tags=[\"graphs\"], dependencies=[Depends(auth_middleware)]\n)\n    return await do_create_graph(create_graph, is_template=False, user_id=user_id)\n\n\n    return graph\n\n\n@v1_router.delete(\n    path=\"/graphs/{graph_id}\", tags=[\"graphs\"], dependencies=[Depends(auth_middleware)]\n)\n    return {\"version_counts\": await graph_db.delete_graph(graph_id, user_id=user_id)}\n\n\n@v1_router.put(\n    path=\"/graphs/{graph_id}\", tags=[\"graphs\"], dependencies=[Depends(auth_middleware)]\n)\n@v1_router.put(\n    path=\"/templates/{graph_id}\",\n    tags=[\"templates\", \"graphs\"],\n    dependencies=[Depends(auth_middleware)],\n)\n    return new_graph_version\n\n\n@v1_router.put(\n    path=\"/graphs/{graph_id}/versions/active\",\n    tags=[\"graphs\"],\n    dependencies=[Depends(auth_middleware)],\n)\n        )\n\n\n@v1_router.post(\n    path=\"/graphs/{graph_id}/execute\",\n    tags=[\"graphs\"],\n    dependencies=[Depends(auth_middleware)],\n)\n        raise HTTPException(status_code=400, detail=msg)\n\n\n@v1_router.post(\n    path=\"/graphs/{graph_id}/executions/{graph_exec_id}/stop\",\n    tags=[\"graphs\"],\n    dependencies=[Depends(auth_middleware)],\n)\n    return await execution_db.get_execution_results(graph_exec_id)\n\n\n@v1_router.get(\n    path=\"/executions\",\n    tags=[\"graphs\"],\n    dependencies=[Depends(auth_middleware)],\n)\n    return await graph_db.get_executions(user_id=user_id)\n\n\n@v1_router.get(\n    path=\"/graphs/{graph_id}/executions/{graph_exec_id}\",\n    tags=[\"graphs\"],\n    dependencies=[Depends(auth_middleware)],\n)\n    return await execution_db.get_execution_results(graph_exec_id)\n\n\n########################################################\n##################### Templates ########################\n########################################################\n\n\n@v1_router.get(\n    path=\"/templates\",\n    tags=[\"graphs\", \"templates\"],\n    dependencies=[Depends(auth_middleware)],\n)\n    return await graph_db.get_graphs(filter_by=\"template\", user_id=user_id)\n\n\n@v1_router.get(\n    path=\"/templates/{graph_id}\",\n    tags=[\"templates\", \"graphs\"],\n    dependencies=[Depends(auth_middleware)],\n)\n    return graph\n\n\n@v1_router.post(\n    path=\"/templates\",\n    tags=[\"templates\", \"graphs\"],\n    dependencies=[Depends(auth_middleware)],\n)\n    return await do_create_graph(create_graph, is_template=True, user_id=user_id)\n\n\n########################################################\n##################### Schedules ########################\n########################################################\n\n\n    graph_id: str\n\n\n@v1_router.post(\n    path=\"/schedules\",\n    tags=[\"schedules\"],\n    dependencies=[Depends(auth_middleware)],\n)\n    )\n\n\n@v1_router.delete(\n    path=\"/schedules/{schedule_id}\",\n    tags=[\"schedules\"],\n    dependencies=[Depends(auth_middleware)],\n)\n    return {\"id\": schedule_id}\n\n\n@v1_router.get(\n    path=\"/schedules\",\n    tags=[\"schedules\"],\n    dependencies=[Depends(auth_middleware)],\n)\n    )\n\n\n########################################################\n#####################  API KEY ##############################\n########################################################\n\n\n@v1_router.post(\n    \"/api-keys\",\n    response_model=list[CreateAPIKeyResponse] | dict[str, str],\n    tags=[\"api-keys\"],\n    dependencies=[Depends(auth_middleware)],\n)\n@feature_flag(\"api-keys-enabled\")\n        raise HTTPException(status_code=400, detail=str(e))\n\n\n@v1_router.get(\n    \"/api-keys\",\n    response_model=list[APIKeyWithoutHash] | dict[str, str],\n    tags=[\"api-keys\"],\n    dependencies=[Depends(auth_middleware)],\n)\n@feature_flag(\"api-keys-enabled\")\n        raise HTTPException(status_code=400, detail=str(e))\n\n\n@v1_router.get(\n    \"/api-keys/{key_id}\",\n    response_model=list[APIKeyWithoutHash] | dict[str, str],\n    tags=[\"api-keys\"],\n    dependencies=[Depends(auth_middleware)],\n)\n@feature_flag(\"api-keys-enabled\")\n        raise HTTPException(status_code=400, detail=str(e))\n\n\n@v1_router.delete(\n    \"/api-keys/{key_id}\",\n    response_model=list[APIKeyWithoutHash] | dict[str, str],\n    tags=[\"api-keys\"],\n    dependencies=[Depends(auth_middleware)],\n)\n@feature_flag(\"api-keys-enabled\")\n        raise HTTPException(status_code=400, detail=str(e))\n\n\n@v1_router.post(\n    \"/api-keys/{key_id}/suspend\",\n    response_model=list[APIKeyWithoutHash] | dict[str, str],\n    tags=[\"api-keys\"],\n    dependencies=[Depends(auth_middleware)],\n)\n@feature_flag(\"api-keys-enabled\")\n        raise HTTPException(status_code=400, detail=str(e))\n\n\n@v1_router.put(\n    \"/api-keys/{key_id}/permissions\",\n    response_model=list[APIKeyWithoutHash] | dict[str, str],\n    tags=[\"api-keys\"],\n    dependencies=[Depends(auth_middleware)],\n)\n@feature_flag(\"api-keys-enabled\")\n        raise HTTPException(status_code=400, detail=str(e))", "blocks": [{"id": 1, "label": "@thread_cached\n    return get_service_client(ExecutionManager)", "successors": []}]}
{"file_name": "22.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 581, "functions": [{"name": "is_github_url", "type": "function", "start_line": 18, "end_line": 19, "functions": [], "classes": [], "simplified_code": "def is_github_url(url: str) -> bool:\n    return urlparse(url).netloc == \"github.com\"", "blocks": [{"id": 1, "label": "def is_github_url(url: str) -> bool:\n    return urlparse(url).netloc == \"github.com\"", "successors": []}]}], "classes": [{"name": "GithubCommentBlock", "type": "class", "start_line": 23, "end_line": 108, "functions": [{"name": "__init__", "type": "function", "start_line": 42, "end_line": 77, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"a8db4d8d-db1c-4a25-a1b0-416a8c33602b\",\n            description=\"This block posts a comment on a specified GitHub issue or pull request.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubCommentBlock.Input,\n            output_schema=GithubCommentBlock.Output,\n            test_input=[\n                {\n                    \"issue_url\": \"https://github.com/owner/repo/issues/1\",\n                    \"comment\": \"This is a test comment.\",\n                    \"credentials\": TEST_CREDENTIALS_INPUT,\n                },\n                {\n                    \"issue_url\": \"https://github.com/owner/repo/pull/1\",\n                    \"comment\": \"This is a test comment.\",\n                    \"credentials\": TEST_CREDENTIALS_INPUT,\n                },\n            ],\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\"id\", 1337),\n                (\"url\", \"https://github.com/owner/repo/issues/1#issuecomment-1337\"),\n                (\"id\", 1337),\n                (\n                    \"url\",\n                    \"https://github.com/owner/repo/issues/1#issuecomment-1337\",\n                ),\n            ],\n            test_mock={\n                \"post_comment\": lambda *args, **kwargs: (\n                    1337,\n                    \"https://github.com/owner/repo/issues/1#issuecomment-1337\",\n                )\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"a8db4d8d-db1c-4a25-a1b0-416a8c33602b\",\n    description=\"This block posts a comment on a specified GitHub issue or pull request.\",\n    categories={BlockCategory.DEVELOPER_TOOLS},\n    input_schema=GithubCommentBlock.Input,\n    output_schema=GithubCommentBlock.Output,\n    test_input=[\n        {\n            \"issue_url\": \"https://github.com/owner/repo/issues/1\",\n            \"comment\": \"This is a test comment.\",\n            \"credentials\": TEST_CREDENTIALS_INPUT,\n        },\n        {\n            \"issue_url\": \"https://github.com/owner/repo/pull/1\",\n            \"comment\": \"This is a test comment.\",\n            \"credentials\": TEST_CREDENTIALS_INPUT,\n        },\n    ],\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\"id\", 1337),\n        (\"url\", \"https://github.com/owner/repo/issues/1#issuecomment-1337\"),\n        (\"id\", 1337),\n        (\n            \"url\",\n            \"https://github.com/owner/repo/issues/1#issuecomment-1337\",\n        ),\n    ],\n    test_mock={\n        \"post_comment\": lambda *args, **kwargs: (\n            1337,\n            \"https://github.com/owner/repo/issues/1#issuecomment-1337\",\n        )\n    },\n)", "successors": []}]}, {"name": "post_comment", "type": "function", "start_line": 80, "end_line": 90, "functions": [], "classes": [], "simplified_code": "    def post_comment(\n        credentials: GithubCredentials, issue_url: str, body_text: str\n    ) -> tuple[int, str]:\n        api = get_api(credentials)\n        data = {\"body\": body_text}\n        if \"pull\" in issue_url:\n            issue_url = issue_url.replace(\"pull\", \"issues\")\n        comments_url = issue_url + \"/comments\"\n        response = api.post(comments_url, json=data)\n        comment = response.json()\n        return comment[\"id\"], comment[\"html_url\"]", "blocks": [{"id": 1, "label": "def post_comment( credentials: GithubCredentials, issue_url: str, body_text: str ) -> tuple[int, str]:\napi = get_api(credentials)\ndata = {\"body\": body_text}", "successors": [{"id": 3, "label": "if \"pull\" in issue_url:", "successors": [{"id": 4, "label": "    issue_url = issue_url.replace(\"pull\", \"issues\")\ncomments_url = issue_url + \"/comments\"\nresponse = api.post(comments_url, json=data)\ncomment = response.json()\nreturn comment[\"id\"], comment[\"html_url\"]", "successors": []}, {"id": 5, "label": "comments_url = issue_url + \"/comments\"\nresponse = api.post(comments_url, json=data)\ncomment = response.json()\nreturn comment[\"id\"], comment[\"html_url\"]", "successors": []}]}]}]}, {"name": "run", "type": "function", "start_line": 92, "end_line": 105, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        id, url = self.post_comment(\n            credentials,\n            input_data.issue_url,\n            input_data.comment,\n        )\n        yield \"id\", id\n        yield \"url\", url", "blocks": [{"id": 1, "label": "def run(\n    self,\n    input_data: Input,\n    *,\n    credentials: GithubCredentials,\n    **kwargs,\n) -> BlockOutput:\nid, url = self.post_comment(\n    credentials,\n    input_data.issue_url,\n    input_data.comment,\n)", "successors": [{"id": 3, "label": "yield \"id\", id\nyield \"url\", url", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 24, "end_line": 33, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        issue_url: str = SchemaField(\n            description=\"URL of the GitHub issue or pull request\",\n            placeholder=\"https://github.com/owner/repo/issues/1\",\n        )\n        comment: str = SchemaField(\n            description=\"Comment to post on the issue or pull request\",\n            placeholder=\"Enter your comment\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")", "successors": [{"id": 3, "label": "    issue_url: str = SchemaField(\n        description=\"URL of the GitHub issue or pull request\",\n        placeholder=\"https://github.com/owner/repo/issues/1\",\n    )\n    comment: str = SchemaField(\n        description=\"Comment to post on the issue or pull request\",\n        placeholder=\"Enter your comment\",\n    )", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 35, "end_line": 40, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        id: int = SchemaField(description=\"ID of the created comment\")\n        url: str = SchemaField(description=\"URL to the comment on GitHub\")\n        error: str = SchemaField(\n            description=\"Error message if the comment posting failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    id: int = SchemaField(description=\"ID of the created comment\")", "successors": [{"id": 3, "label": "    url: str = SchemaField(description=\"URL to the comment on GitHub\")\n    error: str = SchemaField(description=\"Error message if the comment posting failed\")", "successors": []}]}]}], "simplified_code": "class GithubCommentBlock(Block):\n        )\n\n        )\n\n        )\n\n    @staticmethod\n        return comment[\"id\"], comment[\"html_url\"]\n\n        yield \"url\", url\n\n\n# --8<-- [end:GithubCommentBlockExample]", "blocks": [{"id": 1, "label": "class GithubCommentBlock(Block):\n", "successors": [{"id": 3, "label": "@staticmethod\nreturn comment[\"id\"], comment[\"html_url\"]", "successors": [{"id": 5, "label": "yield \"url\", url", "successors": []}]}]}]}, {"name": "GithubMakeIssueBlock", "type": "class", "start_line": 111, "end_line": 185, "functions": [{"name": "__init__", "type": "function", "start_line": 132, "end_line": 156, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"691dad47-f494-44c3-a1e8-05b7990f2dab\",\n            description=\"This block creates a new issue on a specified GitHub repository.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubMakeIssueBlock.Input,\n            output_schema=GithubMakeIssueBlock.Output,\n            test_input={\n                \"repo_url\": \"https://github.com/owner/repo\",\n                \"title\": \"Test Issue\",\n                \"body\": \"This is a test issue.\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\"number\", 1),\n                (\"url\", \"https://github.com/owner/repo/issues/1\"),\n            ],\n            test_mock={\n                \"create_issue\": lambda *args, **kwargs: (\n                    1,\n                    \"https://github.com/owner/repo/issues/1\",\n                )\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"691dad47-f494-44c3-a1e8-05b7990f2dab\",\n    description=\"This block creates a new issue on a specified GitHub repository.\",\n    categories={BlockCategory.DEVELOPER_TOOLS},\n    input_schema=GithubMakeIssueBlock.Input,\n    output_schema=GithubMakeIssueBlock.Output,\n    test_input={\n        \"repo_url\": \"https://github.com/owner/repo\",\n        \"title\": \"Test Issue\",\n        \"body\": \"This is a test issue.\",\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\"number\", 1),\n        (\"url\", \"https://github.com/owner/repo/issues/1\"),\n    ],\n    test_mock={\n        \"create_issue\": lambda *args, **kwargs: (\n            1,\n            \"https://github.com/owner/repo/issues/1\",\n        )\n    },\n)", "successors": []}]}, {"name": "create_issue", "type": "function", "start_line": 159, "end_line": 167, "functions": [], "classes": [], "simplified_code": "    def create_issue(\n        credentials: GithubCredentials, repo_url: str, title: str, body: str\n    ) -> tuple[int, str]:\n        api = get_api(credentials)\n        data = {\"title\": title, \"body\": body}\n        issues_url = repo_url + \"/issues\"\n        response = api.post(issues_url, json=data)\n        issue = response.json()\n        return issue[\"number\"], issue[\"html_url\"]", "blocks": [{"id": 1, "label": "def create_issue(\n    credentials: GithubCredentials, repo_url: str, title: str, body: str\n) -> tuple[int, str]:\napi = get_api(credentials)\ndata = {\"title\": title, \"body\": body}\nissues_url = repo_url + \"/issues\"\nresponse = api.post(issues_url, json=data)\nissue = response.json()", "successors": [{"id": 3, "label": "return issue[\"number\"], issue[\"html_url\"]", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 169, "end_line": 183, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        number, url = self.create_issue(\n            credentials,\n            input_data.repo_url,\n            input_data.title,\n            input_data.body,\n        )\n        yield \"number\", number\n        yield \"url\", url", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: GithubCredentials, **kwargs) -> BlockOutput:\nnumber, url = self.create_issue(credentials, input_data.repo_url, input_data.title, input_data.body)", "successors": [{"id": 3, "label": "yield \"number\", number\nyield \"url\", url", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 112, "end_line": 123, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        repo_url: str = SchemaField(\n            description=\"URL of the GitHub repository\",\n            placeholder=\"https://github.com/owner/repo\",\n        )\n        title: str = SchemaField(\n            description=\"Title of the issue\", placeholder=\"Enter the issue title\"\n        )\n        body: str = SchemaField(\n            description=\"Body of the issue\", placeholder=\"Enter the issue body\"\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")", "successors": [{"id": 3, "label": "    repo_url: str = SchemaField(description=\"URL of the GitHub repository\", placeholder=\"https://github.com/owner/repo\")\n    title: str = SchemaField(description=\"Title of the issue\", placeholder=\"Enter the issue title\")", "successors": [{"id": 5, "label": "    body: str = SchemaField(description=\"Body of the issue\", placeholder=\"Enter the issue body\")", "successors": []}]}]}]}, {"name": "Output", "type": "class", "start_line": 125, "end_line": 130, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        number: int = SchemaField(description=\"Number of the created issue\")\n        url: str = SchemaField(description=\"URL of the created issue\")\n        error: str = SchemaField(\n            description=\"Error message if the issue creation failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "    number: int = SchemaField(description=\"Number of the created issue\")", "successors": []}, {"id": 3, "label": "    url: str = SchemaField(description=\"URL of the created issue\")", "successors": []}, {"id": 4, "label": "    error: str = SchemaField(description=\"Error message if the issue creation failed\")", "successors": []}]}]}], "simplified_code": "class GithubMakeIssueBlock(Block):\n        )\n\n        )\n\n        )\n\n    @staticmethod\n        return issue[\"number\"], issue[\"html_url\"]\n\n        yield \"url\", url\n\n", "blocks": [{"id": 1, "label": "class GithubMakeIssueBlock(Block):", "successors": [{"id": 2, "label": "@staticmethod\nreturn issue[\"number\"], issue[\"html_url\"]", "successors": []}, {"id": 4, "label": "yield \"url\", url", "successors": []}]}]}, {"name": "GithubReadIssueBlock", "type": "class", "start_line": 186, "end_line": 258, "functions": [{"name": "__init__", "type": "function", "start_line": 202, "end_line": 226, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"6443c75d-032a-4772-9c08-230c707c8acc\",\n            description=\"This block reads the body, title, and user of a specified GitHub issue.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubReadIssueBlock.Input,\n            output_schema=GithubReadIssueBlock.Output,\n            test_input={\n                \"issue_url\": \"https://github.com/owner/repo/issues/1\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\"title\", \"Title of the issue\"),\n                (\"body\", \"This is the body of the issue.\"),\n                (\"user\", \"username\"),\n            ],\n            test_mock={\n                \"read_issue\": lambda *args, **kwargs: (\n                    \"Title of the issue\",\n                    \"This is the body of the issue.\",\n                    \"username\",\n                )\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\n    super().__init__(\n        id=\"6443c75d-032a-4772-9c08-230c707c8acc\",\n        description=\"This block reads the body, title, and user of a specified GitHub issue.\",\n        categories={BlockCategory.DEVELOPER_TOOLS},\n        input_schema=GithubReadIssueBlock.Input,\n        output_schema=GithubReadIssueBlock.Output,\n        test_input={\n            \"issue_url\": \"https://github.com/owner/repo/issues/1\",\n            \"credentials\": TEST_CREDENTIALS_INPUT,\n        },\n        test_credentials=TEST_CREDENTIALS,\n        test_output=[\n            (\"title\", \"Title of the issue\"),\n            (\"body\", \"This is the body of the issue.\"),\n            (\"user\", \"username\"),\n        ],\n        test_mock={\n            \"read_issue\": lambda *args, **kwargs: (\n                \"Title of the issue\",\n                \"This is the body of the issue.\",\n                \"username\",\n            )\n        },\n    )", "successors": []}]}, {"name": "read_issue", "type": "function", "start_line": 229, "end_line": 238, "functions": [], "classes": [], "simplified_code": "    def read_issue(\n        credentials: GithubCredentials, issue_url: str\n    ) -> tuple[str, str, str]:\n        api = get_api(credentials)\n        response = api.get(issue_url)\n        data = response.json()\n        title = data.get(\"title\", \"No title found\")\n        body = data.get(\"body\", \"No body content found\")\n        user = data.get(\"user\", {}).get(\"login\", \"No user found\")\n        return title, body, user", "blocks": [{"id": 1, "label": "def read_issue(credentials: GithubCredentials, issue_url: str) -> tuple[str, str, str]:\napi = get_api(credentials)\nresponse = api.get(issue_url)\ndata = response.json()\ntitle = data.get(\"title\", \"No title found\")\nbody = data.get(\"body\", \"No body content found\")\nuser = data.get(\"user\", {}).get(\"login\", \"No user found\")", "successors": [{"id": 3, "label": "return title, body, user", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 240, "end_line": 256, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        title, body, user = self.read_issue(\n            credentials,\n            input_data.issue_url,\n        )\n        if title:\n            yield \"title\", title\n        if body:\n            yield \"body\", body\n        if user:\n            yield \"user\", user", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: GithubCredentials, **kwargs) -> BlockOutput:\ntitle, body, user = self.read_issue(credentials, input_data.issue_url)", "successors": [{"id": 3, "label": "if title:", "successors": [{"id": 4, "label": "    yield \"title\", title\nif body:", "successors": [{"id": 8, "label": "    yield \"body\", body\nif user:", "successors": [{"id": 12, "label": "    yield \"user\", user", "successors": []}]}, {"id": 11, "label": "if user:\n    yield \"user\", user", "successors": []}]}, {"id": 7, "label": "if body:", "successors": [{"id": 8, "label": "    yield \"body\", body\nif user:", "successors": [{"id": 12, "label": "    yield \"user\", user", "successors": []}]}, {"id": 11, "label": "if user:\n    yield \"user\", user", "successors": []}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 187, "end_line": 192, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        issue_url: str = SchemaField(\n            description=\"URL of the GitHub issue\",\n            placeholder=\"https://github.com/owner/repo/issues/1\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")", "successors": [{"id": 3, "label": "    issue_url: str = SchemaField(description=\"URL of the GitHub issue\", placeholder=\"https://github.com/owner/repo/issues/1\",)", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 194, "end_line": 200, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        title: str = SchemaField(description=\"Title of the issue\")\n        body: str = SchemaField(description=\"Body of the issue\")\n        user: str = SchemaField(description=\"User who created the issue\")\n        error: str = SchemaField(\n            description=\"Error message if reading the issue failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    title: str = SchemaField(description=\"Title of the issue\")", "successors": [{"id": 3, "label": "    body: str = SchemaField(description=\"Body of the issue\")\n    user: str = SchemaField(description=\"User who created the issue\")", "successors": [{"id": 5, "label": "    error: str = SchemaField(description=\"Error message if reading the issue failed\")", "successors": []}]}]}]}], "simplified_code": "class GithubReadIssueBlock(Block):\n        )\n\n        )\n\n        )\n\n    @staticmethod\n        return title, body, user\n\n            yield \"user\", user\n\n", "blocks": [{"id": 1, "label": "class GithubReadIssueBlock(Block):\n    pass", "successors": []}]}, {"name": "GithubListIssuesBlock", "type": "class", "start_line": 259, "end_line": 334, "functions": [{"name": "__init__", "type": "function", "start_line": 277, "end_line": 306, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"c215bfd7-0e57-4573-8f8c-f7d4963dcd74\",\n            description=\"This block lists all issues for a specified GitHub repository.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubListIssuesBlock.Input,\n            output_schema=GithubListIssuesBlock.Output,\n            test_input={\n                \"repo_url\": \"https://github.com/owner/repo\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\n                    \"issue\",\n                    {\n                        \"title\": \"Issue 1\",\n                        \"url\": \"https://github.com/owner/repo/issues/1\",\n                    },\n                )\n            ],\n            test_mock={\n                \"list_issues\": lambda *args, **kwargs: [\n                    {\n                        \"title\": \"Issue 1\",\n                        \"url\": \"https://github.com/owner/repo/issues/1\",\n                    }\n                ]\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n id=\"c215bfd7-0e57-4573-8f8c-f7d4963dcd74\",\n description=\"This block lists all issues for a specified GitHub repository.\",\n categories={BlockCategory.DEVELOPER_TOOLS},\n input_schema=GithubListIssuesBlock.Input,\n output_schema=GithubListIssuesBlock.Output,\n test_input={\n \"repo_url\": \"https://github.com/owner/repo\",\n \"credentials\": TEST_CREDENTIALS_INPUT,\n },\n test_credentials=TEST_CREDENTIALS,\n test_output=[\n (\n \"issue\",\n {\n \"title\": \"Issue 1\",\n \"url\": \"https://github.com/owner/repo/issues/1\",\n },\n )\n ],\n test_mock={\n \"list_issues\": lambda *args, **kwargs: [\n {\n \"title\": \"Issue 1\",\n \"url\": \"https://github.com/owner/repo/issues/1\",\n }\n ]\n },\n )", "successors": []}]}, {"name": "list_issues", "type": "function", "start_line": 309, "end_line": 319, "functions": [], "classes": [], "simplified_code": "    def list_issues(\n        credentials: GithubCredentials, repo_url: str\n    ) -> list[Output.IssueItem]:\n        api = get_api(credentials)\n        issues_url = repo_url + \"/issues\"\n        response = api.get(issues_url)\n        data = response.json()\n        issues: list[GithubListIssuesBlock.Output.IssueItem] = [\n            {\"title\": issue[\"title\"], \"url\": issue[\"html_url\"]} for issue in data\n        ]\n        return issues", "blocks": [{"id": 1, "label": "def list_issues(\n    credentials: GithubCredentials, repo_url: str\n) -> list[Output.IssueItem]:\napi = get_api(credentials)", "successors": [{"id": 3, "label": "issues_url = repo_url + \"/issues\"\nresponse = api.get(issues_url)", "successors": [{"id": 5, "label": "data = response.json()\nissues: list[GithubListIssuesBlock.Output.IssueItem] = [\n    {\"title\": issue[\"title\"], \"url\": issue[\"html_url\"]} for issue in data\n]", "successors": [{"id": 7, "label": "return issues", "successors": []}]}]}]}]}, {"name": "run", "type": "function", "start_line": 321, "end_line": 332, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        issues = self.list_issues(\n            credentials,\n            input_data.repo_url,\n        )\n        yield from ((\"issue\", issue) for issue in issues)", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: GithubCredentials, **kwargs) -> BlockOutput:\nissues = self.list_issues(credentials, input_data.repo_url)", "successors": [{"id": 3, "label": "yield from ((\"issue\", issue) for issue in issues)", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 260, "end_line": 265, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        repo_url: str = SchemaField(\n            description=\"URL of the GitHub repository\",\n            placeholder=\"https://github.com/owner/repo\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")", "successors": [{"id": 3, "label": "    repo_url: str = SchemaField(\n        description=\"URL of the GitHub repository\",\n        placeholder=\"https://github.com/owner/repo\",\n    )", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 267, "end_line": 275, "functions": [], "classes": [{"name": "IssueItem", "type": "class", "start_line": 268, "end_line": 270, "functions": [], "classes": [], "simplified_code": "        class IssueItem(TypedDict):\n            title: str\n            url: str", "blocks": [{"id": 1, "label": "class IssueItem(TypedDict):\n    title: str\n    url: str", "successors": []}]}], "simplified_code": "    class Output(BlockSchema):\n            url: str\n\n        issue: IssueItem = SchemaField(\n            title=\"Issue\", description=\"Issues with their title and URL\"\n        )\n        error: str = SchemaField(description=\"Error message if listing issues failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    url: str", "successors": []}]}], "simplified_code": "class GithubListIssuesBlock(Block):\n        )\n\n        error: str = SchemaField(description=\"Error message if listing issues failed\")\n\n        )\n\n    @staticmethod\n        return issues\n\n        yield from ((\"issue\", issue) for issue in issues)\n\n", "blocks": [{"id": 1, "label": "class GithubListIssuesBlock(Block):", "successors": [{"id": 2, "label": "error: str = SchemaField(description=\"Error message if listing issues failed\")", "successors": []}, {"id": 3, "label": "@staticmethod", "successors": []}, {"id": 4, "label": "return issues", "successors": []}, {"id": 5, "label": "yield from ((\"issue\", issue) for issue in issues)", "successors": []}]}]}, {"name": "GithubAddLabelBlock", "type": "class", "start_line": 335, "end_line": 392, "functions": [{"name": "__init__", "type": "function", "start_line": 353, "end_line": 368, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"98bd6b77-9506-43d5-b669-6b9733c4b1f1\",\n            description=\"This block adds a label to a specified GitHub issue or pull request.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubAddLabelBlock.Input,\n            output_schema=GithubAddLabelBlock.Output,\n            test_input={\n                \"issue_url\": \"https://github.com/owner/repo/issues/1\",\n                \"label\": \"bug\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[(\"status\", \"Label added successfully\")],\n            test_mock={\"add_label\": lambda *args, **kwargs: \"Label added successfully\"},\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"98bd6b77-9506-43d5-b669-6b9733c4b1f1\",\n    description=\"This block adds a label to a specified GitHub issue or pull request.\",\n    categories={BlockCategory.DEVELOPER_TOOLS},\n    input_schema=GithubAddLabelBlock.Input,\n    output_schema=GithubAddLabelBlock.Output,\n    test_input={\n        \"issue_url\": \"https://github.com/owner/repo/issues/1\",\n        \"label\": \"bug\",\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[(\"status\", \"Label added successfully\")],\n    test_mock={\"add_label\": lambda *args, **kwargs: \"Label added successfully\"},\n)", "successors": []}]}, {"name": "add_label", "type": "function", "start_line": 371, "end_line": 376, "functions": [], "classes": [], "simplified_code": "    def add_label(credentials: GithubCredentials, issue_url: str, label: str) -> str:\n        api = get_api(credentials)\n        data = {\"labels\": [label]}\n        labels_url = issue_url + \"/labels\"\n        api.post(labels_url, json=data)\n        return \"Label added successfully\"", "blocks": [{"id": 1, "label": "def add_label(credentials: GithubCredentials, issue_url: str, label: str) -> str:\n    api = get_api(credentials)\n    data = {\"labels\": [label]}\n    labels_url = issue_url + \"/labels\"\n    api.post(labels_url, json=data)\n    return \"Label added successfully\"", "successors": []}]}, {"name": "run", "type": "function", "start_line": 378, "end_line": 390, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        status = self.add_label(\n            credentials,\n            input_data.issue_url,\n            input_data.label,\n        )\n        yield \"status\", status", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: GithubCredentials, **kwargs) -> BlockOutput:\nstatus = self.add_label(credentials, input_data.issue_url, input_data.label)", "successors": [{"id": 3, "label": "yield \"status\", status", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 336, "end_line": 345, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        issue_url: str = SchemaField(\n            description=\"URL of the GitHub issue or pull request\",\n            placeholder=\"https://github.com/owner/repo/issues/1\",\n        )\n        label: str = SchemaField(\n            description=\"Label to add to the issue or pull request\",\n            placeholder=\"Enter the label\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\ncredentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")", "successors": [{"id": 3, "label": "issue_url: str = SchemaField(description=\"URL of the GitHub issue or pull request\", placeholder=\"https://github.com/owner/repo/issues/1\")\nlabel: str = SchemaField(description=\"Label to add to the issue or pull request\", placeholder=\"Enter the label\")", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 347, "end_line": 351, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        status: str = SchemaField(description=\"Status of the label addition operation\")\n        error: str = SchemaField(\n            description=\"Error message if the label addition failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\nstatus: str = SchemaField(description=\"Status of the label addition operation\")", "successors": [{"id": 3, "label": "error: str = SchemaField(description=\"Error message if the label addition failed\")", "successors": []}]}]}], "simplified_code": "class GithubAddLabelBlock(Block):\n        )\n\n        )\n\n        )\n\n    @staticmethod\n        return \"Label added successfully\"\n\n        yield \"status\", status\n\n", "blocks": [{"id": 1, "label": "class GithubAddLabelBlock(Block):\n@staticmethod", "successors": [{"id": 3, "label": "return \"Label added successfully\"", "successors": []}]}]}, {"name": "GithubRemoveLabelBlock", "type": "class", "start_line": 393, "end_line": 451, "functions": [{"name": "__init__", "type": "function", "start_line": 411, "end_line": 428, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"78f050c5-3e3a-48c0-9e5b-ef1ceca5589c\",\n            description=\"This block removes a label from a specified GitHub issue or pull request.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubRemoveLabelBlock.Input,\n            output_schema=GithubRemoveLabelBlock.Output,\n            test_input={\n                \"issue_url\": \"https://github.com/owner/repo/issues/1\",\n                \"label\": \"bug\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[(\"status\", \"Label removed successfully\")],\n            test_mock={\n                \"remove_label\": lambda *args, **kwargs: \"Label removed successfully\"\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"78f050c5-3e3a-48c0-9e5b-ef1ceca5589c\",\n    description=\"This block removes a label from a specified GitHub issue or pull request.\",\n    categories={BlockCategory.DEVELOPER_TOOLS},\n    input_schema=GithubRemoveLabelBlock.Input,\n    output_schema=GithubRemoveLabelBlock.Output,\n    test_input={\n        \"issue_url\": \"https://github.com/owner/repo/issues/1\",\n        \"label\": \"bug\",\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[(\"status\", \"Label removed successfully\")],\n    test_mock={\n        \"remove_label\": lambda *args, **kwargs: \"Label removed successfully\"\n    },\n)", "successors": []}]}, {"name": "remove_label", "type": "function", "start_line": 431, "end_line": 435, "functions": [], "classes": [], "simplified_code": "    def remove_label(credentials: GithubCredentials, issue_url: str, label: str) -> str:\n        api = get_api(credentials)\n        label_url = issue_url + f\"/labels/{label}\"\n        api.delete(label_url)\n        return \"Label removed successfully\"", "blocks": [{"id": 1, "label": "def remove_label(credentials: GithubCredentials, issue_url: str, label: str) -> str:\n    api = get_api(credentials)\n    label_url = issue_url + f\"/labels/{label}\"\n    api.delete(label_url)", "successors": [{"id": 3, "label": "    return \"Label removed successfully\"", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 437, "end_line": 449, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        status = self.remove_label(\n            credentials,\n            input_data.issue_url,\n            input_data.label,\n        )\n        yield \"status\", status", "blocks": [{"id": 1, "label": "def run(\n    self,\n    input_data: Input,\n    *,\n    credentials: GithubCredentials,\n    **kwargs\n) -> BlockOutput:\nstatus = self.remove_label(\n    credentials,\n    input_data.issue_url,\n    input_data.label\n)", "successors": [{"id": 3, "label": "yield \"status\", status", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 394, "end_line": 403, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        issue_url: str = SchemaField(\n            description=\"URL of the GitHub issue or pull request\",\n            placeholder=\"https://github.com/owner/repo/issues/1\",\n        )\n        label: str = SchemaField(\n            description=\"Label to remove from the issue or pull request\",\n            placeholder=\"Enter the label\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")", "successors": []}, {"id": 3, "label": "    issue_url: str = SchemaField(description=\"URL of the GitHub issue or pull request\", placeholder=\"https://github.com/owner/repo/issues/1\",)", "successors": []}, {"id": 4, "label": "    label: str = SchemaField(description=\"Label to remove from the issue or pull request\", placeholder=\"Enter the label\",)", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 405, "end_line": 409, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        status: str = SchemaField(description=\"Status of the label removal operation\")\n        error: str = SchemaField(\n            description=\"Error message if the label removal failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    status: str = SchemaField(description=\"Status of the label removal operation\")", "successors": [{"id": 3, "label": "    error: str = SchemaField(description=\"Error message if the label removal failed\")", "successors": []}]}]}], "simplified_code": "class GithubRemoveLabelBlock(Block):\n        )\n\n        )\n\n        )\n\n    @staticmethod\n        return \"Label removed successfully\"\n\n        yield \"status\", status\n\n", "blocks": [{"id": 1, "label": "class GithubRemoveLabelBlock(Block):", "successors": []}]}, {"name": "GithubAssignIssueBlock", "type": "class", "start_line": 452, "end_line": 517, "functions": [{"name": "__init__", "type": "function", "start_line": 472, "end_line": 489, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"90507c72-b0ff-413a-886a-23bbbd66f542\",\n            description=\"This block assigns a user to a specified GitHub issue.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubAssignIssueBlock.Input,\n            output_schema=GithubAssignIssueBlock.Output,\n            test_input={\n                \"issue_url\": \"https://github.com/owner/repo/issues/1\",\n                \"assignee\": \"username1\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[(\"status\", \"Issue assigned successfully\")],\n            test_mock={\n                \"assign_issue\": lambda *args, **kwargs: \"Issue assigned successfully\"\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\n    super().__init__(\n        id=\"90507c72-b0ff-413a-886a-23bbbd66f542\",\n        description=\"This block assigns a user to a specified GitHub issue.\",\n        categories={BlockCategory.DEVELOPER_TOOLS},\n        input_schema=GithubAssignIssueBlock.Input,\n        output_schema=GithubAssignIssueBlock.Output,\n        test_input={\n            \"issue_url\": \"https://github.com/owner/repo/issues/1\",\n            \"assignee\": \"username1\",\n            \"credentials\": TEST_CREDENTIALS_INPUT,\n        },\n        test_credentials=TEST_CREDENTIALS,\n        test_output=[(\"status\", \"Issue assigned successfully\")],\n        test_mock={\n            \"assign_issue\": lambda *args, **kwargs: \"Issue assigned successfully\"\n        },\n    )", "successors": []}]}, {"name": "assign_issue", "type": "function", "start_line": 492, "end_line": 501, "functions": [], "classes": [], "simplified_code": "    def assign_issue(\n        credentials: GithubCredentials,\n        issue_url: str,\n        assignee: str,\n    ) -> str:\n        api = get_api(credentials)\n        assignees_url = issue_url + \"/assignees\"\n        data = {\"assignees\": [assignee]}\n        api.post(assignees_url, json=data)\n        return \"Issue assigned successfully\"", "blocks": [{"id": 1, "label": "def assign_issue(\n    credentials: GithubCredentials,\n    issue_url: str,\n    assignee: str,\n) -> str:\n    api = get_api(credentials)\n    assignees_url = issue_url + \"/assignees\"\n    data = {\"assignees\": [assignee]}\n    api.post(assignees_url, json=data)", "successors": [{"id": 3, "label": "return \"Issue assigned successfully\"", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 503, "end_line": 515, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        status = self.assign_issue(\n            credentials,\n            input_data.issue_url,\n            input_data.assignee,\n        )\n        yield \"status\", status", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: GithubCredentials, **kwargs) -> BlockOutput:\nstatus = self.assign_issue(credentials, input_data.issue_url, input_data.assignee)", "successors": [{"id": 3, "label": "yield \"status\", status", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 453, "end_line": 462, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        issue_url: str = SchemaField(\n            description=\"URL of the GitHub issue\",\n            placeholder=\"https://github.com/owner/repo/issues/1\",\n        )\n        assignee: str = SchemaField(\n            description=\"Username to assign to the issue\",\n            placeholder=\"Enter the username\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")", "successors": []}, {"id": 3, "label": "issue_url: str = SchemaField(\n    description=\"URL of the GitHub issue\",\n    placeholder=\"https://github.com/owner/repo/issues/1\",\n)", "successors": []}, {"id": 4, "label": "assignee: str = SchemaField(\n    description=\"Username to assign to the issue\",\n    placeholder=\"Enter the username\",\n)", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 464, "end_line": 470, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        status: str = SchemaField(\n            description=\"Status of the issue assignment operation\"\n        )\n        error: str = SchemaField(\n            description=\"Error message if the issue assignment failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "    status: str = SchemaField(\n        description=\"Status of the issue assignment operation\"\n    )", "successors": []}, {"id": 3, "label": "    error: str = SchemaField(\n        description=\"Error message if the issue assignment failed\"\n    )", "successors": []}]}]}], "simplified_code": "class GithubAssignIssueBlock(Block):\n        )\n\n        )\n\n        )\n\n    @staticmethod\n        return \"Issue assigned successfully\"\n\n        yield \"status\", status\n\n", "blocks": [{"id": 1, "label": "class GithubAssignIssueBlock(Block):\n@staticmethod", "successors": [{"id": 3, "label": "return \"Issue assigned successfully\"\nyield \"status\", status", "successors": []}]}]}, {"name": "GithubUnassignIssueBlock", "type": "class", "start_line": 518, "end_line": 581, "functions": [{"name": "__init__", "type": "function", "start_line": 538, "end_line": 555, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"d154002a-38f4-46c2-962d-2488f2b05ece\",\n            description=\"This block unassigns a user from a specified GitHub issue.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubUnassignIssueBlock.Input,\n            output_schema=GithubUnassignIssueBlock.Output,\n            test_input={\n                \"issue_url\": \"https://github.com/owner/repo/issues/1\",\n                \"assignee\": \"username1\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[(\"status\", \"Issue unassigned successfully\")],\n            test_mock={\n                \"unassign_issue\": lambda *args, **kwargs: \"Issue unassigned successfully\"\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\n    super().__init__(\n        id=\"d154002a-38f4-46c2-962d-2488f2b05ece\",\n        description=\"This block unassigns a user from a specified GitHub issue.\",\n        categories={BlockCategory.DEVELOPER_TOOLS},\n        input_schema=GithubUnassignIssueBlock.Input,\n        output_schema=GithubUnassignIssueBlock.Output,\n        test_input={\n            \"issue_url\": \"https://github.com/owner/repo/issues/1\",\n            \"assignee\": \"username1\",\n            \"credentials\": TEST_CREDENTIALS_INPUT,\n        },\n        test_credentials=TEST_CREDENTIALS,\n        test_output=[(\"status\", \"Issue unassigned successfully\")],\n        test_mock={\n            \"unassign_issue\": lambda *args, **kwargs: \"Issue unassigned successfully\"\n        },\n    )", "successors": []}]}, {"name": "unassign_issue", "type": "function", "start_line": 558, "end_line": 567, "functions": [], "classes": [], "simplified_code": "    def unassign_issue(\n        credentials: GithubCredentials,\n        issue_url: str,\n        assignee: str,\n    ) -> str:\n        api = get_api(credentials)\n        assignees_url = issue_url + \"/assignees\"\n        data = {\"assignees\": [assignee]}\n        api.delete(assignees_url, json=data)\n        return \"Issue unassigned successfully\"", "blocks": [{"id": 1, "label": "def unassign_issue(\n    credentials: GithubCredentials,\n    issue_url: str,\n    assignee: str,\n) -> str:\napi = get_api(credentials)\nassignees_url = issue_url + \"/assignees\"\ndata = {\"assignees\": [assignee]}\napi.delete(assignees_url, json=data)", "successors": [{"id": 3, "label": "return \"Issue unassigned successfully\"", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 569, "end_line": 581, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        status = self.unassign_issue(\n            credentials,\n            input_data.issue_url,\n            input_data.assignee,\n        )\n        yield \"status\", status", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: GithubCredentials, **kwargs) -> BlockOutput:\nstatus = self.unassign_issue(credentials, input_data.issue_url, input_data.assignee)", "successors": [{"id": 3, "label": "yield \"status\", status", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 519, "end_line": 528, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        issue_url: str = SchemaField(\n            description=\"URL of the GitHub issue\",\n            placeholder=\"https://github.com/owner/repo/issues/1\",\n        )\n        assignee: str = SchemaField(\n            description=\"Username to unassign from the issue\",\n            placeholder=\"Enter the username\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")", "successors": [{"id": 3, "label": "    issue_url: str = SchemaField(\n        description=\"URL of the GitHub issue\",\n        placeholder=\"https://github.com/owner/repo/issues/1\",\n    )\n    assignee: str = SchemaField(\n        description=\"Username to unassign from the issue\",\n        placeholder=\"Enter the username\",\n    )", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 530, "end_line": 536, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        status: str = SchemaField(\n            description=\"Status of the issue unassignment operation\"\n        )\n        error: str = SchemaField(\n            description=\"Error message if the issue unassignment failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    status: str = SchemaField(\n        description=\"Status of the issue unassignment operation\"\n    )", "successors": [{"id": 3, "label": "    error: str = SchemaField(\n        description=\"Error message if the issue unassignment failed\"\n    )", "successors": []}]}]}], "simplified_code": "class GithubUnassignIssueBlock(Block):\n        )\n\n        )\n\n        )\n\n    @staticmethod\n        return \"Issue unassigned successfully\"\n\n        yield \"status\", status", "blocks": [{"id": 1, "label": "class GithubUnassignIssueBlock(Block):\n@staticmethod", "successors": [{"id": 3, "label": "return \"Issue unassigned successfully\"", "successors": []}]}]}], "simplified_code": "from urllib.parse import urlparse\n\nfrom typing_extensions import TypedDict\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\nfrom ._api import get_api\nfrom ._auth import (\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    GithubCredentials,\n    GithubCredentialsField,\n    GithubCredentialsInput,\n)\n\n\n    return urlparse(url).netloc == \"github.com\"\n\n\n# --8<-- [start:GithubCommentBlockExample]\n# --8<-- [end:GithubCommentBlockExample]\n\n\n\n\n\n\n\n\n        yield \"status\", status", "blocks": [{"id": 1, "label": "from urllib.parse import urlparse\n\nfrom typing_extensions import TypedDict\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\nfrom ._api import get_api\nfrom ._auth import (\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    GithubCredentials,\n    GithubCredentialsField,\n    GithubCredentialsInput,\n)\n\n\n    return urlparse(url).netloc == \"github.com\"\n\n# --8<-- [start:GithubCommentBlockExample]\n# --8<-- [end:GithubCommentBlockExample]\n\n        yield \"status\", status", "successors": []}]}
{"file_name": "23.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 79, "functions": [{"name": "test_validate_url", "type": "function", "start_line": 6, "end_line": 79, "functions": [], "classes": [], "simplified_code": "def test_validate_url():\n    # Rejected IP ranges\n    with pytest.raises(ValueError):\n        validate_url(\"localhost\", [])\n\n    with pytest.raises(ValueError):\n        validate_url(\"192.168.1.1\", [])\n\n    with pytest.raises(ValueError):\n        validate_url(\"127.0.0.1\", [])\n\n    with pytest.raises(ValueError):\n        validate_url(\"0.0.0.0\", [])\n\n    # Normal URLs\n    assert validate_url(\"google.com/a?b=c\", []) == \"http://google.com/a?b=c\"\n    assert validate_url(\"github.com?key=!@!@\", []) == \"http://github.com?key=!@!@\"\n\n    # Scheme Enforcement\n    with pytest.raises(ValueError):\n        validate_url(\"ftp://example.com\", [])\n    with pytest.raises(ValueError):\n        validate_url(\"file://example.com\", [])\n\n    # International domain that converts to punycode - should be allowed if public\n    assert validate_url(\"http://xn--exmple-cua.com\", []) == \"http://xn--exmple-cua.com\"\n    # If the domain fails IDNA encoding or is invalid, it should raise an error\n    with pytest.raises(ValueError):\n        validate_url(\"http://exa\u25ccmple.com\", [])\n\n    # IPv6 Addresses\n    with pytest.raises(ValueError):\n        validate_url(\"::1\", [])  # IPv6 loopback should be blocked\n    with pytest.raises(ValueError):\n        validate_url(\"http://[::1]\", [])  # IPv6 loopback in URL form\n\n    # Suspicious Characters in Hostname\n    with pytest.raises(ValueError):\n        validate_url(\"http://example_underscore.com\", [])\n    with pytest.raises(ValueError):\n        validate_url(\"http://exa mple.com\", [])  # Space in hostname\n\n    # Malformed URLs\n    with pytest.raises(ValueError):\n        validate_url(\"http://\", [])  # No hostname\n    with pytest.raises(ValueError):\n        validate_url(\"://missing-scheme\", [])  # Missing proper scheme\n\n    # Trusted Origins\n    trusted = [\"internal-api.company.com\", \"10.0.0.5\"]\n    assert (\n        validate_url(\"internal-api.company.com\", trusted)\n        == \"http://internal-api.company.com\"\n    )\n    assert validate_url(\"10.0.0.5\", [\"10.0.0.5\"]) == \"http://10.0.0.5\"\n\n    # Special Characters in Path or Query\n    assert (\n        validate_url(\"example.com/path%20with%20spaces\", [])\n        == \"http://example.com/path%20with%20spaces\"\n    )\n\n    # Backslashes should be replaced with forward slashes\n    assert (\n        validate_url(\"http://example.com\\\\backslash\", [])\n        == \"http://example.com/backslash\"\n    )\n\n    # Check defaulting scheme behavior for valid domains\n    assert validate_url(\"example.com\", []) == \"http://example.com\"\n    assert validate_url(\"https://secure.com\", []) == \"https://secure.com\"\n\n    # Non-ASCII Characters in Query/Fragment\n    assert validate_url(\"example.com?param=\u00e4\u00f6\u00fc\", []) == \"http://example.com?param=\u00e4\u00f6\u00fc\"", "blocks": [{"id": 1, "label": "def test_validate_url():\nwith pytest.raises(ValueError):\n    validate_url(\"localhost\", [])", "successors": [{"id": 3, "label": "with pytest.raises(ValueError):\n    validate_url(\"192.168.1.1\", [])\nwith pytest.raises(ValueError):\n    validate_url(\"127.0.0.1\", [])", "successors": [{"id": 5, "label": "with pytest.raises(ValueError):\n    validate_url(\"0.0.0.0\", [])\nassert validate_url(\"google.com/a?b=c\", []) == \"http://google.com/a?b=c\"\nassert validate_url(\"github.com?key=!@!@\", []) == \"http://github.com?key=!@!@\"", "successors": [{"id": 7, "label": "with pytest.raises(ValueError):\n    validate_url(\"ftp://example.com\", [])\nwith pytest.raises(ValueError):\n    validate_url(\"file://example.com\", [])", "successors": [{"id": 9, "label": "assert validate_url(\"http://xn--exmple-cua.com\", []) == \"http://xn--exmple-cua.com\"\nwith pytest.raises(ValueError):\n    validate_url(\"http://exa\u25ccmple.com\", [])", "successors": [{"id": 11, "label": "with pytest.raises(ValueError):\n    validate_url(\"::1\", [])\nwith pytest.raises(ValueError):\n    validate_url(\"http://[::1]\", [])", "successors": [{"id": 13, "label": "with pytest.raises(ValueError):\n    validate_url(\"http://example_underscore.com\", [])\nwith pytest.raises(ValueError):\n    validate_url(\"http://exa mple.com\", [])", "successors": [{"id": 15, "label": "with pytest.raises(ValueError):\n    validate_url(\"http://\", [])\nwith pytest.raises(ValueError):\n    validate_url(\"://missing-scheme\", [])", "successors": [{"id": 17, "label": "trusted = [\"internal-api.company.com\", \"10.0.0.5\"]\nassert (validate_url(\"internal-api.company.com\", trusted) == \"http://internal-api.company.com\")\nassert validate_url(\"10.0.0.5\", [\"10.0.0.5\"]) == \"http://10.0.0.5\"\nassert (validate_url(\"example.com/path%20with%20spaces\", []) == \"http://example.com/path%20with%20spaces\")", "successors": [{"id": 19, "label": "assert (validate_url(\"http://example.com\\\\backslash\", []) == \"http://example.com/backslash\")\nassert validate_url(\"example.com\", []) == \"http://example.com\"\nassert validate_url(\"https://secure.com\", []) == \"https://secure.com\"", "successors": [{"id": 21, "label": "assert validate_url(\"example.com?param=\u00e4\u00f6\u00fc\", []) == \"http://example.com?param=\u00e4\u00f6\u00fc\"", "successors": []}]}]}]}]}]}]}]}]}]}]}]}], "classes": [], "simplified_code": "import pytest\n\nfrom backend.util.request import validate_url\n\n\n    assert validate_url(\"example.com?param=\u00e4\u00f6\u00fc\", []) == \"http://example.com?param=\u00e4\u00f6\u00fc\"", "blocks": [{"id": 1, "label": "import pytest\nfrom backend.util.request import validate_url", "successors": [{"id": 3, "label": "assert validate_url(\"example.com?param=\u00e4\u00f6\u00fc\", []) == \"http://example.com?param=\u00e4\u00f6\u00fc\"", "successors": []}]}]}
{"file_name": "24.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 61, "functions": [], "classes": [{"name": "Slant3DSlicerBlock", "type": "class", "start_line": 13, "end_line": 61, "functions": [{"name": "__init__", "type": "function", "start_line": 27, "end_line": 45, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"f8a12c8d-3e4b-4d5f-b6a7-8c9d0e1f2g3h\",\n            description=\"Slice a 3D model file and get pricing information\",\n            input_schema=self.Input,\n            output_schema=self.Output,\n            test_input={\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n                \"file_url\": \"https://example.com/model.stl\",\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[(\"message\", \"Slicing successful\"), (\"price\", 8.23)],\n            test_mock={\n                \"_make_request\": lambda *args, **kwargs: {\n                    \"message\": \"Slicing successful\",\n                    \"data\": {\"price\": 8.23},\n                }\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"f8a12c8d-3e4b-4d5f-b6a7-8c9d0e1f2g3h\",\n    description=\"Slice a 3D model file and get pricing information\",\n    input_schema=self.Input,\n    output_schema=self.Output,\n    test_input={\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n        \"file_url\": \"https://example.com/model.stl\",\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[(\"message\", \"Slicing successful\"), (\"price\", 8.23)],\n    test_mock={\n       \"_make_request\": lambda *args, **kwargs: {\n            \"message\": \"Slicing successful\",\n            \"data\": {\"price\": 8.23},\n       }\n   },\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 47, "end_line": 61, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        try:\n            result = self._make_request(\n                \"POST\",\n                \"slicer\",\n                credentials.api_key.get_secret_value(),\n                json={\"fileURL\": input_data.file_url},\n            )\n            yield \"message\", result[\"message\"]\n            yield \"price\", result[\"data\"][\"price\"]\n        except Exception as e:\n            yield \"error\", str(e)\n            raise", "blocks": [{"id": 1, "label": "def run( self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs ) -> BlockOutput:\ntry:", "successors": [{"id": 3, "label": "result = self._make_request( \"POST\", \"slicer\", credentials.api_key.get_secret_value(), json={\"fileURL\": input_data.file_url}, )\nyield \"message\", result[\"message\"]", "successors": [{"id": 5, "label": "yield \"price\", result[\"data\"][\"price\"]", "successors": []}]}, {"id": 6, "label": "except Exception as e:\nyield \"error\", str(e)", "successors": [{"id": 8, "label": "raise", "successors": []}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 16, "end_line": 20, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: Slant3DCredentialsInput = Slant3DCredentialsField()\n        file_url: str = SchemaField(\n            description=\"URL of the 3D model file to slice (STL)\"\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: Slant3DCredentialsInput = Slant3DCredentialsField()", "successors": [{"id": 3, "label": "    file_url: str = SchemaField(\n        description=\"URL of the 3D model file to slice (STL)\"\n    )", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 22, "end_line": 25, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        message: str = SchemaField(description=\"Response message\")\n        price: float = SchemaField(description=\"Calculated price for printing\")\n        error: str = SchemaField(description=\"Error message if slicing failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "    message: str = SchemaField(description=\"Response message\")", "successors": []}, {"id": 3, "label": "    price: float = SchemaField(description=\"Calculated price for printing\")", "successors": []}, {"id": 4, "label": "    error: str = SchemaField(description=\"Error message if slicing failed\")", "successors": []}]}]}], "simplified_code": "class Slant3DSlicerBlock(Slant3DBlockBase):\n    \"\"\"Block for slicing 3D model files\"\"\"\n\n        )\n\n        error: str = SchemaField(description=\"Error message if slicing failed\")\n\n        )\n\n            raise", "blocks": [{"id": 1, "label": "class Slant3DSlicerBlock(Slant3DBlockBase):\n    \"\"\"Block for slicing 3D model files\"\"\"", "successors": [{"id": 3, "label": "    error: str = SchemaField(description=\"Error message if slicing failed\")\n    pass", "successors": []}]}]}], "simplified_code": "from backend.data.block import BlockOutput, BlockSchema\nfrom backend.data.model import APIKeyCredentials, SchemaField\n\nfrom ._api import (\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    Slant3DCredentialsField,\n    Slant3DCredentialsInput,\n)\nfrom .base import Slant3DBlockBase\n\n\n            raise", "blocks": [{"id": 1, "label": "from backend.data.block import BlockOutput, BlockSchema\nfrom backend.data.model import APIKeyCredentials, SchemaField\n\nfrom ._api import (\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    Slant3DCredentialsField,\n    Slant3DCredentialsInput,\n)\nfrom .base import Slant3DBlockBase\nraise", "successors": []}]}
{"file_name": "25.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 227, "functions": [], "classes": [{"name": "MusicGenModelVersion", "type": "class", "start_line": 36, "end_line": 39, "functions": [], "classes": [], "simplified_code": "class MusicGenModelVersion(str, Enum):\n    STEREO_LARGE = \"stereo-large\"\n    MELODY_LARGE = \"melody-large\"\n    LARGE = \"large\"", "blocks": [{"id": 1, "label": "class MusicGenModelVersion(str, Enum):\nSTEREO_LARGE = \"stereo-large\"\nMELODY_LARGE = \"melody-large\"\nLARGE = \"large\"", "successors": []}]}, {"name": "AudioFormat", "type": "class", "start_line": 43, "end_line": 45, "functions": [], "classes": [], "simplified_code": "class AudioFormat(str, Enum):\n    WAV = \"wav\"\n    MP3 = \"mp3\"", "blocks": [{"id": 1, "label": "class AudioFormat(str, Enum):", "successors": [{"id": 2, "label": "    WAV = \"wav\"", "successors": []}, {"id": 3, "label": "    MP3 = \"mp3\"", "successors": []}]}]}, {"name": "NormalizationStrategy", "type": "class", "start_line": 49, "end_line": 53, "functions": [], "classes": [], "simplified_code": "class NormalizationStrategy(str, Enum):\n    LOUDNESS = \"loudness\"\n    CLIP = \"clip\"\n    PEAK = \"peak\"\n    RMS = \"rms\"", "blocks": [{"id": 1, "label": "class NormalizationStrategy(str, Enum):\n    LOUDNESS = \"loudness\"\n    CLIP = \"clip\"\n    PEAK = \"peak\"\n    RMS = \"rms\"", "successors": []}]}, {"name": "AIMusicGeneratorBlock", "type": "class", "start_line": 56, "end_line": 227, "functions": [{"name": "__init__", "type": "function", "start_line": 114, "end_line": 143, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"44f6c8ad-d75c-4ae1-8209-aad1c0326928\",\n            description=\"This block generates music using Meta's MusicGen model on Replicate.\",\n            categories={BlockCategory.AI},\n            input_schema=AIMusicGeneratorBlock.Input,\n            output_schema=AIMusicGeneratorBlock.Output,\n            test_input={\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n                \"prompt\": \"An upbeat electronic dance track with heavy bass\",\n                \"music_gen_model_version\": MusicGenModelVersion.STEREO_LARGE,\n                \"duration\": 8,\n                \"temperature\": 1.0,\n                \"top_k\": 250,\n                \"top_p\": 0.0,\n                \"classifier_free_guidance\": 3,\n                \"output_format\": AudioFormat.WAV,\n                \"normalization_strategy\": NormalizationStrategy.LOUDNESS,\n            },\n            test_output=[\n                (\n                    \"result\",\n                    \"https://replicate.com/output/generated-audio-url.wav\",\n                ),\n            ],\n            test_mock={\n                \"run_model\": lambda api_key, music_gen_model_version, prompt, duration, temperature, top_k, top_p, classifier_free_guidance, output_format, normalization_strategy: \"https://replicate.com/output/generated-audio-url.wav\",\n            },\n            test_credentials=TEST_CREDENTIALS,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"44f6c8ad-d75c-4ae1-8209-aad1c0326928\",\n    description=\"This block generates music using Meta's MusicGen model on Replicate.\",\n    categories={BlockCategory.AI},\n    input_schema=AIMusicGeneratorBlock.Input,\n    output_schema=AIMusicGeneratorBlock.Output,\n    test_input={\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n        \"prompt\": \"An upbeat electronic dance track with heavy bass\",\n        \"music_gen_model_version\": MusicGenModelVersion.STEREO_LARGE,\n        \"duration\": 8,\n        \"temperature\": 1.0,\n        \"top_k\": 250,\n        \"top_p\": 0.0,\n        \"classifier_free_guidance\": 3,\n        \"output_format\": AudioFormat.WAV,\n        \"normalization_strategy\": NormalizationStrategy.LOUDNESS,\n    },\n    test_output=[\n        (\n            \"result\",\n            \"https://replicate.com/output/generated-audio-url.wav\",\n        ),\n    ],\n    test_mock={\n        \"run_model\": lambda api_key, music_gen_model_version, prompt, duration, temperature, top_k, top_p, classifier_free_guidance, output_format, normalization_strategy: \"https://replicate.com/output/generated-audio-url.wav\",\n    },\n    test_credentials=TEST_CREDENTIALS,\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 145, "end_line": 183, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        max_retries = 3\n        retry_delay = 5  # seconds\n        last_error = None\n\n        for attempt in range(max_retries):\n            try:\n                logger.debug(\n                    f\"[AIMusicGeneratorBlock] - Running model (attempt {attempt + 1})\"\n                )\n                result = self.run_model(\n                    api_key=credentials.api_key,\n                    music_gen_model_version=input_data.music_gen_model_version,\n                    prompt=input_data.prompt,\n                    duration=input_data.duration,\n                    temperature=input_data.temperature,\n                    top_k=input_data.top_k,\n                    top_p=input_data.top_p,\n                    classifier_free_guidance=input_data.classifier_free_guidance,\n                    output_format=input_data.output_format,\n                    normalization_strategy=input_data.normalization_strategy,\n                )\n                if result and result != \"No output received\":\n                    yield \"result\", result\n                    return\n                else:\n                    last_error = \"Model returned empty or invalid response\"\n                    raise ValueError(last_error)\n            except Exception as e:\n                last_error = f\"Unexpected error: {str(e)}\"\n                logger.error(f\"[AIMusicGeneratorBlock] - Error: {last_error}\")\n                if attempt < max_retries - 1:\n                    time.sleep(retry_delay)\n                    continue\n\n        # If we've exhausted all retries, yield the error\n        yield \"error\", f\"Failed after {max_retries} attempts. Last error: {last_error}\"", "blocks": [{"id": 1, "label": "def run(\n    self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n) -> BlockOutput:\nmax_retries = 3\nretry_delay = 5  # seconds\nlast_error = None", "successors": [{"id": 3, "label": "for attempt in range(max_retries):", "successors": [{"id": 4, "label": "try:", "successors": [{"id": 5, "label": "logger.debug(\n    f\"[AIMusicGeneratorBlock] - Running model (attempt {attempt + 1})\"\n)\nresult = self.run_model(\n    api_key=credentials.api_key,\n    music_gen_model_version=input_data.music_gen_model_version,\n    prompt=input_data.prompt,\n    duration=input_data.duration,\n    temperature=input_data.temperature,\n    top_k=input_data.top_k,\n    top_p=input_data.top_p,\n    classifier_free_guidance=input_data.classifier_free_guidance,\n    output_format=input_data.output_format,\n    normalization_strategy=input_data.normalization_strategy,\n)", "successors": [{"id": 7, "label": "if result and result != \"No output received\":", "successors": [{"id": 8, "label": "yield \"result\", result\nreturn", "successors": []}, {"id": 9, "label": "last_error = \"Model returned empty or invalid response\"\nraise ValueError(last_error)", "successors": []}]}]}, {"id": 10, "label": "except Exception as e:\nlast_error = f\"Unexpected error: {str(e)}\"\nlogger.error(f\"[AIMusicGeneratorBlock] - Error: {last_error}\")", "successors": [{"id": 12, "label": "if attempt < max_retries - 1:\ntime.sleep(retry_delay)\ncontinue", "successors": [{"id": 3, "label": "for attempt in range(max_retries):", "successors": []}]}]}]}]}, {"id": 14, "label": "yield \"error\", f\"Failed after {max_retries} attempts. Last error: {last_error}\"", "successors": []}]}]}, {"name": "run_model", "type": "function", "start_line": 185, "end_line": 227, "functions": [], "classes": [], "simplified_code": "    def run_model(\n        self,\n        api_key: SecretStr,\n        music_gen_model_version: MusicGenModelVersion,\n        prompt: str,\n        duration: int,\n        temperature: float,\n        top_k: int,\n        top_p: float,\n        classifier_free_guidance: int,\n        output_format: AudioFormat,\n        normalization_strategy: NormalizationStrategy,\n    ):\n        # Initialize Replicate client with the API key\n        client = replicate.Client(api_token=api_key.get_secret_value())\n\n        # Run the model with parameters\n        output = client.run(\n            \"meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb\",\n            input={\n                \"prompt\": prompt,\n                \"music_gen_model_version\": music_gen_model_version,\n                \"duration\": duration,\n                \"temperature\": temperature,\n                \"top_k\": top_k,\n                \"top_p\": top_p,\n                \"classifier_free_guidance\": classifier_free_guidance,\n                \"output_format\": output_format,\n                \"normalization_strategy\": normalization_strategy,\n            },\n        )\n\n        # Handle the output\n        if isinstance(output, list) and len(output) > 0:\n            result_url = output[0]  # If output is a list, get the first element\n        elif isinstance(output, str):\n            result_url = output  # If output is a string, use it directly\n        else:\n            result_url = (\n                \"No output received\"  # Fallback message if output is not as expected\n            )\n\n        return result_url", "blocks": [{"id": 1, "label": "def run_model(self, api_key: SecretStr, music_gen_model_version: MusicGenModelVersion, prompt: str, duration: int, temperature: float, top_k: int, top_p: float, classifier_free_guidance: int, output_format: AudioFormat, normalization_strategy: NormalizationStrategy):\n    client = replicate.Client(api_token=api_key.get_secret_value())\n\n    output = client.run(\"meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb\", input={\"prompt\": prompt, \"music_gen_model_version\": music_gen_model_version, \"duration\": duration, \"temperature\": temperature, \"top_k\": top_k, \"top_p\": top_p, \"classifier_free_guidance\": classifier_free_guidance, \"output_format\": output_format, \"normalization_strategy\": normalization_strategy})\nif isinstance(output, list) and len(output) > 0:", "successors": [{"id": 3, "label": "    result_url = output[0]\nreturn result_url", "successors": []}, {"id": 4, "label": "elif isinstance(output, str):\n    result_url = output", "successors": [{"id": 6, "label": "return result_url", "successors": []}]}, {"id": 6, "label": "else:\n    result_url = \"No output received\"\nreturn result_url", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 57, "end_line": 108, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: CredentialsMetaInput[\n            Literal[ProviderName.REPLICATE], Literal[\"api_key\"]\n        ] = CredentialsField(\n            description=\"The Replicate integration can be used with \"\n            \"any API key with sufficient permissions for the blocks it is used on.\",\n        )\n        prompt: str = SchemaField(\n            description=\"A description of the music you want to generate\",\n            placeholder=\"e.g., 'An upbeat electronic dance track with heavy bass'\",\n            title=\"Prompt\",\n        )\n        music_gen_model_version: MusicGenModelVersion = SchemaField(\n            description=\"Model to use for generation\",\n            default=MusicGenModelVersion.STEREO_LARGE,\n            title=\"Model Version\",\n        )\n        duration: int = SchemaField(\n            description=\"Duration of the generated audio in seconds\",\n            default=8,\n            title=\"Duration\",\n        )\n        temperature: float = SchemaField(\n            description=\"Controls the 'conservativeness' of the sampling process. Higher temperature means more diversity\",\n            default=1.0,\n            title=\"Temperature\",\n        )\n        top_k: int = SchemaField(\n            description=\"Reduces sampling to the k most likely tokens\",\n            default=250,\n            title=\"Top K\",\n        )\n        top_p: float = SchemaField(\n            description=\"Reduces sampling to tokens with cumulative probability of p. When set to 0 (default), top_k sampling is used\",\n            default=0.0,\n            title=\"Top P\",\n        )\n        classifier_free_guidance: int = SchemaField(\n            description=\"Increases the influence of inputs on the output. Higher values produce lower-variance outputs that adhere more closely to inputs\",\n            default=3,\n            title=\"Classifier Free Guidance\",\n        )\n        output_format: AudioFormat = SchemaField(\n            description=\"Output format for generated audio\",\n            default=AudioFormat.WAV,\n            title=\"Output Format\",\n        )\n        normalization_strategy: NormalizationStrategy = SchemaField(\n            description=\"Strategy for normalizing audio\",\n            default=NormalizationStrategy.LOUDNESS,\n            title=\"Normalization Strategy\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: CredentialsMetaInput[\n        Literal[ProviderName.REPLICATE], Literal[\"api_key\"]\n    ] = CredentialsField(\n        description=\"The Replicate integration can be used with \"\n        \"any API key with sufficient permissions for the blocks it is used on.\",\n    )", "successors": [{"id": 3, "label": "    prompt: str = SchemaField(\n        description=\"A description of the music you want to generate\",\n        placeholder=\"e.g., 'An upbeat electronic dance track with heavy bass'\",\n        title=\"Prompt\",\n    )\n    music_gen_model_version: MusicGenModelVersion = SchemaField(\n        description=\"Model to use for generation\",\n        default=MusicGenModelVersion.STEREO_LARGE,\n        title=\"Model Version\",\n    )", "successors": [{"id": 5, "label": "    duration: int = SchemaField(\n        description=\"Duration of the generated audio in seconds\",\n        default=8,\n        title=\"Duration\",\n    )\n    temperature: float = SchemaField(\n        description=\"Controls the 'conservativeness' of the sampling process. Higher temperature means more diversity\",\n        default=1.0,\n        title=\"Temperature\",\n    )", "successors": [{"id": 7, "label": "    top_k: int = SchemaField(\n        description=\"Reduces sampling to the k most likely tokens\",\n        default=250,\n        title=\"Top K\",\n    )\n    top_p: float = SchemaField(\n        description=\"Reduces sampling to tokens with cumulative probability of p. When set to 0 (default), top_k sampling is used\",\n        default=0.0,\n        title=\"Top P\",\n    )", "successors": [{"id": 9, "label": "    classifier_free_guidance: int = SchemaField(\n        description=\"Increases the influence of inputs on the output. Higher values produce lower-variance outputs that adhere more closely to inputs\",\n        default=3,\n        title=\"Classifier Free Guidance\",\n    )\n    output_format: AudioFormat = SchemaField(\n        description=\"Output format for generated audio\",\n        default=AudioFormat.WAV,\n        title=\"Output Format\",\n    )", "successors": [{"id": 11, "label": "    normalization_strategy: NormalizationStrategy = SchemaField(\n        description=\"Strategy for normalizing audio\",\n        default=NormalizationStrategy.LOUDNESS,\n        title=\"Normalization Strategy\",\n    )", "successors": []}]}]}]}]}]}]}, {"name": "Output", "type": "class", "start_line": 110, "end_line": 112, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        result: str = SchemaField(description=\"URL of the generated audio file\")\n        error: str = SchemaField(description=\"Error message if the model run failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    result: str = SchemaField(description=\"URL of the generated audio file\")", "successors": [{"id": 3, "label": "    error: str = SchemaField(description=\"Error message if the model run failed\")", "successors": []}]}]}], "simplified_code": "class AIMusicGeneratorBlock(Block):\n        )\n\n        error: str = SchemaField(description=\"Error message if the model run failed\")\n\n        )\n\n        yield \"error\", f\"Failed after {max_retries} attempts. Last error: {last_error}\"\n\n        return result_url", "blocks": [{"id": 1, "label": "class AIMusicGeneratorBlock(Block):\nerror: str = SchemaField(description=\"Error message if the model run failed\")", "successors": [{"id": 3, "label": "yield \"error\", f\"Failed after {max_retries} attempts. Last error: {last_error}\"\nreturn result_url", "successors": []}]}]}], "simplified_code": "import logging\nimport time\nfrom enum import Enum\nfrom typing import Literal\n\nimport replicate\nfrom pydantic import SecretStr\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\n\nlogger = logging.getLogger(__name__)\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"replicate\",\n    api_key=SecretStr(\"mock-replicate-api-key\"),\n    title=\"Mock Replicate API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.type,\n}\n\n\n# Model version enum\n    LARGE = \"large\"\n\n\n# Audio format enum\n    MP3 = \"mp3\"\n\n\n# Normalization strategy enum\n    RMS = \"rms\"\n\n\n        return result_url", "blocks": [{"id": 1, "label": "import logging\nimport time\nfrom enum import Enum\nfrom typing import Literal\n\nimport replicate\nfrom pydantic import SecretStr\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\n\nlogger = logging.getLogger(__name__)\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"replicate\",\n    api_key=SecretStr(\"mock-replicate-api-key\"),\n    title=\"Mock Replicate API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.type,\n}\n\n\n# Model version enum\n    LARGE = \"large\"\n\n\n# Audio format enum\n    MP3 = \"mp3\"\n\n\n# Normalization strategy enum\n    RMS = \"rms\"\n\n\n        return result_url", "successors": []}]}
{"file_name": "26.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 325, "functions": [], "classes": [{"name": "ImageSize", "type": "class", "start_line": 18, "end_line": 27, "functions": [], "simplified_code": "class ImageSize(str, Enum):\n    \"\"\"\n    Semantic sizes that map reliably across all models\n    \"\"\"\n\n    SQUARE = \"square\"  # For profile pictures, icons, etc.\n    LANDSCAPE = \"landscape\"  # For traditional photos, scenes\n    PORTRAIT = \"portrait\"  # For vertical photos, portraits\n    WIDE = \"wide\"  # For cinematic, desktop wallpapers\n    TALL = \"tall\"  # For mobile wallpapers, stories", "blocks": [{"id": 1, "label": "class ImageSize(str, Enum):\n\"\"\"\nSemantic sizes that map reliably across all models\n\"\"\"", "successors": [{"id": 3, "label": "SQUARE = \"square\"  # For profile pictures, icons, etc.\nLANDSCAPE = \"landscape\"  # For traditional photos, scenes", "successors": [{"id": 5, "label": "PORTRAIT = \"portrait\"  # For vertical photos, portraits\nWIDE = \"wide\"  # For cinematic, desktop wallpapers", "successors": [{"id": 7, "label": "TALL = \"tall\"  # For mobile wallpapers, stories", "successors": []}]}]}]}]}, {"name": "ImageStyle", "type": "class", "start_line": 64, "end_line": 89, "functions": [], "simplified_code": "class ImageStyle(str, Enum):\n    \"\"\"\n    Complete set of supported styles\n    \"\"\"\n\n    ANY = \"any\"\n    # Realistic image styles\n    REALISTIC = \"realistic_image\"\n    REALISTIC_BW = \"realistic_image/b_and_w\"\n    REALISTIC_HDR = \"realistic_image/hdr\"\n    REALISTIC_NATURAL = \"realistic_image/natural_light\"\n    REALISTIC_STUDIO = \"realistic_image/studio_portrait\"\n    REALISTIC_ENTERPRISE = \"realistic_image/enterprise\"\n    REALISTIC_HARD_FLASH = \"realistic_image/hard_flash\"\n    REALISTIC_MOTION_BLUR = \"realistic_image/motion_blur\"\n    # Digital illustration styles\n    DIGITAL_ART = \"digital_illustration\"\n    PIXEL_ART = \"digital_illustration/pixel_art\"\n    HAND_DRAWN = \"digital_illustration/hand_drawn\"\n    GRAIN = \"digital_illustration/grain\"\n    SKETCH = \"digital_illustration/infantile_sketch\"\n    POSTER = \"digital_illustration/2d_art_poster\"\n    POSTER_2 = \"digital_illustration/2d_art_poster_2\"\n    HANDMADE_3D = \"digital_illustration/handmade_3d\"\n    HAND_DRAWN_OUTLINE = \"digital_illustration/hand_drawn_outline\"\n    ENGRAVING_COLOR = \"digital_illustration/engraving_color\"", "blocks": [{"id": 1, "label": "class ImageStyle(str, Enum):\n\"\"\"\nComplete set of supported styles\n\"\"\"", "successors": [{"id": 3, "label": "ANY = \"any\"\nREALISTIC = \"realistic_image\"", "successors": [{"id": 5, "label": "REALISTIC_BW = \"realistic_image/b_and_w\"\nREALISTIC_HDR = \"realistic_image/hdr\"", "successors": [{"id": 7, "label": "REALISTIC_NATURAL = \"realistic_image/natural_light\"\nREALISTIC_STUDIO = \"realistic_image/studio_portrait\"", "successors": [{"id": 9, "label": "REALISTIC_ENTERPRISE = \"realistic_image/enterprise\"\nREALISTIC_HARD_FLASH = \"realistic_image/hard_flash\"", "successors": [{"id": 11, "label": "REALISTIC_MOTION_BLUR = \"realistic_image/motion_blur\"\nDIGITAL_ART = \"digital_illustration\"", "successors": [{"id": 13, "label": "PIXEL_ART = \"digital_illustration/pixel_art\"\nHAND_DRAWN = \"digital_illustration/hand_drawn\"", "successors": [{"id": 15, "label": "GRAIN = \"digital_illustration/grain\"\nSKETCH = \"digital_illustration/infantile_sketch\"", "successors": [{"id": 17, "label": "POSTER = \"digital_illustration/2d_art_poster\"\nPOSTER_2 = \"digital_illustration/2d_art_poster_2\"", "successors": [{"id": 19, "label": "HANDMADE_3D = \"digital_illustration/handmade_3d\"\nHAND_DRAWN_OUTLINE = \"digital_illustration/hand_drawn_outline\"", "successors": [{"id": 21, "label": "ENGRAVING_COLOR = \"digital_illustration/engraving_color\"", "successors": []}]}]}]}]}]}]}]}]}]}]}]}, {"name": "ImageGenModel", "type": "class", "start_line": 92, "end_line": 100, "functions": [], "simplified_code": "class ImageGenModel(str, Enum):\n    \"\"\"\n    Available model providers\n    \"\"\"\n\n    FLUX = \"Flux 1.1 Pro\"\n    FLUX_ULTRA = \"Flux 1.1 Pro Ultra\"\n    RECRAFT = \"Recraft v3\"\n    SD3_5 = \"Stable Diffusion 3.5 Medium\"", "blocks": [{"id": 1, "label": "class ImageGenModel(str, Enum):\n\"\"\"\nAvailable model providers\n\"\"\"", "successors": [{"id": 3, "label": "FLUX = \"Flux 1.1 Pro\"\nFLUX_ULTRA = \"Flux 1.1 Pro Ultra\"\nRECRAFT = \"Recraft v3\"\nSD3_5 = \"Stable Diffusion 3.5 Medium\"", "successors": []}]}]}, {"name": "AIImageGeneratorBlock", "type": "class", "start_line": 103, "end_line": 308, "functions": [{"name": "__init__", "type": "function", "start_line": 142, "end_line": 166, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"ed1ae7a0-b770-4089-b520-1f0005fad19a\",\n            description=\"Generate images using various AI models through a unified interface\",\n            categories={BlockCategory.AI},\n            input_schema=AIImageGeneratorBlock.Input,\n            output_schema=AIImageGeneratorBlock.Output,\n            test_input={\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n                \"prompt\": \"An octopus using a laptop in a snowy forest with 'AutoGPT' clearly visible on the screen\",\n                \"model\": ImageGenModel.RECRAFT,\n                \"size\": ImageSize.SQUARE,\n                \"style\": ImageStyle.REALISTIC,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\n                    \"image_url\",\n                    \"https://replicate.delivery/generated-image.webp\",\n                ),\n            ],\n            test_mock={\n                \"_run_client\": lambda *args, **kwargs: \"https://replicate.delivery/generated-image.webp\"\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"ed1ae7a0-b770-4089-b520-1f0005fad19a\",\n    description=\"Generate images using various AI models through a unified interface\",\n    categories={BlockCategory.AI},\n    input_schema=AIImageGeneratorBlock.Input,\n    output_schema=AIImageGeneratorBlock.Output,\n    test_input={\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n        \"prompt\": \"An octopus using a laptop in a snowy forest with 'AutoGPT' clearly visible on the screen\",\n        \"model\": ImageGenModel.RECRAFT,\n        \"size\": ImageSize.SQUARE,\n        \"style\": ImageStyle.REALISTIC,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\n            \"image_url\",\n            \"https://replicate.delivery/generated-image.webp\",\n        ),\n    ],\n    test_mock={\n        \"_run_client\": lambda *args, **kwargs: \"https://replicate.delivery/generated-image.webp\"\n    },\n)", "successors": []}]}, {"name": "_run_client", "type": "function", "start_line": 168, "end_line": 196, "functions": [], "classes": [], "simplified_code": "    def _run_client(\n        self, credentials: APIKeyCredentials, model_name: str, input_params: dict\n    ):\n        try:\n            # Initialize Replicate client\n            client = replicate.Client(api_token=credentials.api_key.get_secret_value())\n\n            # Run the model with input parameters\n            output = client.run(model_name, input=input_params, wait=False)\n\n            # Process output\n            if isinstance(output, list) and len(output) > 0:\n                if isinstance(output[0], FileOutput):\n                    result_url = output[0].url\n                else:\n                    result_url = output[0]\n            elif isinstance(output, FileOutput):\n                result_url = output.url\n            elif isinstance(output, str):\n                result_url = output\n            else:\n                result_url = None\n\n            return result_url\n\n        except TypeError as e:\n            raise TypeError(f\"Error during model execution: {e}\")\n        except Exception as e:\n            raise RuntimeError(f\"Unexpected error during model execution: {e}\")", "blocks": [{"id": 1, "label": "try:", "successors": [{"id": 2, "label": "    client = replicate.Client(api_token=credentials.api_key.get_secret_value())\n    output = client.run(model_name, input=input_params, wait=False)", "successors": [{"id": 4, "label": "    if isinstance(output, list) and len(output) > 0:", "successors": [{"id": 5, "label": "        if isinstance(output[0], FileOutput):", "successors": [{"id": 6, "label": "            result_url = output[0].url\nreturn result_url", "successors": []}, {"id": 7, "label": "        else:\n            result_url = output[0]", "successors": [{"id": 9, "label": "return result_url", "successors": []}]}]}, {"id": 10, "label": "    elif isinstance(output, FileOutput):\n        result_url = output.url", "successors": [{"id": 9, "label": "return result_url", "successors": []}]}, {"id": 12, "label": "    elif isinstance(output, str):\n        result_url = output", "successors": [{"id": 9, "label": "return result_url", "successors": []}]}, {"id": 14, "label": "    else:\n        result_url = None", "successors": [{"id": 9, "label": "return result_url", "successors": []}]}]}]}, {"id": 16, "label": "except TypeError as e:\n    raise TypeError(f\"Error during model execution: {e}\")", "successors": []}, {"id": 18, "label": "except Exception as e:\n    raise RuntimeError(f\"Unexpected error during model execution: {e}\")", "successors": []}]}]}, {"name": "generate_image", "type": "function", "start_line": 198, "end_line": 266, "functions": [], "classes": [], "simplified_code": "    def generate_image(self, input_data: Input, credentials: APIKeyCredentials):\n        try:\n            # Handle style-based prompt modification for models without native style support\n            modified_prompt = input_data.prompt\n            if input_data.model not in [ImageGenModel.RECRAFT]:\n                style_prefix = self._style_to_prompt_prefix(input_data.style)\n                modified_prompt = f\"{style_prefix} {modified_prompt}\".strip()\n\n            if input_data.model == ImageGenModel.SD3_5:\n                # Use Stable Diffusion 3.5 with aspect ratio\n                input_params = {\n                    \"prompt\": modified_prompt,\n                    \"aspect_ratio\": SIZE_TO_SD_RATIO[input_data.size],\n                    \"output_format\": \"webp\",\n                    \"output_quality\": 90,\n                    \"steps\": 40,\n                    \"cfg_scale\": 7.0,\n                }\n                output = self._run_client(\n                    credentials,\n                    \"stability-ai/stable-diffusion-3.5-medium\",\n                    input_params,\n                )\n                return output\n\n            elif input_data.model == ImageGenModel.FLUX:\n                # Use Flux-specific dimensions with 'jpg' format to avoid ReplicateError\n                width, height = SIZE_TO_FLUX_DIMENSIONS[input_data.size]\n                input_params = {\n                    \"prompt\": modified_prompt,\n                    \"width\": width,\n                    \"height\": height,\n                    \"aspect_ratio\": SIZE_TO_FLUX_RATIO[input_data.size],\n                    \"output_format\": \"jpg\",  # Set to jpg for Flux models\n                    \"output_quality\": 90,\n                }\n                output = self._run_client(\n                    credentials, \"black-forest-labs/flux-1.1-pro\", input_params\n                )\n                return output\n\n            elif input_data.model == ImageGenModel.FLUX_ULTRA:\n                width, height = SIZE_TO_FLUX_DIMENSIONS[input_data.size]\n                input_params = {\n                    \"prompt\": modified_prompt,\n                    \"width\": width,\n                    \"height\": height,\n                    \"aspect_ratio\": SIZE_TO_FLUX_RATIO[input_data.size],\n                    \"output_format\": \"jpg\",\n                    \"output_quality\": 90,\n                }\n                output = self._run_client(\n                    credentials, \"black-forest-labs/flux-1.1-pro-ultra\", input_params\n                )\n                return output\n\n            elif input_data.model == ImageGenModel.RECRAFT:\n                input_params = {\n                    \"prompt\": input_data.prompt,\n                    \"size\": SIZE_TO_RECRAFT_DIMENSIONS[input_data.size],\n                    \"style\": input_data.style.value,\n                }\n                output = self._run_client(\n                    credentials, \"recraft-ai/recraft-v3\", input_params\n                )\n                return output\n\n        except Exception as e:\n            raise RuntimeError(f\"Failed to generate image: {str(e)}\")", "blocks": [{"id": 1, "label": "try:\nmodified_prompt = input_data.prompt", "successors": [{"id": 3, "label": "if input_data.model not in [ImageGenModel.RECRAFT]:\nstyle_prefix = self._style_to_prompt_prefix(input_data.style)\nmodified_prompt = f\"{style_prefix} {modified_prompt}\".strip()", "successors": [{"id": 5, "label": "if input_data.model == ImageGenModel.SD3_5:\ninput_params = {\n    \"prompt\": modified_prompt,\n    \"aspect_ratio\": SIZE_TO_SD_RATIO[input_data.size],\n    \"output_format\": \"webp\",\n    \"output_quality\": 90,\n    \"steps\": 40,\n    \"cfg_scale\": 7.0,\n}\noutput = self._run_client(\n    credentials,\n    \"stability-ai/stable-diffusion-3.5-medium\",\n    input_params,\n)\nreturn output", "successors": []}, {"id": 7, "label": "elif input_data.model == ImageGenModel.FLUX:\nwidth, height = SIZE_TO_FLUX_DIMENSIONS[input_data.size]\ninput_params = {\n    \"prompt\": modified_prompt,\n    \"width\": width,\n    \"height\": height,\n    \"aspect_ratio\": SIZE_TO_FLUX_RATIO[input_data.size],\n    \"output_format\": \"jpg\",\n    \"output_quality\": 90,\n}\noutput = self._run_client(\n    credentials, \"black-forest-labs/flux-1.1-pro\", input_params\n)\nreturn output", "successors": []}, {"id": 9, "label": "elif input_data.model == ImageGenModel.FLUX_ULTRA:\nwidth, height = SIZE_TO_FLUX_DIMENSIONS[input_data.size]\ninput_params = {\n    \"prompt\": modified_prompt,\n    \"width\": width,\n    \"height\": height,\n    \"aspect_ratio\": SIZE_TO_FLUX_RATIO[input_data.size],\n    \"output_format\": \"jpg\",\n    \"output_quality\": 90,\n}\noutput = self._run_client(\n    credentials, \"black-forest-labs/flux-1.1-pro-ultra\", input_params\n)\nreturn output", "successors": []}]}, {"id": 11, "label": "elif input_data.model == ImageGenModel.RECRAFT:\ninput_params = {\n    \"prompt\": input_data.prompt,\n    \"size\": SIZE_TO_RECRAFT_DIMENSIONS[input_data.size],\n    \"style\": input_data.style.value,\n}\noutput = self._run_client(\n    credentials, \"recraft-ai/recraft-v3\", input_params\n)\nreturn output", "successors": []}]}]}, {"name": "_style_to_prompt_prefix", "type": "function", "start_line": 268, "end_line": 297, "functions": [], "classes": [], "simplified_code": "    def _style_to_prompt_prefix(self, style: ImageStyle) -> str:\n        \"\"\"\n        Convert a style enum to a prompt prefix for models without native style support.\n        \"\"\"\n        if style == ImageStyle.ANY:\n            return \"\"\n\n        style_map = {\n            ImageStyle.REALISTIC: \"photorealistic\",\n            ImageStyle.REALISTIC_BW: \"black and white photograph\",\n            ImageStyle.REALISTIC_HDR: \"HDR photograph\",\n            ImageStyle.REALISTIC_NATURAL: \"natural light photograph\",\n            ImageStyle.REALISTIC_STUDIO: \"studio portrait photograph\",\n            ImageStyle.REALISTIC_ENTERPRISE: \"enterprise photograph\",\n            ImageStyle.REALISTIC_HARD_FLASH: \"hard flash photograph\",\n            ImageStyle.REALISTIC_MOTION_BLUR: \"motion blur photograph\",\n            ImageStyle.DIGITAL_ART: \"digital art\",\n            ImageStyle.PIXEL_ART: \"pixel art\",\n            ImageStyle.HAND_DRAWN: \"hand drawn illustration\",\n            ImageStyle.GRAIN: \"grainy digital illustration\",\n            ImageStyle.SKETCH: \"sketchy illustration\",\n            ImageStyle.POSTER: \"2D art poster\",\n            ImageStyle.POSTER_2: \"alternate 2D art poster\",\n            ImageStyle.HANDMADE_3D: \"handmade 3D illustration\",\n            ImageStyle.HAND_DRAWN_OUTLINE: \"hand drawn outline illustration\",\n            ImageStyle.ENGRAVING_COLOR: \"color engraving illustration\",\n        }\n\n        style_text = style_map.get(style, \"\")\n        return f\"{style_text} of\" if style_text else \"\"", "blocks": [{"id": 1, "label": "def _style_to_prompt_prefix(self, style: ImageStyle) -> str:\n    if style == ImageStyle.ANY:", "successors": [{"id": 3, "label": "        return \"\"\nreturn f\"{style_text} of\" if style_text else \"\"", "successors": []}, {"id": 4, "label": "    style_map = { ImageStyle.REALISTIC: \"photorealistic\", ImageStyle.REALISTIC_BW: \"black and white photograph\", ImageStyle.REALISTIC_HDR: \"HDR photograph\", ImageStyle.REALISTIC_NATURAL: \"natural light photograph\", ImageStyle.REALISTIC_STUDIO: \"studio portrait photograph\", ImageStyle.REALISTIC_ENTERPRISE: \"enterprise photograph\", ImageStyle.REALISTIC_HARD_FLASH: \"hard flash photograph\", ImageStyle.REALISTIC_MOTION_BLUR: \"motion blur photograph\", ImageStyle.DIGITAL_ART: \"digital art\", ImageStyle.PIXEL_ART: \"pixel art\", ImageStyle.HAND_DRAWN: \"hand drawn illustration\", ImageStyle.GRAIN: \"grainy digital illustration\", ImageStyle.SKETCH: \"sketchy illustration\", ImageStyle.POSTER: \"2D art poster\", ImageStyle.POSTER_2: \"alternate 2D art poster\", ImageStyle.HANDMADE_3D: \"handmade 3D illustration\", ImageStyle.HAND_DRAWN_OUTLINE: \"hand drawn outline illustration\", ImageStyle.ENGRAVING_COLOR: \"color engraving illustration\", }\n    style_text = style_map.get(style, \"\")", "successors": [{"id": 6, "label": "return f\"{style_text} of\" if style_text else \"\"", "successors": []}]}]}]}, {"name": "run", "type": "function", "start_line": 299, "end_line": 308, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs):\n        try:\n            url = self.generate_image(input_data, credentials)\n            if url:\n                yield \"image_url\", url\n            else:\n                yield \"error\", \"Image generation returned an empty result.\"\n        except Exception as e:\n            # Capture and return only the message of the exception, avoiding serialization of non-serializable objects\n            yield \"error\", str(e)", "blocks": [{"id": 1, "label": "try:\n    url = self.generate_image(input_data, credentials)", "successors": [{"id": 3, "label": "if url:", "successors": [{"id": 4, "label": "    yield \"image_url\", url", "successors": []}, {"id": 5, "label": "else:\n    yield \"error\", \"Image generation returned an empty result.\"", "successors": []}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 104, "end_line": 136, "functions": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: CredentialsMetaInput[\n            Literal[ProviderName.REPLICATE], Literal[\"api_key\"]\n        ] = CredentialsField(\n            description=\"Enter your Replicate API key to access the image generation API. You can obtain an API key from https://replicate.com/account/api-tokens.\",\n        )\n        prompt: str = SchemaField(\n            description=\"Text prompt for image generation\",\n            placeholder=\"e.g., 'A red panda using a laptop in a snowy forest'\",\n            title=\"Prompt\",\n        )\n        model: ImageGenModel = SchemaField(\n            description=\"The AI model to use for image generation\",\n            default=ImageGenModel.SD3_5,\n            title=\"Model\",\n        )\n        size: ImageSize = SchemaField(\n            description=(\n                \"Format of the generated image:\\n\"\n                \"- Square: Perfect for profile pictures, icons\\n\"\n                \"- Landscape: Traditional photo format\\n\"\n                \"- Portrait: Vertical photos, portraits\\n\"\n                \"- Wide: Cinematic format, desktop wallpapers\\n\"\n                \"- Tall: Mobile wallpapers, social media stories\"\n            ),\n            default=ImageSize.SQUARE,\n            title=\"Image Format\",\n        )\n        style: ImageStyle = SchemaField(\n            description=\"Visual style for the generated image\",\n            default=ImageStyle.ANY,\n            title=\"Image Style\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    credentials: CredentialsMetaInput[\n        Literal[ProviderName.REPLICATE], Literal[\"api_key\"]\n    ] = CredentialsField(\n        description=\"Enter your Replicate API key to access the image generation API. You can obtain an API key from https://replicate.com/account/api-tokens.\",\n    )", "successors": []}, {"id": 3, "label": "    prompt: str = SchemaField(\n        description=\"Text prompt for image generation\",\n        placeholder=\"e.g., 'A red panda using a laptop in a snowy forest'\",\n        title=\"Prompt\",\n    )", "successors": []}, {"id": 4, "label": "    model: ImageGenModel = SchemaField(\n        description=\"The AI model to use for image generation\",\n        default=ImageGenModel.SD3_5,\n        title=\"Model\",\n    )", "successors": []}, {"id": 5, "label": "    size: ImageSize = SchemaField(\n        description=(\n            \"Format of the generated image:\\n\"\n            \"- Square: Perfect for profile pictures, icons\\n\"\n            \"- Landscape: Traditional photo format\\n\"\n            \"- Portrait: Vertical photos, portraits\\n\"\n            \"- Wide: Cinematic format, desktop wallpapers\\n\"\n            \"- Tall: Mobile wallpapers, social media stories\"\n        ),\n        default=ImageSize.SQUARE,\n        title=\"Image Format\",\n    )", "successors": []}, {"id": 6, "label": "    style: ImageStyle = SchemaField(\n        description=\"Visual style for the generated image\",\n        default=ImageStyle.ANY,\n        title=\"Image Style\",\n    )", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 138, "end_line": 140, "functions": [], "simplified_code": "    class Output(BlockSchema):\n        image_url: str = SchemaField(description=\"URL of the generated image\")\n        error: str = SchemaField(description=\"Error message if generation failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    image_url: str = SchemaField(description=\"URL of the generated image\")\n    error: str = SchemaField(description=\"Error message if generation failed\")", "successors": []}]}], "simplified_code": "class AIImageGeneratorBlock(Block):\n        )\n\n        error: str = SchemaField(description=\"Error message if generation failed\")\n\n        )\n\n            raise RuntimeError(f\"Unexpected error during model execution: {e}\")\n\n            raise RuntimeError(f\"Failed to generate image: {str(e)}\")\n\n        return f\"{style_text} of\" if style_text else \"\"\n\n            yield \"error\", str(e)", "blocks": [{"id": 1, "label": "class AIImageGeneratorBlock(Block):", "successors": [{"id": 2, "label": "error: str = SchemaField(description=\"Error message if generation failed\")", "successors": []}, {"id": 3, "label": "raise RuntimeError(f\"Unexpected error during model execution: {e}\")", "successors": []}, {"id": 4, "label": "raise RuntimeError(f\"Failed to generate image: {str(e)}\")", "successors": []}, {"id": 5, "label": "return f\"{style_text} of\" if style_text else \"\"", "successors": []}, {"id": 6, "label": "yield \"error\", str(e)", "successors": []}]}]}], "simplified_code": "from enum import Enum\nfrom typing import Literal\n\nimport replicate\nfrom pydantic import SecretStr\nfrom replicate.helpers import FileOutput\n\nfrom backend.data.block import Block, BlockCategory, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\n\n\n    TALL = \"tall\"  # For mobile wallpapers, stories\n\n\n# Mapping semantic sizes to model-specific formats\nSIZE_TO_SD_RATIO = {\n    ImageSize.SQUARE: \"1:1\",\n    ImageSize.LANDSCAPE: \"4:3\",\n    ImageSize.PORTRAIT: \"3:4\",\n    ImageSize.WIDE: \"16:9\",\n    ImageSize.TALL: \"9:16\",\n}\n\nSIZE_TO_FLUX_RATIO = {\n    ImageSize.SQUARE: \"1:1\",\n    ImageSize.LANDSCAPE: \"4:3\",\n    ImageSize.PORTRAIT: \"3:4\",\n    ImageSize.WIDE: \"16:9\",\n    ImageSize.TALL: \"9:16\",\n}\n\nSIZE_TO_FLUX_DIMENSIONS = {\n    ImageSize.SQUARE: (1024, 1024),\n    ImageSize.LANDSCAPE: (1365, 1024),\n    ImageSize.PORTRAIT: (1024, 1365),\n    ImageSize.WIDE: (1440, 810),  # Adjusted to maintain 16:9 within 1440 limit\n    ImageSize.TALL: (810, 1440),  # Adjusted to maintain 9:16 within 1440 limit\n}\n\nSIZE_TO_RECRAFT_DIMENSIONS = {\n    ImageSize.SQUARE: \"1024x1024\",\n    ImageSize.LANDSCAPE: \"1365x1024\",\n    ImageSize.PORTRAIT: \"1024x1365\",\n    ImageSize.WIDE: \"1536x1024\",\n    ImageSize.TALL: \"1024x1536\",\n}\n\n\n    ENGRAVING_COLOR = \"digital_illustration/engraving_color\"\n\n\n    SD3_5 = \"Stable Diffusion 3.5 Medium\"\n\n\n            yield \"error\", str(e)\n\n\n# Test credentials stay the same\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"replicate\",\n    api_key=SecretStr(\"mock-replicate-api-key\"),\n    title=\"Mock Replicate API key\",\n    expires_at=None,\n)\n\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.title,\n}", "blocks": [{"id": 1, "label": "from enum import Enum\nfrom typing import Literal\n\nimport replicate\nfrom pydantic import SecretStr\nfrom replicate.helpers import FileOutput\n\nfrom backend.data.block import Block, BlockCategory, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\nTALL = \"tall\"  # For mobile wallpapers, stories\n\n\n# Mapping semantic sizes to model-specific formats\nSIZE_TO_SD_RATIO = {\n    ImageSize.SQUARE: \"1:1\",\n    ImageSize.LANDSCAPE: \"4:3\",\n    ImageSize.PORTRAIT: \"3:4\",\n    ImageSize.WIDE: \"16:9\",\n    ImageSize.TALL: \"9:16\",\n}\n\nSIZE_TO_FLUX_RATIO = {\n    ImageSize.SQUARE: \"1:1\",\n    ImageSize.LANDSCAPE: \"4:3\",\n    ImageSize.PORTRAIT: \"3:4\",\n    ImageSize.WIDE: \"16:9\",\n    ImageSize.TALL: \"9:16\",\n}\n\nSIZE_TO_FLUX_DIMENSIONS = {\n    ImageSize.SQUARE: (1024, 1024),\n    ImageSize.LANDSCAPE: (1365, 1024),\n    ImageSize.PORTRAIT: (1024, 1365),\n    ImageSize.WIDE: (1440, 810),  # Adjusted to maintain 16:9 within 1440 limit\n    ImageSize.TALL: (810, 1440),  # Adjusted to maintain 9:16 within 1440 limit\n}\n\nSIZE_TO_RECRAFT_DIMENSIONS = {\n    ImageSize.SQUARE: \"1024x1024\",\n    ImageSize.LANDSCAPE: \"1365x1024\",\n    ImageSize.PORTRAIT: \"1024x1365\",\n    ImageSize.WIDE: \"1536x1024\",\n    ImageSize.TALL: \"1024x1536\",\n}", "successors": [{"id": 3, "label": "ENGRAVING_COLOR = \"digital_illustration/engraving_color\"\n\n\nSD3_5 = \"Stable Diffusion 3.5 Medium\"\nyield \"error\", str(e)", "successors": [{"id": 5, "label": "TEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"replicate\",\n    api_key=SecretStr(\"mock-replicate-api-key\"),\n    title=\"Mock Replicate API key\",\n    expires_at=None,\n)\n\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.title,\n}", "successors": []}]}]}]}
{"file_name": "27.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 154, "functions": [{"name": "mock_websocket", "type": "function", "start_line": 18, "end_line": 19, "functions": [], "classes": [], "simplified_code": "def mock_websocket() -> AsyncMock:\n    return AsyncMock(spec=WebSocket)", "blocks": [{"id": 1, "label": "def mock_websocket() -> AsyncMock:\nreturn AsyncMock(spec=WebSocket)", "successors": []}]}, {"name": "mock_manager", "type": "function", "start_line": 23, "end_line": 24, "functions": [], "classes": [], "simplified_code": "def mock_manager() -> AsyncMock:\n    return AsyncMock(spec=ConnectionManager)", "blocks": [{"id": 1, "label": "def mock_manager() -> AsyncMock:\n    return AsyncMock(spec=ConnectionManager)", "successors": []}]}, {"name": "test_websocket_router_subscribe", "type": "function", "start_line": 28, "end_line": 47, "functions": [], "classes": [], "simplified_code": "async def test_websocket_router_subscribe(\n    mock_websocket: AsyncMock, mock_manager: AsyncMock\n) -> None:\n    mock_websocket.receive_text.side_effect = [\n        WsMessage(\n            method=Methods.SUBSCRIBE, data={\"graph_id\": \"test_graph\"}\n        ).model_dump_json(),\n        WebSocketDisconnect(),\n    ]\n\n    await websocket_router(\n        cast(WebSocket, mock_websocket), cast(ConnectionManager, mock_manager)\n    )\n\n    mock_manager.connect.assert_called_once_with(mock_websocket)\n    mock_manager.subscribe.assert_called_once_with(\"test_graph\", mock_websocket)\n    mock_websocket.send_text.assert_called_once()\n    assert '\"method\":\"subscribe\"' in mock_websocket.send_text.call_args[0][0]\n    assert '\"success\":true' in mock_websocket.send_text.call_args[0][0]\n    mock_manager.disconnect.assert_called_once_with(mock_websocket)", "blocks": [{"id": 1, "label": "async def test_websocket_router_subscribe(\n    mock_websocket: AsyncMock, mock_manager: AsyncMock\n) -> None:\n    mock_websocket.receive_text.side_effect = [\n        WsMessage(\n            method=Methods.SUBSCRIBE, data={\"graph_id\": \"test_graph\"}\n        ).model_dump_json(),\n        WebSocketDisconnect(),\n    ]", "successors": [{"id": 3, "label": "    await websocket_router(\n        cast(WebSocket, mock_websocket), cast(ConnectionManager, mock_manager)\n    )\n    mock_manager.connect.assert_called_once_with(mock_websocket)\n    mock_manager.subscribe.assert_called_once_with(\"test_graph\", mock_websocket)\n    mock_websocket.send_text.assert_called_once()", "successors": [{"id": 5, "label": "    assert '\"method\":\"subscribe\"' in mock_websocket.send_text.call_args[0][0]\n    assert '\"success\":true' in mock_websocket.send_text.call_args[0][0]\n    mock_manager.disconnect.assert_called_once_with(mock_websocket)", "successors": []}]}]}]}, {"name": "test_websocket_router_unsubscribe", "type": "function", "start_line": 51, "end_line": 70, "functions": [], "classes": [], "simplified_code": "async def test_websocket_router_unsubscribe(\n    mock_websocket: AsyncMock, mock_manager: AsyncMock\n) -> None:\n    mock_websocket.receive_text.side_effect = [\n        WsMessage(\n            method=Methods.UNSUBSCRIBE, data={\"graph_id\": \"test_graph\"}\n        ).model_dump_json(),\n        WebSocketDisconnect(),\n    ]\n\n    await websocket_router(\n        cast(WebSocket, mock_websocket), cast(ConnectionManager, mock_manager)\n    )\n\n    mock_manager.connect.assert_called_once_with(mock_websocket)\n    mock_manager.unsubscribe.assert_called_once_with(\"test_graph\", mock_websocket)\n    mock_websocket.send_text.assert_called_once()\n    assert '\"method\":\"unsubscribe\"' in mock_websocket.send_text.call_args[0][0]\n    assert '\"success\":true' in mock_websocket.send_text.call_args[0][0]\n    mock_manager.disconnect.assert_called_once_with(mock_websocket)", "blocks": [{"id": 1, "label": "mock_websocket.receive_text.side_effect = [\n    WsMessage(\n        method=Methods.UNSUBSCRIBE, data={\"graph_id\": \"test_graph\"}\n    ).model_dump_json(),\n    WebSocketDisconnect(),\n]\nawait websocket_router(\n    cast(WebSocket, mock_websocket), cast(ConnectionManager, mock_manager)\n)", "successors": [{"id": 3, "label": "mock_manager.connect.assert_called_once_with(mock_websocket)\nmock_manager.unsubscribe.assert_called_once_with(\"test_graph\", mock_websocket)", "successors": [{"id": 5, "label": "mock_websocket.send_text.assert_called_once()\nassert '\"method\":\"unsubscribe\"' in mock_websocket.send_text.call_args[0][0]", "successors": [{"id": 7, "label": "assert '\"success\":true' in mock_websocket.send_text.call_args[0][0]\nmock_manager.disconnect.assert_called_once_with(mock_websocket)", "successors": []}]}]}]}]}, {"name": "test_websocket_router_invalid_method", "type": "function", "start_line": 74, "end_line": 90, "functions": [], "classes": [], "simplified_code": "async def test_websocket_router_invalid_method(\n    mock_websocket: AsyncMock, mock_manager: AsyncMock\n) -> None:\n    mock_websocket.receive_text.side_effect = [\n        WsMessage(method=Methods.EXECUTION_EVENT).model_dump_json(),\n        WebSocketDisconnect(),\n    ]\n\n    await websocket_router(\n        cast(WebSocket, mock_websocket), cast(ConnectionManager, mock_manager)\n    )\n\n    mock_manager.connect.assert_called_once_with(mock_websocket)\n    mock_websocket.send_text.assert_called_once()\n    assert '\"method\":\"error\"' in mock_websocket.send_text.call_args[0][0]\n    assert '\"success\":false' in mock_websocket.send_text.call_args[0][0]\n    mock_manager.disconnect.assert_called_once_with(mock_websocket)", "blocks": [{"id": 1, "label": "async def test_websocket_router_invalid_method(\n    mock_websocket: AsyncMock, mock_manager: AsyncMock\n) -> None:\n    mock_websocket.receive_text.side_effect = [\n        WsMessage(method=Methods.EXECUTION_EVENT).model_dump_json(),\n        WebSocketDisconnect(),\n    ]", "successors": [{"id": 3, "label": "    await websocket_router(\n        cast(WebSocket, mock_websocket), cast(ConnectionManager, mock_manager)\n    )\n    mock_manager.connect.assert_called_once_with(mock_websocket)", "successors": [{"id": 5, "label": "    mock_websocket.send_text.assert_called_once()\n    assert '\"method\":\"error\"' in mock_websocket.send_text.call_args[0][0]", "successors": [{"id": 7, "label": "    assert '\"success\":false' in mock_websocket.send_text.call_args[0][0]\n    mock_manager.disconnect.assert_called_once_with(mock_websocket)", "successors": []}]}]}]}]}, {"name": "test_handle_subscribe_success", "type": "function", "start_line": 94, "end_line": 106, "functions": [], "classes": [], "simplified_code": "async def test_handle_subscribe_success(\n    mock_websocket: AsyncMock, mock_manager: AsyncMock\n) -> None:\n    message = WsMessage(method=Methods.SUBSCRIBE, data={\"graph_id\": \"test_graph\"})\n\n    await handle_subscribe(\n        cast(WebSocket, mock_websocket), cast(ConnectionManager, mock_manager), message\n    )\n\n    mock_manager.subscribe.assert_called_once_with(\"test_graph\", mock_websocket)\n    mock_websocket.send_text.assert_called_once()\n    assert '\"method\":\"subscribe\"' in mock_websocket.send_text.call_args[0][0]\n    assert '\"success\":true' in mock_websocket.send_text.call_args[0][0]", "blocks": [{"id": 1, "label": "message = WsMessage(method=Methods.SUBSCRIBE, data={\"graph_id\": \"test_graph\"})\nawait handle_subscribe(\n    cast(WebSocket, mock_websocket), cast(ConnectionManager, mock_manager), message\n)", "successors": [{"id": 3, "label": "mock_manager.subscribe.assert_called_once_with(\"test_graph\", mock_websocket)\nmock_websocket.send_text.assert_called_once()", "successors": [{"id": 5, "label": "assert '\"method\":\"subscribe\"' in mock_websocket.send_text.call_args[0][0]\nassert '\"success\":true' in mock_websocket.send_text.call_args[0][0]", "successors": []}]}]}]}, {"name": "test_handle_subscribe_missing_data", "type": "function", "start_line": 110, "end_line": 122, "functions": [], "classes": [], "simplified_code": "async def test_handle_subscribe_missing_data(\n    mock_websocket: AsyncMock, mock_manager: AsyncMock\n) -> None:\n    message = WsMessage(method=Methods.SUBSCRIBE)\n\n    await handle_subscribe(\n        cast(WebSocket, mock_websocket), cast(ConnectionManager, mock_manager), message\n    )\n\n    mock_manager.subscribe.assert_not_called()\n    mock_websocket.send_text.assert_called_once()\n    assert '\"method\":\"error\"' in mock_websocket.send_text.call_args[0][0]\n    assert '\"success\":false' in mock_websocket.send_text.call_args[0][0]", "blocks": [{"id": 1, "label": "async def test_handle_subscribe_missing_data(\n mock_websocket: AsyncMock, mock_manager: AsyncMock\n) -> None:\nmessage = WsMessage(method=Methods.SUBSCRIBE)", "successors": [{"id": 3, "label": "await handle_subscribe(\n cast(WebSocket, mock_websocket), cast(ConnectionManager, mock_manager), message\n)\nmock_manager.subscribe.assert_not_called()", "successors": [{"id": 5, "label": "mock_websocket.send_text.assert_called_once()\nassert '\"method\":\"error\"' in mock_websocket.send_text.call_args[0][0]", "successors": [{"id": 7, "label": "assert '\"success\":false' in mock_websocket.send_text.call_args[0][0]", "successors": []}]}]}]}]}, {"name": "test_handle_unsubscribe_success", "type": "function", "start_line": 126, "end_line": 138, "functions": [], "classes": [], "simplified_code": "async def test_handle_unsubscribe_success(\n    mock_websocket: AsyncMock, mock_manager: AsyncMock\n) -> None:\n    message = WsMessage(method=Methods.UNSUBSCRIBE, data={\"graph_id\": \"test_graph\"})\n\n    await handle_unsubscribe(\n        cast(WebSocket, mock_websocket), cast(ConnectionManager, mock_manager), message\n    )\n\n    mock_manager.unsubscribe.assert_called_once_with(\"test_graph\", mock_websocket)\n    mock_websocket.send_text.assert_called_once()\n    assert '\"method\":\"unsubscribe\"' in mock_websocket.send_text.call_args[0][0]\n    assert '\"success\":true' in mock_websocket.send_text.call_args[0][0]", "blocks": [{"id": 1, "label": "async def test_handle_unsubscribe_success(    mock_websocket: AsyncMock, mock_manager: AsyncMock) -> None:\n    message = WsMessage(method=Methods.UNSUBSCRIBE, data={\"graph_id\": \"test_graph\"})", "successors": [{"id": 3, "label": "    await handle_unsubscribe(        cast(WebSocket, mock_websocket), cast(ConnectionManager, mock_manager), message    )\n    mock_manager.unsubscribe.assert_called_once_with(\"test_graph\", mock_websocket)", "successors": [{"id": 5, "label": "    mock_websocket.send_text.assert_called_once()\n    assert '\"method\":\"unsubscribe\"' in mock_websocket.send_text.call_args[0][0]", "successors": [{"id": 7, "label": "    assert '\"success\":true' in mock_websocket.send_text.call_args[0][0]", "successors": []}]}]}]}]}, {"name": "test_handle_unsubscribe_missing_data", "type": "function", "start_line": 142, "end_line": 154, "functions": [], "classes": [], "simplified_code": "async def test_handle_unsubscribe_missing_data(\n    mock_websocket: AsyncMock, mock_manager: AsyncMock\n) -> None:\n    message = WsMessage(method=Methods.UNSUBSCRIBE)\n\n    await handle_unsubscribe(\n        cast(WebSocket, mock_websocket), cast(ConnectionManager, mock_manager), message\n    )\n\n    mock_manager.unsubscribe.assert_not_called()\n    mock_websocket.send_text.assert_called_once()\n    assert '\"method\":\"error\"' in mock_websocket.send_text.call_args[0][0]\n    assert '\"success\":false' in mock_websocket.send_text.call_args[0][0]", "blocks": [{"id": 1, "label": "async def test_handle_unsubscribe_missing_data( mock_websocket: AsyncMock, mock_manager: AsyncMock) -> None:\nmessage = WsMessage(method=Methods.UNSUBSCRIBE)", "successors": [{"id": 3, "label": "await handle_unsubscribe( cast(WebSocket, mock_websocket), cast(ConnectionManager, mock_manager), message )\nmock_manager.unsubscribe.assert_not_called()", "successors": [{"id": 5, "label": "mock_websocket.send_text.assert_called_once()\nassert '\"method\":\"error\"' in mock_websocket.send_text.call_args[0][0]", "successors": [{"id": 7, "label": "assert '\"success\":false' in mock_websocket.send_text.call_args[0][0]", "successors": []}]}]}]}]}], "classes": [], "simplified_code": "from typing import cast\nfrom unittest.mock import AsyncMock\n\nimport pytest\nfrom fastapi import WebSocket, WebSocketDisconnect\n\nfrom backend.server.conn_manager import ConnectionManager\nfrom backend.server.ws_api import (\n    Methods,\n    WsMessage,\n    handle_subscribe,\n    handle_unsubscribe,\n    websocket_router,\n)\n\n\n@pytest.fixture\n    return AsyncMock(spec=WebSocket)\n\n\n@pytest.fixture\n    return AsyncMock(spec=ConnectionManager)\n\n\n@pytest.mark.asyncio\n    mock_manager.disconnect.assert_called_once_with(mock_websocket)\n\n\n@pytest.mark.asyncio\n    mock_manager.disconnect.assert_called_once_with(mock_websocket)\n\n\n@pytest.mark.asyncio\n    mock_manager.disconnect.assert_called_once_with(mock_websocket)\n\n\n@pytest.mark.asyncio\n    assert '\"success\":true' in mock_websocket.send_text.call_args[0][0]\n\n\n@pytest.mark.asyncio\n    assert '\"success\":false' in mock_websocket.send_text.call_args[0][0]\n\n\n@pytest.mark.asyncio\n    assert '\"success\":true' in mock_websocket.send_text.call_args[0][0]\n\n\n@pytest.mark.asyncio\n    assert '\"success\":false' in mock_websocket.send_text.call_args[0][0]", "blocks": [{"id": 1, "label": "from typing import cast\nfrom unittest.mock import AsyncMock\n\nimport pytest\nfrom fastapi import WebSocket, WebSocketDisconnect\n\nfrom backend.server.conn_manager import ConnectionManager\nfrom backend.server.ws_api import (\n    Methods,\n    WsMessage,\n    handle_subscribe,\n    handle_unsubscribe,\n    websocket_router,\n)\n@pytest.fixture\nasync def mock_websocket() -> WebSocket:\n    return AsyncMock(spec=WebSocket)", "successors": [{"id": 3, "label": "@pytest.fixture\nasync def mock_manager() -> ConnectionManager:\n    return AsyncMock(spec=ConnectionManager)\n@pytest.mark.asyncio\nasync def test_subscribe_success(mock_manager: ConnectionManager, mock_websocket: WebSocket):\n    mock_manager.disconnect.assert_called_once_with(mock_websocket)", "successors": [{"id": 5, "label": "@pytest.mark.asyncio\nasync def test_unsubscribe_success(mock_manager: ConnectionManager, mock_websocket: WebSocket):\n    mock_manager.disconnect.assert_called_once_with(mock_websocket)\n@pytest.mark.asyncio\nasync def test_subscribe_failure(mock_manager: ConnectionManager, mock_websocket: WebSocket):\n    assert '\"success\":true' in mock_websocket.send_text.call_args[0][0]", "successors": [{"id": 7, "label": "@pytest.mark.asyncio\nasync def test_unsubscribe_failure(mock_manager: ConnectionManager, mock_websocket: WebSocket):\n    assert '\"success\":false' in mock_websocket.send_text.call_args[0][0]\n@pytest.mark.asyncio\nasync def test_multiple_invocations(mock_manager: ConnectionManager, mock_websocket: WebSocket):\n    assert '\"success\":true' in mock_websocket.send_text.call_args[0][0]", "successors": [{"id": 9, "label": "@pytest.mark.asyncio\nasync def test_additional_case(mock_manager: ConnectionManager, mock_websocket: WebSocket):\n    assert '\"success\":false' in mock_websocket.send_text.call_args[0][0]", "successors": []}]}]}]}]}]}
{"file_name": "28.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 33, "functions": [], "classes": [{"name": "BlockCostType", "type": "class", "start_line": 9, "end_line": 13, "functions": [], "simplified_code": "class BlockCostType(str, Enum):\n    RUN = \"run\"  # cost X credits per run\n    BYTE = \"byte\"  # cost X credits per byte\n    SECOND = \"second\"  # cost X credits per second\n    DOLLAR = \"dollar\"  # cost X dollars per run", "blocks": [{"id": 1, "label": "class BlockCostType(str, Enum):\n    RUN = \"run\"  # cost X credits per run", "successors": [{"id": 3, "label": "    BYTE = \"byte\"  # cost X credits per byte\n    SECOND = \"second\"  # cost X credits per second", "successors": [{"id": 5, "label": "    DOLLAR = \"dollar\"  # cost X dollars per run", "successors": []}]}]}]}, {"name": "BlockCost", "type": "class", "start_line": 16, "end_line": 33, "functions": [{"name": "__init__", "type": "function", "start_line": 21, "end_line": 33, "functions": [], "classes": [], "simplified_code": "    def __init__(\n        self,\n        cost_amount: int,\n        cost_type: BlockCostType = BlockCostType.RUN,\n        cost_filter: Optional[BlockInput] = None,\n        **data: Any,\n    ) -> None:\n        super().__init__(\n            cost_amount=cost_amount,\n            cost_filter=cost_filter or {},\n            cost_type=cost_type,\n            **data,\n        )", "blocks": [{"id": 1, "label": "def __init__(\n    self,\n    cost_amount: int,\n    cost_type: BlockCostType = BlockCostType.RUN,\n    cost_filter: Optional[BlockInput] = None,\n    **data: Any,\n) -> None:\n    super().__init__(\n        cost_amount=cost_amount,\n        cost_filter=cost_filter or {},\n        cost_type=cost_type,\n        **data,\n    )", "successors": []}]}], "simplified_code": "class BlockCost(BaseModel):\n    cost_amount: int\n    cost_filter: BlockInput\n    cost_type: BlockCostType\n\n        )", "blocks": [{"id": 1, "label": "class BlockCost(BaseModel):\n    cost_amount: int\n    cost_filter: BlockInput\n    cost_type: BlockCostType", "successors": []}]}], "simplified_code": "from enum import Enum\nfrom typing import Any, Optional\n\nfrom pydantic import BaseModel\n\nfrom backend.data.block import BlockInput\n\n\n    DOLLAR = \"dollar\"  # cost X dollars per run\n\n\n        )", "blocks": [{"id": 1, "label": "from enum import Enum\nfrom typing import Any, Optional\n\nfrom pydantic import BaseModel\n\nfrom backend.data.block import BlockInput", "successors": []}]}
{"file_name": "29.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 13, "functions": [{"name": "main", "type": "function", "start_line": 5, "end_line": 9, "functions": [], "classes": [], "simplified_code": "def main():\n    \"\"\"\n    Run all the processes required for the AutoGPT-server WebSocket API.\n    \"\"\"\n    run_processes(WebsocketServer())", "blocks": [{"id": 1, "label": "def main():\n\"\"\"\n    Run all the processes required for the AutoGPT-server WebSocket API.\n    \"\"\"", "successors": [{"id": 3, "label": "run_processes(WebsocketServer())", "successors": []}]}]}], "classes": [], "simplified_code": "from backend.app import run_processes\nfrom backend.server.ws_api import WebsocketServer\n\n\n    run_processes(WebsocketServer())\n\n\nif __name__ == \"__main__\":\n    main()", "blocks": [{"id": 1, "label": "from backend.app import run_processes\nfrom backend.server.ws_api import WebsocketServer\nrun_processes(WebsocketServer())", "successors": [{"id": 3, "label": "if __name__ == \"__main__\":\n    main()", "successors": []}]}]}
{"file_name": "30.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 273, "functions": [{"name": "find_links_in_text", "type": "function", "start_line": 12, "end_line": 23, "functions": [], "classes": [], "simplified_code": "def find_links_in_text(text: str) -> List[str]:\n    \"\"\"Find links in a text and return a list of URLs.\"\"\"\n\n    link_pattern = re.compile(r'((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\\\".,<>?\u00ab\u00bb\u201c\u201d\u2018\u2019]))')\n\n    raw_links = re.findall(link_pattern, text)\n\n    links = [\n        str(raw_link[0]) for raw_link in raw_links\n    ]\n\n    return links", "blocks": [{"id": 1, "label": "def find_links_in_text(text: str) -> List[str]:\n    \"\"\"Find links in a text and return a list of URLs.\"\"\"", "successors": [{"id": 3, "label": "    link_pattern = re.compile(r'((?:https?://|www\\\\d{0,3}[.]|[a-z0-9.\\\\-]+[.][a-z]{2,4}/)(?:[^\\\\s()<>]+|\\\\(([^\\\\s()<>]+|(\\\\([^\\\\s()<>]+\\\\)))*\\\\))+(?:\\\\(([^\\\\s()<>]+|(\\\\([^\\\\s()<>]+\\\\)))*\\\\)|[^\\\\s`!()\\\\[\\\\]{};:\\\\'\\\".,<>?\u00ab\u00bb\u201c\u201d\u2018\u2019]))')\n    raw_links = re.findall(link_pattern, text)", "successors": [{"id": 5, "label": "    links = [\n        str(raw_link[0]) for raw_link in raw_links\n    ]\n    return links", "successors": []}]}]}]}, {"name": "find_links_in_file", "type": "function", "start_line": 26, "end_line": 38, "functions": [], "classes": [], "simplified_code": "def find_links_in_file(filename: str) -> List[str]:\n    \"\"\"Find links in a file and return a list of URLs from text file.\"\"\"\n\n    with open(filename, mode='r', encoding='utf-8') as file:\n        readme = file.read()\n        index_section = readme.find('## Index')\n        if index_section == -1:\n            index_section = 0\n        content = readme[index_section:]\n\n    links = find_links_in_text(content)\n\n    return links", "blocks": [{"id": 1, "label": "def find_links_in_file(filename: str) -> List[str]:\n    \"\"\"Find links in a file and return a list of URLs from text file.\"\"\"", "successors": [{"id": 2, "label": "with open(filename, mode='r', encoding='utf-8') as file:\n    readme = file.read()\n    index_section = readme.find('## Index')\n    if index_section == -1:", "successors": [{"id": 4, "label": "        index_section = 0\ncontent = readme[index_section:]", "successors": []}, {"id": 5, "label": "content = readme[index_section:]", "successors": []}]}, {"id": 6, "label": "links = find_links_in_text(content)\nreturn links", "successors": []}]}]}, {"name": "check_duplicate_links", "type": "function", "start_line": 41, "end_line": 62, "functions": [], "classes": [], "simplified_code": "def check_duplicate_links(links: List[str]) -> Tuple[bool, List]:\n    \"\"\"Check for duplicated links.\n\n    Returns a tuple with True or False and duplicate list.\n    \"\"\"\n\n    seen = {}\n    duplicates = []\n    has_duplicate = False\n\n    for link in links:\n        link = link.rstrip('/')\n        if link not in seen:\n            seen[link] = 1\n        else:\n            if seen[link] == 1:\n                duplicates.append(link)\n\n    if duplicates:\n        has_duplicate = True\n\n    return (has_duplicate, duplicates)", "blocks": [{"id": 1, "label": "def check_duplicate_links(links: List[str]) -> Tuple[bool, List]:\nseen = {}\nduplicates = []\nhas_duplicate = False", "successors": [{"id": 3, "label": "for link in links:", "successors": [{"id": 4, "label": "link = link.rstrip('/')\nif link not in seen:", "successors": [{"id": 6, "label": "seen[link] = 1\n", "successors": []}, {"id": 7, "label": "if seen[link] == 1:\nduplicates.append(link)", "successors": [{"id": 9, "label": "", "successors": []}]}]}]}, {"id": 10, "label": "if duplicates:\nhas_duplicate = True", "successors": [{"id": 12, "label": "", "successors": []}]}, {"id": 12, "label": "return (has_duplicate, duplicates)", "successors": []}]}]}, {"name": "fake_user_agent", "type": "function", "start_line": 65, "end_line": 75, "functions": [], "classes": [], "simplified_code": "def fake_user_agent() -> str:\n    \"\"\"Faking user agent as some hosting services block not-whitelisted UA.\"\"\"\n\n    user_agents = [\n        'Mozilla/5.0 (Windows NT 6.2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1467.0 Safari/537.36',\n        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/605.1.15 (KHTML, like Gecko)',\n        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36',\n        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36',\n    ]\n\n    return random.choice(user_agents)", "blocks": [{"id": 1, "label": "def fake_user_agent() -> str:\n    \"\"\"Faking user agent as some hosting services block not-whitelisted UA.\"\"\"\nuser_agents = [\n    'Mozilla/5.0 (Windows NT 6.2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1467.0 Safari/537.36',\n    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/605.1.15 (KHTML, like Gecko)',\n    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36',\n    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36',\n]", "successors": [{"id": 3, "label": "return random.choice(user_agents)", "successors": []}]}]}, {"name": "get_host_from_link", "type": "function", "start_line": 78, "end_line": 92, "functions": [], "classes": [], "simplified_code": "def get_host_from_link(link: str) -> str:\n\n    host = link.split('://', 1)[1] if '://' in link else link\n\n    # Remove routes, arguments and anchors\n    if '/' in host:\n        host = host.split('/', 1)[0]\n\n    elif '?' in host:\n        host = host.split('?', 1)[0]\n\n    elif '#' in host:\n        host = host.split('#', 1)[0]\n\n    return host", "blocks": [{"id": 1, "label": "def get_host_from_link(link: str) -> str:\nhost = link.split('://', 1)[1] if '://' in link else link", "successors": [{"id": 3, "label": "if '/' in host:\nhost = host.split('/', 1)[0]", "successors": [{"id": 8, "label": "return host", "successors": []}]}, {"id": 5, "label": "elif '?' in host:\nhost = host.split('?', 1)[0]", "successors": [{"id": 8, "label": "return host", "successors": []}]}, {"id": 7, "label": "elif '#' in host:\nhost = host.split('#', 1)[0]", "successors": [{"id": 8, "label": "return host", "successors": []}]}, {"id": 8, "label": "return host", "successors": []}]}]}, {"name": "has_cloudflare_protection", "type": "function", "start_line": 95, "end_line": 149, "functions": [], "classes": [], "simplified_code": "def has_cloudflare_protection(resp: Response) -> bool:\n    \"\"\"Checks if there is any cloudflare protection in the response.\n\n    Cloudflare implements multiple network protections on a given link,\n    this script tries to detect if any of them exist in the response from request.\n\n    Common protections have the following HTTP code as a response:\n        - 403: When host header is missing or incorrect (and more)\n        - 503: When DDOS protection exists\n\n    See more about it at:\n        - https://support.cloudflare.com/hc/en-us/articles/115003014512-4xx-Client-Error\n        - https://support.cloudflare.com/hc/en-us/articles/115003011431-Troubleshooting-Cloudflare-5XX-errors\n        - https://www.cloudflare.com/ddos/\n        - https://superuser.com/a/888526\n\n    Discussions in issues and pull requests:\n        - https://github.com/public-apis/public-apis/pull/2409\n        - https://github.com/public-apis/public-apis/issues/2960 \n    \"\"\"\n\n    code = resp.status_code\n    server = resp.headers.get('Server') or resp.headers.get('server')\n    cloudflare_flags = [\n        '403 Forbidden',\n        'cloudflare',\n        'Cloudflare',\n        'Security check',\n        'Please Wait... | Cloudflare',\n        'We are checking your browser...',\n        'Please stand by, while we are checking your browser...',\n        'Checking your browser before accessing',\n        'This process is automatic.',\n        'Your browser will redirect to your requested content shortly.',\n        'Please allow up to 5 seconds',\n        'DDoS protection by',\n        'Ray ID:',\n        'Cloudflare Ray ID:',\n        '_cf_chl',\n        '_cf_chl_opt',\n        '__cf_chl_rt_tk',\n        'cf-spinner-please-wait',\n        'cf-spinner-redirecting'\n    ]\n\n    if code in [403, 503] and server == 'cloudflare':\n        html = resp.text\n\n        flags_found = [flag in html for flag in cloudflare_flags]\n        any_flag_found = any(flags_found)\n\n        if any_flag_found:\n            return True\n\n    return False", "blocks": [{"id": 1, "label": "def has_cloudflare_protection(resp: Response) -> bool:\n    code = resp.status_code\n    server = resp.headers.get('Server') or resp.headers.get('server')\n    cloudflare_flags = [\n        '403 Forbidden',\n        'cloudflare',\n        'Cloudflare',\n        'Security check',\n        'Please Wait... | Cloudflare',\n        'We are checking your browser...',\n        'Please stand by, while we are checking your browser...',\n        'Checking your browser before accessing',\n        'This process is automatic.',\n        'Your browser will redirect to your requested content shortly.',\n        'Please allow up to 5 seconds',\n        'DDoS protection by',\n        'Ray ID:',\n        'Cloudflare Ray ID:',\n        '_cf_chl',\n        '_cf_chl_opt',\n        '__cf_chl_rt_tk',\n        'cf-spinner-please-wait',\n        'cf-spinner-redirecting'\n    ]", "successors": [{"id": 3, "label": "if code in [403, 503] and server == 'cloudflare':\n    html = resp.text\n    flags_found = [flag in html for flag in cloudflare_flags]\n    any_flag_found = any(flags_found)", "successors": [{"id": 5, "label": "if any_flag_found:\n    return True", "successors": []}, {"id": 7, "label": "return False", "successors": []}]}, {"id": 7, "label": "return False", "successors": []}]}]}, {"name": "check_if_link_is_working", "type": "function", "start_line": 152, "end_line": 198, "functions": [], "classes": [], "simplified_code": "def check_if_link_is_working(link: str) -> Tuple[bool, str]:\n    \"\"\"Checks if a link is working.\n\n    If an error is identified when the request for the link occurs,\n    the return will be a tuple with the first value True and the second\n    value a string containing the error message.\n\n    If no errors are identified, the return will be a tuple with the\n    first value False and the second an empty string.\n    \"\"\"\n\n    has_error = False\n    error_message = ''\n\n    try:\n        resp = requests.get(link, timeout=25, headers={\n            'User-Agent': fake_user_agent(),\n            'host': get_host_from_link(link)\n        })\n\n        code = resp.status_code\n\n        if code >= 400 and not has_cloudflare_protection(resp):\n            has_error = True\n            error_message = f'ERR:CLT: {code} : {link}'\n\n    except requests.exceptions.SSLError as error:\n        has_error = True\n        error_message = f'ERR:SSL: {error} : {link}'\n\n    except requests.exceptions.ConnectionError as error:\n        has_error = True\n        error_message = f'ERR:CNT: {error} : {link}'\n\n    except (TimeoutError, requests.exceptions.ConnectTimeout):\n        has_error = True\n        error_message = f'ERR:TMO: {link}'\n\n    except requests.exceptions.TooManyRedirects as error:\n        has_error = True\n        error_message = f'ERR:TMR: {error} : {link}'\n\n    except (Exception, requests.exceptions.RequestException) as error:\n        has_error = True\n        error_message = f'ERR:UKN: {error} : {link}'\n\n    return (has_error, error_message)", "blocks": [{"id": 1, "label": "def check_if_link_is_working(link: str) -> Tuple[bool, str]:\nhas_error = False\nerror_message = ''", "successors": [{"id": 3, "label": "try:", "successors": [{"id": 4, "label": "resp = requests.get(link, timeout=25, headers={\n    'User-Agent': fake_user_agent(),\n    'host': get_host_from_link(link)\n})\n\ncode = resp.status_code\nif code >= 400 and not has_cloudflare_protection(resp):", "successors": [{"id": 6, "label": "has_error = True\nerror_message = f'ERR:CLT: {code} : {link}'\nreturn (has_error, error_message)", "successors": []}, {"id": 12, "label": "return (has_error, error_message)", "successors": []}]}, {"id": 7, "label": "except requests.exceptions.SSLError as error:\nhas_error = True\nerror_message = f'ERR:SSL: {error} : {link}'", "successors": [{"id": 12, "label": "return (has_error, error_message)", "successors": []}]}, {"id": 9, "label": "except requests.exceptions.ConnectionError as error:\nhas_error = True\nerror_message = f'ERR:CNT: {error} : {link}'", "successors": [{"id": 12, "label": "return (has_error, error_message)", "successors": []}]}, {"id": 11, "label": "except (TimeoutError, requests.exceptions.ConnectTimeout):\nhas_error = True\nerror_message = f'ERR:TMO: {link}'", "successors": [{"id": 12, "label": "return (has_error, error_message)", "successors": []}]}, {"id": 14, "label": "except requests.exceptions.TooManyRedirects as error:\nhas_error = True\nerror_message = f'ERR:TMR: {error} : {link}'", "successors": [{"id": 12, "label": "return (has_error, error_message)", "successors": []}]}, {"id": 16, "label": "except (Exception, requests.exceptions.RequestException) as error:\nhas_error = True\nerror_message = f'ERR:UKN: {error} : {link}'", "successors": [{"id": 12, "label": "return (has_error, error_message)", "successors": []}]}]}]}]}, {"name": "check_if_list_of_links_are_working", "type": "function", "start_line": 201, "end_line": 209, "functions": [], "classes": [], "simplified_code": "def check_if_list_of_links_are_working(list_of_links: List[str]) -> List[str]:\n    error_messages = []\n    for link in list_of_links:\n        has_error, error_message = check_if_link_is_working(link)\n\n        if has_error:\n            error_messages.append(error_message)\n\n    return error_messages", "blocks": [{"id": 1, "label": "def check_if_list_of_links_are_working(list_of_links: List[str]) -> List[str]:\nerror_messages = []", "successors": [{"id": 3, "label": "for link in list_of_links:", "successors": [{"id": 4, "label": "has_error, error_message = check_if_link_is_working(link)", "successors": [{"id": 5, "label": "if has_error:\nerror_messages.append(error_message)", "successors": [{"id": 7, "label": "return error_messages", "successors": []}]}, {"id": 7, "label": "return error_messages", "successors": []}]}]}]}]}, {"name": "start_duplicate_links_checker", "type": "function", "start_line": 212, "end_line": 226, "functions": [], "classes": [], "simplified_code": "def start_duplicate_links_checker(links: List[str]) -> None:\n\n    print('Checking for duplicate links...')\n\n    has_duplicate_link, duplicates_links = check_duplicate_links(links)\n\n    if has_duplicate_link:\n        print(f'Found duplicate links:')\n\n        for duplicate_link in duplicates_links:\n            print(duplicate_link)\n\n        sys.exit(1)\n    else:\n        print('No duplicate links.')", "blocks": [{"id": 1, "label": "print('Checking for duplicate links...')\nhas_duplicate_link, duplicates_links = check_duplicate_links(links)", "successors": [{"id": 3, "label": "if has_duplicate_link:", "successors": [{"id": 4, "label": "    print(f'Found duplicate links:')", "successors": [{"id": 5, "label": "    for duplicate_link in duplicates_links:", "successors": [{"id": 6, "label": "        print(duplicate_link)\nsys.exit(1)", "successors": []}]}]}, {"id": 8, "label": "else:\n    print('No duplicate links.')", "successors": []}]}]}]}, {"name": "start_links_working_checker", "type": "function", "start_line": 229, "end_line": 242, "functions": [], "classes": [], "simplified_code": "def start_links_working_checker(links: List[str]) -> None:\n\n    print(f'Checking if {len(links)} links are working...')\n\n    errors = check_if_list_of_links_are_working(links)\n    if errors:\n\n        num_errors = len(errors)\n        print(f'Apparently {num_errors} links are not working properly. See in:')\n\n        for error_message in errors:\n            print(error_message)\n\n        sys.exit(1)", "blocks": [{"id": 1, "label": "def start_links_working_checker(links: List[str]) -> None:\n\n    print(f'Checking if {len(links)} links are working...')\nerrors = check_if_list_of_links_are_working(links)\nif errors:", "successors": [{"id": 3, "label": "    num_errors = len(errors)\n    print(f'Apparently {num_errors} links are not working properly. See in:')", "successors": [{"id": 4, "label": "for error_message in errors:\n    print(error_message)", "successors": [{"id": 5, "label": "sys.exit(1)", "successors": []}]}]}]}]}, {"name": "main", "type": "function", "start_line": 245, "end_line": 252, "functions": [], "classes": [], "simplified_code": "def main(filename: str, only_duplicate_links_checker: bool) -> None:\n\n    links = find_links_in_file(filename)\n\n    start_duplicate_links_checker(links)\n\n    if not only_duplicate_links_checker:\n        start_links_working_checker(links)", "blocks": [{"id": 1, "label": "links = find_links_in_file(filename)\nstart_duplicate_links_checker(links)", "successors": [{"id": 3, "label": "if not only_duplicate_links_checker:\n    start_links_working_checker(links)", "successors": []}]}]}], "classes": [], "simplified_code": "# -*- coding: utf-8 -*-\n\nimport re\nimport sys\nimport random\nfrom typing import List, Tuple\n\nimport requests\nfrom requests.models import Response\n\n\n    return links\n\n\n    return links\n\n\n    return (has_duplicate, duplicates)\n\n\n    return random.choice(user_agents)\n\n\n    return host\n\n\n    return False\n\n\n    return (has_error, error_message)\n\n\n    return error_messages\n\n\n        print('No duplicate links.')\n\n\n        sys.exit(1)\n\n\n        start_links_working_checker(links)\n\n\nif __name__ == '__main__':\n    num_args = len(sys.argv)\n    only_duplicate_links_checker = False\n\n    if num_args < 2:\n        print('No .md file passed')\n        sys.exit(1)\n    elif num_args == 3:\n        third_arg = sys.argv[2].lower()\n\n        if third_arg == '-odlc' or third_arg == '--only_duplicate_links_checker':\n            only_duplicate_links_checker = True\n        else:\n            print(f'Third invalid argument. Usage: python {__file__} [-odlc | --only_duplicate_links_checker]')\n            sys.exit(1)\n\n    filename = sys.argv[1]\n\n    main(filename, only_duplicate_links_checker)", "blocks": [{"id": 1, "label": "if __name__ == '__main__':", "successors": [{"id": 2, "label": "    num_args = len(sys.argv)\n    only_duplicate_links_checker = False\n\n    if num_args < 2:\n        print('No .md file passed')\n        sys.exit(1)\nfilename = sys.argv[1]\n\nmain(filename, only_duplicate_links_checker)", "successors": []}, {"id": 3, "label": "    elif num_args == 3:\n        third_arg = sys.argv[2].lower()\n\n        if third_arg == '-odlc' or third_arg == '--only_duplicate_links_checker':\n            only_duplicate_links_checker = True\n        else:\n            print(f'Third invalid argument. Usage: python {__file__} [-odlc | --only_duplicate_links_checker]')\n            sys.exit(1)", "successors": [{"id": 5, "label": "filename = sys.argv[1]\n\nmain(filename, only_duplicate_links_checker)", "successors": []}]}]}]}
{"file_name": "31.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 27, "functions": [{"name": "excess_3_code", "type": "function", "start_line": 1, "end_line": 21, "functions": [], "classes": [], "simplified_code": "def excess_3_code(number: int) -> str:\n    \"\"\"\n    Find excess-3 code of integer base 10.\n    Add 3 to all digits in a decimal number then convert to a binary-coded decimal.\n    https://en.wikipedia.org/wiki/Excess-3\n\n    >>> excess_3_code(0)\n    '0b0011'\n    >>> excess_3_code(3)\n    '0b0110'\n    >>> excess_3_code(2)\n    '0b0101'\n    >>> excess_3_code(20)\n    '0b01010011'\n    >>> excess_3_code(120)\n    '0b010001010011'\n    \"\"\"\n    num = \"\"\n    for digit in str(max(0, number)):\n        num += str(bin(int(digit) + 3))[2:].zfill(4)\n    return \"0b\" + num", "blocks": [{"id": 1, "label": "def excess_3_code(number: int) -> str:\n    num = \"\"", "successors": [{"id": 3, "label": "    for digit in str(max(0, number)):", "successors": [{"id": 4, "label": "        num += str(bin(int(digit) + 3))[2:].zfill(4)\n    return \"0b\" + num", "successors": []}]}]}]}], "classes": [], "simplified_code": "    return \"0b\" + num\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()", "blocks": [{"id": 1, "label": "return \"0b\" + num", "successors": []}]}
{"file_name": "32.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 552, "functions": [{"name": "override_auth_middleware", "type": "function", "start_line": 19, "end_line": 21, "functions": [], "classes": [], "simplified_code": "def override_auth_middleware():\n    \"\"\"Override auth middleware for testing\"\"\"\n    return {\"sub\": \"test-user-id\"}", "blocks": [{"id": 1, "label": "def override_auth_middleware():\n\"\"\"Override auth middleware for testing\"\"\"", "successors": [{"id": 3, "label": "return {\"sub\": \"test-user-id\"}", "successors": []}]}]}, {"name": "override_get_user_id", "type": "function", "start_line": 24, "end_line": 26, "functions": [], "classes": [], "simplified_code": "def override_get_user_id():\n    \"\"\"Override get_user_id for testing\"\"\"\n    return \"test-user-id\"", "blocks": [{"id": 1, "label": "def override_get_user_id():\n\"\"\"Override get_user_id for testing\"\"\"", "successors": [{"id": 3, "label": "return \"test-user-id\"", "successors": []}]}]}, {"name": "test_get_agents_defaults", "type": "function", "start_line": 35, "end_line": 63, "functions": [], "classes": [], "simplified_code": "def test_get_agents_defaults(mocker: pytest_mock.MockFixture):\n    mocked_value = backend.server.v2.store.model.StoreAgentsResponse(\n        agents=[],\n        pagination=backend.server.v2.store.model.Pagination(\n            current_page=0,\n            total_items=0,\n            total_pages=0,\n            page_size=10,\n        ),\n    )\n    mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_agents\")\n    mock_db_call.return_value = mocked_value\n    response = client.get(\"/agents\")\n    assert response.status_code == 200\n\n    data = backend.server.v2.store.model.StoreAgentsResponse.model_validate(\n        response.json()\n    )\n    assert data.pagination.total_pages == 0\n    assert data.agents == []\n    mock_db_call.assert_called_once_with(\n        featured=False,\n        creator=None,\n        sorted_by=None,\n        search_query=None,\n        category=None,\n        page=1,\n        page_size=20,\n    )", "blocks": [{"id": 1, "label": "mocked_value = backend.server.v2.store.model.StoreAgentsResponse(\n    agents=[],\n    pagination=backend.server.v2.store.model.Pagination(\n        current_page=0,\n        total_items=0,\n        total_pages=0,\n        page_size=10,\n    ),\n)\nmock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_agents\")", "successors": [{"id": 3, "label": "mock_db_call.return_value = mocked_value\nresponse = client.get(\"/agents\")", "successors": [{"id": 5, "label": "assert response.status_code == 200\ndata = backend.server.v2.store.model.StoreAgentsResponse.model_validate(\n    response.json()\n)", "successors": [{"id": 7, "label": "assert data.pagination.total_pages == 0\nassert data.agents == []", "successors": [{"id": 9, "label": "mock_db_call.assert_called_once_with(\n    featured=False,\n    creator=None,\n    sorted_by=None,\n    search_query=None,\n    category=None,\n    page=1,\n    page_size=20,\n)", "successors": []}]}]}]}]}]}, {"name": "test_get_agents_featured", "type": "function", "start_line": 66, "end_line": 105, "functions": [], "classes": [], "simplified_code": "def test_get_agents_featured(mocker: pytest_mock.MockFixture):\n    mocked_value = backend.server.v2.store.model.StoreAgentsResponse(\n        agents=[\n            backend.server.v2.store.model.StoreAgent(\n                slug=\"featured-agent\",\n                agent_name=\"Featured Agent\",\n                agent_image=\"featured.jpg\",\n                creator=\"creator1\",\n                creator_avatar=\"avatar1.jpg\",\n                sub_heading=\"Featured agent subheading\",\n                description=\"Featured agent description\",\n                runs=100,\n                rating=4.5,\n            )\n        ],\n        pagination=backend.server.v2.store.model.Pagination(\n            current_page=1,\n            total_items=1,\n            total_pages=1,\n            page_size=20,\n        ),\n    )\n    mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_agents\")\n    mock_db_call.return_value = mocked_value\n    response = client.get(\"/agents?featured=true\")\n    assert response.status_code == 200\n    data = backend.server.v2.store.model.StoreAgentsResponse.model_validate(\n        response.json()\n    )\n    assert len(data.agents) == 1\n    assert data.agents[0].slug == \"featured-agent\"\n    mock_db_call.assert_called_once_with(\n        featured=True,\n        creator=None,\n        sorted_by=None,\n        search_query=None,\n        category=None,\n        page=1,\n        page_size=20,\n    )", "blocks": [{"id": 1, "label": "mocked_value = backend.server.v2.store.model.StoreAgentsResponse(\n    agents=[\n        backend.server.v2.store.model.StoreAgent(\n            slug=\"featured-agent\",\n            agent_name=\"Featured Agent\",\n            agent_image=\"featured.jpg\",\n            creator=\"creator1\",\n            creator_avatar=\"avatar1.jpg\",\n            sub_heading=\"Featured agent subheading\",\n            description=\"Featured agent description\",\n            runs=100,\n            rating=4.5,\n        )\n    ],\n    pagination=backend.server.v2.store.model.Pagination(\n        current_page=1,\n        total_items=1,\n        total_pages=1,\n        page_size=20,\n    ),\n)\nmock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_agents\")\nmock_db_call.return_value = mocked_value\nresponse = client.get(\"/agents?featured=true\")\nassert response.status_code == 200\ndata = backend.server.v2.store.model.StoreAgentsResponse.model_validate(\n    response.json()\n)\nassert len(data.agents) == 1\nassert data.agents[0].slug == \"featured-agent\"\nmock_db_call.assert_called_once_with(\n    featured=True,\n    creator=None,\n    sorted_by=None,\n    search_query=None,\n    category=None,\n    page=1,\n    page_size=20,\n)", "successors": []}]}, {"name": "test_get_agents_by_creator", "type": "function", "start_line": 108, "end_line": 147, "functions": [], "classes": [], "simplified_code": "def test_get_agents_by_creator(mocker: pytest_mock.MockFixture):\n    mocked_value = backend.server.v2.store.model.StoreAgentsResponse(\n        agents=[\n            backend.server.v2.store.model.StoreAgent(\n                slug=\"creator-agent\",\n                agent_name=\"Creator Agent\",\n                agent_image=\"agent.jpg\",\n                creator=\"specific-creator\",\n                creator_avatar=\"avatar.jpg\",\n                sub_heading=\"Creator agent subheading\",\n                description=\"Creator agent description\",\n                runs=50,\n                rating=4.0,\n            )\n        ],\n        pagination=backend.server.v2.store.model.Pagination(\n            current_page=1,\n            total_items=1,\n            total_pages=1,\n            page_size=20,\n        ),\n    )\n    mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_agents\")\n    mock_db_call.return_value = mocked_value\n    response = client.get(\"/agents?creator=specific-creator\")\n    assert response.status_code == 200\n    data = backend.server.v2.store.model.StoreAgentsResponse.model_validate(\n        response.json()\n    )\n    assert len(data.agents) == 1\n    assert data.agents[0].creator == \"specific-creator\"\n    mock_db_call.assert_called_once_with(\n        featured=False,\n        creator=\"specific-creator\",\n        sorted_by=None,\n        search_query=None,\n        category=None,\n        page=1,\n        page_size=20,\n    )", "blocks": [{"id": 1, "label": "mocked_value = backend.server.v2.store.model.StoreAgentsResponse(...\nmock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_agents\")", "successors": [{"id": 3, "label": "mock_db_call.return_value = mocked_value\nresponse = client.get(\"/agents?creator=specific-creator\")", "successors": [{"id": 5, "label": "assert response.status_code == 200\ndata = backend.server.v2.store.model.StoreAgentsResponse.model_validate(response.json())", "successors": [{"id": 7, "label": "assert len(data.agents) == 1\nassert data.agents[0].creator == \"specific-creator\"", "successors": [{"id": 9, "label": "mock_db_call.assert_called_once_with(...)", "successors": []}]}]}]}]}]}, {"name": "test_get_agents_sorted", "type": "function", "start_line": 150, "end_line": 189, "functions": [], "classes": [], "simplified_code": "def test_get_agents_sorted(mocker: pytest_mock.MockFixture):\n    mocked_value = backend.server.v2.store.model.StoreAgentsResponse(\n        agents=[\n            backend.server.v2.store.model.StoreAgent(\n                slug=\"top-agent\",\n                agent_name=\"Top Agent\",\n                agent_image=\"top.jpg\",\n                creator=\"creator1\",\n                creator_avatar=\"avatar1.jpg\",\n                sub_heading=\"Top agent subheading\",\n                description=\"Top agent description\",\n                runs=1000,\n                rating=5.0,\n            )\n        ],\n        pagination=backend.server.v2.store.model.Pagination(\n            current_page=1,\n            total_items=1,\n            total_pages=1,\n            page_size=20,\n        ),\n    )\n    mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_agents\")\n    mock_db_call.return_value = mocked_value\n    response = client.get(\"/agents?sorted_by=runs\")\n    assert response.status_code == 200\n    data = backend.server.v2.store.model.StoreAgentsResponse.model_validate(\n        response.json()\n    )\n    assert len(data.agents) == 1\n    assert data.agents[0].runs == 1000\n    mock_db_call.assert_called_once_with(\n        featured=False,\n        creator=None,\n        sorted_by=\"runs\",\n        search_query=None,\n        category=None,\n        page=1,\n        page_size=20,\n    )", "blocks": [{"id": 1, "label": "mocked_value = backend.server.v2.store.model.StoreAgentsResponse(\n    agents=[\n        backend.server.v2.store.model.StoreAgent(\n            slug=\"top-agent\",\n            agent_name=\"Top Agent\",\n            agent_image=\"top.jpg\",\n            creator=\"creator1\",\n            creator_avatar=\"avatar1.jpg\",\n            sub_heading=\"Top agent subheading\",\n            description=\"Top agent description\",\n            runs=1000,\n            rating=5.0,\n        )\n    ],\n    pagination=backend.server.v2.store.model.Pagination(\n        current_page=1,\n        total_items=1,\n        total_pages=1,\n        page_size=20,\n    ),\n)\nmock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_agents\")", "successors": [{"id": 3, "label": "mock_db_call.return_value = mocked_value\nresponse = client.get(\"/agents?sorted_by=runs\")", "successors": [{"id": 5, "label": "assert response.status_code == 200\ndata = backend.server.v2.store.model.StoreAgentsResponse.model_validate(\n    response.json()\n)", "successors": [{"id": 7, "label": "assert len(data.agents) == 1\nassert data.agents[0].runs == 1000", "successors": [{"id": 9, "label": "mock_db_call.assert_called_once_with(\n    featured=False,\n    creator=None,\n    sorted_by=\"runs\",\n    search_query=None,\n    category=None,\n    page=1,\n    page_size=20,\n)", "successors": []}]}]}]}]}]}, {"name": "test_get_agents_search", "type": "function", "start_line": 192, "end_line": 231, "functions": [], "classes": [], "simplified_code": "def test_get_agents_search(mocker: pytest_mock.MockFixture):\n    mocked_value = backend.server.v2.store.model.StoreAgentsResponse(\n        agents=[\n            backend.server.v2.store.model.StoreAgent(\n                slug=\"search-agent\",\n                agent_name=\"Search Agent\",\n                agent_image=\"search.jpg\",\n                creator=\"creator1\",\n                creator_avatar=\"avatar1.jpg\",\n                sub_heading=\"Search agent subheading\",\n                description=\"Specific search term description\",\n                runs=75,\n                rating=4.2,\n            )\n        ],\n        pagination=backend.server.v2.store.model.Pagination(\n            current_page=1,\n            total_items=1,\n            total_pages=1,\n            page_size=20,\n        ),\n    )\n    mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_agents\")\n    mock_db_call.return_value = mocked_value\n    response = client.get(\"/agents?search_query=specific\")\n    assert response.status_code == 200\n    data = backend.server.v2.store.model.StoreAgentsResponse.model_validate(\n        response.json()\n    )\n    assert len(data.agents) == 1\n    assert \"specific\" in data.agents[0].description.lower()\n    mock_db_call.assert_called_once_with(\n        featured=False,\n        creator=None,\n        sorted_by=None,\n        search_query=\"specific\",\n        category=None,\n        page=1,\n        page_size=20,\n    )", "blocks": [{"id": 1, "label": "def test_get_agents_search(mocker: pytest_mock.MockFixture):\nmocked_value = backend.server.v2.store.model.StoreAgentsResponse(\n    agents=[\n        backend.server.v2.store.model.StoreAgent(\n            slug=\"search-agent\",\n            agent_name=\"Search Agent\",\n            agent_image=\"search.jpg\",\n            creator=\"creator1\",\n            creator_avatar=\"avatar1.jpg\",\n            sub_heading=\"Search agent subheading\",\n            description=\"Specific search term description\",\n            runs=75,\n            rating=4.2,\n        )\n    ],\n    pagination=backend.server.v2.store.model.Pagination(\n        current_page=1,\n        total_items=1,\n        total_pages=1,\n        page_size=20,\n    ),\n)", "successors": [{"id": 3, "label": "mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_agents\")\nmock_db_call.return_value = mocked_value", "successors": [{"id": 5, "label": "response = client.get(\"/agents?search_query=specific\")\nassert response.status_code == 200", "successors": [{"id": 7, "label": "data = backend.server.v2.store.model.StoreAgentsResponse.model_validate(\n    response.json()\n)\nassert len(data.agents) == 1", "successors": [{"id": 9, "label": "assert \"specific\" in data.agents[0].description.lower()\nmock_db_call.assert_called_once_with(\n    featured=False,\n    creator=None,\n    sorted_by=None,\n    search_query=\"specific\",\n    category=None,\n    page=1,\n    page_size=20,\n)", "successors": []}]}]}]}]}]}, {"name": "test_get_agents_category", "type": "function", "start_line": 234, "end_line": 272, "functions": [], "classes": [], "simplified_code": "def test_get_agents_category(mocker: pytest_mock.MockFixture):\n    mocked_value = backend.server.v2.store.model.StoreAgentsResponse(\n        agents=[\n            backend.server.v2.store.model.StoreAgent(\n                slug=\"category-agent\",\n                agent_name=\"Category Agent\",\n                agent_image=\"category.jpg\",\n                creator=\"creator1\",\n                creator_avatar=\"avatar1.jpg\",\n                sub_heading=\"Category agent subheading\",\n                description=\"Category agent description\",\n                runs=60,\n                rating=4.1,\n            )\n        ],\n        pagination=backend.server.v2.store.model.Pagination(\n            current_page=1,\n            total_items=1,\n            total_pages=1,\n            page_size=20,\n        ),\n    )\n    mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_agents\")\n    mock_db_call.return_value = mocked_value\n    response = client.get(\"/agents?category=test-category\")\n    assert response.status_code == 200\n    data = backend.server.v2.store.model.StoreAgentsResponse.model_validate(\n        response.json()\n    )\n    assert len(data.agents) == 1\n    mock_db_call.assert_called_once_with(\n        featured=False,\n        creator=None,\n        sorted_by=None,\n        search_query=None,\n        category=\"test-category\",\n        page=1,\n        page_size=20,\n    )", "blocks": [{"id": 1, "label": "def test_get_agents_category(mocker: pytest_mock.MockFixture):\nmocked_value = backend.server.v2.store.model.StoreAgentsResponse(\n    agents=[\n        backend.server.v2.store.model.StoreAgent(\n            slug=\"category-agent\",\n            agent_name=\"Category Agent\",\n            agent_image=\"category.jpg\",\n            creator=\"creator1\",\n            creator_avatar=\"avatar1.jpg\",\n            sub_heading=\"Category agent subheading\",\n            description=\"Category agent description\",\n            runs=60,\n            rating=4.1,\n        )\n    ],\n    pagination=backend.server.v2.store.model.Pagination(\n        current_page=1,\n        total_items=1,\n        total_pages=1,\n        page_size=20,\n    ),\n)", "successors": [{"id": 3, "label": "mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_agents\")\nmock_db_call.return_value = mocked_value", "successors": [{"id": 5, "label": "response = client.get(\"/agents?category=test-category\")\nassert response.status_code == 200", "successors": [{"id": 7, "label": "data = backend.server.v2.store.model.StoreAgentsResponse.model_validate(\n    response.json()\n)\nassert len(data.agents) == 1", "successors": [{"id": 9, "label": "mock_db_call.assert_called_once_with(\n    featured=False,\n    creator=None,\n    sorted_by=None,\n    search_query=None,\n    category=\"test-category\",\n    page=1,\n    page_size=20,\n)", "successors": []}]}]}]}]}]}, {"name": "test_get_agents_pagination", "type": "function", "start_line": 275, "end_line": 316, "functions": [], "classes": [], "simplified_code": "def test_get_agents_pagination(mocker: pytest_mock.MockFixture):\n    mocked_value = backend.server.v2.store.model.StoreAgentsResponse(\n        agents=[\n            backend.server.v2.store.model.StoreAgent(\n                slug=f\"agent-{i}\",\n                agent_name=f\"Agent {i}\",\n                agent_image=f\"agent{i}.jpg\",\n                creator=\"creator1\",\n                creator_avatar=\"avatar1.jpg\",\n                sub_heading=f\"Agent {i} subheading\",\n                description=f\"Agent {i} description\",\n                runs=i * 10,\n                rating=4.0,\n            )\n            for i in range(5)\n        ],\n        pagination=backend.server.v2.store.model.Pagination(\n            current_page=2,\n            total_items=15,\n            total_pages=3,\n            page_size=5,\n        ),\n    )\n    mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_agents\")\n    mock_db_call.return_value = mocked_value\n    response = client.get(\"/agents?page=2&page_size=5\")\n    assert response.status_code == 200\n    data = backend.server.v2.store.model.StoreAgentsResponse.model_validate(\n        response.json()\n    )\n    assert len(data.agents) == 5\n    assert data.pagination.current_page == 2\n    assert data.pagination.page_size == 5\n    mock_db_call.assert_called_once_with(\n        featured=False,\n        creator=None,\n        sorted_by=None,\n        search_query=None,\n        category=None,\n        page=2,\n        page_size=5,\n    )", "blocks": [{"id": 1, "label": "def test_get_agents_pagination(mocker: pytest_mock.MockFixture):\nmocked_value = backend.server.v2.store.model.StoreAgentsResponse(\n    agents=[\n        backend.server.v2.store.model.StoreAgent(\n            slug=f\"agent-{i}\",\n            agent_name=f\"Agent {i}\",\n            agent_image=f\"agent{i}.jpg\",\n            creator=\"creator1\",\n            creator_avatar=\"avatar1.jpg\",\n            sub_heading=f\"Agent {i} subheading\",\n            description=f\"Agent {i} description\",\n            runs=i * 10,\n            rating=4.0,\n        )\n        for i in range(5)\n    ],\n    pagination=backend.server.v2.store.model.Pagination(\n        current_page=2,\n        total_items=15,\n        total_pages=3,\n        page_size=5,\n    ),\n)", "successors": [{"id": 3, "label": "mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_agents\")\nmock_db_call.return_value = mocked_value\nresponse = client.get(\"/agents?page=2&page_size=5\")\nassert response.status_code == 200\ndata = backend.server.v2.store.model.StoreAgentsResponse.model_validate(\n    response.json()\n)\nassert len(data.agents) == 5\nassert data.pagination.current_page == 2\nassert data.pagination.page_size == 5\nmock_db_call.assert_called_once_with(\n    featured=False,\n    creator=None,\n    sorted_by=None,\n    search_query=None,\n    category=None,\n    page=2,\n    page_size=5,\n)", "successors": []}]}]}, {"name": "test_get_agents_malformed_request", "type": "function", "start_line": 319, "end_line": 334, "functions": [], "classes": [], "simplified_code": "def test_get_agents_malformed_request(mocker: pytest_mock.MockFixture):\n    # Test with invalid page number\n    response = client.get(\"/agents?page=-1\")\n    assert response.status_code == 422\n\n    # Test with invalid page size\n    response = client.get(\"/agents?page_size=0\")\n    assert response.status_code == 422\n\n    # Test with non-numeric values\n    response = client.get(\"/agents?page=abc&page_size=def\")\n    assert response.status_code == 422\n\n    # Verify no DB calls were made\n    mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_agents\")\n    mock_db_call.assert_not_called()", "blocks": [{"id": 1, "label": "def test_get_agents_malformed_request(mocker: pytest_mock.MockFixture):\n    response = client.get(\"/agents?page=-1\")", "successors": [{"id": 3, "label": "    assert response.status_code == 422\n    response = client.get(\"/agents?page_size=0\")", "successors": [{"id": 5, "label": "    assert response.status_code == 422\n    response = client.get(\"/agents?page=abc&page_size=def\")", "successors": [{"id": 7, "label": "    assert response.status_code == 422\n    mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_agents\")", "successors": [{"id": 9, "label": "    mock_db_call.assert_not_called()", "successors": []}]}]}]}]}]}, {"name": "test_get_agent_details", "type": "function", "start_line": 337, "end_line": 365, "functions": [], "classes": [], "simplified_code": "def test_get_agent_details(mocker: pytest_mock.MockFixture):\n    mocked_value = backend.server.v2.store.model.StoreAgentDetails(\n        store_listing_version_id=\"test-version-id\",\n        slug=\"test-agent\",\n        agent_name=\"Test Agent\",\n        agent_video=\"video.mp4\",\n        agent_image=[\"image1.jpg\", \"image2.jpg\"],\n        creator=\"creator1\",\n        creator_avatar=\"avatar1.jpg\",\n        sub_heading=\"Test agent subheading\",\n        description=\"Test agent description\",\n        categories=[\"category1\", \"category2\"],\n        runs=100,\n        rating=4.5,\n        versions=[\"1.0.0\", \"1.1.0\"],\n        last_updated=datetime.datetime.now(),\n    )\n    mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_agent_details\")\n    mock_db_call.return_value = mocked_value\n\n    response = client.get(\"/agents/creator1/test-agent\")\n    assert response.status_code == 200\n\n    data = backend.server.v2.store.model.StoreAgentDetails.model_validate(\n        response.json()\n    )\n    assert data.agent_name == \"Test Agent\"\n    assert data.creator == \"creator1\"\n    mock_db_call.assert_called_once_with(username=\"creator1\", agent_name=\"test-agent\")", "blocks": [{"id": 1, "label": "def test_get_agent_details(mocker: pytest_mock.MockFixture):\nmocked_value = backend.server.v2.store.model.StoreAgentDetails(\n    store_listing_version_id=\"test-version-id\",\n    slug=\"test-agent\",\n    agent_name=\"Test Agent\",\n    agent_video=\"video.mp4\",\n    agent_image=[\"image1.jpg\", \"image2.jpg\"],\n    creator=\"creator1\",\n    creator_avatar=\"avatar1.jpg\",\n    sub_heading=\"Test agent subheading\",\n    description=\"Test agent description\",\n    categories=[\"category1\", \"category2\"],\n    runs=100,\n    rating=4.5,\n    versions=[\"1.0.0\", \"1.1.0\"],\n    last_updated=datetime.datetime.now(),\n)", "successors": [{"id": 3, "label": "mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_agent_details\")\nmock_db_call.return_value = mocked_value", "successors": [{"id": 5, "label": "response = client.get(\"/agents/creator1/test-agent\")\nassert response.status_code == 200", "successors": [{"id": 7, "label": "data = backend.server.v2.store.model.StoreAgentDetails.model_validate(response.json())\nassert data.agent_name == \"Test Agent\"", "successors": [{"id": 9, "label": "assert data.creator == \"creator1\"\nmock_db_call.assert_called_once_with(username=\"creator1\", agent_name=\"test-agent\")", "successors": []}]}]}]}]}]}, {"name": "test_get_creators_defaults", "type": "function", "start_line": 368, "end_line": 391, "functions": [], "classes": [], "simplified_code": "def test_get_creators_defaults(mocker: pytest_mock.MockFixture):\n    mocked_value = backend.server.v2.store.model.CreatorsResponse(\n        creators=[],\n        pagination=backend.server.v2.store.model.Pagination(\n            current_page=0,\n            total_items=0,\n            total_pages=0,\n            page_size=10,\n        ),\n    )\n    mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_creators\")\n    mock_db_call.return_value = mocked_value\n\n    response = client.get(\"/creators\")\n    assert response.status_code == 200\n\n    data = backend.server.v2.store.model.CreatorsResponse.model_validate(\n        response.json()\n    )\n    assert data.pagination.total_pages == 0\n    assert data.creators == []\n    mock_db_call.assert_called_once_with(\n        featured=False, search_query=None, sorted_by=None, page=1, page_size=20\n    )", "blocks": [{"id": 1, "label": "mocked_value = backend.server.v2.store.model.CreatorsResponse(\n    creators=[],\n    pagination=backend.server.v2.store.model.Pagination(\n        current_page=0,\n        total_items=0,\n        total_pages=0,\n        page_size=10,\n    ),\n)\nmock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_creators\")\nmock_db_call.return_value = mocked_value", "successors": [{"id": 3, "label": "response = client.get(\"/creators\")\nassert response.status_code == 200\ndata = backend.server.v2.store.model.CreatorsResponse.model_validate(\n    response.json()\n)\nassert data.pagination.total_pages == 0\nassert data.creators == []", "successors": [{"id": 5, "label": "mock_db_call.assert_called_once_with(\n    featured=False, search_query=None, sorted_by=None, page=1, page_size=20\n)", "successors": []}]}]}]}, {"name": "test_get_creators_pagination", "type": "function", "start_line": 394, "end_line": 430, "functions": [], "classes": [], "simplified_code": "def test_get_creators_pagination(mocker: pytest_mock.MockFixture):\n    mocked_value = backend.server.v2.store.model.CreatorsResponse(\n        creators=[\n            backend.server.v2.store.model.Creator(\n                name=f\"Creator {i}\",\n                username=f\"creator{i}\",\n                description=f\"Creator {i} description\",\n                avatar_url=f\"avatar{i}.jpg\",\n                num_agents=1,\n                agent_rating=4.5,\n                agent_runs=100,\n                is_featured=False,\n            )\n            for i in range(5)\n        ],\n        pagination=backend.server.v2.store.model.Pagination(\n            current_page=2,\n            total_items=15,\n            total_pages=3,\n            page_size=5,\n        ),\n    )\n    mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_creators\")\n    mock_db_call.return_value = mocked_value\n\n    response = client.get(\"/creators?page=2&page_size=5\")\n    assert response.status_code == 200\n\n    data = backend.server.v2.store.model.CreatorsResponse.model_validate(\n        response.json()\n    )\n    assert len(data.creators) == 5\n    assert data.pagination.current_page == 2\n    assert data.pagination.page_size == 5\n    mock_db_call.assert_called_once_with(\n        featured=False, search_query=None, sorted_by=None, page=2, page_size=5\n    )", "blocks": [{"id": 1, "label": "def test_get_creators_pagination(mocker: pytest_mock.MockFixture):\nmocked_value = backend.server.v2.store.model.CreatorsResponse(...)", "successors": [{"id": 3, "label": "mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_creators\")\nmock_db_call.return_value = mocked_value", "successors": [{"id": 5, "label": "response = client.get(\"/creators?page=2&page_size=5\")\nassert response.status_code == 200", "successors": [{"id": 7, "label": "data = backend.server.v2.store.model.CreatorsResponse.model_validate(\n response.json()\n)\nassert len(data.creators) == 5", "successors": [{"id": 9, "label": "assert data.pagination.current_page == 2\nassert data.pagination.page_size == 5", "successors": [{"id": 11, "label": "mock_db_call.assert_called_once_with(\n featured=False, search_query=None, sorted_by=None, page=2, page_size=5\n)", "successors": []}]}]}]}]}]}]}, {"name": "test_get_creators_malformed_request", "type": "function", "start_line": 433, "end_line": 448, "functions": [], "classes": [], "simplified_code": "def test_get_creators_malformed_request(mocker: pytest_mock.MockFixture):\n    # Test with invalid page number\n    response = client.get(\"/creators?page=-1\")\n    assert response.status_code == 422\n\n    # Test with invalid page size\n    response = client.get(\"/creators?page_size=0\")\n    assert response.status_code == 422\n\n    # Test with non-numeric values\n    response = client.get(\"/creators?page=abc&page_size=def\")\n    assert response.status_code == 422\n\n    # Verify no DB calls were made\n    mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_creators\")\n    mock_db_call.assert_not_called()", "blocks": [{"id": 1, "label": "response = client.get(\"/creators?page=-1\")\nassert response.status_code == 422", "successors": [{"id": 3, "label": "response = client.get(\"/creators?page_size=0\")\nassert response.status_code == 422", "successors": [{"id": 5, "label": "response = client.get(\"/creators?page=abc&page_size=def\")\nassert response.status_code == 422", "successors": [{"id": 7, "label": "mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_creators\")\nmock_db_call.assert_not_called()", "successors": []}]}]}]}]}, {"name": "test_get_creator_details", "type": "function", "start_line": 451, "end_line": 471, "functions": [], "classes": [], "simplified_code": "def test_get_creator_details(mocker: pytest_mock.MockFixture):\n    mocked_value = backend.server.v2.store.model.CreatorDetails(\n        name=\"Test User\",\n        username=\"creator1\",\n        description=\"Test creator description\",\n        links=[\"link1.com\", \"link2.com\"],\n        avatar_url=\"avatar.jpg\",\n        agent_rating=4.8,\n        agent_runs=1000,\n        top_categories=[\"category1\", \"category2\"],\n    )\n    mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_creator_details\")\n    mock_db_call.return_value = mocked_value\n\n    response = client.get(\"/creator/creator1\")\n    assert response.status_code == 200\n\n    data = backend.server.v2.store.model.CreatorDetails.model_validate(response.json())\n    assert data.username == \"creator1\"\n    assert data.name == \"Test User\"\n    mock_db_call.assert_called_once_with(username=\"creator1\")", "blocks": [{"id": 1, "label": "mocked_value = backend.server.v2.store.model.CreatorDetails(name=\"Test User\", username=\"creator1\", description=\"Test creator description\", links=[\"link1.com\", \"link2.com\"], avatar_url=\"avatar.jpg\", agent_rating=4.8, agent_runs=1000, top_categories=[\"category1\", \"category2\"])\nmock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_creator_details\")", "successors": [{"id": 3, "label": "mock_db_call.return_value = mocked_value\nresponse = client.get(\"/creator/creator1\")", "successors": [{"id": 5, "label": "assert response.status_code == 200\ndata = backend.server.v2.store.model.CreatorDetails.model_validate(response.json())", "successors": [{"id": 7, "label": "assert data.username == \"creator1\"\nassert data.name == \"Test User\"", "successors": [{"id": 9, "label": "mock_db_call.assert_called_once_with(username=\"creator1\")", "successors": []}]}]}]}]}]}, {"name": "test_get_submissions_success", "type": "function", "start_line": 474, "end_line": 510, "functions": [], "classes": [], "simplified_code": "def test_get_submissions_success(mocker: pytest_mock.MockFixture):\n    mocked_value = backend.server.v2.store.model.StoreSubmissionsResponse(\n        submissions=[\n            backend.server.v2.store.model.StoreSubmission(\n                name=\"Test Agent\",\n                description=\"Test agent description\",\n                image_urls=[\"test.jpg\"],\n                date_submitted=datetime.datetime.now(),\n                status=prisma.enums.SubmissionStatus.APPROVED,\n                runs=50,\n                rating=4.2,\n                agent_id=\"test-agent-id\",\n                agent_version=1,\n                sub_heading=\"Test agent subheading\",\n                slug=\"test-agent\",\n            )\n        ],\n        pagination=backend.server.v2.store.model.Pagination(\n            current_page=1,\n            total_items=1,\n            total_pages=1,\n            page_size=20,\n        ),\n    )\n    mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_submissions\")\n    mock_db_call.return_value = mocked_value\n\n    response = client.get(\"/submissions\")\n    assert response.status_code == 200\n\n    data = backend.server.v2.store.model.StoreSubmissionsResponse.model_validate(\n        response.json()\n    )\n    assert len(data.submissions) == 1\n    assert data.submissions[0].name == \"Test Agent\"\n    assert data.pagination.current_page == 1\n    mock_db_call.assert_called_once_with(user_id=\"test-user-id\", page=1, page_size=20)", "blocks": [{"id": 1, "label": "def test_get_submissions_success(mocker: pytest_mock.MockFixture):\nmocked_value = backend.server.v2.store.model.StoreSubmissionsResponse(\n    submissions=[\n        backend.server.v2.store.model.StoreSubmission(\n            name=\"Test Agent\",\n            description=\"Test agent description\",\n            image_urls=[\"test.jpg\"],\n            date_submitted=datetime.datetime.now(),\n            status=prisma.enums.SubmissionStatus.APPROVED,\n            runs=50,\n            rating=4.2,\n            agent_id=\"test-agent-id\",\n            agent_version=1,\n            sub_heading=\"Test agent subheading\",\n            slug=\"test-agent\",\n        )\n    ],\n    pagination=backend.server.v2.store.model.Pagination(\n        current_page=1,\n        total_items=1,\n        total_pages=1,\n        page_size=20,\n    ),\n)", "successors": [{"id": 3, "label": "mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_submissions\")\nmock_db_call.return_value = mocked_value", "successors": [{"id": 5, "label": "response = client.get(\"/submissions\")\nassert response.status_code == 200", "successors": [{"id": 7, "label": "data = backend.server.v2.store.model.StoreSubmissionsResponse.model_validate(\n    response.json()\n)\nassert len(data.submissions) == 1", "successors": [{"id": 9, "label": "assert data.submissions[0].name == \"Test Agent\"\nassert data.pagination.current_page == 1", "successors": [{"id": 11, "label": "mock_db_call.assert_called_once_with(user_id=\"test-user-id\", page=1, page_size=20)", "successors": []}]}]}]}]}]}]}, {"name": "test_get_submissions_pagination", "type": "function", "start_line": 513, "end_line": 534, "functions": [], "classes": [], "simplified_code": "def test_get_submissions_pagination(mocker: pytest_mock.MockFixture):\n    mocked_value = backend.server.v2.store.model.StoreSubmissionsResponse(\n        submissions=[],\n        pagination=backend.server.v2.store.model.Pagination(\n            current_page=2,\n            total_items=10,\n            total_pages=2,\n            page_size=5,\n        ),\n    )\n    mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_submissions\")\n    mock_db_call.return_value = mocked_value\n\n    response = client.get(\"/submissions?page=2&page_size=5\")\n    assert response.status_code == 200\n\n    data = backend.server.v2.store.model.StoreSubmissionsResponse.model_validate(\n        response.json()\n    )\n    assert data.pagination.current_page == 2\n    assert data.pagination.page_size == 5\n    mock_db_call.assert_called_once_with(user_id=\"test-user-id\", page=2, page_size=5)", "blocks": [{"id": 1, "label": "def test_get_submissions_pagination(mocker: pytest_mock.MockFixture):\nmocked_value = backend.server.v2.store.model.StoreSubmissionsResponse(\n    submissions=[],\n    pagination=backend.server.v2.store.model.Pagination(\n        current_page=2,\n        total_items=10,\n        total_pages=2,\n        page_size=5,\n    ),\n)", "successors": [{"id": 3, "label": "mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_submissions\")\nmock_db_call.return_value = mocked_value", "successors": [{"id": 5, "label": "response = client.get(\"/submissions?page=2&page_size=5\")\nassert response.status_code == 200", "successors": [{"id": 7, "label": "data = backend.server.v2.store.model.StoreSubmissionsResponse.model_validate(\n    response.json()\n)\nassert data.pagination.current_page == 2", "successors": [{"id": 9, "label": "assert data.pagination.page_size == 5\nmock_db_call.assert_called_once_with(user_id=\"test-user-id\", page=2, page_size=5)", "successors": []}]}]}]}]}]}, {"name": "test_get_submissions_malformed_request", "type": "function", "start_line": 537, "end_line": 552, "functions": [], "classes": [], "simplified_code": "def test_get_submissions_malformed_request(mocker: pytest_mock.MockFixture):\n    # Test with invalid page number\n    response = client.get(\"/submissions?page=-1\")\n    assert response.status_code == 422\n\n    # Test with invalid page size\n    response = client.get(\"/submissions?page_size=0\")\n    assert response.status_code == 422\n\n    # Test with non-numeric values\n    response = client.get(\"/submissions?page=abc&page_size=def\")\n    assert response.status_code == 422\n\n    # Verify no DB calls were made\n    mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_submissions\")\n    mock_db_call.assert_not_called()", "blocks": [{"id": 1, "label": "response = client.get(\"/submissions?page=-1\")\nassert response.status_code == 422", "successors": [{"id": 3, "label": "response = client.get(\"/submissions?page_size=0\")\nassert response.status_code == 422", "successors": [{"id": 5, "label": "response = client.get(\"/submissions?page=abc&page_size=def\")\nassert response.status_code == 422", "successors": [{"id": 7, "label": "mock_db_call = mocker.patch(\"backend.server.v2.store.db.get_store_submissions\")\nmock_db_call.assert_not_called()", "successors": []}]}]}]}]}], "classes": [], "simplified_code": "import datetime\n\nimport autogpt_libs.auth.depends\nimport autogpt_libs.auth.middleware\nimport fastapi\nimport fastapi.testclient\nimport prisma.enums\nimport pytest_mock\n\nimport backend.server.v2.store.model\nimport backend.server.v2.store.routes\n\napp = fastapi.FastAPI()\napp.include_router(backend.server.v2.store.routes.router)\n\nclient = fastapi.testclient.TestClient(app)\n\n\n    return {\"sub\": \"test-user-id\"}\n\n\n    return \"test-user-id\"\n\n\napp.dependency_overrides[autogpt_libs.auth.middleware.auth_middleware] = (\n    override_auth_middleware\n)\napp.dependency_overrides[autogpt_libs.auth.depends.get_user_id] = override_get_user_id\n\n\n    )\n\n\n    )\n\n\n    )\n\n\n    )\n\n\n    )\n\n\n    )\n\n\n    )\n\n\n    mock_db_call.assert_not_called()\n\n\n    mock_db_call.assert_called_once_with(username=\"creator1\", agent_name=\"test-agent\")\n\n\n    )\n\n\n    )\n\n\n    mock_db_call.assert_not_called()\n\n\n    mock_db_call.assert_called_once_with(username=\"creator1\")\n\n\n    mock_db_call.assert_called_once_with(user_id=\"test-user-id\", page=1, page_size=20)\n\n\n    mock_db_call.assert_called_once_with(user_id=\"test-user-id\", page=2, page_size=5)\n\n\n    mock_db_call.assert_not_called()", "blocks": [{"id": 1, "label": "import datetime\n\nimport autogpt_libs.auth.depends\nimport autogpt_libs.auth.middleware\nimport fastapi\nimport fastapi.testclient\nimport prisma.enums\nimport pytest_mock\n\nimport backend.server.v2.store.model\nimport backend.server.v2.store.routes\n\napp = fastapi.FastAPI()\napp.include_router(backend.server.v2.store.routes.router)\n\nclient = fastapi.testclient.TestClient(app)\n\n\n    return {\"sub\": \"test-user-id\"}\n\n\n    return \"test-user-id\"\n\n\napp.dependency_overrides[autogpt_libs.auth.middleware.auth_middleware] = (\n    override_auth_middleware\n)\napp.dependency_overrides[autogpt_libs.auth.depends.get_user_id] = override_get_user_id\n\n\n    )\n\n\n    )\n\n\n    )\n\n\n    )\n\n\n    )\n\n\n    )\n\n\n    )\n\n\n    mock_db_call.assert_not_called()\n\n\n    mock_db_call.assert_called_once_with(username=\"creator1\", agent_name=\"test-agent\")\n\n\n    )\n\n\n    )\n\n\n    mock_db_call.assert_not_called()\n\n\n    mock_db_call.assert_called_once_with(username=\"creator1\")\n\n\n    mock_db_call.assert_called_once_with(user_id=\"test-user-id\", page=1, page_size=20)\n\n\n    mock_db_call.assert_called_once_with(user_id=\"test-user-id\", page=2, page_size=5)\n\n\n    mock_db_call.assert_not_called()", "successors": []}]}
{"file_name": "33.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 39, "functions": [], "classes": [{"name": "TextDecoderBlock", "type": "class", "start_line": 7, "end_line": 39, "functions": [{"name": "__init__", "type": "function", "start_line": 19, "end_line": 35, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"2570e8fe-8447-43ed-84c7-70d657923231\",\n            description=\"Decodes a string containing escape sequences into actual text\",\n            categories={BlockCategory.TEXT},\n            input_schema=TextDecoderBlock.Input,\n            output_schema=TextDecoderBlock.Output,\n            test_input={\"text\": \"\"\"Hello\\nWorld!\\nThis is a \\\"quoted\\\" string.\"\"\"},\n            test_output=[\n                (\n                    \"decoded_text\",\n                    \"\"\"Hello\nWorld!\nThis is a \"quoted\" string.\"\"\",\n                )\n            ],\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"2570e8fe-8447-43ed-84c7-70d657923231\",\n    description=\"Decodes a string containing escape sequences into actual text\",\n    categories={BlockCategory.TEXT},\n    input_schema=TextDecoderBlock.Input,\n    output_schema=TextDecoderBlock.Output,\n    test_input={\"text\": \"\"\"Hello\\nWorld!\\nThis is a \\\"quoted\\\" string.\"\"\"},\n    test_output=[\n        (\n            \"decoded_text\",\n            \"\"\"Hello\nWorld!\nThis is a \"quoted\" string.\"\"\",\n        )\n    ],\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 37, "end_line": 39, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        decoded_text = codecs.decode(input_data.text, \"unicode_escape\")\n        yield \"decoded_text\", decoded_text", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\n    decoded_text = codecs.decode(input_data.text, \"unicode_escape\")", "successors": [{"id": 3, "label": "    yield \"decoded_text\", decoded_text", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 8, "end_line": 12, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        text: str = SchemaField(\n            description=\"A string containing escaped characters to be decoded\",\n            placeholder='Your entire text block with \\\\n and \\\\\" escaped characters',\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\ntext: str = SchemaField(description=\"A string containing escaped characters to be decoded\", placeholder='Your entire text block with \\n and \\\\\" escaped characters')", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 14, "end_line": 17, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        decoded_text: str = SchemaField(\n            description=\"The decoded text with escape sequences processed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\ndecoded_text: str = SchemaField(description=\"The decoded text with escape sequences processed\")", "successors": []}]}], "simplified_code": "class TextDecoderBlock(Block):\n        )\n\n        )\n\n        )\n\n        yield \"decoded_text\", decoded_text", "blocks": [{"id": 1, "label": "class TextDecoderBlock(Block):\n    def decode(self, text):", "successors": [{"id": 3, "label": "        decoded_text = \"\"", "successors": [{"id": 4, "label": "        for char in text:", "successors": [{"id": 5, "label": "            if char.isdigit():", "successors": [{"id": 6, "label": "                decoded_text += char\nyield \"decoded_text\", decoded_text", "successors": []}, {"id": 7, "label": "            elif char.isalpha():\n                decoded_text += char.lower()", "successors": [{"id": 11, "label": "yield \"decoded_text\", decoded_text", "successors": []}]}, {"id": 9, "label": "            else:\n                continue", "successors": [{"id": 11, "label": "yield \"decoded_text\", decoded_text", "successors": []}]}]}]}]}]}]}], "simplified_code": "import codecs\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\n\n        yield \"decoded_text\", decoded_text", "blocks": [{"id": 1, "label": "import codecs\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema", "successors": [{"id": 3, "label": "from backend.data.model import SchemaField\nyield \"decoded_text\", decoded_text", "successors": []}]}]}
{"file_name": "34.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 94, "functions": [], "classes": [{"name": "DatabaseManager", "type": "class", "start_line": 33, "end_line": 94, "functions": [{"name": "__init__", "type": "function", "start_line": 34, "end_line": 38, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__()\n        self.use_db = True\n        self.use_redis = True\n        self.event_queue = RedisExecutionEventBus()", "blocks": [{"id": 1, "label": "def __init__(self):\n    super().__init__()", "successors": [{"id": 3, "label": "    self.use_db = True\n    self.use_redis = True", "successors": [{"id": 5, "label": "    self.event_queue = RedisExecutionEventBus()", "successors": []}]}]}]}, {"name": "get_port", "type": "function", "start_line": 41, "end_line": 42, "functions": [], "classes": [], "simplified_code": "    def get_port(cls) -> int:\n        return config.database_api_port", "blocks": [{"id": 1, "label": "def get_port(cls) -> int:\n    return config.database_api_port", "successors": []}]}, {"name": "send_execution_update", "type": "function", "start_line": 45, "end_line": 46, "functions": [], "classes": [], "simplified_code": "    def send_execution_update(self, execution_result: ExecutionResult):\n        self.event_queue.publish(execution_result)", "blocks": [{"id": 1, "label": "def send_execution_update(self, execution_result: ExecutionResult):\n    self.event_queue.publish(execution_result)", "successors": []}]}, {"name": "exposed_run_and_wait", "type": "function", "start_line": 49, "end_line": 62, "functions": [{"name": "wrapper", "type": "function", "start_line": 54, "end_line": 57, "functions": [], "classes": [], "simplified_code": "        def wrapper(self, *args: P.args, **kwargs: P.kwargs) -> R:\n            coroutine = f(*args, **kwargs)\n            res = self.run_and_wait(coroutine)\n            return res", "blocks": [{"id": 1, "label": "def wrapper(self, *args: P.args, **kwargs: P.kwargs) -> R:\n    coroutine = f(*args, **kwargs)\n    res = self.run_and_wait(coroutine)\n    return res", "successors": []}]}], "classes": [], "simplified_code": "    def exposed_run_and_wait(\n        f: Callable[P, Coroutine[None, None, R]]\n    ) -> Callable[Concatenate[object, P], R]:\n        @expose\n        @wraps(f)\n            return res\n\n        # Register serializers for annotations on bare function\n        register_pydantic_serializers(f)\n\n        return wrapper", "blocks": [{"id": 1, "label": "def exposed_run_and_wait(f: Callable[P, Coroutine[None, None, R]]) -> Callable[Concatenate[object, P], R]:\n@expose\n@wraps(f)\ndef wrapper(*args: P) -> R:", "successors": [{"id": 3, "label": "res = await f(*args)\nreturn res\nregister_pydantic_serializers(f)", "successors": [{"id": 5, "label": "return wrapper", "successors": []}]}]}]}], "classes": [], "simplified_code": "class DatabaseManager(AppService):\n        self.event_queue = RedisExecutionEventBus()\n\n    @classmethod\n        return config.database_api_port\n\n    @expose\n        self.event_queue.publish(execution_result)\n\n    @staticmethod\n        return wrapper\n\n    # Executions\n    create_graph_execution = exposed_run_and_wait(create_graph_execution)\n    get_execution_results = exposed_run_and_wait(get_execution_results)\n    get_incomplete_executions = exposed_run_and_wait(get_incomplete_executions)\n    get_latest_execution = exposed_run_and_wait(get_latest_execution)\n    update_execution_status = exposed_run_and_wait(update_execution_status)\n    update_graph_execution_stats = exposed_run_and_wait(update_graph_execution_stats)\n    update_node_execution_stats = exposed_run_and_wait(update_node_execution_stats)\n    upsert_execution_input = exposed_run_and_wait(upsert_execution_input)\n    upsert_execution_output = exposed_run_and_wait(upsert_execution_output)\n\n    # Graphs\n    get_node = exposed_run_and_wait(get_node)\n    get_graph = exposed_run_and_wait(get_graph)\n\n    # Credits\n    user_credit_model = get_user_credit_model()\n    get_or_refill_credit = cast(\n        Callable[[Any, str], int],\n        exposed_run_and_wait(user_credit_model.get_or_refill_credit),\n    )\n    spend_credits = cast(\n        Callable[[Any, str, int, str, dict[str, str], float, float], int],\n        exposed_run_and_wait(user_credit_model.spend_credits),\n    )\n\n    # User + User Metadata + User Integrations\n    get_user_metadata = exposed_run_and_wait(get_user_metadata)\n    update_user_metadata = exposed_run_and_wait(update_user_metadata)\n    get_user_integrations = exposed_run_and_wait(get_user_integrations)\n    update_user_integrations = exposed_run_and_wait(update_user_integrations)", "blocks": [{"id": 1, "label": "class DatabaseManager(AppService):\nself.event_queue = RedisExecutionEventBus()", "successors": [{"id": 3, "label": "@classmethod\nreturn config.database_api_port", "successors": [{"id": 5, "label": "@expose\nself.event_queue.publish(execution_result)", "successors": [{"id": 7, "label": "@staticmethod\nreturn wrapper", "successors": [{"id": 9, "label": "create_graph_execution = exposed_run_and_wait(create_graph_execution)\nget_execution_results = exposed_run_and_wait(get_execution_results)", "successors": [{"id": 11, "label": "get_incomplete_executions = exposed_run_and_wait(get_incomplete_executions)\nget_latest_execution = exposed_run_and_wait(get_latest_execution)", "successors": [{"id": 13, "label": "update_execution_status = exposed_run_and_wait(update_execution_status)\nupdate_graph_execution_stats = exposed_run_and_wait(update_graph_execution_stats)", "successors": [{"id": 15, "label": "update_node_execution_stats = exposed_run_and_wait(update_node_execution_stats)\nupsert_execution_input = exposed_run_and_wait(upsert_execution_input)", "successors": [{"id": 17, "label": "upsert_execution_output = exposed_run_and_wait(upsert_execution_output)\nget_node = exposed_run_and_wait(get_node)", "successors": [{"id": 19, "label": "get_graph = exposed_run_and_wait(get_graph)\nuser_credit_model = get_user_credit_model()", "successors": [{"id": 21, "label": "get_or_refill_credit = cast(Callable[[Any, str], int], exposed_run_and_wait(user_credit_model.get_or_refill_credit),)\nspend_credits = cast(Callable[[Any, str, int, str, dict[str, str], float, float], int], exposed_run_and_wait(user_credit_model.spend_credits),)", "successors": [{"id": 23, "label": "get_user_metadata = exposed_run_and_wait(get_user_metadata)\nupdate_user_metadata = exposed_run_and_wait(update_user_metadata)", "successors": [{"id": 25, "label": "get_user_integrations = exposed_run_and_wait(get_user_integrations)\nupdate_user_integrations = exposed_run_and_wait(update_user_integrations)", "successors": []}]}]}]}]}]}]}]}]}]}]}]}]}]}], "simplified_code": "from functools import wraps\nfrom typing import Any, Callable, Concatenate, Coroutine, ParamSpec, TypeVar, cast\n\nfrom backend.data.credit import get_user_credit_model\nfrom backend.data.execution import (\n    ExecutionResult,\n    RedisExecutionEventBus,\n    create_graph_execution,\n    get_execution_results,\n    get_incomplete_executions,\n    get_latest_execution,\n    update_execution_status,\n    update_graph_execution_stats,\n    update_node_execution_stats,\n    upsert_execution_input,\n    upsert_execution_output,\n)\nfrom backend.data.graph import get_graph, get_node\nfrom backend.data.user import (\n    get_user_integrations,\n    get_user_metadata,\n    update_user_integrations,\n    update_user_metadata,\n)\nfrom backend.util.service import AppService, expose, register_pydantic_serializers\nfrom backend.util.settings import Config\n\nP = ParamSpec(\"P\")\nR = TypeVar(\"R\")\nconfig = Config()\n\n\n    update_user_integrations = exposed_run_and_wait(update_user_integrations)", "blocks": [{"id": 1, "label": "from functools import wraps\nfrom typing import Any, Callable, Concatenate, Coroutine, ParamSpec, TypeVar, cast\n\nfrom backend.data.credit import get_user_credit_model\nfrom backend.data.execution import (\n    ExecutionResult,\n    RedisExecutionEventBus,\n    create_graph_execution,\n    get_execution_results,\n    get_incomplete_executions,\n    get_latest_execution,\n    update_execution_status,\n    update_graph_execution_stats,\n    update_node_execution_stats,\n    upsert_execution_input,\n    upsert_execution_output,\n)\nfrom backend.data.graph import get_graph, get_node\nfrom backend.data.user import (\n    get_user_integrations,\n    get_user_metadata,\n    update_user_integrations,\n    update_user_metadata,\n)\nfrom backend.util.service import AppService, expose, register_pydantic_serializers\nfrom backend.util.settings import Config\n\nP = ParamSpec(\"P\")\nR = TypeVar(\"R\")\nconfig = Config()\nupdate_user_integrations = exposed_run_and_wait(update_user_integrations)", "successors": []}]}
{"file_name": "35.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 32, "functions": [{"name": "test_type_conversion", "type": "function", "start_line": 4, "end_line": 32, "functions": [], "classes": [], "simplified_code": "def test_type_conversion():\n    assert convert(5.5, int) == 5\n    assert convert(\"5.5\", int) == 5\n    assert convert([1, 2, 3], int) == 3\n\n    assert convert(\"5.5\", float) == 5.5\n    assert convert(5, float) == 5.0\n\n    assert convert(\"True\", bool) is True\n    assert convert(\"False\", bool) is False\n\n    assert convert(5, str) == \"5\"\n    assert convert({\"a\": 1, \"b\": 2}, str) == '{\"a\": 1, \"b\": 2}'\n    assert convert([1, 2, 3], str) == \"[1, 2, 3]\"\n\n    assert convert(\"5\", list) == [\"5\"]\n    assert convert((1, 2, 3), list) == [1, 2, 3]\n    assert convert({1, 2, 3}, list) == [1, 2, 3]\n\n    assert convert(\"5\", dict) == {\"value\": 5}\n    assert convert('{\"a\": 1, \"b\": 2}', dict) == {\"a\": 1, \"b\": 2}\n    assert convert([1, 2, 3], dict) == {0: 1, 1: 2, 2: 3}\n    assert convert((1, 2, 3), dict) == {0: 1, 1: 2, 2: 3}\n\n    from typing import List\n\n    assert convert(\"5\", List[int]) == [5]\n    assert convert(\"[5,4,2]\", List[int]) == [5, 4, 2]\n    assert convert([5, 4, 2], List[str]) == [\"5\", \"4\", \"2\"]", "blocks": [{"id": 1, "label": "def test_type_conversion():\n    assert convert(5.5, int) == 5\n    assert convert(\"5.5\", int) == 5\n    assert convert([1, 2, 3], int) == 3\n\n    assert convert(\"5.5\", float) == 5.5\n    assert convert(5, float) == 5.0\n\n    assert convert(\"True\", bool) is True\n    assert convert(\"False\", bool) is False\n\n    assert convert(5, str) == \"5\"\n    assert convert({\"a\": 1, \"b\": 2}, str) == '{\"a\": 1, \"b\": 2}'\n    assert convert([1, 2, 3], str) == \"[1, 2, 3]\"\n\n    assert convert(\"5\", list) == [\"5\"]\n    assert convert((1, 2, 3), list) == [1, 2, 3]\n    assert convert({1, 2, 3}, list) == [1, 2, 3]\n\n    assert convert(\"5\", dict) == {\"value\": 5}\n    assert convert('{\"a\": 1, \"b\": 2}', dict) == {\"a\": 1, \"b\": 2}\n    assert convert([1, 2, 3], dict) == {0: 1, 1: 2, 2: 3}\n    assert convert((1, 2, 3), dict) == {0: 1, 1: 2, 2: 3}\n", "successors": [{"id": 3, "label": "    from typing import List\n    assert convert(\"5\", List[int]) == [5]\n    assert convert(\"[5,4,2]\", List[int]) == [5, 4, 2]\n    assert convert([5, 4, 2], List[str]) == [\"5\", \"4\", \"2\"]", "successors": []}]}]}], "classes": [], "simplified_code": "from backend.util.type import convert\n\n\n    assert convert([5, 4, 2], List[str]) == [\"5\", \"4\", \"2\"]", "blocks": [{"id": 1, "label": "from backend.util.type import convert\n\n\n    assert convert([5, 4, 2], List[str]) == [\"5\", \"4\", \"2\"]", "successors": []}]}
{"file_name": "36.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 44, "functions": [{"name": "binary_count_trailing_zeros", "type": "function", "start_line": 4, "end_line": 38, "functions": [], "classes": [], "simplified_code": "def binary_count_trailing_zeros(a: int) -> int:\n    \"\"\"\n    Take in 1 integer, return a number that is\n    the number of trailing zeros in binary representation of that number.\n\n    >>> binary_count_trailing_zeros(25)\n    0\n    >>> binary_count_trailing_zeros(36)\n    2\n    >>> binary_count_trailing_zeros(16)\n    4\n    >>> binary_count_trailing_zeros(58)\n    1\n    >>> binary_count_trailing_zeros(4294967296)\n    32\n    >>> binary_count_trailing_zeros(0)\n    0\n    >>> binary_count_trailing_zeros(-10)\n    Traceback (most recent call last):\n        ...\n    ValueError: Input value must be a positive integer\n    >>> binary_count_trailing_zeros(0.8)\n    Traceback (most recent call last):\n        ...\n    TypeError: Input value must be a 'int' type\n    >>> binary_count_trailing_zeros(\"0\")\n    Traceback (most recent call last):\n        ...\n    TypeError: '<' not supported between instances of 'str' and 'int'\n    \"\"\"\n    if a < 0:\n        raise ValueError(\"Input value must be a positive integer\")\n    elif isinstance(a, float):\n        raise TypeError(\"Input value must be a 'int' type\")\n    return 0 if (a == 0) else int(log2(a & -a))", "blocks": [{"id": 1, "label": "def binary_count_trailing_zeros(a: int) -> int:\nif a < 0:", "successors": [{"id": 3, "label": "raise ValueError(\"Input value must be a positive integer\")", "successors": []}, {"id": 4, "label": "elif isinstance(a, float):", "successors": [{"id": 5, "label": "raise TypeError(\"Input value must be a 'int' type\")", "successors": []}, {"id": 6, "label": "return 0 if (a == 0) else int(log2(a & -a))", "successors": []}]}]}]}], "classes": [], "simplified_code": "from math import log2\n\n\n    return 0 if (a == 0) else int(log2(a & -a))\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()", "blocks": [{"id": 1, "label": "from math import log2", "successors": [{"id": 2, "label": "return 0 if (a == 0) else int(log2(a & -a))", "successors": []}, {"id": 3, "label": "if __name__ == \"__main__\":\nimport doctest", "successors": [{"id": 5, "label": "doctest.testmod()", "successors": []}]}]}]}
{"file_name": "37.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 121, "functions": [], "classes": [{"name": "HubSpotEngagementBlock", "type": "class", "start_line": 13, "end_line": 121, "functions": [{"name": "__init__", "type": "function", "start_line": 37, "end_line": 44, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"c6524385-7d87-49d6-a470-248bd29ca765\",\n            description=\"Manages HubSpot engagements - sends emails and tracks engagement metrics\",\n            categories={BlockCategory.CRM, BlockCategory.COMMUNICATION},\n            input_schema=HubSpotEngagementBlock.Input,\n            output_schema=HubSpotEngagementBlock.Output,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\n    super().__init__(id=\"c6524385-7d87-49d6-a470-248bd29ca765\", description=\"Manages HubSpot engagements - sends emails and tracks engagement metrics\", categories={BlockCategory.CRM, BlockCategory.COMMUNICATION}, input_schema=HubSpotEngagementBlock.Input, output_schema=HubSpotEngagementBlock.Output)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 46, "end_line": 121, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: HubSpotCredentials, **kwargs\n    ) -> BlockOutput:\n        base_url = \"https://api.hubapi.com\"\n        headers = {\n            \"Authorization\": f\"Bearer {credentials.api_key.get_secret_value()}\",\n            \"Content-Type\": \"application/json\",\n        }\n\n        if input_data.operation == \"send_email\":\n            # Using the email send API\n            email_url = f\"{base_url}/crm/v3/objects/emails\"\n            email_data = {\n                \"properties\": {\n                    \"hs_timestamp\": datetime.now().isoformat(),\n                    \"hubspot_owner_id\": \"1\",  # This should be configurable\n                    \"hs_email_direction\": \"OUTBOUND\",\n                    \"hs_email_status\": \"SEND\",\n                    \"hs_email_subject\": input_data.email_data.get(\"subject\"),\n                    \"hs_email_text\": input_data.email_data.get(\"content\"),\n                    \"hs_email_to_email\": input_data.email_data.get(\"recipient\"),\n                }\n            }\n\n            response = requests.post(email_url, headers=headers, json=email_data)\n            result = response.json()\n            yield \"result\", result\n            yield \"status\", \"email_sent\"\n\n        elif input_data.operation == \"track_engagement\":\n            # Get engagement events for the contact\n            from_date = datetime.now() - timedelta(days=input_data.timeframe_days)\n            engagement_url = (\n                f\"{base_url}/crm/v3/objects/contacts/{input_data.contact_id}/engagement\"\n            )\n\n            params = {\"limit\": 100, \"after\": from_date.isoformat()}\n\n            response = requests.get(engagement_url, headers=headers, params=params)\n            engagements = response.json()\n\n            # Process engagement metrics\n            metrics = {\n                \"email_opens\": 0,\n                \"email_clicks\": 0,\n                \"email_replies\": 0,\n                \"last_engagement\": None,\n                \"engagement_score\": 0,\n            }\n\n            for engagement in engagements.get(\"results\", []):\n                eng_type = engagement.get(\"properties\", {}).get(\"hs_engagement_type\")\n                if eng_type == \"EMAIL\":\n                    metrics[\"email_opens\"] += 1\n                elif eng_type == \"EMAIL_CLICK\":\n                    metrics[\"email_clicks\"] += 1\n                elif eng_type == \"EMAIL_REPLY\":\n                    metrics[\"email_replies\"] += 1\n\n                # Update last engagement time\n                eng_time = engagement.get(\"properties\", {}).get(\"hs_timestamp\")\n                if eng_time and (\n                    not metrics[\"last_engagement\"]\n                    or eng_time > metrics[\"last_engagement\"]\n                ):\n                    metrics[\"last_engagement\"] = eng_time\n\n            # Calculate simple engagement score\n            metrics[\"engagement_score\"] = (\n                metrics[\"email_opens\"]\n                + metrics[\"email_clicks\"] * 2\n                + metrics[\"email_replies\"] * 3\n            )\n\n            yield \"result\", metrics\n            yield \"status\", \"engagement_tracked\"", "blocks": [{"id": 1, "label": "def run( self, input_data: Input, *, credentials: HubSpotCredentials, **kwargs ) -> BlockOutput:\nbase_url = \"https://api.hubapi.com\"\nheaders = {\n    \"Authorization\": f\"Bearer {credentials.api_key.get_secret_value()}\",\n    \"Content-Type\": \"application/json\",\n}", "successors": [{"id": 3, "label": "if input_data.operation == \"send_email\":", "successors": [{"id": 4, "label": "    email_url = f\"{base_url}/crm/v3/objects/emails\"\n    email_data = {\n        \"properties\": {\n            \"hs_timestamp\": datetime.now().isoformat(),\n            \"hubspot_owner_id\": \"1\",  # This should be configurable\n            \"hs_email_direction\": \"OUTBOUND\",\n            \"hs_email_status\": \"SEND\",\n            \"hs_email_subject\": input_data.email_data.get(\"subject\"),\n            \"hs_email_text\": input_data.email_data.get(\"content\"),\n            \"hs_email_to_email\": input_data.email_data.get(\"recipient\"),\n        }\n    }\n\n    response = requests.post(email_url, headers=headers, json=email_data)\n    result = response.json()\n    yield \"result\", result\n    yield \"status\", \"email_sent\"", "successors": []}, {"id": 5, "label": "elif input_data.operation == \"track_engagement\":\n    from_date = datetime.now() - timedelta(days=input_data.timeframe_days)\n    engagement_url = (\n        f\"{base_url}/crm/v3/objects/contacts/{input_data.contact_id}/engagement\"\n    )\n\n    params = {\"limit\": 100, \"after\": from_date.isoformat()}\n\n    response = requests.get(engagement_url, headers=headers, params=params)\n    engagements = response.json()\n\n    metrics = {\n        \"email_opens\": 0,\n        \"email_clicks\": 0,\n        \"email_replies\": 0,\n        \"last_engagement\": None,\n        \"engagement_score\": 0,\n    }", "successors": [{"id": 7, "label": "for engagement in engagements.get(\"results\", []):", "successors": [{"id": 8, "label": "    eng_type = engagement.get(\"properties\", {}).get(\"hs_engagement_type\")\n    if eng_type == \"EMAIL\":\n        metrics[\"email_opens\"] += 1\n    elif eng_type == \"EMAIL_CLICK\":\n        metrics[\"email_clicks\"] += 1\n    elif eng_type == \"EMAIL_REPLY\":\n        metrics[\"email_replies\"] += 1\n\n    eng_time = engagement.get(\"properties\", {}).get(\"hs_timestamp\")\n    if eng_time and (\n        not metrics[\"last_engagement\"]\n        or eng_time > metrics[\"last_engagement\"]\n    ):\n        metrics[\"last_engagement\"] = eng_time", "successors": []}]}, {"id": 9, "label": "metrics[\"engagement_score\"] = (\n    metrics[\"email_opens\"]\n    + metrics[\"email_clicks\"] * 2\n    + metrics[\"email_replies\"] * 3\n)\n\nyield \"result\", metrics\nyield \"status\", \"engagement_tracked\"", "successors": []}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 14, "end_line": 31, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: HubSpotCredentialsInput = HubSpotCredentialsField()\n        operation: str = SchemaField(\n            description=\"Operation to perform (send_email, track_engagement)\",\n            default=\"send_email\",\n        )\n        email_data: dict = SchemaField(\n            description=\"Email data including recipient, subject, content\",\n            default={},\n        )\n        contact_id: str = SchemaField(\n            description=\"Contact ID for engagement tracking\", default=\"\"\n        )\n        timeframe_days: int = SchemaField(\n            description=\"Number of days to look back for engagement\",\n            default=30,\n            optional=True,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: HubSpotCredentialsInput = HubSpotCredentialsField()", "successors": [{"id": 3, "label": "    operation: str = SchemaField(\n        description=\"Operation to perform (send_email, track_engagement)\",\n        default=\"send_email\",\n    )\n    email_data: dict = SchemaField(\n        description=\"Email data including recipient, subject, content\",\n        default={},\n    )", "successors": [{"id": 5, "label": "    contact_id: str = SchemaField(\n        description=\"Contact ID for engagement tracking\", default=\"\"\n    )\n    timeframe_days: int = SchemaField(\n        description=\"Number of days to look back for engagement\",\n        default=30,\n        optional=True,\n    )", "successors": []}]}]}]}, {"name": "Output", "type": "class", "start_line": 33, "end_line": 35, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        result: dict = SchemaField(description=\"Operation result\")\n        status: str = SchemaField(description=\"Operation status\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    result: dict = SchemaField(description=\"Operation result\")", "successors": [{"id": 3, "label": "    status: str = SchemaField(description=\"Operation status\")", "successors": []}]}]}], "simplified_code": "class HubSpotEngagementBlock(Block):\n        )\n\n        status: str = SchemaField(description=\"Operation status\")\n\n        )\n\n            yield \"status\", \"engagement_tracked\"", "blocks": [{"id": 1, "label": "class HubSpotEngagementBlock(Block):", "successors": [{"id": 2, "label": "status: str = SchemaField(description=\"Operation status\")", "successors": []}, {"id": 3, "label": "yield \"status\", \"engagement_tracked\"", "successors": []}]}]}], "simplified_code": "from datetime import datetime, timedelta\n\nfrom backend.blocks.hubspot._auth import (\n    HubSpotCredentials,\n    HubSpotCredentialsField,\n    HubSpotCredentialsInput,\n)\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\nfrom backend.util.request import requests\n\n\n            yield \"status\", \"engagement_tracked\"", "blocks": [{"id": 1, "label": "from datetime import datetime, timedelta\nfrom backend.blocks.hubspot._auth import (\n    HubSpotCredentials,\n    HubSpotCredentialsField,\n    HubSpotCredentialsInput,\n)", "successors": [{"id": 3, "label": "from backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField", "successors": [{"id": 5, "label": "from backend.util.request import requests\nyield \"status\", \"engagement_tracked\"", "successors": []}]}]}]}
{"file_name": "38.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 746, "functions": [{"name": "get_node", "type": "function", "start_line": 430, "end_line": 435, "functions": [], "classes": [], "simplified_code": "async def get_node(node_id: str) -> NodeModel:\n    node = await AgentNode.prisma().find_unique_or_raise(\n        where={\"id\": node_id},\n        include=AGENT_NODE_INCLUDE,\n    )\n    return NodeModel.from_db(node)", "blocks": [{"id": 1, "label": "async def get_node(node_id: str) -> NodeModel:\n    node = await AgentNode.prisma().find_unique_or_raise(\n        where={\"id\": node_id},\n        include=AGENT_NODE_INCLUDE,\n    )", "successors": [{"id": 3, "label": "    return NodeModel.from_db(node)", "successors": []}]}]}, {"name": "set_node_webhook", "type": "function", "start_line": 438, "end_line": 450, "functions": [], "classes": [], "simplified_code": "async def set_node_webhook(node_id: str, webhook_id: str | None) -> NodeModel:\n    node = await AgentNode.prisma().update(\n        where={\"id\": node_id},\n        data=(\n            {\"Webhook\": {\"connect\": {\"id\": webhook_id}}}\n            if webhook_id\n            else {\"Webhook\": {\"disconnect\": True}}\n        ),\n        include=AGENT_NODE_INCLUDE,\n    )\n    if not node:\n        raise ValueError(f\"Node #{node_id} not found\")\n    return NodeModel.from_db(node)", "blocks": [{"id": 1, "label": "async def set_node_webhook(node_id: str, webhook_id: str | None) -> NodeModel:\nnode = await AgentNode.prisma().update(\n    where={\"id\": node_id},\n    data=(\n        {\"Webhook\": {\"connect\": {\"id\": webhook_id}}}\n        if webhook_id\n        else {\"Webhook\": {\"disconnect\": True}}\n    ),\n    include=AGENT_NODE_INCLUDE,\n)", "successors": [{"id": 3, "label": "if not node:", "successors": [{"id": 4, "label": "    raise ValueError(f\"Node #{node_id} not found\")", "successors": []}, {"id": 5, "label": "return NodeModel.from_db(node)", "successors": []}]}]}]}, {"name": "get_graphs", "type": "function", "start_line": 453, "end_line": 490, "functions": [], "classes": [], "simplified_code": "async def get_graphs(\n    user_id: str,\n    filter_by: Literal[\"active\", \"template\"] | None = \"active\",\n) -> list[GraphModel]:\n    \"\"\"\n    Retrieves graph metadata objects.\n    Default behaviour is to get all currently active graphs.\n\n    Args:\n        filter_by: An optional filter to either select templates or active graphs.\n        user_id: The ID of the user that owns the graph.\n\n    Returns:\n        list[GraphModel]: A list of objects representing the retrieved graphs.\n    \"\"\"\n    where_clause: AgentGraphWhereInput = {\"userId\": user_id}\n\n    if filter_by == \"active\":\n        where_clause[\"isActive\"] = True\n    elif filter_by == \"template\":\n        where_clause[\"isTemplate\"] = True\n\n    graphs = await AgentGraph.prisma().find_many(\n        where=where_clause,\n        distinct=[\"id\"],\n        order={\"version\": \"desc\"},\n        include=AGENT_GRAPH_INCLUDE,\n    )\n\n    graph_models = []\n    for graph in graphs:\n        try:\n            graph_models.append(GraphModel.from_db(graph))\n        except Exception as e:\n            logger.error(f\"Error processing graph {graph.id}: {e}\")\n            continue\n\n    return graph_models", "blocks": [{"id": 1, "label": "async def get_graphs(user_id: str, filter_by: Literal[\"active\", \"template\"] | None = \"active\",) -> list[GraphModel]:\nwhere_clause: AgentGraphWhereInput = {\"userId\": user_id}", "successors": [{"id": 3, "label": "if filter_by == \"active\":\n    where_clause[\"isActive\"] = True", "successors": [{"id": 7, "label": "graphs = await AgentGraph.prisma().find_many(where=where_clause, distinct=[\"id\"], order={\"version\": \"desc\"}, include=AGENT_GRAPH_INCLUDE,)\ngraph_models = []\nfor graph in graphs:", "successors": [{"id": 9, "label": "    try:", "successors": [{"id": 10, "label": "        graph_models.append(GraphModel.from_db(graph))\n    return graph_models", "successors": []}, {"id": 11, "label": "    except Exception as e:\n        logger.error(f\"Error processing graph {graph.id}: {e}\")\n        continue\n    return graph_models", "successors": []}]}]}]}, {"id": 5, "label": "elif filter_by == \"template\":\n    where_clause[\"isTemplate\"] = True", "successors": [{"id": 7, "label": "graphs = await AgentGraph.prisma().find_many(where=where_clause, distinct=[\"id\"], order={\"version\": \"desc\"}, include=AGENT_GRAPH_INCLUDE,)\ngraph_models = []\nfor graph in graphs:", "successors": [{"id": 9, "label": "    try:", "successors": [{"id": 10, "label": "        graph_models.append(GraphModel.from_db(graph))\n    return graph_models", "successors": []}, {"id": 11, "label": "    except Exception as e:\n        logger.error(f\"Error processing graph {graph.id}: {e}\")\n        continue\n    return graph_models", "successors": []}]}]}]}]}]}, {"name": "get_executions", "type": "function", "start_line": 493, "end_line": 498, "functions": [], "classes": [], "simplified_code": "async def get_executions(user_id: str) -> list[GraphExecution]:\n    executions = await AgentGraphExecution.prisma().find_many(\n        where={\"userId\": user_id},\n        order={\"createdAt\": \"desc\"},\n    )\n    return [GraphExecution.from_db(execution) for execution in executions]", "blocks": [{"id": 1, "label": "executions = await AgentGraphExecution.prisma().find_many(where={\"userId\": user_id}, order={\"createdAt\": \"desc\"},)\nreturn [GraphExecution.from_db(execution) for execution in executions]", "successors": []}]}, {"name": "get_execution", "type": "function", "start_line": 501, "end_line": 505, "functions": [], "classes": [], "simplified_code": "async def get_execution(user_id: str, execution_id: str) -> GraphExecution | None:\n    execution = await AgentGraphExecution.prisma().find_first(\n        where={\"id\": execution_id, \"userId\": user_id}\n    )\n    return GraphExecution.from_db(execution) if execution else None", "blocks": [{"id": 1, "label": "execution = await AgentGraphExecution.prisma().find_first(\n    where={\"id\": execution_id, \"userId\": user_id}\n)\nreturn GraphExecution.from_db(execution) if execution else None", "successors": []}]}, {"name": "get_graph", "type": "function", "start_line": 508, "end_line": 539, "functions": [], "classes": [], "simplified_code": "async def get_graph(\n    graph_id: str,\n    version: int | None = None,\n    template: bool = False,\n    user_id: str | None = None,\n    for_export: bool = False,\n) -> GraphModel | None:\n    \"\"\"\n    Retrieves a graph from the DB.\n    Defaults to the version with `is_active` if `version` is not passed,\n    or the latest version with `is_template` if `template=True`.\n\n    Returns `None` if the record is not found.\n    \"\"\"\n    where_clause: AgentGraphWhereInput = {\n        \"id\": graph_id,\n    }\n    if version is not None:\n        where_clause[\"version\"] = version\n    elif not template:\n        where_clause[\"isActive\"] = True\n\n    # TODO: Fix hack workaround to get adding store agents to work\n    if user_id is not None and not template:\n        where_clause[\"userId\"] = user_id\n\n    graph = await AgentGraph.prisma().find_first(\n        where=where_clause,\n        include=AGENT_GRAPH_INCLUDE,\n        order={\"version\": \"desc\"},\n    )\n    return GraphModel.from_db(graph, for_export) if graph else None", "blocks": [{"id": 1, "label": "# Example input code\nasync def get_graph(\n    graph_id: str,\n    version: int | None = None,\n    template: bool = False,\n    user_id: str | None = None,\n    for_export: bool = False,\n) -> GraphModel | None:\n    \"\"\"\n    Retrieves a graph from the DB.\n    Defaults to the version with `is_active` if `version` is not passed,\n    or the latest version with `is_template` if `template=True`.\n\n    Returns `None` if the record is not found.\n    \"\"\"\n    where_clause: AgentGraphWhereInput = {\n        \"id\": graph_id,\n    }", "successors": [{"id": 2, "label": "if version is not None:\n    where_clause[\"version\"] = version", "successors": [{"id": 7, "label": "graph = await AgentGraph.prisma().find_first(\n    where=where_clause,\n    include=AGENT_GRAPH_INCLUDE,\n    order={\"version\": \"desc\"},\n)\nreturn GraphModel.from_db(graph, for_export) if graph else None", "successors": []}]}, {"id": 4, "label": "elif not template:\n    where_clause[\"isActive\"] = True", "successors": [{"id": 7, "label": "graph = await AgentGraph.prisma().find_first(\n    where=where_clause,\n    include=AGENT_GRAPH_INCLUDE,\n    order={\"version\": \"desc\"},\n)\nreturn GraphModel.from_db(graph, for_export) if graph else None", "successors": []}]}, {"id": 6, "label": "if user_id is not None and not template:\n    where_clause[\"userId\"] = user_id\ngraph = await AgentGraph.prisma().find_first(\n    where=where_clause,\n    include=AGENT_GRAPH_INCLUDE,\n    order={\"version\": \"desc\"},\n)\nreturn GraphModel.from_db(graph, for_export) if graph else None", "successors": []}]}]}, {"name": "set_graph_active_version", "type": "function", "start_line": 542, "end_line": 564, "functions": [], "classes": [], "simplified_code": "async def set_graph_active_version(graph_id: str, version: int, user_id: str) -> None:\n    # Activate the requested version if it exists and is owned by the user.\n    updated_count = await AgentGraph.prisma().update_many(\n        data={\"isActive\": True},\n        where={\n            \"id\": graph_id,\n            \"version\": version,\n            \"userId\": user_id,\n        },\n    )\n    if updated_count == 0:\n        raise Exception(f\"Graph #{graph_id} v{version} not found or not owned by user\")\n\n    # Deactivate all other versions.\n    await AgentGraph.prisma().update_many(\n        data={\"isActive\": False},\n        where={\n            \"id\": graph_id,\n            \"version\": {\"not\": version},\n            \"userId\": user_id,\n            \"isActive\": True,\n        },\n    )", "blocks": [{"id": 1, "label": "async def set_graph_active_version(graph_id: str, version: int, user_id: str) -> None:\nupdated_count = await AgentGraph.prisma().update_many(\n    data={\"isActive\": True},\n    where={\n        \"id\": graph_id,\n        \"version\": version,\n        \"userId\": user_id,\n    },\n)", "successors": [{"id": 3, "label": "if updated_count == 0:\n    raise Exception(f\"Graph #{graph_id} v{version} not found or not owned by user\")", "successors": []}, {"id": 5, "label": "await AgentGraph.prisma().update_many(\n    data={\"isActive\": False},\n    where={\n        \"id\": graph_id,\n        \"version\": {\"not\": version},\n        \"userId\": user_id,\n        \"isActive\": True,\n    },\n)", "successors": []}]}]}, {"name": "get_graph_all_versions", "type": "function", "start_line": 567, "end_line": 577, "functions": [], "classes": [], "simplified_code": "async def get_graph_all_versions(graph_id: str, user_id: str) -> list[GraphModel]:\n    graph_versions = await AgentGraph.prisma().find_many(\n        where={\"id\": graph_id, \"userId\": user_id},\n        order={\"version\": \"desc\"},\n        include=AGENT_GRAPH_INCLUDE,\n    )\n\n    if not graph_versions:\n        return []\n\n    return [GraphModel.from_db(graph) for graph in graph_versions]", "blocks": [{"id": 1, "label": "async def get_graph_all_versions(graph_id: str, user_id: str) -> list[GraphModel]:\n    graph_versions = await AgentGraph.prisma().find_many(where={\"id\": graph_id, \"userId\": user_id}, order={\"version\": \"desc\"}, include=AGENT_GRAPH_INCLUDE,)\nif not graph_versions:", "successors": [{"id": 3, "label": "    return []", "successors": []}, {"id": 4, "label": "return [GraphModel.from_db(graph) for graph in graph_versions]", "successors": []}]}]}, {"name": "delete_graph", "type": "function", "start_line": 580, "end_line": 586, "functions": [], "classes": [], "simplified_code": "async def delete_graph(graph_id: str, user_id: str) -> int:\n    entries_count = await AgentGraph.prisma().delete_many(\n        where={\"id\": graph_id, \"userId\": user_id}\n    )\n    if entries_count:\n        logger.info(f\"Deleted {entries_count} graph entries for Graph #{graph_id}\")\n    return entries_count", "blocks": [{"id": 1, "label": "async def delete_graph(graph_id: str, user_id: str) -> int:\nentries_count = await AgentGraph.prisma().delete_many(\n    where={\"id\": graph_id, \"userId\": user_id}\n)", "successors": [{"id": 3, "label": "if entries_count:", "successors": [{"id": 4, "label": "    logger.info(f\"Deleted {entries_count} graph entries for Graph #{graph_id}\")\nreturn entries_count", "successors": []}, {"id": 5, "label": "return entries_count", "successors": []}]}]}]}, {"name": "create_graph", "type": "function", "start_line": 589, "end_line": 598, "functions": [], "classes": [], "simplified_code": "async def create_graph(graph: Graph, user_id: str) -> GraphModel:\n    async with transaction() as tx:\n        await __create_graph(tx, graph, user_id)\n\n    if created_graph := await get_graph(\n        graph.id, graph.version, graph.is_template, user_id=user_id\n    ):\n        return created_graph\n\n    raise ValueError(f\"Created graph {graph.id} v{graph.version} is not in DB\")", "blocks": [{"id": 1, "label": "async def create_graph(graph: Graph, user_id: str) -> GraphModel:", "successors": [{"id": 2, "label": "async with transaction() as tx:\nawait __create_graph(tx, graph, user_id)", "successors": []}, {"id": 4, "label": "if created_graph := await get_graph( graph.id, graph.version, graph.is_template, user_id=user_id ):", "successors": [{"id": 5, "label": "return created_graph", "successors": []}, {"id": 6, "label": "raise ValueError(f\"Created graph {graph.id} v{graph.version} is not in DB\")", "successors": []}]}]}]}, {"name": "__create_graph", "type": "function", "start_line": 601, "end_line": 644, "functions": [], "classes": [], "simplified_code": "async def __create_graph(tx, graph: Graph, user_id: str):\n    await AgentGraph.prisma(tx).create(\n        data={\n            \"id\": graph.id,\n            \"version\": graph.version,\n            \"name\": graph.name,\n            \"description\": graph.description,\n            \"isTemplate\": graph.is_template,\n            \"isActive\": graph.is_active,\n            \"userId\": user_id,\n        }\n    )\n\n    await asyncio.gather(\n        *[\n            AgentNode.prisma(tx).create(\n                {\n                    \"id\": node.id,\n                    \"agentBlockId\": node.block_id,\n                    \"agentGraphId\": graph.id,\n                    \"agentGraphVersion\": graph.version,\n                    \"constantInput\": json.dumps(node.input_default),\n                    \"metadata\": json.dumps(node.metadata),\n                }\n            )\n            for node in graph.nodes\n        ]\n    )\n\n    await asyncio.gather(\n        *[\n            AgentNodeLink.prisma(tx).create(\n                {\n                    \"id\": str(uuid.uuid4()),\n                    \"sourceName\": link.source_name,\n                    \"sinkName\": link.sink_name,\n                    \"agentNodeSourceId\": link.source_id,\n                    \"agentNodeSinkId\": link.sink_id,\n                    \"isStatic\": link.is_static,\n                }\n            )\n            for link in graph.links\n        ]\n    )", "blocks": [{"id": 1, "label": "async def __create_graph(tx, graph: Graph, user_id: str):\nawait AgentGraph.prisma(tx).create(\n    data={\n        \"id\": graph.id,\n        \"version\": graph.version,\n        \"name\": graph.name,\n        \"description\": graph.description,\n        \"isTemplate\": graph.is_template,\n        \"isActive\": graph.is_active,\n        \"userId\": user_id,\n    }\n)", "successors": [{"id": 3, "label": "await asyncio.gather(\n    *[\n        AgentNode.prisma(tx).create(\n            {\n                \"id\": node.id,\n                \"agentBlockId\": node.block_id,\n                \"agentGraphId\": graph.id,\n                \"agentGraphVersion\": graph.version,\n                \"constantInput\": json.dumps(node.input_default),\n                \"metadata\": json.dumps(node.metadata),\n            }\n        )\n        for node in graph.nodes\n    ]\n)\nawait asyncio.gather(\n    *[\n        AgentNodeLink.prisma(tx).create(\n            {\n                \"id\": str(uuid.uuid4()),\n                \"sourceName\": link.source_name,\n                \"sinkName\": link.sink_name,\n                \"agentNodeSourceId\": link.source_id,\n                \"agentNodeSinkId\": link.sink_id,\n                \"isStatic\": link.is_static,\n            }\n        )\n        for link in graph.links\n    ]\n)", "successors": []}]}]}, {"name": "make_graph_model", "type": "function", "start_line": 650, "end_line": 673, "functions": [], "classes": [], "simplified_code": "def make_graph_model(creatable_graph: Graph, user_id: str) -> GraphModel:\n    \"\"\"\n    Convert a Graph to a GraphModel, setting graph_id and graph_version on all nodes.\n\n    Args:\n        creatable_graph (Graph): The creatable graph to convert.\n        user_id (str): The ID of the user creating the graph.\n\n    Returns:\n        GraphModel: The converted Graph object.\n    \"\"\"\n    # Create a new Graph object, inheriting properties from CreatableGraph\n    return GraphModel(\n        **creatable_graph.model_dump(exclude={\"nodes\"}),\n        user_id=user_id,\n        nodes=[\n            NodeModel(\n                **creatable_node.model_dump(),\n                graph_id=creatable_graph.id,\n                graph_version=creatable_graph.version,\n            )\n            for creatable_node in creatable_graph.nodes\n        ],\n    )", "blocks": [{"id": 1, "label": "def make_graph_model(creatable_graph: Graph, user_id: str) -> GraphModel:\n\"\"\"\n    Convert a Graph to a GraphModel, setting graph_id and graph_version on all nodes.\n\n    Args:\n        creatable_graph (Graph): The creatable graph to convert.\n        user_id (str): The ID of the user creating the graph.\n\n    Returns:\n        GraphModel: The converted Graph object.\n    \"\"\"", "successors": [{"id": 3, "label": "return GraphModel(\n    **creatable_graph.model_dump(exclude={\"nodes\"}),\n    user_id=user_id,\n    nodes=[\n        NodeModel(\n            **creatable_node.model_dump(),\n            graph_id=creatable_graph.id,\n            graph_version=creatable_graph.version,\n        )\n        for creatable_node in creatable_graph.nodes\n    ],\n)", "successors": []}]}]}, {"name": "fix_llm_provider_credentials", "type": "function", "start_line": 676, "end_line": 746, "functions": [], "classes": [], "simplified_code": "async def fix_llm_provider_credentials():\n    \"\"\"Fix node credentials with provider `llm`\"\"\"\n    from backend.integrations.credentials_store import IntegrationCredentialsStore\n\n    from .user import get_user_integrations\n\n    store = IntegrationCredentialsStore()\n\n    broken_nodes = await prisma.get_client().query_raw(\n        \"\"\"\n        SELECT    graph.\"userId\"       user_id,\n                  node.id              node_id,\n                  node.\"constantInput\" node_preset_input\n        FROM      platform.\"AgentNode\"  node\n        LEFT JOIN platform.\"AgentGraph\" graph\n        ON        node.\"agentGraphId\" = graph.id\n        WHERE     node.\"constantInput\"::jsonb->'credentials'->>'provider' = 'llm'\n        ORDER BY  graph.\"userId\";\n        \"\"\"\n    )\n    logger.info(f\"Fixing LLM credential inputs on {len(broken_nodes)} nodes\")\n\n    user_id: str = \"\"\n    user_integrations = None\n    for node in broken_nodes:\n        if node[\"user_id\"] != user_id:\n            # Save queries by only fetching once per user\n            user_id = node[\"user_id\"]\n            user_integrations = await get_user_integrations(user_id)\n        elif not user_integrations:\n            raise RuntimeError(f\"Impossible state while processing node {node}\")\n\n        node_id: str = node[\"node_id\"]\n        node_preset_input: dict = json.loads(node[\"node_preset_input\"])\n        credentials_meta: dict = node_preset_input[\"credentials\"]\n\n        credentials = next(\n            (\n                c\n                for c in user_integrations.credentials\n                if c.id == credentials_meta[\"id\"]\n            ),\n            None,\n        )\n        if not credentials:\n            continue\n        if credentials.type != \"api_key\":\n            logger.warning(\n                f\"User {user_id} credentials {credentials.id} with provider 'llm' \"\n                f\"has invalid type '{credentials.type}'\"\n            )\n            continue\n\n        api_key = credentials.api_key.get_secret_value()\n        if api_key.startswith(\"sk-ant-api03-\"):\n            credentials.provider = credentials_meta[\"provider\"] = \"anthropic\"\n        elif api_key.startswith(\"sk-\"):\n            credentials.provider = credentials_meta[\"provider\"] = \"openai\"\n        elif api_key.startswith(\"gsk_\"):\n            credentials.provider = credentials_meta[\"provider\"] = \"groq\"\n        else:\n            logger.warning(\n                f\"Could not identify provider from key prefix {api_key[:13]}*****\"\n            )\n            continue\n\n        store.update_creds(user_id, credentials)\n        await AgentNode.prisma().update(\n            where={\"id\": node_id},\n            data={\"constantInput\": json.dumps(node_preset_input)},\n        )", "blocks": [{"id": 1, "label": "async def fix_llm_provider_credentials():\n    \"\"\"Fix node credentials with provider `llm`\"\"\"\n    from backend.integrations.credentials_store import IntegrationCredentialsStore\n\n    from .user import get_user_integrations\n\n    store = IntegrationCredentialsStore()\nbroken_nodes = await prisma.get_client().query_raw(\n    \"\"\"\n    SELECT    graph.\"userId\"       user_id,\n              node.id              node_id,\n              node.\"constantInput\" node_preset_input\n    FROM      platform.\"AgentNode\"  node\n    LEFT JOIN platform.\"AgentGraph\" graph\n    ON        node.\"agentGraphId\" = graph.id\n    WHERE     node.\"constantInput\"::jsonb->'credentials'->>'provider' = 'llm'\n    ORDER BY  graph.\"userId\";\n    \"\"\")\nlogger.info(f\"Fixing LLM credential inputs on {len(broken_nodes)} nodes\")", "successors": [{"id": 3, "label": "user_id: str = \"\"\nuser_integrations = None\nfor node in broken_nodes:\nif node[\"user_id\"] != user_id:", "successors": [{"id": 5, "label": "    user_id = node[\"user_id\"]\n    user_integrations = await get_user_integrations(user_id)\nnode_id: str = node[\"node_id\"]\nnode_preset_input: dict = json.loads(node[\"node_preset_input\"])\ncredentials_meta: dict = node_preset_input[\"credentials\"]\n\ncredentials = next(\n    (\n        c\n        for c in user_integrations.credentials\n        if c.id == credentials_meta[\"id\"]\n    ),\n    None,\n)", "successors": [{"id": 9, "label": "if not credentials:", "successors": [{"id": 10, "label": "    continue", "successors": []}, {"id": 11, "label": "if credentials.type != \"api_key\":\n    logger.warning(\n        f\"User {user_id} credentials {credentials.id} with provider 'llm' \"\n        f\"has invalid type '{credentials.type}'\"\n    )\n    continue\napi_key = credentials.api_key.get_secret_value()", "successors": [{"id": 13, "label": "if api_key.startswith(\"sk-ant-api03-\"):\n    credentials.provider = credentials_meta[\"provider\"] = \"anthropic\"\nelif api_key.startswith(\"sk-\"):\n    credentials.provider = credentials_meta[\"provider\"] = \"openai\"\nelif api_key.startswith(\"gsk_\"):\n    credentials.provider = credentials_meta[\"provider\"] = \"groq\"\nelse:\n    logger.warning(\n        f\"Could not identify provider from key prefix {api_key[:13]}*****\"\n    )\n    continue\nstore.update_creds(user_id, credentials)\nawait AgentNode.prisma().update(\n    where={\"id\": node_id},\n    data={\"constantInput\": json.dumps(node_preset_input)},\n)", "successors": []}]}]}]}, {"id": 6, "label": "elif not user_integrations:\n    raise RuntimeError(f\"Impossible state while processing node {node}\")\nnode_id: str = node[\"node_id\"]\nnode_preset_input: dict = json.loads(node[\"node_preset_input\"])\ncredentials_meta: dict = node_preset_input[\"credentials\"]\n\ncredentials = next(\n    (\n        c\n        for c in user_integrations.credentials\n        if c.id == credentials_meta[\"id\"]\n    ),\n    None,\n)", "successors": [{"id": 9, "label": "if not credentials:", "successors": [{"id": 10, "label": "    continue", "successors": []}, {"id": 11, "label": "if credentials.type != \"api_key\":\n    logger.warning(\n        f\"User {user_id} credentials {credentials.id} with provider 'llm' \"\n        f\"has invalid type '{credentials.type}'\"\n    )\n    continue\napi_key = credentials.api_key.get_secret_value()", "successors": [{"id": 13, "label": "if api_key.startswith(\"sk-ant-api03-\"):\n    credentials.provider = credentials_meta[\"provider\"] = \"anthropic\"\nelif api_key.startswith(\"sk-\"):\n    credentials.provider = credentials_meta[\"provider\"] = \"openai\"\nelif api_key.startswith(\"gsk_\"):\n    credentials.provider = credentials_meta[\"provider\"] = \"groq\"\nelse:\n    logger.warning(\n        f\"Could not identify provider from key prefix {api_key[:13]}*****\"\n    )\n    continue\nstore.update_creds(user_id, credentials)\nawait AgentNode.prisma().update(\n    where={\"id\": node_id},\n    data={\"constantInput\": json.dumps(node_preset_input)},\n)", "successors": []}]}]}]}]}]}]}], "classes": [{"name": "Link", "type": "class", "start_line": 26, "end_line": 45, "functions": [{"name": "from_db", "type": "function", "start_line": 34, "end_line": 42, "functions": [], "classes": [], "simplified_code": "    def from_db(link: AgentNodeLink):\n        return Link(\n            id=link.id,\n            source_name=link.sourceName,\n            source_id=link.agentNodeSourceId,\n            sink_name=link.sinkName,\n            sink_id=link.agentNodeSinkId,\n            is_static=link.isStatic,\n        )", "blocks": [{"id": 1, "label": "def from_db(link: AgentNodeLink):\nreturn Link(id=link.id, source_name=link.sourceName, source_id=link.agentNodeSourceId, sink_name=link.sinkName, sink_id=link.agentNodeSinkId, is_static=link.isStatic)", "successors": []}]}, {"name": "__hash__", "type": "function", "start_line": 44, "end_line": 45, "functions": [], "classes": [], "simplified_code": "    def __hash__(self):\n        return hash((self.source_id, self.sink_id, self.source_name, self.sink_name))", "blocks": [{"id": 1, "label": "def __hash__(self):\n    return hash((self.source_id, self.sink_id, self.source_name, self.sink_name))", "successors": []}]}], "classes": [], "simplified_code": "class Link(BaseDbModel):\n    source_id: str\n    sink_id: str\n    source_name: str\n    sink_name: str\n    is_static: bool = False\n\n    @staticmethod\n        )\n\n        return hash((self.source_id, self.sink_id, self.source_name, self.sink_name))", "blocks": [{"id": 1, "label": "class Link(BaseDbModel):\n    source_id: str\n    sink_id: str\n    source_name: str\n    sink_name: str\n    is_static: bool = False", "successors": [{"id": 3, "label": "@staticmethod\n    def generate_unique_id(link):\nreturn hash((link.source_id, link.sink_id, link.source_name, link.sink_name))", "successors": []}, {"id": 5, "label": "def __hash__(self):\nreturn hash((self.source_id, self.sink_id, self.source_name, self.sink_name))", "successors": []}]}]}, {"name": "Node", "type": "class", "start_line": 48, "end_line": 53, "functions": [], "classes": [], "simplified_code": "class Node(BaseDbModel):\n    block_id: str\n    input_default: BlockInput = {}  # dict[input_name, default_value]\n    metadata: dict[str, Any] = {}\n    input_links: list[Link] = []\n    output_links: list[Link] = []", "blocks": [{"id": 1, "label": "class Node(BaseDbModel):", "successors": [{"id": 2, "label": "    block_id: str", "successors": []}, {"id": 3, "label": "    input_default: BlockInput = {}  # dict[input_name, default_value]", "successors": []}, {"id": 4, "label": "    metadata: dict[str, Any] = {}", "successors": []}, {"id": 5, "label": "    input_links: list[Link] = []", "successors": []}, {"id": 6, "label": "    output_links: list[Link] = []", "successors": []}]}]}, {"name": "NodeModel", "type": "class", "start_line": 58, "end_line": 96, "functions": [{"name": "from_db", "type": "function", "start_line": 65, "end_line": 80, "functions": [], "classes": [], "simplified_code": "    def from_db(node: AgentNode):\n        if not node.AgentBlock:\n            raise ValueError(f\"Invalid node {node.id}, invalid AgentBlock.\")\n        obj = NodeModel(\n            id=node.id,\n            block_id=node.AgentBlock.id,\n            input_default=json.loads(node.constantInput, target_type=dict[str, Any]),\n            metadata=json.loads(node.metadata, target_type=dict[str, Any]),\n            graph_id=node.agentGraphId,\n            graph_version=node.agentGraphVersion,\n            webhook_id=node.webhookId,\n            webhook=Webhook.from_db(node.Webhook) if node.Webhook else None,\n        )\n        obj.input_links = [Link.from_db(link) for link in node.Input or []]\n        obj.output_links = [Link.from_db(link) for link in node.Output or []]\n        return obj", "blocks": [{"id": 1, "label": "def from_db(node: AgentNode):", "successors": [{"id": 2, "label": "if not node.AgentBlock:\nraise ValueError(f\"Invalid node {node.id}, invalid AgentBlock.\")", "successors": []}, {"id": 4, "label": "obj = NodeModel(\n    id=node.id,\n    block_id=node.AgentBlock.id,\n    input_default=json.loads(node.constantInput, target_type=dict[str, Any]),\n    metadata=json.loads(node.metadata, target_type=dict[str, Any]),\n    graph_id=node.agentGraphId,\n    graph_version=node.agentGraphVersion,\n    webhook_id=node.webhookId,\n    webhook=Webhook.from_db(node.Webhook) if node.Webhook else None,\n)\nobj.input_links = [Link.from_db(link) for link in node.Input or []]", "successors": [{"id": 6, "label": "obj.output_links = [Link.from_db(link) for link in node.Output or []]\nreturn obj", "successors": []}]}]}]}, {"name": "is_triggered_by_event_type", "type": "function", "start_line": 82, "end_line": 96, "functions": [], "classes": [], "simplified_code": "    def is_triggered_by_event_type(self, event_type: str) -> bool:\n        if not (block := get_block(self.block_id)):\n            raise ValueError(f\"Block #{self.block_id} not found for node #{self.id}\")\n        if not block.webhook_config:\n            raise TypeError(\"This method can't be used on non-webhook blocks\")\n        if not block.webhook_config.event_filter_input:\n            return True\n        event_filter = self.input_default.get(block.webhook_config.event_filter_input)\n        if not event_filter:\n            raise ValueError(f\"Event filter is not configured on node #{self.id}\")\n        return event_type in [\n            block.webhook_config.event_format.format(event=k)\n            for k in event_filter\n            if event_filter[k] is True\n        ]", "blocks": [{"id": 1, "label": "def is_triggered_by_event_type(self, event_type: str) -> bool:\nif not (block := get_block(self.block_id)):", "successors": [{"id": 3, "label": "raise ValueError(f\"Block #{self.block_id} not found for node #{self.id}\")", "successors": []}, {"id": 4, "label": "if not block.webhook_config:", "successors": [{"id": 5, "label": "raise TypeError(\"This method can't be used on non-webhook blocks\")", "successors": []}, {"id": 6, "label": "if not block.webhook_config.event_filter_input:", "successors": [{"id": 7, "label": "return True", "successors": []}, {"id": 8, "label": "event_filter = self.input_default.get(block.webhook_config.event_filter_input)\nif not event_filter:", "successors": [{"id": 10, "label": "raise ValueError(f\"Event filter is not configured on node #{self.id}\")", "successors": []}, {"id": 11, "label": "return event_type in [\n            block.webhook_config.event_format.format(event=k)\n            for k in event_filter\n            if event_filter[k] is True\n        ]", "successors": []}]}]}]}]}]}], "classes": [], "simplified_code": "class NodeModel(Node):\n    graph_id: str\n    graph_version: int\n\n    webhook: Optional[Webhook] = None\n\n    @staticmethod\n        return obj\n\n        ]", "blocks": [{"id": 1, "label": "class NodeModel(Node):\n    graph_id: str\n    graph_version: int\n    webhook: Optional[Webhook] = None\n@staticmethod\ndef from_dict(obj: Dict[str, Any]) -> 'NodeModel':\n    node = NodeModel(\n        graph_id=obj['graph_id'],\n        graph_version=obj.get('graph_version', 1),\n    )", "successors": [{"id": 3, "label": "    if 'webhook' in obj:\n        node.webhook = Webhook.from_dict(obj['webhook'])\nreturn node", "successors": []}, {"id": 5, "label": "return node", "successors": []}]}]}, {"name": "GraphExecution", "type": "class", "start_line": 103, "end_line": 139, "functions": [{"name": "from_db", "type": "function", "start_line": 114, "end_line": 139, "functions": [], "classes": [], "simplified_code": "    def from_db(execution: AgentGraphExecution):\n        now = datetime.now(timezone.utc)\n        start_time = execution.startedAt or execution.createdAt\n        end_time = execution.updatedAt or now\n        duration = (end_time - start_time).total_seconds()\n        total_run_time = duration\n\n        try:\n            stats = json.loads(execution.stats or \"{}\", target_type=dict[str, Any])\n        except ValueError:\n            stats = {}\n\n        duration = stats.get(\"walltime\", duration)\n        total_run_time = stats.get(\"nodes_walltime\", total_run_time)\n\n        return GraphExecution(\n            id=execution.id,\n            execution_id=execution.id,\n            started_at=start_time,\n            ended_at=end_time,\n            duration=duration,\n            total_run_time=total_run_time,\n            status=ExecutionStatus(execution.executionStatus),\n            graph_id=execution.agentGraphId,\n            graph_version=execution.agentGraphVersion,\n        )", "blocks": [{"id": 1, "label": "def from_db(execution: AgentGraphExecution):\nnow = datetime.now(timezone.utc)\nstart_time = execution.startedAt or execution.createdAt\nend_time = execution.updatedAt or now\nduration = (end_time - start_time).total_seconds()\ntotal_run_time = duration", "successors": [{"id": 3, "label": "try:", "successors": [{"id": 4, "label": "stats = json.loads(execution.stats or \"{}\", target_type=dict[str, Any])\nduration = stats.get(\"walltime\", duration)\ntotal_run_time = stats.get(\"nodes_walltime\", total_run_time)", "successors": [{"id": 7, "label": "return GraphExecution(\n    id=execution.id,\n    execution_id=execution.id,\n    started_at=start_time,\n    ended_at=end_time,\n    duration=duration,\n    total_run_time=total_run_time,\n    status=ExecutionStatus(execution.executionStatus),\n    graph_id=execution.agentGraphId,\n    graph_version=execution.agentGraphVersion,\n)", "successors": []}]}, {"id": 5, "label": "except ValueError:\n    stats = {}\nduration = stats.get(\"walltime\", duration)\ntotal_run_time = stats.get(\"nodes_walltime\", total_run_time)", "successors": [{"id": 7, "label": "return GraphExecution(\n    id=execution.id,\n    execution_id=execution.id,\n    started_at=start_time,\n    ended_at=end_time,\n    duration=duration,\n    total_run_time=total_run_time,\n    status=ExecutionStatus(execution.executionStatus),\n    graph_id=execution.agentGraphId,\n    graph_version=execution.agentGraphVersion,\n)", "successors": []}]}]}]}]}], "classes": [], "simplified_code": "class GraphExecution(BaseDbModel):\n    execution_id: str\n    started_at: datetime\n    ended_at: datetime\n    duration: float\n    total_run_time: float\n    status: ExecutionStatus\n    graph_id: str\n    graph_version: int\n\n    @staticmethod\n        )", "blocks": [{"id": 1, "label": "class GraphExecution(BaseDbModel):\nexecution_id: str\nstarted_at: datetime\nended_at: datetime\nduration: float\ntotal_run_time: float\nstatus: ExecutionStatus\ngraph_id: str\ngraph_version: int", "successors": [{"id": 3, "label": "@staticmethod", "successors": []}]}]}, {"name": "Graph", "type": "class", "start_line": 142, "end_line": 246, "functions": [{"name": "input_schema", "type": "function", "start_line": 153, "end_line": 163, "functions": [], "classes": [], "simplified_code": "    def input_schema(self) -> dict[str, Any]:\n        return self._generate_schema(\n            AgentInputBlock.Input,\n            [\n                node.input_default\n                for node in self.nodes\n                if (b := get_block(node.block_id))\n                and b.block_type == BlockType.INPUT\n                and \"name\" in node.input_default\n            ],\n        )", "blocks": [{"id": 1, "label": "def input_schema(self) -> dict[str, Any]:\nreturn self._generate_schema(AgentInputBlock.Input, [node.input_default for node in self.nodes if (b := get_block(node.block_id)) and b.block_type == BlockType.INPUT and \"name\" in node.input_default], )", "successors": []}]}, {"name": "output_schema", "type": "function", "start_line": 167, "end_line": 177, "functions": [], "classes": [], "simplified_code": "    def output_schema(self) -> dict[str, Any]:\n        return self._generate_schema(\n            AgentOutputBlock.Input,\n            [\n                node.input_default\n                for node in self.nodes\n                if (b := get_block(node.block_id))\n                and b.block_type == BlockType.OUTPUT\n                and \"name\" in node.input_default\n            ],\n        )", "blocks": [{"id": 1, "label": "def output_schema(self) -> dict[str, Any]:\nreturn self._generate_schema(AgentOutputBlock.Input, [\n    node.input_default\n    for node in self.nodes\n    if (b := get_block(node.block_id))\n    and b.block_type == BlockType.OUTPUT\n    and \"name\" in node.input_default\n],\n)", "successors": []}]}, {"name": "_generate_schema", "type": "function", "start_line": 180, "end_line": 204, "functions": [], "classes": [], "simplified_code": "    def _generate_schema(\n        type_class: Type[AgentInputBlock.Input] | Type[AgentOutputBlock.Input],\n        data: list[dict],\n    ) -> dict[str, Any]:\n        props = []\n        for p in data:\n            try:\n                props.append(type_class(**p))\n            except Exception as e:\n                logger.warning(f\"Invalid {type_class}: {p}, {e}\")\n\n        return {\n            \"type\": \"object\",\n            \"properties\": {\n                p.name: {\n                    \"secret\": p.secret,\n                    \"advanced\": p.advanced,\n                    \"title\": p.title or p.name,\n                    **({\"description\": p.description} if p.description else {}),\n                    **({\"default\": p.value} if p.value is not None else {}),\n                }\n                for p in props\n            },\n            \"required\": [p.name for p in props if p.value is None],\n        }", "blocks": [{"id": 1, "label": "def _generate_schema(type_class: Type[AgentInputBlock.Input] | Type[AgentOutputBlock.Input], data: list[dict]) -> dict[str, Any]:\nprops = []", "successors": [{"id": 3, "label": "for p in data:", "successors": [{"id": 4, "label": "try:", "successors": [{"id": 5, "label": "props.append(type_class(**p))\nreturn {\n    \"type\": \"object\",\n    \"properties\": {\n        p.name: {\n            \"secret\": p.secret,\n            \"advanced\": p.advanced,\n            \"title\": p.title or p.name,\n            **({\"description\": p.description} if p.description else {}),\n            **({\"default\": p.value} if p.value is not None else {}),\n        }\n        for p in props\n    },\n    \"required\": [p.name for p in props if p.value is None],\n}", "successors": []}, {"id": 6, "label": "except Exception as e:\nlogger.warning(f\"Invalid {type_class}: {p}, {e}\")", "successors": [{"id": 8, "label": "return {\n    \"type\": \"object\",\n    \"properties\": {\n        p.name: {\n            \"secret\": p.secret,\n            \"advanced\": p.advanced,\n            \"title\": p.title or p.name,\n            **({\"description\": p.description} if p.description else {}),\n            **({\"default\": p.value} if p.value is not None else {}),\n        }\n        for p in props\n    },\n    \"required\": [p.name for p in props if p.value is None],\n}", "successors": []}]}]}]}]}]}], "classes": [], "simplified_code": "class Graph(BaseDbModel):\n    version: int = 1\n    is_active: bool = True\n    is_template: bool = False\n    name: str\n    description: str\n    nodes: list[Node] = []\n    links: list[Link] = []\n\n    @computed_field\n    @property\n        )\n\n    @computed_field\n    @property\n        )\n\n    @staticmethod\n        }\n\n\nclass GraphModel(Graph):\n    user_id: str\n    nodes: list[NodeModel] = []  # type: ignore\n\n    @property\n    def starting_nodes(self) -> list[Node]:\n        outbound_nodes = {link.sink_id for link in self.links}\n        input_nodes = {\n            v.id\n            for v in self.nodes\n            if (b := get_block(v.block_id)) and b.block_type == BlockType.INPUT\n        }\n        return [\n            node\n            for node in self.nodes\n            if node.id not in outbound_nodes or node.id in input_nodes\n        ]\n\n    def reassign_ids(self, user_id: str, reassign_graph_id: bool = False):\n        \"\"\"\n        Reassigns all IDs in the graph to new UUIDs.\n        This method can be used before storing a new graph to the database.\n        \"\"\"\n\n        # Reassign Graph ID\n        id_map = {node.id: str(uuid.uuid4()) for node in self.nodes}\n        if reassign_graph_id:\n            self.id = str(uuid.uuid4())\n\n        # Reassign Node IDs\n        for node in self.nodes:\n            node.id = id_map[node.id]\n\n        # Reassign Link IDs\n        for link in self.links:\n            link.source_id = id_map[link.source_id]\n            link.sink_id = id_map[link.sink_id]\n\n        # Reassign User IDs for agent blocks\n        for node in self.nodes:", "blocks": [{"id": 1, "label": "class Graph(BaseDbModel):", "successors": [{"id": 2, "label": "version: int = 1\nis_active: bool = True\nis_template: bool = False\nname: str\ndescription: str\nnodes: list[Node] = []\nlinks: list[Link] = []", "successors": []}, {"id": 3, "label": "@computed_field\n@property", "successors": []}, {"id": 4, "label": "@staticmethod", "successors": []}]}]}, {"name": "GraphModel", "type": "class", "start_line": 207, "end_line": 226, "functions": [{"name": "starting_nodes", "type": "function", "start_line": 212, "end_line": 224, "functions": [], "classes": [], "simplified_code": "    def starting_nodes(self) -> list[Node]:\n        outbound_nodes = {link.sink_id for link in self.links}\n        input_nodes = {\n            v.id\n            for v in self.nodes\n            if (b := get_block(v.block_id)) and b.block_type == BlockType.INPUT\n        }\n        return [\n            node\n            for node in self.nodes\n            if node.id not in outbound_nodes or node.id in input_nodes\n        ]\n", "blocks": [{"id": 1, "label": "def starting_nodes(self) -> list[Node]:\noutbound_nodes = {link.sink_id for link in self.links}", "successors": [{"id": 3, "label": "input_nodes = { v.id for v in self.nodes if (b := get_block(v.block_id)) and b.block_type == BlockType.INPUT }\nreturn [ node for node in self.nodes if node.id not in outbound_nodes or node.id in input_nodes ]", "successors": []}]}]}, {"name": "reassign_ids", "type": "function", "start_line": 225, "end_line": 252, "functions": [], "classes": [], "simplified_code": "    def reassign_ids(self, user_id: str, reassign_graph_id: bool = False):\n        \"\"\"\n        Reassigns all IDs in the graph to new UUIDs.\n        This method can be used before storing a new graph to the database.\n        \"\"\"\n\n        # Reassign Graph ID\n        id_map = {node.id: str(uuid.uuid4()) for node in self.nodes}\n        if reassign_graph_id:\n            self.id = str(uuid.uuid4())\n\n        # Reassign Node IDs\n        for node in self.nodes:\n            node.id = id_map[node.id]\n\n        # Reassign Link IDs\n        for link in self.links:\n            link.source_id = id_map[link.source_id]\n            link.sink_id = id_map[link.sink_id]\n\n        # Reassign User IDs for agent blocks\n        for node in self.nodes:\n            if node.block_id != AgentExecutorBlock().id:\n                continue\n            node.input_default[\"user_id\"] = user_id\n            node.input_default.setdefault(\"data\", {})\n\n        self.validate_graph()", "blocks": [{"id": 1, "label": "def reassign_ids(self, user_id: str, reassign_graph_id: bool = False):\nid_map = {node.id: str(uuid.uuid4()) for node in self.nodes}", "successors": [{"id": 3, "label": "if reassign_graph_id:", "successors": [{"id": 4, "label": "self.id = str(uuid.uuid4())", "successors": []}, {"id": 5, "label": "# Reassign Node IDs\nfor node in self.nodes:\n    node.id = id_map[node.id]\n# Reassign Link IDs\nfor link in self.links:\n    link.source_id = id_map[link.source_id]\n    link.sink_id = id_map[link.sink_id]", "successors": [{"id": 7, "label": "for node in self.nodes:\n    if node.block_id != AgentExecutorBlock().id:\n        continue", "successors": [{"id": 8, "label": "node.input_default[\"user_id\"] = user_id\nnode.input_default.setdefault(\"data\", {})\nself.validate_graph()", "successors": []}]}, {"id": 9, "label": "self.validate_graph()", "successors": []}]}]}]}]}], "classes": [], "simplified_code": "class GraphModel(Graph):\n    user_id: str\n    nodes: list[NodeModel] = []  # type: ignore\n\n    @property\n", "blocks": [{"id": 1, "label": "class GraphModel(Graph):", "successors": [{"id": 2, "label": "user_id: str\nnodes: list[NodeModel] = []  # type: ignore", "successors": []}, {"id": 3, "label": "@property", "successors": []}]}]}], "simplified_code": "import asyncio\nimport logging\nimport uuid\nfrom collections import defaultdict\nfrom datetime import datetime, timezone\nfrom typing import Any, Literal, Optional, Type\n\nimport prisma\nfrom prisma.models import AgentGraph, AgentGraphExecution, AgentNode, AgentNodeLink\nfrom prisma.types import AgentGraphWhereInput\nfrom pydantic.fields import computed_field\n\nfrom backend.blocks.agent import AgentExecutorBlock\nfrom backend.blocks.basic import AgentInputBlock, AgentOutputBlock\nfrom backend.util import json\n\nfrom .block import BlockInput, BlockType, get_block, get_blocks\nfrom .db import BaseDbModel, transaction\nfrom .execution import ExecutionStatus\nfrom .includes import AGENT_GRAPH_INCLUDE, AGENT_NODE_INCLUDE\nfrom .integrations import Webhook\n\nlogger = logging.getLogger(__name__)\n\n\n        return hash((self.source_id, self.sink_id, self.source_name, self.sink_name))\n\n\n    output_links: list[Link] = []\n\n    webhook_id: Optional[str] = None\n\n\n        ]\n\n\n# Fix 2-way reference Node <-> Webhook\nWebhook.model_rebuild()\n\n\n        )\n\n\n        for node in self.nodes:\n            if node.block_id != AgentExecutorBlock().id:\n                continue\n            node.input_default[\"user_id\"] = user_id\n            node.input_default.setdefault(\"data\", {})\n\n        self.validate_graph()\n\n    def validate_graph(self, for_run: bool = False):\n        def sanitize(name):\n            return name.split(\"_#_\")[0].split(\"_@_\")[0].split(\"_$_\")[0]\n\n        input_links = defaultdict(list)\n        for link in self.links:\n            input_links[link.sink_id].append(link)\n\n        # Nodes: required fields are filled or connected and dependencies are satisfied\n        for node in self.nodes:\n            block = get_block(node.block_id)\n            if block is None:\n                raise ValueError(f\"Invalid block {node.block_id} for node #{node.id}\")\n\n            provided_inputs = set(\n                [sanitize(name) for name in node.input_default]\n                + [sanitize(link.sink_name) for link in input_links.get(node.id, [])]\n            )\n            for name in block.input_schema.get_required_fields():\n                if (\n                    name not in provided_inputs\n                    and not (\n                        name == \"payload\"\n                        and block.block_type\n                        in (BlockType.WEBHOOK, BlockType.WEBHOOK_MANUAL)\n                    )\n                    and (\n                        for_run  # Skip input completion validation, unless when executing.\n                        or block.block_type == BlockType.INPUT\n                        or block.block_type == BlockType.OUTPUT\n                        or block.block_type == BlockType.AGENT\n                    )\n                ):\n                    raise ValueError(\n                        f\"Node {block.name} #{node.id} required input missing: `{name}`\"\n                    )\n\n            # Get input schema properties and check dependencies\n            input_schema = block.input_schema.model_fields\n            required_fields = block.input_schema.get_required_fields()\n\n            def has_value(name):\n                return (\n                    node is not None\n                    and name in node.input_default\n                    and node.input_default[name] is not None\n                    and str(node.input_default[name]).strip() != \"\"\n                ) or (name in input_schema and input_schema[name].default is not None)\n\n            # Validate dependencies between fields\n            for field_name, field_info in input_schema.items():\n                # Apply input dependency validation only on run & field with depends_on\n                json_schema_extra = field_info.json_schema_extra or {}\n                dependencies = json_schema_extra.get(\"depends_on\", [])\n                if not for_run or not dependencies:\n                    continue\n\n                # Check if dependent field has value in input_default\n                field_has_value = has_value(field_name)\n                field_is_required = field_name in required_fields\n\n                # Check for missing dependencies when dependent field is present\n                missing_deps = [dep for dep in dependencies if not has_value(dep)]\n                if missing_deps and (field_has_value or field_is_required):\n                    raise ValueError(\n                        f\"Node {block.name} #{node.id}: Field `{field_name}` requires [{', '.join(missing_deps)}] to be set\"\n                    )\n\n        node_map = {v.id: v for v in self.nodes}\n\n        def is_static_output_block(nid: str) -> bool:\n            bid = node_map[nid].block_id\n            b = get_block(bid)\n            return b.static_output if b else False\n\n        # Links: links are connected and the connected pin data type are compatible.\n        for link in self.links:\n            source = (link.source_id, link.source_name)\n            sink = (link.sink_id, link.sink_name)\n            suffix = f\"Link {source} <-> {sink}\"\n\n            for i, (node_id, name) in enumerate([source, sink]):\n                node = node_map.get(node_id)\n                if not node:\n                    raise ValueError(\n                        f\"{suffix}, {node_id} is invalid node id, available nodes: {node_map.keys()}\"\n                    )\n\n                block = get_block(node.block_id)\n                if not block:\n                    blocks = {v().id: v().name for v in get_blocks().values()}\n                    raise ValueError(\n                        f\"{suffix}, {node.block_id} is invalid block id, available blocks: {blocks}\"\n                    )\n\n                sanitized_name = sanitize(name)\n                vals = node.input_default\n                if i == 0:\n                    fields = (\n                        block.output_schema.get_fields()\n                        if block.block_type != BlockType.AGENT\n                        else vals.get(\"output_schema\", {}).get(\"properties\", {}).keys()\n                    )\n                else:\n                    fields = (\n                        block.input_schema.get_fields()\n                        if block.block_type != BlockType.AGENT\n                        else vals.get(\"input_schema\", {}).get(\"properties\", {}).keys()\n                    )\n                if sanitized_name not in fields:\n                    fields_msg = f\"Allowed fields: {fields}\"\n                    raise ValueError(f\"{suffix}, `{name}` invalid, {fields_msg}\")\n\n            if is_static_output_block(link.source_id):\n                link.is_static = True  # Each value block output should be static.\n\n    @staticmethod\n    def from_db(graph: AgentGraph, for_export: bool = False):\n        return GraphModel(\n            id=graph.id,\n            user_id=graph.userId,\n            version=graph.version,\n            is_active=graph.isActive,\n            is_template=graph.isTemplate,\n            name=graph.name or \"\",\n            description=graph.description or \"\",\n            nodes=[\n                NodeModel.from_db(GraphModel._process_node(node, for_export))\n                for node in graph.AgentNodes or []\n            ],\n            links=list(\n                {\n                    Link.from_db(link)\n                    for node in graph.AgentNodes or []\n                    for link in (node.Input or []) + (node.Output or [])\n                }\n            ),\n        )\n\n    @staticmethod\n    def _process_node(node: AgentNode, for_export: bool) -> AgentNode:\n        if for_export:\n            # Remove credentials from node input\n            if node.constantInput:\n                constant_input = json.loads(\n                    node.constantInput, target_type=dict[str, Any]\n                )\n                constant_input = GraphModel._hide_node_input_credentials(constant_input)\n                node.constantInput = json.dumps(constant_input)\n\n            # Remove webhook info\n            node.webhookId = None\n            node.Webhook = None\n\n        return node\n\n    @staticmethod\n    def _hide_node_input_credentials(input_data: dict[str, Any]) -> dict[str, Any]:\n        sensitive_keys = [\"credentials\", \"api_key\", \"password\", \"token\", \"secret\"]\n        result = {}\n        for key, value in input_data.items():\n            if isinstance(value, dict):\n                result[key] = GraphModel._hide_node_input_credentials(value)\n            elif isinstance(value, str) and any(\n                sensitive_key in key.lower() for sensitive_key in sensitive_keys\n            ):\n                # Skip this key-value pair in the result\n                continue\n            else:\n                result[key] = value\n        return result\n\n\n# --------------------- CRUD functions --------------------- #\n\n\n    return NodeModel.from_db(node)\n\n\n    return NodeModel.from_db(node)\n\n\n    return graph_models\n\n\n    return [GraphExecution.from_db(execution) for execution in executions]\n\n\n    return GraphExecution.from_db(execution) if execution else None\n\n\n    return GraphModel.from_db(graph, for_export) if graph else None\n\n\n    )\n\n\n    return [GraphModel.from_db(graph) for graph in graph_versions]\n\n\n    return entries_count\n\n\n    raise ValueError(f\"Created graph {graph.id} v{graph.version} is not in DB\")\n\n\n    )\n\n\n# ------------------------ UTILITIES ------------------------ #\n\n\n    )\n\n\n        )", "blocks": [{"id": 1, "label": "for node in self.nodes:", "successors": [{"id": 2, "label": "if node.block_id != AgentExecutorBlock().id:", "successors": [{"id": 3, "label": "continue", "successors": []}, {"id": 4, "label": "node.input_default[\"user_id\"] = user_id\nnode.input_default.setdefault(\"data\", {})", "successors": []}]}]}]}
{"file_name": "39.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 254, "functions": [{"name": "DiscordCredentialsField", "type": "function", "start_line": 22, "end_line": 23, "functions": [], "classes": [], "simplified_code": "def DiscordCredentialsField() -> DiscordCredentials:\n    return CredentialsField(description=\"Discord bot token\")", "blocks": [{"id": 1, "label": "def DiscordCredentialsField() -> DiscordCredentials:\n    return CredentialsField(description=\"Discord bot token\")", "successors": []}]}], "classes": [{"name": "ReadDiscordMessagesBlock", "type": "class", "start_line": 41, "end_line": 161, "functions": [{"name": "__init__", "type": "function", "start_line": 56, "end_line": 79, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"df06086a-d5ac-4abb-9996-2ad0acb2eff7\",\n            input_schema=ReadDiscordMessagesBlock.Input,  # Assign input schema\n            output_schema=ReadDiscordMessagesBlock.Output,  # Assign output schema\n            description=\"Reads messages from a Discord channel using a bot token.\",\n            categories={BlockCategory.SOCIAL},\n            test_input={\n                \"continuous_read\": False,\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\n                    \"message_content\",\n                    \"Hello!\\n\\nFile from user: example.txt\\nContent: This is the content of the file.\",\n                ),\n                (\"channel_name\", \"general\"),\n                (\"username\", \"test_user\"),\n            ],\n            test_mock={\n                \"run_bot\": lambda token: asyncio.Future()  # Create a Future object for mocking\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"df06086a-d5ac-4abb-9996-2ad0acb2eff7\",\n    input_schema=ReadDiscordMessagesBlock.Input,\n    output_schema=ReadDiscordMessagesBlock.Output,\n    description=\"Reads messages from a Discord channel using a bot token.\",\n    categories={BlockCategory.SOCIAL},\n    test_input={\n        \"continuous_read\": False,\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\n            \"message_content\",\n            \"Hello!\\n\\nFile from user: example.txt\\nContent: This is the content of the file.\",\n        ),\n        (\"channel_name\", \"general\"),\n        (\"username\", \"test_user\"),\n    ],\n    test_mock={\n        \"run_bot\": lambda token: asyncio.Future()\n    },\n)", "successors": []}]}, {"name": "run_bot", "type": "function", "start_line": 81, "end_line": 114, "functions": [{"name": "on_ready", "type": "function", "start_line": 92, "end_line": 93, "functions": [], "classes": [], "simplified_code": "        async def on_ready():\n            print(f\"Logged in as {client.user}\")", "blocks": [{"id": 1, "label": "async def on_ready():\n    print(f\"Logged in as {client.user}\")", "successors": []}]}, {"name": "on_message", "type": "function", "start_line": 96, "end_line": 112, "functions": [], "classes": [], "simplified_code": "        async def on_message(message):\n            if message.author == client.user:\n                return\n\n            self.output_data = message.content\n            self.channel_name = message.channel.name\n            self.username = message.author.name\n\n            if message.attachments:\n                attachment = message.attachments[0]  # Process the first attachment\n                if attachment.filename.endswith((\".txt\", \".py\")):\n                    async with aiohttp.ClientSession() as session:\n                        async with session.get(attachment.url) as response:\n                            file_content = await response.text()\n                            self.output_data += f\"\\n\\nFile from user: {attachment.filename}\\nContent: {file_content}\"\n\n            await client.close()", "blocks": [{"id": 1, "label": "async def on_message(message):", "successors": [{"id": 2, "label": "if message.author == client.user:\nreturn", "successors": []}, {"id": 4, "label": "self.output_data = message.content\nself.channel_name = message.channel.name\nself.username = message.author.name", "successors": [{"id": 5, "label": "if message.attachments:\nattachment = message.attachments[0]", "successors": [{"id": 7, "label": "if attachment.filename.endswith((\".txt\", \".py\")):\nasync with aiohttp.ClientSession() as session:", "successors": [{"id": 9, "label": "async with session.get(attachment.url) as response:\nfile_content = await response.text()\nself.output_data += f\"\\n\\nFile from user: {attachment.filename}\\nContent: {file_content}\"", "successors": []}]}]}, {"id": 11, "label": "await client.close()", "successors": []}]}]}]}], "classes": [], "simplified_code": "    async def run_bot(self, token: SecretStr):\n        intents = discord.Intents.default()\n        intents.message_content = True\n\n        client = discord.Client(intents=intents)\n\n        self.output_data = None\n        self.channel_name = None\n        self.username = None\n\n        @client.event\n            print(f\"Logged in as {client.user}\")\n\n        @client.event\n            await client.close()\n\n        await client.start(token.get_secret_value())", "blocks": [{"id": 1, "label": "async def run_bot(self, token: SecretStr):\nintents = discord.Intents.default()\nintents.message_content = True\nclient = discord.Client(intents=intents)\nself.output_data = None\nself.channel_name = None\nself.username = None", "successors": [{"id": 3, "label": "@client.event\nasync def on_ready():\n    print(f\"Logged in as {client.user}\")\n@client.event\nasync def on_disconnect():\n    await client.close()", "successors": [{"id": 5, "label": "await client.start(token.get_secret_value())", "successors": []}]}]}]}, {"name": "run", "type": "function", "start_line": 116, "end_line": 122, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        while True:\n            for output_name, output_value in self.__run(input_data, credentials):\n                yield output_name, output_value\n            break", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs):", "successors": [{"id": 2, "label": "while True:", "successors": [{"id": 3, "label": "    for output_name, output_value in self.__run(input_data, credentials):", "successors": [{"id": 4, "label": "        yield output_name, output_value", "successors": [{"id": 3, "label": "    for output_name, output_value in self.__run(input_data, credentials):", "successors": []}, {"id": 5, "label": "break", "successors": []}]}]}]}]}]}, {"name": "__run", "type": "function", "start_line": 124, "end_line": 161, "functions": [], "classes": [], "simplified_code": "    def __run(self, input_data: Input, credentials: APIKeyCredentials) -> BlockOutput:\n        try:\n            loop = asyncio.get_event_loop()\n            future = self.run_bot(credentials.api_key)\n\n            # If it's a Future (mock), set the result\n            if isinstance(future, asyncio.Future):\n                future.set_result(\n                    {\n                        \"output_data\": \"Hello!\\n\\nFile from user: example.txt\\nContent: This is the content of the file.\",\n                        \"channel_name\": \"general\",\n                        \"username\": \"test_user\",\n                    }\n                )\n\n            result = loop.run_until_complete(future)\n\n            # For testing purposes, use the mocked result\n            if isinstance(result, dict):\n                self.output_data = result.get(\"output_data\")\n                self.channel_name = result.get(\"channel_name\")\n                self.username = result.get(\"username\")\n\n            if (\n                self.output_data is None\n                or self.channel_name is None\n                or self.username is None\n            ):\n                raise ValueError(\"No message, channel name, or username received.\")\n\n            yield \"message_content\", self.output_data\n            yield \"channel_name\", self.channel_name\n            yield \"username\", self.username\n\n        except discord.errors.LoginFailure as login_err:\n            raise ValueError(f\"Login error occurred: {login_err}\")\n        except Exception as e:\n            raise ValueError(f\"An error occurred: {e}\")", "blocks": [{"id": 1, "label": "try:\n    loop = asyncio.get_event_loop()\n    future = self.run_bot(credentials.api_key)", "successors": [{"id": 3, "label": "if isinstance(future, asyncio.Future):", "successors": [{"id": 4, "label": "    future.set_result({\n        \"output_data\": \"Hello!\\n\\nFile from user: example.txt\\nContent: This is the content of the file.\",\n        \"channel_name\": \"general\",\n        \"username\": \"test_user\",\n    })\nresult = loop.run_until_complete(future)", "successors": [{"id": 7, "label": "if isinstance(result, dict):\n    self.output_data = result.get(\"output_data\")\n    self.channel_name = result.get(\"channel_name\")\n    self.username = result.get(\"username\")", "successors": [{"id": 10, "label": "if self.output_data is None or self.channel_name is None or self.username is None:\n    raise ValueError(\"No message, channel name, or username received.\")", "successors": [{"id": 12, "label": "yield \"message_content\", self.output_data\nyield \"channel_name\", self.channel_name\nyield \"username\", self.username", "successors": []}]}]}]}, {"id": 5, "label": "\nresult = loop.run_until_complete(future)", "successors": [{"id": 7, "label": "if isinstance(result, dict):\n    self.output_data = result.get(\"output_data\")\n    self.channel_name = result.get(\"channel_name\")\n    self.username = result.get(\"username\")", "successors": [{"id": 10, "label": "if self.output_data is None or self.channel_name is None or self.username is None:\n    raise ValueError(\"No message, channel name, or username received.\")", "successors": [{"id": 12, "label": "yield \"message_content\", self.output_data\nyield \"channel_name\", self.channel_name\nyield \"username\", self.username", "successors": []}]}]}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 42, "end_line": 43, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: DiscordCredentials = DiscordCredentialsField()", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: DiscordCredentials = DiscordCredentialsField()", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 45, "end_line": 54, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        message_content: str = SchemaField(\n            description=\"The content of the message received\"\n        )\n        channel_name: str = SchemaField(\n            description=\"The name of the channel the message was received from\"\n        )\n        username: str = SchemaField(\n            description=\"The username of the user who sent the message\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    message_content: str = SchemaField(\n        description=\"The content of the message received\"\n    )\n    channel_name: str = SchemaField(\n        description=\"The name of the channel the message was received from\"\n    )\n    username: str = SchemaField(\n        description=\"The username of the user who sent the message\"\n    )", "successors": []}]}], "simplified_code": "class ReadDiscordMessagesBlock(Block):\n        credentials: DiscordCredentials = DiscordCredentialsField()\n\n        )\n\n        )\n\n        await client.start(token.get_secret_value())\n\n            break\n\n            raise ValueError(f\"An error occurred: {e}\")", "blocks": [{"id": 1, "label": "class ReadDiscordMessagesBlock(Block):\n    credentials: DiscordCredentials = DiscordCredentialsField()", "successors": [{"id": 3, "label": "await client.start(token.get_secret_value())", "successors": [{"id": 4, "label": "break", "successors": []}, {"id": 5, "label": "raise ValueError(f\"An error occurred: {e}\")", "successors": []}]}]}]}, {"name": "SendDiscordMessageBlock", "type": "class", "start_line": 164, "end_line": 254, "functions": [{"name": "__init__", "type": "function", "start_line": 179, "end_line": 196, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"d0822ab5-9f8a-44a3-8971-531dd0178b6b\",\n            input_schema=SendDiscordMessageBlock.Input,  # Assign input schema\n            output_schema=SendDiscordMessageBlock.Output,  # Assign output schema\n            description=\"Sends a message to a Discord channel using a bot token.\",\n            categories={BlockCategory.SOCIAL},\n            test_input={\n                \"channel_name\": \"general\",\n                \"message_content\": \"Hello, Discord!\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_output=[(\"status\", \"Message sent\")],\n            test_mock={\n                \"send_message\": lambda token, channel_name, message_content: asyncio.Future()\n            },\n            test_credentials=TEST_CREDENTIALS,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"d0822ab5-9f8a-44a3-8971-531dd0178b6b\",\n    input_schema=SendDiscordMessageBlock.Input,  # Assign input schema\n    output_schema=SendDiscordMessageBlock.Output,  # Assign output schema\n    description=\"Sends a message to a Discord channel using a bot token.\",\n    categories={BlockCategory.SOCIAL},\n    test_input={\n        \"channel_name\": \"general\",\n        \"message_content\": \"Hello, Discord!\",\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_output=[(\"status\", \"Message sent\")],\n    test_mock={\n        \"send_message\": lambda token, channel_name, message_content: asyncio.Future()\n    },\n    test_credentials=TEST_CREDENTIALS,\n)", "successors": []}]}, {"name": "send_message", "type": "function", "start_line": 198, "end_line": 219, "functions": [{"name": "on_ready", "type": "function", "start_line": 204, "end_line": 217, "functions": [], "classes": [], "simplified_code": "        async def on_ready():\n            print(f\"Logged in as {client.user}\")\n            for guild in client.guilds:\n                for channel in guild.text_channels:\n                    if channel.name == channel_name:\n                        # Split message into chunks if it exceeds 2000 characters\n                        for chunk in self.chunk_message(message_content):\n                            await channel.send(chunk)\n                        self.output_data = \"Message sent\"\n                        await client.close()\n                        return\n\n            self.output_data = \"Channel not found\"\n            await client.close()", "blocks": [{"id": 1, "label": "async def on_ready():\n    print(f\"Logged in as {client.user}\")", "successors": [{"id": 3, "label": "for guild in client.guilds:", "successors": [{"id": 4, "label": "    for channel in guild.text_channels:", "successors": [{"id": 5, "label": "        if channel.name == channel_name:", "successors": [{"id": 6, "label": "            for chunk in self.chunk_message(message_content):", "successors": [{"id": 7, "label": "                await channel.send(chunk)\nself.output_data = \"Message sent\"", "successors": [{"id": 9, "label": "await client.close()\nreturn", "successors": []}]}]}]}]}]}, {"id": 11, "label": "self.output_data = \"Channel not found\"\nawait client.close()", "successors": []}]}]}], "classes": [], "simplified_code": "    async def send_message(self, token: str, channel_name: str, message_content: str):\n        intents = discord.Intents.default()\n        intents.guilds = True  # Required for fetching guild/channel information\n        client = discord.Client(intents=intents)\n\n        @client.event\n            await client.close()\n\n        await client.start(token)", "blocks": [{"id": 1, "label": "async def send_message(self, token: str, channel_name: str, message_content: str):\nintents = discord.Intents.default()\nintents.guilds = True  # Required for fetching guild/channel information\nclient = discord.Client(intents=intents)", "successors": [{"id": 3, "label": "@client.event\nasync def on_ready():\n    guild = discord.utils.get(client.guilds, name=channel_name)\n    if guild is not None:\n        channel = discord.utils.get(guild.text_channels, name=channel_name)\n        if channel is not None:\n            await channel.send(message_content)\n    await client.close()", "successors": [{"id": 5, "label": "await client.start(token)", "successors": []}]}]}]}, {"name": "chunk_message", "type": "function", "start_line": 221, "end_line": 223, "functions": [], "classes": [], "simplified_code": "    def chunk_message(self, message: str, limit: int = 2000) -> list:\n        \"\"\"Splits a message into chunks not exceeding the Discord limit.\"\"\"\n        return [message[i : i + limit] for i in range(0, len(message), limit)]", "blocks": [{"id": 1, "label": "def chunk_message(self, message: str, limit: int = 2000) -> list:\n\"\"\"Splits a message into chunks not exceeding the Discord limit.\"\"\"", "successors": [{"id": 3, "label": "return [message[i : i + limit] for i in range(0, len(message), limit)]", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 225, "end_line": 249, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        try:\n            loop = asyncio.get_event_loop()\n            future = self.send_message(\n                credentials.api_key.get_secret_value(),\n                input_data.channel_name,\n                input_data.message_content,\n            )\n\n            # If it's a Future (mock), set the result\n            if isinstance(future, asyncio.Future):\n                future.set_result(\"Message sent\")\n\n            result = loop.run_until_complete(future)\n\n            # For testing purposes, use the mocked result\n            if isinstance(result, str):\n                self.output_data = result\n\n            if self.output_data is None:\n                raise ValueError(\"No status message received.\")\n\n            yield \"status\", self.output_data", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs) -> BlockOutput:\ntry:", "successors": [{"id": 3, "label": "loop = asyncio.get_event_loop()\nfuture = self.send_message(credentials.api_key.get_secret_value(), input_data.channel_name, input_data.message_content)", "successors": [{"id": 4, "label": "if isinstance(future, asyncio.Future):\nfuture.set_result(\"Message sent\")", "successors": [{"id": 6, "label": "result = loop.run_until_complete(future)", "successors": [{"id": 7, "label": "if isinstance(result, str):\nself.output_data = result", "successors": [{"id": 9, "label": "if self.output_data is None:\nraise ValueError(\"No status message received.\")", "successors": [{"id": 11, "label": "yield \"status\", self.output_data", "successors": []}]}, {"id": 11, "label": "yield \"status\", self.output_data", "successors": []}]}, {"id": 9, "label": "if self.output_data is None:\nraise ValueError(\"No status message received.\")", "successors": [{"id": 11, "label": "yield \"status\", self.output_data", "successors": []}]}, {"id": 11, "label": "yield \"status\", self.output_data", "successors": []}]}]}, {"id": 6, "label": "result = loop.run_until_complete(future)", "successors": [{"id": 7, "label": "if isinstance(result, str):\nself.output_data = result", "successors": [{"id": 9, "label": "if self.output_data is None:\nraise ValueError(\"No status message received.\")", "successors": [{"id": 11, "label": "yield \"status\", self.output_data", "successors": []}]}, {"id": 11, "label": "yield \"status\", self.output_data", "successors": []}]}, {"id": 9, "label": "if self.output_data is None:\nraise ValueError(\"No status message received.\")", "successors": [{"id": 11, "label": "yield \"status\", self.output_data", "successors": []}]}, {"id": 11, "label": "yield \"status\", self.output_data", "successors": []}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 165, "end_line": 172, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: DiscordCredentials = DiscordCredentialsField()\n        message_content: str = SchemaField(\n            description=\"The content of the message received\"\n        )\n        channel_name: str = SchemaField(\n            description=\"The name of the channel the message was received from\"\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    credentials: DiscordCredentials = DiscordCredentialsField()", "successors": []}, {"id": 3, "label": "    message_content: str = SchemaField(description=\"The content of the message received\")", "successors": []}, {"id": 4, "label": "    channel_name: str = SchemaField(description=\"The name of the channel the message was received from\")", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 174, "end_line": 177, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        status: str = SchemaField(\n            description=\"The status of the operation (e.g., 'Message sent', 'Error')\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\nstatus: str = SchemaField(description=\"The status of the operation (e.g., 'Message sent', 'Error')\")", "successors": []}]}], "simplified_code": "class SendDiscordMessageBlock(Block):\n        )\n\n        )\n\n        )\n\n        await client.start(token)\n\n        return [message[i : i + limit] for i in range(0, len(message), limit)]\n\n            yield \"status\", self.output_data\n\n        except discord.errors.LoginFailure as login_err:\n            raise ValueError(f\"Login error occurred: {login_err}\")\n        except Exception as e:\n            raise ValueError(f\"An error occurred: {e}\")", "blocks": [{"id": 1, "label": "class SendDiscordMessageBlock(Block):\nasync def run(self, inputs):", "successors": [{"id": 3, "label": "client = discord.Client()\ntry:", "successors": [{"id": 5, "label": "token = inputs['token']\nmessage = inputs['message']", "successors": [{"id": 7, "label": "limit = 2000\nawait client.start(token)", "successors": [{"id": 9, "label": "return [message[i : i + limit] for i in range(0, len(message), limit)]", "successors": []}]}]}, {"id": 10, "label": "except discord.errors.LoginFailure as login_err:\nraise ValueError(f\"Login error occurred: {login_err}\")", "successors": []}, {"id": 12, "label": "except Exception as e:\nraise ValueError(f\"An error occurred: {e}\")", "successors": []}]}]}]}], "simplified_code": "import asyncio\nfrom typing import Literal\n\nimport aiohttp\nimport discord\nfrom pydantic import SecretStr\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\n\nDiscordCredentials = CredentialsMetaInput[\n    Literal[ProviderName.DISCORD], Literal[\"api_key\"]\n]\n\n\n    return CredentialsField(description=\"Discord bot token\")\n\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"discord\",\n    api_key=SecretStr(\"test_api_key\"),\n    title=\"Mock Discord API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.type,\n}\n\n\n            raise ValueError(f\"An error occurred: {e}\")\n\n\n            raise ValueError(f\"An error occurred: {e}\")", "blocks": [{"id": 1, "label": "# Example input code\nimport asyncio\nfrom typing import Literal\n\nimport aiohttp\nimport discord\nfrom pydantic import SecretStr\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\n\nDiscordCredentials = CredentialsMetaInput[\n    Literal[ProviderName.DISCORD], Literal[\"api_key\"]\n]\n\n\n    return CredentialsField(description=\"Discord bot token\")\n\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"discord\",\n    api_key=SecretStr(\"test_api_key\"),\n    title=\"Mock Discord API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.type,\n}", "successors": []}]}
{"file_name": "40.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 71, "functions": [{"name": "backtrack", "type": "function", "start_line": 10, "end_line": 45, "functions": [], "classes": [], "simplified_code": "def backtrack(input_string: str, word_dict: set[str], start: int) -> bool:\n    \"\"\"\n    Helper function that uses backtracking to determine if a valid\n    word segmentation is possible starting from index 'start'.\n\n    Parameters:\n    input_string (str): The input string to be segmented.\n    word_dict (set[str]): A set of valid dictionary words.\n    start (int): The starting index of the substring to be checked.\n\n    Returns:\n    bool: True if a valid segmentation is possible, otherwise False.\n\n    Example:\n    >>> backtrack(\"leetcode\", {\"leet\", \"code\"}, 0)\n    True\n\n    >>> backtrack(\"applepenapple\", {\"apple\", \"pen\"}, 0)\n    True\n\n    >>> backtrack(\"catsandog\", {\"cats\", \"dog\", \"sand\", \"and\", \"cat\"}, 0)\n    False\n    \"\"\"\n\n    # Base case: if the starting index has reached the end of the string\n    if start == len(input_string):\n        return True\n\n    # Try every possible substring from 'start' to 'end'\n    for end in range(start + 1, len(input_string) + 1):\n        if input_string[start:end] in word_dict and backtrack(\n            input_string, word_dict, end\n        ):\n            return True\n\n    return False", "blocks": [{"id": 1, "label": "def backtrack(input_string: str, word_dict: set[str], start: int) -> bool:", "successors": [{"id": 2, "label": "if start == len(input_string):\nreturn True", "successors": []}, {"id": 4, "label": "for end in range(start + 1, len(input_string) + 1):", "successors": [{"id": 5, "label": "if input_string[start:end] in word_dict and backtrack(input_string, word_dict, end):", "successors": [{"id": 6, "label": "return True", "successors": []}, {"id": 7, "label": "return False", "successors": []}]}]}, {"id": 7, "label": "return False", "successors": []}]}]}, {"name": "word_break", "type": "function", "start_line": 48, "end_line": 71, "functions": [], "classes": [], "simplified_code": "def word_break(input_string: str, word_dict: set[str]) -> bool:\n    \"\"\"\n    Determines if the input string can be segmented into a sequence of\n    valid dictionary words using backtracking.\n\n    Parameters:\n    input_string (str): The input string to segment.\n    word_dict (set[str]): The set of valid words.\n\n    Returns:\n    bool: True if the string can be segmented into valid words, otherwise False.\n\n    Example:\n    >>> word_break(\"leetcode\", {\"leet\", \"code\"})\n    True\n\n    >>> word_break(\"applepenapple\", {\"apple\", \"pen\"})\n    True\n\n    >>> word_break(\"catsandog\", {\"cats\", \"dog\", \"sand\", \"and\", \"cat\"})\n    False\n    \"\"\"\n\n    return backtrack(input_string, word_dict, 0)", "blocks": [{"id": 1, "label": "def word_break(input_string: str, word_dict: set[str]) -> bool:\nreturn backtrack(input_string, word_dict, 0)", "successors": []}]}], "classes": [], "simplified_code": "\"\"\"\nWord Break Problem is a well-known problem in computer science.\nGiven a string and a dictionary of words, the task is to determine if\nthe string can be segmented into a sequence of one or more dictionary words.\n\nWikipedia: https://en.wikipedia.org/wiki/Word_break_problem\n\"\"\"\n\n\n    return False\n\n\n    return backtrack(input_string, word_dict, 0)", "blocks": [{"id": 1, "label": "# Example input code\n\"\"\"\nWord Break Problem is a well-known problem in computer science.\nGiven a string and a dictionary of words, the task is to determine if\nthe string can be segmented into a sequence of one or more dictionary words.\n\nWikipedia: https://en.wikipedia.org/wiki/Word_break_problem\n\"\"\"\n\n\n    return False\n\n\n    return backtrack(input_string, word_dict, 0)", "successors": []}]}
{"file_name": "41.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 83, "functions": [{"name": "sort_blocks", "type": "function", "start_line": 17, "end_line": 43, "functions": [], "classes": [], "simplified_code": "def sort_blocks():\n    # First, we load the current README into memory\n    with open('README.md', 'r') as read_me_file:\n        read_me = read_me_file.read()\n\n    # Separating the 'table of contents' from the contents (blocks)\n    table_of_contents = ''.join(read_me.split('- - -')[0])\n    blocks = ''.join(read_me.split('- - -')[1]).split('\\n# ')\n    for i in range(len(blocks)):\n        if i == 0:\n            blocks[i] = blocks[i] + '\\n'\n        else:\n            blocks[i] = '# ' + blocks[i] + '\\n'\n\n    # Sorting the libraries\n    inner_blocks = sorted(blocks[0].split('##'))\n    for i in range(1, len(inner_blocks)):\n        if inner_blocks[i][0] != '#':\n            inner_blocks[i] = '##' + inner_blocks[i]\n    inner_blocks = ''.join(inner_blocks)\n\n    # Replacing the non-sorted libraries by the sorted ones and gathering all at the final_README file\n    blocks[0] = inner_blocks\n    final_README = table_of_contents + '- - -' + ''.join(blocks)\n\n    with open('README.md', 'w+') as sorted_file:\n        sorted_file.write(final_README)", "blocks": [{"id": 1, "label": "def sort_blocks():\nwith open('README.md', 'r') as read_me_file:", "successors": [{"id": 3, "label": "read_me = read_me_file.read()", "successors": [{"id": 11, "label": "with open('README.md', 'w+') as sorted_file:\nsorted_file.write(final_README)", "successors": []}, {"id": 4, "label": "table_of_contents = ''.join(read_me.split('- - -')[0])\nblocks = ''.join(read_me.split('- - -')[1]).split('\\n# ')", "successors": [{"id": 6, "label": "for i in range(len(blocks)):", "successors": [{"id": 7, "label": "if i == 0:\nblocks[i] = blocks[i] + '\\n'", "successors": [{"id": 10, "label": "inner_blocks = ''.join(inner_blocks)\nwith open('README.md', 'w+') as sorted_file:", "successors": [{"id": 12, "label": "sorted_file.write(final_README)", "successors": []}]}]}, {"id": 9, "label": "blocks[i] = '# ' + blocks[i] + '\\n'\ninner_blocks = ''.join(inner_blocks)", "successors": [{"id": 11, "label": "with open('README.md', 'w+') as sorted_file:\nsorted_file.write(final_README)", "successors": []}]}]}, {"id": 10, "label": "inner_blocks = ''.join(inner_blocks)\nwith open('README.md', 'w+') as sorted_file:", "successors": [{"id": 12, "label": "sorted_file.write(final_README)", "successors": []}]}]}]}]}]}, {"name": "main", "type": "function", "start_line": 45, "end_line": 79, "functions": [], "classes": [], "simplified_code": "def main():\n    # First, we load the current README into memory as an array of lines\n    with open('README.md', 'r') as read_me_file:\n        read_me = read_me_file.readlines()\n\n    # Then we cluster the lines together as blocks\n    # Each block represents a collection of lines that should be sorted\n    # This was done by assuming only links ([...](...)) are meant to be sorted\n    # Clustering is done by indentation\n    blocks = []\n    last_indent = None\n    for line in read_me:\n        s_line = line.lstrip()\n        indent = len(line) - len(s_line)\n\n        if any([s_line.startswith(s) for s in ['* [', '- [']]):\n            if indent == last_indent:\n                blocks[-1].append(line)\n            else:\n                blocks.append([line])\n            last_indent = indent\n        else:\n            blocks.append([line])\n            last_indent = None\n\n    with open('README.md', 'w+') as sorted_file:\n        # Then all of the blocks are sorted individually\n        blocks = [\n            ''.join(sorted(block, key=str.lower)) for block in blocks\n        ]\n        # And the result is written back to README.md\n        sorted_file.write(''.join(blocks))\n\n    # Then we call the sorting method\n    sort_blocks()", "blocks": [{"id": 1, "label": "def main():\nwith open('README.md', 'r') as read_me_file:\n    read_me = read_me_file.readlines()", "successors": [{"id": 3, "label": "blocks = []\nlast_indent = None\nfor line in read_me:\n    s_line = line.lstrip()\n    indent = len(line) - len(s_line)", "successors": [{"id": 4, "label": "if any([s_line.startswith(s) for s in ['* [', '- [']]):", "successors": [{"id": 5, "label": "if indent == last_indent:\n    blocks[-1].append(line)\nlast_indent = indent", "successors": [{"id": 12, "label": "with open('README.md', 'w+') as sorted_file:\nblocks = [\n    ''.join(sorted(block, key=str.lower)) for block in blocks\n]", "successors": [{"id": 14, "label": "sorted_file.write(''.join(blocks))\nsort_blocks()", "successors": []}]}]}, {"id": 6, "label": "else:\n    blocks.append([line])\nlast_indent = indent", "successors": [{"id": 12, "label": "with open('README.md', 'w+') as sorted_file:\nblocks = [\n    ''.join(sorted(block, key=str.lower)) for block in blocks\n]", "successors": [{"id": 14, "label": "sorted_file.write(''.join(blocks))\nsort_blocks()", "successors": []}]}]}]}, {"id": 8, "label": "else:\n    blocks.append([line])\nlast_indent = None", "successors": [{"id": 12, "label": "with open('README.md', 'w+') as sorted_file:\nblocks = [\n    ''.join(sorted(block, key=str.lower)) for block in blocks\n]", "successors": [{"id": 14, "label": "sorted_file.write(''.join(blocks))\nsort_blocks()", "successors": []}]}]}]}]}]}], "classes": [], "simplified_code": "#!/usr/bin/env python\n# coding: utf-8\n\n\"\"\"\n    The approach taken is explained below. I decided to do it simply.\n    Initially I was considering parsing the data into some sort of\n    structure and then generating an appropriate README. I am still\n    considering doing it - but for now this should work. The only issue\n    I see is that it only sorts the entries at the lowest level, and that\n    the order of the top-level contents do not match the order of the actual\n    entries.\n\n    This could be extended by having nested blocks, sorting them recursively\n    and flattening the end structure into a list of lines. Revision 2 maybe ^.^.\n\"\"\"\n\n        sorted_file.write(final_README)\n\n    sort_blocks()\n\n\nif __name__ == \"__main__\":\n    main()", "blocks": [{"id": 1, "label": "#!/usr/bin/env python\n# coding: utf-8\n\n\"\"\"\n    The approach taken is explained below. I decided to do it simply.\n    Initially I was considering parsing the data into some sort of\n    structure and then generating an appropriate README. I am still\n    considering doing it - but for now this should work. The only issue\n    I see is that it only sorts the entries at the lowest level, and that\n    the order of the top-level contents do not match the order of the actual\n    entries.\n\n    This could be extended by having nested blocks, sorting them recursively\n    and flattening the end structure into a list of lines. Revision 2 maybe ^.^.\n\"\"\"\n\n        sorted_file.write(final_README)\n\n    sort_blocks()\nif __name__ == \"__main__\":", "successors": [{"id": 3, "label": "    main()", "successors": []}]}]}
{"file_name": "42.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 30, "functions": [], "classes": [{"name": "ManualWebhookManagerBase", "type": "class", "start_line": 11, "end_line": 30, "functions": [{"name": "_register_webhook", "type": "function", "start_line": 12, "end_line": 23, "functions": [], "classes": [], "simplified_code": "    async def _register_webhook(\n        self,\n        credentials: Credentials,\n        webhook_type: WT,\n        resource: str,\n        events: list[str],\n        ingress_url: str,\n        secret: str,\n    ) -> tuple[str, dict]:\n        print(ingress_url)  # FIXME: pass URL to user in front end\n\n        return \"\", {}", "blocks": [{"id": 1, "label": "async def _register_webhook( self, credentials: Credentials, webhook_type: WT, resource: str, events: list[str], ingress_url: str, secret: str, ) -> tuple[str, dict]:\nprint(ingress_url) # FIXME: pass URL to user in front end", "successors": [{"id": 3, "label": "return \"\", {}", "successors": []}]}]}, {"name": "_deregister_webhook", "type": "function", "start_line": 25, "end_line": 30, "functions": [], "classes": [], "simplified_code": "    async def _deregister_webhook(\n        self,\n        webhook: integrations.Webhook,\n        credentials: OAuth2Credentials | APIKeyCredentials,\n    ) -> None:\n        pass", "blocks": [{"id": 1, "label": "async def _deregister_webhook(self, webhook: integrations.Webhook, credentials: OAuth2Credentials | APIKeyCredentials) -> None:\npass", "successors": []}]}], "simplified_code": "class ManualWebhookManagerBase(BaseWebhooksManager[WT]):\n        return \"\", {}\n\n        pass", "blocks": [{"id": 1, "label": "class ManualWebhookManagerBase(BaseWebhooksManager[WT]):", "successors": [{"id": 2, "label": "return \"\", {}", "successors": []}, {"id": 3, "label": "pass", "successors": []}]}]}], "simplified_code": "import logging\n\nfrom backend.data import integrations\nfrom backend.data.model import APIKeyCredentials, Credentials, OAuth2Credentials\n\nfrom ._base import WT, BaseWebhooksManager\n\nlogger = logging.getLogger(__name__)\n\n\n        pass", "blocks": [{"id": 1, "label": "import logging\nfrom backend.data import integrations", "successors": [{"id": 3, "label": "from backend.data.model import APIKeyCredentials, Credentials, OAuth2Credentials\nfrom ._base import WT, BaseWebhooksManager", "successors": [{"id": 5, "label": "logger = logging.getLogger(__name__)\npass", "successors": []}]}]}]}
{"file_name": "43.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 11, "functions": [{"name": "get_user_id", "type": "function", "start_line": 10, "end_line": 11, "functions": [], "classes": [], "simplified_code": "def get_user_id(user: User = Depends(requires_user)) -> str:\n    return user.user_id", "blocks": [{"id": 1, "label": "def get_user_id(user: User = Depends(requires_user)) -> str:\n    return user.user_id", "successors": []}]}], "classes": [], "simplified_code": "from autogpt_libs.auth.depends import requires_user\nfrom autogpt_libs.auth.models import User\nfrom fastapi import Depends\n\nfrom backend.util.settings import Settings\n\nsettings = Settings()\n\n\n    return user.user_id", "blocks": [{"id": 1, "label": "from autogpt_libs.auth.depends import requires_user\nfrom autogpt_libs.auth.models import User\nfrom fastapi import Depends\n\nfrom backend.util.settings import Settings\n\nsettings = Settings()\nreturn user.user_id", "successors": []}]}
{"file_name": "44.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 195, "functions": [], "classes": [{"name": "PublishToMediumStatus", "type": "class", "start_line": 33, "end_line": 36, "functions": [], "simplified_code": "class PublishToMediumStatus(str, Enum):\n    PUBLIC = \"public\"\n    DRAFT = \"draft\"\n    UNLISTED = \"unlisted\"", "blocks": [{"id": 1, "label": "class PublishToMediumStatus(str, Enum):\n    PUBLIC = \"public\"\n    DRAFT = \"draft\"\n    UNLISTED = \"unlisted\"", "successors": []}]}, {"name": "PublishToMediumBlock", "type": "class", "start_line": 39, "end_line": 195, "functions": [{"name": "__init__", "type": "function", "start_line": 97, "end_line": 131, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"3f7b2dcb-4a78-4e3f-b0f1-88132e1b89df\",\n            input_schema=PublishToMediumBlock.Input,\n            output_schema=PublishToMediumBlock.Output,\n            description=\"Publishes a post to Medium.\",\n            categories={BlockCategory.SOCIAL},\n            test_input={\n                \"author_id\": \"1234567890abcdef\",\n                \"title\": \"Test Post\",\n                \"content\": \"<h1>Test Content</h1><p>This is a test post.</p>\",\n                \"content_format\": \"html\",\n                \"tags\": [\"test\", \"automation\"],\n                \"license\": \"all-rights-reserved\",\n                \"notify_followers\": False,\n                \"publish_status\": PublishToMediumStatus.DRAFT.value,\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_output=[\n                (\"post_id\", \"e6f36a\"),\n                (\"post_url\", \"https://medium.com/@username/test-post-e6f36a\"),\n                (\"published_at\", 1626282600),\n            ],\n            test_mock={\n                \"create_post\": lambda *args, **kwargs: {\n                    \"data\": {\n                        \"id\": \"e6f36a\",\n                        \"url\": \"https://medium.com/@username/test-post-e6f36a\",\n                        \"authorId\": \"1234567890abcdef\",\n                        \"publishedAt\": 1626282600,\n                    }\n                }\n            },\n            test_credentials=TEST_CREDENTIALS,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\n    super().__init__(\n        id=\"3f7b2dcb-4a78-4e3f-b0f1-88132e1b89df\",\n        input_schema=PublishToMediumBlock.Input,\n        output_schema=PublishToMediumBlock.Output,\n        description=\"Publishes a post to Medium.\",\n        categories={BlockCategory.SOCIAL},\n        test_input={\n            \"author_id\": \"1234567890abcdef\",\n            \"title\": \"Test Post\",\n            \"content\": \"<h1>Test Content</h1><p>This is a test post.</p>\",\n            \"content_format\": \"html\",\n            \"tags\": [\"test\", \"automation\"],\n            \"license\": \"all-rights-reserved\",\n            \"notify_followers\": False,\n            \"publish_status\": PublishToMediumStatus.DRAFT.value,\n            \"credentials\": TEST_CREDENTIALS_INPUT,\n        },\n        test_output=[\n            (\"post_id\", \"e6f36a\"),\n            (\"post_url\", \"https://medium.com/@username/test-post-e6f36a\"),\n            (\"published_at\", 1626282600),\n        ],\n        test_mock={\n            \"create_post\": lambda *args, **kwargs: {\n                \"data\": {\n                    \"id\": \"e6f36a\",\n                    \"url\": \"https://medium.com/@username/test-post-e6f36a\",\n                    \"authorId\": \"1234567890abcdef\",\n                    \"publishedAt\": 1626282600,\n                }\n            }\n        },\n        test_credentials=TEST_CREDENTIALS,\n    )", "successors": []}]}, {"name": "create_post", "type": "function", "start_line": 133, "end_line": 169, "functions": [], "classes": [], "simplified_code": "    def create_post(\n        self,\n        api_key: SecretStr,\n        author_id,\n        title,\n        content,\n        content_format,\n        tags,\n        canonical_url,\n        publish_status,\n        license,\n        notify_followers,\n    ):\n        headers = {\n            \"Authorization\": f\"Bearer {api_key.get_secret_value()}\",\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\",\n        }\n\n        data = {\n            \"title\": title,\n            \"content\": content,\n            \"contentFormat\": content_format,\n            \"tags\": tags,\n            \"canonicalUrl\": canonical_url,\n            \"publishStatus\": publish_status,\n            \"license\": license,\n            \"notifyFollowers\": notify_followers,\n        }\n\n        response = requests.post(\n            f\"https://api.medium.com/v1/users/{author_id}/posts\",\n            headers=headers,\n            json=data,\n        )\n\n        return response.json()", "blocks": [{"id": 1, "label": "headers = {\n    \"Authorization\": f\"Bearer {api_key.get_secret_value()}\",\n    \"Content-Type\": \"application/json\",\n    \"Accept\": \"application/json\",\n}\ndata = {\n    \"title\": title,\n    \"content\": content,\n    \"contentFormat\": content_format,\n    \"tags\": tags,\n    \"canonicalUrl\": canonical_url,\n    \"publishStatus\": publish_status,\n    \"license\": license,\n    \"notifyFollowers\": notify_followers,\n}", "successors": [{"id": 3, "label": "response = requests.post(\n    f\"https://api.medium.com/v1/users/{author_id}/posts\",\n    headers=headers,\n    json=data,\n)\nreturn response.json()", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 171, "end_line": 195, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        response = self.create_post(\n            credentials.api_key,\n            input_data.author_id.get_secret_value(),\n            input_data.title,\n            input_data.content,\n            input_data.content_format,\n            input_data.tags,\n            input_data.canonical_url,\n            input_data.publish_status,\n            input_data.license,\n            input_data.notify_followers,\n        )\n\n        if \"data\" in response:\n            yield \"post_id\", response[\"data\"][\"id\"]\n            yield \"post_url\", response[\"data\"][\"url\"]\n            yield \"published_at\", response[\"data\"][\"publishedAt\"]\n        else:\n            error_message = response.get(\"errors\", [{}])[0].get(\n                \"message\", \"Unknown error occurred\"\n            )\n            raise RuntimeError(f\"Failed to create Medium post: {error_message}\")", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs) -> BlockOutput:\n    response = self.create_post(\n        credentials.api_key,\n        input_data.author_id.get_secret_value(),\n        input_data.title,\n        input_data.content,\n        input_data.content_format,\n        input_data.tags,\n        input_data.canonical_url,\n        input_data.publish_status,\n        input_data.license,\n        input_data.notify_followers,\n    )\nif \"data\" in response:", "successors": [{"id": 3, "label": "    yield \"post_id\", response[\"data\"][\"id\"]\n    yield \"post_url\", response[\"data\"][\"url\"]\n    yield \"published_at\", response[\"data\"][\"publishedAt\"]", "successors": []}, {"id": 4, "label": "else:\n    error_message = response.get(\"errors\", [{}])[0].get(\n        \"message\", \"Unknown error occurred\"\n    )\n    raise RuntimeError(f\"Failed to create Medium post: {error_message}\")", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 40, "end_line": 85, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        author_id: BlockSecret = SecretField(\n            key=\"medium_author_id\",\n            description=\"\"\"The Medium AuthorID of the user. You can get this by calling the /me endpoint of the Medium API.\\n\\ncurl -H \"Authorization: Bearer YOUR_ACCESS_TOKEN\" https://api.medium.com/v1/me\" the response will contain the authorId field.\"\"\",\n            placeholder=\"Enter the author's Medium AuthorID\",\n        )\n        title: str = SchemaField(\n            description=\"The title of your Medium post\",\n            placeholder=\"Enter your post title\",\n        )\n        content: str = SchemaField(\n            description=\"The main content of your Medium post\",\n            placeholder=\"Enter your post content\",\n        )\n        content_format: str = SchemaField(\n            description=\"The format of the content: 'html' or 'markdown'\",\n            placeholder=\"html\",\n        )\n        tags: List[str] = SchemaField(\n            description=\"List of tags for your Medium post (up to 5)\",\n            placeholder=\"['technology', 'AI', 'blogging']\",\n        )\n        canonical_url: str | None = SchemaField(\n            default=None,\n            description=\"The original home of this content, if it was originally published elsewhere\",\n            placeholder=\"https://yourblog.com/original-post\",\n        )\n        publish_status: PublishToMediumStatus = SchemaField(\n            description=\"The publish status\",\n            placeholder=PublishToMediumStatus.DRAFT,\n        )\n        license: str = SchemaField(\n            default=\"all-rights-reserved\",\n            description=\"The license of the post: 'all-rights-reserved', 'cc-40-by', 'cc-40-by-sa', 'cc-40-by-nd', 'cc-40-by-nc', 'cc-40-by-nc-nd', 'cc-40-by-nc-sa', 'cc-40-zero', 'public-domain'\",\n            placeholder=\"all-rights-reserved\",\n        )\n        notify_followers: bool = SchemaField(\n            default=False,\n            description=\"Whether to notify followers that the user has published\",\n            placeholder=\"False\",\n        )\n        credentials: CredentialsMetaInput[\n            Literal[ProviderName.MEDIUM], Literal[\"api_key\"]\n        ] = CredentialsField(\n            description=\"The Medium integration can be used with any API key with sufficient permissions for the blocks it is used on.\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    author_id: BlockSecret = SecretField(\n        key=\"medium_author_id\",\n        description=\"\"\"The Medium AuthorID of the user. You can get this by calling the /me endpoint of the Medium API.\\n\\ncurl -H \\\"Authorization: Bearer YOUR_ACCESS_TOKEN\\\" https://api.medium.com/v1/me\\\" the response will contain the authorId field.\"\"\",\n        placeholder=\"Enter the author's Medium AuthorID\"\n    )", "successors": [{"id": 3, "label": "    title: str = SchemaField(\n        description=\"The title of your Medium post\",\n        placeholder=\"Enter your post title\"\n    )\n    content: str = SchemaField(\n        description=\"The main content of your Medium post\",\n        placeholder=\"Enter your post content\"\n    )", "successors": [{"id": 5, "label": "    content_format: str = SchemaField(\n        description=\"The format of the content: 'html' or 'markdown'\",\n        placeholder=\"html\"\n    )\n    tags: List[str] = SchemaField(\n        description=\"List of tags for your Medium post (up to 5)\",\n        placeholder=\"['technology', 'AI', 'blogging']\"\n    )", "successors": [{"id": 7, "label": "    canonical_url: str | None = SchemaField(\n        default=None,\n        description=\"The original home of this content, if it was originally published elsewhere\",\n        placeholder=\"https://yourblog.com/original-post\"\n    )\n    publish_status: PublishToMediumStatus = SchemaField(\n        description=\"The publish status\",\n        placeholder=PublishToMediumStatus.DRAFT\n    )", "successors": [{"id": 9, "label": "    license: str = SchemaField(\n        default=\"all-rights-reserved\",\n        description=\"The license of the post: 'all-rights-reserved', 'cc-40-by', 'cc-40-by-sa', 'cc-40-by-nd', 'cc-40-by-nc', 'cc-40-by-nc-nd', 'cc-40-by-nc-sa', 'cc-40-zero', 'public-domain'\",\n        placeholder=\"all-rights-reserved\"\n    )\n    notify_followers: bool = SchemaField(\n        default=False,\n        description=\"Whether to notify followers that the user has published\",\n        placeholder=\"False\"\n    )", "successors": [{"id": 11, "label": "    credentials: CredentialsMetaInput[\n        Literal[ProviderName.MEDIUM], Literal[\"api_key\"]\n    ] = CredentialsField(\n        description=\"The Medium integration can be used with any API key with sufficient permissions for the blocks it is used on.\"\n    )", "successors": []}]}]}]}]}]}]}, {"name": "Output", "type": "class", "start_line": 87, "end_line": 95, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        post_id: str = SchemaField(description=\"The ID of the created Medium post\")\n        post_url: str = SchemaField(description=\"The URL of the created Medium post\")\n        published_at: int = SchemaField(\n            description=\"The timestamp when the post was published\"\n        )\n        error: str = SchemaField(\n            description=\"Error message if the post creation failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    post_id: str = SchemaField(description=\"The ID of the created Medium post\")", "successors": [{"id": 3, "label": "    post_url: str = SchemaField(description=\"The URL of the created Medium post\")\n    published_at: int = SchemaField(description=\"The timestamp when the post was published\")", "successors": [{"id": 5, "label": "    error: str = SchemaField(description=\"Error message if the post creation failed\")", "successors": []}]}]}]}], "simplified_code": "class PublishToMediumBlock(Block):\n        )\n\n        )\n\n        )\n\n        return response.json()\n\n            raise RuntimeError(f\"Failed to create Medium post: {error_message}\")", "blocks": [{"id": 1, "label": "class PublishToMediumBlock(Block):", "successors": [{"id": 2, "label": "def __init__(self, token, title, content):\nself.token = token\nself.title = title\nself.content = content", "successors": []}, {"id": 4, "label": "def publish(self):\nheaders = {'Authorization': f'Bearer {self.token}', 'Content-Type': 'application/json'}", "successors": [{"id": 6, "label": "data = {\"title\": self.title, \"content\": self.content, \"contentFormat\": \"markdown\", \"publishStatus\": \"public\"}\nresponse = requests.post('https://api.medium.com/v1/users/me/posts', headers=headers, json=data)", "successors": [{"id": 8, "label": "if response.status_code != 201:\nerror_message = response.json().get('errors', 'Unknown error')", "successors": [{"id": 10, "label": "raise RuntimeError(f\"Failed to create Medium post: {error_message}\")", "successors": []}]}, {"id": 11, "label": "return response.json()", "successors": []}]}]}]}]}], "simplified_code": "from enum import Enum\nfrom typing import List, Literal\n\nfrom pydantic import SecretStr\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    BlockSecret,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n    SecretField,\n)\nfrom backend.integrations.providers import ProviderName\nfrom backend.util.request import requests\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"medium\",\n    api_key=SecretStr(\"mock-medium-api-key\"),\n    title=\"Mock Medium API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.type,\n}\n\n\n    UNLISTED = \"unlisted\"\n\n\n            raise RuntimeError(f\"Failed to create Medium post: {error_message}\")", "blocks": [{"id": 1, "label": "# Example input code\nfrom enum import Enum\nfrom typing : List, Literal\n\nfrom pydantic import SecretStr\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    BlockSecret,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n    SecretField,\n)\nfrom backend.integrations.providers import ProviderName\nfrom backend.util.request import requests\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"medium\",\n    api_key=SecretStr(\"mock-medium-api-key\"),\n    title=\"Mock Medium API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.type,\n}\n\nUNLISTED = \"unlisted\"\nraise RuntimeError(f\"Failed to create Medium post: {error_message}\")", "successors": []}]}
{"file_name": "45.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 325, "functions": [{"name": "generate_api_key", "type": "function", "start_line": 117, "end_line": 151, "functions": [], "classes": [], "simplified_code": "async def generate_api_key(\n    name: str,\n    user_id: str,\n    permissions: List[APIKeyPermission],\n    description: Optional[str] = None,\n) -> tuple[APIKeyWithoutHash, str]:\n    \"\"\"\n    Generate a new API key and store it in the database.\n    Returns the API key object (without hash) and the plain text key.\n    \"\"\"\n    try:\n        api_manager = APIKeyManager()\n        key = api_manager.generate_api_key()\n\n        api_key = await PrismaAPIKey.prisma().create(\n            data=APIKeyCreateInput(\n                id=str(uuid.uuid4()),\n                name=name,\n                prefix=key.prefix,\n                postfix=key.postfix,\n                key=key.hash,\n                permissions=[p for p in permissions],\n                description=description,\n                userId=user_id,\n            )\n        )\n\n        api_key_without_hash = APIKeyWithoutHash.from_db(api_key)\n        return api_key_without_hash, key.raw\n    except PrismaError as e:\n        logger.error(f\"Database error while generating API key: {str(e)}\")\n        raise APIKeyError(f\"Failed to generate API key: {str(e)}\")\n    except Exception as e:\n        logger.error(f\"Unexpected error while generating API key: {str(e)}\")\n        raise APIKeyError(f\"Failed to generate API key: {str(e)}\")", "blocks": [{"id": 1, "label": "try:", "successors": [{"id": 2, "label": "api_manager = APIKeyManager()\nkey = api_manager.generate_api_key()\n\napi_key = await PrismaAPIKey.prisma().create(\n    data=APIKeyCreateInput(\n        id=str(uuid.uuid4()),\n        name=name,\n        prefix=key.prefix,\n        postfix=key.postfix,\n        key=key.hash,\n        permissions=[p for p in permissions],\n        description=description,\n        userId=user_id,\n    )\n)\n\napi_key_without_hash = APIKeyWithoutHash.from_db(api_key)\nreturn api_key_without_hash, key.raw", "successors": []}, {"id": 3, "label": "except PrismaError as e:\nlogger.error(f\"Database error while generating API key: {str(e)}\")\nraise APIKeyError(f\"Failed to generate API key: {str(e)}\")", "successors": []}, {"id": 5, "label": "except Exception as e:\nlogger.error(f\"Unexpected error while generating API key: {str(e)}\")\nraise APIKeyError(f\"Failed to generate API key: {str(e)}\")", "successors": []}]}]}, {"name": "validate_api_key", "type": "function", "start_line": 154, "end_line": 182, "functions": [], "classes": [], "simplified_code": "async def validate_api_key(plain_text_key: str) -> Optional[APIKey]:\n    \"\"\"\n    Validate an API key and return the API key object if valid.\n    \"\"\"\n    try:\n        if not plain_text_key.startswith(APIKeyManager.PREFIX):\n            logger.warning(\"Invalid API key format\")\n            return None\n\n        prefix = plain_text_key[: APIKeyManager.PREFIX_LENGTH]\n        api_manager = APIKeyManager()\n\n        api_key = await PrismaAPIKey.prisma().find_first(\n            where=APIKeyWhereInput(prefix=prefix, status=(APIKeyStatus.ACTIVE))\n        )\n\n        if not api_key:\n            logger.warning(f\"No active API key found with prefix {prefix}\")\n            return None\n\n        is_valid = api_manager.verify_api_key(plain_text_key, api_key.key)\n        if not is_valid:\n            logger.warning(\"API key verification failed\")\n            return None\n\n        return APIKey.from_db(api_key)\n    except Exception as e:\n        logger.error(f\"Error validating API key: {str(e)}\")\n        raise APIKeyValidationError(f\"Failed to validate API key: {str(e)}\")", "blocks": [{"id": 1, "label": "async def validate_api_key(plain_text_key: str) -> Optional[APIKey]:", "successors": []}]}, {"name": "revoke_api_key", "type": "function", "start_line": 185, "end_line": 215, "functions": [], "classes": [], "simplified_code": "async def revoke_api_key(key_id: str, user_id: str) -> Optional[APIKeyWithoutHash]:\n    try:\n        api_key = await PrismaAPIKey.prisma().find_unique(where={\"id\": key_id})\n\n        if not api_key:\n            raise APIKeyNotFoundError(f\"API key with id {key_id} not found\")\n\n        if api_key.userId != user_id:\n            raise APIKeyPermissionError(\n                \"You do not have permission to revoke this API key.\"\n            )\n\n        where_clause: APIKeyWhereUniqueInput = {\"id\": key_id}\n        updated_api_key = await PrismaAPIKey.prisma().update(\n            where=where_clause,\n            data=APIKeyUpdateInput(\n                status=APIKeyStatus.REVOKED, revokedAt=datetime.now(timezone.utc)\n            ),\n        )\n\n        if updated_api_key:\n            return APIKeyWithoutHash.from_db(updated_api_key)\n        return None\n    except (APIKeyNotFoundError, APIKeyPermissionError) as e:\n        raise e\n    except PrismaError as e:\n        logger.error(f\"Database error while revoking API key: {str(e)}\")\n        raise APIKeyError(f\"Failed to revoke API key: {str(e)}\")\n    except Exception as e:\n        logger.error(f\"Unexpected error while revoking API key: {str(e)}\")\n        raise APIKeyError(f\"Failed to revoke API key: {str(e)}\")", "blocks": [{"id": 1, "label": "async def revoke_api_key(key_id: str, user_id: str) -> Optional[APIKeyWithoutHash]:", "successors": [{"id": 2, "label": "try:\napi_key = await PrismaAPIKey.prisma().find_unique(where={\"id\": key_id})", "successors": [{"id": 4, "label": "if not api_key:\nraise APIKeyNotFoundError(f\"API key with id {key_id} not found\")", "successors": []}, {"id": 6, "label": "if api_key.userId != user_id:\nraise APIKeyPermissionError(\"You do not have permission to revoke this API key.\")", "successors": []}, {"id": 8, "label": "where_clause: APIKeyWhereUniqueInput = {\"id\": key_id}\nupdated_api_key = await PrismaAPIKey.prisma().update(\n    where=where_clause,\n    data=APIKeyUpdateInput(\n        status=APIKeyStatus.REVOKED, revokedAt=datetime.now(timezone.utc)\n    ),\n)", "successors": [{"id": 9, "label": "if updated_api_key:\nreturn APIKeyWithoutHash.from_db(updated_api_key)", "successors": []}, {"id": 11, "label": "return None", "successors": []}]}]}, {"id": 12, "label": "except (APIKeyNotFoundError, APIKeyPermissionError) as e:\nraise e", "successors": []}, {"id": 14, "label": "except PrismaError as e:\nlogger.error(f\"Database error while revoking API key: {str(e)}\")\nraise APIKeyError(f\"Failed to revoke API key: {str(e)}\")", "successors": []}, {"id": 16, "label": "except Exception as e:\nlogger.error(f\"Unexpected error while revoking API key: {str(e)}\")\nraise APIKeyError(f\"Failed to revoke API key: {str(e)}\")", "successors": []}]}]}, {"name": "list_user_api_keys", "type": "function", "start_line": 218, "end_line": 232, "functions": [], "classes": [], "simplified_code": "async def list_user_api_keys(user_id: str) -> List[APIKeyWithoutHash]:\n    try:\n        where_clause: APIKeyWhereInput = {\"userId\": user_id}\n\n        api_keys = await PrismaAPIKey.prisma().find_many(\n            where=where_clause, order={\"createdAt\": \"desc\"}\n        )\n\n        return [APIKeyWithoutHash.from_db(key) for key in api_keys]\n    except PrismaError as e:\n        logger.error(f\"Database error while listing API keys: {str(e)}\")\n        raise APIKeyError(f\"Failed to list API keys: {str(e)}\")\n    except Exception as e:\n        logger.error(f\"Unexpected error while listing API keys: {str(e)}\")\n        raise APIKeyError(f\"Failed to list API keys: {str(e)}\")", "blocks": [{"id": 1, "label": "async def list_user_api_keys(user_id: str) -> List[APIKeyWithoutHash]:\ntry:", "successors": [{"id": 3, "label": "where_clause: APIKeyWhereInput = {\"userId\": user_id}\n\napi_keys = await PrismaAPIKey.prisma().find_many(\n    where=where_clause, order={\"createdAt\": \"desc\"}\n)\n\nreturn [APIKeyWithoutHash.from_db(key) for key in api_keys]", "successors": []}, {"id": 4, "label": "except PrismaError as e:\nlogger.error(f\"Database error while listing API keys: {str(e)}\")\nraise APIKeyError(f\"Failed to list API keys: {str(e)}\")", "successors": []}, {"id": 6, "label": "except Exception as e:\nlogger.error(f\"Unexpected error while listing API keys: {str(e)}\")\nraise APIKeyError(f\"Failed to list API keys: {str(e)}\")", "successors": []}]}]}, {"name": "suspend_api_key", "type": "function", "start_line": 235, "end_line": 263, "functions": [], "classes": [], "simplified_code": "async def suspend_api_key(key_id: str, user_id: str) -> Optional[APIKeyWithoutHash]:\n    try:\n        api_key = await PrismaAPIKey.prisma().find_unique(where={\"id\": key_id})\n\n        if not api_key:\n            raise APIKeyNotFoundError(f\"API key with id {key_id} not found\")\n\n        if api_key.userId != user_id:\n            raise APIKeyPermissionError(\n                \"You do not have permission to suspend this API key.\"\n            )\n\n        where_clause: APIKeyWhereUniqueInput = {\"id\": key_id}\n        updated_api_key = await PrismaAPIKey.prisma().update(\n            where=where_clause,\n            data=APIKeyUpdateInput(status=APIKeyStatus.SUSPENDED),\n        )\n\n        if updated_api_key:\n            return APIKeyWithoutHash.from_db(updated_api_key)\n        return None\n    except (APIKeyNotFoundError, APIKeyPermissionError) as e:\n        raise e\n    except PrismaError as e:\n        logger.error(f\"Database error while suspending API key: {str(e)}\")\n        raise APIKeyError(f\"Failed to suspend API key: {str(e)}\")\n    except Exception as e:\n        logger.error(f\"Unexpected error while suspending API key: {str(e)}\")\n        raise APIKeyError(f\"Failed to suspend API key: {str(e)}\")", "blocks": [{"id": 1, "label": "async def suspend_api_key(key_id: str, user_id: str) -> Optional[APIKeyWithoutHash]:", "successors": [{"id": 2, "label": "try:\napi_key = await PrismaAPIKey.prisma().find_unique(where={\"id\": key_id})", "successors": [{"id": 4, "label": "if not api_key:", "successors": [{"id": 5, "label": "raise APIKeyNotFoundError(f\"API key with id {key_id} not found\")", "successors": []}, {"id": 6, "label": "if api_key.userId != user_id:", "successors": [{"id": 7, "label": "raise APIKeyPermissionError(\"You do not have permission to suspend this API key.\")", "successors": []}, {"id": 8, "label": "where_clause: APIKeyWhereUniqueInput = {\"id\": key_id}\nupdated_api_key = await PrismaAPIKey.prisma().update(\n    where=where_clause,\n    data=APIKeyUpdateInput(status=APIKeyStatus.SUSPENDED),\n)\nif updated_api_key:", "successors": [{"id": 10, "label": "return APIKeyWithoutHash.from_db(updated_api_key)", "successors": []}, {"id": 11, "label": "return None", "successors": []}]}]}]}]}, {"id": 12, "label": "except (APIKeyNotFoundError, APIKeyPermissionError) as e:\nraise e", "successors": []}, {"id": 14, "label": "except PrismaError as e:\nlogger.error(f\"Database error while suspending API key: {str(e)}\")\nraise APIKeyError(f\"Failed to suspend API key: {str(e)}\")", "successors": []}, {"id": 16, "label": "except Exception as e:\nlogger.error(f\"Unexpected error while suspending API key: {str(e)}\")\nraise APIKeyError(f\"Failed to suspend API key: {str(e)}\")", "successors": []}]}]}, {"name": "has_permission", "type": "function", "start_line": 266, "end_line": 271, "functions": [], "classes": [], "simplified_code": "def has_permission(api_key: APIKey, required_permission: APIKeyPermission) -> bool:\n    try:\n        return required_permission in api_key.permissions\n    except Exception as e:\n        logger.error(f\"Error checking API key permissions: {str(e)}\")\n        return False", "blocks": [{"id": 1, "label": "def has_permission(api_key: APIKey, required_permission: APIKeyPermission) -> bool:\ntry:", "successors": [{"id": 3, "label": "return required_permission in api_key.permissions", "successors": []}, {"id": 4, "label": "except Exception as e:\nlogger.error(f\"Error checking API key permissions: {str(e)}\")", "successors": [{"id": 6, "label": "return False", "successors": []}]}]}]}, {"name": "get_api_key_by_id", "type": "function", "start_line": 274, "end_line": 289, "functions": [], "classes": [], "simplified_code": "async def get_api_key_by_id(key_id: str, user_id: str) -> Optional[APIKeyWithoutHash]:\n    try:\n        api_key = await PrismaAPIKey.prisma().find_first(\n            where=APIKeyWhereInput(id=key_id, userId=user_id)\n        )\n\n        if not api_key:\n            return None\n\n        return APIKeyWithoutHash.from_db(api_key)\n    except PrismaError as e:\n        logger.error(f\"Database error while getting API key: {str(e)}\")\n        raise APIKeyError(f\"Failed to get API key: {str(e)}\")\n    except Exception as e:\n        logger.error(f\"Unexpected error while getting API key: {str(e)}\")\n        raise APIKeyError(f\"Failed to get API key: {str(e)}\")", "blocks": [{"id": 1, "label": "async def get_api_key_by_id(key_id: str, user_id: str) -> Optional[APIKeyWithoutHash]:\ntry:", "successors": [{"id": 3, "label": "api_key = await PrismaAPIKey.prisma().find_first(\n    where=APIKeyWhereInput(id=key_id, userId=user_id)\n)\nif not api_key:", "successors": [{"id": 5, "label": "return None", "successors": []}, {"id": 6, "label": "return APIKeyWithoutHash.from_db(api_key)", "successors": []}]}, {"id": 7, "label": "except PrismaError as e:\nlogger.error(f\"Database error while getting API key: {str(e)}\")\nraise APIKeyError(f\"Failed to get API key: {str(e)}\")", "successors": []}, {"id": 9, "label": "except Exception as e:\nlogger.error(f\"Unexpected error while getting API key: {str(e)}\")\nraise APIKeyError(f\"Failed to get API key: {str(e)}\")", "successors": []}]}]}, {"name": "update_api_key_permissions", "type": "function", "start_line": 292, "end_line": 325, "functions": [], "classes": [], "simplified_code": "async def update_api_key_permissions(\n    key_id: str, user_id: str, permissions: List[APIKeyPermission]\n) -> Optional[APIKeyWithoutHash]:\n    \"\"\"\n    Update the permissions of an API key.\n    \"\"\"\n    try:\n        api_key = await PrismaAPIKey.prisma().find_unique(where={\"id\": key_id})\n\n        if api_key is None:\n            raise APIKeyNotFoundError(\"No such API key found.\")\n\n        if api_key.userId != user_id:\n            raise APIKeyPermissionError(\n                \"You do not have permission to update this API key.\"\n            )\n\n        where_clause: APIKeyWhereUniqueInput = {\"id\": key_id}\n        updated_api_key = await PrismaAPIKey.prisma().update(\n            where=where_clause,\n            data=APIKeyUpdateInput(permissions=permissions),\n        )\n\n        if updated_api_key:\n            return APIKeyWithoutHash.from_db(updated_api_key)\n        return None\n    except (APIKeyNotFoundError, APIKeyPermissionError) as e:\n        raise e\n    except PrismaError as e:\n        logger.error(f\"Database error while updating API key permissions: {str(e)}\")\n        raise APIKeyError(f\"Failed to update API key permissions: {str(e)}\")\n    except Exception as e:\n        logger.error(f\"Unexpected error while updating API key permissions: {str(e)}\")\n        raise APIKeyError(f\"Failed to update API key permissions: {str(e)}\")", "blocks": [{"id": 1, "label": "async def update_api_key_permissions(\n    key_id: str, user_id: str, permissions: List[APIKeyPermission]\n) -> Optional[APIKeyWithoutHash]:\ntry:", "successors": [{"id": 3, "label": "    api_key = await PrismaAPIKey.prisma().find_unique(where={\"id\": key_id})", "successors": [{"id": 4, "label": "if api_key is None:\n    raise APIKeyNotFoundError(\"No such API key found.\")", "successors": []}, {"id": 6, "label": "if api_key.userId != user_id:\n    raise APIKeyPermissionError(\n        \"You do not have permission to update this API key.\"\n    )", "successors": []}, {"id": 8, "label": "where_clause: APIKeyWhereUniqueInput = {\"id\": key_id}\nupdated_api_key = await PrismaAPIKey.prisma().update(\n    where=where_clause,\n    data=APIKeyUpdateInput(permissions=permissions),\n)", "successors": [{"id": 9, "label": "if updated_api_key:\n    return APIKeyWithoutHash.from_db(updated_api_key)", "successors": []}, {"id": 11, "label": "return None", "successors": []}]}]}, {"id": 12, "label": "except (APIKeyNotFoundError, APIKeyPermissionError) as e:\n    raise e", "successors": []}, {"id": 14, "label": "except PrismaError as e:\n    logger.error(f\"Database error while updating API key permissions: {str(e)}\")\n    raise APIKeyError(f\"Failed to update API key permissions: {str(e)}\")", "successors": []}, {"id": 16, "label": "except Exception as e:\n    logger.error(f\"Unexpected error while updating API key permissions: {str(e)}\")\n    raise APIKeyError(f\"Failed to update API key permissions: {str(e)}\")", "successors": []}]}]}], "classes": [{"name": "APIKeyError", "type": "class", "start_line": 24, "end_line": 27, "functions": [], "classes": [], "simplified_code": "class APIKeyError(Exception):\n    \"\"\"Base exception for API key operations\"\"\"\n\n    pass", "blocks": [{"id": 1, "label": "class APIKeyError(Exception):\n    \"\"\"Base exception for API key operations\"\"\"\n\n    pass", "successors": []}]}, {"name": "APIKeyNotFoundError", "type": "class", "start_line": 30, "end_line": 33, "functions": [], "classes": [], "simplified_code": "class APIKeyNotFoundError(APIKeyError):\n    \"\"\"Raised when an API key is not found\"\"\"\n\n    pass", "blocks": [{"id": 1, "label": "class APIKeyNotFoundError(APIKeyError):\n\"\"\"Raised when an API key is not found\"\"\"\n\n    pass", "successors": []}]}, {"name": "APIKeyPermissionError", "type": "class", "start_line": 36, "end_line": 39, "functions": [], "classes": [], "simplified_code": "class APIKeyPermissionError(APIKeyError):\n    \"\"\"Raised when there are permission issues with API key operations\"\"\"\n\n    pass", "blocks": [{"id": 1, "label": "class APIKeyPermissionError(APIKeyError):\n    \"\"\"Raised when there are permission issues with API key operations\"\"\"", "successors": [{"id": 3, "label": "    pass", "successors": []}]}]}, {"name": "APIKeyValidationError", "type": "class", "start_line": 42, "end_line": 45, "functions": [], "classes": [], "simplified_code": "class APIKeyValidationError(APIKeyError):\n    \"\"\"Raised when API key validation fails\"\"\"\n\n    pass", "blocks": [{"id": 1, "label": "class APIKeyValidationError(APIKeyError):\n    \"\"\"Raised when API key validation fails\"\"\"", "successors": [{"id": 3, "label": "    pass", "successors": []}]}]}, {"name": "APIKey", "type": "class", "start_line": 48, "end_line": 80, "functions": [{"name": "from_db", "type": "function", "start_line": 62, "end_line": 80, "functions": [], "classes": [], "simplified_code": "    def from_db(api_key: PrismaAPIKey):\n        try:\n            return APIKey(\n                id=api_key.id,\n                name=api_key.name,\n                prefix=api_key.prefix,\n                postfix=api_key.postfix,\n                key=api_key.key,\n                status=APIKeyStatus(api_key.status),\n                permissions=[APIKeyPermission(p) for p in api_key.permissions],\n                created_at=api_key.createdAt,\n                last_used_at=api_key.lastUsedAt,\n                revoked_at=api_key.revokedAt,\n                description=api_key.description,\n                user_id=api_key.userId,\n            )\n        except Exception as e:\n            logger.error(f\"Error creating APIKey from db: {str(e)}\")\n            raise APIKeyError(f\"Failed to create API key object: {str(e)}\")", "blocks": [{"id": 1, "label": "try:", "successors": [{"id": 2, "label": "    return APIKey(\n        id=api_key.id,\n        name=api_key.name,\n        prefix=api_key.prefix,\n        postfix=api_key.postfix,\n        key=api_key.key,\n        status=APIKeyStatus(api_key.status),\n        permissions=[APIKeyPermission(p) for p in api_key.permissions],\n        created_at=api_key.createdAt,\n        last_used_at=api_key.lastUsedAt,\n        revoked_at=api_key.revokedAt,\n        description=api_key.description,\n        user_id=api_key.userId,\n    )", "successors": []}, {"id": 3, "label": "except Exception as e:\n    logger.error(f\"Error creating APIKey from db: {str(e)}\")", "successors": [{"id": 5, "label": "    raise APIKeyError(f\"Failed to create API key object: {str(e)}\")", "successors": []}]}]}]}], "classes": [], "simplified_code": "class APIKey(BaseDbModel):\n    name: str\n    prefix: str\n    key: str\n    status: APIKeyStatus = APIKeyStatus.ACTIVE\n    permissions: List[APIKeyPermission]\n    postfix: str\n    created_at: datetime\n    last_used_at: Optional[datetime] = None\n    revoked_at: Optional[datetime] = None\n    description: Optional[str] = None\n    user_id: str\n\n    @staticmethod\n            raise APIKeyError(f\"Failed to create API key object: {str(e)}\")", "blocks": [{"id": 1, "label": "class APIKey(BaseDbModel):\nname: str\nprefix: str\nkey: str\nstatus: APIKeyStatus = APIKeyStatus.ACTIVE\npermissions: List[APIKeyPermission]\npostfix: str\ncreated_at: datetime\nlast_used_at: Optional[datetime] = None\nrevoked_at: Optional[datetime] = None\ndescription: Optional[str] = None\nuser_id: str", "successors": [{"id": 3, "label": "@staticmethod\ndef create_from_headers(api_key: str, headers: Dict[str, str]) -> \"APIKey\":\n    try:", "successors": [{"id": 4, "label": "        user_id = headers[\"User-ID\"]\n        if not user_id:\n            raise ValueError(\"User-ID header is missing\")\n        prefix, postfix = headers.get(\"Prefix\", \"\"), headers.get(\"Postfix\", \"\")", "successors": [{"id": 6, "label": "        return APIKey(name=\"example\", prefix=prefix, key=api_key, status=APIKeyStatus.ACTIVE,\n                      permissions=[], postfix=postfix, created_at=datetime.now(),\n                      user_id=user_id)", "successors": []}]}, {"id": 7, "label": "    except KeyError as e:\n        raise APIKeyError(f\"Key not found in headers: {str(e)}\")", "successors": []}, {"id": 9, "label": "    except Exception as e:\n        raise APIKeyError(f\"Failed to create API key object: {str(e)}\")", "successors": []}]}]}]}, {"name": "APIKeyWithoutHash", "type": "class", "start_line": 83, "end_line": 114, "functions": [{"name": "from_db", "type": "function", "start_line": 97, "end_line": 114, "functions": [], "classes": [], "simplified_code": "    def from_db(api_key: PrismaAPIKey):\n        try:\n            return APIKeyWithoutHash(\n                id=api_key.id,\n                name=api_key.name,\n                prefix=api_key.prefix,\n                postfix=api_key.postfix,\n                status=APIKeyStatus(api_key.status),\n                permissions=[APIKeyPermission(p) for p in api_key.permissions],\n                created_at=api_key.createdAt,\n                last_used_at=api_key.lastUsedAt,\n                revoked_at=api_key.revokedAt,\n                description=api_key.description,\n                user_id=api_key.userId,\n            )\n        except Exception as e:\n            logger.error(f\"Error creating APIKeyWithoutHash from db: {str(e)}\")\n            raise APIKeyError(f\"Failed to create API key object: {str(e)}\")", "blocks": [{"id": 1, "label": "def from_db(api_key: PrismaAPIKey):\ntry:", "successors": [{"id": 3, "label": "return APIKeyWithoutHash(\n    id=api_key.id,\n    name=api_key.name,\n    prefix=api_key.prefix,\n    postfix=api_key.postfix,\n    status=APIKeyStatus(api_key.status),\n    permissions=[APIKeyPermission(p) for p in api_key.permissions],\n    created_at=api_key.createdAt,\n    last_used_at=api_key.lastUsedAt,\n    revoked_at=api_key.revokedAt,\n    description=api_key.description,\n    user_id=api_key.userId,\n)", "successors": []}, {"id": 4, "label": "except Exception as e:\nlogger.error(f\"Error creating APIKeyWithoutHash from db: {str(e)}\")", "successors": [{"id": 6, "label": "raise APIKeyError(f\"Failed to create API key object: {str(e)}\")", "successors": []}]}]}]}], "classes": [], "simplified_code": "class APIKeyWithoutHash(BaseModel):\n    id: str\n    name: str\n    prefix: str\n    postfix: str\n    status: APIKeyStatus\n    permissions: List[APIKeyPermission]\n    created_at: datetime\n    last_used_at: Optional[datetime]\n    revoked_at: Optional[datetime]\n    description: Optional[str]\n    user_id: str\n\n    @staticmethod\n            raise APIKeyError(f\"Failed to create API key object: {str(e)}\")", "blocks": [{"id": 1, "label": "class APIKeyWithoutHash(BaseModel):\n    id: str\n    name: str\n    prefix: str\n    postfix: str\n    status: APIKeyStatus\n    permissions: List[APIKeyPermission]\n    created_at: datetime\n    last_used_at: Optional[datetime]\n    revoked_at: Optional[datetime]\n    description: Optional[str]\n    user_id: str", "successors": [{"id": 3, "label": "@staticmethod\ndef example_static_method():\n    try:", "successors": [{"id": 5, "label": "        # Some code that could raise an exception\n        pass\n    except Exception as e:", "successors": [{"id": 8, "label": "        # Handle exception\n        raise APIKeyError(f\"Failed to create API key object: {str(e)}\")", "successors": []}]}]}]}]}], "simplified_code": "import logging\nimport uuid\nfrom datetime import datetime, timezone\nfrom typing import List, Optional\n\nfrom autogpt_libs.api_key.key_manager import APIKeyManager\nfrom prisma.enums import APIKeyPermission, APIKeyStatus\nfrom prisma.errors import PrismaError\nfrom prisma.models import APIKey as PrismaAPIKey\nfrom prisma.types import (\n    APIKeyCreateInput,\n    APIKeyUpdateInput,\n    APIKeyWhereInput,\n    APIKeyWhereUniqueInput,\n)\nfrom pydantic import BaseModel\n\nfrom backend.data.db import BaseDbModel\n\nlogger = logging.getLogger(__name__)\n\n\n# Some basic exceptions\n    pass\n\n\n    pass\n\n\n    pass\n\n\n    pass\n\n\n            raise APIKeyError(f\"Failed to create API key object: {str(e)}\")\n\n\n            raise APIKeyError(f\"Failed to create API key object: {str(e)}\")\n\n\n        raise APIKeyError(f\"Failed to generate API key: {str(e)}\")\n\n\n        raise APIKeyValidationError(f\"Failed to validate API key: {str(e)}\")\n\n\n        raise APIKeyError(f\"Failed to revoke API key: {str(e)}\")\n\n\n        raise APIKeyError(f\"Failed to list API keys: {str(e)}\")\n\n\n        raise APIKeyError(f\"Failed to suspend API key: {str(e)}\")\n\n\n        return False\n\n\n        raise APIKeyError(f\"Failed to get API key: {str(e)}\")\n\n\n        raise APIKeyError(f\"Failed to update API key permissions: {str(e)}\")", "blocks": [{"id": 1, "label": "import logging\nimport uuid\nfrom datetime import datetime, timezone\nfrom typing import List, Optional\n\nfrom autogpt_libs.api_key.key_manager import APIKeyManager\nfrom prisma.enums import APIKeyPermission, APIKeyStatus\nfrom prisma.errors import PrismaError\nfrom prisma.models import APIKey as PrismaAPIKey\nfrom prisma.types import (\n    APIKeyCreateInput,\n    APIKeyUpdateInput,\n    APIKeyWhereInput,\n    APIKeyWhereUniqueInput,\n)\nfrom pydantic import BaseModel\n\nfrom backend.data.db import BaseDbModel\nlogger = logging.getLogger(__name__)", "successors": []}]}
{"file_name": "46.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 128, "functions": [], "classes": [{"name": "ExaFindSimilarBlock", "type": "class", "start_line": 16, "end_line": 128, "functions": [{"name": "__init__", "type": "function", "start_line": 71, "end_line": 78, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"5e7315d1-af61-4a0c-9350-7c868fa7438a\",\n            description=\"Finds similar links using Exa's findSimilar API\",\n            categories={BlockCategory.SEARCH},\n            input_schema=ExaFindSimilarBlock.Input,\n            output_schema=ExaFindSimilarBlock.Output,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"5e7315d1-af61-4a0c-9350-7c868fa7438a\",\n    description=\"Finds similar links using Exa's findSimilar API\",\n    categories={BlockCategory.SEARCH},\n    input_schema=ExaFindSimilarBlock.Input,\n    output_schema=ExaFindSimilarBlock.Output,\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 80, "end_line": 128, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: ExaCredentials, **kwargs\n    ) -> BlockOutput:\n        url = \"https://api.exa.ai/findSimilar\"\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"x-api-key\": credentials.api_key.get_secret_value(),\n        }\n\n        payload = {\n            \"url\": input_data.url,\n            \"numResults\": input_data.number_of_results,\n            \"contents\": input_data.contents.dict(),\n        }\n\n        optional_field_mapping = {\n            \"include_domains\": \"includeDomains\",\n            \"exclude_domains\": \"excludeDomains\",\n            \"include_text\": \"includeText\",\n            \"exclude_text\": \"excludeText\",\n        }\n\n        # Add optional fields if they have values\n        for input_field, api_field in optional_field_mapping.items():\n            value = getattr(input_data, input_field)\n            if value:  # Only add non-empty values\n                payload[api_field] = value\n\n        date_field_mapping = {\n            \"start_crawl_date\": \"startCrawlDate\",\n            \"end_crawl_date\": \"endCrawlDate\",\n            \"start_published_date\": \"startPublishedDate\",\n            \"end_published_date\": \"endPublishedDate\",\n        }\n\n        # Add dates if they exist\n        for input_field, api_field in date_field_mapping.items():\n            value = getattr(input_data, input_field, None)\n            if value:\n                payload[api_field] = value.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\")\n\n        try:\n            response = requests.post(url, headers=headers, json=payload)\n            response.raise_for_status()\n            data = response.json()\n            yield \"results\", data.get(\"results\", [])\n        except Exception as e:\n            yield \"error\", str(e)\n            yield \"results\", []", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: ExaCredentials, **kwargs) -> BlockOutput:\nurl = \"https://api.exa.ai/findSimilar\"\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"x-api-key\": credentials.api_key.get_secret_value(),\n}", "successors": [{"id": 3, "label": "payload = {\n    \"url\": input_data.url,\n    \"numResults\": input_data.number_of_results,\n    \"contents\": input_data.contents.dict(),\n}\noptional_field_mapping = {\n    \"include_domains\": \"includeDomains\",\n    \"exclude_domains\": \"excludeDomains\",\n    \"include_text\": \"includeText\",\n    \"exclude_text\": \"excludeText\",\n}", "successors": [{"id": 5, "label": "for input_field, api_field in optional_field_mapping.items():", "successors": [{"id": 6, "label": "value = getattr(input_data, input_field)\nif value:  # Only add non-empty values\n    payload[api_field] = value", "successors": []}]}, {"id": 7, "label": "date_field_mapping = {\n    \"start_crawl_date\": \"startCrawlDate\",\n    \"end_crawl_date\": \"endCrawlDate\",\n    \"start_published_date\": \"startPublishedDate\",\n    \"end_published_date\": \"endPublishedDate\",\n}", "successors": [{"id": 8, "label": "for input_field, api_field in date_field_mapping.items():", "successors": [{"id": 9, "label": "value = getattr(input_data, input_field, None)\nif value:\n    payload[api_field] = value.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\")", "successors": []}]}, {"id": 10, "label": "try:", "successors": [{"id": 11, "label": "response = requests.post(url, headers=headers, json=payload)\nresponse.raise_for_status()\ndata = response.json()\nyield \"results\", data.get(\"results\", [])", "successors": []}, {"id": 12, "label": "except Exception as e:\nyield \"error\", str(e)\nyield \"results\", []", "successors": []}]}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 17, "end_line": 63, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: ExaCredentialsInput = ExaCredentialsField()\n        url: str = SchemaField(\n            description=\"The url for which you would like to find similar links\"\n        )\n        number_of_results: int = SchemaField(\n            description=\"Number of results to return\",\n            default=10,\n            advanced=True,\n        )\n        include_domains: List[str] = SchemaField(\n            description=\"Domains to include in search\",\n            default=[],\n            advanced=True,\n        )\n        exclude_domains: List[str] = SchemaField(\n            description=\"Domains to exclude from search\",\n            default=[],\n            advanced=True,\n        )\n        start_crawl_date: datetime = SchemaField(\n            description=\"Start date for crawled content\",\n        )\n        end_crawl_date: datetime = SchemaField(\n            description=\"End date for crawled content\",\n        )\n        start_published_date: datetime = SchemaField(\n            description=\"Start date for published content\",\n        )\n        end_published_date: datetime = SchemaField(\n            description=\"End date for published content\",\n        )\n        include_text: List[str] = SchemaField(\n            description=\"Text patterns to include (max 1 string, up to 5 words)\",\n            default=[],\n            advanced=True,\n        )\n        exclude_text: List[str] = SchemaField(\n            description=\"Text patterns to exclude (max 1 string, up to 5 words)\",\n            default=[],\n            advanced=True,\n        )\n        contents: ContentSettings = SchemaField(\n            description=\"Content retrieval settings\",\n            default=ContentSettings(),\n            advanced=True,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: ExaCredentialsInput = ExaCredentialsField()", "successors": [{"id": 3, "label": "    url: str = SchemaField(\n        description=\"The url for which you would like to find similar links\"\n    )\n    number_of_results: int = SchemaField(\n        description=\"Number of results to return\",\n        default=10,\n        advanced=True,\n    )", "successors": [{"id": 5, "label": "    include_domains: List[str] = SchemaField(\n        description=\"Domains to include in search\",\n        default=[],\n        advanced=True,\n    )\n    exclude_domains: List[str] = SchemaField(\n        description=\"Domains to exclude from search\",\n        default=[],\n        advanced=True,\n    )", "successors": [{"id": 7, "label": "    start_crawl_date: datetime = SchemaField(\n        description=\"Start date for crawled content\",\n    )\n    end_crawl_date: datetime = SchemaField(\n        description=\"End date for crawled content\",\n    )", "successors": [{"id": 9, "label": "    start_published_date: datetime = SchemaField(\n        description=\"Start date for published content\",\n    )\n    end_published_date: datetime = SchemaField(\n        description=\"End date for published content\",\n    )", "successors": [{"id": 11, "label": "    include_text: List[str] = SchemaField(\n        description=\"Text patterns to include (max 1 string, up to 5 words)\",\n        default=[],\n        advanced=True,\n    )\n    exclude_text: List[str] = SchemaField(\n        description=\"Text patterns to exclude (max 1 string, up to 5 words)\",\n        default=[],\n        advanced=True,\n    )", "successors": [{"id": 13, "label": "    contents: ContentSettings = SchemaField(\n        description=\"Content retrieval settings\",\n        default=ContentSettings(),\n        advanced=True,\n    )", "successors": []}]}]}]}]}]}]}]}, {"name": "Output", "type": "class", "start_line": 65, "end_line": 69, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        results: List[Any] = SchemaField(\n            description=\"List of similar documents with title, URL, published date, author, and score\",\n            default=[],\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    results: List[Any] = SchemaField(", "successors": [{"id": 3, "label": "        description=\"List of similar documents with title, URL, published date, author, and score\",\n        default=[],", "successors": []}]}]}], "simplified_code": "class ExaFindSimilarBlock(Block):\n        )\n\n        )\n\n        )\n\n            yield \"results\", []", "blocks": [{"id": 1, "label": "class ExaFindSimilarBlock(Block):\nyield \"results\", []", "successors": []}]}], "simplified_code": "from datetime import datetime\nfrom typing import Any, List\n\nfrom backend.blocks.exa._auth import (\n    ExaCredentials,\n    ExaCredentialsField,\n    ExaCredentialsInput,\n)\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\nfrom backend.util.request import requests\n\nfrom .helpers import ContentSettings\n\n\n            yield \"results\", []", "blocks": [{"id": 1, "label": "from datetime import datetime\nfrom typing import Any, List\n\nfrom backend.blocks.exa._auth import (\n    ExaCredentials,\n    ExaCredentialsField,\n    ExaCredentialsInput,\n)\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\nfrom backend.util.request import requests\n\nfrom .helpers import ContentSettings\nyield \"results\", []", "successors": []}]}
{"file_name": "47.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 75, "functions": [{"name": "_log_prefix", "type": "function", "start_line": 15, "end_line": 21, "functions": [], "classes": [], "simplified_code": "def _log_prefix(resource_name: str, conn_id: str):\n    \"\"\"\n    Returns a prefix string for logging purposes.\n    This needs to be called on the fly to get the current process ID & service name,\n    not the parent process ID & service name.\n    \"\"\"\n    return f\"[PID-{os.getpid()}|THREAD-{threading.get_native_id()}|{get_service_name()}|{resource_name}-{conn_id}]\"", "blocks": [{"id": 1, "label": "def _log_prefix(resource_name: str, conn_id: str):\n    \"\"\"\n    Returns a prefix string for logging purposes.\n    This needs to be called on the fly to get the current process ID & service name,\n    not the parent process ID & service name.\n    \"\"\"", "successors": [{"id": 3, "label": "    return f\"[PID-{os.getpid()}|THREAD-{threading.get_native_id()}|{get_service_name()}|{resource_name}-{conn_id}]\"", "successors": []}]}]}, {"name": "conn_retry", "type": "function", "start_line": 24, "end_line": 75, "functions": [{"name": "on_retry", "type": "function", "start_line": 34, "end_line": 37, "functions": [], "classes": [], "simplified_code": "    def on_retry(retry_state):\n        prefix = _log_prefix(resource_name, conn_id)\n        exception = retry_state.outcome.exception()\n        logger.error(f\"{prefix} {action_name} failed: {exception}. Retrying now...\")", "blocks": [{"id": 1, "label": "def on_retry(retry_state):\n    prefix = _log_prefix(resource_name, conn_id)", "successors": [{"id": 3, "label": "    exception = retry_state.outcome.exception()\n    logger.error(f\"{prefix} {action_name} failed: {exception}. Retrying now...\")", "successors": []}]}]}, {"name": "decorator", "type": "function", "start_line": 39, "end_line": 73, "functions": [{"name": "sync_wrapper", "type": "function", "start_line": 50, "end_line": 59, "functions": [], "classes": [], "simplified_code": "        def sync_wrapper(*args, **kwargs):\n            prefix = _log_prefix(resource_name, conn_id)\n            logger.info(f\"{prefix} {action_name} started...\")\n            try:\n                result = wrapped_func(*args, **kwargs)\n                logger.info(f\"{prefix} {action_name} completed successfully.\")\n                return result\n            except Exception as e:\n                logger.error(f\"{prefix} {action_name} failed after retries: {e}\")\n                raise", "blocks": [{"id": 1, "label": "def sync_wrapper(*args, **kwargs):\n    prefix = _log_prefix(resource_name, conn_id)\n    logger.info(f\"{prefix} {action_name} started...\")", "successors": [{"id": 3, "label": "try:", "successors": [{"id": 4, "label": "    result = wrapped_func(*args, **kwargs)\n    logger.info(f\"{prefix} {action_name} completed successfully.\")\n    return result", "successors": []}, {"id": 5, "label": "except Exception as e:\n    logger.error(f\"{prefix} {action_name} failed after retries: {e}\")\n    raise", "successors": []}]}]}]}, {"name": "async_wrapper", "type": "function", "start_line": 62, "end_line": 71, "functions": [], "classes": [], "simplified_code": "        async def async_wrapper(*args, **kwargs):\n            prefix = _log_prefix(resource_name, conn_id)\n            logger.info(f\"{prefix} {action_name} started...\")\n            try:\n                result = await wrapped_func(*args, **kwargs)\n                logger.info(f\"{prefix} {action_name} completed successfully.\")\n                return result\n            except Exception as e:\n                logger.error(f\"{prefix} {action_name} failed after retries: {e}\")\n                raise", "blocks": [{"id": 1, "label": "async def async_wrapper(*args, **kwargs):\nprefix = _log_prefix(resource_name, conn_id)\nlogger.info(f\"{prefix} {action_name} started...\")", "successors": [{"id": 3, "label": "try:", "successors": [{"id": 4, "label": "result = await wrapped_func(*args, **kwargs)\nlogger.info(f\"{prefix} {action_name} completed successfully.\")\nreturn result", "successors": []}, {"id": 5, "label": "except Exception as e:\nlogger.error(f\"{prefix} {action_name} failed after retries: {e}\")\nraise", "successors": []}]}]}]}], "classes": [], "simplified_code": "    def decorator(func):\n        is_coroutine = asyncio.iscoroutinefunction(func)\n        retry_decorator = retry(\n            stop=stop_after_attempt(max_retry + 1),\n            wait=wait_exponential(multiplier=multiplier, min=min_wait, max=max_wait),\n            before_sleep=on_retry,\n            reraise=True,\n        )\n        wrapped_func = retry_decorator(func)\n\n        @wraps(func)\n                raise\n\n        @wraps(func)\n                raise\n\n        return async_wrapper if is_coroutine else sync_wrapper", "blocks": [{"id": 1, "label": "def decorator(func):\nis_coroutine = asyncio.iscoroutinefunction(func)\nretry_decorator = retry(\n    stop=stop_after_attempt(max_retry + 1),\n    wait=wait_exponential(multiplier=multiplier, min=min_wait, max=max_wait),\n    before_sleep=on_retry,\n    reraise=True,\n)\nwrapped_func = retry_decorator(func)", "successors": [{"id": 3, "label": "if is_coroutine:", "successors": [{"id": 4, "label": "async def async_wrapper(*args, **kwargs):\ntry:", "successors": [{"id": 6, "label": "return await wrapped_func(*args, **kwargs)\n    return async_wrapper if is_coroutine else sync_wrapper", "successors": []}, {"id": 7, "label": "except Exception as e:\nlogger.exception(\"Error executing function\")\nraise", "successors": [{"id": 11, "label": "    return async_wrapper if is_coroutine else sync_wrapper", "successors": []}]}]}, {"id": 9, "label": "else:\ndef sync_wrapper(*args, **kwargs):\n    try:\n        return wrapped_func(*args, **kwargs)\n    except Exception as e:\n        logger.exception(\"Error executing function\")\n        raise", "successors": [{"id": 11, "label": "    return async_wrapper if is_coroutine else sync_wrapper", "successors": []}]}]}]}]}], "classes": [], "simplified_code": "def conn_retry(\n    resource_name: str,\n    action_name: str,\n    max_retry: int = 5,\n    multiplier: int = 1,\n    min_wait: float = 1,\n    max_wait: float = 30,\n):\n    conn_id = str(uuid4())\n\n        logger.error(f\"{prefix} {action_name} failed: {exception}. Retrying now...\")\n\n        return async_wrapper if is_coroutine else sync_wrapper\n\n    return decorator", "blocks": [{"id": 1, "label": "def conn_retry(\n    resource_name: str,\n    action_name: str,\n    max_retry: int = 5,\n    multiplier: int = 1,\n    min_wait: float = 1,\n    max_wait: float = 30,\n):\n    conn_id = str(uuid4())", "successors": [{"id": 3, "label": "    logger.error(f\"{prefix} {action_name} failed: {exception}. Retrying now...\")", "successors": []}, {"id": 4, "label": "    return async_wrapper if is_coroutine else sync_wrapper", "successors": []}, {"id": 5, "label": "    return decorator", "successors": []}]}]}], "classes": [], "simplified_code": "import asyncio\nimport logging\nimport os\nimport threading\nfrom functools import wraps\nfrom uuid import uuid4\n\nfrom tenacity import retry, stop_after_attempt, wait_exponential\n\nfrom backend.util.process import get_service_name\n\nlogger = logging.getLogger(__name__)\n\n\n    return f\"[PID-{os.getpid()}|THREAD-{threading.get_native_id()}|{get_service_name()}|{resource_name}-{conn_id}]\"\n\n\n    return decorator", "blocks": [{"id": 1, "label": "import asyncio\nimport logging\nimport os\nimport threading\nfrom functools import wraps\nfrom uuid import uuid4\n\nfrom tenacity import retry, stop_after_attempt, wait_exponential\n\nfrom backend.util.process import get_service_name\n\nlogger = logging.getLogger(__name__)", "successors": []}]}
{"file_name": "48.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 61, "functions": [{"name": "match_word_pattern", "type": "function", "start_line": 1, "end_line": 55, "functions": [{"name": "backtrack", "type": "function", "start_line": 19, "end_line": 51, "functions": [], "classes": [], "simplified_code": "    def backtrack(pattern_index: int, str_index: int) -> bool:\n        \"\"\"\n        >>> backtrack(0, 0)\n        True\n\n        >>> backtrack(0, 1)\n        True\n\n        >>> backtrack(0, 4)\n        False\n        \"\"\"\n        if pattern_index == len(pattern) and str_index == len(input_string):\n            return True\n        if pattern_index == len(pattern) or str_index == len(input_string):\n            return False\n        char = pattern[pattern_index]\n        if char in pattern_map:\n            mapped_str = pattern_map[char]\n            if input_string.startswith(mapped_str, str_index):\n                return backtrack(pattern_index + 1, str_index + len(mapped_str))\n            else:\n                return False\n        for end in range(str_index + 1, len(input_string) + 1):\n            substr = input_string[str_index:end]\n            if substr in str_map:\n                continue\n            pattern_map[char] = substr\n            str_map[substr] = char\n            if backtrack(pattern_index + 1, end):\n                return True\n            del pattern_map[char]\n            del str_map[substr]\n        return False", "blocks": [{"id": 1, "label": "def backtrack(pattern_index: int, str_index: int) -> bool:", "successors": [{"id": 2, "label": "if pattern_index == len(pattern) and str_index == len(input_string):\nreturn True", "successors": []}, {"id": 4, "label": "if pattern_index == len(pattern) or str_index == len(input_string):\nreturn False", "successors": []}, {"id": 6, "label": "char = pattern[pattern_index]", "successors": [{"id": 7, "label": "if char in pattern_map:\nmapped_str = pattern_map[char]", "successors": [{"id": 9, "label": "if input_string.startswith(mapped_str, str_index):\nreturn backtrack(pattern_index + 1, str_index + len(mapped_str))", "successors": []}, {"id": 11, "label": "else:\nreturn False", "successors": []}]}, {"id": 13, "label": "for end in range(str_index + 1, len(input_string) + 1):", "successors": [{"id": 14, "label": "substr = input_string[str_index:end]", "successors": [{"id": 15, "label": "if substr in str_map:\ncontinue", "successors": []}, {"id": 17, "label": "pattern_map[char] = substr\nstr_map[substr] = char", "successors": [{"id": 18, "label": "if backtrack(pattern_index + 1, end):\nreturn True", "successors": []}, {"id": 20, "label": "del pattern_map[char]\ndel str_map[substr]", "successors": []}]}]}]}, {"id": 21, "label": "return False", "successors": []}]}]}]}], "classes": [], "simplified_code": "def match_word_pattern(pattern: str, input_string: str) -> bool:\n    \"\"\"\n    Determine if a given pattern matches a string using backtracking.\n\n    pattern: The pattern to match.\n    input_string: The string to match against the pattern.\n    return: True if the pattern matches the string, False otherwise.\n\n    >>> match_word_pattern(\"aba\", \"GraphTreesGraph\")\n    True\n\n    >>> match_word_pattern(\"xyx\", \"PythonRubyPython\")\n    True\n\n    >>> match_word_pattern(\"GG\", \"PythonJavaPython\")\n    False\n    \"\"\"\n\n        return False\n\n    pattern_map: dict[str, str] = {}\n    str_map: dict[str, str] = {}\n    return backtrack(0, 0)", "blocks": [{"id": 1, "label": "def match_word_pattern(pattern: str, input_string: str) -> bool:\npattern_map: dict[str, str] = {}\nstr_map: dict[str, str] = {}", "successors": [{"id": 3, "label": "return backtrack(0, 0)", "successors": []}]}]}], "classes": [], "simplified_code": "    return backtrack(0, 0)\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()", "blocks": [{"id": 1, "label": "return backtrack(0, 0)", "successors": []}]}
{"file_name": "49.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 109, "functions": [], "classes": [{"name": "ReadCsvBlock", "type": "class", "start_line": 5, "end_line": 109, "functions": [{"name": "__init__", "type": "function", "start_line": 48, "end_line": 70, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"acf7625e-d2cb-4941-bfeb-2819fc6fc015\",\n            input_schema=ReadCsvBlock.Input,\n            output_schema=ReadCsvBlock.Output,\n            description=\"Reads a CSV file and outputs the data as a list of dictionaries and individual rows via rows.\",\n            contributors=[ContributorDetails(name=\"Nicholas Tindle\")],\n            categories={BlockCategory.TEXT, BlockCategory.DATA},\n            test_input={\n                \"contents\": \"a, b, c\\n1,2,3\\n4,5,6\",\n            },\n            test_output=[\n                (\"row\", {\"a\": \"1\", \"b\": \"2\", \"c\": \"3\"}),\n                (\"row\", {\"a\": \"4\", \"b\": \"5\", \"c\": \"6\"}),\n                (\n                    \"all_data\",\n                    [\n                        {\"a\": \"1\", \"b\": \"2\", \"c\": \"3\"},\n                        {\"a\": \"4\", \"b\": \"5\", \"c\": \"6\"},\n                    ],\n                ),\n            ],\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"acf7625e-d2cb-4941-bfeb-2819fc6fc015\",\n    input_schema=ReadCsvBlock.Input,\n    output_schema=ReadCsvBlock.Output,\n    description=\"Reads a CSV file and outputs the data as a list of dictionaries and individual rows via rows.\",\n    contributors=[ContributorDetails(name=\"Nicholas Tindle\")],\n    categories={BlockCategory.TEXT, BlockCategory.DATA},\n    test_input={\n        \"contents\": \"a, b, c\\n1,2,3\\n4,5,6\",\n    },\n    test_output=[\n        (\"row\", {\"a\": \"1\", \"b\": \"2\", \"c\": \"3\"}),\n        (\"row\", {\"a\": \"4\", \"b\": \"5\", \"c\": \"6\"}),\n        (\n            \"all_data\",\n            [\n                {\"a\": \"1\", \"b\": \"2\", \"c\": \"3\"},\n                {\"a\": \"4\", \"b\": \"5\", \"c\": \"6\"},\n            ],\n        ),\n    ],\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 72, "end_line": 109, "functions": [{"name": "process_row", "type": "function", "start_line": 93, "end_line": 101, "functions": [], "classes": [], "simplified_code": "        def process_row(row):\n            data = {}\n            for i, value in enumerate(row):\n                if i not in input_data.skip_columns:\n                    if input_data.has_header and header:\n                        data[header[i]] = value.strip() if input_data.strip else value\n                    else:\n                        data[str(i)] = value.strip() if input_data.strip else value\n            return data", "blocks": [{"id": 1, "label": "def process_row(row):\ndata = {}", "successors": [{"id": 3, "label": "for i, value in enumerate(row):", "successors": [{"id": 4, "label": "if i not in input_data.skip_columns:\nif input_data.has_header and header:", "successors": [{"id": 6, "label": "data[header[i]] = value.strip() if input_data.strip else value\nreturn data", "successors": []}, {"id": 7, "label": "else:\ndata[str(i)] = value.strip() if input_data.strip else value", "successors": [{"id": 9, "label": "return data", "successors": []}]}]}, {"id": 9, "label": "return data", "successors": []}]}]}]}], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        import csv\n        from io import StringIO\n\n        csv_file = StringIO(input_data.contents)\n        reader = csv.reader(\n            csv_file,\n            delimiter=input_data.delimiter,\n            quotechar=input_data.quotechar,\n            escapechar=input_data.escapechar,\n        )\n\n        header = None\n        if input_data.has_header:\n            header = next(reader)\n            if input_data.strip:\n                header = [h.strip() for h in header]\n\n        for _ in range(input_data.skip_rows):\n            next(reader)\n\n            return data\n\n        all_data = []\n        for row in reader:\n            processed_row = process_row(row)\n            all_data.append(processed_row)\n            yield \"row\", processed_row\n\n        yield \"all_data\", all_data", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\nimport csv\nfrom io import StringIO", "successors": [{"id": 3, "label": "csv_file = StringIO(input_data.contents)\nreader = csv.reader(\n    csv_file,\n    delimiter=input_data.delimiter,\n    quotechar=input_data.quotechar,\n    escapechar=input_data.escapechar,\n)\nheader = None", "successors": [{"id": 5, "label": "if input_data.has_header:\nheader = next(reader)\nif input_data.strip:\n    header = [h.strip() for h in header]", "successors": [{"id": 7, "label": "for _ in range(input_data.skip_rows):", "successors": [{"id": 8, "label": "next(reader)\nreturn data", "successors": []}]}, {"id": 9, "label": "all_data = []\nfor row in reader:\n    processed_row = process_row(row)\n    all_data.append(processed_row)\n    yield \"row\", processed_row\nyield \"all_data\", all_data", "successors": []}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 6, "end_line": 38, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        contents: str = SchemaField(\n            description=\"The contents of the CSV file to read\",\n            placeholder=\"a, b, c\\n1,2,3\\n4,5,6\",\n        )\n        delimiter: str = SchemaField(\n            description=\"The delimiter used in the CSV file\",\n            default=\",\",\n        )\n        quotechar: str = SchemaField(\n            description=\"The character used to quote fields\",\n            default='\"',\n        )\n        escapechar: str = SchemaField(\n            description=\"The character used to escape the delimiter\",\n            default=\"\\\\\",\n        )\n        has_header: bool = SchemaField(\n            description=\"Whether the CSV file has a header row\",\n            default=True,\n        )\n        skip_rows: int = SchemaField(\n            description=\"The number of rows to skip from the start of the file\",\n            default=0,\n        )\n        strip: bool = SchemaField(\n            description=\"Whether to strip whitespace from the values\",\n            default=True,\n        )\n        skip_columns: list[str] = SchemaField(\n            description=\"The columns to skip from the start of the row\",\n            default=[],\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\ncontents: str = SchemaField(\n    description=\"The contents of the CSV file to read\",\n    placeholder=\"a, b, c\\n1,2,3\\n4,5,6\",\n)", "successors": [{"id": 3, "label": "delimiter: str = SchemaField(\n    description=\"The delimiter used in the CSV file\",\n    default=\",\",\n)\nquotechar: str = SchemaField(\n    description=\"The character used to quote fields\",\n    default='\"',\n)", "successors": [{"id": 5, "label": "escapechar: str = SchemaField(\n    description=\"The character used to escape the delimiter\",\n    default=\"\\\\\",\n)\nhas_header: bool = SchemaField(\n    description=\"Whether the CSV file has a header row\",\n    default=True,\n)", "successors": [{"id": 7, "label": "skip_rows: int = SchemaField(\n    description=\"The number of rows to skip from the start of the file\",\n    default=0,\n)\nstrip: bool = SchemaField(\n    description=\"Whether to strip whitespace from the values\",\n    default=True,\n)", "successors": [{"id": 9, "label": "skip_columns: list[str] = SchemaField(\n    description=\"The columns to skip from the start of the row\",\n    default=[],\n)", "successors": []}]}]}]}]}]}, {"name": "Output", "type": "class", "start_line": 40, "end_line": 46, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        row: dict[str, str] = SchemaField(\n            description=\"The data produced from each row in the CSV file\"\n        )\n        all_data: list[dict[str, str]] = SchemaField(\n            description=\"All the data in the CSV file as a list of rows\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    row: dict[str, str] = SchemaField(\n        description=\"The data produced from each row in the CSV file\"\n    )", "successors": [{"id": 3, "label": "    all_data: list[dict[str, str]] = SchemaField(\n        description=\"All the data in the CSV file as a list of rows\"\n    )", "successors": []}]}]}], "simplified_code": "class ReadCsvBlock(Block):\n        )\n\n        )\n\n        )\n\n        yield \"all_data\", all_data", "blocks": [{"id": 1, "label": "class ReadCsvBlock(Block):\n\n    def run(self):", "successors": [{"id": 3, "label": "df = pd.read_csv(self.path, nrows=50)\nprint(\"Initial data read successfully\")", "successors": [{"id": 5, "label": "for column in df.columns:", "successors": [{"id": 6, "label": "if df[column].dtype == 'object':", "successors": [{"id": 7, "label": "df[column] = df[column].astype(str)\nprint(f\"Converted column {column} to string\")", "successors": [{"id": 5, "label": "for column in df.columns:", "successors": []}]}, {"id": 8, "label": "else:\nprint(f\"Converted column {column} to string\")", "successors": [{"id": 5, "label": "for column in df.columns:", "successors": []}]}]}, {"id": 10, "label": "all_data = df.to_dict(orient='list')\nprint(\"Data conversion to dict format complete\")", "successors": [{"id": 12, "label": "yield \"all_data\", all_data", "successors": []}]}]}]}]}]}], "simplified_code": "from backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import ContributorDetails, SchemaField\n\n\n        yield \"all_data\", all_data", "blocks": [{"id": 1, "label": "from backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import ContributorDetails, SchemaField", "successors": [{"id": 3, "label": "yield \"all_data\", all_data", "successors": []}]}]}
{"file_name": "50.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 70, "functions": [{"name": "Slant3DCredentialsField", "type": "function", "start_line": 14, "end_line": 15, "functions": [], "classes": [], "simplified_code": "def Slant3DCredentialsField() -> Slant3DCredentialsInput:\n    return CredentialsField(description=\"Slant3D API key for authentication\")", "blocks": [{"id": 1, "label": "def Slant3DCredentialsField() -> Slant3DCredentialsInput:\n    return CredentialsField(description=\"Slant3D API key for authentication\")", "successors": []}]}], "classes": [{"name": "CustomerDetails", "type": "class", "start_line": 34, "end_line": 43, "functions": [], "classes": [], "simplified_code": "class CustomerDetails(BaseModel):\n    name: str\n    email: str\n    phone: str\n    address: str\n    city: str\n    state: str\n    zip: str\n    country_iso: str = \"US\"\n    is_residential: bool = True", "blocks": [{"id": 1, "label": "class CustomerDetails(BaseModel):\n    name: str\n    email: str\n    phone: str\n    address: str\n    city: str\n    state: str\n    zip: str\n    country_iso: str = \"US\"\n    is_residential: bool = True", "successors": []}]}, {"name": "Color", "type": "class", "start_line": 46, "end_line": 48, "functions": [], "classes": [], "simplified_code": "class Color(Enum):\n    WHITE = \"white\"\n    BLACK = \"black\"", "blocks": [{"id": 1, "label": "class Color(Enum):\n    WHITE = \"white\"", "successors": [{"id": 3, "label": "    BLACK = \"black\"", "successors": []}]}]}, {"name": "Profile", "type": "class", "start_line": 51, "end_line": 53, "functions": [], "classes": [], "simplified_code": "class Profile(Enum):\n    PLA = \"PLA\"\n    PETG = \"PETG\"", "blocks": [{"id": 1, "label": "class Profile(Enum):\n    PLA = \"PLA\"\n    PETG = \"PETG\"", "successors": []}]}, {"name": "OrderItem", "type": "class", "start_line": 56, "end_line": 61, "functions": [], "classes": [], "simplified_code": "class OrderItem(BaseModel):\n    # filename: str\n    file_url: str\n    quantity: str  # String as per API spec\n    color: Color = Color.WHITE\n    profile: Profile = Profile.PLA", "blocks": [{"id": 1, "label": "class OrderItem(BaseModel):", "successors": [{"id": 2, "label": "    file_url: str", "successors": []}, {"id": 3, "label": "    quantity: str  # String as per API spec", "successors": []}, {"id": 4, "label": "    color: Color = Color.WHITE", "successors": []}, {"id": 5, "label": "    profile: Profile = Profile.PLA", "successors": []}]}]}, {"name": "Filament", "type": "class", "start_line": 66, "end_line": 70, "functions": [], "classes": [], "simplified_code": "class Filament(BaseModel):\n    filament: str\n    hexColor: str\n    colorTag: str\n    profile: str", "blocks": [{"id": 1, "label": "class Filament(BaseModel):\n    filament: str", "successors": [{"id": 3, "label": "    hexColor: str\n    colorTag: str", "successors": [{"id": 5, "label": "    profile: str", "successors": []}]}]}]}], "simplified_code": "from enum import Enum\nfrom typing import Literal\n\nfrom pydantic import BaseModel, SecretStr\n\nfrom backend.data.model import APIKeyCredentials, CredentialsField, CredentialsMetaInput\nfrom backend.integrations.providers import ProviderName\n\nSlant3DCredentialsInput = CredentialsMetaInput[\n    Literal[ProviderName.SLANT3D], Literal[\"api_key\"]\n]\n\n\n    return CredentialsField(description=\"Slant3D API key for authentication\")\n\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"slant3d\",\n    api_key=SecretStr(\"mock-slant3d-api-key\"),\n    title=\"Mock Slant3D API key\",\n    expires_at=None,\n)\n\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.title,\n}\n\n\n    is_residential: bool = True\n\n\n    BLACK = \"black\"\n\n\n    PETG = \"PETG\"\n\n\n    profile: Profile = Profile.PLA\n    # image_url: str = \"\"\n    # sku: str = \"\"\n\n\n    profile: str", "blocks": [{"id": 1, "label": "from enum import Enum\nfrom typing import Literal\n\nfrom pydantic import BaseModel, SecretStr\n\nfrom backend.data.model import APIKeyCredentials, CredentialsField, CredentialsMetaInput\nfrom backend.integrations.providers import ProviderName\n\nSlant3DCredentialsInput = CredentialsMetaInput[\n    Literal[ProviderName.SLANT3D], Literal[\"api_key\"]\n]\n\n\n    return CredentialsField(description=\"Slant3D API key for authentication\")\n\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"slant3d\",\n    api_key=SecretStr(\"mock-slant3d-api-key\"),\n    title=\"Mock Slant3D API key\",\n    expires_at=None,\n)\n\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.title,\n}\n\n\n    is_residential: bool = True\n\n\n    BLACK = \"black\"\n\n\n    PETG = \"PETG\"\n\n\n    profile: Profile = Profile.PLA\n    # image_url: str = \"\"\n    # sku: str = \"\"\n\n\n    profile: str\n", "successors": []}]}
{"file_name": "51.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 66, "functions": [{"name": "backtrack", "type": "function", "start_line": 16, "end_line": 38, "functions": [], "classes": [], "simplified_code": "def backtrack(\n    candidates: list, path: list, answer: list, target: int, previous_index: int\n) -> None:\n    \"\"\"\n    A recursive function that searches for possible combinations. Backtracks in case\n    of a bigger current combination value than the target value.\n\n    Parameters\n    ----------\n    previous_index: Last index from the previous search\n    target: The value we need to obtain by summing our integers in the path list.\n    answer: A list of possible combinations\n    path: Current combination\n    candidates: A list of integers we can use.\n    \"\"\"\n    if target == 0:\n        answer.append(path.copy())\n    else:\n        for index in range(previous_index, len(candidates)):\n            if target >= candidates[index]:\n                path.append(candidates[index])\n                backtrack(candidates, path, answer, target - candidates[index], index)\n                path.pop(len(path) - 1)", "blocks": [{"id": 1, "label": "def backtrack(candidates: list, path: list, answer: list, target: int, previous_index: int) -> None:", "successors": [{"id": 2, "label": "if target == 0:\nanswer.append(path.copy())", "successors": []}, {"id": 4, "label": "for index in range(previous_index, len(candidates)):", "successors": [{"id": 5, "label": "if target >= candidates[index]:\npath.append(candidates[index])", "successors": [{"id": 7, "label": "backtrack(candidates, path, answer, target - candidates[index], index)\npath.pop(len(path) - 1)", "successors": []}]}]}]}]}, {"name": "combination_sum", "type": "function", "start_line": 41, "end_line": 55, "functions": [], "classes": [], "simplified_code": "def combination_sum(candidates: list, target: int) -> list:\n    \"\"\"\n    >>> combination_sum([2, 3, 5], 8)\n    [[2, 2, 2, 2], [2, 3, 3], [3, 5]]\n    >>> combination_sum([2, 3, 6, 7], 7)\n    [[2, 2, 3], [7]]\n    >>> combination_sum([-8, 2.3, 0], 1)\n    Traceback (most recent call last):\n        ...\n    RecursionError: maximum recursion depth exceeded\n    \"\"\"\n    path = []  # type: list[int]\n    answer = []  # type: list[int]\n    backtrack(candidates, path, answer, target, 0)\n    return answer", "blocks": [{"id": 1, "label": "def combination_sum(candidates: list, target: int) -> list:\n    path = []  # type: list[int]", "successors": [{"id": 3, "label": "    answer = []  # type: list[int]\n    backtrack(candidates, path, answer, target, 0)", "successors": [{"id": 5, "label": "    return answer", "successors": []}]}]}]}, {"name": "main", "type": "function", "start_line": 58, "end_line": 59, "functions": [], "classes": [], "simplified_code": "def main() -> None:\n    print(combination_sum([-8, 2.3, 0], 1))", "blocks": [{"id": 1, "label": "print(combination_sum([-8, 2.3, 0], 1))", "successors": []}]}], "classes": [], "simplified_code": "\"\"\"\nIn the Combination Sum problem, we are given a list consisting of distinct integers.\nWe need to find all the combinations whose sum equals to target given.\nWe can use an element more than one.\n\nTime complexity(Average Case): O(n!)\n\nConstraints:\n1 <= candidates.length <= 30\n2 <= candidates[i] <= 40\nAll elements of candidates are distinct.\n1 <= target <= 40\n\"\"\"\n\n\n                path.pop(len(path) - 1)\n\n\n    return answer\n\n\n    print(combination_sum([-8, 2.3, 0], 1))\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()\n    main()", "blocks": [{"id": 1, "label": "def combination_sum(candidates, target):\n    answer = []", "successors": [{"id": 3, "label": "    def backtrack(remain, path, start):", "successors": [{"id": 4, "label": "        if remain == 0:\n            answer.append(list(path))", "successors": []}, {"id": 5, "label": "        elif remain < 0:\n            return", "successors": []}, {"id": 6, "label": "        for i in range(start, len(candidates)):", "successors": []}, {"id": 10, "label": "    backtrack(target, [], 0)\n    return answer", "successors": []}]}]}]}
{"file_name": "52.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 34, "functions": [], "classes": [{"name": "APIKeyContainer", "type": "class", "start_line": 6, "end_line": 12, "functions": [], "simplified_code": "class APIKeyContainer(NamedTuple):\n    \"\"\"Container for API key parts.\"\"\"\n\n    raw: str\n    prefix: str\n    postfix: str\n    hash: str", "blocks": [{"id": 1, "label": "class APIKeyContainer(NamedTuple):\n\"\"\"Container for API key parts.\"\"\"", "successors": [{"id": 3, "label": "raw: str\nprefix: str\npostfix: str\nhash: str", "successors": []}]}]}, {"name": "APIKeyManager", "type": "class", "start_line": 15, "end_line": 34, "functions": [{"name": "generate_api_key", "type": "function", "start_line": 20, "end_line": 28, "functions": [], "classes": [], "simplified_code": "    def generate_api_key(self) -> APIKeyContainer:\n        \"\"\"Generate a new API key with all its parts.\"\"\"\n        raw_key = f\"{self.PREFIX}{secrets.token_urlsafe(32)}\"\n        return APIKeyContainer(\n            raw=raw_key,\n            prefix=raw_key[: self.PREFIX_LENGTH],\n            postfix=raw_key[-self.POSTFIX_LENGTH :],\n            hash=hashlib.sha256(raw_key.encode()).hexdigest(),\n        )", "blocks": [{"id": 1, "label": "def generate_api_key(self) -> APIKeyContainer:\n\"\"\"Generate a new API key with all its parts.\"\"\"", "successors": [{"id": 3, "label": "raw_key = f\"{self.PREFIX}{secrets.token_urlsafe(32)}\"\nreturn APIKeyContainer(\n    raw=raw_key,\n    prefix=raw_key[: self.PREFIX_LENGTH],\n    postfix=raw_key[-self.POSTFIX_LENGTH :],\n    hash=hashlib.sha256(raw_key.encode()).hexdigest(),\n)", "successors": []}]}]}, {"name": "verify_api_key", "type": "function", "start_line": 30, "end_line": 34, "functions": [], "classes": [], "simplified_code": "    def verify_api_key(self, provided_key: str, stored_hash: str) -> bool:\n        \"\"\"Verify if a provided API key matches the stored hash.\"\"\"\n        if not provided_key.startswith(self.PREFIX):\n            return False\n        return hashlib.sha256(provided_key.encode()).hexdigest() == stored_hash", "blocks": [{"id": 1, "label": "def verify_api_key(self, provided_key: str, stored_hash: str) -> bool:\n    \"\"\"Verify if a provided API key matches the stored hash.\"\"\"\nif not provided_key.startswith(self.PREFIX):", "successors": [{"id": 3, "label": "    return False", "successors": []}, {"id": 4, "label": "return hashlib.sha256(provided_key.encode()).hexdigest() == stored_hash", "successors": []}]}]}], "simplified_code": "class APIKeyManager:\n    PREFIX: str = \"agpt_\"\n    PREFIX_LENGTH: int = 8\n    POSTFIX_LENGTH: int = 8\n\n        )\n\n        return hashlib.sha256(provided_key.encode()).hexdigest() == stored_hash", "blocks": [{"id": 1, "label": "class APIKeyManager:\n    PREFIX: str = \"agpt_\"", "successors": [{"id": 3, "label": "    PREFIX_LENGTH: int = 8\n    POSTFIX_LENGTH: int = 8", "successors": []}]}]}], "simplified_code": "import hashlib\nimport secrets\nfrom typing import NamedTuple\n\n\n    hash: str\n\n\n        return hashlib.sha256(provided_key.encode()).hexdigest() == stored_hash", "blocks": [{"id": 1, "label": "import hashlib\nimport secrets\nfrom typing import NamedTuple", "successors": [{"id": 2, "label": "User(NamedTuple):\nusername: str\n    password: str", "successors": []}, {"id": 4, "label": "def generate_api_key() -> str:\nreturn secrets.token_hex(16)", "successors": []}, {"id": 6, "label": "def verify_key(provided_key: str, stored_hash: str) -> bool:\nhash: str = hashlib.sha256(provided_key.encode()).hexdigest()", "successors": [{"id": 8, "label": "return hashlib.sha256(provided_key.encode()).hexdigest() == stored_hash", "successors": []}]}]}]}
{"file_name": "53.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 289, "functions": [{"name": "create_graph", "type": "function", "start_line": 17, "end_line": 19, "functions": [], "classes": [], "simplified_code": "async def create_graph(s: SpinTestServer, g: graph.Graph, u: User) -> graph.Graph:\n    logger.info(f\"Creating graph for user {u.id}\")\n    return await s.agent_server.test_create_graph(CreateGraph(graph=g), u.id)", "blocks": [{"id": 1, "label": "async def create_graph(s: SpinTestServer, g: graph.Graph, u: User) -> graph.Graph:\n    logger.info(f\"Creating graph for user {u.id}\")\nreturn await s.agent_server.test_create_graph(CreateGraph(graph=g), u.id)", "successors": []}]}, {"name": "execute_graph", "type": "function", "start_line": 22, "end_line": 44, "functions": [], "classes": [], "simplified_code": "async def execute_graph(\n    agent_server: AgentServer,\n    test_graph: graph.Graph,\n    test_user: User,\n    input_data: dict,\n    num_execs: int = 4,\n) -> str:\n    logger.info(f\"Executing graph {test_graph.id} for user {test_user.id}\")\n    logger.info(f\"Input data: {input_data}\")\n\n    # --- Test adding new executions --- #\n    response = await agent_server.test_execute_graph(\n        test_graph.id, input_data, test_user.id\n    )\n    graph_exec_id = response[\"id\"]\n    logger.info(f\"Created execution with ID: {graph_exec_id}\")\n\n    # Execution queue should be empty\n    logger.info(\"Waiting for execution to complete...\")\n    result = await wait_execution(test_user.id, test_graph.id, graph_exec_id)\n    logger.info(f\"Execution completed with {len(result)} results\")\n    assert result and len(result) == num_execs\n    return graph_exec_id", "blocks": [{"id": 1, "label": "async def execute_graph(    agent_server: AgentServer,    test_graph: graph.Graph,    test_user: User,    input_data: dict,    num_execs: int = 4,) -> str:\n    logger.info(f\"Executing graph {test_graph.id} for user {test_user.id}\")\n    logger.info(f\"Input data: {input_data}\")", "successors": [{"id": 3, "label": "    response = await agent_server.test_execute_graph(        test_graph.id, input_data, test_user.id    )\n    graph_exec_id = response[\"id\"]\n    logger.info(f\"Created execution with ID: {graph_exec_id}\")\n    logger.info(\"Waiting for execution to complete...\")\n    result = await wait_execution(test_user.id, test_graph.id, graph_exec_id)\n    logger.info(f\"Execution completed with {len(result)} results\")", "successors": [{"id": 5, "label": "    assert result and len(result) == num_execs\n    return graph_exec_id", "successors": []}]}]}]}, {"name": "assert_sample_graph_executions", "type": "function", "start_line": 47, "end_line": 120, "functions": [], "classes": [], "simplified_code": "async def assert_sample_graph_executions(\n    agent_server: AgentServer,\n    test_graph: graph.Graph,\n    test_user: User,\n    graph_exec_id: str,\n):\n    logger.info(f\"Checking execution results for graph {test_graph.id}\")\n    executions = await agent_server.test_get_graph_run_node_execution_results(\n        test_graph.id,\n        graph_exec_id,\n        test_user.id,\n    )\n\n    output_list = [{\"result\": [\"Hello\"]}, {\"result\": [\"World\"]}]\n    input_list = [\n        {\n            \"name\": \"input_1\",\n            \"value\": \"Hello\",\n        },\n        {\n            \"name\": \"input_2\",\n            \"value\": \"World\",\n        },\n    ]\n\n    # Executing StoreValueBlock\n    exec = executions[0]\n    logger.info(f\"Checking first StoreValueBlock execution: {exec}\")\n    assert exec.status == execution.ExecutionStatus.COMPLETED\n    assert exec.graph_exec_id == graph_exec_id\n    assert (\n        exec.output_data in output_list\n    ), f\"Output data: {exec.output_data} and {output_list}\"\n    assert (\n        exec.input_data in input_list\n    ), f\"Input data: {exec.input_data} and {input_list}\"\n    assert exec.node_id in [test_graph.nodes[0].id, test_graph.nodes[1].id]\n\n    # Executing StoreValueBlock\n    exec = executions[1]\n    logger.info(f\"Checking second StoreValueBlock execution: {exec}\")\n    assert exec.status == execution.ExecutionStatus.COMPLETED\n    assert exec.graph_exec_id == graph_exec_id\n    assert (\n        exec.output_data in output_list\n    ), f\"Output data: {exec.output_data} and {output_list}\"\n    assert (\n        exec.input_data in input_list\n    ), f\"Input data: {exec.input_data} and {input_list}\"\n    assert exec.node_id in [test_graph.nodes[0].id, test_graph.nodes[1].id]\n\n    # Executing FillTextTemplateBlock\n    exec = executions[2]\n    logger.info(f\"Checking FillTextTemplateBlock execution: {exec}\")\n    assert exec.status == execution.ExecutionStatus.COMPLETED\n    assert exec.graph_exec_id == graph_exec_id\n    assert exec.output_data == {\"output\": [\"Hello, World!!!\"]}\n    assert exec.input_data == {\n        \"format\": \"{a}, {b}{c}\",\n        \"values\": {\"a\": \"Hello\", \"b\": \"World\", \"c\": \"!!!\"},\n        \"values_#_a\": \"Hello\",\n        \"values_#_b\": \"World\",\n        \"values_#_c\": \"!!!\",\n    }\n    assert exec.node_id == test_graph.nodes[2].id\n\n    # Executing PrintToConsoleBlock\n    exec = executions[3]\n    logger.info(f\"Checking PrintToConsoleBlock execution: {exec}\")\n    assert exec.status == execution.ExecutionStatus.COMPLETED\n    assert exec.graph_exec_id == graph_exec_id\n    assert exec.output_data == {\"status\": [\"printed\"]}\n    assert exec.input_data == {\"text\": \"Hello, World!!!\"}\n    assert exec.node_id == test_graph.nodes[3].id", "blocks": [{"id": 1, "label": "async def assert_sample_graph_executions(\n    agent_server: AgentServer,\n    test_graph: graph.Graph,\n    test_user: User,\n    graph_exec_id: str,\n):\nlogger.info(f\"Checking execution results for graph {test_graph.id}\")\nexecutions = await agent_server.test_get_graph_run_node_execution_results(\n    test_graph.id,\n    graph_exec_id,\n    test_user.id,\n)", "successors": [{"id": 3, "label": "output_list = [{\"result\": [\"Hello\"]}, {\"result\": [\"World\"]}]\ninput_list = [\n    {\n        \"name\": \"input_1\",\n        \"value\": \"Hello\",\n    },\n    {\n        \"name\": \"input_2\",\n        \"value\": \"World\",\n    },\n]\n# Executing StoreValueBlock\nexec = executions[0]\nlogger.info(f\"Checking first StoreValueBlock execution: {exec}\")\nassert exec.status == execution.ExecutionStatus.COMPLETED\nassert exec.graph_exec_id == graph_exec_id\nassert (\n    exec.output_data in output_list\n), f\"Output data: {exec.output_data} and {output_list}\"\nassert (\n    exec.input_data in input_list\n), f\"Input data: {exec.input_data} and {input_list}\"\nassert exec.node_id in [test_graph.nodes[0].id, test_graph.nodes[1].id]", "successors": [{"id": 5, "label": "# Executing StoreValueBlock\nexec = executions[1]\nlogger.info(f\"Checking second StoreValueBlock execution: {exec}\")\nassert exec.status == execution.ExecutionStatus.COMPLETED\nassert exec.graph_exec_id == graph_exec_id\nassert (\n    exec.output_data in output_list\n), f\"Output data: {exec.output_data} and {output_list}\"\nassert (\n    exec.input_data in input_list\n), f\"Input data: {exec.input_data} and {input_list}\"\nassert exec.node_id in [test_graph.nodes[0].id, test_graph.nodes[1].id]\n# Executing FillTextTemplateBlock\nexec = executions[2]\nlogger.info(f\"Checking FillTextTemplateBlock execution: {exec}\")\nassert exec.status == execution.ExecutionStatus.COMPLETED\nassert exec.graph_exec_id == graph_exec_id\nassert exec.output_data == {\"output\": [\"Hello, World!!!\"]}\nassert exec.input_data == {\n    \"format\": \"{a}, {b}{c}\",\n    \"values\": {\"a\": \"Hello\", \"b\": \"World\", \"c\": \"!!!\"},\n    \"values_#_a\": \"Hello\",\n    \"values_#_b\": \"World\",\n    \"values_#_c\": \"!!!\",\n}\nassert exec.node_id == test_graph.nodes[2].id", "successors": [{"id": 7, "label": "# Executing PrintToConsoleBlock\nexec = executions[3]\nlogger.info(f\"Checking PrintToConsoleBlock execution: {exec}\")\nassert exec.status == execution.ExecutionStatus.COMPLETED\nassert exec.graph_exec_id == graph_exec_id\nassert exec.output_data == {\"status\": [\"printed\"]}\nassert exec.input_data == {\"text\": \"Hello, World!!!\"}\nassert exec.node_id == test_graph.nodes[3].id", "successors": []}]}]}]}]}, {"name": "test_agent_execution", "type": "function", "start_line": 124, "end_line": 139, "functions": [], "classes": [], "simplified_code": "async def test_agent_execution(server: SpinTestServer):\n    logger.info(\"Starting test_agent_execution\")\n    test_user = await create_test_user()\n    test_graph = await create_graph(server, create_test_graph(), test_user)\n    data = {\"input_1\": \"Hello\", \"input_2\": \"World\"}\n    graph_exec_id = await execute_graph(\n        server.agent_server,\n        test_graph,\n        test_user,\n        data,\n        4,\n    )\n    await assert_sample_graph_executions(\n        server.agent_server, test_graph, test_user, graph_exec_id\n    )\n    logger.info(\"Completed test_agent_execution\")", "blocks": [{"id": 1, "label": "async def test_agent_execution(server: SpinTestServer):\nlogger.info(\"Starting test_agent_execution\")\ntest_user = await create_test_user()\ntest_graph = await create_graph(server, create_test_graph(), test_user)\ndata = {\"input_1\": \"Hello\", \"input_2\": \"World\"}\ngraph_exec_id = await execute_graph(\n    server.agent_server,\n    test_graph,\n    test_user,\n    data,\n    4,\n)", "successors": [{"id": 3, "label": "await assert_sample_graph_executions(\n    server.agent_server, test_graph, test_user, graph_exec_id\n)\nlogger.info(\"Completed test_agent_execution\")", "successors": []}]}]}, {"name": "test_input_pin_always_waited", "type": "function", "start_line": 143, "end_line": 205, "functions": [], "classes": [], "simplified_code": "async def test_input_pin_always_waited(server: SpinTestServer):\n    \"\"\"\n    This test is asserting that the input pin should always be waited for the execution,\n    even when default value on that pin is defined, the value has to be ignored.\n\n    Test scenario:\n    StoreValueBlock1\n                \\\\ input\n                     >------- FindInDictionaryBlock | input_default: key: \"\", input: {}\n                // key\n    StoreValueBlock2\n    \"\"\"\n    logger.info(\"Starting test_input_pin_always_waited\")\n    nodes = [\n        graph.Node(\n            block_id=StoreValueBlock().id,\n            input_default={\"input\": {\"key1\": \"value1\", \"key2\": \"value2\"}},\n        ),\n        graph.Node(\n            block_id=StoreValueBlock().id,\n            input_default={\"input\": \"key2\"},\n        ),\n        graph.Node(\n            block_id=FindInDictionaryBlock().id,\n            input_default={\"key\": \"\", \"input\": {}},\n        ),\n    ]\n    links = [\n        graph.Link(\n            source_id=nodes[0].id,\n            sink_id=nodes[2].id,\n            source_name=\"output\",\n            sink_name=\"input\",\n        ),\n        graph.Link(\n            source_id=nodes[1].id,\n            sink_id=nodes[2].id,\n            source_name=\"output\",\n            sink_name=\"key\",\n        ),\n    ]\n    test_graph = graph.Graph(\n        name=\"TestGraph\",\n        description=\"Test graph\",\n        nodes=nodes,\n        links=links,\n    )\n    test_user = await create_test_user()\n    test_graph = await create_graph(server, test_graph, test_user)\n    graph_exec_id = await execute_graph(\n        server.agent_server, test_graph, test_user, {}, 3\n    )\n\n    logger.info(\"Checking execution results\")\n    executions = await server.agent_server.test_get_graph_run_node_execution_results(\n        test_graph.id, graph_exec_id, test_user.id\n    )\n    assert len(executions) == 3\n    # FindInDictionaryBlock should wait for the input pin to be provided,\n    # Hence executing extraction of \"key\" from {\"key1\": \"value1\", \"key2\": \"value2\"}\n    assert executions[2].status == execution.ExecutionStatus.COMPLETED\n    assert executions[2].output_data == {\"output\": [\"value2\"]}\n    logger.info(\"Completed test_input_pin_always_waited\")", "blocks": [{"id": 1, "label": "async def test_input_pin_always_waited(server: SpinTestServer):\nlogger.info(\"Starting test_input_pin_always_waited\")\nnodes = [\n    graph.Node(\n        block_id=StoreValueBlock().id,\n        input_default={\"input\": {\"key1\": \"value1\", \"key2\": \"value2\"}},\n    ),\n    graph.Node(\n        block_id=StoreValueBlock().id,\n        input_default={\"input\": \"key2\"},\n    ),\n    graph.Node(\n        block_id=FindInDictionaryBlock().id,\n        input_default={\"key\": \"\", \"input\": {}},\n    ),\n]\nlinks = [\n    graph.Link(\n        source_id=nodes[0].id,\n        sink_id=nodes[2].id,\n        source_name=\"output\",\n        sink_name=\"input\",\n    ),\n    graph.Link(\n        source_id=nodes[1].id,\n        sink_id=nodes[2].id,\n        source_name=\"output\",\n        sink_name=\"key\",\n    ),\n]\ntest_graph = graph.Graph(\n    name=\"TestGraph\",\n    description=\"Test graph\",\n    nodes=nodes,\n    links=links,\n)\ntest_user = await create_test_user()\ntest_graph = await create_graph(server, test_graph, test_user)\ngraph_exec_id = await execute_graph(\n    server.agent_server, test_graph, test_user, {}, 3\n)", "successors": [{"id": 3, "label": "logger.info(\"Checking execution results\")\nexecutions = await server.agent_server.test_get_graph_run_node_execution_results(\n    test_graph.id, graph_exec_id, test_user.id\n)\nassert len(executions) == 3", "successors": [{"id": 5, "label": "assert executions[2].status == execution.ExecutionStatus.COMPLETED\nassert executions[2].output_data == {\"output\": [\"value2\"]}\nlogger.info(\"Completed test_input_pin_always_waited\")", "successors": []}]}]}]}, {"name": "test_static_input_link_on_graph", "type": "function", "start_line": 209, "end_line": 289, "functions": [], "classes": [], "simplified_code": "async def test_static_input_link_on_graph(server: SpinTestServer):\n    \"\"\"\n    This test is asserting the behaviour of static input link, e.g: reusable input link.\n\n    Test scenario:\n    *StoreValueBlock1*===a=========\\\\\n    *StoreValueBlock2*===a=====\\\\  ||\n    *StoreValueBlock3*===a===*MathBlock*====b / static====*StoreValueBlock5*\n    *StoreValueBlock4*=========================================//\n\n    In this test, there will be three input waiting in the MathBlock input pin `a`.\n    And later, another output is produced on input pin `b`, which is a static link,\n    this input will complete the input of those three incomplete executions.\n    \"\"\"\n    logger.info(\"Starting test_static_input_link_on_graph\")\n    nodes = [\n        graph.Node(block_id=StoreValueBlock().id, input_default={\"input\": 4}),  # a\n        graph.Node(block_id=StoreValueBlock().id, input_default={\"input\": 4}),  # a\n        graph.Node(block_id=StoreValueBlock().id, input_default={\"input\": 4}),  # a\n        graph.Node(block_id=StoreValueBlock().id, input_default={\"input\": 5}),  # b\n        graph.Node(block_id=StoreValueBlock().id),\n        graph.Node(\n            block_id=CalculatorBlock().id,\n            input_default={\"operation\": Operation.ADD.value},\n        ),\n    ]\n    links = [\n        graph.Link(\n            source_id=nodes[0].id,\n            sink_id=nodes[5].id,\n            source_name=\"output\",\n            sink_name=\"a\",\n        ),\n        graph.Link(\n            source_id=nodes[1].id,\n            sink_id=nodes[5].id,\n            source_name=\"output\",\n            sink_name=\"a\",\n        ),\n        graph.Link(\n            source_id=nodes[2].id,\n            sink_id=nodes[5].id,\n            source_name=\"output\",\n            sink_name=\"a\",\n        ),\n        graph.Link(\n            source_id=nodes[3].id,\n            sink_id=nodes[4].id,\n            source_name=\"output\",\n            sink_name=\"input\",\n        ),\n        graph.Link(\n            source_id=nodes[4].id,\n            sink_id=nodes[5].id,\n            source_name=\"output\",\n            sink_name=\"b\",\n            is_static=True,  # This is the static link to test.\n        ),\n    ]\n    test_graph = graph.Graph(\n        name=\"TestGraph\",\n        description=\"Test graph\",\n        nodes=nodes,\n        links=links,\n    )\n    test_user = await create_test_user()\n    test_graph = await create_graph(server, test_graph, test_user)\n    graph_exec_id = await execute_graph(\n        server.agent_server, test_graph, test_user, {}, 8\n    )\n    logger.info(\"Checking execution results\")\n    executions = await server.agent_server.test_get_graph_run_node_execution_results(\n        test_graph.id, graph_exec_id, test_user.id\n    )\n    assert len(executions) == 8\n    # The last 3 executions will be a+b=4+5=9\n    for i, exec_data in enumerate(executions[-3:]):\n        logger.info(f\"Checking execution {i+1} of last 3: {exec_data}\")\n        assert exec_data.status == execution.ExecutionStatus.COMPLETED\n        assert exec_data.output_data == {\"result\": [9]}\n    logger.info(\"Completed test_static_input_link_on_graph\")", "blocks": [{"id": 1, "label": "logger.info(\"Starting test_static_input_link_on_graph\")\nnodes = [\n    graph.Node(block_id=StoreValueBlock().id, input_default={\"input\": 4}),  # a\n    graph.Node(block_id=StoreValueBlock().id, input_default={\"input\": 4}),  # a\n    graph.Node(block_id=StoreValueBlock().id, input_default={\"input\": 4}),  # a\n    graph.Node(block_id=StoreValueBlock().id, input_default={\"input\": 5}),  # b\n    graph.Node(block_id=StoreValueBlock().id),\n    graph.Node(\n        block_id=CalculatorBlock().id,\n        input_default={\"operation\": Operation.ADD.value},\n    ),\n]", "successors": [{"id": 3, "label": "links = [\n    graph.Link(\n        source_id=nodes[0].id,\n        sink_id=nodes[5].id,\n        source_name=\"output\",\n        sink_name=\"a\",\n    ),\n    graph.Link(\n        source_id=nodes[1].id,\n        sink_id=nodes[5].id,\n        source_name=\"output\",\n        sink_name=\"a\",\n    ),\n    graph.Link(\n        source_id=nodes[2].id,\n        sink_id=nodes[5].id,\n        source_name=\"output\",\n        sink_name=\"a\",\n    ),\n    graph.Link(\n        source_id=nodes[3].id,\n        sink_id=nodes[4].id,\n        source_name=\"output\",\n        sink_name=\"input\",\n    ),\n    graph.Link(\n        source_id=nodes[4].id,\n        sink_id=nodes[5].id,\n        source_name=\"output\",\n        sink_name=\"b\",\n        is_static=True,  # This is the static link to test.\n    ),\n]\ntest_graph = graph.Graph(\n    name=\"TestGraph\",\n    description=\"Test graph\",\n    nodes=nodes,\n    links=links,\n)", "successors": [{"id": 5, "label": "test_user = await create_test_user()\ntest_graph = await create_graph(server, test_graph, test_user)", "successors": [{"id": 7, "label": "graph_exec_id = await execute_graph(\n    server.agent_server, test_graph, test_user, {}, 8\n)\nlogger.info(\"Checking execution results\")", "successors": [{"id": 9, "label": "executions = await server.agent_server.test_get_graph_run_node_execution_results(\n    test_graph.id, graph_exec_id, test_user.id\n)\nassert len(executions) == 8", "successors": [{"id": 11, "label": "for i, exec_data in enumerate(executions[-3:]):\n    logger.info(f\"Checking execution {i+1} of last 3: {exec_data}\")\n    assert exec_data.status == execution.ExecutionStatus.COMPLETED\n    assert exec_data.output_data == {\"result\": [9]}", "successors": [{"id": 12, "label": "logger.info(\"Completed test_static_input_link_on_graph\")", "successors": []}]}]}]}]}]}]}]}], "classes": [], "simplified_code": "import logging\n\nimport pytest\nfrom prisma.models import User\n\nfrom backend.blocks.basic import FindInDictionaryBlock, StoreValueBlock\nfrom backend.blocks.maths import CalculatorBlock, Operation\nfrom backend.data import execution, graph\nfrom backend.server.model import CreateGraph\nfrom backend.server.rest_api import AgentServer\nfrom backend.usecases.sample import create_test_graph, create_test_user\nfrom backend.util.test import SpinTestServer, wait_execution\n\nlogger = logging.getLogger(__name__)\n\n\n    return await s.agent_server.test_create_graph(CreateGraph(graph=g), u.id)\n\n\n    return graph_exec_id\n\n\n    assert exec.node_id == test_graph.nodes[3].id\n\n\n@pytest.mark.asyncio(scope=\"session\")\n    logger.info(\"Completed test_agent_execution\")\n\n\n@pytest.mark.asyncio(scope=\"session\")\n    logger.info(\"Completed test_input_pin_always_waited\")\n\n\n@pytest.mark.asyncio(scope=\"session\")\n    logger.info(\"Completed test_static_input_link_on_graph\")", "blocks": [{"id": 1, "label": "import logging\n\nimport pytest\nfrom prisma.models import User\n\nfrom backend.blocks.basic import FindInDictionaryBlock, StoreValueBlock\nfrom backend.blocks.maths import CalculatorBlock, Operation\nfrom backend.data import execution, graph\nfrom backend.server.model import CreateGraph\nfrom backend.server.rest_api import AgentServer\nfrom backend.usecases.sample import create_test_graph, create_test_user\nfrom backend.util.test import SpinTestServer, wait_execution\n\nlogger = logging.getLogger(__name__)", "successors": []}]}
{"file_name": "54.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 277, "functions": [{"name": "error_message", "type": "function", "start_line": 37, "end_line": 39, "functions": [], "classes": [], "simplified_code": "def error_message(line_number: int, message: str) -> str:\n    line = line_number + 1\n    return f'(L{line:03d}) {message}'", "blocks": [{"id": 1, "label": "def error_message(line_number: int, message: str) -> str:\nline = line_number + 1", "successors": [{"id": 3, "label": "return f'(L{line:03d}) {message}'", "successors": []}]}]}, {"name": "get_categories_content", "type": "function", "start_line": 42, "end_line": 67, "functions": [], "classes": [], "simplified_code": "def get_categories_content(contents: List[str]) -> Tuple[Categories, CategoriesLineNumber]:\n\n    categories = {}\n    category_line_num = {}\n\n    for line_num, line_content in enumerate(contents):\n\n        if line_content.startswith(anchor):\n            category = line_content.split(anchor)[1].strip()\n            categories[category] = []\n            category_line_num[category] = line_num\n            continue\n\n        if not line_content.startswith('|') or line_content.startswith('|---'):\n            continue\n\n        raw_title = [\n            raw_content.strip() for raw_content in line_content.split('|')[1:-1]\n        ][0]\n\n        title_match = link_re.match(raw_title)\n        if title_match:\n                title = title_match.group(1).upper()\n                categories[category].append(title)\n\n    return (categories, category_line_num)", "blocks": [{"id": 1, "label": "def get_categories_content(contents: List[str]) -> Tuple[Categories, CategoriesLineNumber]:\ncategories = {}\ncategory_line_num = {}", "successors": [{"id": 3, "label": "for line_num, line_content in enumerate(contents):", "successors": [{"id": 4, "label": "if line_content.startswith(anchor):", "successors": [{"id": 5, "label": "category = line_content.split(anchor)[1].strip()\ncategories[category] = []\ncategory_line_num[category] = line_num\ncontinue\nreturn (categories, category_line_num)", "successors": []}, {"id": 6, "label": "if not line_content.startswith('|') or line_content.startswith('|---'):", "successors": [{"id": 7, "label": "continue\nreturn (categories, category_line_num)", "successors": []}, {"id": 8, "label": "raw_title = [\n    raw_content.strip() for raw_content in line_content.split('|')[1:-1]\n][0]\ntitle_match = link_re.match(raw_title)", "successors": [{"id": 10, "label": "if title_match:\ntitle = title_match.group(1).upper()\ncategories[category].append(title)", "successors": [{"id": 12, "label": "return (categories, category_line_num)", "successors": []}]}, {"id": 12, "label": "return (categories, category_line_num)", "successors": []}]}]}, {"id": 12, "label": "return (categories, category_line_num)", "successors": []}]}, {"id": 12, "label": "return (categories, category_line_num)", "successors": []}]}]}]}, {"name": "check_alphabetical_order", "type": "function", "start_line": 70, "end_line": 84, "functions": [], "classes": [], "simplified_code": "def check_alphabetical_order(lines: List[str]) -> List[str]:\n\n    err_msgs = []\n\n    categories, category_line_num = get_categories_content(contents=lines)\n\n    for category, api_list in categories.items():\n        if sorted(api_list) != api_list:\n            err_msg = error_message(\n                category_line_num[category], \n                f'{category} category is not alphabetical order'\n            )\n            err_msgs.append(err_msg)\n    \n    return err_msgs", "blocks": [{"id": 1, "label": "err_msgs = []\n\ncategories, category_line_num = get_categories_content(contents=lines)", "successors": [{"id": 2, "label": "for category, api_list in categories.items():", "successors": [{"id": 3, "label": "if sorted(api_list) != api_list:", "successors": [{"id": 4, "label": "err_msg = error_message(\n    category_line_num[category], \n    f'{category} category is not alphabetical order'\n)\nerr_msgs.append(err_msg)\nreturn err_msgs", "successors": []}, {"id": 5, "label": "return err_msgs", "successors": []}]}, {"id": 5, "label": "return err_msgs", "successors": []}]}]}]}, {"name": "check_title", "type": "function", "start_line": 87, "end_line": 104, "functions": [], "classes": [], "simplified_code": "def check_title(line_num: int, raw_title: str) -> List[str]:\n\n    err_msgs = []\n\n    title_match = link_re.match(raw_title)\n\n    # url should be wrapped in \"[TITLE](LINK)\" Markdown syntax\n    if not title_match:\n        err_msg = error_message(line_num, 'Title syntax should be \"[TITLE](LINK)\"')\n        err_msgs.append(err_msg)\n    else:\n        # do not allow \"... API\" in the entry title\n        title = title_match.group(1)\n        if title.upper().endswith(' API'):\n            err_msg = error_message(line_num, 'Title should not end with \"... API\". Every entry is an API here!')\n            err_msgs.append(err_msg)\n\n    return err_msgs", "blocks": [{"id": 1, "label": "def check_title(line_num: int, raw_title: str) -> List[str]:\nerr_msgs = []", "successors": [{"id": 3, "label": "title_match = link_re.match(raw_title)\nif not title_match:", "successors": [{"id": 5, "label": "    err_msg = error_message(line_num, 'Title syntax should be \"[TITLE](LINK)\"')\n    err_msgs.append(err_msg)\nreturn err_msgs", "successors": []}, {"id": 6, "label": "else:\n    title = title_match.group(1)\n    if title.upper().endswith(' API'):\n        err_msg = error_message(line_num, 'Title should not end with \"... API\". Every entry is an API here!')\n        err_msgs.append(err_msg)", "successors": [{"id": 8, "label": "return err_msgs", "successors": []}]}]}]}]}, {"name": "check_description", "type": "function", "start_line": 107, "end_line": 126, "functions": [], "classes": [], "simplified_code": "def check_description(line_num: int, description: str) -> List[str]:\n\n    err_msgs = []\n\n    first_char = description[0]\n    if first_char.upper() != first_char:\n        err_msg = error_message(line_num, 'first character of description is not capitalized')\n        err_msgs.append(err_msg)\n\n    last_char = description[-1]\n    if last_char in punctuation:\n        err_msg = error_message(line_num, f'description should not end with {last_char}')\n        err_msgs.append(err_msg)\n\n    desc_length = len(description)\n    if desc_length > max_description_length:\n        err_msg = error_message(line_num, f'description should not exceed {max_description_length} characters (currently {desc_length})')\n        err_msgs.append(err_msg)\n    \n    return err_msgs", "blocks": [{"id": 1, "label": "def check_description(line_num: int, description: str) -> List[str]:\n\n    err_msgs = []\n\n    first_char = description[0]", "successors": [{"id": 2, "label": "if first_char.upper() != first_char:\n    err_msg = error_message(line_num, 'first character of description is not capitalized')\n    err_msgs.append(err_msg)", "successors": []}, {"id": 4, "label": "last_char = description[-1]", "successors": [{"id": 5, "label": "if last_char in punctuation:\n    err_msg = error_message(line_num, f'description should not end with {last_char}')\n    err_msgs.append(err_msg)", "successors": []}, {"id": 7, "label": "desc_length = len(description)", "successors": [{"id": 8, "label": "if desc_length > max_description_length:\n    err_msg = error_message(line_num, f'description should not exceed {max_description_length} characters (currently {desc_length})')\n    err_msgs.append(err_msg)", "successors": []}, {"id": 10, "label": "return err_msgs", "successors": []}]}]}]}]}, {"name": "check_auth", "type": "function", "start_line": 129, "end_line": 142, "functions": [], "classes": [], "simplified_code": "def check_auth(line_num: int, auth: str) -> List[str]:\n\n    err_msgs = []\n\n    backtick = '`'\n    if auth != 'No' and (not auth.startswith(backtick) or not auth.endswith(backtick)):\n        err_msg = error_message(line_num, 'auth value is not enclosed with `backticks`')\n        err_msgs.append(err_msg)\n\n    if auth.replace(backtick, '') not in auth_keys:\n        err_msg = error_message(line_num, f'{auth} is not a valid Auth option')\n        err_msgs.append(err_msg)\n    \n    return err_msgs", "blocks": [{"id": 1, "label": "def check_auth(line_num: int, auth: str) -> List[str]:\n\n    err_msgs = []\n\n    backtick = '`'", "successors": [{"id": 2, "label": "if auth != 'No' and (not auth.startswith(backtick) or not auth.endswith(backtick)):\n        err_msg = error_message(line_num, 'auth value is not enclosed with `backticks`')\n        err_msgs.append(err_msg)\nif auth.replace(backtick, '') not in auth_keys:\n        err_msg = error_message(line_num, f'{auth} is not a valid Auth option')\n        err_msgs.append(err_msg)", "successors": [{"id": 4, "label": "return err_msgs", "successors": []}]}, {"id": 3, "label": "if auth.replace(backtick, '') not in auth_keys:\n        err_msg = error_message(line_num, f'{auth} is not a valid Auth option')\n        err_msgs.append(err_msg)\nreturn err_msgs", "successors": []}]}]}, {"name": "check_https", "type": "function", "start_line": 145, "end_line": 153, "functions": [], "classes": [], "simplified_code": "def check_https(line_num: int, https: str) -> List[str]:\n\n    err_msgs = []\n\n    if https not in https_keys:\n        err_msg = error_message(line_num, f'{https} is not a valid HTTPS option')\n        err_msgs.append(err_msg)\n\n    return err_msgs", "blocks": [{"id": 1, "label": "def check_https(line_num: int, https: str) -> List[str]:\n\n    err_msgs = []\n\n    if https not in https_keys:\n        err_msg = error_message(line_num, f'{https} is not a valid HTTPS option')\n        err_msgs.append(err_msg)", "successors": []}]}, {"name": "check_cors", "type": "function", "start_line": 156, "end_line": 164, "functions": [], "classes": [], "simplified_code": "def check_cors(line_num: int, cors: str) -> List[str]:\n\n    err_msgs = []\n\n    if cors not in cors_keys:\n        err_msg = error_message(line_num, f'{cors} is not a valid CORS option')\n        err_msgs.append(err_msg)\n    \n    return err_msgs", "blocks": [{"id": 1, "label": "err_msgs = []\nif cors not in cors_keys:", "successors": [{"id": 3, "label": "    err_msg = error_message(line_num, f'{cors} is not a valid CORS option')\n    err_msgs.append(err_msg)\nreturn err_msgs", "successors": []}, {"id": 4, "label": "return err_msgs", "successors": []}]}]}, {"name": "check_entry", "type": "function", "start_line": 167, "end_line": 189, "functions": [], "classes": [], "simplified_code": "def check_entry(line_num: int, segments: List[str]) -> List[str]:\n\n    raw_title = segments[index_title]\n    description = segments[index_desc]\n    auth = segments[index_auth]\n    https = segments[index_https]\n    cors = segments[index_cors]\n\n    title_err_msgs = check_title(line_num, raw_title)\n    desc_err_msgs = check_description(line_num, description)\n    auth_err_msgs = check_auth(line_num, auth)\n    https_err_msgs = check_https(line_num, https)\n    cors_err_msgs = check_cors(line_num, cors)\n\n    err_msgs = [\n        *title_err_msgs,\n        *desc_err_msgs,\n        *auth_err_msgs,\n        *https_err_msgs,\n        *cors_err_msgs\n    ]\n\n    return err_msgs", "blocks": [{"id": 1, "label": "def check_entry(line_num: int, segments: List[str]) -> List[str]:\nraw_title = segments[index_title]\ndescription = segments[index_desc]\nauth = segments[index_auth]\nhttps = segments[index_https]\ncors = segments[index_cors]", "successors": [{"id": 3, "label": "title_err_msgs = check_title(line_num, raw_title)\ndesc_err_msgs = check_description(line_num, description)\nauth_err_msgs = check_auth(line_num, auth)\nhttps_err_msgs = check_https(line_num, https)\ncors_err_msgs = check_cors(line_num, cors)\nerr_msgs = [\n    *title_err_msgs,\n    *desc_err_msgs,\n    *auth_err_msgs,\n    *https_err_msgs,\n    *cors_err_msgs\n]", "successors": [{"id": 5, "label": "return err_msgs", "successors": []}]}]}]}, {"name": "check_file_format", "type": "function", "start_line": 192, "end_line": 251, "functions": [], "classes": [], "simplified_code": "def check_file_format(lines: List[str]) -> List[str]:\n\n    err_msgs = []\n    category_title_in_index = []\n\n    alphabetical_err_msgs = check_alphabetical_order(lines)\n    err_msgs.extend(alphabetical_err_msgs)\n\n    num_in_category = min_entries_per_category + 1\n    category = ''\n    category_line = 0\n\n    for line_num, line_content in enumerate(lines):\n\n        category_title_match = category_title_in_index_re.match(line_content)\n        if category_title_match:\n            category_title_in_index.append(category_title_match.group(1))\n\n        # check each category for the minimum number of entries\n        if line_content.startswith(anchor):\n            category_match = anchor_re.match(line_content)\n            if category_match:\n                if category_match.group(1) not in category_title_in_index:\n                    err_msg = error_message(line_num, f'category header ({category_match.group(1)}) not added to Index section')\n                    err_msgs.append(err_msg)\n            else:\n                err_msg = error_message(line_num, 'category header is not formatted correctly')\n                err_msgs.append(err_msg)\n\n            if num_in_category < min_entries_per_category:\n                err_msg = error_message(category_line, f'{category} category does not have the minimum {min_entries_per_category} entries (only has {num_in_category})')\n                err_msgs.append(err_msg)\n\n            category = line_content.split(' ')[1]\n            category_line = line_num\n            num_in_category = 0\n            continue\n\n        # skips lines that we do not care about\n        if not line_content.startswith('|') or line_content.startswith('|---'):\n            continue\n\n        num_in_category += 1\n        segments = line_content.split('|')[1:-1]\n        if len(segments) < num_segments:\n            err_msg = error_message(line_num, f'entry does not have all the required columns (have {len(segments)}, need {num_segments})')\n            err_msgs.append(err_msg)\n            continue\n    \n        for segment in segments:\n            # every line segment should start and end with exactly 1 space\n            if len(segment) - len(segment.lstrip()) != 1 or len(segment) - len(segment.rstrip()) != 1:\n                err_msg = error_message(line_num, 'each segment must start and end with exactly 1 space')\n                err_msgs.append(err_msg)\n        \n        segments = [segment.strip() for segment in segments]\n        entry_err_msgs = check_entry(line_num, segments)\n        err_msgs.extend(entry_err_msgs)\n    \n    return err_msgs", "blocks": [{"id": 1, "label": "def check_file_format(lines: List[str]) -> List[str]:\n\n    err_msgs = []\n    category_title_in_index = []\n\n    alphabetical_err_msgs = check_alphabetical_order(lines)\n    err_msgs.extend(alphabetical_err_msgs)\n\n    num_in_category = min_entries_per_category + 1\n    category = ''\n    category_line = 0\n", "successors": [{"id": 3, "label": "for line_num, line_content in enumerate(lines):", "successors": [{"id": 4, "label": "\n        category_title_match = category_title_in_index_re.match(line_content)\n        if category_title_match:\ncategory_title_in_index.append(category_title_match.group(1))", "successors": []}, {"id": 6, "label": "\n        if line_content.startswith(anchor):", "successors": [{"id": 7, "label": "\n            category_match = anchor_re.match(line_content)\n            if category_match:\nif category_match.group(1) not in category_title_in_index:", "successors": [{"id": 9, "label": "err_msg = error_message(line_num, f'category header ({category_match.group(1)}) not added to Index section')\nerr_msgs.append(err_msg)", "successors": []}]}, {"id": 10, "label": "else:\nerr_msg = error_message(line_num, 'category header is not formatted correctly')\nerr_msgs.append(err_msg)", "successors": []}, {"id": 11, "label": "\n            if num_in_category < min_entries_per_category:\nerr_msg = error_message(category_line, f'{category} category does not have the minimum {min_entries_per_category} entries (only has {num_in_category})')\nerr_msgs.append(err_msg)", "successors": []}, {"id": 13, "label": "category = line_content.split(' ')[1]\ncategory_line = line_num\nnum_in_category = 0\ncontinue", "successors": []}]}, {"id": 14, "label": "\n        if not line_content.startswith('|') or line_content.startswith('|---'):\ncontinue", "successors": []}, {"id": 16, "label": "\n        num_in_category += 1\n        segments = line_content.split('|')[1:-1]\n        if len(segments) < num_segments:\nerr_msg = error_message(line_num, f'entry does not have all the required columns (have {len(segments)}, need {num_segments})')\nerr_msgs.append(err_msg)\ncontinue", "successors": []}, {"id": 18, "label": "\n        for segment in segments:", "successors": [{"id": 19, "label": "if len(segment) - len(segment.lstrip()) != 1 or len(segment) - len(segment.rstrip()) != 1:\nerr_msg = error_message(line_num, 'each segment must start and end with exactly 1 space')\nerr_msgs.append(err_msg)", "successors": []}]}, {"id": 21, "label": "segments = [segment.strip() for segment in segments]\nentry_err_msgs = check_entry(line_num, segments)\nerr_msgs.extend(entry_err_msgs)\n", "successors": []}]}, {"id": 22, "label": "return err_msgs", "successors": []}]}]}, {"name": "main", "type": "function", "start_line": 254, "end_line": 264, "functions": [], "classes": [], "simplified_code": "def main(filename: str) -> None:\n\n    with open(filename, mode='r', encoding='utf-8') as file:\n        lines = list(line.rstrip() for line in file)\n\n    file_format_err_msgs = check_file_format(lines)\n\n    if file_format_err_msgs:\n        for err_msg in file_format_err_msgs:\n            print(err_msg)\n        sys.exit(1)", "blocks": [{"id": 1, "label": "def main(filename: str) -> None:\nwith open(filename, mode='r', encoding='utf-8') as file:\n    lines = list(line.rstrip() for line in file)", "successors": [{"id": 3, "label": "file_format_err_msgs = check_file_format(lines)\nif file_format_err_msgs:", "successors": [{"id": 5, "label": "for err_msg in file_format_err_msgs:\n    print(err_msg)", "successors": [{"id": 6, "label": "sys.exit(1)", "successors": []}]}]}]}]}], "classes": [], "simplified_code": "# -*- coding: utf-8 -*-\n\nimport re\nimport sys\nfrom string import punctuation\nfrom typing import List, Tuple, Dict\n\n# Temporary replacement\n# The descriptions that contain () at the end must adapt to the new policy later\npunctuation = punctuation.replace('()', '')\n\nanchor = '###'\nauth_keys = ['apiKey', 'OAuth', 'X-Mashape-Key', 'User-Agent', 'No']\nhttps_keys = ['Yes', 'No']\ncors_keys = ['Yes', 'No', 'Unknown']\n\nindex_title = 0\nindex_desc = 1\nindex_auth = 2\nindex_https = 3\nindex_cors = 4\n\nnum_segments = 5\nmin_entries_per_category = 3\nmax_description_length = 100\n\nanchor_re = re.compile(anchor + '\\s(.+)')\ncategory_title_in_index_re = re.compile('\\*\\s\\[(.*)\\]')\nlink_re = re.compile('\\[(.+)\\]\\((http.*)\\)')\n\n# Type aliases\nAPIList = List[str]\nCategories = Dict[str, APIList]\nCategoriesLineNumber = Dict[str, int]\n\n\n    return f'(L{line:03d}) {message}'\n\n\n    return (categories, category_line_num)\n\n\n    return err_msgs\n\n\n    return err_msgs\n\n\n    return err_msgs\n\n\n    return err_msgs\n\n\n    return err_msgs\n\n\n    return err_msgs\n\n\n    return err_msgs\n\n\n    return err_msgs\n\n\n        sys.exit(1)\n\n\nif __name__ == '__main__':\n\n    num_args = len(sys.argv)\n\n    if num_args < 2:\n        print('No .md file passed (file should contain Markdown table syntax)')\n        sys.exit(1)\n\n    filename = sys.argv[1]\n\n    main(filename)", "blocks": [{"id": 1, "label": "import re\nimport sys\nfrom string import punctuation\nfrom typing import List, Tuple, Dict\npunctuation = punctuation.replace('()', '')\n\nanchor = '###'\nauth_keys = ['apiKey', 'OAuth', 'X-Mashape-Key', 'User-Agent', 'No']\nhttps_keys = ['Yes', 'No']\ncors_keys = ['Yes', 'No', 'Unknown']\n\nindex_title = 0\nindex_desc = 1\nindex_auth = 2\nindex_https = 3\nindex_cors = 4\n\nnum_segments = 5\nmin_entries_per_category = 3\nmax_description_length = 100\n\nanchor_re = re.compile(anchor + '\\s(.+)')\ncategory_title_in_index_re = re.compile('\\*\\s\\[(.*)\\]')\nlink_re = re.compile('\\[(.+)\\]\\((http.*)\\)'\n\n# Type aliases\nAPIList = List[str]\nCategories = Dict[str, APIList]\nCategoriesLineNumber = Dict[str, int]", "successors": [{"id": 3, "label": "if __name__ == '__main__':\n    num_args = len(sys.argv)\n\n    if num_args < 2:\n        print('No .md file passed (file should contain Markdown table syntax)')\n        sys.exit(1)\n\n    filename = sys.argv[1]\n\n    main(filename)", "successors": []}]}]}
{"file_name": "55.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 116, "functions": [], "classes": [{"name": "RSSEntry", "type": "class", "start_line": 12, "end_line": 18, "functions": [], "classes": [], "simplified_code": "class RSSEntry(pydantic.BaseModel):\n    title: str\n    link: str\n    description: str\n    pub_date: datetime\n    author: str\n    categories: list[str]", "blocks": [{"id": 1, "label": "class RSSEntry(pydantic.BaseModel):\n    title: str", "successors": [{"id": 3, "label": "    link: str\n    description: str", "successors": [{"id": 5, "label": "    pub_date: datetime\n    author: str", "successors": [{"id": 7, "label": "    categories: list[str]", "successors": []}]}]}]}]}, {"name": "ReadRSSFeedBlock", "type": "class", "start_line": 21, "end_line": 116, "functions": [{"name": "__init__", "type": "function", "start_line": 44, "end_line": 84, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"5ebe6768-8e5d-41e3-9134-1c7bd89a8d52\",\n            input_schema=ReadRSSFeedBlock.Input,\n            output_schema=ReadRSSFeedBlock.Output,\n            description=\"Reads RSS feed entries from a given URL.\",\n            categories={BlockCategory.INPUT},\n            test_input={\n                \"rss_url\": \"https://example.com/rss\",\n                \"time_period\": 10_000_000,\n                \"polling_rate\": 1,\n                \"run_continuously\": False,\n            },\n            test_output=[\n                (\n                    \"entry\",\n                    RSSEntry(\n                        title=\"Example RSS Item\",\n                        link=\"https://example.com/article\",\n                        description=\"This is an example RSS item description.\",\n                        pub_date=datetime(2023, 6, 23, 12, 30, 0, tzinfo=timezone.utc),\n                        author=\"John Doe\",\n                        categories=[\"Technology\", \"News\"],\n                    ),\n                ),\n            ],\n            test_mock={\n                \"parse_feed\": lambda *args, **kwargs: {\n                    \"entries\": [\n                        {\n                            \"title\": \"Example RSS Item\",\n                            \"link\": \"https://example.com/article\",\n                            \"summary\": \"This is an example RSS item description.\",\n                            \"published_parsed\": (2023, 6, 23, 12, 30, 0, 4, 174, 0),\n                            \"author\": \"John Doe\",\n                            \"tags\": [{\"term\": \"Technology\"}, {\"term\": \"News\"}],\n                        }\n                    ]\n                }\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"5ebe6768-8e5d-41e3-9134-1c7bd89a8d52\",\n    input_schema=ReadRSSFeedBlock.Input,\n    output_schema=ReadRSSFeedBlock.Output,\n    description=\"Reads RSS feed entries from a given URL.\",\n    categories={BlockCategory.INPUT},\n    test_input={\n        \"rss_url\": \"https://example.com/rss\",\n        \"time_period\": 10_000_000,\n        \"polling_rate\": 1,\n        \"run_continuously\": False,\n    },\n    test_output=[\n        (\n            \"entry\",\n            RSSEntry(\n                title=\"Example RSS Item\",\n                link=\"https://example.com/article\",\n                description=\"This is an example RSS item description.\",\n                pub_date=datetime(2023, 6, 23, 12, 30, 0, tzinfo=timezone.utc),\n                author=\"John Doe\",\n                categories=[\"Technology\", \"News\"],\n            ),\n        ),\n    ],\n    test_mock={\n        \"parse_feed\": lambda *args, **kwargs: {\n            \"entries\": [\n                {\n                    \"title\": \"Example RSS Item\",\n                    \"link\": \"https://example.com/article\",\n                    \"summary\": \"This is an example RSS item description.\",\n                    \"published_parsed\": (2023, 6, 23, 12, 30, 0, 4, 174, 0),\n                    \"author\": \"John Doe\",\n                    \"tags\": [{\"term\": \"Technology\"}, {\"term\": \"News\"}],\n                }\n            ]\n        }\n    },\n)", "successors": []}]}, {"name": "parse_feed", "type": "function", "start_line": 87, "end_line": 88, "functions": [], "classes": [], "simplified_code": "    def parse_feed(url: str) -> dict[str, Any]:\n        return feedparser.parse(url)  # type: ignore", "blocks": [{"id": 1, "label": "def parse_feed(url: str) -> dict[str, Any]:\n    return feedparser.parse(url)  # type: ignore", "successors": []}]}, {"name": "run", "type": "function", "start_line": 90, "end_line": 116, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        keep_going = True\n        start_time = datetime.now(timezone.utc) - timedelta(\n            minutes=input_data.time_period\n        )\n        while keep_going:\n            keep_going = input_data.run_continuously\n\n            feed = self.parse_feed(input_data.rss_url)\n\n            for entry in feed[\"entries\"]:\n                pub_date = datetime(*entry[\"published_parsed\"][:6], tzinfo=timezone.utc)\n\n                if pub_date > start_time:\n                    yield (\n                        \"entry\",\n                        RSSEntry(\n                            title=entry[\"title\"],\n                            link=entry[\"link\"],\n                            description=entry.get(\"summary\", \"\"),\n                            pub_date=pub_date,\n                            author=entry.get(\"author\", \"\"),\n                            categories=[tag[\"term\"] for tag in entry.get(\"tags\", [])],\n                        ),\n                    )\n\n            time.sleep(input_data.polling_rate)", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\nkeep_going = True\nstart_time = datetime.now(timezone.utc) - timedelta(\n    minutes=input_data.time_period\n)", "successors": [{"id": 3, "label": "while keep_going:", "successors": [{"id": 4, "label": "keep_going = input_data.run_continuously\n\nfeed = self.parse_feed(input_data.rss_url)", "successors": [{"id": 5, "label": "for entry in feed[\"entries\"]:", "successors": [{"id": 6, "label": "pub_date = datetime(*entry[\"published_parsed\"][:6], tzinfo=timezone.utc)", "successors": [{"id": 7, "label": "if pub_date > start_time:\nyield (\n    \"entry\",\n    RSSEntry(\n        title=entry[\"title\"],\n        link=entry[\"link\"],\n        description=entry.get(\"summary\", \"\"),\n        pub_date=pub_date,\n        author=entry.get(\"author\", \"\"),\n        categories=[tag[\"term\"] for tag in entry.get(\"tags\", [])],\n    ),\n)", "successors": [{"id": 9, "label": "time.sleep(input_data.polling_rate)", "successors": []}]}, {"id": 9, "label": "time.sleep(input_data.polling_rate)", "successors": []}]}]}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 22, "end_line": 39, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        rss_url: str = SchemaField(\n            description=\"The URL of the RSS feed to read\",\n            placeholder=\"https://example.com/rss\",\n        )\n        time_period: int = SchemaField(\n            description=\"The time period to check in minutes relative to the run block runtime, e.g. 60 would check for new entries in the last hour.\",\n            placeholder=\"1440\",\n            default=1440,\n        )\n        polling_rate: int = SchemaField(\n            description=\"The number of seconds to wait between polling attempts.\",\n            placeholder=\"300\",\n        )\n        run_continuously: bool = SchemaField(\n            description=\"Whether to run the block continuously or just once.\",\n            default=True,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "rss_url: str = SchemaField(description=\"The URL of the RSS feed to read\", placeholder=\"https://example.com/rss\",)", "successors": []}, {"id": 3, "label": "time_period: int = SchemaField(description=\"The time period to check in minutes relative to the run block runtime, e.g. 60 would check for new entries in the last hour.\", placeholder=\"1440\", default=1440,)", "successors": []}, {"id": 4, "label": "polling_rate: int = SchemaField(description=\"The number of seconds to wait between polling attempts.\", placeholder=\"300\",)", "successors": []}, {"id": 5, "label": "run_continuously: bool = SchemaField(description=\"Whether to run the block continuously or just once.\", default=True,)", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 41, "end_line": 42, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        entry: RSSEntry = SchemaField(description=\"The RSS item\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    entry: RSSEntry = SchemaField(description=\"The RSS item\")", "successors": []}]}], "simplified_code": "class ReadRSSFeedBlock(Block):\n        )\n\n        entry: RSSEntry = SchemaField(description=\"The RSS item\")\n\n        )\n\n    @staticmethod\n        return feedparser.parse(url)  # type: ignore\n\n            time.sleep(input_data.polling_rate)", "blocks": [{"id": 1, "label": "class ReadRSSFeedBlock(Block):\nentry: RSSEntry = SchemaField(description=\"The RSS item\")", "successors": [{"id": 3, "label": "@staticmethod\nreturn feedparser.parse(url)  # type: ignore", "successors": [{"id": 5, "label": "time.sleep(input_data.polling_rate)", "successors": []}]}]}]}], "simplified_code": "import time\nfrom datetime import datetime, timedelta, timezone\nfrom typing import Any\n\nimport feedparser\nimport pydantic\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\n\n    categories: list[str]\n\n\n            time.sleep(input_data.polling_rate)", "blocks": [{"id": 1, "label": "import time\nfrom datetime import datetime, timedelta, timezone\nfrom typing import Any\n\nimport feedparser\nimport pydantic\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\n\n    categories: list[str]\n\n\n            time.sleep(input_data.polling_rate)", "successors": []}]}
{"file_name": "56.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 94, "functions": [{"name": "is_safe", "type": "function", "start_line": 16, "end_line": 45, "functions": [], "classes": [], "simplified_code": "def is_safe(board: list[list[int]], row: int, column: int) -> bool:\n    \"\"\"\n    This function returns a boolean value True if it is safe to place a queen there\n    considering the current state of the board.\n\n    Parameters:\n    board (2D matrix): The chessboard\n    row, column: Coordinates of the cell on the board\n\n    Returns:\n    Boolean Value\n\n    >>> is_safe([[0, 0, 0], [0, 0, 0], [0, 0, 0]], 1, 1)\n    True\n    >>> is_safe([[1, 0, 0], [0, 0, 0], [0, 0, 0]], 1, 1)\n    False\n    \"\"\"\n\n    n = len(board)  # Size of the board\n\n    # Check if there is any queen in the same row, column,\n    # left upper diagonal, and right upper diagonal\n    return (\n        all(board[i][j] != 1 for i, j in zip(range(row, -1, -1), range(column, n)))\n        and all(\n            board[i][j] != 1 for i, j in zip(range(row, -1, -1), range(column, -1, -1))\n        )\n        and all(board[i][j] != 1 for i, j in zip(range(row, n), range(column, n)))\n        and all(board[i][j] != 1 for i, j in zip(range(row, n), range(column, -1, -1)))\n    )", "blocks": [{"id": 1, "label": "def is_safe(board: list[list[int]], row: int, column: int) -> bool:\nn = len(board)", "successors": [{"id": 3, "label": "return (all(board[i][j] != 1 for i, j in zip(range(row, -1, -1), range(column, n))) and all(board[i][j] != 1 for i, j in zip(range(row, -1, -1), range(column, -1, -1))) and all(board[i][j] != 1 for i, j in zip(range(row, n), range(column, n))) and all(board[i][j] != 1 for i, j in zip(range(row, n), range(column, -1, -1))))", "successors": []}]}]}, {"name": "solve", "type": "function", "start_line": 48, "end_line": 74, "functions": [], "classes": [], "simplified_code": "def solve(board: list[list[int]], row: int) -> bool:\n    \"\"\"\n    This function creates a state space tree and calls the safe function until it\n    receives a False Boolean and terminates that branch and backtracks to the next\n    possible solution branch.\n    \"\"\"\n    if row >= len(board):\n        \"\"\"\n        If the row number exceeds N, we have a board with a successful combination\n        and that combination is appended to the solution list and the board is printed.\n        \"\"\"\n        solution.append(board)\n        printboard(board)\n        print()\n        return True\n    for i in range(len(board)):\n        \"\"\"\n        For every row, it iterates through each column to check if it is feasible to\n        place a queen there.\n        If all the combinations for that particular branch are successful, the board is\n        reinitialized for the next possible combination.\n        \"\"\"\n        if is_safe(board, row, i):\n            board[row][i] = 1\n            solve(board, row + 1)\n            board[row][i] = 0\n    return False", "blocks": [{"id": 1, "label": "def solve(board: list[list[int]], row: int) -> bool:\n    if row >= len(board):", "successors": [{"id": 2, "label": "solution.append(board)\n        printboard(board)\n        print()\n        return True", "successors": []}, {"id": 3, "label": "for i in range(len(board)):", "successors": [{"id": 4, "label": "if is_safe(board, row, i):\nboard[row][i] = 1\n            solve(board, row + 1)\n            board[row][i] = 0", "successors": []}]}, {"id": 6, "label": "return False", "successors": []}]}]}, {"name": "printboard", "type": "function", "start_line": 77, "end_line": 87, "functions": [], "classes": [], "simplified_code": "def printboard(board: list[list[int]]) -> None:\n    \"\"\"\n    Prints the boards that have a successful combination.\n    \"\"\"\n    for i in range(len(board)):\n        for j in range(len(board)):\n            if board[i][j] == 1:\n                print(\"Q\", end=\" \")  # Queen is present\n            else:\n                print(\".\", end=\" \")  # Empty cell\n        print()", "blocks": [{"id": 1, "label": "for i in range(len(board)):", "successors": [{"id": 2, "label": "for j in range(len(board)):", "successors": [{"id": 3, "label": "if board[i][j] == 1:", "successors": [{"id": 4, "label": "    print(\"Q\", end=\" \")\nprint()", "successors": [{"id": 1, "label": "for i in range(len(board)):", "successors": []}]}, {"id": 5, "label": "    print(\".\", end=\" \")\nprint()", "successors": [{"id": 1, "label": "for i in range(len(board)):", "successors": []}]}]}]}]}]}], "classes": [], "simplified_code": "\"\"\"\n\nThe nqueens problem is of placing N queens on a N * N\nchess board such that no queen can attack any other queens placed\non that chess board.\nThis means that one queen cannot have any other queen on its horizontal, vertical and\ndiagonal lines.\n\n\"\"\"\n\nfrom __future__ import annotations\n\nsolution = []\n\n\n    )\n\n\n    return False\n\n\n        print()\n\n\n# Number of queens (e.g., n=8 for an 8x8 board)\nn = 8\nboard = [[0 for i in range(n)] for j in range(n)]\nsolve(board, 0)\nprint(\"The total number of solutions are:\", len(solution))", "blocks": [{"id": 1, "label": "from __future__ import annotations\nsolution = []", "successors": [{"id": 3, "label": "def is_safe(board, row, col):", "successors": [{"id": 4, "label": "    for i in range(col):", "successors": [{"id": 5, "label": "        if board[row][i]:\n            return False", "successors": []}]}, {"id": 7, "label": "    for i, j in zip(range(row, -1, -1), range(col, -1, -1)):", "successors": [{"id": 8, "label": "        if board[i][j]:\n            return False", "successors": []}]}, {"id": 10, "label": "    for i, j in zip(range(row, len(board), 1), range(col, -1, -1)):", "successors": [{"id": 11, "label": "        if board[i][j]:\n            return False", "successors": []}]}, {"id": 13, "label": "    return True", "successors": []}]}, {"id": 14, "label": "def solve(board, col):", "successors": [{"id": 15, "label": "    if col >= len(board):\n        solution.append([''.join('Q' if col else '.' for col in row) for row in board])", "successors": [{"id": 17, "label": "        return True", "successors": []}]}, {"id": 18, "label": "    res = False", "successors": [{"id": 19, "label": "    for i in range(len(board)):", "successors": [{"id": 20, "label": "        if is_safe(board, i, col):\n            board[i][col] = 1", "successors": [{"id": 22, "label": "            res = solve(board, col + 1) or res", "successors": []}, {"id": 23, "label": "            board[i][col] = 0", "successors": []}]}]}]}, {"id": 24, "label": "    return res", "successors": []}]}, {"id": 25, "label": "n = 8\nboard = [[0 for i in range(n)] for j in range(n)]", "successors": [{"id": 27, "label": "solve(board, 0)\nprint(\"The total number of solutions are:\", len(solution))", "successors": []}]}]}]}
{"file_name": "57.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 175, "functions": [{"name": "_get_provider_oauth_handler", "type": "function", "start_line": 156, "end_line": 175, "functions": [], "classes": [], "simplified_code": "def _get_provider_oauth_handler(provider_name: str) -> \"BaseOAuthHandler\":\n    if provider_name not in HANDLERS_BY_NAME:\n        raise KeyError(f\"Unknown provider '{provider_name}'\")\n\n    client_id = getattr(settings.secrets, f\"{provider_name}_client_id\")\n    client_secret = getattr(settings.secrets, f\"{provider_name}_client_secret\")\n    if not (client_id and client_secret):\n        raise MissingConfigError(\n            f\"Integration with provider '{provider_name}' is not configured\",\n        )\n\n    handler_class = HANDLERS_BY_NAME[provider_name]\n    frontend_base_url = (\n        settings.config.frontend_base_url or settings.config.platform_base_url\n    )\n    return handler_class(\n        client_id=client_id,\n        client_secret=client_secret,\n        redirect_uri=f\"{frontend_base_url}/auth/integrations/oauth_callback\",\n    )", "blocks": [{"id": 1, "label": "def _get_provider_oauth_handler(provider_name: str) -> \"BaseOAuthHandler\":", "successors": [{"id": 2, "label": "if provider_name not in HANDLERS_BY_NAME:\nraise KeyError(f\"Unknown provider '{provider_name}'\")", "successors": []}, {"id": 4, "label": "client_id = getattr(settings.secrets, f\"{provider_name}_client_id\")\nclient_secret = getattr(settings.secrets, f\"{provider_name}_client_secret\")", "successors": [{"id": 5, "label": "if not (client_id and client_secret):\nraise MissingConfigError(f\"Integration with provider '{provider_name}' is not configured\",)", "successors": []}, {"id": 7, "label": "handler_class = HANDLERS_BY_NAME[provider_name]\nfrontend_base_url = (settings.config.frontend_base_url or settings.config.platform_base_url)\nreturn handler_class(client_id=client_id, client_secret=client_secret, redirect_uri=f\"{frontend_base_url}/auth/integrations/oauth_callback\")", "successors": []}]}]}]}], "classes": [{"name": "IntegrationCredentialsManager", "type": "class", "start_line": 23, "end_line": 154, "functions": [{"name": "__init__", "type": "function", "start_line": 55, "end_line": 58, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        redis_conn = redis.get_redis()\n        self._locks = RedisKeyedMutex(redis_conn)\n        self.store = IntegrationCredentialsStore()", "blocks": [{"id": 1, "label": "def __init__(self):\nredis_conn = redis.get_redis()", "successors": [{"id": 3, "label": "self._locks = RedisKeyedMutex(redis_conn)\nself.store = IntegrationCredentialsStore()", "successors": []}]}]}, {"name": "create", "type": "function", "start_line": 60, "end_line": 61, "functions": [], "classes": [], "simplified_code": "    def create(self, user_id: str, credentials: Credentials) -> None:\n        return self.store.add_creds(user_id, credentials)", "blocks": [{"id": 1, "label": "def create(self, user_id: str, credentials: Credentials) -> None:\n    return self.store.add_creds(user_id, credentials)", "successors": []}]}, {"name": "exists", "type": "function", "start_line": 63, "end_line": 64, "functions": [], "classes": [], "simplified_code": "    def exists(self, user_id: str, credentials_id: str) -> bool:\n        return self.store.get_creds_by_id(user_id, credentials_id) is not None", "blocks": [{"id": 1, "label": "def exists(self, user_id: str, credentials_id: str) -> bool:\n    return self.store.get_creds_by_id(user_id, credentials_id) is not None", "successors": []}]}, {"name": "get", "type": "function", "start_line": 66, "end_line": 102, "functions": [], "classes": [], "simplified_code": "    def get(\n        self, user_id: str, credentials_id: str, lock: bool = True\n    ) -> Credentials | None:\n        credentials = self.store.get_creds_by_id(user_id, credentials_id)\n        if not credentials:\n            return None\n\n        # Refresh OAuth credentials if needed\n        if credentials.type == \"oauth2\" and credentials.access_token_expires_at:\n            logger.debug(\n                f\"Credentials #{credentials.id} expire at \"\n                f\"{datetime.fromtimestamp(credentials.access_token_expires_at)}; \"\n                f\"current time is {datetime.now()}\"\n            )\n\n            with self._locked(user_id, credentials_id, \"refresh\"):\n                oauth_handler = _get_provider_oauth_handler(credentials.provider)\n                if oauth_handler.needs_refresh(credentials):\n                    logger.debug(\n                        f\"Refreshing '{credentials.provider}' \"\n                        f\"credentials #{credentials.id}\"\n                    )\n                    _lock = None\n                    if lock:\n                        # Wait until the credentials are no longer in use anywhere\n                        _lock = self._acquire_lock(user_id, credentials_id)\n\n                    fresh_credentials = oauth_handler.refresh_tokens(credentials)\n                    self.store.update_creds(user_id, fresh_credentials)\n                    if _lock and _lock.locked():\n                        _lock.release()\n\n                    credentials = fresh_credentials\n        else:\n            logger.debug(f\"Credentials #{credentials.id} never expire\")\n\n        return credentials", "blocks": [{"id": 1, "label": "def get(\n        self, user_id: str, credentials_id: str, lock: bool = True\n    ) -> Credentials | None:\ncredentials = self.store.get_creds_by_id(user_id, credentials_id)", "successors": [{"id": 3, "label": "if not credentials:", "successors": [{"id": 4, "label": "return None", "successors": []}, {"id": 5, "label": "# Refresh OAuth credentials if needed\nif credentials.type == \"oauth2\" and credentials.access_token_expires_at:\nlogger.debug(\n    f\"Credentials #{credentials.id} expire at \"\n    f\"{datetime.fromtimestamp(credentials.access_token_expires_at)}; \"\n    f\"current time is {datetime.now()}\"\n)", "successors": [{"id": 7, "label": "with self._locked(user_id, credentials_id, \"refresh\"):\noauth_handler = _get_provider_oauth_handler(credentials.provider)", "successors": [{"id": 9, "label": "if oauth_handler.needs_refresh(credentials):\nlogger.debug(\n    f\"Refreshing '{credentials.provider}' \"\n    f\"credentials #{credentials.id}\"\n)", "successors": [{"id": 11, "label": "_lock = None\nif lock:", "successors": [{"id": 13, "label": "# Wait until the credentials are no longer in use anywhere\n_lock = self._acquire_lock(user_id, credentials_id)\nfresh_credentials = oauth_handler.refresh_tokens(credentials)\nself.store.update_creds(user_id, fresh_credentials)\nif _lock and _lock.locked():\n    _lock.release()\n\ncredentials = fresh_credentials", "successors": [{"id": 15, "label": "return credentials", "successors": []}]}]}]}]}]}, {"id": 16, "label": "else:\n    logger.debug(f\"Credentials #{credentials.id} never expire\")\nreturn credentials", "successors": []}]}]}]}, {"name": "acquire", "type": "function", "start_line": 104, "end_line": 121, "functions": [], "classes": [], "simplified_code": "    def acquire(\n        self, user_id: str, credentials_id: str\n    ) -> tuple[Credentials, RedisLock]:\n        \"\"\"\n        \u26a0\ufe0f WARNING: this locks credentials system-wide and blocks both acquiring\n        and updating them elsewhere until the lock is released.\n        See the class docstring for more info.\n        \"\"\"\n        # Use a low-priority (!time_sensitive) locking queue on top of the general lock\n        # to allow priority access for refreshing/updating the tokens.\n        with self._locked(user_id, credentials_id, \"!time_sensitive\"):\n            lock = self._acquire_lock(user_id, credentials_id)\n        credentials = self.get(user_id, credentials_id, lock=False)\n        if not credentials:\n            raise ValueError(\n                f\"Credentials #{credentials_id} for user #{user_id} not found\"\n            )\n        return credentials, lock", "blocks": [{"id": 1, "label": "def acquire(\n    self, user_id: str, credentials_id: str\n) -> tuple[Credentials, RedisLock]:", "successors": [{"id": 2, "label": "with self._locked(user_id, credentials_id, \"!time_sensitive\"):\n    lock = self._acquire_lock(user_id, credentials_id)", "successors": []}, {"id": 4, "label": "credentials = self.get(user_id, credentials_id, lock=False)", "successors": [{"id": 5, "label": "if not credentials:\n    raise ValueError(f\"Credentials #{credentials_id} for user #{user_id} not found\")", "successors": []}, {"id": 7, "label": "return credentials, lock", "successors": []}]}]}]}, {"name": "update", "type": "function", "start_line": 123, "end_line": 125, "functions": [], "classes": [], "simplified_code": "    def update(self, user_id: str, updated: Credentials) -> None:\n        with self._locked(user_id, updated.id):\n            self.store.update_creds(user_id, updated)", "blocks": [{"id": 1, "label": "def update(self, user_id: str, updated: Credentials) -> None:\nwith self._locked(user_id, updated.id):", "successors": [{"id": 3, "label": "self.store.update_creds(user_id, updated)", "successors": []}]}]}, {"name": "delete", "type": "function", "start_line": 127, "end_line": 129, "functions": [], "classes": [], "simplified_code": "    def delete(self, user_id: str, credentials_id: str) -> None:\n        with self._locked(user_id, credentials_id):\n            self.store.delete_creds_by_id(user_id, credentials_id)", "blocks": [{"id": 1, "label": "def delete(self, user_id: str, credentials_id: str) -> None:\nwith self._locked(user_id, credentials_id):", "successors": [{"id": 3, "label": "    self.store.delete_creds_by_id(user_id, credentials_id)", "successors": []}]}]}, {"name": "_acquire_lock", "type": "function", "start_line": 133, "end_line": 139, "functions": [], "classes": [], "simplified_code": "    def _acquire_lock(self, user_id: str, credentials_id: str, *args: str) -> RedisLock:\n        key = (\n            f\"user:{user_id}\",\n            f\"credentials:{credentials_id}\",\n            *args,\n        )\n        return self._locks.acquire(key)", "blocks": [{"id": 1, "label": "def _acquire_lock(self, user_id: str, credentials_id: str, *args: str) -> RedisLock:\nkey = (\n    f\"user:{user_id}\",\n    f\"credentials:{credentials_id}\",\n    *args,\n)", "successors": [{"id": 3, "label": "return self._locks.acquire(key)", "successors": []}]}]}, {"name": "_locked", "type": "function", "start_line": 142, "end_line": 148, "functions": [], "classes": [], "simplified_code": "    def _locked(self, user_id: str, credentials_id: str, *args: str):\n        lock = self._acquire_lock(user_id, credentials_id, *args)\n        try:\n            yield\n        finally:\n            if lock.locked():\n                lock.release()", "blocks": [{"id": 1, "label": "lock = self._acquire_lock(user_id, credentials_id, *args)\ntry:", "successors": [{"id": 3, "label": "yield\nfinally:", "successors": [{"id": 5, "label": "if lock.locked():\nlock.release()", "successors": []}]}]}]}, {"name": "release_all_locks", "type": "function", "start_line": 150, "end_line": 153, "functions": [], "classes": [], "simplified_code": "    def release_all_locks(self):\n        \"\"\"Call this on process termination to ensure all locks are released\"\"\"\n        self._locks.release_all_locks()\n        self.store.locks.release_all_locks()", "blocks": [{"id": 1, "label": "def release_all_locks(self):\n\"\"\"Call this on process termination to ensure all locks are released\"\"\"", "successors": [{"id": 3, "label": "self._locks.release_all_locks()\nself.store.locks.release_all_locks()", "successors": []}]}]}], "classes": [], "simplified_code": "class IntegrationCredentialsManager:\n    \"\"\"\n    Handles the lifecycle of integration credentials.\n    - Automatically refreshes requested credentials if needed.\n    - Uses locking mechanisms to ensure system-wide consistency and\n      prevent invalidation of in-use tokens.\n\n    ### \u26a0\ufe0f Gotcha\n    With `acquire(..)`, credentials can only be in use in one place at a time (e.g. one\n    block execution).\n\n    ### Locking mechanism\n    - Because *getting* credentials can result in a refresh (= *invalidation* +\n      *replacement*) of the stored credentials, *getting* is an operation that\n      potentially requires read/write access.\n    - Checking whether a token has to be refreshed is subject to an additional `refresh`\n      scoped lock to prevent unnecessary sequential refreshes when multiple executions\n      try to access the same credentials simultaneously.\n    - We MUST lock credentials while in use to prevent them from being invalidated while\n      they are in use, e.g. because they are being refreshed by a different part\n      of the system.\n    - The `!time_sensitive` lock in `acquire(..)` is part of a two-tier locking\n      mechanism in which *updating* gets priority over *getting* credentials.\n      This is to prevent a long queue of waiting *get* requests from blocking essential\n      credential refreshes or user-initiated updates.\n\n    It is possible to implement a reader/writer locking system where either multiple\n    readers or a single writer can have simultaneous access, but this would add a lot of\n    complexity to the mechanism. I don't expect the current (\"simple\") mechanism to\n    cause so much latency that it's worth implementing.\n    \"\"\"\n\n        self.store = IntegrationCredentialsStore()\n\n        return self.store.add_creds(user_id, credentials)\n\n        return self.store.get_creds_by_id(user_id, credentials_id) is not None\n\n        return credentials\n\n        return credentials, lock\n\n            self.store.update_creds(user_id, updated)\n\n            self.store.delete_creds_by_id(user_id, credentials_id)\n\n    # -- Locking utilities -- #\n\n        return self._locks.acquire(key)\n\n    @contextmanager\n                lock.release()\n\n        self.store.locks.release_all_locks()\n", "blocks": [{"id": 1, "label": "class IntegrationCredentialsManager:", "successors": [{"id": 2, "label": "self.store = IntegrationCredentialsStore()\nreturn self.store.add_creds(user_id, credentials)", "successors": []}, {"id": 4, "label": "return self.store.get_creds_by_id(user_id, credentials_id) is not None", "successors": []}, {"id": 5, "label": "return credentials", "successors": []}, {"id": 6, "label": "return credentials, lock", "successors": []}, {"id": 7, "label": "self.store.update_creds(user_id, updated)", "successors": []}, {"id": 8, "label": "self.store.delete_creds_by_id(user_id, credentials_id)", "successors": []}, {"id": 9, "label": "return self._locks.acquire(key)", "successors": []}, {"id": 10, "label": "@contextmanager\nlock.release()", "successors": []}, {"id": 12, "label": "self.store.locks.release_all_locks()", "successors": []}]}]}], "simplified_code": "import logging\nfrom contextlib import contextmanager\nfrom datetime import datetime\nfrom typing import TYPE_CHECKING\n\nfrom autogpt_libs.utils.synchronize import RedisKeyedMutex\nfrom redis.lock import Lock as RedisLock\n\nfrom backend.data import redis\nfrom backend.data.model import Credentials\nfrom backend.integrations.credentials_store import IntegrationCredentialsStore\nfrom backend.integrations.oauth import HANDLERS_BY_NAME\nfrom backend.util.exceptions import MissingConfigError\nfrom backend.util.settings import Settings\n\nif TYPE_CHECKING:\n    from backend.integrations.oauth import BaseOAuthHandler\n\nlogger = logging.getLogger(__name__)\nsettings = Settings()\n\n\n\n\n    )", "blocks": [{"id": 1, "label": "import logging\nfrom contextlib import contextmanager", "successors": [{"id": 3, "label": "from datetime import datetime\nfrom typing import TYPE_CHECKING", "successors": [{"id": 5, "label": "from autogpt_libs.utils.synchronize import RedisKeyedMutex\nfrom redis.lock import Lock as RedisLock", "successors": [{"id": 7, "label": "from backend.data import redis\nfrom backend.data.model import Credentials", "successors": [{"id": 9, "label": "from backend.integrations.credentials_store import IntegrationCredentialsStore\nfrom backend.integrations.oauth import HANDLERS_BY_NAME", "successors": [{"id": 11, "label": "from backend.util.exceptions import MissingConfigError\nfrom backend.util.settings import Settings", "successors": [{"id": 13, "label": "if TYPE_CHECKING:\n    from backend.integrations.oauth import BaseOAuthHandler\nlogger = logging.getLogger(__name__)", "successors": [{"id": 15, "label": "settings = Settings()", "successors": []}]}]}]}]}]}]}]}]}
{"file_name": "58.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 109, "functions": [], "classes": [{"name": "ComparisonOperator", "type": "class", "start_line": 8, "end_line": 14, "functions": [], "simplified_code": "class ComparisonOperator(Enum):\n    EQUAL = \"==\"\n    NOT_EQUAL = \"!=\"\n    GREATER_THAN = \">\"\n    LESS_THAN = \"<\"\n    GREATER_THAN_OR_EQUAL = \">=\"\n    LESS_THAN_OR_EQUAL = \"<=\"", "blocks": [{"id": 1, "label": "class ComparisonOperator(Enum):\n    EQUAL = \"==\"\n    NOT_EQUAL = \"!=\"\n    GREATER_THAN = \">\"\n    LESS_THAN = \"<\"\n    GREATER_THAN_OR_EQUAL = \">=\"\n    LESS_THAN_OR_EQUAL = \"<=\"", "successors": []}]}, {"name": "ConditionBlock", "type": "class", "start_line": 17, "end_line": 109, "functions": [{"name": "__init__", "type": "function", "start_line": 53, "end_line": 71, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"715696a0-e1da-45c8-b209-c2fa9c3b0be6\",\n            input_schema=ConditionBlock.Input,\n            output_schema=ConditionBlock.Output,\n            description=\"Handles conditional logic based on comparison operators\",\n            categories={BlockCategory.LOGIC},\n            test_input={\n                \"value1\": 10,\n                \"operator\": ComparisonOperator.GREATER_THAN.value,\n                \"value2\": 5,\n                \"yes_value\": \"Greater\",\n                \"no_value\": \"Not greater\",\n            },\n            test_output=[\n                (\"result\", True),\n                (\"yes_output\", \"Greater\"),\n            ],\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"715696a0-e1da-45c8-b209-c2fa9c3b0be6\",\n    input_schema=ConditionBlock.Input,\n    output_schema=ConditionBlock.Output,\n    description=\"Handles conditional logic based on comparison operators\",\n    categories={BlockCategory.LOGIC},\n    test_input={\n        \"value1\": 10,\n        \"operator\": ComparisonOperator.GREATER_THAN.value,\n        \"value2\": 5,\n        \"yes_value\": \"Greater\",\n        \"no_value\": \"Not greater\",\n    },\n    test_output=[\n        (\"result\", True),\n        (\"yes_output\", \"Greater\"),\n    ],\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 73, "end_line": 109, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        operator = input_data.operator\n\n        value1 = input_data.value1\n        if isinstance(value1, str):\n            try:\n                value1 = float(value1.strip())\n            except ValueError:\n                value1 = value1.strip()\n\n        value2 = input_data.value2\n        if isinstance(value2, str):\n            try:\n                value2 = float(value2.strip())\n            except ValueError:\n                value2 = value2.strip()\n\n        yes_value = input_data.yes_value if input_data.yes_value is not None else value1\n        no_value = input_data.no_value if input_data.no_value is not None else value2\n\n        comparison_funcs = {\n            ComparisonOperator.EQUAL: lambda a, b: a == b,\n            ComparisonOperator.NOT_EQUAL: lambda a, b: a != b,\n            ComparisonOperator.GREATER_THAN: lambda a, b: a > b,\n            ComparisonOperator.LESS_THAN: lambda a, b: a < b,\n            ComparisonOperator.GREATER_THAN_OR_EQUAL: lambda a, b: a >= b,\n            ComparisonOperator.LESS_THAN_OR_EQUAL: lambda a, b: a <= b,\n        }\n\n        result = comparison_funcs[operator](value1, value2)\n\n        yield \"result\", result\n\n        if result:\n            yield \"yes_output\", yes_value\n        else:\n            yield \"no_output\", no_value", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\noperator = input_data.operator\n\nvalue1 = input_data.value1", "successors": [{"id": 3, "label": "if isinstance(value1, str):", "successors": [{"id": 4, "label": "try:\n    value1 = float(value1.strip())\nexcept ValueError:\n    value1 = value1.strip()", "successors": []}, {"id": 5, "label": "except ValueError:\n    value1 = value1.strip()", "successors": []}]}, {"id": 6, "label": "value2 = input_data.value2", "successors": [{"id": 7, "label": "if isinstance(value2, str):", "successors": [{"id": 8, "label": "try:\n    value2 = float(value2.strip())\nexcept ValueError:\n    value2 = value2.strip()", "successors": []}, {"id": 9, "label": "except ValueError:\n    value2 = value2.strip()", "successors": []}]}, {"id": 10, "label": "yes_value = input_data.yes_value if input_data.yes_value is not None else value1\nno_value = input_data.no_value if input_data.no_value is not None else value2\ncomparison_funcs = {\n    ComparisonOperator.EQUAL: lambda a, b: a == b,\n    ComparisonOperator.NOT_EQUAL: lambda a, b: a != b,\n    ComparisonOperator.GREATER_THAN: lambda a, b: a > b,\n    ComparisonOperator.LESS_THAN: lambda a, b: a < b,\n    ComparisonOperator.GREATER_THAN_OR_EQUAL: lambda a, b: a >= b,\n    ComparisonOperator.LESS_THAN_OR_EQUAL: lambda a, b: a <= b,\n}", "successors": [{"id": 12, "label": "result = comparison_funcs[operator](value1, value2)\nyield \"result\", result", "successors": [{"id": 14, "label": "if result:", "successors": [{"id": 15, "label": "yield \"yes_output\", yes_value", "successors": []}, {"id": 16, "label": "else:\n    yield \"no_output\", no_value", "successors": []}]}]}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 18, "end_line": 40, "functions": [], "simplified_code": "    class Input(BlockSchema):\n        value1: Any = SchemaField(\n            description=\"Enter the first value for comparison\",\n            placeholder=\"For example: 10 or 'hello' or True\",\n        )\n        operator: ComparisonOperator = SchemaField(\n            description=\"Choose the comparison operator\",\n            placeholder=\"Select an operator\",\n        )\n        value2: Any = SchemaField(\n            description=\"Enter the second value for comparison\",\n            placeholder=\"For example: 20 or 'world' or False\",\n        )\n        yes_value: Any = SchemaField(\n            description=\"(Optional) Value to output if the condition is true. If not provided, value1 will be used.\",\n            placeholder=\"Leave empty to use value1, or enter a specific value\",\n            default=None,\n        )\n        no_value: Any = SchemaField(\n            description=\"(Optional) Value to output if the condition is false. If not provided, value1 will be used.\",\n            placeholder=\"Leave empty to use value1, or enter a specific value\",\n            default=None,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    value1: Any = SchemaField(\n        description=\"Enter the first value for comparison\",\n        placeholder=\"For example: 10 or 'hello' or True\",\n    )", "successors": [{"id": 3, "label": "    operator: ComparisonOperator = SchemaField(\n        description=\"Choose the comparison operator\",\n        placeholder=\"Select an operator\",\n    )\n    value2: Any = SchemaField(\n        description=\"Enter the second value for comparison\",\n        placeholder=\"For example: 20 or 'world' or False\",\n    )", "successors": [{"id": 5, "label": "    yes_value: Any = SchemaField(\n        description=\"(Optional) Value to output if the condition is true. If not provided, value1 will be used.\",\n        placeholder=\"Leave empty to use value1, or enter a specific value\",\n        default=None,\n    )\n    no_value: Any = SchemaField(\n        description=\"(Optional) Value to output if the condition is false. If not provided, value1 will be used.\",\n        placeholder=\"Leave empty to use value1, or enter a specific value\",\n        default=None,\n    )", "successors": []}]}]}]}, {"name": "Output", "type": "class", "start_line": 42, "end_line": 51, "functions": [], "simplified_code": "    class Output(BlockSchema):\n        result: bool = SchemaField(\n            description=\"The result of the condition evaluation (True or False)\"\n        )\n        yes_output: Any = SchemaField(\n            description=\"The output value if the condition is true\"\n        )\n        no_output: Any = SchemaField(\n            description=\"The output value if the condition is false\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "result: bool = SchemaField(description=\"The result of the condition evaluation (True or False)\")", "successors": []}, {"id": 3, "label": "yes_output: Any = SchemaField(description=\"The output value if the condition is true\")", "successors": []}, {"id": 4, "label": "no_output: Any = SchemaField(description=\"The output value if the condition is false\")", "successors": []}]}]}], "simplified_code": "class ConditionBlock(Block):\n        )\n\n        )\n\n        )\n\n            yield \"no_output\", no_value", "blocks": [{"id": 1, "label": "class ConditionBlock(Block):\ndef execute(self, a):", "successors": [{"id": 3, "label": "if a > 10:", "successors": [{"id": 4, "label": "print(\"a is greater than 10\")\nyield \"no_output\", no_value", "successors": []}, {"id": 5, "label": "elif a > 5:\nprint(\"a is greater than 5 but less than or equal to 10\")", "successors": [{"id": 9, "label": "yield \"no_output\", no_value", "successors": []}]}, {"id": 7, "label": "else:\nprint(\"a is 5 or less\")", "successors": [{"id": 9, "label": "yield \"no_output\", no_value", "successors": []}]}]}]}]}], "simplified_code": "from enum import Enum\nfrom typing import Any\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\n\n    LESS_THAN_OR_EQUAL = \"<=\"\n\n\n            yield \"no_output\", no_value", "blocks": [{"id": 1, "label": "from enum import Enum\nfrom typing import Any\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\nLESS_THAN_OR_EQUAL = \"<=\"\n\nyield \"no_output\", no_value", "successors": []}]}
{"file_name": "59.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 144, "functions": [{"name": "wait_execution", "type": "function", "start_line": 56, "end_line": 78, "functions": [{"name": "is_execution_completed", "type": "function", "start_line": 62, "end_line": 68, "functions": [], "classes": [], "simplified_code": "    async def is_execution_completed():\n        status = await AgentServer().test_get_graph_run_status(graph_exec_id, user_id)\n        log.info(f\"Execution status: {status}\")\n        if status == ExecutionStatus.FAILED:\n            log.info(\"Execution failed\")\n            raise Exception(\"Execution failed\")\n        return status == ExecutionStatus.COMPLETED", "blocks": [{"id": 1, "label": "status = await AgentServer().test_get_graph_run_status(graph_exec_id, user_id)\nlog.info(f\"Execution status: {status}\")\nif status == ExecutionStatus.FAILED:", "successors": [{"id": 3, "label": "log.info(\"Execution failed\")\nraise Exception(\"Execution failed\")", "successors": []}, {"id": 4, "label": "return status == ExecutionStatus.COMPLETED", "successors": []}]}]}], "classes": [], "simplified_code": "async def wait_execution(\n    user_id: str,\n    graph_id: str,\n    graph_exec_id: str,\n    timeout: int = 20,\n) -> Sequence[ExecutionResult]:\n        return status == ExecutionStatus.COMPLETED\n\n    # Wait for the executions to complete\n    for i in range(timeout):\n        if await is_execution_completed():\n            return await AgentServer().test_get_graph_run_node_execution_results(\n                graph_id, graph_exec_id, user_id\n            )\n        time.sleep(1)\n\n    assert False, \"Execution did not complete in time.\"", "blocks": [{"id": 1, "label": "async def wait_execution(\n    user_id: str,\n    graph_id: str,\n    graph_exec_id: str,\n    timeout: int = 20,\n) -> Sequence[ExecutionResult]:", "successors": [{"id": 2, "label": "return status == ExecutionStatus.COMPLETED", "successors": []}, {"id": 3, "label": "for i in range(timeout):", "successors": [{"id": 4, "label": "if await is_execution_completed():\nreturn await AgentServer().test_get_graph_run_node_execution_results(\n    graph_id, graph_exec_id, user_id\n)", "successors": []}, {"id": 6, "label": "time.sleep(1)\nassert False, \"Execution did not complete in time.\"", "successors": []}]}]}]}, {"name": "execute_block_test", "type": "function", "start_line": 81, "end_line": 144, "functions": [{"name": "compare", "type": "function", "start_line": 120, "end_line": 135, "functions": [], "classes": [], "simplified_code": "            def compare(data, expected_data):\n                if data == expected_data:\n                    is_matching = True\n                elif isinstance(expected_data, type):\n                    is_matching = isinstance(data, expected_data)\n                elif callable(expected_data):\n                    is_matching = expected_data(data)\n                else:\n                    is_matching = False\n\n                mark = \"\u2705\" if is_matching else \"\u274c\"\n                log.info(f\"{prefix} {mark} comparing `{data}` vs `{expected_data}`\")\n                if not is_matching:\n                    raise ValueError(\n                        f\"{prefix}: wrong output {data} vs {expected_data}\"\n                    )", "blocks": [{"id": 1, "label": "def compare(data, expected_data):", "successors": [{"id": 2, "label": "if data == expected_data:\n    is_matching = True", "successors": [{"id": 7, "label": "mark = \"\u2705\" if is_matching else \"\u274c\"\nlog.info(f\"{prefix} {mark} comparing `{data}` vs `{expected_data}`\")\nif not is_matching:", "successors": [{"id": 9, "label": "    raise ValueError(f\"{prefix}: wrong output {data} vs {expected_data}\")", "successors": []}]}]}, {"id": 4, "label": "elif isinstance(expected_data, type):\n    is_matching = isinstance(data, expected_data)", "successors": [{"id": 7, "label": "mark = \"\u2705\" if is_matching else \"\u274c\"\nlog.info(f\"{prefix} {mark} comparing `{data}` vs `{expected_data}`\")\nif not is_matching:", "successors": [{"id": 9, "label": "    raise ValueError(f\"{prefix}: wrong output {data} vs {expected_data}\")", "successors": []}]}]}, {"id": 6, "label": "elif callable(expected_data):\n    is_matching = expected_data(data)", "successors": [{"id": 7, "label": "mark = \"\u2705\" if is_matching else \"\u274c\"\nlog.info(f\"{prefix} {mark} comparing `{data}` vs `{expected_data}`\")\nif not is_matching:", "successors": [{"id": 9, "label": "    raise ValueError(f\"{prefix}: wrong output {data} vs {expected_data}\")", "successors": []}]}]}, {"id": 10, "label": "else:\n    is_matching = False", "successors": [{"id": 7, "label": "mark = \"\u2705\" if is_matching else \"\u274c\"\nlog.info(f\"{prefix} {mark} comparing `{data}` vs `{expected_data}`\")\nif not is_matching:", "successors": [{"id": 9, "label": "    raise ValueError(f\"{prefix}: wrong output {data} vs {expected_data}\")", "successors": []}]}]}]}]}], "classes": [], "simplified_code": "def execute_block_test(block: Block):\n    prefix = f\"[Test-{block.name}]\"\n\n    if not block.test_input or not block.test_output:\n        log.info(f\"{prefix} No test data provided\")\n        return\n    if not isinstance(block.test_input, list):\n        block.test_input = [block.test_input]\n    if not isinstance(block.test_output, list):\n        block.test_output = [block.test_output]\n\n    output_index = 0\n    log.info(f\"{prefix} Executing {len(block.test_input)} tests...\")\n    prefix = \" \" * 4 + prefix\n\n    for mock_name, mock_obj in (block.test_mock or {}).items():\n        log.info(f\"{prefix} mocking {mock_name}...\")\n        if hasattr(block, mock_name):\n            setattr(block, mock_name, mock_obj)\n        else:\n            log.info(f\"{prefix} mock {mock_name} not found in block\")\n\n    extra_exec_kwargs = {}\n\n    if CREDENTIALS_FIELD_NAME in block.input_schema.model_fields:\n        if not block.test_credentials:\n            raise ValueError(\n                f\"{prefix} requires credentials but has no test_credentials\"\n            )\n        extra_exec_kwargs[CREDENTIALS_FIELD_NAME] = block.test_credentials\n\n    for input_data in block.test_input:\n        log.info(f\"{prefix} in: {input_data}\")\n\n        for output_name, output_data in block.execute(input_data, **extra_exec_kwargs):\n            if output_index >= len(block.test_output):\n                raise ValueError(f\"{prefix} produced output more than expected\")\n            ex_output_name, ex_output_data = block.test_output[output_index]\n\n                    )\n\n            compare(output_data, ex_output_data)\n            compare(output_name, ex_output_name)\n            output_index += 1\n\n    if output_index < len(block.test_output):\n        raise ValueError(\n            f\"{prefix} produced output less than expected. output_index={output_index}, len(block.test_output)={len(block.test_output)}\"\n        )", "blocks": [{"id": 1, "label": "def execute_block_test(block: Block):\n    prefix = f\"[Test-{block.name}]\"", "successors": [{"id": 2, "label": "if not block.test_input or not block.test_output:\n    log.info(f\"{prefix} No test data provided\")\n    return", "successors": []}, {"id": 4, "label": "if not isinstance(block.test_input, list):\n    block.test_input = [block.test_input]\nif not isinstance(block.test_output, list):\n    block.test_output = [block.test_output]", "successors": [{"id": 6, "label": "output_index = 0\nlog.info(f\"{prefix} Executing {len(block.test_input)} tests...\")\nprefix = \" \" * 4 + prefix", "successors": [{"id": 7, "label": "for mock_name, mock_obj in (block.test_mock or {}).items():", "successors": [{"id": 8, "label": "    log.info(f\"{prefix} mocking {mock_name}...\")", "successors": [{"id": 9, "label": "if hasattr(block, mock_name):\n    setattr(block, mock_name, mock_obj)", "successors": []}, {"id": 11, "label": "else:\n    log.info(f\"{prefix} mock {mock_name} not found in block\")", "successors": []}]}]}, {"id": 12, "label": "extra_exec_kwargs = {}", "successors": [{"id": 13, "label": "if CREDENTIALS_FIELD_NAME in block.input_schema.model_fields:", "successors": [{"id": 14, "label": "    if not block.test_credentials:\n        raise ValueError(\n            f\"{prefix} requires credentials but has no test_credentials\"\n        )", "successors": []}, {"id": 16, "label": "    extra_exec_kwargs[CREDENTIALS_FIELD_NAME] = block.test_credentials", "successors": []}]}, {"id": 17, "label": "for input_data in block.test_input:", "successors": [{"id": 18, "label": "    log.info(f\"{prefix} in: {input_data}\")", "successors": [{"id": 19, "label": "for output_name, output_data in block.execute(input_data, **extra_exec_kwargs):", "successors": [{"id": 20, "label": "    if output_index >= len(block.test_output):\n        raise ValueError(f\"{prefix} produced output more than expected\")", "successors": []}, {"id": 22, "label": "    ex_output_name, ex_output_data = block.test_output[output_index]\n    compare(output_data, ex_output_data)\n    compare(output_name, ex_output_name)\n    output_index += 1", "successors": []}]}]}]}, {"id": 24, "label": "if output_index < len(block.test_output):\n    raise ValueError(\n        f\"{prefix} produced output less than expected. output_index={output_index}, len(block.test_output)={len(block.test_output)}\"\n    )", "successors": []}]}]}]}]}]}], "classes": [{"name": "SpinTestServer", "type": "class", "start_line": 17, "end_line": 53, "functions": [{"name": "__init__", "type": "function", "start_line": 18, "end_line": 22, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        self.db_api = DatabaseManager()\n        self.exec_manager = ExecutionManager()\n        self.agent_server = AgentServer()\n        self.scheduler = ExecutionScheduler()", "blocks": [{"id": 1, "label": "def __init__(self):\n    self.db_api = DatabaseManager()\n    self.exec_manager = ExecutionManager()\n    self.agent_server = AgentServer()\n    self.scheduler = ExecutionScheduler()", "successors": []}]}, {"name": "test_get_user_id", "type": "function", "start_line": 25, "end_line": 26, "functions": [], "classes": [], "simplified_code": "    def test_get_user_id():\n        return \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\"", "blocks": [{"id": 1, "label": "def test_get_user_id():\n    return \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\"", "successors": []}]}, {"name": "__aenter__", "type": "function", "start_line": 28, "end_line": 39, "functions": [], "classes": [], "simplified_code": "    async def __aenter__(self):\n        self.setup_dependency_overrides()\n        self.db_api.__enter__()\n        self.agent_server.__enter__()\n        self.exec_manager.__enter__()\n        self.scheduler.__enter__()\n\n        await db.connect()\n        await initialize_blocks()\n        await create_default_user()\n\n        return self", "blocks": [{"id": 1, "label": "async def __aenter__(self):\nself.setup_dependency_overrides()\nself.db_api.__enter__()\nself.agent_server.__enter__()\nself.exec_manager.__enter__()\nself.scheduler.__enter__()\nawait db.connect()\nawait initialize_blocks()\nawait create_default_user()", "successors": [{"id": 3, "label": "return self", "successors": []}]}]}, {"name": "__aexit__", "type": "function", "start_line": 41, "end_line": 47, "functions": [], "classes": [], "simplified_code": "    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        await db.disconnect()\n\n        self.scheduler.__exit__(exc_type, exc_val, exc_tb)\n        self.exec_manager.__exit__(exc_type, exc_val, exc_tb)\n        self.agent_server.__exit__(exc_type, exc_val, exc_tb)\n        self.db_api.__exit__(exc_type, exc_val, exc_tb)", "blocks": [{"id": 1, "label": "async def __aexit__(self, exc_type, exc_val, exc_tb):\nawait db.disconnect()", "successors": [{"id": 3, "label": "self.scheduler.__exit__(exc_type, exc_val, exc_tb)\nself.exec_manager.__exit__(exc_type, exc_val, exc_tb)", "successors": [{"id": 5, "label": "self.agent_server.__exit__(exc_type, exc_val, exc_tb)\nself.db_api.__exit__(exc_type, exc_val, exc_tb)", "successors": []}]}]}]}, {"name": "setup_dependency_overrides", "type": "function", "start_line": 49, "end_line": 53, "functions": [], "classes": [], "simplified_code": "    def setup_dependency_overrides(self):\n        # Override get_user_id for testing\n        self.agent_server.set_test_dependency_overrides(\n            {get_user_id: self.test_get_user_id}\n        )", "blocks": [{"id": 1, "label": "def setup_dependency_overrides(self):\n    self.agent_server.set_test_dependency_overrides({get_user_id: self.test_get_user_id})", "successors": []}]}], "classes": [], "simplified_code": "class SpinTestServer:\n        self.scheduler = ExecutionScheduler()\n\n    @staticmethod\n        return \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\"\n\n        return self\n\n        self.db_api.__exit__(exc_type, exc_val, exc_tb)\n\n        )", "blocks": [{"id": 1, "label": "class SpinTestServer:\n    self.scheduler = ExecutionScheduler()", "successors": []}]}], "simplified_code": "import logging\nimport time\nfrom typing import Sequence\n\nfrom backend.data import db\nfrom backend.data.block import Block, initialize_blocks\nfrom backend.data.execution import ExecutionResult, ExecutionStatus\nfrom backend.data.model import CREDENTIALS_FIELD_NAME\nfrom backend.data.user import create_default_user\nfrom backend.executor import DatabaseManager, ExecutionManager, ExecutionScheduler\nfrom backend.server.rest_api import AgentServer\nfrom backend.server.utils import get_user_id\n\nlog = logging.getLogger(__name__)\n\n\n        )\n\n\n    assert False, \"Execution did not complete in time.\"\n\n\n        )", "blocks": [{"id": 1, "label": "import logging\nimport time\nfrom typing import Sequence\n\nfrom backend.data import db\nfrom backend.data.block import Block, initialize_blocks\nfrom backend.data.execution import ExecutionResult, ExecutionStatus\nfrom backend.data.model import CREDENTIALS_FIELD_NAME\nfrom backend.data.user import create_default_user\nfrom backend.executor import DatabaseManager, ExecutionManager, ExecutionScheduler\nfrom backend.server.rest_api import AgentServer\nfrom backend.server.utils import get_user_id\n\nlog = logging.getLogger(__name__)\n\nassert False, \"Execution did not complete in time.\"\n", "successors": []}]}
{"file_name": "60.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 328, "functions": [], "classes": [{"name": "AppEnvironment", "type": "class", "start_line": 19, "end_line": 22, "functions": [], "simplified_code": "class AppEnvironment(str, Enum):\n    LOCAL = \"local\"\n    DEVELOPMENT = \"dev\"\n    PRODUCTION = \"prod\"", "blocks": [{"id": 1, "label": "class AppEnvironment(str, Enum):", "successors": [{"id": 2, "label": "    LOCAL = \"local\"", "successors": []}, {"id": 3, "label": "    DEVELOPMENT = \"dev\"", "successors": []}, {"id": 4, "label": "    PRODUCTION = \"prod\"", "successors": []}]}]}, {"name": "BehaveAs", "type": "class", "start_line": 25, "end_line": 27, "functions": [], "simplified_code": "class BehaveAs(str, Enum):\n    LOCAL = \"local\"\n    CLOUD = \"cloud\"", "blocks": [{"id": 1, "label": "class BehaveAs(str, Enum):", "successors": [{"id": 2, "label": "    LOCAL = \"local\"", "successors": []}, {"id": 3, "label": "    CLOUD = \"cloud\"", "successors": []}]}]}, {"name": "UpdateTrackingModel", "type": "class", "start_line": 30, "end_line": 50, "functions": [{"name": "__setattr__", "type": "function", "start_line": 33, "end_line": 36, "functions": [], "classes": [], "simplified_code": "    def __setattr__(self, name: str, value) -> None:\n        if name in self.model_fields:\n            self._updated_fields.add(name)\n        super().__setattr__(name, value)", "blocks": [{"id": 1, "label": "def __setattr__(self, name: str, value) -> None:\nif name in self.model_fields:", "successors": [{"id": 3, "label": "    self._updated_fields.add(name)\nsuper().__setattr__(name, value)", "successors": []}, {"id": 4, "label": "super().__setattr__(name, value)", "successors": []}]}]}, {"name": "mark_updated", "type": "function", "start_line": 38, "end_line": 40, "functions": [], "classes": [], "simplified_code": "    def mark_updated(self, field_name: str) -> None:\n        if field_name in self.model_fields:\n            self._updated_fields.add(field_name)", "blocks": [{"id": 1, "label": "def mark_updated(self, field_name: str) -> None:\nif field_name in self.model_fields:", "successors": [{"id": 3, "label": "self._updated_fields.add(field_name)", "successors": []}]}]}, {"name": "clear_updates", "type": "function", "start_line": 42, "end_line": 43, "functions": [], "classes": [], "simplified_code": "    def clear_updates(self) -> None:\n        self._updated_fields.clear()", "blocks": [{"id": 1, "label": "def clear_updates(self) -> None:\n    self._updated_fields.clear()", "successors": []}]}, {"name": "get_updates", "type": "function", "start_line": 45, "end_line": 46, "functions": [], "classes": [], "simplified_code": "    def get_updates(self) -> Dict[str, Any]:\n        return {field: getattr(self, field) for field in self._updated_fields}", "blocks": [{"id": 1, "label": "def get_updates(self) -> Dict[str, Any]:\nreturn {field: getattr(self, field) for field in self._updated_fields}", "successors": []}]}, {"name": "updated_fields", "type": "function", "start_line": 49, "end_line": 50, "functions": [], "classes": [], "simplified_code": "    def updated_fields(self):\n        return self._updated_fields", "blocks": [{"id": 1, "label": "def updated_fields(self):\nreturn self._updated_fields", "successors": []}]}], "simplified_code": "class UpdateTrackingModel(BaseModel, Generic[T]):\n    _updated_fields: Set[str] = PrivateAttr(default_factory=set)\n\n        super().__setattr__(name, value)\n\n            self._updated_fields.add(field_name)\n\n        self._updated_fields.clear()\n\n        return {field: getattr(self, field) for field in self._updated_fields}\n\n    @property\n        return self._updated_fields", "blocks": [{"id": 1, "label": "class UpdateTrackingModel(BaseModel, Generic[T]):\n    _updated_fields: Set[str] = PrivateAttr(default_factory=set)", "successors": [{"id": 2, "label": "super().__setattr__(name, value)\nself._updated_fields.add(field_name)", "successors": [{"id": 4, "label": "self._updated_fields.clear()\nreturn {field: getattr(self, field) for field in self._updated_fields}", "successors": []}]}, {"id": 6, "label": "@property\n    def updated_fields(self) -> Set[str]:\nreturn self._updated_fields", "successors": []}]}]}, {"name": "Config", "type": "class", "start_line": 53, "end_line": 234, "functions": [{"name": "validate_platform_base_url", "type": "function", "start_line": 158, "end_line": 168, "functions": [], "classes": [], "simplified_code": "    def validate_platform_base_url(cls, v: str, info: ValidationInfo) -> str:\n        if not v:\n            return v\n        if not v.startswith((\"http://\", \"https://\")):\n            raise ValueError(\n                f\"{info.field_name} must be a full URL \"\n                \"including a http:// or https:// schema\"\n            )\n        if v.endswith(\"/\"):\n            return v.rstrip(\"/\")  # Remove trailing slash\n        return v", "blocks": [{"id": 1, "label": "def validate_platform_base_url(cls, v: str, info: ValidationInfo) -> str:\nif not v:", "successors": [{"id": 3, "label": "return v", "successors": []}, {"id": 4, "label": "if not v.startswith((\"http://\", \"https://\")):", "successors": [{"id": 5, "label": "raise ValueError(\n    f\"{info.field_name} must be a full URL \"\n    \"including a http:// or https:// schema\"\n)", "successors": []}, {"id": 6, "label": "if v.endswith(\"/\"):", "successors": [{"id": 7, "label": "return v.rstrip(\"/\")", "successors": []}, {"id": 8, "label": "return v", "successors": []}]}]}]}]}, {"name": "validate_cors_allow_origins", "type": "function", "start_line": 194, "end_line": 217, "functions": [], "classes": [], "simplified_code": "    def validate_cors_allow_origins(cls, v: List[str]) -> List[str]:\n        out = []\n        port = None\n        has_localhost = False\n        has_127_0_0_1 = False\n        for url in v:\n            url = url.strip()\n            if url.startswith((\"http://\", \"https://\")):\n                if \"localhost\" in url:\n                    port = url.split(\":\")[2]\n                    has_localhost = True\n                if \"127.0.0.1\" in url:\n                    port = url.split(\":\")[2]\n                    has_127_0_0_1 = True\n                out.append(url)\n            else:\n                raise ValueError(f\"Invalid URL: {url}\")\n\n        if has_127_0_0_1 and not has_localhost:\n            out.append(f\"http://localhost:{port}\")\n        if has_localhost and not has_127_0_0_1:\n            out.append(f\"http://127.0.0.1:{port}\")\n\n        return out", "blocks": [{"id": 1, "label": "def validate_cors_allow_origins(cls, v: List[str]) -> List[str]:\nout = []\nport = None\nhas_localhost = False\nhas_127_0_0_1 = False", "successors": [{"id": 3, "label": "for url in v:", "successors": [{"id": 4, "label": "url = url.strip()", "successors": [{"id": 5, "label": "if url.startswith((\"http://\", \"https://\")):", "successors": [{"id": 6, "label": "if \"localhost\" in url:\nport = url.split(\":\")[2]\nhas_localhost = True", "successors": [{"id": 10, "label": "out.append(url)\ncontinue", "successors": [{"id": 3, "label": "for url in v:", "successors": []}]}]}, {"id": 8, "label": "if \"127.0.0.1\" in url:\nport = url.split(\":\")[2]\nhas_127_0_0_1 = True", "successors": [{"id": 10, "label": "out.append(url)\ncontinue", "successors": [{"id": 3, "label": "for url in v:", "successors": []}]}]}]}, {"id": 12, "label": "else:\n    raise ValueError(f\"Invalid URL: {url}\")", "successors": []}]}]}, {"id": 13, "label": "if has_127_0_0_1 and not has_localhost:\nout.append(f\"http://localhost:{port}\")", "successors": []}, {"id": 15, "label": "if has_localhost and not has_127_0_0_1:\nout.append(f\"http://127.0.0.1:{port}\")", "successors": []}, {"id": 17, "label": "return out", "successors": []}]}]}, {"name": "settings_customise_sources", "type": "function", "start_line": 220, "end_line": 234, "functions": [], "classes": [], "simplified_code": "    def settings_customise_sources(\n        cls,\n        settings_cls: Type[BaseSettings],\n        init_settings: PydanticBaseSettingsSource,\n        env_settings: PydanticBaseSettingsSource,\n        dotenv_settings: PydanticBaseSettingsSource,\n        file_secret_settings: PydanticBaseSettingsSource,\n    ) -> Tuple[PydanticBaseSettingsSource, ...]:\n        return (\n            env_settings,\n            file_secret_settings,\n            dotenv_settings,\n            JsonConfigSettingsSource(settings_cls),\n            init_settings,\n        )", "blocks": [{"id": 1, "label": "def settings_customise_sources(\n    cls,\n    settings_cls: Type[BaseSettings],\n    init_settings: PydanticBaseSettingsSource,\n    env_settings: PydanticBaseSettingsSource,\n    dotenv_settings: PydanticBaseSettingsSource,\n    file_secret_settings: PydanticBaseSettingsSource,\n) -> Tuple[PydanticBaseSettingsSource, ...]:\nreturn (\n    env_settings,\n    file_secret_settings,\n    dotenv_settings,\n    JsonConfigSettingsSource(settings_cls),\n    init_settings,\n)", "successors": []}]}], "simplified_code": "class Config(UpdateTrackingModel[\"Config\"], BaseSettings):\n    \"\"\"Config for the server.\"\"\"\n\n    num_graph_workers: int = Field(\n        default=10,\n        ge=1,\n        le=1000,\n        description=\"Maximum number of workers to use for graph execution.\",\n    )\n    num_node_workers: int = Field(\n        default=5,\n        ge=1,\n        le=1000,\n        description=\"Maximum number of workers to use for node execution within a single graph.\",\n    )\n    pyro_host: str = Field(\n        default=\"localhost\",\n        description=\"The default hostname of the Pyro server.\",\n    )\n    pyro_client_comm_timeout: float = Field(\n        default=15,\n        description=\"The default timeout in seconds, for Pyro client connections.\",\n    )\n    pyro_client_comm_retry: int = Field(\n        default=3,\n        description=\"The default number of retries for Pyro client connections.\",\n    )\n    enable_auth: bool = Field(\n        default=True,\n        description=\"If authentication is enabled or not\",\n    )\n    enable_credit: str = Field(\n        default=\"false\",\n        description=\"If user credit system is enabled or not\",\n    )\n    num_user_credits_refill: int = Field(\n        default=1500,\n        description=\"Number of credits to refill for each user\",\n    )\n    # Add more configuration fields as needed\n\n    model_config = SettingsConfigDict(\n        env_file=\".env\",\n        extra=\"allow\",\n    )\n\n    websocket_server_host: str = Field(\n        default=\"0.0.0.0\",\n        description=\"The host for the websocket server to run on\",\n    )\n\n    websocket_server_port: int = Field(\n        default=8001,\n        description=\"The port for the websocket server to run on\",\n    )\n\n    execution_manager_port: int = Field(\n        default=8002,\n        description=\"The port for execution manager daemon to run on\",\n    )\n\n    execution_scheduler_port: int = Field(\n        default=8003,\n        description=\"The port for execution scheduler daemon to run on\",\n    )\n\n    agent_server_port: int = Field(\n        default=8004,\n        description=\"The port for agent server daemon to run on\",\n    )\n\n    database_api_port: int = Field(\n        default=8005,\n        description=\"The port for database server API to run on\",\n    )\n\n    agent_api_host: str = Field(\n        default=\"0.0.0.0\",\n        description=\"The host for agent server API to run on\",\n    )\n\n    agent_api_port: int = Field(\n        default=8006,\n        description=\"The port for agent server API to run on\",\n    )\n\n    platform_base_url: str = Field(\n        default=\"\",\n        description=\"Must be set so the application knows where it's hosted at. \"\n        \"This is necessary to make sure webhooks find their way.\",\n    )\n\n    frontend_base_url: str = Field(\n        default=\"\",\n        description=\"Can be used to explicitly set the base URL for the frontend. \"\n        \"This value is then used to generate redirect URLs for OAuth flows.\",\n    )\n\n    media_gcs_bucket_name: str = Field(\n        default=\"\",\n        description=\"The name of the Google Cloud Storage bucket for media files\",\n    )\n\n    @field_validator(\"platform_base_url\", \"frontend_base_url\")\n    @classmethod\n        return v\n\n    app_env: AppEnvironment = Field(\n        default=AppEnvironment.LOCAL,\n        description=\"The name of the app environment: local or dev or prod\",\n    )\n\n    behave_as: BehaveAs = Field(\n        default=BehaveAs.LOCAL,\n        description=\"What environment to behave as: local or cloud\",\n    )\n\n    execution_event_bus_name: str = Field(\n        default=\"execution_event\",\n        description=\"Name of the event bus\",\n    )\n\n    trust_endpoints_for_requests: List[str] = Field(\n        default_factory=list,\n        description=\"A whitelist of trusted internal endpoints for the backend to make requests to.\",\n    )\n\n    backend_cors_allow_origins: List[str] = Field(default_factory=list)\n\n    @field_validator(\"backend_cors_allow_origins\")\n    @classmethod\n        return out\n\n    @classmethod\n        )", "blocks": [{"id": 1, "label": "class Config(UpdateTrackingModel[\"Config\"], BaseSettings):\n\"\"\"Config for the server.\"\"\"", "successors": [{"id": 3, "label": "num_graph_workers: int = Field(default=10, ge=1, le=1000, description=\"Maximum number of workers to use for graph execution.\")\nnum_node_workers: int = Field(default=5, ge=1, le=1000, description=\"Maximum number of workers to use for node execution within a single graph.\")\npyro_host: str = Field(default=\"localhost\", description=\"The default hostname of the Pyro server.\")\npyro_client_comm_timeout: float = Field(default=15, description=\"The default timeout in seconds, for Pyro client connections.\")\npyro_client_comm_retry: int = Field(default=3, description=\"The default number of retries for Pyro client connections.\")\nenable_auth: bool = Field(default=True, description=\"If authentication is enabled or not\")\nenable_credit: str = Field(default=\"false\", description=\"If user credit system is enabled or not\")\nnum_user_credits_refill: int = Field(default=1500, description=\"Number of credits to refill for each user\")\nmodel_config = SettingsConfigDict(env_file=\".env\", extra=\"allow\")\nwebsocket_server_host: str = Field(default=\"0.0.0.0\", description=\"The host for the websocket server to run on\")\nwebsocket_server_port: int = Field(default=8001, description=\"The port for the websocket server to run on\")\nexecution_manager_port: int = Field(default=8002, description=\"The port for execution manager daemon to run on\")\nexecution_scheduler_port: int = Field(default=8003, description=\"The port for execution scheduler daemon to run on\")\nagent_server_port: int = Field(default=8004, description=\"The port for agent server daemon to run on\")\ndatabase_api_port: int = Field(default=8005, description=\"The port for database server API to run on\")", "successors": [{"id": 5, "label": "agent_api_host: str = Field(default=\"0.0.0.0\", description=\"The host for agent server API to run on\")\nagent_api_port: int = Field(default=8006, description=\"The port for agent server API to run on\")\nplatform_base_url: str = Field(default=\"\", description=\"Must be set so the application knows where it's hosted at. This is necessary to make sure webhooks find their way.\")\nfrontend_base_url: str = Field(default=\"\", description=\"Can be used to explicitly set the base URL for the frontend. This value is then used to generate redirect URLs for OAuth flows.\")\nmedia_gcs_bucket_name: str = Field(default=\"\", description=\"The name of the Google Cloud Storage bucket for media files\")\n@field_validator(\"platform_base_url\", \"frontend_base_url\")\n@classmethod\n    return v\napp_env: AppEnvironment = Field(default=AppEnvironment.LOCAL, description=\"The name of the app environment: local or dev or prod\")\nbehave_as: BehaveAs = Field(default=BehaveAs.LOCAL, description=\"What environment to behave as: local or cloud\")\nexecution_event_bus_name: str = Field(default=\"execution_event\", description=\"Name of the event bus\")\ntrust_endpoints_for_requests: List[str] = Field(default_factory=list, description=\"A whitelist of trusted internal endpoints for the backend to make requests to.\")\nbackend_cors_allow_origins: List[str] = Field(default_factory=list)", "successors": [{"id": 7, "label": "@field_validator(\"backend_cors_allow_origins\")\n@classmethod\n    return out\n@classmethod\n    )", "successors": []}]}]}]}]}, {"name": "Secrets", "type": "class", "start_line": 237, "end_line": 306, "functions": [], "simplified_code": "class Secrets(UpdateTrackingModel[\"Secrets\"], BaseSettings):\n    \"\"\"Secrets for the server.\"\"\"\n\n    supabase_url: str = Field(default=\"\", description=\"Supabase URL\")\n    supabase_service_role_key: str = Field(\n        default=\"\", description=\"Supabase service role key\"\n    )\n\n    encryption_key: str = Field(default=\"\", description=\"Encryption key\")\n\n    # OAuth server credentials for integrations\n    # --8<-- [start:OAuthServerCredentialsExample]\n    github_client_id: str = Field(default=\"\", description=\"GitHub OAuth client ID\")\n    github_client_secret: str = Field(\n        default=\"\", description=\"GitHub OAuth client secret\"\n    )\n    # --8<-- [end:OAuthServerCredentialsExample]\n    google_client_id: str = Field(default=\"\", description=\"Google OAuth client ID\")\n    google_client_secret: str = Field(\n        default=\"\", description=\"Google OAuth client secret\"\n    )\n    notion_client_id: str = Field(default=\"\", description=\"Notion OAuth client ID\")\n    notion_client_secret: str = Field(\n        default=\"\", description=\"Notion OAuth client secret\"\n    )\n\n    openai_api_key: str = Field(default=\"\", description=\"OpenAI API key\")\n    anthropic_api_key: str = Field(default=\"\", description=\"Anthropic API key\")\n    groq_api_key: str = Field(default=\"\", description=\"Groq API key\")\n    open_router_api_key: str = Field(default=\"\", description=\"Open Router API Key\")\n\n    reddit_client_id: str = Field(default=\"\", description=\"Reddit client ID\")\n    reddit_client_secret: str = Field(default=\"\", description=\"Reddit client secret\")\n    reddit_username: str = Field(default=\"\", description=\"Reddit username\")\n    reddit_password: str = Field(default=\"\", description=\"Reddit password\")\n\n    openweathermap_api_key: str = Field(\n        default=\"\", description=\"OpenWeatherMap API key\"\n    )\n\n    medium_api_key: str = Field(default=\"\", description=\"Medium API key\")\n    medium_author_id: str = Field(default=\"\", description=\"Medium author ID\")\n    did_api_key: str = Field(default=\"\", description=\"D-ID API Key\")\n    revid_api_key: str = Field(default=\"\", description=\"revid.ai API key\")\n    discord_bot_token: str = Field(default=\"\", description=\"Discord bot token\")\n\n    smtp_server: str = Field(default=\"\", description=\"SMTP server IP\")\n    smtp_port: str = Field(default=\"\", description=\"SMTP server port\")\n    smtp_username: str = Field(default=\"\", description=\"SMTP username\")\n    smtp_password: str = Field(default=\"\", description=\"SMTP password\")\n\n    sentry_dsn: str = Field(default=\"\", description=\"Sentry DSN\")\n\n    google_maps_api_key: str = Field(default=\"\", description=\"Google Maps API Key\")\n\n    replicate_api_key: str = Field(default=\"\", description=\"Replicate API Key\")\n    unreal_speech_api_key: str = Field(default=\"\", description=\"Unreal Speech API Key\")\n    ideogram_api_key: str = Field(default=\"\", description=\"Ideogram API Key\")\n    jina_api_key: str = Field(default=\"\", description=\"Jina API Key\")\n    unreal_speech_api_key: str = Field(default=\"\", description=\"Unreal Speech API Key\")\n\n    fal_key: str = Field(default=\"\", description=\"FAL API key\")\n\n    # Add more secret fields as needed\n\n    model_config = SettingsConfigDict(\n        env_file=\".env\",\n        env_file_encoding=\"utf-8\",\n        extra=\"allow\",\n    )", "blocks": [{"id": 1, "label": "class Secrets(UpdateTrackingModel[\"Secrets\"], BaseSettings):\n    \"\"\"Secrets for the server.\"\"\"", "successors": [{"id": 3, "label": "    supabase_url: str = Field(default=\"\", description=\"Supabase URL\")\n    supabase_service_role_key: str = Field(\n        default=\"\", description=\"Supabase service role key\"\n    )\n    encryption_key: str = Field(default=\"\", description=\"Encryption key\")\n    \n    # OAuth server credentials for integrations\n    # --8<-- [start:OAuthServerCredentialsExample]\n    github_client_id: str = Field(default=\"\", description=\"GitHub OAuth client ID\")\n    github_client_secret: str = Field(\n        default=\"\", description=\"GitHub OAuth client secret\"\n    )\n    # --8<-- [end:OAuthServerCredentialsExample]\n    google_client_id: str = Field(default=\"\", description=\"Google OAuth client ID\")\n    google_client_secret: str = Field(\n        default=\"\", description=\"Google OAuth client secret\"\n    )\n    notion_client_id: str = Field(default=\"\", description=\"Notion OAuth client ID\")\n    notion_client_secret: str = Field(\n        default=\"\", description=\"Notion OAuth client secret\"\n    )\n\n    openai_api_key: str = Field(default=\"\", description=\"OpenAI API key\")\n    anthropic_api_key: str = Field(default=\"\", description=\"Anthropic API key\")\n    groq_api_key: str = Field(default=\"\", description=\"Groq API key\")\n    open_router_api_key: str = Field(default=\"\", description=\"Open Router API Key\")\n\n    reddit_client_id: str = Field(default=\"\", description=\"Reddit client ID\")\n    reddit_client_secret: str = Field(default=\"\", description=\"Reddit client secret\")\n    reddit_username: str = Field(default=\"\", description=\"Reddit username\")\n    reddit_password: str = Field(default=\"\", description=\"Reddit password\")\n\n    openweathermap_api_key: str = Field(\n        default=\"\", description=\"OpenWeatherMap API key\"\n    )\n\n    medium_api_key: str = Field(default=\"\", description=\"Medium API key\")\n    medium_author_id: str = Field(default=\"\", description=\"Medium author ID\")\n    did_api_key: str = Field(default=\"\", description=\"D-ID API Key\")\n    revid_api_key: str = Field(default=\"\", description=\"revid.ai API key\")\n    discord_bot_token: str = Field(default=\"\", description=\"Discord bot token\")\n\n    smtp_server: str = Field(default=\"\", description=\"SMTP server IP\")\n    smtp_port: str = Field(default=\"\", description=\"SMTP server port\")\n    smtp_username: str = Field(default=\"\", description=\"SMTP username\")\n    smtp_password: str = Field(default=\"\", description=\"SMTP password\")\n\n    sentry_dsn: str = Field(default=\"\", description=\"Sentry DSN\")\n\n    google_maps_api_key: str = Field(default=\"\", description=\"Google Maps API Key\")\n\n    replicate_api_key: str = Field(default=\"\", description=\"Replicate API Key\")\n    unreal_speech_api_key: str = Field(default=\"\", description=\"Unreal Speech API Key\")\n    ideogram_api_key: str = Field(default=\"\", description=\"Ideogram API Key\")\n    jina_api_key: str = Field(default=\"\", description=\"Jina API Key\")\n    unreal_speech_api_key: str = Field(default=\"\", description=\"Unreal Speech API Key\")\n\n    fal_key: str = Field(default=\"\", description=\"FAL API key\")\n\n    # Add more secret fields as needed\n    model_config = SettingsConfigDict(\n        env_file=\".env\",\n        env_file_encoding=\"utf-8\",\n        extra=\"allow\",\n    )", "successors": []}]}]}, {"name": "Settings", "type": "class", "start_line": 309, "end_line": 328, "functions": [{"name": "save", "type": "function", "start_line": 313, "end_line": 328, "functions": [], "classes": [], "simplified_code": "    def save(self) -> None:\n        # Save updated config to JSON file\n        if self.config.updated_fields:\n            config_to_save = self.config.get_updates()\n            config_path = os.path.join(get_data_path(), \"config.json\")\n            if os.path.exists(config_path):\n                with open(config_path, \"r+\") as f:\n                    existing_config: Dict[str, Any] = json.load(f)\n                    existing_config.update(config_to_save)\n                    f.seek(0)\n                    json.dump(existing_config, f, indent=2)\n                    f.truncate()\n            else:\n                with open(config_path, \"w\") as f:\n                    json.dump(config_to_save, f, indent=2)\n            self.config.clear_updates()", "blocks": [{"id": 1, "label": "if self.config.updated_fields:\n    config_to_save = self.config.get_updates()\n    config_path = os.path.join(get_data_path(), \"config.json\")\n    if os.path.exists(config_path):", "successors": [{"id": 3, "label": "        with open(config_path, \"r+\") as f:\n            existing_config: Dict[str, Any] = json.load(f)\n            existing_config.update(config_to_save)\n            f.seek(0)\n            json.dump(existing_config, f, indent=2)\n            f.truncate()\nself.config.clear_updates()", "successors": []}, {"id": 4, "label": "        with open(config_path, \"w\") as f:\n            json.dump(config_to_save, f, indent=2)\nself.config.clear_updates()", "successors": []}]}]}], "simplified_code": "class Settings(BaseModel):\n    config: Config = Config()\n    secrets: Secrets = Secrets()\n\n            self.config.clear_updates()", "blocks": [{"id": 1, "label": "class Settings(BaseModel):\n    config: Config = Config()", "successors": [{"id": 3, "label": "    secrets: Secrets = Secrets()\nself.config.clear_updates()", "successors": []}]}]}], "simplified_code": "import json\nimport os\nfrom enum import Enum\nfrom typing import Any, Dict, Generic, List, Set, Tuple, Type, TypeVar\n\nfrom pydantic import BaseModel, Field, PrivateAttr, ValidationInfo, field_validator\nfrom pydantic_settings import (\n    BaseSettings,\n    JsonConfigSettingsSource,\n    PydanticBaseSettingsSource,\n    SettingsConfigDict,\n)\n\nfrom backend.util.data import get_data_path\n\nT = TypeVar(\"T\", bound=BaseSettings)\n\n\n    PRODUCTION = \"prod\"\n\n\n    CLOUD = \"cloud\"\n\n\n        return self._updated_fields\n\n\n        )\n\n\n    )\n\n\n            self.config.clear_updates()", "blocks": [{"id": 1, "label": "import json\nimport os\nfrom enum import Enum\nfrom typing import Any, Dict, Generic, List, Set, Tuple, Type, TypeVar\n\nfrom pydantic import BaseModel, Field, PrivateAttr, ValidationInfo, field_validator\nfrom pydantic_settings import (\n    BaseSettings,\n    JsonConfigSettingsSource,\n    PydanticBaseSettingsSource,\n    SettingsConfigDict,\n)\n\nfrom backend.util.data import get_data_path\n\nT = TypeVar(\"T\", bound=BaseSettings)", "successors": []}]}
{"file_name": "61.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 47, "functions": [{"name": "to_dict", "type": "function", "start_line": 10, "end_line": 11, "functions": [], "classes": [], "simplified_code": "def to_dict(data) -> dict:\n    return jsonable_encoder(data)", "blocks": [{"id": 1, "label": "def to_dict(data) -> dict:\n    return jsonable_encoder(data)", "successors": []}]}, {"name": "dumps", "type": "function", "start_line": 14, "end_line": 15, "functions": [], "classes": [], "simplified_code": "def dumps(data) -> str:\n    return json.dumps(jsonable_encoder(data))", "blocks": [{"id": 1, "label": "def dumps(data) -> str:\n    return json.dumps(jsonable_encoder(data))", "successors": []}]}, {"name": "loads", "type": "function", "start_line": 29, "end_line": 33, "functions": [], "classes": [], "simplified_code": "def loads(data: str, *args, target_type: Type[T] | None = None, **kwargs) -> Any:\n    parsed = json.loads(data, *args, **kwargs)\n    if target_type:\n        return type_match(parsed, target_type)\n    return parsed", "blocks": [{"id": 1, "label": "parsed = json.loads(data, *args, **kwargs)\nif target_type:", "successors": [{"id": 3, "label": "    return type_match(parsed, target_type)", "successors": []}, {"id": 4, "label": "return parsed", "successors": []}]}]}, {"name": "validate_with_jsonschema", "type": "function", "start_line": 36, "end_line": 47, "functions": [], "classes": [], "simplified_code": "def validate_with_jsonschema(\n    schema: dict[str, Any], data: dict[str, Any]\n) -> str | None:\n    \"\"\"\n    Validate the data against the schema.\n    Returns the validation error message if the data does not match the schema.\n    \"\"\"\n    try:\n        jsonschema.validate(data, schema)\n        return None\n    except jsonschema.ValidationError as e:\n        return str(e)", "blocks": [{"id": 1, "label": "try:", "successors": [{"id": 2, "label": "    jsonschema.validate(data, schema)\n    return None", "successors": []}, {"id": 3, "label": "except jsonschema.ValidationError as e:\n    return str(e)", "successors": []}]}]}], "classes": [], "simplified_code": "import json\nfrom typing import Any, Type, TypeVar, overload\n\nimport jsonschema\nfrom fastapi.encoders import jsonable_encoder\n\nfrom .type import type_match\n\n\n    return jsonable_encoder(data)\n\n\n    return json.dumps(jsonable_encoder(data))\n\n\nT = TypeVar(\"T\")\n\n\n@overload\ndef loads(data: str, *args, target_type: Type[T], **kwargs) -> T: ...\n\n\n@overload\ndef loads(data: str, *args, **kwargs) -> Any: ...\n\n\n    return parsed\n\n\n        return str(e)", "blocks": [{"id": 1, "label": "import json\nfrom typing import Any, Type, TypeVar, overload\n\nimport jsonschema\nfrom fastapi.encoders import jsonable_encoder\n\nfrom .type import type_match", "successors": [{"id": 2, "label": "return jsonable_encoder(data)", "successors": []}, {"id": 3, "label": "return json.dumps(jsonable_encoder(data))", "successors": []}, {"id": 4, "label": "T = TypeVar(\"T\")\n@overload\ndef loads(data: str, *args, target_type: Type[T], **kwargs) -> T: ...", "successors": [{"id": 6, "label": "@overload\ndef loads(data: str, *args, **kwargs) -> Any: ...", "successors": [{"id": 7, "label": "return parsed", "successors": []}, {"id": 8, "label": "return str(e)", "successors": []}]}]}]}]}
{"file_name": "62.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 90, "functions": [], "classes": [{"name": "TranscribeYoutubeVideoBlock", "type": "class", "start_line": 10, "end_line": 90, "functions": [{"name": "__init__", "type": "function", "start_line": 25, "end_line": 46, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"f3a8f7e1-4b1d-4e5f-9f2a-7c3d5a2e6b4c\",\n            input_schema=TranscribeYoutubeVideoBlock.Input,\n            output_schema=TranscribeYoutubeVideoBlock.Output,\n            description=\"Transcribes a YouTube video.\",\n            categories={BlockCategory.SOCIAL},\n            test_input={\"youtube_url\": \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\"},\n            test_output=[\n                (\"video_id\", \"dQw4w9WgXcQ\"),\n                (\n                    \"transcript\",\n                    \"Never gonna give you up\\nNever gonna let you down\",\n                ),\n            ],\n            test_mock={\n                \"get_transcript\": lambda video_id: [\n                    {\"text\": \"Never gonna give you up\"},\n                    {\"text\": \"Never gonna let you down\"},\n                ],\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"f3a8f7e1-4b1d-4e5f-9f2a-7c3d5a2e6b4c\",\n    input_schema=TranscribeYoutubeVideoBlock.Input,\n    output_schema=TranscribeYoutubeVideoBlock.Output,\n    description=\"Transcribes a YouTube video.\",\n    categories={BlockCategory.SOCIAL},\n    test_input={\"youtube_url\": \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\"},\n    test_output=[\n        (\"video_id\", \"dQw4w9WgXcQ\"),\n        (\n            \"transcript\",\n            \"Never gonna give you up\\nNever gonna let you down\",\n        ),\n    ],\n    test_mock={\n        \"get_transcript\": lambda video_id: [\n            {\"text\": \"Never gonna give you up\"},\n            {\"text\": \"Never gonna let you down\"},\n        ],\n    },\n)", "successors": []}]}, {"name": "extract_video_id", "type": "function", "start_line": 49, "end_line": 61, "functions": [], "classes": [], "simplified_code": "    def extract_video_id(url: str) -> str:\n        parsed_url = urlparse(url)\n        if parsed_url.netloc == \"youtu.be\":\n            return parsed_url.path[1:]\n        if parsed_url.netloc in (\"www.youtube.com\", \"youtube.com\"):\n            if parsed_url.path == \"/watch\":\n                p = parse_qs(parsed_url.query)\n                return p[\"v\"][0]\n            if parsed_url.path[:7] == \"/embed/\":\n                return parsed_url.path.split(\"/\")[2]\n            if parsed_url.path[:3] == \"/v/\":\n                return parsed_url.path.split(\"/\")[2]\n        raise ValueError(f\"Invalid YouTube URL: {url}\")", "blocks": [{"id": 1, "label": "parsed_url = urlparse(url)\nif parsed_url.netloc == \"youtu.be\":", "successors": [{"id": 3, "label": "return parsed_url.path[1:]", "successors": []}, {"id": 4, "label": "if parsed_url.netloc in (\"www.youtube.com\", \"youtube.com\"):\nif parsed_url.path == \"/watch\":", "successors": [{"id": 6, "label": "p = parse_qs(parsed_url.query)\nreturn p[\"v\"][0]", "successors": []}, {"id": 8, "label": "if parsed_url.path[:7] == \"/embed/\":", "successors": [{"id": 9, "label": "return parsed_url.path.split(\"/\")[2]", "successors": []}, {"id": 10, "label": "if parsed_url.path[:3] == \"/v/\":", "successors": [{"id": 11, "label": "return parsed_url.path.split(\"/\")[2]", "successors": []}, {"id": 12, "label": "raise ValueError(f\"Invalid YouTube URL: {url}\")", "successors": []}]}]}]}]}]}, {"name": "get_transcript", "type": "function", "start_line": 64, "end_line": 80, "functions": [], "classes": [], "simplified_code": "    def get_transcript(video_id: str):\n        try:\n            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n\n            if not transcript_list:\n                raise ValueError(f\"No transcripts found for the video: {video_id}\")\n\n            for transcript in transcript_list:\n                first_transcript = transcript_list.find_transcript(\n                    [transcript.language_code]\n                )\n                return YouTubeTranscriptApi.get_transcript(\n                    video_id, languages=[first_transcript.language_code]\n                )\n\n        except Exception:\n            raise ValueError(f\"No transcripts found for the video: {video_id}\")", "blocks": [{"id": 1, "label": "def get_transcript(video_id: str):", "successors": [{"id": 2, "label": "try:\ntranscript_list = YouTubeTranscriptApi.list_transcripts(video_id)", "successors": [{"id": 4, "label": "if not transcript_list:", "successors": [{"id": 5, "label": "raise ValueError(f\"No transcripts found for the video: {video_id}\")", "successors": []}, {"id": 6, "label": "for transcript in transcript_list:", "successors": [{"id": 7, "label": "first_transcript = transcript_list.find_transcript([transcript.language_code])\nreturn YouTubeTranscriptApi.get_transcript(video_id, languages=[first_transcript.language_code])", "successors": []}]}]}]}, {"id": 9, "label": "except Exception:\nraise ValueError(f\"No transcripts found for the video: {video_id}\")", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 82, "end_line": 90, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        video_id = self.extract_video_id(input_data.youtube_url)\n        yield \"video_id\", video_id\n\n        transcript = self.get_transcript(video_id)\n        formatter = TextFormatter()\n        transcript_text = formatter.format_transcript(transcript)\n\n        yield \"transcript\", transcript_text", "blocks": [{"id": 1, "label": "video_id = self.extract_video_id(input_data.youtube_url)\nyield \"video_id\", video_id", "successors": [{"id": 3, "label": "transcript = self.get_transcript(video_id)\nformatter = TextFormatter()", "successors": [{"id": 5, "label": "transcript_text = formatter.format_transcript(transcript)\nyield \"transcript\", transcript_text", "successors": []}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 11, "end_line": 16, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        youtube_url: str = SchemaField(\n            title=\"YouTube URL\",\n            description=\"The URL of the YouTube video to transcribe\",\n            placeholder=\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\nyoutube_url: str = SchemaField(\n    title=\"YouTube URL\",\n    description=\"The URL of the YouTube video to transcribe\",\n    placeholder=\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\",\n)", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 18, "end_line": 23, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        video_id: str = SchemaField(description=\"The extracted YouTube video ID\")\n        transcript: str = SchemaField(description=\"The transcribed text of the video\")\n        error: str = SchemaField(\n            description=\"Any error message if the transcription fails\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "video_id: str = SchemaField(description=\"The extracted YouTube video ID\")", "successors": []}, {"id": 3, "label": "transcript: str = SchemaField(description=\"The transcribed text of the video\")", "successors": []}, {"id": 4, "label": "error: str = SchemaField(description=\"Any error message if the transcription fails\")", "successors": []}]}]}], "simplified_code": "class TranscribeYoutubeVideoBlock(Block):\n        )\n\n        )\n\n        )\n\n    @staticmethod\n        raise ValueError(f\"Invalid YouTube URL: {url}\")\n\n    @staticmethod\n            raise ValueError(f\"No transcripts found for the video: {video_id}\")\n\n        yield \"transcript\", transcript_text", "blocks": [{"id": 1, "label": "class TranscribeYoutubeVideoBlock(Block):", "successors": [{"id": 2, "label": "@staticmethod\nraise ValueError(f\"Invalid YouTube URL: {url}\")", "successors": []}, {"id": 3, "label": "@staticmethod\nraise ValueError(f\"No transcripts found for the video: {video_id}\")", "successors": []}, {"id": 4, "label": "yield \"transcript\", transcript_text", "successors": []}]}]}], "simplified_code": "from urllib.parse import parse_qs, urlparse\n\nfrom youtube_transcript_api import YouTubeTranscriptApi\nfrom youtube_transcript_api.formatters import TextFormatter\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\n\n        yield \"transcript\", transcript_text", "blocks": [{"id": 1, "label": "from urllib.parse import parse_qs, urlparse\n\nfrom youtube_transcript_api import YouTubeTranscriptApi\nfrom youtube_transcript_api.formatters import TextFormatter\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\nyield \"transcript\", transcript_text", "successors": []}]}
{"file_name": "63.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 271, "functions": [{"name": "create_test_user", "type": "function", "start_line": 29, "end_line": 36, "functions": [], "classes": [], "simplified_code": "async def create_test_user() -> User:\n    test_user_data = {\n        \"sub\": \"ef3b97d7-1161-4eb4-92b2-10c24fb154c1\",\n        \"email\": \"testuser@example.com\",\n        \"name\": \"Test User\",\n    }\n    user = await get_or_create_user(test_user_data)\n    return user", "blocks": [{"id": 1, "label": "async def create_test_user() -> User:\n    test_user_data = {\n        \"sub\": \"ef3b97d7-1161-4eb4-92b2-10c24fb154c1\",\n        \"email\": \"testuser@example.com\",\n        \"name\": \"Test User\",\n    }\nuser = await get_or_create_user(test_user_data)", "successors": [{"id": 3, "label": "return user", "successors": []}]}]}, {"name": "create_test_graph", "type": "function", "start_line": 39, "end_line": 247, "functions": [], "classes": [], "simplified_code": "def create_test_graph() -> Graph:\n    \"\"\"\n            StoreValueBlock (input)\n                 ||\n                 v\n        FillTextTemplateBlock (input query)\n                 ||\n                 v\n         SendWebRequestBlock (browse)\n                 ||\n                 v\n     ------> StoreValueBlock===============\n    |           |  |                    ||\n    |            --                     ||\n    |                                   ||\n    |                                   ||\n    |                                    v\n    |        AITextGeneratorBlock  <===== FillTextTemplateBlock (query)\n    |            ||                      ^\n    |            v                      ||\n    |       ExtractTextInformationBlock             ||\n    |            ||                     ||\n    |            v                      ||\n    ------ BlockInstallationBlock  ======\n    \"\"\"\n    # ======= Nodes ========= #\n    input_data = Node(block_id=StoreValueBlock().id)\n    input_query_constant = Node(\n        block_id=StoreValueBlock().id,\n        input_default={\"data\": None},\n    )\n    input_text_formatter = Node(\n        block_id=FillTextTemplateBlock().id,\n        input_default={\n            \"format\": \"Show me how to make a python code for this query: `{query}`\",\n        },\n    )\n    search_http_request = Node(\n        block_id=SendWebRequestBlock().id,\n        input_default={\n            \"url\": \"https://osit-v2.bentlybro.com/search\",\n        },\n    )\n    search_result_constant = Node(\n        block_id=StoreValueBlock().id,\n        input_default={\n            \"data\": None,\n        },\n    )\n    prompt_text_formatter = Node(\n        block_id=FillTextTemplateBlock().id,\n        input_default={\n            \"format\": \"\"\"\nWrite me a full Block implementation for this query: `{query}`\n\nHere is the information I get to write a Python code for that:\n{search_result}\n\nHere is your previous attempt:\n{previous_attempt}\n\"\"\",\n            \"values_#_previous_attempt\": \"No previous attempt found.\",\n        },\n    )\n    code_gen_llm_call = Node(\n        block_id=AITextGeneratorBlock().id,\n        input_default={\n            \"sys_prompt\": f\"\"\"\nYou are a software engineer and you are asked to write the full class implementation.\nThe class that you are implementing is extending a class called `Block`.\nThis class will be used as a node in a graph of other blocks to build a complex system.\nThis class has a method called `run` that takes an input and returns an output.\nIt also has an `id` attribute that is a UUID, input_schema, and output_schema.\nFor UUID, you have to hardcode it, like `d2e2ecd2-9ae6-422d-8dfe-ceca500ce6a6`,\ndon't use any automatic UUID generation, because it needs to be consistent.\nTo validate the correctness of your implementation, you can also define a test.\nThere is `test_input` and `test_output` you can use to validate your implementation.\nThere is also `test_mock` to mock a helper function on your block class for testing.\n\nFeel free to start your answer by explaining your plan what's required how to test, etc.\nBut make sure to produce the fully working implementation at the end,\nand it should be enclosed within this block format:\n```python\n<Your implementation here>\n```\n\nHere are a couple of sample of the Block class implementation:\n\n{\"--------------\".join([sample_block_codes[v] for v in sample_block_modules])}\n\"\"\",\n        },\n    )\n    code_text_parser = Node(\n        block_id=ExtractTextInformationBlock().id,\n        input_default={\n            \"pattern\": \"```python\\n(.+?)\\n```\",\n            \"group\": 1,\n        },\n    )\n    block_installation = Node(\n        block_id=BlockInstallationBlock().id,\n    )\n    nodes = [\n        input_data,\n        input_query_constant,\n        input_text_formatter,\n        search_http_request,\n        search_result_constant,\n        prompt_text_formatter,\n        code_gen_llm_call,\n        code_text_parser,\n        block_installation,\n    ]\n\n    # ======= Links ========= #\n    links = [\n        Link(\n            source_id=input_data.id,\n            sink_id=input_query_constant.id,\n            source_name=\"output\",\n            sink_name=\"input\",\n        ),\n        Link(\n            source_id=input_data.id,\n            sink_id=input_text_formatter.id,\n            source_name=\"output\",\n            sink_name=\"values_#_query\",\n        ),\n        Link(\n            source_id=input_query_constant.id,\n            sink_id=input_query_constant.id,\n            source_name=\"output\",\n            sink_name=\"data\",\n        ),\n        Link(\n            source_id=input_text_formatter.id,\n            sink_id=search_http_request.id,\n            source_name=\"output\",\n            sink_name=\"body_#_query\",\n        ),\n        Link(\n            source_id=search_http_request.id,\n            sink_id=search_result_constant.id,\n            source_name=\"response_#_reply\",\n            sink_name=\"input\",\n        ),\n        Link(  # Loopback for constant block\n            source_id=search_result_constant.id,\n            sink_id=search_result_constant.id,\n            source_name=\"output\",\n            sink_name=\"data\",\n        ),\n        Link(\n            source_id=search_result_constant.id,\n            sink_id=prompt_text_formatter.id,\n            source_name=\"output\",\n            sink_name=\"values_#_search_result\",\n        ),\n        Link(\n            source_id=input_query_constant.id,\n            sink_id=prompt_text_formatter.id,\n            source_name=\"output\",\n            sink_name=\"values_#_query\",\n        ),\n        Link(\n            source_id=prompt_text_formatter.id,\n            sink_id=code_gen_llm_call.id,\n            source_name=\"output\",\n            sink_name=\"prompt\",\n        ),\n        Link(\n            source_id=code_gen_llm_call.id,\n            sink_id=code_text_parser.id,\n            source_name=\"response\",\n            sink_name=\"text\",\n        ),\n        Link(\n            source_id=code_text_parser.id,\n            sink_id=block_installation.id,\n            source_name=\"positive\",\n            sink_name=\"code\",\n        ),\n        Link(\n            source_id=block_installation.id,\n            sink_id=prompt_text_formatter.id,\n            source_name=\"error\",\n            sink_name=\"values_#_previous_attempt\",\n        ),\n        Link(  # Re-trigger search result.\n            source_id=block_installation.id,\n            sink_id=search_result_constant.id,\n            source_name=\"error\",\n            sink_name=\"input\",\n        ),\n        Link(  # Re-trigger search result.\n            source_id=block_installation.id,\n            sink_id=input_query_constant.id,\n            source_name=\"error\",\n            sink_name=\"input\",\n        ),\n    ]\n\n    # ======= Graph ========= #\n    return Graph(\n        name=\"BlockAutoGen\",\n        description=\"Block auto generation agent\",\n        nodes=nodes,\n        links=links,\n    )", "blocks": [{"id": 1, "label": "def create_test_graph() -> Graph:\n    \"\"\"\n            StoreValueBlock (input)\n                 ||\n                 v\n        FillTextTemplateBlock (input query)\n                 ||\n                 v\n         SendWebRequestBlock (browse)\n                 ||\n                 v\n     ------> StoreValueBlock===============\n    |           |  |                    ||\n    |            --                     ||\n    |                                   ||\n    |                                   ||\n    |                                    v\n    |        AITextGeneratorBlock  <===== FillTextTemplateBlock (query)\n    |            ||                      ^\n    |            v                      ||\n    |       ExtractTextInformationBlock             ||\n    |            ||                                 ||\n    |            v                                  ||\n    ------ BlockInstallationBlock  ======\n    \"\"\"", "successors": [{"id": 3, "label": "    # ======= Nodes ========= #\n    input_data = Node(block_id=StoreValueBlock().id)", "successors": [{"id": 5, "label": "    input_query_constant = Node(\n        block_id=StoreValueBlock().id,\n        input_default={\"data\": None},\n    )\n    input_text_formatter = Node(\n        block_id=FillTextTemplateBlock().id,\n        input_default={\n            \"format\": \"Show me how to make a python code for this query: `{query}`\",\n        },\n    )", "successors": [{"id": 7, "label": "    search_http_request = Node(\n        block_id=SendWebRequestBlock().id,\n        input_default={\n            \"url\": \"https://osit-v2.bentlybro.com/search\",\n        },\n    )\n    search_result_constant = Node(\n        block_id=StoreValueBlock().id,\n        input_default={\n            \"data\": None,\n        },\n    )", "successors": [{"id": 9, "label": "    prompt_text_formatter = Node(\n        block_id=FillTextTemplateBlock().id,\n        input_default={\n            \"format\": \"\"\"\nWrite me a full Block implementation for this query: `{query}`\n\nHere is the information I get to write a Python code for that:\n{search_result}\n\nHere is your previous attempt:\n{previous_attempt}\n\"\"\",\n            \"values_#_previous_attempt\": \"No previous attempt found.\",\n        },\n    )\n    code_gen_llm_call = Node(\n        block_id=AITextGeneratorBlock().id,\n        input_default={\n            \"sys_prompt\": f\"\"\"\nYou are a software engineer and you are asked to write the full class implementation.\nThe class that you are implementing is extending a class called `Block`.\nThis class will be used as a node in a graph of other blocks to build a complex system.\nThis class has a method called `run` that takes an input and returns an output.\nIt also has an `id` attribute that is a UUID, input_schema, and output_schema.\nFor UUID, you have to hardcode it, like `d2e2ecd2-9ae6-422d-8dfe-ceca500ce6a6`,\ndon't use any automatic UUID generation, because it needs to be consistent.\nTo validate the correctness of your implementation, you can also define a test.\nThere is `test_input` and `test_output` you can use to validate your implementation.\nThere is also `test_mock` to mock a helper function on your block class for testing.\n\nFeel free to start your answer by explaining your plan what's required how to test, etc.\nBut make sure to produce the fully working implementation at the end,\nand it should be enclosed within this block format:\n```python\n<Your implementation here>\n```\n\nHere are a couple of sample of the Block class implementation:\n\n{\"--------------\".join([sample_block_codes[v] for v in sample_block_modules])}\n\"\"\",\n        },\n    )", "successors": [{"id": 11, "label": "    code_text_parser = Node(\n        block_id=ExtractTextInformationBlock().id,\n        input_default={\n            \"pattern\": \"```python\\n(.+?)\\n```\",\n            \"group\": 1,\n        },\n    )\n    block_installation = Node(\n        block_id=BlockInstallationBlock().id,\n    )", "successors": [{"id": 13, "label": "    nodes = [\n        input_data,\n        input_query_constant,\n        input_text_formatter,\n        search_http_request,\n        search_result_constant,\n        prompt_text_formatter,\n        code_gen_llm_call,\n        code_text_parser,\n        block_installation,\n    ]\n    # ======= Links ========= #", "successors": [{"id": 15, "label": "    links = [\n        Link(\n            source_id=input_data.id,\n            sink_id=input_query_constant.id,\n            source_name=\"output\",\n            sink_name=\"input\",\n        ),\n        Link(\n            source_id=input_data.id,\n            sink_id=input_text_formatter.id,\n            source_name=\"output\",\n            sink_name=\"values_#_query\",\n        ),\n        Link(\n            source_id=input_query_constant.id,\n            sink_id=input_query_constant.id,\n            source_name=\"output\",\n            sink_name=\"data\",\n        ),\n        Link(\n            source_id=input_text_formatter.id,\n            sink_id=search_http_request.id,\n            source_name=\"output\",\n            sink_name=\"body_#_query\",\n        ),\n        Link(\n            source_id=search_http_request.id,\n            sink_id=search_result_constant.id,\n            source_name=\"response_#_reply\",\n            sink_name=\"input\",\n        ),\n        Link(  # Loopback for constant block\n            source_id=search_result_constant.id,\n            sink_id=search_result_constant.id,\n            source_name=\"output\",\n            sink_name=\"data\",\n        ),\n        Link(\n            source_id=search_result_constant.id,\n            sink_id=prompt_text_formatter.id,\n            source_name=\"output\",\n            sink_name=\"values_#_search_result\",\n        ),\n        Link(\n            source_id=input_query_constant.id,\n            sink_id=prompt_text_formatter.id,\n            source_name=\"output\",\n            sink_name=\"values_#_query\",\n        ),\n        Link(\n            source_id=prompt_text_formatter.id,\n            sink_id=code_gen_llm_call.id,\n            source_name=\"output\",\n            sink_name=\"prompt\",\n        ),\n        Link(\n            source_id=code_gen_llm_call.id,\n            sink_id=code_text_parser.id,\n            source_name=\"response\",\n            sink_name=\"text\",\n        ),\n        Link(\n            source_id=code_text_parser.id,\n            sink_id=block_installation.id,\n            source_name=\"positive\",\n            sink_name=\"code\",\n        ),\n        Link(\n            source_id=block_installation.id,\n            sink_id=prompt_text_formatter.id,\n            source_name=\"error\",\n            sink_name=\"values_#_previous_attempt\",\n        ),\n        Link(  # Re-trigger search result.\n            source_id=block_installation.id,\n            sink_id=search_result_constant.id,\n            source_name=\"error\",\n            sink_name=\"input\",\n        ),\n        Link(  # Re-trigger search result.\n            source_id=block_installation.id,\n            sink_id=input_query_constant.id,\n            source_name=\"error\",\n            sink_name=\"input\",\n        ),\n    ]\n    # ======= Graph ========= #", "successors": [{"id": 17, "label": "    return Graph(\n        name=\"BlockAutoGen\",\n        description=\"Block auto generation agent\",\n        nodes=nodes,\n        links=links,\n    )", "successors": []}]}]}]}]}]}]}]}]}]}, {"name": "block_autogen_agent", "type": "function", "start_line": 250, "end_line": 265, "functions": [], "classes": [], "simplified_code": "async def block_autogen_agent():\n    async with SpinTestServer() as server:\n        test_user = await create_test_user()\n        test_graph = await create_graph(create_test_graph(), user_id=test_user.id)\n        input_data = {\"input\": \"Write me a block that writes a string into a file.\"}\n        response = await server.agent_server.test_execute_graph(\n            test_graph.id, input_data, test_user.id\n        )\n        print(response)\n        result = await wait_execution(\n            graph_id=test_graph.id,\n            graph_exec_id=response[\"id\"],\n            timeout=1200,\n            user_id=test_user.id,\n        )\n        print(result)", "blocks": [{"id": 1, "label": "async def block_autogen_agent():\nasync with SpinTestServer() as server:", "successors": [{"id": 3, "label": "test_user = await create_test_user()\ntest_graph = await create_graph(create_test_graph(), user_id=test_user.id)\ninput_data = {\"input\": \"Write me a block that writes a string into a file.\"}\nresponse = await server.agent_server.test_execute_graph(\n    test_graph.id, input_data, test_user.id\n)\nprint(response)\nresult = await wait_execution(\n    graph_id=test_graph.id,\n    graph_exec_id=response[\"id\"],\n    timeout=1200,\n    user_id=test_user.id,\n)\nprint(result)", "successors": []}]}]}], "classes": [], "simplified_code": "from pathlib import Path\n\nfrom prisma.models import User\n\nfrom backend.blocks.basic import StoreValueBlock\nfrom backend.blocks.block import BlockInstallationBlock\nfrom backend.blocks.http import SendWebRequestBlock\nfrom backend.blocks.llm import AITextGeneratorBlock\nfrom backend.blocks.text import ExtractTextInformationBlock, FillTextTemplateBlock\nfrom backend.data.graph import Graph, Link, Node, create_graph\nfrom backend.data.user import get_or_create_user\nfrom backend.util.test import SpinTestServer, wait_execution\n\nsample_block_modules = {\n    \"llm\": \"Block that calls the AI model to generate text.\",\n    \"basic\": \"Block that does basic operations.\",\n    \"text\": \"Blocks that do text operations.\",\n    \"reddit\": \"Blocks that interacts with Reddit.\",\n}\nsample_block_codes = {}\nfor module, description in sample_block_modules.items():\n    current_dir = Path(__file__).parent\n    file_path = current_dir.parent / \"blocks\" / f\"{module}.py\"\n    with open(file_path, \"r\") as f:\n        code = \"\\n\".join([\"```python\", f.read(), \"```\"])\n        sample_block_codes[module] = f\"[Example: {description}]\\n{code}\"\n\n\n    return user\n\n\n    )\n\n\n        print(result)\n\n\nif __name__ == \"__main__\":\n    import asyncio\n\n    asyncio.run(block_autogen_agent())", "blocks": [{"id": 1, "label": "from pathlib import Path\n\nfrom prisma.models import User\n\nfrom backend.blocks.basic import StoreValueBlock\nfrom backend.blocks.block import BlockInstallationBlock\nfrom backend.blocks.http import SendWebRequestBlock\nfrom backend.blocks.llm import AITextGeneratorBlock\nfrom backend.blocks.text import ExtractTextInformationBlock, FillTextTemplateBlock\nfrom backend.data.graph import Graph, Link, Node, create_graph\nfrom backend.data.user import get_or_create_user\nfrom backend.util.test import SpinTestServer, wait_execution", "successors": [{"id": 2, "label": "sample_block_modules = {\n    \"llm\": \"Block that calls the AI model to generate text.\",\n    \"basic\": \"Block that does basic operations.\",\n    \"text\": \"Blocks that do text operations.\",\n    \"reddit\": \"Blocks that interacts with Reddit.\",\n}\nsample_block_codes = {}", "successors": [{"id": 3, "label": "for module, description in sample_block_modules.items():", "successors": [{"id": 4, "label": "current_dir = Path(__file__).parent\nfile_path = current_dir.parent / \"blocks\" / f\"{module}.py\"\nwith open(file_path, \"r\") as f:\n    code = \"\\n\".join([\"```python\", f.read(), \"```\"])\n    sample_block_codes[module] = f\"[Example: {description}]\\n{code}\"", "successors": []}]}, {"id": 5, "label": "\nreturn user", "successors": []}, {"id": 6, "label": "\nprint(result)", "successors": []}]}, {"id": 7, "label": "\n\nif __name__ == \"__main__\":\nimport asyncio\n\nasyncio.run(block_autogen_agent())", "successors": []}]}]}
{"file_name": "64.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 93, "functions": [{"name": "generate_all_subsequences", "type": "function", "start_line": 14, "end_line": 15, "functions": [], "classes": [], "simplified_code": "def generate_all_subsequences(sequence: list[Any]) -> None:\n    create_state_space_tree(sequence, [], 0)", "blocks": [{"id": 1, "label": "def generate_all_subsequences(sequence: list[Any]) -> None:\n    create_state_space_tree(sequence, [], 0)", "successors": []}]}, {"name": "create_state_space_tree", "type": "function", "start_line": 18, "end_line": 84, "functions": [], "classes": [], "simplified_code": "def create_state_space_tree(\n    sequence: list[Any], current_subsequence: list[Any], index: int\n) -> None:\n    \"\"\"\n    Creates a state space tree to iterate through each branch using DFS.\n    We know that each state has exactly two children.\n    It terminates when it reaches the end of the given sequence.\n\n    :param sequence: The input sequence for which subsequences are generated.\n    :param current_subsequence: The current subsequence being built.\n    :param index: The current index in the sequence.\n\n    Example:\n    >>> sequence = [3, 2, 1]\n    >>> current_subsequence = []\n    >>> create_state_space_tree(sequence, current_subsequence, 0)\n    []\n    [1]\n    [2]\n    [2, 1]\n    [3]\n    [3, 1]\n    [3, 2]\n    [3, 2, 1]\n\n    >>> sequence = [\"A\", \"B\"]\n    >>> current_subsequence = []\n    >>> create_state_space_tree(sequence, current_subsequence, 0)\n    []\n    ['B']\n    ['A']\n    ['A', 'B']\n\n    >>> sequence = []\n    >>> current_subsequence = []\n    >>> create_state_space_tree(sequence, current_subsequence, 0)\n    []\n\n    >>> sequence = [1, 2, 3, 4]\n    >>> current_subsequence = []\n    >>> create_state_space_tree(sequence, current_subsequence, 0)\n    []\n    [4]\n    [3]\n    [3, 4]\n    [2]\n    [2, 4]\n    [2, 3]\n    [2, 3, 4]\n    [1]\n    [1, 4]\n    [1, 3]\n    [1, 3, 4]\n    [1, 2]\n    [1, 2, 4]\n    [1, 2, 3]\n    [1, 2, 3, 4]\n    \"\"\"\n\n    if index == len(sequence):\n        print(current_subsequence)\n        return\n\n    create_state_space_tree(sequence, current_subsequence, index + 1)\n    current_subsequence.append(sequence[index])\n    create_state_space_tree(sequence, current_subsequence, index + 1)\n    current_subsequence.pop()", "blocks": [{"id": 1, "label": "if index == len(sequence):", "successors": [{"id": 2, "label": "    print(current_subsequence)\n    return", "successors": []}, {"id": 3, "label": "create_state_space_tree(sequence, current_subsequence, index + 1)\ncurrent_subsequence.append(sequence[index])\ncreate_state_space_tree(sequence, current_subsequence, index + 1)\ncurrent_subsequence.pop()", "successors": []}]}]}], "classes": [], "simplified_code": "\"\"\"\nIn this problem, we want to determine all possible subsequences\nof the given sequence. We use backtracking to solve this problem.\n\nTime complexity: O(2^n),\nwhere n denotes the length of the given sequence.\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import Any\n\n\n    create_state_space_tree(sequence, [], 0)\n\n\n    current_subsequence.pop()\n\n\nif __name__ == \"__main__\":\n    seq: list[Any] = [1, 2, 3]\n    generate_all_subsequences(seq)\n\n    seq.clear()\n    seq.extend([\"A\", \"B\", \"C\"])\n    generate_all_subsequences(seq)", "blocks": [{"id": 1, "label": "if __name__ == \"__main__\":\n    seq: list[Any] = [1, 2, 3]\n    generate_all_subsequences(seq)\n\n    seq.clear()\n    seq.extend([\"A\", \"B\", \"C\"])\n    generate_all_subsequences(seq)", "successors": []}]}
{"file_name": "65.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 91, "functions": [{"name": "backtrack", "type": "function", "start_line": 10, "end_line": 51, "functions": [], "classes": [], "simplified_code": "def backtrack(\n    needed_sum: int,\n    power: int,\n    current_number: int,\n    current_sum: int,\n    solutions_count: int,\n) -> tuple[int, int]:\n    \"\"\"\n    >>> backtrack(13, 2, 1, 0, 0)\n    (0, 1)\n    >>> backtrack(10, 2, 1, 0, 0)\n    (0, 1)\n    >>> backtrack(10, 3, 1, 0, 0)\n    (0, 0)\n    >>> backtrack(20, 2, 1, 0, 0)\n    (0, 1)\n    >>> backtrack(15, 10, 1, 0, 0)\n    (0, 0)\n    >>> backtrack(16, 2, 1, 0, 0)\n    (0, 1)\n    >>> backtrack(20, 1, 1, 0, 0)\n    (0, 64)\n    \"\"\"\n    if current_sum == needed_sum:\n        # If the sum of the powers is equal to needed_sum, then we have a solution.\n        solutions_count += 1\n        return current_sum, solutions_count\n\n    i_to_n = current_number**power\n    if current_sum + i_to_n <= needed_sum:\n        # If the sum of the powers is less than needed_sum, then continue adding powers.\n        current_sum += i_to_n\n        current_sum, solutions_count = backtrack(\n            needed_sum, power, current_number + 1, current_sum, solutions_count\n        )\n        current_sum -= i_to_n\n    if i_to_n < needed_sum:\n        # If the power of i is less than needed_sum, then try with the next power.\n        current_sum, solutions_count = backtrack(\n            needed_sum, power, current_number + 1, current_sum, solutions_count\n        )\n    return current_sum, solutions_count", "blocks": [{"id": 1, "label": "def backtrack(needed_sum: int, power: int, current_number: int, current_sum: int, solutions_count: int) -> tuple[int, int]:", "successors": [{"id": 2, "label": "if current_sum == needed_sum:\n    solutions_count += 1\n    return current_sum, solutions_count", "successors": []}, {"id": 4, "label": "i_to_n = current_number**power", "successors": [{"id": 5, "label": "if current_sum + i_to_n <= needed_sum:\n    current_sum += i_to_n\n    current_sum, solutions_count = backtrack(needed_sum, power, current_number + 1, current_sum, solutions_count)\n    current_sum -= i_to_n", "successors": []}, {"id": 7, "label": "if i_to_n < needed_sum:\n    current_sum, solutions_count = backtrack(needed_sum, power, current_number + 1, current_sum, solutions_count)", "successors": []}]}, {"id": 9, "label": "return current_sum, solutions_count", "successors": []}]}]}, {"name": "solve", "type": "function", "start_line": 54, "end_line": 85, "functions": [], "classes": [], "simplified_code": "def solve(needed_sum: int, power: int) -> int:\n    \"\"\"\n    >>> solve(13, 2)\n    1\n    >>> solve(10, 2)\n    1\n    >>> solve(10, 3)\n    0\n    >>> solve(20, 2)\n    1\n    >>> solve(15, 10)\n    0\n    >>> solve(16, 2)\n    1\n    >>> solve(20, 1)\n    Traceback (most recent call last):\n        ...\n    ValueError: Invalid input\n    needed_sum must be between 1 and 1000, power between 2 and 10.\n    >>> solve(-10, 5)\n    Traceback (most recent call last):\n        ...\n    ValueError: Invalid input\n    needed_sum must be between 1 and 1000, power between 2 and 10.\n    \"\"\"\n    if not (1 <= needed_sum <= 1000 and 2 <= power <= 10):\n        raise ValueError(\n            \"Invalid input\\n\"\n            \"needed_sum must be between 1 and 1000, power between 2 and 10.\"\n        )\n\n    return backtrack(needed_sum, power, 1, 0, 0)[1]  # Return the solutions_count", "blocks": [{"id": 1, "label": "def solve(needed_sum: int, power: int) -> int:", "successors": [{"id": 2, "label": "if not (1 <= needed_sum <= 1000 and 2 <= power <= 10):\nraise ValueError(\n    \"Invalid input\\n\"\n    \"needed_sum must be between 1 and 1000, power between 2 and 10.\"\n)", "successors": []}, {"id": 4, "label": "return backtrack(needed_sum, power, 1, 0, 0)[1]  # Return the solutions_count", "successors": []}]}]}], "classes": [], "simplified_code": "\"\"\"\nProblem source: https://www.hackerrank.com/challenges/the-power-sum/problem\nFind the number of ways that a given integer X, can be expressed as the sum\nof the Nth powers of unique, natural numbers. For example, if X=13 and N=2.\nWe have to find all combinations of unique squares adding up to 13.\nThe only solution is 2^2+3^2. Constraints: 1<=X<=1000, 2<=N<=10.\n\"\"\"\n\n\n    return current_sum, solutions_count\n\n\n    return backtrack(needed_sum, power, 1, 0, 0)[1]  # Return the solutions_count\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()", "blocks": [{"id": 1, "label": "# Example input code\n\"\"\"\nProblem source: https://www.hackerrank.com/challenges/the-power-sum/problem\nFind the number of ways that a given integer X, can be expressed as the sum\nof the Nth powers of unique, natural numbers. For example, if X=13 and N=2.\nWe have to find all combinations of unique squares adding up to 13.\nThe only solution is 2^2+3^2. Constraints: 1<=X<=1000, 2<=N<=10.\n\"\"\"", "successors": [{"id": 2, "label": "return current_sum, solutions_count", "successors": []}, {"id": 3, "label": "return backtrack(needed_sum, power, 1, 0, 0)[1]  # Return the solutions_count", "successors": []}, {"id": 4, "label": "if __name__ == \"__main__\":\nimport doctest", "successors": [{"id": 6, "label": "doctest.testmod()", "successors": []}]}]}]}
{"file_name": "66.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 123, "functions": [{"name": "get_service_name", "type": "function", "start_line": 16, "end_line": 17, "functions": [], "classes": [], "simplified_code": "def get_service_name():\n    return _SERVICE_NAME", "blocks": [{"id": 1, "label": "def get_service_name():\nreturn _SERVICE_NAME", "successors": []}]}, {"name": "set_service_name", "type": "function", "start_line": 20, "end_line": 22, "functions": [], "classes": [], "simplified_code": "def set_service_name(name: str):\n    global _SERVICE_NAME\n    _SERVICE_NAME = name", "blocks": [{"id": 1, "label": "def set_service_name(name: str):\nglobal _SERVICE_NAME\n_SERVICE_NAME = name", "successors": []}]}], "classes": [{"name": "AppProcess", "type": "class", "start_line": 25, "end_line": 123, "functions": [{"name": "run", "type": "function", "start_line": 39, "end_line": 43, "functions": [], "classes": [], "simplified_code": "    def run(self):\n        \"\"\"\n        The method that will be executed in the process.\n        \"\"\"\n        pass", "blocks": [{"id": 1, "label": "def run(self):\n\"\"\"\nThe method that will be executed in the process.\n\"\"\"", "successors": [{"id": 3, "label": "pass", "successors": []}]}]}, {"name": "service_name", "type": "function", "start_line": 47, "end_line": 48, "functions": [], "classes": [], "simplified_code": "    def service_name(cls) -> str:\n        return cls.__name__", "blocks": [{"id": 1, "label": "def service_name(cls) -> str:\n    return cls.__name__", "successors": []}]}, {"name": "cleanup", "type": "function", "start_line": 50, "end_line": 55, "functions": [], "classes": [], "simplified_code": "    def cleanup(self):\n        \"\"\"\n        Implement this method on a subclass to do post-execution cleanup,\n        e.g. disconnecting from a database or terminating child processes.\n        \"\"\"\n        pass", "blocks": [{"id": 1, "label": "def cleanup(self):\n\"\"\"\nImplement this method on a subclass to do post-execution cleanup,\ne.g. disconnecting from a database or terminating child processes.\n\"\"\"", "successors": [{"id": 3, "label": "pass", "successors": []}]}]}, {"name": "health_check", "type": "function", "start_line": 57, "end_line": 61, "functions": [], "classes": [], "simplified_code": "    def health_check(self):\n        \"\"\"\n        A method to check the health of the process.\n        \"\"\"\n        pass", "blocks": [{"id": 1, "label": "def health_check(self):\n\"\"\"\n        A method to check the health of the process.\n        \"\"\"", "successors": [{"id": 3, "label": "pass", "successors": []}]}]}, {"name": "execute_run_command", "type": "function", "start_line": 63, "end_line": 75, "functions": [], "classes": [], "simplified_code": "    def execute_run_command(self, silent):\n        signal.signal(signal.SIGTERM, self._self_terminate)\n\n        try:\n            if silent:\n                sys.stdout = open(os.devnull, \"w\")\n                sys.stderr = open(os.devnull, \"w\")\n\n            set_service_name(self.service_name)\n            logger.info(f\"[{self.service_name}] Starting...\")\n            self.run()\n        except (KeyboardInterrupt, SystemExit) as e:\n            logger.warning(f\"[{self.service_name}] Terminated: {e}; quitting...\")", "blocks": [{"id": 1, "label": "def execute_run_command(self, silent):\n    signal.signal(signal.SIGTERM, self._self_terminate)\n", "successors": [{"id": 2, "label": "try:\nif silent:", "successors": [{"id": 4, "label": "sys.stdout = open(os.devnull, \"w\")\n    sys.stderr = open(os.devnull, \"w\")\n\nset_service_name(self.service_name)\nlogger.info(f\"[{self.service_name}] Starting...\")\nself.run()\n", "successors": []}, {"id": 6, "label": "set_service_name(self.service_name)\nlogger.info(f\"[{self.service_name}] Starting...\")\nself.run()\n", "successors": []}]}, {"id": 7, "label": "except (KeyboardInterrupt, SystemExit) as e:\n    logger.warning(f\"[{self.service_name}] Terminated: {e}; quitting...\")\n", "successors": []}]}]}, {"name": "_self_terminate", "type": "function", "start_line": 77, "end_line": 79, "functions": [], "classes": [], "simplified_code": "    def _self_terminate(self, signum: int, frame):\n        self.cleanup()\n        sys.exit(0)", "blocks": [{"id": 1, "label": "def _self_terminate(self, signum: int, frame):\n    self.cleanup()", "successors": [{"id": 3, "label": "    sys.exit(0)", "successors": []}]}]}, {"name": "__enter__", "type": "function", "start_line": 83, "end_line": 85, "functions": [], "classes": [], "simplified_code": "    def __enter__(self):\n        self.start(background=True)\n        return self", "blocks": [{"id": 1, "label": "def __enter__(self):\n    self.start(background=True)", "successors": [{"id": 3, "label": "    return self", "successors": []}]}]}, {"name": "__exit__", "type": "function", "start_line": 87, "end_line": 88, "functions": [], "classes": [], "simplified_code": "    def __exit__(self, *args, **kwargs):\n        self.stop()", "blocks": [{"id": 1, "label": "def __exit__(self, *args, **kwargs):\n    self.stop()", "successors": []}]}, {"name": "start", "type": "function", "start_line": 90, "end_line": 112, "functions": [], "classes": [], "simplified_code": "    def start(self, background: bool = False, silent: bool = False, **proc_args) -> int:\n        \"\"\"\n        Start the background process.\n        Args:\n            background: Whether to run the process in the background.\n            silent: Whether to disable stdout and stderr.\n            proc_args: Additional arguments to pass to the process.\n        Returns:\n            the process id or 0 if the process is not running in the background.\n        \"\"\"\n        if not background:\n            self.execute_run_command(silent)\n            return 0\n\n        self.process = Process(\n            name=self.__class__.__name__,\n            target=self.execute_run_command,\n            args=(silent,),\n            **proc_args,\n        )\n        self.process.start()\n        self.health_check()\n        return self.process.pid or 0", "blocks": [{"id": 1, "label": "def start(self, background: bool = False, silent: bool = False, **proc_args) -> int:\nif not background:", "successors": [{"id": 3, "label": "self.execute_run_command(silent)\nreturn 0", "successors": []}, {"id": 4, "label": "self.process = Process(name=self.__class__.__name__, target=self.execute_run_command, args=(silent,), **proc_args)\nself.process.start()\nself.health_check()\nreturn self.process.pid or 0", "successors": []}]}]}, {"name": "stop", "type": "function", "start_line": 114, "end_line": 123, "functions": [], "classes": [], "simplified_code": "    def stop(self):\n        \"\"\"\n        Stop the background process.\n        \"\"\"\n        if not self.process:\n            return\n\n        self.process.terminate()\n        self.process.join()\n        self.process = None", "blocks": [{"id": 1, "label": "def stop(self):", "successors": [{"id": 2, "label": "if not self.process:\nreturn", "successors": []}, {"id": 4, "label": "self.process.terminate()\nself.process.join()", "successors": [{"id": 6, "label": "self.process = None", "successors": []}]}]}]}], "classes": [], "simplified_code": "class AppProcess(ABC):\n    \"\"\"\n    A class to represent an object that can be executed in a background process.\n    \"\"\"\n\n    process: Optional[Process] = None\n\n    set_start_method(\"spawn\", force=True)\n    configure_logging()\n    sentry_init()\n\n    # Methods that are executed INSIDE the process #\n\n    @abstractmethod\n        pass\n\n    @classmethod\n    @property\n        return cls.__name__\n\n        pass\n\n        pass\n\n            logger.warning(f\"[{self.service_name}] Terminated: {e}; quitting...\")\n\n        sys.exit(0)\n\n    # Methods that are executed OUTSIDE the process #\n\n        return self\n\n        self.stop()\n\n        return self.process.pid or 0\n\n        self.process = None", "blocks": [{"id": 1, "label": "class AppProcess(ABC):\n\"\"\"\n    A class to represent an object that can be executed in a background process.\n    \"\"\"", "successors": [{"id": 3, "label": "process: Optional[Process] = None\nset_start_method(\"spawn\", force=True)", "successors": [{"id": 5, "label": "configure_logging()\nsentry_init()", "successors": [{"id": 7, "label": "@abstractmethod\npass\n@classmethod\n@property\nreturn cls.__name__", "successors": [{"id": 9, "label": "pass\npass", "successors": [{"id": 11, "label": "logger.warning(f\"[{self.service_name}] Terminated: {e}; quitting...\")\nsys.exit(0)", "successors": [{"id": 13, "label": "return self\nself.stop()", "successors": [{"id": 15, "label": "return self.process.pid or 0\nself.process = None", "successors": []}]}]}]}]}]}]}]}]}], "simplified_code": "import logging\nimport os\nimport signal\nimport sys\nfrom abc import ABC, abstractmethod\nfrom multiprocessing import Process, set_start_method\nfrom typing import Optional\n\nfrom backend.util.logging import configure_logging\nfrom backend.util.metrics import sentry_init\n\nlogger = logging.getLogger(__name__)\n_SERVICE_NAME = \"MainProcess\"\n\n\n    return _SERVICE_NAME\n\n\n    _SERVICE_NAME = name\n\n\n        self.process = None", "blocks": [{"id": 1, "label": "import logging\nimport os\nimport signal\nimport sys\nfrom abc import ABC, abstractmethod\nfrom multiprocessing import Process, set_start_method\nfrom typing import Optional\n\nfrom backend.util.logging import configure_logging\nfrom backend.util.metrics import sentry_init\n\nlogger = logging.getLogger(__name__)\n_SERVICE_NAME = \"MainProcess\"", "successors": [{"id": 2, "label": "return _SERVICE_NAME", "successors": []}, {"id": 3, "label": "_SERVICE_NAME = name", "successors": []}, {"id": 4, "label": "self.process = None", "successors": []}]}]}
{"file_name": "67.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 244, "functions": [{"name": "on_graph_activate", "type": "function", "start_line": 18, "end_line": 48, "functions": [], "classes": [], "simplified_code": "async def on_graph_activate(\n    graph: \"GraphModel\", get_credentials: Callable[[str], \"Credentials | None\"]\n):\n    \"\"\"\n    Hook to be called when a graph is activated/created.\n\n    \u26a0\ufe0f Assuming node entities are not re-used between graph versions, \u26a0\ufe0f\n    this hook calls `on_node_activate` on all nodes in this graph.\n\n    Params:\n        get_credentials: `credentials_id` -> Credentials\n    \"\"\"\n    # Compare nodes in new_graph_version with previous_graph_version\n    updated_nodes = []\n    for new_node in graph.nodes:\n        node_credentials = None\n        if creds_meta := new_node.input_default.get(CREDENTIALS_FIELD_NAME):\n            node_credentials = get_credentials(creds_meta[\"id\"])\n            if not node_credentials:\n                raise ValueError(\n                    f\"Node #{new_node.id} updated with non-existent \"\n                    f\"credentials #{node_credentials}\"\n                )\n\n        updated_node = await on_node_activate(\n            graph.user_id, new_node, credentials=node_credentials\n        )\n        updated_nodes.append(updated_node)\n\n    graph.nodes = updated_nodes\n    return graph", "blocks": [{"id": 1, "label": "async def on_graph_activate(graph: \"GraphModel\", get_credentials: Callable[[str], \"Credentials | None\"]):\nupdated_nodes = []", "successors": [{"id": 3, "label": "for new_node in graph.nodes:", "successors": [{"id": 4, "label": "node_credentials = None", "successors": [{"id": 5, "label": "if creds_meta := new_node.input_default.get(CREDENTIALS_FIELD_NAME):\nnode_credentials = get_credentials(creds_meta[\"id\"])", "successors": [{"id": 7, "label": "if not node_credentials:\nraise ValueError(f\"Node #{new_node.id} updated with non-existent \" f\"credentials #{node_credentials}\")", "successors": []}]}, {"id": 9, "label": "updated_node = await on_node_activate(graph.user_id, new_node, credentials=node_credentials)\nupdated_nodes.append(updated_node)", "successors": [{"id": 11, "label": "graph.nodes = updated_nodes\nreturn graph", "successors": []}]}]}]}]}]}, {"name": "on_graph_deactivate", "type": "function", "start_line": 51, "end_line": 78, "functions": [], "classes": [], "simplified_code": "async def on_graph_deactivate(\n    graph: \"GraphModel\", get_credentials: Callable[[str], \"Credentials | None\"]\n):\n    \"\"\"\n    Hook to be called when a graph is deactivated/deleted.\n\n    \u26a0\ufe0f Assuming node entities are not re-used between graph versions, \u26a0\ufe0f\n    this hook calls `on_node_deactivate` on all nodes in `graph`.\n\n    Params:\n        get_credentials: `credentials_id` -> Credentials\n    \"\"\"\n    updated_nodes = []\n    for node in graph.nodes:\n        node_credentials = None\n        if creds_meta := node.input_default.get(CREDENTIALS_FIELD_NAME):\n            node_credentials = get_credentials(creds_meta[\"id\"])\n            if not node_credentials:\n                logger.error(\n                    f\"Node #{node.id} referenced non-existent \"\n                    f\"credentials #{creds_meta['id']}\"\n                )\n\n        updated_node = await on_node_deactivate(node, credentials=node_credentials)\n        updated_nodes.append(updated_node)\n\n    graph.nodes = updated_nodes\n    return graph", "blocks": [{"id": 1, "label": "async def on_graph_deactivate(graph: \"GraphModel\", get_credentials: Callable[[str], \"Credentials | None\"]):\nupdated_nodes = []", "successors": [{"id": 3, "label": "for node in graph.nodes:", "successors": [{"id": 4, "label": "node_credentials = None", "successors": [{"id": 5, "label": "if creds_meta := node.input_default.get(CREDENTIALS_FIELD_NAME):\nnode_credentials = get_credentials(creds_meta[\"id\"])", "successors": [{"id": 7, "label": "if not node_credentials:\nlogger.error(f\"Node #{node.id} referenced non-existent \" f\"credentials #{creds_meta['id']}\")", "successors": []}]}, {"id": 9, "label": "updated_node = await on_node_deactivate(node, credentials=node_credentials)\nupdated_nodes.append(updated_node)", "successors": []}]}, {"id": 11, "label": "graph.nodes = updated_nodes\nreturn graph", "successors": []}]}]}]}, {"name": "on_node_activate", "type": "function", "start_line": 81, "end_line": 185, "functions": [], "classes": [], "simplified_code": "async def on_node_activate(\n    user_id: str,\n    node: \"NodeModel\",\n    *,\n    credentials: Optional[\"Credentials\"] = None,\n) -> \"NodeModel\":\n    \"\"\"Hook to be called when the node is activated/created\"\"\"\n\n    block = get_block(node.block_id)\n    if not block:\n        raise ValueError(\n            f\"Node #{node.id} is instance of unknown block #{node.block_id}\"\n        )\n\n    if not block.webhook_config:\n        return node\n\n    provider = block.webhook_config.provider\n    if provider not in WEBHOOK_MANAGERS_BY_NAME:\n        raise ValueError(\n            f\"Block #{block.id} has webhook_config for provider {provider} \"\n            \"which does not support webhooks\"\n        )\n\n    logger.debug(\n        f\"Activating webhook node #{node.id} with config {block.webhook_config}\"\n    )\n\n    webhooks_manager = WEBHOOK_MANAGERS_BY_NAME[provider]()\n\n    if auto_setup_webhook := isinstance(block.webhook_config, BlockWebhookConfig):\n        try:\n            resource = block.webhook_config.resource_format.format(**node.input_default)\n        except KeyError:\n            resource = None\n        logger.debug(\n            f\"Constructed resource string {resource} from input {node.input_default}\"\n        )\n    else:\n        resource = \"\"  # not relevant for manual webhooks\n\n    needs_credentials = CREDENTIALS_FIELD_NAME in block.input_schema.model_fields\n    credentials_meta = (\n        node.input_default.get(CREDENTIALS_FIELD_NAME) if needs_credentials else None\n    )\n    event_filter_input_name = block.webhook_config.event_filter_input\n    has_everything_for_webhook = (\n        resource is not None\n        and (credentials_meta or not needs_credentials)\n        and (\n            not event_filter_input_name\n            or (\n                event_filter_input_name in node.input_default\n                and any(\n                    is_on\n                    for is_on in node.input_default[event_filter_input_name].values()\n                )\n            )\n        )\n    )\n\n    if has_everything_for_webhook and resource is not None:\n        logger.debug(f\"Node #{node} has everything for a webhook!\")\n        if credentials_meta and not credentials:\n            raise ValueError(\n                f\"Cannot set up webhook for node #{node.id}: \"\n                f\"credentials #{credentials_meta['id']} not available\"\n            )\n\n        if event_filter_input_name:\n            # Shape of the event filter is enforced in Block.__init__\n            event_filter = cast(dict, node.input_default[event_filter_input_name])\n            events = [\n                block.webhook_config.event_format.format(event=event)\n                for event, enabled in event_filter.items()\n                if enabled is True\n            ]\n            logger.debug(f\"Webhook events to subscribe to: {', '.join(events)}\")\n        else:\n            events = []\n\n        # Find/make and attach a suitable webhook to the node\n        if auto_setup_webhook:\n            assert credentials is not None\n            new_webhook = await webhooks_manager.get_suitable_auto_webhook(\n                user_id,\n                credentials,\n                block.webhook_config.webhook_type,\n                resource,\n                events,\n            )\n        else:\n            # Manual webhook -> no credentials -> don't register but do create\n            new_webhook = await webhooks_manager.get_manual_webhook(\n                user_id,\n                node.graph_id,\n                block.webhook_config.webhook_type,\n                events,\n            )\n        logger.debug(f\"Acquired webhook: {new_webhook}\")\n        return await set_node_webhook(node.id, new_webhook.id)\n    else:\n        logger.debug(f\"Node #{node.id} does not have everything for a webhook\")\n\n    return node", "blocks": [{"id": 1, "label": "block = get_block(node.block_id)", "successors": [{"id": 2, "label": "if not block:\nraise ValueError(f\"Node #{node.id} is instance of unknown block #{node.block_id}\")", "successors": []}, {"id": 4, "label": "if not block.webhook_config:\nreturn node", "successors": []}, {"id": 6, "label": "provider = block.webhook_config.provider", "successors": [{"id": 7, "label": "if provider not in WEBHOOK_MANAGERS_BY_NAME:\nraise ValueError(f\"Block #{block.id} has webhook_config for provider {provider} which does not support webhooks\")", "successors": []}, {"id": 9, "label": "logger.debug(f\"Activating webhook node #{node.id} with config {block.webhook_config}\")\nwebhooks_manager = WEBHOOK_MANAGERS_BY_NAME[provider]()", "successors": [{"id": 11, "label": "if auto_setup_webhook := isinstance(block.webhook_config, BlockWebhookConfig):", "successors": [{"id": 12, "label": "try:\n    resource = block.webhook_config.resource_format.format(**node.input_default)\nexcept KeyError:\n    resource = None", "successors": []}, {"id": 14, "label": "logger.debug(f\"Constructed resource string {resource} from input {node.input_default}\")", "successors": []}]}, {"id": 15, "label": "else:\n    resource = \"\"", "successors": []}, {"id": 16, "label": "needs_credentials = CREDENTIALS_FIELD_NAME in block.input_schema.model_fields\ncredentials_meta = node.input_default.get(CREDENTIALS_FIELD_NAME) if needs_credentials else None", "successors": [{"id": 18, "label": "event_filter_input_name = block.webhook_config.event_filter_input\nhas_everything_for_webhook = (resource is not None and (credentials_meta or not needs_credentials) and (not event_filter_input_name or (event_filter_input_name in node.input_default and any(is_on for is_on in node.input_default[event_filter_input_name].values()))))", "successors": [{"id": 20, "label": "if has_everything_for_webhook and resource is not None:\nlogger.debug(f\"Node #{node} has everything for a webhook!\")", "successors": [{"id": 22, "label": "if credentials_meta and not credentials:\nraise ValueError(f\"Cannot set up webhook for node #{node.id}: credentials #{credentials_meta['id']} not available\")", "successors": []}, {"id": 24, "label": "if event_filter_input_name:\nevent_filter = cast(dict, node.input_default[event_filter_input_name])\nevents = [block.webhook_config.event_format.format(event=event) for event, enabled in event_filter.items() if enabled is True]\nlogger.debug(f\"Webhook events to subscribe to: {', '.join(events)}\")", "successors": []}, {"id": 26, "label": "else:\n    events = []", "successors": []}, {"id": 27, "label": "if auto_setup_webhook:\nnew_webhook = await webhooks_manager.get_suitable_auto_webhook(user_id, credentials, block.webhook_config.webhook_type, resource, events)", "successors": []}, {"id": 29, "label": "else:\n    new_webhook = await webhooks_manager.get_manual_webhook(user_id, node.graph_id, block.webhook_config.webhook_type, events)", "successors": []}, {"id": 30, "label": "logger.debug(f\"Acquired webhook: {new_webhook}\")\nreturn await set_node_webhook(node.id, new_webhook.id)", "successors": []}]}, {"id": 31, "label": "else:\n    logger.debug(f\"Node #{node.id} does not have everything for a webhook\")", "successors": []}]}]}]}]}, {"id": 32, "label": "return node", "successors": []}]}]}, {"name": "on_node_deactivate", "type": "function", "start_line": 188, "end_line": 244, "functions": [], "classes": [], "simplified_code": "async def on_node_deactivate(\n    node: \"NodeModel\",\n    *,\n    credentials: Optional[\"Credentials\"] = None,\n    webhooks_manager: Optional[\"BaseWebhooksManager\"] = None,\n) -> \"NodeModel\":\n    \"\"\"Hook to be called when node is deactivated/deleted\"\"\"\n\n    logger.debug(f\"Deactivating node #{node.id}\")\n    block = get_block(node.block_id)\n    if not block:\n        raise ValueError(\n            f\"Node #{node.id} is instance of unknown block #{node.block_id}\"\n        )\n\n    if not block.webhook_config:\n        return node\n\n    provider = block.webhook_config.provider\n    if provider not in WEBHOOK_MANAGERS_BY_NAME:\n        raise ValueError(\n            f\"Block #{block.id} has webhook_config for provider {provider} \"\n            \"which does not support webhooks\"\n        )\n\n    webhooks_manager = WEBHOOK_MANAGERS_BY_NAME[provider]()\n\n    if node.webhook_id:\n        logger.debug(f\"Node #{node.id} has webhook_id {node.webhook_id}\")\n        if not node.webhook:\n            logger.error(f\"Node #{node.id} has webhook_id but no webhook object\")\n            raise ValueError(\"node.webhook not included\")\n\n        # Detach webhook from node\n        logger.debug(f\"Detaching webhook from node #{node.id}\")\n        updated_node = await set_node_webhook(node.id, None)\n\n        # Prune and deregister the webhook if it is no longer used anywhere\n        webhook = node.webhook\n        logger.debug(\n            f\"Pruning{' and deregistering' if credentials else ''} \"\n            f\"webhook #{webhook.id}\"\n        )\n        await webhooks_manager.prune_webhook_if_dangling(webhook.id, credentials)\n        if (\n            CREDENTIALS_FIELD_NAME in block.input_schema.model_fields\n            and not credentials\n        ):\n            logger.warning(\n                f\"Cannot deregister webhook #{webhook.id}: credentials \"\n                f\"#{webhook.credentials_id} not available \"\n                f\"({webhook.provider.value} webhook ID: {webhook.provider_webhook_id})\"\n            )\n        return updated_node\n\n    logger.debug(f\"Node #{node.id} has no webhook_id, returning\")\n    return node", "blocks": [{"id": 1, "label": "# Example input code\nasync def on_node_deactivate(\n    node: \"NodeModel\",\n    *,\n    credentials: Optional[\"Credentials\"] = None,\n    webhooks_manager: Optional[\"BaseWebhooksManager\"] = None,\n) -> \"NodeModel\":\n    \"\"\"Hook to be called when node is deactivated/deleted\"\"\"\n\n    logger.debug(f\"Deactivating node #{node.id}\")\n    block = get_block(node.block_id)\n    if not block:", "successors": [{"id": 2, "label": "        raise ValueError(\n            f\"Node #{node.id} is instance of unknown block #{node.block_id}\"\n        )", "successors": []}, {"id": 3, "label": "    if not block.webhook_config:", "successors": [{"id": 4, "label": "        return node", "successors": []}, {"id": 5, "label": "    provider = block.webhook_config.provider\n    if provider not in WEBHOOK_MANAGERS_BY_NAME:", "successors": [{"id": 6, "label": "        raise ValueError(\n            f\"Block #{block.id} has webhook_config for provider {provider} \"\n            \"which does not support webhooks\"\n        )", "successors": []}, {"id": 7, "label": "    webhooks_manager = WEBHOOK_MANAGERS_BY_NAME[provider]()\n    if node.webhook_id:", "successors": [{"id": 9, "label": "        logger.debug(f\"Node #{node.id} has webhook_id {node.webhook_id}\")\n        if not node.webhook:", "successors": [{"id": 10, "label": "            logger.error(f\"Node #{node.id} has webhook_id but no webhook object\")\n            raise ValueError(\"node.webhook not included\")", "successors": []}, {"id": 11, "label": "        # Detach webhook from node\n        logger.debug(f\"Detaching webhook from node #{node.id}\")\n        updated_node = await set_node_webhook(node.id, None)\n\n        # Prune and deregister the webhook if it is no longer used anywhere\n        webhook = node.webhook\n        logger.debug(\n            f\"Pruning{' and deregistering' if credentials else ''} \"\n            f\"webhook #{webhook.id}\"\n        )\n        await webhooks_manager.prune_webhook_if_dangling(webhook.id, credentials)\n        if (\n            CREDENTIALS_FIELD_NAME in block.input_schema.model_fields\n            and not credentials\n        ):\n            logger.warning(\n                f\"Cannot deregister webhook #{webhook.id}: credentials \"\n                f\"#{webhook.credentials_id} not available \"\n                f\"({webhook.provider.value} webhook ID: {webhook.provider_webhook_id})\"\n            )", "successors": []}, {"id": 13, "label": "        return updated_node", "successors": []}]}, {"id": 14, "label": "    logger.debug(f\"Node #{node.id} has no webhook_id, returning\")\n    return node", "successors": []}]}]}]}]}]}], "classes": [], "simplified_code": "import logging\nfrom typing import TYPE_CHECKING, Callable, Optional, cast\n\nfrom backend.data.block import BlockWebhookConfig, get_block\nfrom backend.data.graph import set_node_webhook\nfrom backend.data.model import CREDENTIALS_FIELD_NAME\nfrom backend.integrations.webhooks import WEBHOOK_MANAGERS_BY_NAME\n\nif TYPE_CHECKING:\n    from backend.data.graph import GraphModel, NodeModel\n    from backend.data.model import Credentials\n\n    from ._base import BaseWebhooksManager\n\nlogger = logging.getLogger(__name__)\n\n\n    return graph\n\n\n    return graph\n\n\n    return node\n\n\n    return node", "blocks": [{"id": 1, "label": "import logging\nfrom typing import TYPE_CHECKING, Callable, Optional, cast\n\nfrom backend.data.block import BlockWebhookConfig, get_block\nfrom backend.data.graph import set_node_webhook\nfrom backend.data.model import CREDENTIALS_FIELD_NAME\nfrom backend.integrations.webhooks import WEBHOOK_MANAGERS_BY_NAME\n\nif TYPE_CHECKING:\n    from backend.data.graph import GraphModel, NodeModel\n    from backend.data.model import Credentials\n\n    from ._base import BaseWebhooksManager\n\nlogger = logging.getLogger(__name__)\n", "successors": []}]}
{"file_name": "68.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 167, "functions": [{"name": "get_client", "type": "function", "start_line": 22, "end_line": 24, "functions": [], "classes": [], "simplified_code": "def get_client() -> LDClient:\n    \"\"\"Get the LaunchDarkly client singleton.\"\"\"\n    return ldclient.get()", "blocks": [{"id": 1, "label": "def get_client() -> LDClient:\n    \"\"\"Get the LaunchDarkly client singleton.\"\"\"\n    return ldclient.get()", "successors": []}]}, {"name": "initialize_launchdarkly", "type": "function", "start_line": 27, "end_line": 43, "functions": [], "classes": [], "simplified_code": "def initialize_launchdarkly() -> None:\n    sdk_key = SETTINGS.launch_darkly_sdk_key\n    logger.debug(\n        f\"Initializing LaunchDarkly with SDK key: {'present' if sdk_key else 'missing'}\"\n    )\n\n    if not sdk_key:\n        logger.warning(\"LaunchDarkly SDK key not configured\")\n        return\n\n    config = Config(sdk_key)\n    ldclient.set_config(config)\n\n    if ldclient.get().is_initialized():\n        logger.info(\"LaunchDarkly client initialized successfully\")\n    else:\n        logger.error(\"LaunchDarkly client failed to initialize\")", "blocks": [{"id": 1, "label": "def initialize_launchdarkly() -> None:\n    sdk_key = SETTINGS.launch_darkly_sdk_key\n    logger.debug(f\"Initializing LaunchDarkly with SDK key: {'present' if sdk_key else 'missing'}\")\nif not sdk_key:", "successors": [{"id": 3, "label": "    logger.warning(\"LaunchDarkly SDK key not configured\")\n    return", "successors": []}, {"id": 4, "label": "config = Config(sdk_key)\nldclient.set_config(config)\nif ldclient.get().is_initialized():", "successors": [{"id": 6, "label": "    logger.info(\"LaunchDarkly client initialized successfully\")", "successors": []}, {"id": 7, "label": "    else:\n        logger.error(\"LaunchDarkly client failed to initialize\")", "successors": []}]}]}]}, {"name": "shutdown_launchdarkly", "type": "function", "start_line": 46, "end_line": 50, "functions": [], "classes": [], "simplified_code": "def shutdown_launchdarkly() -> None:\n    \"\"\"Shutdown the LaunchDarkly client.\"\"\"\n    if ldclient.get().is_initialized():\n        ldclient.get().close()\n        logger.info(\"LaunchDarkly client closed successfully\")", "blocks": [{"id": 1, "label": "def shutdown_launchdarkly() -> None:\n    if ldclient.get().is_initialized():", "successors": [{"id": 3, "label": "        ldclient.get().close()\n        logger.info(\"LaunchDarkly client closed successfully\")", "successors": []}]}]}, {"name": "create_context", "type": "function", "start_line": 53, "end_line": 61, "functions": [], "classes": [], "simplified_code": "def create_context(\n    user_id: str, additional_attributes: Optional[Dict[str, Any]] = None\n) -> Context:\n    \"\"\"Create LaunchDarkly context with optional additional attributes.\"\"\"\n    builder = Context.builder(str(user_id)).kind(\"user\")\n    if additional_attributes:\n        for key, value in additional_attributes.items():\n            builder.set(key, value)\n    return builder.build()", "blocks": [{"id": 1, "label": "def create_context(\n    user_id: str, additional_attributes: Optional[Dict[str, Any]] = None\n) -> Context:\nbuilder = Context.builder(str(user_id)).kind(\"user\")", "successors": [{"id": 3, "label": "if additional_attributes:", "successors": [{"id": 4, "label": "for key, value in additional_attributes.items():", "successors": [{"id": 5, "label": "builder.set(key, value)\nreturn builder.build()", "successors": []}]}, {"id": 6, "label": "return builder.build()", "successors": []}]}]}]}, {"name": "feature_flag", "type": "function", "start_line": 64, "end_line": 133, "functions": [{"name": "decorator", "type": "function", "start_line": 74, "end_line": 133, "functions": [{"name": "async_wrapper", "type": "function", "start_line": 78, "end_line": 103, "functions": [], "classes": [], "simplified_code": "        async def async_wrapper(*args: P.args, **kwargs: P.kwargs) -> T:\n            try:\n                user_id = kwargs.get(\"user_id\")\n                if not user_id:\n                    raise ValueError(\"user_id is required\")\n\n                if not get_client().is_initialized():\n                    logger.warning(\n                        f\"LaunchDarkly not initialized, using default={default}\"\n                    )\n                    is_enabled = default\n                else:\n                    context = create_context(str(user_id))\n                    is_enabled = get_client().variation(flag_key, context, default)\n\n                if not is_enabled:\n                    raise HTTPException(status_code=404, detail=\"Feature not available\")\n\n                result = func(*args, **kwargs)\n                if asyncio.iscoroutine(result):\n                    return await result\n                return cast(T, result)\n            except Exception as e:\n                logger.error(f\"Error evaluating feature flag {flag_key}: {e}\")\n                raise\n", "blocks": [{"id": 1, "label": "async def async_wrapper(*args: P.args, **kwargs: P.kwargs) -> T:\ntry:", "successors": [{"id": 3, "label": "user_id = kwargs.get(\"user_id\")\nif not user_id:", "successors": [{"id": 5, "label": "raise ValueError(\"user_id is required\")", "successors": []}, {"id": 6, "label": "if not get_client().is_initialized():", "successors": [{"id": 7, "label": "logger.warning(f\"LaunchDarkly not initialized, using default={default}\")\nis_enabled = default", "successors": [{"id": 13, "label": "if not is_enabled:", "successors": [{"id": 14, "label": "raise HTTPException(status_code=404, detail=\"Feature not available\")", "successors": []}, {"id": 15, "label": "result = func(*args, **kwargs)\nif asyncio.iscoroutine(result):", "successors": [{"id": 17, "label": "return await result", "successors": []}, {"id": 18, "label": "return cast(T, result)", "successors": []}]}]}]}, {"id": 9, "label": "context = create_context(str(user_id))\nis_enabled = get_client().variation(flag_key, context, default)", "successors": [{"id": 13, "label": "if not is_enabled:", "successors": [{"id": 14, "label": "raise HTTPException(status_code=404, detail=\"Feature not available\")", "successors": []}, {"id": 15, "label": "result = func(*args, **kwargs)\nif asyncio.iscoroutine(result):", "successors": [{"id": 17, "label": "return await result", "successors": []}, {"id": 18, "label": "return cast(T, result)", "successors": []}]}]}]}]}]}, {"id": 11, "label": "except Exception as e:\nlogger.error(f\"Error evaluating feature flag {flag_key}: {e}\")", "successors": [{"id": 13, "label": "raise", "successors": []}]}]}]}, {"name": "sync_wrapper", "type": "function", "start_line": 105, "end_line": 126, "functions": [], "classes": [], "simplified_code": "        def sync_wrapper(*args: P.args, **kwargs: P.kwargs) -> T:\n            try:\n                user_id = kwargs.get(\"user_id\")\n                if not user_id:\n                    raise ValueError(\"user_id is required\")\n\n                if not get_client().is_initialized():\n                    logger.warning(\n                        f\"LaunchDarkly not initialized, using default={default}\"\n                    )\n                    is_enabled = default\n                else:\n                    context = create_context(str(user_id))\n                    is_enabled = get_client().variation(flag_key, context, default)\n\n                if not is_enabled:\n                    raise HTTPException(status_code=404, detail=\"Feature not available\")\n\n                return cast(T, func(*args, **kwargs))\n            except Exception as e:\n                logger.error(f\"Error evaluating feature flag {flag_key}: {e}\")\n                raise", "blocks": [{"id": 1, "label": "def sync_wrapper(*args: P.args, **kwargs: P.kwargs) -> T:", "successors": [{"id": 2, "label": "try:\nuser_id = kwargs.get(\"user_id\")", "successors": [{"id": 4, "label": "if not user_id:\nraise ValueError(\"user_id is required\")", "successors": []}, {"id": 6, "label": "if not get_client().is_initialized():", "successors": [{"id": 7, "label": "logger.warning(f\"LaunchDarkly not initialized, using default={default}\")\nis_enabled = default", "successors": []}, {"id": 8, "label": "context = create_context(str(user_id))\nis_enabled = get_client().variation(flag_key, context, default)", "successors": []}]}, {"id": 9, "label": "if not is_enabled:\nraise HTTPException(status_code=404, detail=\"Feature not available\")", "successors": []}, {"id": 11, "label": "return cast(T, func(*args, **kwargs))", "successors": []}]}, {"id": 12, "label": "except Exception as e:\nlogger.error(f\"Error evaluating feature flag {flag_key}: {e}\")\nraise", "successors": []}]}]}], "classes": [], "simplified_code": "    def decorator(\n        func: Callable[P, Union[T, Awaitable[T]]],\n    ) -> Callable[P, Union[T, Awaitable[T]]]:\n        @wraps(func)\n\n        @wraps(func)\n                raise\n\n        return cast(\n            Callable[P, Union[T, Awaitable[T]]],\n            async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper,\n        )\n\n    return decorator", "blocks": [{"id": 1, "label": "def decorator(\n    func: Callable[P, Union[T, Awaitable[T]]],\n) -> Callable[P, Union[T, Awaitable[T]]]:\n@wraps(func)", "successors": [{"id": 3, "label": "raise\nreturn cast(\n    Callable[P, Union[T, Awaitable[T]]],\n    async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper,\n)", "successors": []}]}]}], "classes": [], "simplified_code": "def feature_flag(\n    flag_key: str,\n    default: bool = False,\n) -> Callable[\n    [Callable[P, Union[T, Awaitable[T]]]], Callable[P, Union[T, Awaitable[T]]]\n]:\n    \"\"\"\n    Decorator for feature flag protected endpoints.\n    \"\"\"\n\n    return decorator", "blocks": [{"id": 1, "label": "def feature_flag(\n    flag_key: str,\n    default: bool = False,\n) -> Callable[\n    [Callable[P, Union[T, Awaitable[T]]]], Callable[P, Union[T, Awaitable[T]]]\n]:\n\"\"\"\nDecorator for feature flag protected endpoints.\n\"\"\"", "successors": [{"id": 3, "label": "return decorator", "successors": []}]}]}, {"name": "percentage_rollout", "type": "function", "start_line": 136, "end_line": 143, "functions": [], "classes": [], "simplified_code": "def percentage_rollout(\n    flag_key: str,\n    default: bool = False,\n) -> Callable[\n    [Callable[P, Union[T, Awaitable[T]]]], Callable[P, Union[T, Awaitable[T]]]\n]:\n    \"\"\"Decorator for percentage-based rollouts.\"\"\"\n    return feature_flag(flag_key, default)", "blocks": [{"id": 1, "label": "def percentage_rollout(\n    flag_key: str,\n    default: bool = False,\n) -> Callable[\n    [Callable[P, Union[T, Awaitable[T]]]], Callable[P, Union[T, Awaitable[T]]]\n]:\n    \"\"\"Decorator for percentage-based rollouts.\"\"\"", "successors": [{"id": 3, "label": "    return feature_flag(flag_key, default)", "successors": []}]}]}, {"name": "beta_feature", "type": "function", "start_line": 146, "end_line": 154, "functions": [], "classes": [], "simplified_code": "def beta_feature(\n    flag_key: Optional[str] = None,\n    unauthorized_response: Any = {\"message\": \"Not available in beta\"},\n) -> Callable[\n    [Callable[P, Union[T, Awaitable[T]]]], Callable[P, Union[T, Awaitable[T]]]\n]:\n    \"\"\"Decorator for beta features.\"\"\"\n    actual_key = f\"beta-{flag_key}\" if flag_key else \"beta\"\n    return feature_flag(actual_key, False)", "blocks": [{"id": 1, "label": "def beta_feature(\n    flag_key: Optional[str] = None,\n    unauthorized_response: Any = {\"message\": \"Not available in beta\"},\n) -> Callable[\n    [Callable[P, Union[T, Awaitable[T]]]], Callable[P, Union[T, Awaitable[T]]]\n]:\n    \"\"\"Decorator for beta features.\"\"\"\n    actual_key = f\"beta-{flag_key}\" if flag_key else \"beta\"", "successors": [{"id": 3, "label": "    return feature_flag(actual_key, False)", "successors": []}]}]}, {"name": "mock_flag_variation", "type": "function", "start_line": 158, "end_line": 167, "functions": [], "classes": [], "simplified_code": "def mock_flag_variation(flag_key: str, return_value: Any):\n    \"\"\"Context manager for testing feature flags.\"\"\"\n    original_variation = get_client().variation\n    get_client().variation = lambda key, context, default: (\n        return_value if key == flag_key else original_variation(key, context, default)\n    )\n    try:\n        yield\n    finally:\n        get_client().variation = original_variation", "blocks": [{"id": 1, "label": "def mock_flag_variation(flag_key: str, return_value: Any):\n\"\"\"Context manager for testing feature flags.\"\"\"\noriginal_variation = get_client().variation\nget_client().variation = lambda key, context, default: (\n    return_value if key == flag_key else original_variation(key, context, default)\n)", "successors": [{"id": 3, "label": "try:\nyield", "successors": [{"id": 5, "label": "finally:\nget_client().variation = original_variation", "successors": []}]}]}]}], "classes": [], "simplified_code": "import asyncio\nimport contextlib\nimport logging\nfrom functools import wraps\nfrom typing import Any, Awaitable, Callable, Dict, Optional, TypeVar, Union, cast\n\nimport ldclient\nfrom fastapi import HTTPException\nfrom ldclient import Context, LDClient\nfrom ldclient.config import Config\nfrom typing_extensions import ParamSpec\n\nfrom .config import SETTINGS\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(level=logging.DEBUG)\n\nP = ParamSpec(\"P\")\nT = TypeVar(\"T\")\n\n\n    return ldclient.get()\n\n\n        logger.error(\"LaunchDarkly client failed to initialize\")\n\n\n        logger.info(\"LaunchDarkly client closed successfully\")\n\n\n    return builder.build()\n\n\n    return decorator\n\n\n    return feature_flag(flag_key, default)\n\n\n    return feature_flag(actual_key, False)\n\n\n@contextlib.contextmanager\n        get_client().variation = original_variation", "blocks": []}
{"file_name": "69.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 323, "functions": [], "classes": [{"name": "AudioTrack", "type": "class", "start_line": 33, "end_line": 81, "functions": [{"name": "audio_url", "type": "function", "start_line": 57, "end_line": 81, "functions": [], "classes": [], "simplified_code": "    def audio_url(self):\n        audio_urls = {\n            AudioTrack.OBSERVER: \"https://cdn.tfrv.xyz/audio/observer.mp3\",\n            AudioTrack.FUTURISTIC_BEAT: \"https://cdn.tfrv.xyz/audio/_futuristic-beat.mp3\",\n            AudioTrack.SCIENCE_DOCUMENTARY: \"https://cdn.tfrv.xyz/audio/_science-documentary.mp3\",\n            AudioTrack.HOTLINE: \"https://cdn.tfrv.xyz/audio/_hotline.mp3\",\n            AudioTrack.BLADERUNNER_2049: \"https://cdn.tfrv.xyz/audio/_bladerunner-2049.mp3\",\n            AudioTrack.A_FUTURE: \"https://cdn.tfrv.xyz/audio/a-future.mp3\",\n            AudioTrack.ELYSIAN_EMBERS: \"https://cdn.tfrv.xyz/audio/elysian-embers.mp3\",\n            AudioTrack.INSPIRING_CINEMATIC: \"https://cdn.tfrv.xyz/audio/inspiring-cinematic-ambient.mp3\",\n            AudioTrack.BLADERUNNER_REMIX: \"https://cdn.tfrv.xyz/audio/bladerunner-remix.mp3\",\n            AudioTrack.IZZAMUZZIC: \"https://cdn.tfrv.xyz/audio/_izzamuzzic.mp3\",\n            AudioTrack.NAS: \"https://cdn.tfrv.xyz/audio/_nas.mp3\",\n            AudioTrack.PARIS_ELSE: \"https://cdn.tfrv.xyz/audio/_paris-else.mp3\",\n            AudioTrack.SNOWFALL: \"https://cdn.tfrv.xyz/audio/_snowfall.mp3\",\n            AudioTrack.BURLESQUE: \"https://cdn.tfrv.xyz/audio/burlesque.mp3\",\n            AudioTrack.CORNY_CANDY: \"https://cdn.tfrv.xyz/audio/corny-candy.mp3\",\n            AudioTrack.HIGHWAY_NOCTURNE: \"https://cdn.tfrv.xyz/audio/highway-nocturne.mp3\",\n            AudioTrack.I_DONT_THINK_SO: \"https://cdn.tfrv.xyz/audio/i-dont-think-so.mp3\",\n            AudioTrack.LOSING_YOUR_MARBLES: \"https://cdn.tfrv.xyz/audio/losing-your-marbles.mp3\",\n            AudioTrack.REFRESHER: \"https://cdn.tfrv.xyz/audio/refresher.mp3\",\n            AudioTrack.TOURIST: \"https://cdn.tfrv.xyz/audio/tourist.mp3\",\n            AudioTrack.TWIN_TYCHES: \"https://cdn.tfrv.xyz/audio/twin-tynches.mp3\",\n        }\n        return audio_urls[self]", "blocks": [{"id": 1, "label": "def audio_url(self):\naudio_urls = {\n    AudioTrack.OBSERVER: \"https://cdn.tfrv.xyz/audio/observer.mp3\",\n    AudioTrack.FUTURISTIC_BEAT: \"https://cdn.tfrv.xyz/audio/_futuristic-beat.mp3\",\n    AudioTrack.SCIENCE_DOCUMENTARY: \"https://cdn.tfrv.xyz/audio/_science-documentary.mp3\",\n    AudioTrack.HOTLINE: \"https://cdn.tfrv.xyz/audio/_hotline.mp3\",\n    AudioTrack.BLADERUNNER_2049: \"https://cdn.tfrv.xyz/audio/_bladerunner-2049.mp3\",\n    AudioTrack.A_FUTURE: \"https://cdn.tfrv.xyz/audio/a-future.mp3\",\n    AudioTrack.ELYSIAN_EMBERS: \"https://cdn.tfrv.xyz/audio/elysian-embers.mp3\",\n    AudioTrack.INSPIRING_CINEMATIC: \"https://cdn.tfrv.xyz/audio/inspiring-cinematic-ambient.mp3\",\n    AudioTrack.BLADERUNNER_REMIX: \"https://cdn.tfrv.xyz/audio/bladerunner-remix.mp3\",\n    AudioTrack.IZZAMUZZIC: \"https://cdn.tfrv.xyz/audio/_izzamuzzic.mp3\",\n    AudioTrack.NAS: \"https://cdn.tfrv.xyz/audio/_nas.mp3\",\n    AudioTrack.PARIS_ELSE: \"https://cdn.tfrv.xyz/audio/_paris-else.mp3\",\n    AudioTrack.SNOWFALL: \"https://cdn.tfrv.xyz/audio/_snowfall.mp3\",\n    AudioTrack.BURLESQUE: \"https://cdn.tfrv.xyz/audio/burlesque.mp3\",\n    AudioTrack.CORNY_CANDY: \"https://cdn.tfrv.xyz/audio/corny-candy.mp3\",\n    AudioTrack.HIGHWAY_NOCTURNE: \"https://cdn.tfrv.xyz/audio/highway-nocturne.mp3\",\n    AudioTrack.I_DONT_THINK_SO: \"https://cdn.tfrv.xyz/audio/i-dont-think-so.mp3\",\n    AudioTrack.LOSING_YOUR_MARBLES: \"https://cdn.tfrv.xyz/audio/losing-your-marbles.mp3\",\n    AudioTrack.REFRESHER: \"https://cdn.tfrv.xyz/audio/refresher.mp3\",\n    AudioTrack.TOURIST: \"https://cdn.tfrv.xyz/audio/tourist.mp3\",\n    AudioTrack.TWIN_TYCHES: \"https://cdn.tfrv.xyz/audio/twin-tynches.mp3\",\n}", "successors": [{"id": 3, "label": "return audio_urls[self]", "successors": []}]}]}], "simplified_code": "class AudioTrack(str, Enum):\n    OBSERVER = (\"Observer\",)\n    FUTURISTIC_BEAT = (\"Futuristic Beat\",)\n    SCIENCE_DOCUMENTARY = (\"Science Documentary\",)\n    HOTLINE = (\"Hotline\",)\n    BLADERUNNER_2049 = (\"Bladerunner 2049\",)\n    A_FUTURE = (\"A Future\",)\n    ELYSIAN_EMBERS = (\"Elysian Embers\",)\n    INSPIRING_CINEMATIC = (\"Inspiring Cinematic\",)\n    BLADERUNNER_REMIX = (\"Bladerunner Remix\",)\n    IZZAMUZZIC = (\"Izzamuzzic\",)\n    NAS = (\"Nas\",)\n    PARIS_ELSE = (\"Paris - Else\",)\n    SNOWFALL = (\"Snowfall\",)\n    BURLESQUE = (\"Burlesque\",)\n    CORNY_CANDY = (\"Corny Candy\",)\n    HIGHWAY_NOCTURNE = (\"Highway Nocturne\",)\n    I_DONT_THINK_SO = (\"I Don't Think So\",)\n    LOSING_YOUR_MARBLES = (\"Losing Your Marbles\",)\n    REFRESHER = (\"Refresher\",)\n    TOURIST = (\"Tourist\",)\n    TWIN_TYCHES = (\"Twin Tyches\",)\n\n    @property\n        return audio_urls[self]", "blocks": [{"id": 1, "label": "class AudioTrack(str, Enum):\nOBSERVER = (\"Observer\",)", "successors": [{"id": 3, "label": "FUTURISTIC_BEAT = (\"Futuristic Beat\",)\nSCIENCE_DOCUMENTARY = (\"Science Documentary\",)", "successors": [{"id": 5, "label": "HOTLINE = (\"Hotline\",)\nBLADERUNNER_2049 = (\"Bladerunner 2049\",)", "successors": [{"id": 7, "label": "A_FUTURE = (\"A Future\",)\nELYSIAN_EMBERS = (\"Elysian Embers\",)", "successors": [{"id": 9, "label": "INSPIRING_CINEMATIC = (\"Inspiring Cinematic\",)\nBLADERUNNER_REMIX = (\"Bladerunner Remix\",)", "successors": [{"id": 11, "label": "IZZAMUZZIC = (\"Izzamuzzic\",)\nNAS = (\"Nas\",)", "successors": [{"id": 13, "label": "PARIS_ELSE = (\"Paris - Else\",)\nSNOWFALL = (\"Snowfall\",)", "successors": [{"id": 15, "label": "BURLESQUE = (\"Burlesque\",)\nCORNY_CANDY = (\"Corny Candy\",)", "successors": [{"id": 17, "label": "HIGHWAY_NOCTURNE = (\"Highway Nocturne\",)\nI_DONT_THINK_SO = (\"I Don't Think So\",)", "successors": [{"id": 19, "label": "LOSING_YOUR_MARBLES = (\"Losing Your Marbles\",)\nREFRESHER = (\"Refresher\",)", "successors": [{"id": 21, "label": "TOURIST = (\"Tourist\",)\nTWIN_TYCHES = (\"Twin Tyches\",)", "successors": [{"id": 23, "label": "@property\nreturn audio_urls[self]", "successors": []}]}]}]}]}]}]}]}]}]}]}]}]}, {"name": "GenerationPreset", "type": "class", "start_line": 84, "end_line": 106, "functions": [], "classes": [], "simplified_code": "class GenerationPreset(str, Enum):\n    LEONARDO = (\"Default\",)\n    ANIME = (\"Anime\",)\n    REALISM = (\"Realist\",)\n    ILLUSTRATION = (\"Illustration\",)\n    SKETCH_COLOR = (\"Sketch Color\",)\n    SKETCH_BW = (\"Sketch B&W\",)\n    PIXAR = (\"Pixar\",)\n    INK = (\"Japanese Ink\",)\n    RENDER_3D = (\"3D Render\",)\n    LEGO = (\"Lego\",)\n    SCIFI = (\"Sci-Fi\",)\n    RECRO_CARTOON = (\"Retro Cartoon\",)\n    PIXEL_ART = (\"Pixel Art\",)\n    CREATIVE = (\"Creative\",)\n    PHOTOGRAPHY = (\"Photography\",)\n    RAYTRACED = (\"Raytraced\",)\n    ENVIRONMENT = (\"Environment\",)\n    FANTASY = (\"Fantasy\",)\n    ANIME_SR = (\"Anime Realism\",)\n    MOVIE = (\"Movie\",)\n    STYLIZED_ILLUSTRATION = (\"Stylized Illustration\",)\n    MANGA = (\"Manga\",)", "blocks": [{"id": 1, "label": "class GenerationPreset(str, Enum):\n    LEONARDO = (\"Default\",)\n    ANIME = (\"Anime\",)\n    REALISM = (\"Realist\",)\n    ILLUSTRATION = (\"Illustration\",)\n    SKETCH_COLOR = (\"Sketch Color\",)\n    SKETCH_BW = (\"Sketch B&W\",)\n    PIXAR = (\"Pixar\",)\n    INK = (\"Japanese Ink\",)\n    RENDER_3D = (\"3D Render\",)\n    LEGO = (\"Lego\",)\n    SCIFI = (\"Sci-Fi\",)\n    RECRO_CARTOON = (\"Retro Cartoon\",)\n    PIXEL_ART = (\"Pixel Art\",)\n    CREATIVE = (\"Creative\",)\n    PHOTOGRAPHY = (\"Photography\",)\n    RAYTRACED = (\"Raytraced\",)\n    ENVIRONMENT = (\"Environment\",)\n    FANTASY = (\"Fantasy\",)\n    ANIME_SR = (\"Anime Realism\",)\n    MOVIE = (\"Movie\",)\n    STYLIZED_ILLUSTRATION = (\"Stylized Illustration\",)\n    MANGA = (\"Manga\",)", "successors": []}]}, {"name": "Voice", "type": "class", "start_line": 109, "end_line": 130, "functions": [{"name": "voice_id", "type": "function", "start_line": 118, "end_line": 127, "functions": [], "classes": [], "simplified_code": "    def voice_id(self):\n        voice_id_map = {\n            Voice.LILY: \"pFZP5JQG7iQjIQuC4Bku\",\n            Voice.DANIEL: \"onwK4e9ZLuTAKqWW03F9\",\n            Voice.BRIAN: \"nPczCjzI2devNBz1zQrb\",\n            Voice.JESSICA: \"cgSgspJ2msm6clMCkdW9\",\n            Voice.CHARLOTTE: \"XB0fDUnXU5powFXDhCwa\",\n            Voice.CALLUM: \"N2lVS1w4EtoT3dr4eOWO\",\n        }\n        return voice_id_map[self]", "blocks": [{"id": 1, "label": "def voice_id(self):\nvoice_id_map = {\n    Voice.LILY: \"pFZP5JQG7iQjIQuC4Bku\",\n    Voice.DANIEL: \"onwK4e9ZLuTAKqWW03F9\",\n    Voice.BRIAN: \"nPczCjzI2devNBz1zQrb\",\n    Voice.JESSICA: \"cgSgspJ2msm6clMCkdW9\",\n    Voice.CHARLOTTE: \"XB0fDUnXU5powFXDhCwa\",\n    Voice.CALLUM: \"N2lVS1w4EtoT3dr4eOWO\",\n}", "successors": [{"id": 3, "label": "return voice_id_map[self]", "successors": []}]}]}, {"name": "__str__", "type": "function", "start_line": 129, "end_line": 130, "functions": [], "classes": [], "simplified_code": "    def __str__(self):\n        return self.value", "blocks": [{"id": 1, "label": "def __str__(self):\n    return self.value", "successors": []}]}], "simplified_code": "class Voice(str, Enum):\n    LILY = \"Lily\"\n    DANIEL = \"Daniel\"\n    BRIAN = \"Brian\"\n    JESSICA = \"Jessica\"\n    CHARLOTTE = \"Charlotte\"\n    CALLUM = \"Callum\"\n\n    @property\n        return voice_id_map[self]\n\n        return self.value", "blocks": [{"id": 1, "label": "class Voice(str, Enum):\nLILY = \"Lily\"\nDANIEL = \"Daniel\"\nBRIAN = \"Brian\"\nJESSICA = \"Jessica\"\nCHARLOTTE = \"Charlotte\"\nCALLUM = \"Callum\"", "successors": [{"id": 3, "label": "@property\ndef id(self):", "successors": [{"id": 5, "label": "return voice_id_map[self]\nreturn self.value", "successors": []}]}]}]}, {"name": "VisualMediaType", "type": "class", "start_line": 133, "end_line": 136, "functions": [], "classes": [], "simplified_code": "class VisualMediaType(str, Enum):\n    STOCK_VIDEOS = (\"stockVideo\",)\n    MOVING_AI_IMAGES = (\"movingImage\",)\n    AI_VIDEO = (\"aiVideo\",)", "blocks": [{"id": 1, "label": "class VisualMediaType(str, Enum):", "successors": [{"id": 2, "label": "    STOCK_VIDEOS = (\"stockVideo\",)", "successors": []}, {"id": 3, "label": "    MOVING_AI_IMAGES = (\"movingImage\",)", "successors": []}, {"id": 4, "label": "    AI_VIDEO = (\"aiVideo\",)", "successors": []}]}]}, {"name": "AIShortformVideoCreatorBlock", "type": "class", "start_line": 142, "end_line": 323, "functions": [{"name": "__init__", "type": "function", "start_line": 186, "end_line": 217, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"361697fb-0c4f-4feb-aed3-8320c88c771b\",\n            description=\"Creates a shortform video using revid.ai\",\n            categories={BlockCategory.SOCIAL, BlockCategory.AI},\n            input_schema=AIShortformVideoCreatorBlock.Input,\n            output_schema=AIShortformVideoCreatorBlock.Output,\n            test_input={\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n                \"script\": \"[close-up of a cat] Meow!\",\n                \"ratio\": \"9 / 16\",\n                \"resolution\": \"720p\",\n                \"frame_rate\": 60,\n                \"generation_preset\": GenerationPreset.LEONARDO,\n                \"background_music\": AudioTrack.HIGHWAY_NOCTURNE,\n                \"voice\": Voice.LILY,\n                \"video_style\": VisualMediaType.STOCK_VIDEOS,\n            },\n            test_output=(\n                \"video_url\",\n                \"https://example.com/video.mp4\",\n            ),\n            test_mock={\n                \"create_webhook\": lambda: (\n                    \"test_uuid\",\n                    \"https://webhook.site/test_uuid\",\n                ),\n                \"create_video\": lambda api_key, payload: {\"pid\": \"test_pid\"},\n                \"wait_for_video\": lambda api_key, pid, webhook_token, max_wait_time=1000: \"https://example.com/video.mp4\",\n            },\n            test_credentials=TEST_CREDENTIALS,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"361697fb-0c4f-4feb-aed3-8320c88c771b\",\n    description=\"Creates a shortform video using revid.ai\",\n    categories={BlockCategory.SOCIAL, BlockCategory.AI},\n    input_schema=AIShortformVideoCreatorBlock.Input,\n    output_schema=AIShortformVideoCreatorBlock.Output,\n    test_input={\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n        \"script\": \"[close-up of a cat] Meow!\",\n        \"ratio\": \"9 / 16\",\n        \"resolution\": \"720p\",\n        \"frame_rate\": 60,\n        \"generation_preset\": GenerationPreset.LEONARDO,\n        \"background_music\": AudioTrack.HIGHWAY_NOCTURNE,\n        \"voice\": Voice.LILY,\n        \"video_style\": VisualMediaType.STOCK_VIDEOS,\n    },\n    test_output=(\n        \"video_url\",\n        \"https://example.com/video.mp4\",\n    ),\n    test_mock={\n        \"create_webhook\": lambda: (\n            \"test_uuid\",\n            \"https://webhook.site/test_uuid\",\n        ),\n        \"create_video\": lambda api_key, payload: {\"pid\": \"test_pid\"},\n        \"wait_for_video\": lambda api_key, pid, webhook_token, max_wait_time=1000: \"https://example.com/video.mp4\",\n    },\n    test_credentials=TEST_CREDENTIALS,\n)", "successors": []}]}, {"name": "create_webhook", "type": "function", "start_line": 219, "end_line": 224, "functions": [], "classes": [], "simplified_code": "    def create_webhook(self):\n        url = \"https://webhook.site/token\"\n        headers = {\"Accept\": \"application/json\", \"Content-Type\": \"application/json\"}\n        response = requests.post(url, headers=headers)\n        webhook_data = response.json()\n        return webhook_data[\"uuid\"], f\"https://webhook.site/{webhook_data['uuid']}\"", "blocks": [{"id": 1, "label": "def create_webhook(self):\nurl = \"https://webhook.site/token\"\nheaders = {\"Accept\": \"application/json\", \"Content-Type\": \"application/json\"}\nresponse = requests.post(url, headers=headers)\nwebhook_data = response.json()", "successors": [{"id": 3, "label": "return webhook_data[\"uuid\"], f\"https://webhook.site/{webhook_data['uuid']}\"", "successors": []}]}]}, {"name": "create_video", "type": "function", "start_line": 226, "end_line": 233, "functions": [], "classes": [], "simplified_code": "    def create_video(self, api_key: SecretStr, payload: dict) -> dict:\n        url = \"https://www.revid.ai/api/public/v2/render\"\n        headers = {\"key\": api_key.get_secret_value()}\n        response = requests.post(url, json=payload, headers=headers)\n        logger.debug(\n            f\"API Response Status Code: {response.status_code}, Content: {response.text}\"\n        )\n        return response.json()", "blocks": [{"id": 1, "label": "def create_video(self, api_key: SecretStr, payload: dict) -> dict:\nurl = \"https://www.revid.ai/api/public/v2/render\"\nheaders = {\"key\": api_key.get_secret_value()}\nresponse = requests.post(url, json=payload, headers=headers)\nlogger.debug(\n    f\"API Response Status Code: {response.status_code}, Content: {response.text}\"\n)", "successors": [{"id": 3, "label": "return response.json()", "successors": []}]}]}, {"name": "check_video_status", "type": "function", "start_line": 235, "end_line": 239, "functions": [], "classes": [], "simplified_code": "    def check_video_status(self, api_key: SecretStr, pid: str) -> dict:\n        url = f\"https://www.revid.ai/api/public/v2/status?pid={pid}\"\n        headers = {\"key\": api_key.get_secret_value()}\n        response = requests.get(url, headers=headers)\n        return response.json()", "blocks": [{"id": 1, "label": "def check_video_status(self, api_key: SecretStr, pid: str) -> dict:\n    url = f\"https://www.revid.ai/api/public/v2/status?pid={pid}\"", "successors": [{"id": 3, "label": "    headers = {\"key\": api_key.get_secret_value()}\n    response = requests.get(url, headers=headers)", "successors": [{"id": 5, "label": "    return response.json()", "successors": []}]}]}]}, {"name": "wait_for_video", "type": "function", "start_line": 241, "end_line": 266, "functions": [], "classes": [], "simplified_code": "    def wait_for_video(\n        self,\n        api_key: SecretStr,\n        pid: str,\n        webhook_token: str,\n        max_wait_time: int = 1000,\n    ) -> str:\n        start_time = time.time()\n        while time.time() - start_time < max_wait_time:\n            status = self.check_video_status(api_key, pid)\n            logger.debug(f\"Video status: {status}\")\n\n            if status.get(\"status\") == \"ready\" and \"videoUrl\" in status:\n                return status[\"videoUrl\"]\n            elif status.get(\"status\") == \"error\":\n                error_message = status.get(\"error\", \"Unknown error occurred\")\n                logger.error(f\"Video creation failed: {error_message}\")\n                raise ValueError(f\"Video creation failed: {error_message}\")\n            elif status.get(\"status\") in [\"FAILED\", \"CANCELED\"]:\n                logger.error(f\"Video creation failed: {status.get('message')}\")\n                raise ValueError(f\"Video creation failed: {status.get('message')}\")\n\n            time.sleep(10)\n\n        logger.error(\"Video creation timed out\")\n        raise TimeoutError(\"Video creation timed out\")", "blocks": [{"id": 1, "label": "def wait_for_video( self, api_key: SecretStr, pid: str, webhook_token: str, max_wait_time: int = 1000, ) -> str:\nstart_time = time.time()", "successors": [{"id": 3, "label": "while time.time() - start_time < max_wait_time:", "successors": [{"id": 4, "label": "status = self.check_video_status(api_key, pid)\nlogger.debug(f\"Video status: {status}\")", "successors": [{"id": 5, "label": "if status.get(\"status\") == \"ready\" and \"videoUrl\" in status:\nreturn status[\"videoUrl\"]", "successors": []}, {"id": 7, "label": "elif status.get(\"status\") == \"error\":\nerror_message = status.get(\"error\", \"Unknown error occurred\")\nlogger.error(f\"Video creation failed: {error_message}\")\nraise ValueError(f\"Video creation failed: {error_message}\")", "successors": []}, {"id": 9, "label": "elif status.get(\"status\") in [\"FAILED\", \"CANCELED\"]:\nlogger.error(f\"Video creation failed: {status.get('message')}\")\nraise ValueError(f\"Video creation failed: {status.get('message')}\")", "successors": []}, {"id": 11, "label": "time.sleep(10)", "successors": [{"id": 3, "label": "while time.time() - start_time < max_wait_time:", "successors": []}]}]}]}, {"id": 12, "label": "logger.error(\"Video creation timed out\")\nraise TimeoutError(\"Video creation timed out\")", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 268, "end_line": 323, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        # Create a new Webhook.site URL\n        webhook_token, webhook_url = self.create_webhook()\n        logger.debug(f\"Webhook URL: {webhook_url}\")\n\n        audio_url = input_data.background_music.audio_url\n\n        payload = {\n            \"frameRate\": input_data.frame_rate,\n            \"resolution\": input_data.resolution,\n            \"frameDurationMultiplier\": 18,\n            \"webhook\": webhook_url,\n            \"creationParams\": {\n                \"mediaType\": input_data.video_style,\n                \"captionPresetName\": \"Wrap 1\",\n                \"selectedVoice\": input_data.voice.voice_id,\n                \"hasEnhancedGeneration\": True,\n                \"generationPreset\": input_data.generation_preset.name,\n                \"selectedAudio\": input_data.background_music,\n                \"origin\": \"/create\",\n                \"inputText\": input_data.script,\n                \"flowType\": \"text-to-video\",\n                \"slug\": \"create-tiktok-video\",\n                \"hasToGenerateVoice\": True,\n                \"hasToTranscript\": False,\n                \"hasToSearchMedia\": True,\n                \"hasAvatar\": False,\n                \"hasWebsiteRecorder\": False,\n                \"hasTextSmallAtBottom\": False,\n                \"ratio\": input_data.ratio,\n                \"sourceType\": \"contentScraping\",\n                \"selectedStoryStyle\": {\"value\": \"custom\", \"label\": \"Custom\"},\n                \"hasToGenerateVideos\": input_data.video_style\n                != VisualMediaType.STOCK_VIDEOS,\n                \"audioUrl\": audio_url,\n            },\n        }\n\n        logger.debug(\"Creating video...\")\n        response = self.create_video(credentials.api_key, payload)\n        pid = response.get(\"pid\")\n\n        if not pid:\n            logger.error(\n                f\"Failed to create video: No project ID returned. API Response: {response}\"\n            )\n            raise RuntimeError(\"Failed to create video: No project ID returned\")\n        else:\n            logger.debug(\n                f\"Video created with project ID: {pid}. Waiting for completion...\"\n            )\n            video_url = self.wait_for_video(credentials.api_key, pid, webhook_token)\n            logger.debug(f\"Video ready: {video_url}\")\n            yield \"video_url\", video_url", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs) -> BlockOutput:\n    webhook_token, webhook_url = self.create_webhook()\n    logger.debug(f\"Webhook URL: {webhook_url}\")\n\n    audio_url = input_data.background_music.audio_url\n\n    payload = {\n        \"frameRate\": input_data.frame_rate,\n        \"resolution\": input_data.resolution,\n        \"frameDurationMultiplier\": 18,\n        \"webhook\": webhook_url,\n        \"creationParams\": {\n            \"mediaType\": input_data.video_style,\n            \"captionPresetName\": \"Wrap 1\",\n            \"selectedVoice\": input_data.voice.voice_id,\n            \"hasEnhancedGeneration\": True,\n            \"generationPreset\": input_data.generation_preset.name,\n            \"selectedAudio\": input_data.background_music,\n            \"origin\": \"/create\",\n            \"inputText\": input_data.script,\n            \"flowType\": \"text-to-video\",\n            \"slug\": \"create-tiktok-video\",\n            \"hasToGenerateVoice\": True,\n            \"hasToTranscript\": False,\n            \"hasToSearchMedia\": True,\n            \"hasAvatar\": False,\n            \"hasWebsiteRecorder\": False,\n            \"hasTextSmallAtBottom\": False,\n            \"ratio\": input_data.ratio,\n            \"sourceType\": \"contentScraping\",\n            \"selectedStoryStyle\": {\"value\": \"custom\", \"label\": \"Custom\"},\n            \"hasToGenerateVideos\": input_data.video_style != VisualMediaType.STOCK_VIDEOS,\n            \"audioUrl\": audio_url,\n        },\n    }\n\n    logger.debug(\"Creating video...\")\n    response = self.create_video(credentials.api_key, payload)\n    pid = response.get(\"pid\")\nif not pid:", "successors": [{"id": 3, "label": "    logger.error(f\"Failed to create video: No project ID returned. API Response: {response}\")\n    raise RuntimeError(\"Failed to create video: No project ID returned\")", "successors": []}, {"id": 4, "label": "else:\n    logger.debug(f\"Video created with project ID: {pid}. Waiting for completion...\")\n    video_url = self.wait_for_video(credentials.api_key, pid, webhook_token)\n    logger.debug(f\"Video ready: {video_url}\")\n    yield \"video_url\", video_url", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 143, "end_line": 180, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: CredentialsMetaInput[\n            Literal[ProviderName.REVID], Literal[\"api_key\"]\n        ] = CredentialsField(\n            description=\"The revid.ai integration can be used with \"\n            \"any API key with sufficient permissions for the blocks it is used on.\",\n        )\n        script: str = SchemaField(\n            description=\"\"\"1. Use short and punctuated sentences\\n\\n2. Use linebreaks to create a new clip\\n\\n3. Text outside of brackets is spoken by the AI, and [text between brackets] will be used to guide the visual generation. For example, [close-up of a cat] will show a close-up of a cat.\"\"\",\n            placeholder=\"[close-up of a cat] Meow!\",\n        )\n        ratio: str = SchemaField(\n            description=\"Aspect ratio of the video\", default=\"9 / 16\"\n        )\n        resolution: str = SchemaField(\n            description=\"Resolution of the video\", default=\"720p\"\n        )\n        frame_rate: int = SchemaField(description=\"Frame rate of the video\", default=60)\n        generation_preset: GenerationPreset = SchemaField(\n            description=\"Generation preset for visual style - only effects AI generated visuals\",\n            default=GenerationPreset.LEONARDO,\n            placeholder=GenerationPreset.LEONARDO,\n        )\n        background_music: AudioTrack = SchemaField(\n            description=\"Background music track\",\n            default=AudioTrack.HIGHWAY_NOCTURNE,\n            placeholder=AudioTrack.HIGHWAY_NOCTURNE,\n        )\n        voice: Voice = SchemaField(\n            description=\"AI voice to use for narration\",\n            default=Voice.LILY,\n            placeholder=Voice.LILY,\n        )\n        video_style: VisualMediaType = SchemaField(\n            description=\"Type of visual media to use for the video\",\n            default=VisualMediaType.STOCK_VIDEOS,\n            placeholder=VisualMediaType.STOCK_VIDEOS,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    credentials: CredentialsMetaInput[\n        Literal[ProviderName.REVID], Literal[\"api_key\"]\n    ] = CredentialsField(\n        description=\"The revid.ai integration can be used with \"\n        \"any API key with sufficient permissions for the blocks it is used on.\",\n    )", "successors": []}, {"id": 3, "label": "    script: str = SchemaField(\n        description=\"\"\"1. Use short and punctuated sentences\\n\\n2. Use linebreaks to create a new clip\\n\\n3. Text outside of brackets is spoken by the AI, and [text between brackets] will be used to guide the visual generation. For example, [close-up of a cat] will show a close-up of a cat.\"\"\",\n        placeholder=\"[close-up of a cat] Meow!\",\n    )", "successors": []}, {"id": 4, "label": "    ratio: str = SchemaField(\n        description=\"Aspect ratio of the video\", default=\"9 / 16\"\n    )", "successors": []}, {"id": 5, "label": "    resolution: str = SchemaField(\n        description=\"Resolution of the video\", default=\"720p\"\n    )", "successors": []}, {"id": 6, "label": "    frame_rate: int = SchemaField(description=\"Frame rate of the video\", default=60)", "successors": []}, {"id": 7, "label": "    generation_preset: GenerationPreset = SchemaField(\n        description=\"Generation preset for visual style - only effects AI generated visuals\",\n        default=GenerationPreset.LEONARDO,\n        placeholder=GenerationPreset.LEONARDO,\n    )", "successors": []}, {"id": 8, "label": "    background_music: AudioTrack = SchemaField(\n        description=\"Background music track\",\n        default=AudioTrack.HIGHWAY_NOCTURNE,\n        placeholder=AudioTrack.HIGHWAY_NOCTURNE,\n    )", "successors": []}, {"id": 9, "label": "    voice: Voice = SchemaField(\n        description=\"AI voice to use for narration\",\n        default=Voice.LILY,\n        placeholder=Voice.LILY,\n    )", "successors": []}, {"id": 10, "label": "    video_style: VisualMediaType = SchemaField(\n        description=\"Type of visual media to use for the video\",\n        default=VisualMediaType.STOCK_VIDEOS,\n        placeholder=VisualMediaType.STOCK_VIDEOS,\n    )", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 182, "end_line": 184, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        video_url: str = SchemaField(description=\"The URL of the created video\")\n        error: str = SchemaField(description=\"Error message if the request failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\nvideo_url: str = SchemaField(description=\"The URL of the created video\")", "successors": [{"id": 3, "label": "error: str = SchemaField(description=\"Error message if the request failed\")", "successors": []}]}]}], "simplified_code": "class AIShortformVideoCreatorBlock(Block):\n        )\n\n        error: str = SchemaField(description=\"Error message if the request failed\")\n\n        )\n\n        return webhook_data[\"uuid\"], f\"https://webhook.site/{webhook_data['uuid']}\"\n\n        return response.json()\n\n        return response.json()\n\n        raise TimeoutError(\"Video creation timed out\")\n\n            yield \"video_url\", video_url", "blocks": [{"id": 1, "label": "class AIShortformVideoCreatorBlock(Block):", "successors": [{"id": 2, "label": "error: str = SchemaField(description=\"Error message if the request failed\")", "successors": []}, {"id": 3, "label": "return webhook_data[\"uuid\"], f\"https://webhook.site/{webhook_data['uuid']}\"", "successors": []}, {"id": 4, "label": "return response.json()", "successors": []}, {"id": 5, "label": "return response.json()", "successors": []}, {"id": 6, "label": "raise TimeoutError(\"Video creation timed out\")", "successors": []}, {"id": 7, "label": "yield \"video_url\", video_url", "successors": []}]}]}], "simplified_code": "import logging\nimport time\nfrom enum import Enum\nfrom typing import Literal\n\nfrom pydantic import SecretStr\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\nfrom backend.util.request import requests\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"revid\",\n    api_key=SecretStr(\"mock-revid-api-key\"),\n    title=\"Mock Revid API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.type,\n}\n\n\n        return audio_urls[self]\n\n\n    MANGA = (\"Manga\",)\n\n\n        return self.value\n\n\n    AI_VIDEO = (\"aiVideo\",)\n\n\nlogger = logging.getLogger(__name__)\n\n\n            yield \"video_url\", video_url", "blocks": [{"id": 1, "label": "import logging\nimport time\nfrom enum import Enum\nfrom typing import Literal\n\nfrom pydantic import SecretStr\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\nfrom backend.util.request import requests", "successors": [{"id": 2, "label": "TEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"revid\",\n    api_key=SecretStr(\"mock-revid-api-key\"),\n    title=\"Mock Revid API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.type,\n}", "successors": [{"id": 4, "label": "return audio_urls[self]", "successors": []}]}, {"id": 5, "label": "MANGA = (\"Manga\",)\nreturn self.value", "successors": []}, {"id": 7, "label": "AI_VIDEO = (\"aiVideo\",)\nlogger = logging.getLogger(__name__)", "successors": [{"id": 9, "label": "yield \"video_url\", video_url", "successors": []}]}]}]}
{"file_name": "70.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 422, "functions": [{"name": "login", "type": "function", "start_line": 48, "end_line": 69, "functions": [], "classes": [], "simplified_code": "def login(\n    provider: Annotated[\n        ProviderName, Path(title=\"The provider to initiate an OAuth flow for\")\n    ],\n    user_id: Annotated[str, Depends(get_user_id)],\n    request: Request,\n    scopes: Annotated[\n        str, Query(title=\"Comma-separated list of authorization scopes\")\n    ] = \"\",\n) -> LoginResponse:\n    handler = _get_provider_oauth_handler(request, provider)\n\n    requested_scopes = scopes.split(\",\") if scopes else []\n\n    # Generate and store a secure random state token along with the scopes\n    state_token = creds_manager.store.store_state_token(\n        user_id, provider, requested_scopes\n    )\n\n    login_url = handler.get_login_url(requested_scopes, state_token)\n\n    return LoginResponse(login_url=login_url, state_token=state_token)", "blocks": [{"id": 1, "label": "def login(provider: Annotated[ProviderName, Path(title=\"The provider to initiate an OAuth flow for\")], user_id: Annotated[str, Depends(get_user_id)], request: Request, scopes: Annotated[str, Query(title=\"Comma-separated list of authorization scopes\")] = \"\") -> LoginResponse:\n    handler = _get_provider_oauth_handler(request, provider)", "successors": [{"id": 3, "label": "    requested_scopes = scopes.split(\",\") if scopes else []\n    state_token = creds_manager.store.store_state_token(user_id, provider, requested_scopes)", "successors": [{"id": 5, "label": "    login_url = handler.get_login_url(requested_scopes, state_token)\n    return LoginResponse(login_url=login_url, state_token=state_token)", "successors": []}]}]}]}, {"name": "callback", "type": "function", "start_line": 82, "end_line": 138, "functions": [], "classes": [], "simplified_code": "def callback(\n    provider: Annotated[\n        ProviderName, Path(title=\"The target provider for this OAuth exchange\")\n    ],\n    code: Annotated[str, Body(title=\"Authorization code acquired by user login\")],\n    state_token: Annotated[str, Body(title=\"Anti-CSRF nonce\")],\n    user_id: Annotated[str, Depends(get_user_id)],\n    request: Request,\n) -> CredentialsMetaResponse:\n    logger.debug(f\"Received OAuth callback for provider: {provider}\")\n    handler = _get_provider_oauth_handler(request, provider)\n\n    # Verify the state token\n    if not creds_manager.store.verify_state_token(user_id, state_token, provider):\n        logger.warning(f\"Invalid or expired state token for user {user_id}\")\n        raise HTTPException(status_code=400, detail=\"Invalid or expired state token\")\n\n    try:\n        scopes = creds_manager.store.get_any_valid_scopes_from_state_token(\n            user_id, state_token, provider\n        )\n        logger.debug(f\"Retrieved scopes from state token: {scopes}\")\n\n        scopes = handler.handle_default_scopes(scopes)\n\n        credentials = handler.exchange_code_for_tokens(code, scopes)\n        logger.debug(f\"Received credentials with final scopes: {credentials.scopes}\")\n\n        # Check if the granted scopes are sufficient for the requested scopes\n        if not set(scopes).issubset(set(credentials.scopes)):\n            # For now, we'll just log the warning and continue\n            logger.warning(\n                f\"Granted scopes {credentials.scopes} for provider {provider.value} \"\n                f\"do not include all requested scopes {scopes}\"\n            )\n\n    except Exception as e:\n        logger.error(f\"Code->Token exchange failed for provider {provider.value}: {e}\")\n        raise HTTPException(\n            status_code=400, detail=f\"Failed to exchange code for tokens: {str(e)}\"\n        )\n\n    # TODO: Allow specifying `title` to set on `credentials`\n    creds_manager.create(user_id, credentials)\n\n    logger.debug(\n        f\"Successfully processed OAuth callback for user {user_id} \"\n        f\"and provider {provider.value}\"\n    )\n    return CredentialsMetaResponse(\n        id=credentials.id,\n        provider=credentials.provider,\n        type=credentials.type,\n        title=credentials.title,\n        scopes=credentials.scopes,\n        username=credentials.username,\n    )", "blocks": [{"id": 1, "label": "def callback(\n    provider: Annotated[\n        ProviderName, Path(title=\"The target provider for this OAuth exchange\")\n    ],\n    code: Annotated[str, Body(title=\"Authorization code acquired by user login\")],\n    state_token: Annotated[str, Body(title=\"Anti-CSRF nonce\")],\n    user_id: Annotated[str, Depends(get_user_id)],\n    request: Request,\n) -> CredentialsMetaResponse:\n    logger.debug(f\"Received OAuth callback for provider: {provider}\")\n    handler = _get_provider_oauth_handler(request, provider)", "successors": [{"id": 3, "label": "if not creds_manager.store.verify_state_token(user_id, state_token, provider):", "successors": [{"id": 4, "label": "    logger.warning(f\"Invalid or expired state token for user {user_id}\")\n    raise HTTPException(status_code=400, detail=\"Invalid or expired state token\")", "successors": []}, {"id": 5, "label": "try:", "successors": [{"id": 6, "label": "    scopes = creds_manager.store.get_any_valid_scopes_from_state_token(\n        user_id, state_token, provider\n    )\n    logger.debug(f\"Retrieved scopes from state token: {scopes}\")\n\n    scopes = handler.handle_default_scopes(scopes)\n\n    credentials = handler.exchange_code_for_tokens(code, scopes)\n    logger.debug(f\"Received credentials with final scopes: {credentials.scopes}\")\nif not set(scopes).issubset(set(credentials.scopes)):", "successors": [{"id": 8, "label": "    logger.warning(\n        f\"Granted scopes {credentials.scopes} for provider {provider.value} \"\n        f\"do not include all requested scopes {scopes}\"\n    )", "successors": []}]}, {"id": 9, "label": "except Exception as e:\n    logger.error(f\"Code->Token exchange failed for provider {provider.value}: {e}\")\n    raise HTTPException(\n        status_code=400, detail=f\"Failed to exchange code for tokens: {str(e)}\"\n    )", "successors": []}]}]}, {"id": 11, "label": "creds_manager.create(user_id, credentials)\n\nlogger.debug(\n    f\"Successfully processed OAuth callback for user {user_id} \"\n    f\"and provider {provider.value}\"\n)\nreturn CredentialsMetaResponse(\n    id=credentials.id,\n    provider=credentials.provider,\n    type=credentials.type,\n    title=credentials.title,\n    scopes=credentials.scopes,\n    username=credentials.username,\n)", "successors": []}]}]}, {"name": "list_credentials", "type": "function", "start_line": 142, "end_line": 156, "functions": [], "classes": [], "simplified_code": "def list_credentials(\n    user_id: Annotated[str, Depends(get_user_id)],\n) -> list[CredentialsMetaResponse]:\n    credentials = creds_manager.store.get_all_creds(user_id)\n    return [\n        CredentialsMetaResponse(\n            id=cred.id,\n            provider=cred.provider,\n            type=cred.type,\n            title=cred.title,\n            scopes=cred.scopes if isinstance(cred, OAuth2Credentials) else None,\n            username=cred.username if isinstance(cred, OAuth2Credentials) else None,\n        )\n        for cred in credentials\n    ]", "blocks": [{"id": 1, "label": "def list_credentials(user_id: Annotated[str, Depends(get_user_id)]) -> list[CredentialsMetaResponse]:\ncredentials = creds_manager.store.get_all_creds(user_id)", "successors": [{"id": 3, "label": "return [\n    CredentialsMetaResponse(\n        id=cred.id,\n        provider=cred.provider,\n        type=cred.type,\n        title=cred.title,\n        scopes=cred.scopes if isinstance(cred, OAuth2Credentials) else None,\n        username=cred.username if isinstance(cred, OAuth2Credentials) else None,\n    )\n    for cred in credentials\n]", "successors": []}]}]}, {"name": "list_credentials_by_provider", "type": "function", "start_line": 160, "end_line": 177, "functions": [], "classes": [], "simplified_code": "def list_credentials_by_provider(\n    provider: Annotated[\n        ProviderName, Path(title=\"The provider to list credentials for\")\n    ],\n    user_id: Annotated[str, Depends(get_user_id)],\n) -> list[CredentialsMetaResponse]:\n    credentials = creds_manager.store.get_creds_by_provider(user_id, provider)\n    return [\n        CredentialsMetaResponse(\n            id=cred.id,\n            provider=cred.provider,\n            type=cred.type,\n            title=cred.title,\n            scopes=cred.scopes if isinstance(cred, OAuth2Credentials) else None,\n            username=cred.username if isinstance(cred, OAuth2Credentials) else None,\n        )\n        for cred in credentials\n    ]", "blocks": [{"id": 1, "label": "def list_credentials_by_provider(provider: Annotated[ProviderName, Path(title=\"The provider to list credentials for\")], user_id: Annotated[str, Depends(get_user_id)]) -> list[CredentialsMetaResponse]:\n    credentials = creds_manager.store.get_creds_by_provider(user_id, provider)", "successors": [{"id": 3, "label": "    return [\n        CredentialsMetaResponse(\n            id=cred.id,\n            provider=cred.provider,\n            type=cred.type,\n            title=cred.title,\n            scopes=cred.scopes if isinstance(cred, OAuth2Credentials) else None,\n            username=cred.username if isinstance(cred, OAuth2Credentials) else None,\n        )\n        for cred in credentials\n    ]", "successors": []}]}]}, {"name": "get_credential", "type": "function", "start_line": 181, "end_line": 195, "functions": [], "classes": [], "simplified_code": "def get_credential(\n    provider: Annotated[\n        ProviderName, Path(title=\"The provider to retrieve credentials for\")\n    ],\n    cred_id: Annotated[str, Path(title=\"The ID of the credentials to retrieve\")],\n    user_id: Annotated[str, Depends(get_user_id)],\n) -> Credentials:\n    credential = creds_manager.get(user_id, cred_id)\n    if not credential:\n        raise HTTPException(status_code=404, detail=\"Credentials not found\")\n    if credential.provider != provider:\n        raise HTTPException(\n            status_code=404, detail=\"Credentials do not match the specified provider\"\n        )\n    return credential", "blocks": [{"id": 1, "label": "def get_credential(provider: Annotated[ProviderName, Path(title=\"The provider to retrieve credentials for\")], cred_id: Annotated[str, Path(title=\"The ID of the credentials to retrieve\")], user_id: Annotated[str, Depends(get_user_id)]) -> Credentials:\n    credential = creds_manager.get(user_id, cred_id)\nif not credential:", "successors": [{"id": 3, "label": "raise HTTPException(status_code=404, detail=\"Credentials not found\")", "successors": []}, {"id": 4, "label": "if credential.provider != provider:", "successors": [{"id": 5, "label": "raise HTTPException(status_code=404, detail=\"Credentials do not match the specified provider\")", "successors": []}, {"id": 6, "label": "return credential", "successors": []}]}]}]}, {"name": "create_api_key_credentials", "type": "function", "start_line": 199, "end_line": 223, "functions": [], "classes": [], "simplified_code": "def create_api_key_credentials(\n    user_id: Annotated[str, Depends(get_user_id)],\n    provider: Annotated[\n        ProviderName, Path(title=\"The provider to create credentials for\")\n    ],\n    api_key: Annotated[str, Body(title=\"The API key to store\")],\n    title: Annotated[str, Body(title=\"Optional title for the credentials\")],\n    expires_at: Annotated[\n        int | None, Body(title=\"Unix timestamp when the key expires\")\n    ] = None,\n) -> APIKeyCredentials:\n    new_credentials = APIKeyCredentials(\n        provider=provider,\n        api_key=SecretStr(api_key),\n        title=title,\n        expires_at=expires_at,\n    )\n\n    try:\n        creds_manager.create(user_id, new_credentials)\n    except Exception as e:\n        raise HTTPException(\n            status_code=500, detail=f\"Failed to store credentials: {str(e)}\"\n        )\n    return new_credentials", "blocks": [{"id": 1, "label": "def create_api_key_credentials(    user_id: Annotated[str, Depends(get_user_id)],    provider: Annotated[        ProviderName, Path(title=\"The provider to create credentials for\")    ],    api_key: Annotated[str, Body(title=\"The API key to store\")],    title: Annotated[str, Body(title=\"Optional title for the credentials\")],    expires_at: Annotated[        int | None, Body(title=\"Unix timestamp when the key expires\")    ] = None,) -> APIKeyCredentials:\nnew_credentials = APIKeyCredentials(    provider=provider,    api_key=SecretStr(api_key),    title=title,    expires_at=expires_at,)", "successors": [{"id": 3, "label": "try:\n    creds_manager.create(user_id, new_credentials)", "successors": [{"id": 4, "label": "except Exception as e:\n    raise HTTPException(        status_code=500, detail=f\"Failed to store credentials: {str(e)}\")\nreturn new_credentials", "successors": []}, {"id": 5, "label": "return new_credentials", "successors": []}]}]}]}, {"name": "delete_credentials", "type": "function", "start_line": 242, "end_line": 273, "functions": [], "classes": [], "simplified_code": "async def delete_credentials(\n    request: Request,\n    provider: Annotated[\n        ProviderName, Path(title=\"The provider to delete credentials for\")\n    ],\n    cred_id: Annotated[str, Path(title=\"The ID of the credentials to delete\")],\n    user_id: Annotated[str, Depends(get_user_id)],\n    force: Annotated[\n        bool, Query(title=\"Whether to proceed if any linked webhooks are still in use\")\n    ] = False,\n) -> CredentialsDeletionResponse | CredentialsDeletionNeedsConfirmationResponse:\n    creds = creds_manager.store.get_creds_by_id(user_id, cred_id)\n    if not creds:\n        raise HTTPException(status_code=404, detail=\"Credentials not found\")\n    if creds.provider != provider:\n        raise HTTPException(\n            status_code=404, detail=\"Credentials do not match the specified provider\"\n        )\n\n    try:\n        await remove_all_webhooks_for_credentials(creds, force)\n    except NeedConfirmation as e:\n        return CredentialsDeletionNeedsConfirmationResponse(message=str(e))\n\n    creds_manager.delete(user_id, cred_id)\n\n    tokens_revoked = None\n    if isinstance(creds, OAuth2Credentials):\n        handler = _get_provider_oauth_handler(request, provider)\n        tokens_revoked = handler.revoke_tokens(creds)\n\n    return CredentialsDeletionResponse(revoked=tokens_revoked)", "blocks": [{"id": 1, "label": "creds = creds_manager.store.get_creds_by_id(user_id, cred_id)\nif not creds:", "successors": [{"id": 3, "label": "raise HTTPException(status_code=404, detail=\"Credentials not found\")", "successors": []}, {"id": 4, "label": "if creds.provider != provider:", "successors": [{"id": 5, "label": "raise HTTPException(\n    status_code=404, detail=\"Credentials do not match the specified provider\"\n)", "successors": []}, {"id": 6, "label": "try:", "successors": [{"id": 7, "label": "await remove_all_webhooks_for_credentials(creds, force)\ncreds_manager.delete(user_id, cred_id)", "successors": [{"id": 10, "label": "tokens_revoked = None\nif isinstance(creds, OAuth2Credentials):", "successors": [{"id": 12, "label": "handler = _get_provider_oauth_handler(request, provider)\ntokens_revoked = handler.revoke_tokens(creds)\nreturn CredentialsDeletionResponse(revoked=tokens_revoked)", "successors": []}, {"id": 13, "label": "return CredentialsDeletionResponse(revoked=tokens_revoked)", "successors": []}]}]}, {"id": 8, "label": "except NeedConfirmation as e:\nreturn CredentialsDeletionNeedsConfirmationResponse(message=str(e))", "successors": []}]}]}]}]}, {"name": "webhook_ingress_generic", "type": "function", "start_line": 283, "end_line": 323, "functions": [], "classes": [], "simplified_code": "async def webhook_ingress_generic(\n    request: Request,\n    provider: Annotated[\n        ProviderName, Path(title=\"Provider where the webhook was registered\")\n    ],\n    webhook_id: Annotated[str, Path(title=\"Our ID for the webhook\")],\n):\n    logger.debug(f\"Received {provider.value} webhook ingress for ID {webhook_id}\")\n    webhook_manager = WEBHOOK_MANAGERS_BY_NAME[provider]()\n    webhook = await get_webhook(webhook_id)\n    logger.debug(f\"Webhook #{webhook_id}: {webhook}\")\n    payload, event_type = await webhook_manager.validate_payload(webhook, request)\n    logger.debug(\n        f\"Validated {provider.value} {webhook.webhook_type} {event_type} event \"\n        f\"with payload {payload}\"\n    )\n\n    webhook_event = WebhookEvent(\n        provider=provider,\n        webhook_id=webhook_id,\n        event_type=event_type,\n        payload=payload,\n    )\n    await publish_webhook_event(webhook_event)\n    logger.debug(f\"Webhook event published: {webhook_event}\")\n\n    if not webhook.attached_nodes:\n        return\n\n    executor = get_service_client(ExecutionManager)\n    for node in webhook.attached_nodes:\n        logger.debug(f\"Webhook-attached node: {node}\")\n        if not node.is_triggered_by_event_type(event_type):\n            logger.debug(f\"Node #{node.id} doesn't trigger on event {event_type}\")\n            continue\n        logger.debug(f\"Executing graph #{node.graph_id} node #{node.id}\")\n        executor.add_execution(\n            node.graph_id,\n            data={f\"webhook_{webhook_id}_payload\": payload},\n            user_id=webhook.user_id,\n        )", "blocks": [{"id": 1, "label": "logger.debug(f\"Received {provider.value} webhook ingress for ID {webhook_id}\")\nwebhook_manager = WEBHOOK_MANAGERS_BY_NAME[provider]()", "successors": [{"id": 3, "label": "webhook = await get_webhook(webhook_id)\nlogger.debug(f\"Webhook #{webhook_id}: {webhook}\")", "successors": [{"id": 5, "label": "payload, event_type = await webhook_manager.validate_payload(webhook, request)\nlogger.debug(f\"Validated {provider.value} {webhook.webhook_type} {event_type} event with payload {payload}\")", "successors": [{"id": 7, "label": "webhook_event = WebhookEvent(provider=provider, webhook_id=webhook_id, event_type=event_type, payload=payload)\nawait publish_webhook_event(webhook_event)", "successors": [{"id": 9, "label": "logger.debug(f\"Webhook event published: {webhook_event}\")", "successors": [{"id": 10, "label": "if not webhook.attached_nodes:\nreturn", "successors": []}, {"id": 12, "label": "executor = get_service_client(ExecutionManager)", "successors": [{"id": 13, "label": "for node in webhook.attached_nodes:", "successors": [{"id": 14, "label": "logger.debug(f\"Webhook-attached node: {node}\")", "successors": [{"id": 15, "label": "if not node.is_triggered_by_event_type(event_type):\nlogger.debug(f\"Node #{node.id} doesn't trigger on event {event_type}\")", "successors": [{"id": 17, "label": "continue", "successors": []}]}, {"id": 18, "label": "logger.debug(f\"Executing graph #{node.graph_id} node #{node.id}\")\nexecutor.add_execution(node.graph_id, data={f\"webhook_{webhook_id}_payload\": payload}, user_id=webhook.user_id)", "successors": []}]}]}]}]}]}]}]}]}]}, {"name": "webhook_ping", "type": "function", "start_line": 327, "end_line": 347, "functions": [], "classes": [], "simplified_code": "async def webhook_ping(\n    webhook_id: Annotated[str, Path(title=\"Our ID for the webhook\")],\n    user_id: Annotated[str, Depends(get_user_id)],  # require auth\n):\n    webhook = await get_webhook(webhook_id)\n    webhook_manager = WEBHOOK_MANAGERS_BY_NAME[webhook.provider]()\n\n    credentials = (\n        creds_manager.get(user_id, webhook.credentials_id)\n        if webhook.credentials_id\n        else None\n    )\n    try:\n        await webhook_manager.trigger_ping(webhook, credentials)\n    except NotImplementedError:\n        return False\n\n    if not await wait_for_webhook_event(webhook_id, event_type=\"ping\", timeout=10):\n        raise HTTPException(status_code=504, detail=\"Webhook ping timed out\")\n\n    return True", "blocks": [{"id": 1, "label": "async def webhook_ping(\n    webhook_id: Annotated[str, Path(title=\"Our ID for the webhook\")],\n    user_id: Annotated[str, Depends(get_user_id)],  # require auth\n):\n    webhook = await get_webhook(webhook_id)\n    webhook_manager = WEBHOOK_MANAGERS_BY_NAME[webhook.provider]()\n\n    credentials = (\n        creds_manager.get(user_id, webhook.credentials_id)\n        if webhook.credentials_id\n        else None\n    )", "successors": [{"id": 2, "label": "try:\n        await webhook_manager.trigger_ping(webhook, credentials)\nexcept NotImplementedError:\n        return False", "successors": [{"id": 6, "label": "if not await wait_for_webhook_event(webhook_id, event_type=\"ping\", timeout=10):\n        raise HTTPException(status_code=504, detail=\"Webhook ping timed out\")\nreturn True", "successors": []}]}, {"id": 4, "label": "await webhook_manager.trigger_ping(webhook, credentials)\nif not await wait_for_webhook_event(webhook_id, event_type=\"ping\", timeout=10):\n        raise HTTPException(status_code=504, detail=\"Webhook ping timed out\")", "successors": [{"id": 7, "label": "return True", "successors": []}]}]}]}, {"name": "remove_all_webhooks_for_credentials", "type": "function", "start_line": 353, "end_line": 391, "functions": [], "classes": [], "simplified_code": "async def remove_all_webhooks_for_credentials(\n    credentials: Credentials, force: bool = False\n) -> None:\n    \"\"\"\n    Remove and deregister all webhooks that were registered using the given credentials.\n\n    Params:\n        credentials: The credentials for which to remove the associated webhooks.\n        force: Whether to proceed if any of the webhooks are still in use.\n\n    Raises:\n        NeedConfirmation: If any of the webhooks are still in use and `force` is `False`\n    \"\"\"\n    webhooks = await get_all_webhooks_by_creds(credentials.id)\n    if credentials.provider not in WEBHOOK_MANAGERS_BY_NAME:\n        if webhooks:\n            logger.error(\n                f\"Credentials #{credentials.id} for provider {credentials.provider} \"\n                f\"are attached to {len(webhooks)} webhooks, \"\n                f\"but there is no available WebhooksHandler for {credentials.provider}\"\n            )\n        return\n    if any(w.attached_nodes for w in webhooks) and not force:\n        raise NeedConfirmation(\n            \"Some webhooks linked to these credentials are still in use by an agent\"\n        )\n    for webhook in webhooks:\n        # Unlink all nodes\n        for node in webhook.attached_nodes or []:\n            await set_node_webhook(node.id, None)\n\n        # Prune the webhook\n        webhook_manager = WEBHOOK_MANAGERS_BY_NAME[credentials.provider]()\n        success = await webhook_manager.prune_webhook_if_dangling(\n            webhook.id, credentials\n        )\n        if not success:\n            logger.warning(f\"Webhook #{webhook.id} failed to prune\")\n", "blocks": [{"id": 1, "label": "webhooks = await get_all_webhooks_by_creds(credentials.id)", "successors": [{"id": 2, "label": "if credentials.provider not in WEBHOOK_MANAGERS_BY_NAME:\nif webhooks:", "successors": [{"id": 4, "label": "logger.error(\n    f\"Credentials #{credentials.id} for provider {credentials.provider} \"\n    f\"are attached to {len(webhooks)} webhooks, \"\n    f\"but there is no available WebhooksHandler for {credentials.provider}\"\n)\nreturn", "successors": []}, {"id": 5, "label": "return", "successors": []}]}, {"id": 6, "label": "if any(w.attached_nodes for w in webhooks) and not force:\nraise NeedConfirmation(\n    \"Some webhooks linked to these credentials are still in use by an agent\"\n)", "successors": []}, {"id": 8, "label": "for webhook in webhooks:", "successors": [{"id": 9, "label": "# Unlink all nodes\nfor node in webhook.attached_nodes or []:\n    await set_node_webhook(node.id, None)\n# Prune the webhook\nwebhook_manager = WEBHOOK_MANAGERS_BY_NAME[credentials.provider]()\nsuccess = await webhook_manager.prune_webhook_if_dangling(\n    webhook.id, credentials\n)", "successors": [{"id": 11, "label": "if not success:\nlogger.warning(f\"Webhook #{webhook.id} failed to prune\")", "successors": [{"id": 8, "label": "for webhook in webhooks:", "successors": [{"id": 9, "label": "# Unlink all nodes\nfor node in webhook.attached_nodes or []:\n    await set_node_webhook(node.id, None)\n# Prune the webhook\nwebhook_manager = WEBHOOK_MANAGERS_BY_NAME[credentials.provider]()\nsuccess = await webhook_manager.prune_webhook_if_dangling(\n    webhook.id, credentials\n)", "successors": [{"id": 11, "label": "if not success:\nlogger.warning(f\"Webhook #{webhook.id} failed to prune\")", "successors": []}]}]}]}]}]}]}]}, {"name": "_get_provider_oauth_handler", "type": "function", "start_line": 393, "end_line": 422, "functions": [], "classes": [], "simplified_code": "def _get_provider_oauth_handler(\n    req: Request, provider_name: ProviderName\n) -> \"BaseOAuthHandler\":\n    if provider_name not in HANDLERS_BY_NAME:\n        raise HTTPException(\n            status_code=404,\n            detail=f\"Provider '{provider_name.value}' does not support OAuth\",\n        )\n\n    client_id = getattr(settings.secrets, f\"{provider_name.value}_client_id\")\n    client_secret = getattr(settings.secrets, f\"{provider_name.value}_client_secret\")\n    if not (client_id and client_secret):\n        raise HTTPException(\n            status_code=501,\n            detail=(\n                f\"Integration with provider '{provider_name.value}' is not configured\"\n            ),\n        )\n\n    handler_class = HANDLERS_BY_NAME[provider_name]\n    frontend_base_url = (\n        settings.config.frontend_base_url\n        or settings.config.platform_base_url\n        or str(req.base_url)\n    )\n    return handler_class(\n        client_id=client_id,\n        client_secret=client_secret,\n        redirect_uri=f\"{frontend_base_url}/auth/integrations/oauth_callback\",\n    )", "blocks": [{"id": 1, "label": "def _get_provider_oauth_handler(\n    req: Request, provider_name: ProviderName\n) -> \"BaseOAuthHandler\":", "successors": [{"id": 2, "label": "if provider_name not in HANDLERS_BY_NAME:\nraise HTTPException(\n    status_code=404,\n    detail=f\"Provider '{provider_name.value}' does not support OAuth\",\n)", "successors": []}, {"id": 4, "label": "client_id = getattr(settings.secrets, f\"{provider_name.value}_client_id\")\nclient_secret = getattr(settings.secrets, f\"{provider_name.value}_client_secret\")", "successors": [{"id": 5, "label": "if not (client_id and client_secret):\nraise HTTPException(\n    status_code=501,\n    detail=(\n        f\"Integration with provider '{provider_name.value}' is not configured\"\n    ),\n)", "successors": []}, {"id": 7, "label": "handler_class = HANDLERS_BY_NAME[provider_name]\nfrontend_base_url = (\n    settings.config.frontend_base_url\n    or settings.config.platform_base_url\n    or str(req.base_url)\n)\nreturn handler_class(\n    client_id=client_id,\n    client_secret=client_secret,\n    redirect_uri=f\"{frontend_base_url}/auth/integrations/oauth_callback\",\n)", "successors": []}]}]}]}], "classes": [{"name": "LoginResponse", "type": "class", "start_line": 42, "end_line": 44, "functions": [], "classes": [], "simplified_code": "class LoginResponse(BaseModel):\n    login_url: str\n    state_token: str", "blocks": [{"id": 1, "label": "class LoginResponse(BaseModel):\n    login_url: str\n    state_token: str", "successors": []}]}, {"name": "CredentialsMetaResponse", "type": "class", "start_line": 72, "end_line": 78, "functions": [], "classes": [], "simplified_code": "class CredentialsMetaResponse(BaseModel):\n    id: str\n    provider: str\n    type: CredentialsType\n    title: str | None\n    scopes: list[str] | None\n    username: str | None", "blocks": [{"id": 1, "label": "class CredentialsMetaResponse(BaseModel):\n    id: str", "successors": [{"id": 3, "label": "    provider: str\n    type: CredentialsType", "successors": [{"id": 5, "label": "    title: str | None\n    scopes: list[str] | None", "successors": [{"id": 7, "label": "    username: str | None", "successors": []}]}]}]}]}, {"name": "CredentialsDeletionResponse", "type": "class", "start_line": 226, "end_line": 232, "functions": [], "classes": [], "simplified_code": "class CredentialsDeletionResponse(BaseModel):\n    deleted: Literal[True] = True\n    revoked: bool | None = Field(\n        description=\"Indicates whether the credentials were also revoked by their \"\n        \"provider. `None`/`null` if not applicable, e.g. when deleting \"\n        \"non-revocable credentials such as API keys.\"\n    )", "blocks": [{"id": 1, "label": "class CredentialsDeletionResponse(BaseModel):\n    deleted: Literal[True] = True", "successors": [{"id": 3, "label": "    revoked: bool | None = Field(     description=\"Indicates whether the credentials were also revoked by their \"     \"provider. `None`/`null` if not applicable, e.g. when deleting \"     \"non-revocable credentials such as API keys.\")", "successors": []}]}]}, {"name": "CredentialsDeletionNeedsConfirmationResponse", "type": "class", "start_line": 235, "end_line": 238, "functions": [], "classes": [], "simplified_code": "class CredentialsDeletionNeedsConfirmationResponse(BaseModel):\n    deleted: Literal[False] = False\n    need_confirmation: Literal[True] = True\n    message: str", "blocks": [{"id": 1, "label": "class CredentialsDeletionNeedsConfirmationResponse(BaseModel):", "successors": [{"id": 2, "label": "    deleted: Literal[False] = False", "successors": []}, {"id": 3, "label": "    need_confirmation: Literal[True] = True", "successors": []}, {"id": 4, "label": "    message: str", "successors": []}]}]}], "simplified_code": "import logging\nfrom typing import TYPE_CHECKING, Annotated, Literal\n\nfrom fastapi import APIRouter, Body, Depends, HTTPException, Path, Query, Request\nfrom pydantic import BaseModel, Field, SecretStr\n\nfrom backend.data.graph import set_node_webhook\nfrom backend.data.integrations import (\n    WebhookEvent,\n    get_all_webhooks_by_creds,\n    get_webhook,\n    publish_webhook_event,\n    wait_for_webhook_event,\n)\nfrom backend.data.model import (\n    APIKeyCredentials,\n    Credentials,\n    CredentialsType,\n    OAuth2Credentials,\n)\nfrom backend.executor.manager import ExecutionManager\nfrom backend.integrations.creds_manager import IntegrationCredentialsManager\nfrom backend.integrations.oauth import HANDLERS_BY_NAME\nfrom backend.integrations.providers import ProviderName\nfrom backend.integrations.webhooks import WEBHOOK_MANAGERS_BY_NAME\nfrom backend.util.exceptions import NeedConfirmation\nfrom backend.util.service import get_service_client\nfrom backend.util.settings import Settings\n\nif TYPE_CHECKING:\n    from backend.integrations.oauth import BaseOAuthHandler\n\nfrom ..utils import get_user_id\n\nlogger = logging.getLogger(__name__)\nsettings = Settings()\nrouter = APIRouter()\n\ncreds_manager = IntegrationCredentialsManager()\n\n\n    state_token: str\n\n\n@router.get(\"/{provider}/login\")\n    return LoginResponse(login_url=login_url, state_token=state_token)\n\n\n    username: str | None\n\n\n@router.post(\"/{provider}/callback\")\n    )\n\n\n@router.get(\"/credentials\")\n    ]\n\n\n@router.get(\"/{provider}/credentials\")\n    ]\n\n\n@router.get(\"/{provider}/credentials/{cred_id}\")\n    return credential\n\n\n@router.post(\"/{provider}/credentials\", status_code=201)\n    return new_credentials\n\n\n    )\n\n\n    message: str\n\n\n@router.delete(\"/{provider}/credentials/{cred_id}\")\n    return CredentialsDeletionResponse(revoked=tokens_revoked)\n\n\n# ------------------------- WEBHOOK STUFF -------------------------- #\n\n\n# \u26a0\ufe0f Note\n# No user auth check because this endpoint is for webhook ingress and relies on\n# validation by the provider-specific `WebhooksManager`.\n@router.post(\"/{provider}/webhooks/{webhook_id}/ingress\")\n        )\n\n\n@router.post(\"/webhooks/{webhook_id}/ping\")\n    return True\n\n\n# --------------------------- UTILITIES ---------------------------- #\n\n\n\n\n    )", "blocks": [{"id": 1, "label": "import logging\nfrom typing import TYPE_CHECKING, Annotated, Literal\n\nfrom fastapi import APIRouter, Body, Depends, HTTPException, Path, Query, Request\nfrom pydantic import BaseModel, Field, SecretStr\n\nfrom backend.data.graph import set_node_webhook\nfrom backend.data.integrations import (\n    WebhookEvent,\n    get_all_webhooks_by_creds,\n    get_webhook,\n    publish_webhook_event,\n    wait_for_webhook_event,\n)\nfrom backend.data.model import (\n    APIKeyCredentials,\n    Credentials,\n    CredentialsType,\n    OAuth2Credentials,\n)\nfrom backend.executor.manager import ExecutionManager\nfrom backend.integrations.creds_manager import IntegrationCredentialsManager\nfrom backend.integrations.oauth import HANDLERS_BY_NAME\nfrom backend.integrations.providers import ProviderName\nfrom backend.integrations.webhooks import WEBHOOK_MANAGERS_BY_NAME\nfrom backend.util.exceptions import NeedConfirmation\nfrom backend.util.service import get_service_client\nfrom backend.util.settings import Settings\n\nif TYPE_CHECKING:\n    from backend.integrations.oauth import BaseOAuthHandler\n\nfrom ..utils import get_user_id\n\nlogger = logging.getLogger(__name__)\nsettings = Settings()\nrouter = APIRouter()\n\ncreds_manager = IntegrationCredentialsManager()\n@router.get(\"/{provider}/login\")\n    return LoginResponse(login_url=login_url, state_token=state_token)", "successors": [{"id": 3, "label": "@router.post(\"/{provider}/callback\")\n@router.get(\"/credentials\")", "successors": [{"id": 5, "label": "@router.get(\"/{provider}/credentials\")\n@router.get(\"/{provider}/credentials/{cred_id}\")\n    return credential", "successors": [{"id": 7, "label": "@router.post(\"/{provider}/credentials\", status_code=201)\n    return new_credentials\n@router.delete(\"/{provider}/credentials/{cred_id}\")\n    return CredentialsDeletionResponse(revoked=tokens_revoked)", "successors": [{"id": 9, "label": "@router.post(\"/{provider}/webhooks/{webhook_id}/ingress\")\n@router.post(\"/webhooks/{webhook_id}/ping\")\n    return True", "successors": []}]}]}]}]}]}
{"file_name": "71.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 133, "functions": [{"name": "is_safe", "type": "function", "start_line": 44, "end_line": 60, "functions": [], "classes": [], "simplified_code": "def is_safe(grid: Matrix, row: int, column: int, n: int) -> bool:\n    \"\"\"\n    This function checks the grid to see if each row,\n    column, and the 3x3 subgrids contain the digit 'n'.\n    It returns False if it is not 'safe' (a duplicate digit\n    is found) else returns True if it is 'safe'\n    \"\"\"\n    for i in range(9):\n        if n in {grid[row][i], grid[i][column]}:\n            return False\n\n    for i in range(3):\n        for j in range(3):\n            if grid[(row - row % 3) + i][(column - column % 3) + j] == n:\n                return False\n\n    return True", "blocks": [{"id": 1, "label": "def is_safe(grid: Matrix, row: int, column: int, n: int) -> bool:", "successors": [{"id": 2, "label": "for i in range(9):", "successors": [{"id": 3, "label": "if n in {grid[row][i], grid[i][column]}:\nreturn False", "successors": []}, {"id": 5, "label": "for i in range(3):", "successors": [{"id": 6, "label": "for j in range(3):", "successors": [{"id": 7, "label": "if grid[(row - row % 3) + i][(column - column % 3) + j] == n:\nreturn False", "successors": []}, {"id": 9, "label": "return True", "successors": []}]}]}]}]}]}, {"name": "find_empty_location", "type": "function", "start_line": 63, "end_line": 72, "functions": [], "classes": [], "simplified_code": "def find_empty_location(grid: Matrix) -> tuple[int, int] | None:\n    \"\"\"\n    This function finds an empty location so that we can assign a number\n    for that particular row and column.\n    \"\"\"\n    for i in range(9):\n        for j in range(9):\n            if grid[i][j] == 0:\n                return i, j\n    return None", "blocks": [{"id": 1, "label": "def find_empty_location(grid: Matrix) -> tuple[int, int] | None:\n    \"\"\"\n    This function finds an empty location so that we can assign a number\n    for that particular row and column.\n    \"\"\"", "successors": [{"id": 2, "label": "for i in range(9):", "successors": [{"id": 3, "label": "    for j in range(9):", "successors": [{"id": 4, "label": "        if grid[i][j] == 0:\n            return i, j", "successors": []}]}, {"id": 6, "label": "return None", "successors": []}]}]}]}, {"name": "sudoku", "type": "function", "start_line": 75, "end_line": 109, "functions": [], "classes": [], "simplified_code": "def sudoku(grid: Matrix) -> Matrix | None:\n    \"\"\"\n    Takes a partially filled-in grid and attempts to assign values to\n    all unassigned locations in such a way to meet the requirements\n    for Sudoku solution (non-duplication across rows, columns, and boxes)\n\n    >>> sudoku(initial_grid)  # doctest: +NORMALIZE_WHITESPACE\n    [[3, 1, 6, 5, 7, 8, 4, 9, 2],\n     [5, 2, 9, 1, 3, 4, 7, 6, 8],\n     [4, 8, 7, 6, 2, 9, 5, 3, 1],\n     [2, 6, 3, 4, 1, 5, 9, 8, 7],\n     [9, 7, 4, 8, 6, 3, 1, 2, 5],\n     [8, 5, 1, 7, 9, 2, 6, 4, 3],\n     [1, 3, 8, 9, 4, 7, 2, 5, 6],\n     [6, 9, 2, 3, 5, 1, 8, 7, 4],\n     [7, 4, 5, 2, 8, 6, 3, 1, 9]]\n     >>> sudoku(no_solution) is None\n     True\n    \"\"\"\n    if location := find_empty_location(grid):\n        row, column = location\n    else:\n        # If the location is ``None``, then the grid is solved.\n        return grid\n\n    for digit in range(1, 10):\n        if is_safe(grid, row, column, digit):\n            grid[row][column] = digit\n\n            if sudoku(grid) is not None:\n                return grid\n\n            grid[row][column] = 0\n\n    return None", "blocks": [{"id": 1, "label": "def sudoku(grid: Matrix) -> Matrix | None:", "successors": [{"id": 2, "label": "if location := find_empty_location(grid):\nrow, column = location", "successors": [{"id": 5, "label": "for digit in range(1, 10):", "successors": [{"id": 6, "label": "if is_safe(grid, row, column, digit):\ngrid[row][column] = digit", "successors": [{"id": 8, "label": "if sudoku(grid) is not None:\nreturn grid", "successors": []}, {"id": 10, "label": "grid[row][column] = 0", "successors": []}]}]}, {"id": 11, "label": "return None", "successors": []}]}, {"id": 4, "label": "return grid", "successors": []}]}]}, {"name": "print_solution", "type": "function", "start_line": 112, "end_line": 120, "functions": [], "classes": [], "simplified_code": "def print_solution(grid: Matrix) -> None:\n    \"\"\"\n    A function to print the solution in the form\n    of a 9x9 grid\n    \"\"\"\n    for row in grid:\n        for cell in row:\n            print(cell, end=\" \")\n        print()", "blocks": [{"id": 1, "label": "def print_solution(grid: Matrix) -> None:", "successors": [{"id": 2, "label": "for row in grid:", "successors": [{"id": 3, "label": "    for cell in row:", "successors": [{"id": 4, "label": "        print(cell, end=\" \")\n    print()", "successors": []}]}, {"id": 5, "label": "    print()", "successors": []}]}]}]}], "classes": [], "simplified_code": "\"\"\"\nGiven a partially filled 9x9 2D array, the objective is to fill a 9x9\nsquare grid with digits numbered 1 to 9, so that every row, column, and\nand each of the nine 3x3 sub-grids contains all of the digits.\n\nThis can be solved using Backtracking and is similar to n-queens.\nWe check to see if a cell is safe or not and recursively call the\nfunction on the next column to see if it returns True. if yes, we\nhave solved the puzzle. else, we backtrack and place another number\nin that cell and repeat this process.\n\"\"\"\n\nfrom __future__ import annotations\n\nMatrix = list[list[int]]\n\n# assigning initial values to the grid\ninitial_grid: Matrix = [\n    [3, 0, 6, 5, 0, 8, 4, 0, 0],\n    [5, 2, 0, 0, 0, 0, 0, 0, 0],\n    [0, 8, 7, 0, 0, 0, 0, 3, 1],\n    [0, 0, 3, 0, 1, 0, 0, 8, 0],\n    [9, 0, 0, 8, 6, 3, 0, 0, 5],\n    [0, 5, 0, 0, 9, 0, 6, 0, 0],\n    [1, 3, 0, 0, 0, 0, 2, 5, 0],\n    [0, 0, 0, 0, 0, 0, 0, 7, 4],\n    [0, 0, 5, 2, 0, 6, 3, 0, 0],\n]\n\n# a grid with no solution\nno_solution: Matrix = [\n    [5, 0, 6, 5, 0, 8, 4, 0, 3],\n    [5, 2, 0, 0, 0, 0, 0, 0, 2],\n    [1, 8, 7, 0, 0, 0, 0, 3, 1],\n    [0, 0, 3, 0, 1, 0, 0, 8, 0],\n    [9, 0, 0, 8, 6, 3, 0, 0, 5],\n    [0, 5, 0, 0, 9, 0, 6, 0, 0],\n    [1, 3, 0, 0, 0, 0, 2, 5, 0],\n    [0, 0, 0, 0, 0, 0, 0, 7, 4],\n    [0, 0, 5, 2, 0, 6, 3, 0, 0],\n]\n\n\n    return True\n\n\n    return None\n\n\n    return None\n\n\n        print()\n\n\nif __name__ == \"__main__\":\n    # make a copy of grid so that you can compare with the unmodified grid\n    for example_grid in (initial_grid, no_solution):\n        print(\"\\nExample grid:\\n\" + \"=\" * 20)\n        print_solution(example_grid)\n        print(\"\\nExample grid solution:\")\n        solution = sudoku(example_grid)\n        if solution is not None:\n            print_solution(solution)\n        else:\n            print(\"Cannot find a solution.\")", "blocks": [{"id": 1, "label": "from __future__ import annotations\n\nMatrix = list[list[int]]\n\n# assigning initial values to the grid\ninitial_grid: Matrix = [\n [3, 0, 6, 5, 0, 8, 4, 0, 0],\n [5, 2, 0, 0, 0, 0, 0, 0, 0],\n [0, 8, 7, 0, 0, 0, 0, 3, 1],\n [0, 0, 3, 0, 1, 0, 0, 8, 0],\n [9, 0, 0, 8, 6, 3, 0, 0, 5],\n [0, 5, 0, 0, 9, 0, 6, 0, 0],\n [1, 3, 0, 0, 0, 0, 2, 5, 0],\n [0, 0, 0, 0, 0, 0, 0, 7, 4],\n [0, 0, 5, 2, 0, 6, 3, 0, 0],\n]\n\n# a grid with no solution\nno_solution: Matrix = [\n [5, 0, 6, 5, 0, 8, 4, 0, 3],\n [5, 2, 0, 0, 0, 0, 0, 0, 2],\n [1, 8, 7, 0, 0, 0, 0, 3, 1],\n [0, 0, 3, 0, 1, 0, 0, 8, 0],\n [9, 0, 0, 8, 6, 3, 0, 0, 5],\n [0, 5, 0, 0, 9, 0, 6, 0, 0],\n [1, 3, 0, 0, 0, 0, 2, 5, 0],\n [0, 0, 0, 0, 0, 0, 0, 7, 4],\n [0, 0, 5, 2, 0, 6, 3, 0, 0],\n]\nif __name__ == \"__main__\":", "successors": [{"id": 3, "label": " # make a copy of grid so that you can compare with the unmodified grid\nfor example_grid in (initial_grid, no_solution):\n print(\"\\nExample grid:\\n\" + \"=\" * 20)\n print_solution(example_grid)\n print(\"\\nExample grid solution:\")\n solution = sudoku(example_grid)\n if solution is not None:\n print_solution(solution)\n else:\n print(\"Cannot find a solution.\")", "successors": []}]}]}
{"file_name": "72.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 78, "functions": [], "classes": [{"name": "HttpMethod", "type": "class", "start_line": 10, "end_line": 17, "functions": [], "simplified_code": "class HttpMethod(Enum):\n    GET = \"GET\"\n    POST = \"POST\"\n    PUT = \"PUT\"\n    DELETE = \"DELETE\"\n    PATCH = \"PATCH\"\n    OPTIONS = \"OPTIONS\"\n    HEAD = \"HEAD\"", "blocks": [{"id": 1, "label": "class HttpMethod(Enum):\n    GET = \"GET\"\n    POST = \"POST\"\n    PUT = \"PUT\"\n    DELETE = \"DELETE\"\n    PATCH = \"PATCH\"\n    OPTIONS = \"OPTIONS\"\n    HEAD = \"HEAD\"", "successors": []}]}, {"name": "SendWebRequestBlock", "type": "class", "start_line": 20, "end_line": 78, "functions": [{"name": "__init__", "type": "function", "start_line": 49, "end_line": 56, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"6595ae1f-b924-42cb-9a41-551a0611c4b4\",\n            description=\"This block makes an HTTP request to the given URL.\",\n            categories={BlockCategory.OUTPUT},\n            input_schema=SendWebRequestBlock.Input,\n            output_schema=SendWebRequestBlock.Output,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"6595ae1f-b924-42cb-9a41-551a0611c4b4\",\n    description=\"This block makes an HTTP request to the given URL.\",\n    categories={BlockCategory.OUTPUT},\n    input_schema=SendWebRequestBlock.Input,\n    output_schema=SendWebRequestBlock.Output,\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 58, "end_line": 78, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        if isinstance(input_data.body, str):\n            input_data.body = json.loads(input_data.body)\n\n        response = requests.request(\n            input_data.method.value,\n            input_data.url,\n            headers=input_data.headers,\n            json=input_data.body if input_data.json_format else None,\n            data=input_data.body if not input_data.json_format else None,\n        )\n        result = response.json() if input_data.json_format else response.text\n\n        if response.status_code // 100 == 2:\n            yield \"response\", result\n        elif response.status_code // 100 == 4:\n            yield \"client_error\", result\n        elif response.status_code // 100 == 5:\n            yield \"server_error\", result\n        else:\n            raise ValueError(f\"Unexpected status code: {response.status_code}\")", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:", "successors": [{"id": 2, "label": "if isinstance(input_data.body, str):\ninput_data.body = json.loads(input_data.body)", "successors": [{"id": 4, "label": "response = requests.request(\n    input_data.method.value,\n    input_data.url,\n    headers=input_data.headers,\n    json=input_data.body if input_data.json_format else None,\n    data=input_data.body if not input_data.json_format else None,\n)\nresult = response.json() if input_data.json_format else response.text\nif response.status_code // 100 == 2:", "successors": [{"id": 6, "label": "yield \"response\", result", "successors": []}, {"id": 7, "label": "elif response.status_code // 100 == 4:", "successors": [{"id": 8, "label": "yield \"client_error\", result", "successors": []}, {"id": 9, "label": "elif response.status_code // 100 == 5:", "successors": [{"id": 10, "label": "yield \"server_error\", result", "successors": []}, {"id": 11, "label": "else:\nraise ValueError(f\"Unexpected status code: {response.status_code}\")", "successors": []}]}]}]}]}, {"id": 4, "label": "response = requests.request(\n    input_data.method.value,\n    input_data.url,\n    headers=input_data.headers,\n    json=input_data.body if input_data.json_format else None,\n    data=input_data.body if not input_data.json_format else None,\n)\nresult = response.json() if input_data.json_format else response.text\nif response.status_code // 100 == 2:", "successors": [{"id": 6, "label": "yield \"response\", result", "successors": []}, {"id": 7, "label": "elif response.status_code // 100 == 4:", "successors": [{"id": 8, "label": "yield \"client_error\", result", "successors": []}, {"id": 9, "label": "elif response.status_code // 100 == 5:", "successors": [{"id": 10, "label": "yield \"server_error\", result", "successors": []}, {"id": 11, "label": "else:\nraise ValueError(f\"Unexpected status code: {response.status_code}\")", "successors": []}]}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 21, "end_line": 42, "functions": [], "simplified_code": "    class Input(BlockSchema):\n        url: str = SchemaField(\n            description=\"The URL to send the request to\",\n            placeholder=\"https://api.example.com\",\n        )\n        method: HttpMethod = SchemaField(\n            description=\"The HTTP method to use for the request\",\n            default=HttpMethod.POST,\n        )\n        headers: dict[str, str] = SchemaField(\n            description=\"The headers to include in the request\",\n            default={},\n        )\n        json_format: bool = SchemaField(\n            title=\"JSON format\",\n            description=\"Whether to send and receive body as JSON\",\n            default=True,\n        )\n        body: Any = SchemaField(\n            description=\"The body of the request\",\n            default=None,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    url: str = SchemaField(description=\"The URL to send the request to\", placeholder=\"https://api.example.com\", )", "successors": [{"id": 3, "label": "    method: HttpMethod = SchemaField(description=\"The HTTP method to use for the request\", default=HttpMethod.POST, )\n    headers: dict[str, str] = SchemaField(description=\"The headers to include in the request\", default={}, )", "successors": [{"id": 5, "label": "    json_format: bool = SchemaField(title=\"JSON format\", description=\"Whether to send and receive body as JSON\", default=True, )\n    body: Any = SchemaField(description=\"The body of the request\", default=None, )", "successors": []}]}]}]}, {"name": "Output", "type": "class", "start_line": 44, "end_line": 47, "functions": [], "simplified_code": "    class Output(BlockSchema):\n        response: object = SchemaField(description=\"The response from the server\")\n        client_error: object = SchemaField(description=\"The error on 4xx status codes\")\n        server_error: object = SchemaField(description=\"The error on 5xx status codes\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "response: object = SchemaField(description=\"The response from the server\")", "successors": []}, {"id": 3, "label": "client_error: object = SchemaField(description=\"The error on 4xx status codes\")", "successors": []}, {"id": 4, "label": "server_error: object = SchemaField(description=\"The error on 5xx status codes\")", "successors": []}]}]}], "simplified_code": "class SendWebRequestBlock(Block):\n        )\n\n        server_error: object = SchemaField(description=\"The error on 5xx status codes\")\n\n        )\n\n            raise ValueError(f\"Unexpected status code: {response.status_code}\")", "blocks": [{"id": 1, "label": "class SendWebRequestBlock(Block):\nserver_error: object = SchemaField(description=\"The error on 5xx status codes\")", "successors": [{"id": 3, "label": "if not response.ok:\nraise ValueError(f\"Unexpected status code: {response.status_code}\")", "successors": []}]}]}], "simplified_code": "import json\nfrom enum import Enum\nfrom typing import Any\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\nfrom backend.util.request import requests\n\n\n    HEAD = \"HEAD\"\n\n\n            raise ValueError(f\"Unexpected status code: {response.status_code}\")", "blocks": [{"id": 1, "label": "import json\nfrom enum import Enum\nfrom typing import Any\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\nfrom backend.util.request import requests\nHEAD = \"HEAD\"", "successors": [{"id": 3, "label": "raise ValueError(f\"Unexpected status code: {response.status_code}\")", "successors": []}]}]}
{"file_name": "73.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 94, "functions": [{"name": "generate_agent_image", "type": "function", "start_line": 24, "end_line": 94, "functions": [], "classes": [], "simplified_code": "async def generate_agent_image(agent: Graph) -> io.BytesIO:\n    \"\"\"\n    Generate an image for an agent using Flux model via Replicate API.\n\n    Args:\n        agent (Graph): The agent to generate an image for\n\n    Returns:\n        io.BytesIO: The generated image as bytes\n    \"\"\"\n    try:\n        settings = Settings()\n\n        if not settings.secrets.replicate_api_key:\n            raise ValueError(\"Missing Replicate API key in settings\")\n\n        # Construct prompt from agent details\n        prompt = f\"Create a visually engaging app store thumbnail for the AI agent that highlights what it does in a clear and captivating way:\\n- **Name**: {agent.name}\\n- **Description**: {agent.description}\\nFocus on showcasing its core functionality with an appealing design.\"\n\n        # Set up Replicate client\n        client = replicate.Client(api_token=settings.secrets.replicate_api_key)\n\n        # Model parameters\n        input_data = {\n            \"prompt\": prompt,\n            \"width\": 1024,\n            \"height\": 768,\n            \"aspect_ratio\": \"4:3\",\n            \"output_format\": \"jpg\",\n            \"output_quality\": 90,\n            \"num_inference_steps\": 30,\n            \"guidance\": 3.5,\n            \"negative_prompt\": \"blurry, low quality, distorted, deformed\",\n            \"disable_safety_checker\": True,\n        }\n\n        try:\n            # Run model\n            output = client.run(\"black-forest-labs/flux-1.1-pro\", input=input_data)\n\n            # Depending on the model output, extract the image URL or bytes\n            # If the output is a list of FileOutput or URLs\n            if isinstance(output, list) and output:\n                if isinstance(output[0], FileOutput):\n                    image_bytes = output[0].read()\n                else:\n                    # If it's a URL string, fetch the image bytes\n                    result_url = output[0]\n                    response = requests.get(result_url)\n                    response.raise_for_status()\n                    image_bytes = response.content\n            elif isinstance(output, FileOutput):\n                image_bytes = output.read()\n            elif isinstance(output, str):\n                # Output is a URL\n                response = requests.get(output)\n                response.raise_for_status()\n                image_bytes = response.content\n            else:\n                raise RuntimeError(\"Unexpected output format from the model.\")\n\n            return io.BytesIO(image_bytes)\n\n        except replicate.exceptions.ReplicateError as e:\n            if e.status == 401:\n                raise RuntimeError(\"Invalid Replicate API token\") from e\n            raise RuntimeError(f\"Replicate API error: {str(e)}\") from e\n\n    except Exception as e:\n        logger.exception(\"Failed to generate agent image\")\n        raise RuntimeError(f\"Image generation failed: {str(e)}\")", "blocks": [{"id": 1, "label": "async def generate_agent_image(agent: Graph) -> io.BytesIO:", "successors": [{"id": 2, "label": "    try:\n        settings = Settings()", "successors": [{"id": 4, "label": "if not settings.secrets.replicate_api_key:\n            raise ValueError(\"Missing Replicate API key in settings\")", "successors": [{"id": 6, "label": "# Construct prompt from agent details\n        prompt = f\"Create a visually engaging app store thumbnail for the AI agent that highlights what it does in a clear and captivating way:\\n- **Name**: {agent.name}\\n- **Description**: {agent.description}\\nFocus on showcasing its core functionality with an appealing design.\"\n# Set up Replicate client\n        client = replicate.Client(api_token=settings.secrets.replicate_api_key)", "successors": [{"id": 8, "label": "# Model parameters\n        input_data = {\n            \"prompt\": prompt,\n            \"width\": 1024,\n            \"height\": 768,\n            \"aspect_ratio\": \"4:3\",\n            \"output_format\": \"jpg\",\n            \"output_quality\": 90,\n            \"num_inference_steps\": 30,\n            \"guidance\": 3.5,\n            \"negative_prompt\": \"blurry, low quality, distorted, deformed\",\n            \"disable_safety_checker\": True,\n        }\ntry:", "successors": [{"id": 10, "label": "# Run model\n            output = client.run(\"black-forest-labs/flux-1.1-pro\", input=input_data)", "successors": [{"id": 11, "label": "if isinstance(output, list) and output:", "successors": [{"id": 12, "label": "if isinstance(output[0], FileOutput):\n                image_bytes = output[0].read()", "successors": [{"id": 14, "label": "return io.BytesIO(image_bytes)", "successors": []}]}, {"id": 15, "label": "else:\n# If it's a URL string, fetch the image bytes\n                    result_url = output[0]\n                    response = requests.get(result_url)\n                    response.raise_for_status()\n                    image_bytes = response.content", "successors": [{"id": 14, "label": "return io.BytesIO(image_bytes)", "successors": []}]}]}, {"id": 17, "label": "elif isinstance(output, FileOutput):\n                image_bytes = output.read()", "successors": [{"id": 14, "label": "return io.BytesIO(image_bytes)", "successors": []}]}, {"id": 19, "label": "elif isinstance(output, str):\n# Output is a URL\n                response = requests.get(output)\n                response.raise_for_status()\n                image_bytes = response.content", "successors": [{"id": 14, "label": "return io.BytesIO(image_bytes)", "successors": []}]}, {"id": 21, "label": "else:\n                raise RuntimeError(\"Unexpected output format from the model.\")", "successors": []}]}, {"id": 23, "label": "except replicate.exceptions.ReplicateError as e:", "successors": [{"id": 24, "label": "if e.status == 401:\n                raise RuntimeError(\"Invalid Replicate API token\") from e", "successors": []}, {"id": 26, "label": "raise RuntimeError(f\"Replicate API error: {str(e)}\") from e", "successors": []}]}]}]}]}]}, {"id": 27, "label": "except Exception as e:\nlogger.exception(\"Failed to generate agent image\")", "successors": [{"id": 29, "label": "raise RuntimeError(f\"Image generation failed: {str(e)}\")", "successors": []}]}]}]}], "classes": [{"name": "ImageSize", "type": "class", "start_line": 16, "end_line": 18, "functions": [], "simplified_code": "class ImageSize(str, Enum):\n    LANDSCAPE = \"1024x768\"\n", "blocks": []}, {"name": "ImageStyle", "type": "class", "start_line": 20, "end_line": 22, "functions": [], "simplified_code": "class ImageStyle(str, Enum):\n    DIGITAL_ART = \"digital art\"\n", "blocks": [{"id": 1, "label": "class ImageStyle(str, Enum):\n    DIGITAL_ART = \"digital art\"", "successors": []}]}], "simplified_code": "import io\nimport logging\nfrom enum import Enum\n\nimport replicate\nimport replicate.exceptions\nimport requests\nfrom replicate.helpers import FileOutput\n\nfrom backend.data.graph import Graph\nfrom backend.util.settings import Settings\n\nlogger = logging.getLogger(__name__)\n\n\n\n\n\n\n        raise RuntimeError(f\"Image generation failed: {str(e)}\")", "blocks": [{"id": 1, "label": "import io\nimport logging\nfrom enum import Enum\n\nimport replicate\nimport replicate.exceptions\nimport requests\nfrom replicate.helpers import FileOutput\n\nfrom backend.data.graph import Graph\nfrom backend.util.settings import Settings\n\nlogger = logging.getLogger(__name__)\n\n\ne\nraise RuntimeError(f\"Image generation failed: {str(e)}\")", "successors": []}]}
{"file_name": "74.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 169, "functions": [], "classes": [{"name": "GoogleOAuthHandler", "type": "class", "start_line": 20, "end_line": 169, "functions": [{"name": "__init__", "type": "function", "start_line": 34, "end_line": 39, "functions": [], "classes": [], "simplified_code": "    def __init__(self, client_id: str, client_secret: str, redirect_uri: str):\n        self.client_id = client_id\n        self.client_secret = client_secret\n        self.redirect_uri = redirect_uri\n        self.token_uri = \"https://oauth2.googleapis.com/token\"\n        self.revoke_uri = \"https://oauth2.googleapis.com/revoke\"", "blocks": [{"id": 1, "label": "def __init__(self, client_id: str, client_secret: str, redirect_uri: str):\nself.client_id = client_id\nself.client_secret = client_secret\nself.redirect_uri = redirect_uri\nself.token_uri = \"https://oauth2.googleapis.com/token\"\nself.revoke_uri = \"https://oauth2.googleapis.com/revoke\"", "successors": []}]}, {"name": "get_login_url", "type": "function", "start_line": 41, "end_line": 52, "functions": [], "classes": [], "simplified_code": "    def get_login_url(self, scopes: list[str], state: str) -> str:\n        all_scopes = list(set(scopes + self.DEFAULT_SCOPES))\n        logger.debug(f\"Setting up OAuth flow with scopes: {all_scopes}\")\n        flow = self._setup_oauth_flow(all_scopes)\n        flow.redirect_uri = self.redirect_uri\n        authorization_url, _ = flow.authorization_url(\n            access_type=\"offline\",\n            include_granted_scopes=\"true\",\n            state=state,\n            prompt=\"consent\",\n        )\n        return authorization_url", "blocks": [{"id": 1, "label": "def get_login_url(self, scopes: list[str], state: str) -> str:\n    all_scopes = list(set(scopes + self.DEFAULT_SCOPES))", "successors": [{"id": 3, "label": "    logger.debug(f\"Setting up OAuth flow with scopes: {all_scopes}\")\n    flow = self._setup_oauth_flow(all_scopes)", "successors": [{"id": 5, "label": "    flow.redirect_uri = self.redirect_uri\n    authorization_url, _ = flow.authorization_url(access_type=\"offline\", include_granted_scopes=\"true\", state=state, prompt=\"consent\")", "successors": [{"id": 7, "label": "    return authorization_url", "successors": []}]}]}]}]}, {"name": "exchange_code_for_tokens", "type": "function", "start_line": 54, "end_line": 104, "functions": [], "classes": [], "simplified_code": "    def exchange_code_for_tokens(\n        self, code: str, scopes: list[str]\n    ) -> OAuth2Credentials:\n        logger.debug(f\"Exchanging code for tokens with scopes: {scopes}\")\n\n        # Use the scopes from the initial request\n        flow = self._setup_oauth_flow(scopes)\n        flow.redirect_uri = self.redirect_uri\n\n        logger.debug(\"Fetching token from Google\")\n\n        # Disable scope check in fetch_token\n        flow.oauth2session.scope = None\n        token = flow.fetch_token(code=code)\n        logger.debug(\"Token fetched successfully\")\n\n        # Get the actual scopes granted by Google\n        granted_scopes: list[str] = token.get(\"scope\", [])\n\n        logger.debug(f\"Scopes granted by Google: {granted_scopes}\")\n\n        google_creds = flow.credentials\n        logger.debug(f\"Received credentials: {google_creds}\")\n\n        logger.debug(\"Requesting user email\")\n        username = self._request_email(google_creds)\n        logger.debug(f\"User email retrieved: {username}\")\n\n        assert google_creds.token\n        assert google_creds.refresh_token\n        assert google_creds.expiry\n        assert granted_scopes\n\n        # Create OAuth2Credentials with the granted scopes\n        credentials = OAuth2Credentials(\n            provider=self.PROVIDER_NAME,\n            title=None,\n            username=username,\n            access_token=SecretStr(google_creds.token),\n            refresh_token=(SecretStr(google_creds.refresh_token)),\n            access_token_expires_at=(\n                int(google_creds.expiry.timestamp()) if google_creds.expiry else None\n            ),\n            refresh_token_expires_at=None,\n            scopes=granted_scopes,\n        )\n        logger.debug(\n            f\"OAuth2Credentials object created successfully with scopes: {credentials.scopes}\"\n        )\n\n        return credentials", "blocks": [{"id": 1, "label": "def exchange_code_for_tokens(self, code: str, scopes: list[str]) -> OAuth2Credentials:\nlogger.debug(f\"Exchanging code for tokens with scopes: {scopes}\")", "successors": [{"id": 3, "label": "flow = self._setup_oauth_flow(scopes)\nflow.redirect_uri = self.redirect_uri\nlogger.debug(\"Fetching token from Google\")", "successors": [{"id": 5, "label": "flow.oauth2session.scope = None\ntoken = flow.fetch_token(code=code)\nlogger.debug(\"Token fetched successfully\")\ngranted_scopes: list[str] = token.get(\"scope\", [])", "successors": [{"id": 7, "label": "logger.debug(f\"Scopes granted by Google: {granted_scopes}\")\ngoogle_creds = flow.credentials\nlogger.debug(f\"Received credentials: {google_creds}\")", "successors": [{"id": 9, "label": "logger.debug(\"Requesting user email\")\nusername = self._request_email(google_creds)\nlogger.debug(f\"User email retrieved: {username}\")\nassert google_creds.token\nassert google_creds.refresh_token\nassert google_creds.expiry\nassert granted_scopes", "successors": [{"id": 11, "label": "credentials = OAuth2Credentials(provider=self.PROVIDER_NAME, title=None, username=username, access_token=SecretStr(google_creds.token), refresh_token=(SecretStr(google_creds.refresh_token)), access_token_expires_at=(int(google_creds.expiry.timestamp()) if google_creds.expiry else None), refresh_token_expires_at=None, scopes=granted_scopes)\nlogger.debug(f\"OAuth2Credentials object created successfully with scopes: {credentials.scopes}\")", "successors": [{"id": 13, "label": "return credentials", "successors": []}]}]}]}]}]}]}]}, {"name": "revoke_tokens", "type": "function", "start_line": 106, "end_line": 113, "functions": [], "classes": [], "simplified_code": "    def revoke_tokens(self, credentials: OAuth2Credentials) -> bool:\n        session = AuthorizedSession(credentials)\n        session.post(\n            self.revoke_uri,\n            params={\"token\": credentials.access_token.get_secret_value()},\n            headers={\"content-type\": \"application/x-www-form-urlencoded\"},\n        )\n        return True", "blocks": [{"id": 1, "label": "def revoke_tokens(self, credentials: OAuth2Credentials) -> bool:\nsession = AuthorizedSession(credentials)\nsession.post(\n    self.revoke_uri,\n    params={\"token\": credentials.access_token.get_secret_value()},\n    headers={\"content-type\": \"application/x-www-form-urlencoded\"},\n)", "successors": [{"id": 3, "label": "return True", "successors": []}]}]}, {"name": "_request_email", "type": "function", "start_line": 115, "end_line": 125, "functions": [], "classes": [], "simplified_code": "    def _request_email(\n        self, creds: Credentials | ExternalAccountCredentials\n    ) -> str | None:\n        session = AuthorizedSession(creds)\n        response = session.get(self.EMAIL_ENDPOINT)\n        if not response.ok:\n            logger.error(\n                f\"Failed to get user email. Status code: {response.status_code}\"\n            )\n            return None\n        return response.json()[\"email\"]", "blocks": [{"id": 1, "label": "def _request_email( self, creds: Credentials | ExternalAccountCredentials ) -> str | None:\nsession = AuthorizedSession(creds)", "successors": [{"id": 3, "label": "response = session.get(self.EMAIL_ENDPOINT)\nif not response.ok:", "successors": [{"id": 5, "label": "logger.error( f\"Failed to get user email. Status code: {response.status_code}\" )\nreturn None", "successors": []}, {"id": 7, "label": "return response.json()[\"email\"]", "successors": []}]}]}]}, {"name": "_refresh_tokens", "type": "function", "start_line": 127, "end_line": 156, "functions": [], "classes": [], "simplified_code": "    def _refresh_tokens(self, credentials: OAuth2Credentials) -> OAuth2Credentials:\n        # Google credentials should ALWAYS have a refresh token\n        assert credentials.refresh_token\n\n        google_creds = Credentials(\n            token=credentials.access_token.get_secret_value(),\n            refresh_token=credentials.refresh_token.get_secret_value(),\n            token_uri=self.token_uri,\n            client_id=self.client_id,\n            client_secret=self.client_secret,\n            scopes=credentials.scopes,\n        )\n        # Google's OAuth library is poorly typed so we need some of these:\n        assert google_creds.refresh_token\n        assert google_creds.scopes\n\n        google_creds.refresh(Request())\n        assert google_creds.expiry\n\n        return OAuth2Credentials(\n            provider=self.PROVIDER_NAME,\n            id=credentials.id,\n            title=credentials.title,\n            username=credentials.username,\n            access_token=SecretStr(google_creds.token),\n            refresh_token=SecretStr(google_creds.refresh_token),\n            access_token_expires_at=int(google_creds.expiry.timestamp()),\n            refresh_token_expires_at=None,\n            scopes=google_creds.scopes,\n        )", "blocks": [{"id": 1, "label": "def _refresh_tokens(self, credentials: OAuth2Credentials) -> OAuth2Credentials:\nassert credentials.refresh_token", "successors": [{"id": 3, "label": "google_creds = Credentials(\n    token=credentials.access_token.get_secret_value(),\n    refresh_token=credentials.refresh_token.get_secret_value(),\n    token_uri=self.token_uri,\n    client_id=self.client_id,\n    client_secret=self.client_secret,\n    scopes=credentials.scopes,\n)\nassert google_creds.refresh_token\nassert google_creds.scopes", "successors": [{"id": 5, "label": "google_creds.refresh(Request())\nassert google_creds.expiry\nreturn OAuth2Credentials(\n    provider=self.PROVIDER_NAME,\n    id=credentials.id,\n    title=credentials.title,\n    username=credentials.username,\n    access_token=SecretStr(google_creds.token),\n    refresh_token=SecretStr(google_creds.refresh_token),\n    access_token_expires_at=int(google_creds.expiry.timestamp()),\n    refresh_token_expires_at=None,\n    scopes=google_creds.scopes,\n)", "successors": []}]}]}]}, {"name": "_setup_oauth_flow", "type": "function", "start_line": 158, "end_line": 169, "functions": [], "classes": [], "simplified_code": "    def _setup_oauth_flow(self, scopes: list[str]) -> Flow:\n        return Flow.from_client_config(\n            {\n                \"web\": {\n                    \"client_id\": self.client_id,\n                    \"client_secret\": self.client_secret,\n                    \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n                    \"token_uri\": self.token_uri,\n                }\n            },\n            scopes=scopes,\n        )", "blocks": [{"id": 1, "label": "def _setup_oauth_flow(self, scopes: list[str]) -> Flow:\nreturn Flow.from_client_config(\n    {\n        \"web\": {\n            \"client_id\": self.client_id,\n            \"client_secret\": self.client_secret,\n            \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n            \"token_uri\": self.token_uri,\n        }\n    },\n    scopes=scopes,\n)", "successors": []}]}], "classes": [], "simplified_code": "class GoogleOAuthHandler(BaseOAuthHandler):\n    \"\"\"\n    Based on the documentation at https://developers.google.com/identity/protocols/oauth2/web-server\n    \"\"\"  # noqa\n\n    PROVIDER_NAME = ProviderName.GOOGLE\n    EMAIL_ENDPOINT = \"https://www.googleapis.com/oauth2/v2/userinfo\"\n    DEFAULT_SCOPES = [\n        \"https://www.googleapis.com/auth/userinfo.email\",\n        \"https://www.googleapis.com/auth/userinfo.profile\",\n        \"openid\",\n    ]\n    # --8<-- [end:GoogleOAuthHandlerExample]\n\n        self.revoke_uri = \"https://oauth2.googleapis.com/revoke\"\n\n        return authorization_url\n\n        return credentials\n\n        return True\n\n        return response.json()[\"email\"]\n\n        )\n\n        )", "blocks": [{"id": 1, "label": "class GoogleOAuthHandler(BaseOAuthHandler):\n\"\"\"\nBased on the documentation at https://developers.google.com/identity/protocols/oauth2/web-server\n\"\"\"  # noqa\n\nPROVIDER_NAME = ProviderName.GOOGLE\nEMAIL_ENDPOINT = \"https://www.googleapis.com/oauth2/v2/userinfo\"\nDEFAULT_SCOPES = [\n    \"https://www.googleapis.com/auth/userinfo.email\",\n    \"https://www.googleapis.com/auth/userinfo.profile\",\n    \"openid\",\n]\n# --8<-- [end:GoogleOAuthHandlerExample]\n\n    self.revoke_uri = \"https://oauth2.googleapis.com/revoke\"\n\n    return authorization_url\n\n    return credentials\n\n    return True\n\n    return response.json()[\"email\"]\n\n    )\n\n    )", "successors": []}]}], "simplified_code": "import logging\n\nfrom google.auth.external_account_authorized_user import (\n    Credentials as ExternalAccountCredentials,\n)\nfrom google.auth.transport.requests import AuthorizedSession, Request\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import Flow\nfrom pydantic import SecretStr\n\nfrom backend.data.model import OAuth2Credentials\nfrom backend.integrations.providers import ProviderName\n\nfrom .base import BaseOAuthHandler\n\nlogger = logging.getLogger(__name__)\n\n\n# --8<-- [start:GoogleOAuthHandlerExample]\n        )", "blocks": [{"id": 1, "label": "import logging\n\nfrom google.auth.external_account_authorized_user import (\n    Credentials as ExternalAccountCredentials,\n)\nfrom google.auth.transport.requests import AuthorizedSession, Request\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import Flow\nfrom pydantic import SecretStr\n\nfrom backend.data.model import OAuth2Credentials\nfrom backend.integrations.providers import ProviderName\n\nfrom .base import BaseOAuthHandler\n\nlogger = logging.getLogger(__name__)\n\n\n# --8<-- [start:GoogleOAuthHandlerExample]\n        )", "successors": []}]}
{"file_name": "75.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 36, "functions": [{"name": "test_remove_color_codes", "type": "function", "start_line": 35, "end_line": 36, "functions": [], "classes": [], "simplified_code": "def test_remove_color_codes(raw_text, clean_text):\n    assert remove_color_codes(raw_text) == clean_text", "blocks": [{"id": 1, "label": "def test_remove_color_codes(raw_text, clean_text):\n    assert remove_color_codes(raw_text) == clean_text", "successors": []}]}], "classes": [], "simplified_code": "import pytest\n\nfrom .utils import remove_color_codes\n\n\n@pytest.mark.parametrize(\n    \"raw_text, clean_text\",\n    [\n        (\n            \"COMMAND = \\x1b[36mbrowse_website\\x1b[0m  \"\n            \"ARGUMENTS = \\x1b[36m{'url': 'https://www.google.com',\"\n            \" 'question': 'What is the capital of France?'}\\x1b[0m\",\n            \"COMMAND = browse_website  \"\n            \"ARGUMENTS = {'url': 'https://www.google.com',\"\n            \" 'question': 'What is the capital of France?'}\",\n        ),\n        (\n            \"{'Schaue dir meine Projekte auf github () an, als auch meine Webseiten': \"\n            \"'https://github.com/Significant-Gravitas/AutoGPT,\"\n            \" https://discord.gg/autogpt und https://twitter.com/Auto_GPT'}\",\n            \"{'Schaue dir meine Projekte auf github () an, als auch meine Webseiten': \"\n            \"'https://github.com/Significant-Gravitas/AutoGPT,\"\n            \" https://discord.gg/autogpt und https://twitter.com/Auto_GPT'}\",\n        ),\n        (\"\", \"\"),\n        (\"hello\", \"hello\"),\n        (\"hello\\x1b[31m world\", \"hello world\"),\n        (\"\\x1b[36mHello,\\x1b[32m World!\", \"Hello, World!\"),\n        (\n            \"\\x1b[1m\\x1b[31mError:\\x1b[0m\\x1b[31m file not found\",\n            \"Error: file not found\",\n        ),\n    ],\n)\n    assert remove_color_codes(raw_text) == clean_text", "blocks": [{"id": 1, "label": "import pytest\nfrom .utils import remove_color_codes", "successors": [{"id": 3, "label": "@pytest.mark.parametrize(\n    \"raw_text, clean_text\",\n    [\n        (\n            \"COMMAND = \\x1b[36mbrowse_website\\x1b[0m  \"\n            \"ARGUMENTS = \\x1b[36m{'url': 'https://www.google.com',\"\n            \" 'question': 'What is the capital of France?'}\\x1b[0m\",\n            \"COMMAND = browse_website  \"\n            \"ARGUMENTS = {'url': 'https://www.google.com',\"\n            \" 'question': 'What is the capital of France?'}\",\n        ),\n        (\n            \"{'Schaue dir meine Projekte auf github () an, als auch meine Webseiten': \"\n            \"'https://github.com/Significant-Gravitas/AutoGPT,\"\n            \" https://discord.gg/autogpt und https://twitter.com/Auto_GPT'}\",\n            \"{'Schaue dir meine Projekte auf github () an, als auch meine Webseiten': \"\n            \"'https://github.com/Significant-Gravitas/AutoGPT,\"\n            \" https://discord.gg/autogpt und https://twitter.com/Auto_GPT'}\",\n        ),\n        (\"\", \"\"),\n        (\"hello\", \"hello\"),\n        (\"hello\\x1b[31m world\", \"hello world\"),\n        (\"\\x1b[36mHello,\\x1b[32m World!\", \"Hello, World!\"),\n        (\n            \"\\x1b[1m\\x1b[31mError:\\x1b[0m\\x1b[31m file not found\",\n            \"Error: file not found\",\n        ),\n    ],\nassert remove_color_codes(raw_text) == clean_text", "successors": []}]}]}
{"file_name": "76.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 31, "functions": [], "classes": [{"name": "ProviderName", "type": "class", "start_line": 5, "end_line": 30, "functions": [], "classes": [], "simplified_code": "class ProviderName(str, Enum):\n    ANTHROPIC = \"anthropic\"\n    COMPASS = \"compass\"\n    DISCORD = \"discord\"\n    D_ID = \"d_id\"\n    E2B = \"e2b\"\n    EXA = \"exa\"\n    FAL = \"fal\"\n    GITHUB = \"github\"\n    GOOGLE = \"google\"\n    GOOGLE_MAPS = \"google_maps\"\n    GROQ = \"groq\"\n    HUBSPOT = \"hubspot\"\n    IDEOGRAM = \"ideogram\"\n    JINA = \"jina\"\n    MEDIUM = \"medium\"\n    NOTION = \"notion\"\n    OLLAMA = \"ollama\"\n    OPENAI = \"openai\"\n    OPENWEATHERMAP = \"openweathermap\"\n    OPEN_ROUTER = \"open_router\"\n    PINECONE = \"pinecone\"\n    REPLICATE = \"replicate\"\n    REVID = \"revid\"\n    SLANT3D = \"slant3d\"\n    UNREAL_SPEECH = \"unreal_speech\"", "blocks": [{"id": 1, "label": "class ProviderName(str, Enum):\n    ANTHROPIC = \"anthropic\"\n    COMPASS = \"compass\"\n    DISCORD = \"discord\"\n    D_ID = \"d_id\"\n    E2B = \"e2b\"\n    EXA = \"exa\"\n    FAL = \"fal\"\n    GITHUB = \"github\"\n    GOOGLE = \"google\"\n    GOOGLE_MAPS = \"google_maps\"\n    GROQ = \"groq\"\n    HUBSPOT = \"hubspot\"\n    IDEOGRAM = \"ideogram\"\n    JINA = \"jina\"\n    MEDIUM = \"medium\"\n    NOTION = \"notion\"\n    OLLAMA = \"ollama\"\n    OPENAI = \"openai\"\n    OPENWEATHERMAP = \"openweathermap\"\n    OPEN_ROUTER = \"open_router\"\n    PINECONE = \"pinecone\"\n    REPLICATE = \"replicate\"\n    REVID = \"revid\"\n    SLANT3D = \"slant3d\"\n    UNREAL_SPEECH = \"unreal_speech\"", "successors": []}]}], "simplified_code": "from enum import Enum\n\n\n# --8<-- [start:ProviderName]\n    UNREAL_SPEECH = \"unreal_speech\"\n    # --8<-- [end:ProviderName]", "blocks": [{"id": 1, "label": "from enum import Enum", "successors": []}]}
{"file_name": "77.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 234, "functions": [{"name": "make_lowpass", "type": "function", "start_line": 13, "end_line": 40, "functions": [], "classes": [], "simplified_code": "def make_lowpass(\n    frequency: int,\n    samplerate: int,\n    q_factor: float = 1 / sqrt(2),\n) -> IIRFilter:\n    \"\"\"\n    Creates a low-pass filter\n\n    >>> filter = make_lowpass(1000, 48000)\n    >>> filter.a_coeffs + filter.b_coeffs  # doctest: +NORMALIZE_WHITESPACE\n    [1.0922959556412573, -1.9828897227476208, 0.9077040443587427, 0.004277569313094809,\n     0.008555138626189618, 0.004277569313094809]\n    \"\"\"\n    w0 = tau * frequency / samplerate\n    _sin = sin(w0)\n    _cos = cos(w0)\n    alpha = _sin / (2 * q_factor)\n\n    b0 = (1 - _cos) / 2\n    b1 = 1 - _cos\n\n    a0 = 1 + alpha\n    a1 = -2 * _cos\n    a2 = 1 - alpha\n\n    filt = IIRFilter(2)\n    filt.set_coefficients([a0, a1, a2], [b0, b1, b0])\n    return filt", "blocks": [{"id": 1, "label": "def make_lowpass(\n    frequency: int,\n    samplerate: int,\n    q_factor: float = 1 / sqrt(2),\n) -> IIRFilter:\n\"\"\"\n    Creates a low-pass filter\n\n    >>> filter = make_lowpass(1000, 48000)\n    >>> filter.a_coeffs + filter.b_coeffs  # doctest: +NORMALIZE_WHITESPACE\n    [1.0922959556412573, -1.9828897227476208, 0.9077040443587427, 0.004277569313094809,\n     0.008555138626189618, 0.004277569313094809]\n    \"\"\"", "successors": [{"id": 3, "label": "w0 = tau * frequency / samplerate\n_sin = sin(w0)\n_cos = cos(w0)\nalpha = _sin / (2 * q_factor)\n\nb0 = (1 - _cos) / 2\nb1 = 1 - _cos\n\na0 = 1 + alpha\na1 = -2 * _cos\na2 = 1 - alpha\n\nfilt = IIRFilter(2)\nfilt.set_coefficients([a0, a1, a2], [b0, b1, b0])\nreturn filt", "successors": []}]}]}, {"name": "make_highpass", "type": "function", "start_line": 43, "end_line": 70, "functions": [], "classes": [], "simplified_code": "def make_highpass(\n    frequency: int,\n    samplerate: int,\n    q_factor: float = 1 / sqrt(2),\n) -> IIRFilter:\n    \"\"\"\n    Creates a high-pass filter\n\n    >>> filter = make_highpass(1000, 48000)\n    >>> filter.a_coeffs + filter.b_coeffs  # doctest: +NORMALIZE_WHITESPACE\n    [1.0922959556412573, -1.9828897227476208, 0.9077040443587427, 0.9957224306869052,\n     -1.9914448613738105, 0.9957224306869052]\n    \"\"\"\n    w0 = tau * frequency / samplerate\n    _sin = sin(w0)\n    _cos = cos(w0)\n    alpha = _sin / (2 * q_factor)\n\n    b0 = (1 + _cos) / 2\n    b1 = -1 - _cos\n\n    a0 = 1 + alpha\n    a1 = -2 * _cos\n    a2 = 1 - alpha\n\n    filt = IIRFilter(2)\n    filt.set_coefficients([a0, a1, a2], [b0, b1, b0])\n    return filt", "blocks": [{"id": 1, "label": "def make_highpass(\n    frequency: int,\n    samplerate: int,\n    q_factor: float = 1 / sqrt(2),\n) -> IIRFilter:\n    w0 = tau * frequency / samplerate\n    _sin = sin(w0)\n    _cos = cos(w0)\n    alpha = _sin / (2 * q_factor)", "successors": [{"id": 3, "label": "    b0 = (1 + _cos) / 2\n    b1 = -1 - _cos\n    a0 = 1 + alpha\n    a1 = -2 * _cos\n    a2 = 1 - alpha", "successors": [{"id": 5, "label": "    filt = IIRFilter(2)\n    filt.set_coefficients([a0, a1, a2], [b0, b1, b0])\n    return filt", "successors": []}]}]}]}, {"name": "make_bandpass", "type": "function", "start_line": 73, "end_line": 101, "functions": [], "classes": [], "simplified_code": "def make_bandpass(\n    frequency: int,\n    samplerate: int,\n    q_factor: float = 1 / sqrt(2),\n) -> IIRFilter:\n    \"\"\"\n    Creates a band-pass filter\n\n    >>> filter = make_bandpass(1000, 48000)\n    >>> filter.a_coeffs + filter.b_coeffs  # doctest: +NORMALIZE_WHITESPACE\n    [1.0922959556412573, -1.9828897227476208, 0.9077040443587427, 0.06526309611002579,\n     0, -0.06526309611002579]\n    \"\"\"\n    w0 = tau * frequency / samplerate\n    _sin = sin(w0)\n    _cos = cos(w0)\n    alpha = _sin / (2 * q_factor)\n\n    b0 = _sin / 2\n    b1 = 0\n    b2 = -b0\n\n    a0 = 1 + alpha\n    a1 = -2 * _cos\n    a2 = 1 - alpha\n\n    filt = IIRFilter(2)\n    filt.set_coefficients([a0, a1, a2], [b0, b1, b2])\n    return filt", "blocks": [{"id": 1, "label": "def make_bandpass(\n    frequency: int,\n    samplerate: int,\n    q_factor: float = 1 / sqrt(2),\n) -> IIRFilter:\n\"\"\"\n    Creates a band-pass filter\n\n    >>> filter = make_bandpass(1000, 48000)\n    >>> filter.a_coeffs + filter.b_coeffs  # doctest: +NORMALIZE_WHITESPACE\n    [1.0922959556412573, -1.9828897227476208, 0.9077040443587427, 0.06526309611002579,\n     0, -0.06526309611002579]\n    \"\"\"", "successors": [{"id": 3, "label": "w0 = tau * frequency / samplerate\n_sin = sin(w0)\n_cos = cos(w0)\nalpha = _sin / (2 * q_factor)\nb0 = _sin / 2\nb1 = 0\nb2 = -b0", "successors": [{"id": 5, "label": "a0 = 1 + alpha\na1 = -2 * _cos\na2 = 1 - alpha\nfilt = IIRFilter(2)\nfilt.set_coefficients([a0, a1, a2], [b0, b1, b2])", "successors": [{"id": 7, "label": "return filt", "successors": []}]}]}]}]}, {"name": "make_allpass", "type": "function", "start_line": 104, "end_line": 128, "functions": [], "classes": [], "simplified_code": "def make_allpass(\n    frequency: int,\n    samplerate: int,\n    q_factor: float = 1 / sqrt(2),\n) -> IIRFilter:\n    \"\"\"\n    Creates an all-pass filter\n\n    >>> filter = make_allpass(1000, 48000)\n    >>> filter.a_coeffs + filter.b_coeffs  # doctest: +NORMALIZE_WHITESPACE\n    [1.0922959556412573, -1.9828897227476208, 0.9077040443587427, 0.9077040443587427,\n     -1.9828897227476208, 1.0922959556412573]\n    \"\"\"\n    w0 = tau * frequency / samplerate\n    _sin = sin(w0)\n    _cos = cos(w0)\n    alpha = _sin / (2 * q_factor)\n\n    b0 = 1 - alpha\n    b1 = -2 * _cos\n    b2 = 1 + alpha\n\n    filt = IIRFilter(2)\n    filt.set_coefficients([b2, b1, b0], [b0, b1, b2])\n    return filt", "blocks": [{"id": 1, "label": "def make_allpass(\n    frequency: int,\n    samplerate: int,\n    q_factor: float = 1 / sqrt(2),\n) -> IIRFilter:\n    \"\"\"\n    Creates an all-pass filter\n\n    >>> filter = make_allpass(1000, 48000)\n    >>> filter.a_coeffs + filter.b_coeffs  # doctest: +NORMALIZE_WHITESPACE\n    [1.0922959556412573, -1.9828897227476208, 0.9077040443587427, 0.9077040443587427,\n     -1.9828897227476208, 1.0922959556412573]\n    \"\"\"\n    w0 = tau * frequency / samplerate\n    _sin = sin(w0)\n    _cos = cos(w0)\n    alpha = _sin / (2 * q_factor)\n\n    b0 = 1 - alpha\n    b1 = -2 * _cos\n    b2 = 1 + alpha\n\n    filt = IIRFilter(2)\n    filt.set_coefficients([b2, b1, b0], [b0, b1, b2])", "successors": [{"id": 3, "label": "    return filt", "successors": []}]}]}, {"name": "make_peak", "type": "function", "start_line": 131, "end_line": 160, "functions": [], "classes": [], "simplified_code": "def make_peak(\n    frequency: int,\n    samplerate: int,\n    gain_db: float,\n    q_factor: float = 1 / sqrt(2),\n) -> IIRFilter:\n    \"\"\"\n    Creates a peak filter\n\n    >>> filter = make_peak(1000, 48000, 6)\n    >>> filter.a_coeffs + filter.b_coeffs  # doctest: +NORMALIZE_WHITESPACE\n    [1.0653405327119334, -1.9828897227476208, 0.9346594672880666, 1.1303715025601122,\n     -1.9828897227476208, 0.8696284974398878]\n    \"\"\"\n    w0 = tau * frequency / samplerate\n    _sin = sin(w0)\n    _cos = cos(w0)\n    alpha = _sin / (2 * q_factor)\n    big_a = 10 ** (gain_db / 40)\n\n    b0 = 1 + alpha * big_a\n    b1 = -2 * _cos\n    b2 = 1 - alpha * big_a\n    a0 = 1 + alpha / big_a\n    a1 = -2 * _cos\n    a2 = 1 - alpha / big_a\n\n    filt = IIRFilter(2)\n    filt.set_coefficients([a0, a1, a2], [b0, b1, b2])\n    return filt", "blocks": [{"id": 1, "label": "def make_peak(\n    frequency: int,\n    samplerate: int,\n    gain_db: float,\n    q_factor: float = 1 / sqrt(2),\n) -> IIRFilter:\n    \"\"\"\n    Creates a peak filter\n\n    >>> filter = make_peak(1000, 48000, 6)\n    >>> filter.a_coeffs + filter.b_coeffs  # doctest: +NORMALIZE_WHITESPACE\n    [1.0653405327119334, -1.9828897227476208, 0.9346594672880666, 1.1303715025601122,\n     -1.9828897227476208, 0.8696284974398878]\n    \"\"\"\n    w0 = tau * frequency / samplerate\n    _sin = sin(w0)\n    _cos = cos(w0)\n    alpha = _sin / (2 * q_factor)\n    big_a = 10 ** (gain_db / 40)\n\n    b0 = 1 + alpha * big_a\n    b1 = -2 * _cos\n    b2 = 1 - alpha * big_a\n    a0 = 1 + alpha / big_a\n    a1 = -2 * _cos\n    a2 = 1 - alpha / big_a\n\n    filt = IIRFilter(2)\n    filt.set_coefficients([a0, a1, a2], [b0, b1, b2])\nreturn filt", "successors": []}]}, {"name": "make_lowshelf", "type": "function", "start_line": 163, "end_line": 197, "functions": [], "classes": [], "simplified_code": "def make_lowshelf(\n    frequency: int,\n    samplerate: int,\n    gain_db: float,\n    q_factor: float = 1 / sqrt(2),\n) -> IIRFilter:\n    \"\"\"\n    Creates a low-shelf filter\n\n    >>> filter = make_lowshelf(1000, 48000, 6)\n    >>> filter.a_coeffs + filter.b_coeffs  # doctest: +NORMALIZE_WHITESPACE\n    [3.0409336710888786, -5.608870992220748, 2.602157875636628, 3.139954022810743,\n     -5.591841778072785, 2.5201667380627257]\n    \"\"\"\n    w0 = tau * frequency / samplerate\n    _sin = sin(w0)\n    _cos = cos(w0)\n    alpha = _sin / (2 * q_factor)\n    big_a = 10 ** (gain_db / 40)\n    pmc = (big_a + 1) - (big_a - 1) * _cos\n    ppmc = (big_a + 1) + (big_a - 1) * _cos\n    mpc = (big_a - 1) - (big_a + 1) * _cos\n    pmpc = (big_a - 1) + (big_a + 1) * _cos\n    aa2 = 2 * sqrt(big_a) * alpha\n\n    b0 = big_a * (pmc + aa2)\n    b1 = 2 * big_a * mpc\n    b2 = big_a * (pmc - aa2)\n    a0 = ppmc + aa2\n    a1 = -2 * pmpc\n    a2 = ppmc - aa2\n\n    filt = IIRFilter(2)\n    filt.set_coefficients([a0, a1, a2], [b0, b1, b2])\n    return filt", "blocks": [{"id": 1, "label": "def make_lowshelf(\n    frequency: int,\n    samplerate: int,\n    gain_db: float,\n    q_factor: float = 1 / sqrt(2),\n) -> IIRFilter:\n\"\"\"\n    Creates a low-shelf filter\n\n    >>> filter = make_lowshelf(1000, 48000, 6)\n    >>> filter.a_coeffs + filter.b_coeffs  # doctest: +NORMALIZE_WHITESPACE\n    [3.0409336710888786, -5.608870992220748, 2.602157875636628, 3.139954022810743,\n     -5.591841778072785, 2.5201667380627257]\n    \"\"\"", "successors": [{"id": 3, "label": "w0 = tau * frequency / samplerate\n_sin = sin(w0)\n_cos = cos(w0)\nalpha = _sin / (2 * q_factor)\nbig_a = 10 ** (gain_db / 40)\npmc = (big_a + 1) - (big_a - 1) * _cos\nppmc = (big_a + 1) + (big_a - 1) * _cos\nmpc = (big_a - 1) - (big_a + 1) * _cos\npmpc = (big_a - 1) + (big_a + 1) * _cos\naa2 = 2 * sqrt(big_a) * alpha\nb0 = big_a * (pmc + aa2)\nb1 = 2 * big_a * mpc\nb2 = big_a * (pmc - aa2)\na0 = ppmc + aa2\na1 = -2 * pmpc\na2 = ppmc - aa2", "successors": [{"id": 5, "label": "filt = IIRFilter(2)\nfilt.set_coefficients([a0, a1, a2], [b0, b1, b2])\nreturn filt", "successors": []}]}]}]}, {"name": "make_highshelf", "type": "function", "start_line": 200, "end_line": 234, "functions": [], "classes": [], "simplified_code": "def make_highshelf(\n    frequency: int,\n    samplerate: int,\n    gain_db: float,\n    q_factor: float = 1 / sqrt(2),\n) -> IIRFilter:\n    \"\"\"\n    Creates a high-shelf filter\n\n    >>> filter = make_highshelf(1000, 48000, 6)\n    >>> filter.a_coeffs + filter.b_coeffs  # doctest: +NORMALIZE_WHITESPACE\n    [2.2229172136088806, -3.9587208137297303, 1.7841414181566304, 4.295432981120543,\n     -7.922740859457287, 3.6756456963725253]\n    \"\"\"\n    w0 = tau * frequency / samplerate\n    _sin = sin(w0)\n    _cos = cos(w0)\n    alpha = _sin / (2 * q_factor)\n    big_a = 10 ** (gain_db / 40)\n    pmc = (big_a + 1) - (big_a - 1) * _cos\n    ppmc = (big_a + 1) + (big_a - 1) * _cos\n    mpc = (big_a - 1) - (big_a + 1) * _cos\n    pmpc = (big_a - 1) + (big_a + 1) * _cos\n    aa2 = 2 * sqrt(big_a) * alpha\n\n    b0 = big_a * (ppmc + aa2)\n    b1 = -2 * big_a * pmpc\n    b2 = big_a * (ppmc - aa2)\n    a0 = pmc + aa2\n    a1 = 2 * mpc\n    a2 = pmc - aa2\n\n    filt = IIRFilter(2)\n    filt.set_coefficients([a0, a1, a2], [b0, b1, b2])\n    return filt", "blocks": [{"id": 1, "label": "def make_highshelf(\n    frequency: int,\n    samplerate: int,\n    gain_db: float,\n    q_factor: float = 1 / sqrt(2),\n) -> IIRFilter:\n    w0 = tau * frequency / samplerate\n    _sin = sin(w0)\n    _cos = cos(w0)\n    alpha = _sin / (2 * q_factor)\n    big_a = 10 ** (gain_db / 40)\n    pmc = (big_a + 1) - (big_a - 1) * _cos\n    ppmc = (big_a + 1) + (big_a - 1) * _cos\n    mpc = (big_a - 1) - (big_a + 1) * _cos\n    pmpc = (big_a - 1) + (big_a + 1) * _cos\n    aa2 = 2 * sqrt(big_a) * alpha", "successors": [{"id": 3, "label": "    b0 = big_a * (ppmc + aa2)\n    b1 = -2 * big_a * pmpc\n    b2 = big_a * (ppmc - aa2)\n    a0 = pmc + aa2\n    a1 = 2 * mpc\n    a2 = pmc - aa2\n    filt = IIRFilter(2)\n    filt.set_coefficients([a0, a1, a2], [b0, b1, b2])", "successors": [{"id": 5, "label": "    return filt", "successors": []}]}]}]}], "classes": [], "simplified_code": "from math import cos, sin, sqrt, tau\n\nfrom audio_filters.iir_filter import IIRFilter\n\n\"\"\"\nCreate 2nd-order IIR filters with Butterworth design.\n\nCode based on https://webaudio.github.io/Audio-EQ-Cookbook/audio-eq-cookbook.html\nAlternatively you can use scipy.signal.butter, which should yield the same results.\n\"\"\"\n\n\n    return filt\n\n\n    return filt\n\n\n    return filt\n\n\n    return filt\n\n\n    return filt\n\n\n    return filt\n\n\n    return filt", "blocks": [{"id": 1, "label": "from math import cos, sin, sqrt, tau\nfrom audio_filters.iir_filter import IIRFilter", "successors": []}]}
{"file_name": "78.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 27, "functions": [{"name": "get_frontend_path", "type": "function", "start_line": 6, "end_line": 15, "functions": [], "classes": [], "simplified_code": "def get_frontend_path() -> pathlib.Path:\n    if getattr(sys, \"frozen\", False):\n        # The application is frozen\n        datadir = pathlib.Path(os.path.dirname(sys.executable)) / \"example_files\"\n    else:\n        # The application is not frozen\n        # Change this bit to match where you store your data files:\n        filedir = os.path.dirname(__file__)\n        datadir = pathlib.Path(filedir).parent.parent.parent / \"example_files\"\n    return pathlib.Path(datadir)", "blocks": [{"id": 1, "label": "def get_frontend_path() -> pathlib.Path:", "successors": [{"id": 2, "label": "if getattr(sys, \"frozen\", False):", "successors": [{"id": 3, "label": "    datadir = pathlib.Path(os.path.dirname(sys.executable)) / \"example_files\"", "successors": []}, {"id": 4, "label": "    filedir = os.path.dirname(__file__)\n    datadir = pathlib.Path(filedir).parent.parent.parent / \"example_files\"", "successors": []}]}, {"id": 5, "label": "return pathlib.Path(datadir)", "successors": []}]}]}, {"name": "get_data_path", "type": "function", "start_line": 18, "end_line": 27, "functions": [], "classes": [], "simplified_code": "def get_data_path() -> pathlib.Path:\n    if getattr(sys, \"frozen\", False):\n        # The application is frozen\n        datadir = os.path.dirname(sys.executable)\n    else:\n        # The application is not frozen\n        # Change this bit to match where you store your data files:\n        filedir = os.path.dirname(__file__)\n        datadir = pathlib.Path(filedir).parent.parent\n    return pathlib.Path(datadir)", "blocks": [{"id": 1, "label": "def get_data_path() -> pathlib.Path:\nif getattr(sys, \"frozen\", False):", "successors": [{"id": 3, "label": "    datadir = os.path.dirname(sys.executable)\nreturn pathlib.Path(datadir)", "successors": []}, {"id": 4, "label": "    filedir = os.path.dirname(__file__)\n    datadir = pathlib.Path(filedir).parent.parent\nreturn pathlib.Path(datadir)", "successors": []}]}]}], "classes": [], "simplified_code": "import os\nimport pathlib\nimport sys\n\n\n    return pathlib.Path(datadir)\n\n\n    return pathlib.Path(datadir)", "blocks": [{"id": 1, "label": "import os\nimport pathlib\nimport sys\nreturn pathlib.Path(datadir)", "successors": []}]}
{"file_name": "79.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 52, "functions": [{"name": "binary_and", "type": "function", "start_line": 4, "end_line": 46, "functions": [], "classes": [], "simplified_code": "def binary_and(a: int, b: int) -> str:\n    \"\"\"\n    Take in 2 integers, convert them to binary,\n    return a binary number that is the\n    result of a binary and operation on the integers provided.\n\n    >>> binary_and(25, 32)\n    '0b000000'\n    >>> binary_and(37, 50)\n    '0b100000'\n    >>> binary_and(21, 30)\n    '0b10100'\n    >>> binary_and(58, 73)\n    '0b0001000'\n    >>> binary_and(0, 255)\n    '0b00000000'\n    >>> binary_and(256, 256)\n    '0b100000000'\n    >>> binary_and(0, -1)\n    Traceback (most recent call last):\n        ...\n    ValueError: the value of both inputs must be positive\n    >>> binary_and(0, 1.1)\n    Traceback (most recent call last):\n        ...\n    ValueError: Unknown format code 'b' for object of type 'float'\n    >>> binary_and(\"0\", \"1\")\n    Traceback (most recent call last):\n        ...\n    TypeError: '<' not supported between instances of 'str' and 'int'\n    \"\"\"\n    if a < 0 or b < 0:\n        raise ValueError(\"the value of both inputs must be positive\")\n\n    a_binary = format(a, \"b\")\n    b_binary = format(b, \"b\")\n\n    max_len = max(len(a_binary), len(b_binary))\n\n    return \"0b\" + \"\".join(\n        str(int(char_a == \"1\" and char_b == \"1\"))\n        for char_a, char_b in zip(a_binary.zfill(max_len), b_binary.zfill(max_len))\n    )", "blocks": [{"id": 1, "label": "if a < 0 or b < 0:", "successors": [{"id": 2, "label": "    raise ValueError(\"the value of both inputs must be positive\")", "successors": []}, {"id": 3, "label": "a_binary = format(a, \"b\")\nb_binary = format(b, \"b\")\n\nmax_len = max(len(a_binary), len(b_binary))\n\nreturn \"0b\" + \"\".join(\n    str(int(char_a == \"1\" and char_b == \"1\"))\n    for char_a, char_b in zip(a_binary.zfill(max_len), b_binary.zfill(max_len))\n)", "successors": []}]}]}], "classes": [], "simplified_code": "# https://www.tutorialspoint.com/python3/bitwise_operators_example.htm\n\n\n    )\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()", "blocks": [{"id": 1, "label": "if __name__ == \"__main__\":\n    import doctest", "successors": [{"id": 3, "label": "    doctest.testmod()", "successors": []}]}]}
{"file_name": "80.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 12, "functions": [], "classes": [{"name": "BelowLevelFilter", "type": "class", "start_line": 4, "end_line": 12, "functions": [{"name": "__init__", "type": "function", "start_line": 7, "end_line": 9, "functions": [], "classes": [], "simplified_code": "    def __init__(self, below_level: int):\n        super().__init__()\n        self.below_level = below_level", "blocks": [{"id": 1, "label": "def __init__(self, below_level: int):\n    super().__init__()", "successors": [{"id": 3, "label": "    self.below_level = below_level", "successors": []}]}]}, {"name": "filter", "type": "function", "start_line": 11, "end_line": 12, "functions": [], "classes": [], "simplified_code": "    def filter(self, record: logging.LogRecord):\n        return record.levelno < self.below_level", "blocks": [{"id": 1, "label": "def filter(self, record: logging.LogRecord):\n    return record.levelno < self.below_level", "successors": []}]}], "simplified_code": "class BelowLevelFilter(logging.Filter):\n    \"\"\"Filter for logging levels below a certain threshold.\"\"\"\n\n        self.below_level = below_level\n\n        return record.levelno < self.below_level", "blocks": [{"id": 1, "label": "class BelowLevelFilter(logging.Filter):\n\"\"\"Filter for logging levels below a certain threshold.\"\"\"", "successors": [{"id": 3, "label": "self.below_level = below_level", "successors": []}, {"id": 4, "label": "return record.levelno < self.below_level", "successors": []}]}]}], "simplified_code": "import logging\n\n\n        return record.levelno < self.below_level", "blocks": [{"id": 1, "label": "import logging\nreturn record.levelno < self.below_level", "successors": []}]}
{"file_name": "81.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 38, "functions": [{"name": "test_service_creation", "type": "function", "start_line": 33, "end_line": 38, "functions": [], "classes": [], "simplified_code": "async def test_service_creation(server):\n    with ServiceTest():\n        client = get_service_client(ServiceTest)\n        assert client.add(5, 3) == 8\n        assert client.subtract(10, 4) == 6\n        assert client.fun_with_async(5, 3) == 8", "blocks": [{"id": 1, "label": "async def test_service_creation(server):\nwith ServiceTest():", "successors": [{"id": 3, "label": "    client = get_service_client(ServiceTest)\n    assert client.add(5, 3) == 8\n    assert client.subtract(10, 4) == 6\n    assert client.fun_with_async(5, 3) == 8", "successors": []}]}]}], "classes": [{"name": "ServiceTest", "type": "class", "start_line": 8, "end_line": 29, "functions": [{"name": "__init__", "type": "function", "start_line": 9, "end_line": 10, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__()", "blocks": [{"id": 1, "label": "def __init__(self):\n    super().__init__()", "successors": []}]}, {"name": "get_port", "type": "function", "start_line": 13, "end_line": 14, "functions": [], "classes": [], "simplified_code": "    def get_port(cls) -> int:\n        return TEST_SERVICE_PORT", "blocks": [{"id": 1, "label": "def get_port(cls) -> int:\n    return TEST_SERVICE_PORT", "successors": []}]}, {"name": "add", "type": "function", "start_line": 17, "end_line": 18, "functions": [], "classes": [], "simplified_code": "    def add(self, a: int, b: int) -> int:\n        return a + b", "blocks": [{"id": 1, "label": "def add(self, a: int, b: int) -> int:\n    return a + b", "successors": []}]}, {"name": "subtract", "type": "function", "start_line": 21, "end_line": 22, "functions": [], "classes": [], "simplified_code": "    def subtract(self, a: int, b: int) -> int:\n        return a - b", "blocks": [{"id": 1, "label": "def subtract(self, a: int, b: int) -> int:\n    return a - b", "successors": []}]}, {"name": "fun_with_async", "type": "function", "start_line": 25, "end_line": 29, "functions": [{"name": "add_async", "type": "function", "start_line": 26, "end_line": 27, "functions": [], "classes": [], "simplified_code": "        async def add_async(a: int, b: int) -> int:\n            return a + b", "blocks": [{"id": 1, "label": "async def add_async(a: int, b: int) -> int:\nreturn a + b", "successors": []}]}], "classes": [], "simplified_code": "    def fun_with_async(self, a: int, b: int) -> int:\n            return a + b\n\n        return self.run_and_wait(add_async(a, b))", "blocks": [{"id": 1, "label": "def fun_with_async(self, a: int, b: int) -> int:\n    return a + b", "successors": []}]}], "simplified_code": "class ServiceTest(AppService):\n        super().__init__()\n\n    @classmethod\n        return TEST_SERVICE_PORT\n\n    @expose\n        return a + b\n\n    @expose\n        return a - b\n\n    @expose\n        return self.run_and_wait(add_async(a, b))", "blocks": [{"id": 1, "label": "class ServiceTest(AppService):\nsuper().__init__()", "successors": []}]}], "simplified_code": "import pytest\n\nfrom backend.util.service import AppService, expose, get_service_client\n\nTEST_SERVICE_PORT = 8765\n\n\n        return self.run_and_wait(add_async(a, b))\n\n\n@pytest.mark.asyncio(scope=\"session\")\n        assert client.fun_with_async(5, 3) == 8", "blocks": [{"id": 1, "label": "import pytest\nfrom backend.util.service import AppService, expose, get_service_client", "successors": [{"id": 3, "label": "TEST_SERVICE_PORT = 8765\nreturn self.run_and_wait(add_async(a, b))", "successors": [{"id": 5, "label": "@pytest.mark.asyncio(scope=\"session\")\nassert client.fun_with_async(5, 3) == 8", "successors": []}]}]}]}
{"file_name": "82.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 94, "functions": [{"name": "gray_code", "type": "function", "start_line": 1, "end_line": 47, "functions": [], "classes": [], "simplified_code": "def gray_code(bit_count: int) -> list:\n    \"\"\"\n    Takes in an integer n and returns a n-bit\n    gray code sequence\n    An n-bit gray code sequence is a sequence of 2^n\n    integers where:\n\n    a) Every integer is between [0,2^n -1] inclusive\n    b) The sequence begins with 0\n    c) An integer appears at most one times in the sequence\n    d)The binary representation of every pair of integers differ\n       by exactly one bit\n    e) The binary representation of first and last bit also\n       differ by exactly one bit\n\n    >>> gray_code(2)\n    [0, 1, 3, 2]\n\n    >>> gray_code(1)\n    [0, 1]\n\n    >>> gray_code(3)\n    [0, 1, 3, 2, 6, 7, 5, 4]\n\n    >>> gray_code(-1)\n    Traceback (most recent call last):\n        ...\n    ValueError: The given input must be positive\n\n    >>> gray_code(10.6)\n    Traceback (most recent call last):\n        ...\n    TypeError: unsupported operand type(s) for <<: 'int' and 'float'\n    \"\"\"\n\n    # bit count represents no. of bits in the gray code\n    if bit_count < 0:\n        raise ValueError(\"The given input must be positive\")\n\n    # get the generated string sequence\n    sequence = gray_code_sequence_string(bit_count)\n    #\n    # convert them to integers\n    for i in range(len(sequence)):\n        sequence[i] = int(sequence[i], 2)\n\n    return sequence", "blocks": [{"id": 1, "label": "def gray_code(bit_count: int) -> list:\nif bit_count < 0:", "successors": [{"id": 3, "label": "raise ValueError(\"The given input must be positive\")", "successors": []}, {"id": 4, "label": "sequence = gray_code_sequence_string(bit_count)", "successors": [{"id": 5, "label": "for i in range(len(sequence)):", "successors": [{"id": 6, "label": "sequence[i] = int(sequence[i], 2)\nreturn sequence", "successors": []}]}]}]}]}, {"name": "gray_code_sequence_string", "type": "function", "start_line": 50, "end_line": 88, "functions": [], "classes": [], "simplified_code": "def gray_code_sequence_string(bit_count: int) -> list:\n    \"\"\"\n    Will output the n-bit grey sequence as a\n    string of bits\n\n    >>> gray_code_sequence_string(2)\n    ['00', '01', '11', '10']\n\n    >>> gray_code_sequence_string(1)\n    ['0', '1']\n    \"\"\"\n\n    # The approach is a recursive one\n    # Base case achieved when either n = 0 or n=1\n    if bit_count == 0:\n        return [\"0\"]\n\n    if bit_count == 1:\n        return [\"0\", \"1\"]\n\n    seq_len = 1 << bit_count  # defines the length of the sequence\n    # 1<< n is equivalent to 2^n\n\n    # recursive answer will generate answer for n-1 bits\n    smaller_sequence = gray_code_sequence_string(bit_count - 1)\n\n    sequence = []\n\n    # append 0 to first half of the smaller sequence generated\n    for i in range(seq_len // 2):\n        generated_no = \"0\" + smaller_sequence[i]\n        sequence.append(generated_no)\n\n    # append 1 to second half ... start from the end of the list\n    for i in reversed(range(seq_len // 2)):\n        generated_no = \"1\" + smaller_sequence[i]\n        sequence.append(generated_no)\n\n    return sequence", "blocks": [{"id": 1, "label": "def gray_code_sequence_string(bit_count: int) -> list:\nif bit_count == 0:", "successors": [{"id": 3, "label": "    return [\"0\"]", "successors": []}, {"id": 4, "label": "if bit_count == 1:", "successors": [{"id": 5, "label": "    return [\"0\", \"1\"]", "successors": []}, {"id": 6, "label": "seq_len = 1 << bit_count\nsmaller_sequence = gray_code_sequence_string(bit_count - 1)", "successors": [{"id": 8, "label": "sequence = []", "successors": [{"id": 9, "label": "for i in range(seq_len // 2):", "successors": [{"id": 10, "label": "    generated_no = \"0\" + smaller_sequence[i]\n    sequence.append(generated_no)", "successors": []}]}, {"id": 12, "label": "for i in reversed(range(seq_len // 2)):", "successors": [{"id": 13, "label": "    generated_no = \"1\" + smaller_sequence[i]\n    sequence.append(generated_no)", "successors": []}]}, {"id": 15, "label": "return sequence", "successors": []}]}]}]}]}]}], "classes": [], "simplified_code": "    return sequence\n\n\n    return sequence\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()", "blocks": [{"id": 1, "label": "return sequence", "successors": []}]}
{"file_name": "83.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 22, "functions": [], "classes": [{"name": "User", "type": "class", "start_line": 9, "end_line": 22, "functions": [{"name": "from_payload", "type": "function", "start_line": 16, "end_line": 22, "functions": [], "classes": [], "simplified_code": "    def from_payload(cls, payload):\n        return cls(\n            user_id=payload[\"sub\"],\n            email=payload.get(\"email\", \"\"),\n            phone_number=payload.get(\"phone\", \"\"),\n            role=payload[\"role\"],\n        )", "blocks": [{"id": 1, "label": "def from_payload(cls, payload):\nreturn cls(user_id=payload[\"sub\"], email=payload.get(\"email\", \"\"), phone_number=payload.get(\"phone\", \"\"), role=payload[\"role\"])", "successors": []}]}], "simplified_code": "class User:\n    user_id: str\n    email: str\n    phone_number: str\n    role: str\n\n    @classmethod\n        )", "blocks": [{"id": 1, "label": "class User:\n    user_id: str\n    email: str\n    phone_number: str\n    role: str", "successors": [{"id": 3, "label": "@classmethod\n        )", "successors": []}]}]}], "simplified_code": "from dataclasses import dataclass\n\nDEFAULT_USER_ID = \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\"\nDEFAULT_EMAIL = \"default@example.com\"\n\n\n# Using dataclass here to avoid adding dependency on pydantic\n@dataclass(frozen=True)\n        )", "blocks": [{"id": 1, "label": "from dataclasses import dataclass\n\nDEFAULT_USER_ID = \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\"\nDEFAULT_EMAIL = \"default@example.com\"\n\n\n@dataclass(frozen=True)", "successors": []}]}
{"file_name": "84.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 118, "functions": [{"name": "connection_manager", "type": "function", "start_line": 13, "end_line": 14, "functions": [], "classes": [], "simplified_code": "def connection_manager() -> ConnectionManager:\n    return ConnectionManager()", "blocks": [{"id": 1, "label": "def connection_manager() -> ConnectionManager:\n    return ConnectionManager()", "successors": []}]}, {"name": "mock_websocket", "type": "function", "start_line": 18, "end_line": 21, "functions": [], "classes": [], "simplified_code": "def mock_websocket() -> AsyncMock:\n    websocket: AsyncMock = AsyncMock(spec=WebSocket)\n    websocket.send_text = AsyncMock()\n    return websocket", "blocks": [{"id": 1, "label": "def mock_websocket() -> AsyncMock:\n    websocket: AsyncMock = AsyncMock(spec=WebSocket)", "successors": [{"id": 3, "label": "    websocket.send_text = AsyncMock()\n    return websocket", "successors": []}]}]}, {"name": "test_connect", "type": "function", "start_line": 25, "end_line": 30, "functions": [], "classes": [], "simplified_code": "async def test_connect(\n    connection_manager: ConnectionManager, mock_websocket: AsyncMock\n) -> None:\n    await connection_manager.connect(mock_websocket)\n    assert mock_websocket in connection_manager.active_connections\n    mock_websocket.accept.assert_called_once()", "blocks": [{"id": 1, "label": "async def test_connect(\n    connection_manager: ConnectionManager, mock_websocket: AsyncMock\n) -> None:\n    await connection_manager.connect(mock_websocket)", "successors": [{"id": 3, "label": "    assert mock_websocket in connection_manager.active_connections\n    mock_websocket.accept.assert_called_once()", "successors": []}]}]}, {"name": "test_disconnect", "type": "function", "start_line": 33, "end_line": 42, "functions": [], "classes": [], "simplified_code": "def test_disconnect(\n    connection_manager: ConnectionManager, mock_websocket: AsyncMock\n) -> None:\n    connection_manager.active_connections.add(mock_websocket)\n    connection_manager.subscriptions[\"test_graph\"] = {mock_websocket}\n\n    connection_manager.disconnect(mock_websocket)\n\n    assert mock_websocket not in connection_manager.active_connections\n    assert mock_websocket not in connection_manager.subscriptions[\"test_graph\"]", "blocks": [{"id": 1, "label": "def test_disconnect(\n    connection_manager: ConnectionManager, mock_websocket: AsyncMock\n) -> None:\nconnection_manager.active_connections.add(mock_websocket)\nconnection_manager.subscriptions[\"test_graph\"] = {mock_websocket}", "successors": [{"id": 3, "label": "connection_manager.disconnect(mock_websocket)\nassert mock_websocket not in connection_manager.active_connections\nassert mock_websocket not in connection_manager.subscriptions[\"test_graph\"]", "successors": []}]}]}, {"name": "test_subscribe", "type": "function", "start_line": 46, "end_line": 50, "functions": [], "classes": [], "simplified_code": "async def test_subscribe(\n    connection_manager: ConnectionManager, mock_websocket: AsyncMock\n) -> None:\n    await connection_manager.subscribe(\"test_graph\", mock_websocket)\n    assert mock_websocket in connection_manager.subscriptions[\"test_graph\"]", "blocks": [{"id": 1, "label": "async def test_subscribe(\n    connection_manager: ConnectionManager, mock_websocket: AsyncMock\n) -> None:\nawait connection_manager.subscribe(\"test_graph\", mock_websocket)", "successors": [{"id": 3, "label": "assert mock_websocket in connection_manager.subscriptions[\"test_graph\"]", "successors": []}]}]}, {"name": "test_unsubscribe", "type": "function", "start_line": 54, "end_line": 61, "functions": [], "classes": [], "simplified_code": "async def test_unsubscribe(\n    connection_manager: ConnectionManager, mock_websocket: AsyncMock\n) -> None:\n    connection_manager.subscriptions[\"test_graph\"] = {mock_websocket}\n\n    await connection_manager.unsubscribe(\"test_graph\", mock_websocket)\n\n    assert \"test_graph\" not in connection_manager.subscriptions", "blocks": [{"id": 1, "label": "async def test_unsubscribe(\n    connection_manager: ConnectionManager, mock_websocket: AsyncMock\n) -> None:\n    connection_manager.subscriptions[\"test_graph\"] = {mock_websocket}", "successors": [{"id": 3, "label": "    await connection_manager.unsubscribe(\"test_graph\", mock_websocket)\n    assert \"test_graph\" not in connection_manager.subscriptions", "successors": []}]}]}, {"name": "test_send_execution_result", "type": "function", "start_line": 65, "end_line": 93, "functions": [], "classes": [], "simplified_code": "async def test_send_execution_result(\n    connection_manager: ConnectionManager, mock_websocket: AsyncMock\n) -> None:\n    connection_manager.subscriptions[\"test_graph\"] = {mock_websocket}\n    result: ExecutionResult = ExecutionResult(\n        graph_id=\"test_graph\",\n        graph_version=1,\n        graph_exec_id=\"test_exec_id\",\n        node_exec_id=\"test_node_exec_id\",\n        node_id=\"test_node_id\",\n        block_id=\"test_block_id\",\n        status=ExecutionStatus.COMPLETED,\n        input_data={\"input1\": \"value1\"},\n        output_data={\"output1\": [\"result1\"]},\n        add_time=datetime.now(tz=timezone.utc),\n        queue_time=None,\n        start_time=datetime.now(tz=timezone.utc),\n        end_time=datetime.now(tz=timezone.utc),\n    )\n\n    await connection_manager.send_execution_result(result)\n\n    mock_websocket.send_text.assert_called_once_with(\n        WsMessage(\n            method=Methods.EXECUTION_EVENT,\n            channel=\"test_graph\",\n            data=result.model_dump(),\n        ).model_dump_json()\n    )", "blocks": [{"id": 1, "label": "connection_manager.subscriptions[\"test_graph\"] = {mock_websocket}\nresult: ExecutionResult = ExecutionResult(\n    graph_id=\"test_graph\",\n    graph_version=1,\n    graph_exec_id=\"test_exec_id\",\n    node_exec_id=\"test_node_exec_id\",\n    node_id=\"test_node_id\",\n    block_id=\"test_block_id\",\n    status=ExecutionStatus.COMPLETED,\n    input_data={\"input1\": \"value1\"},\n    output_data={\"output1\": [\"result1\"]},\n    add_time=datetime.now(tz=timezone.utc),\n    queue_time=None,\n    start_time=datetime.now(tz=timezone.utc),\n    end_time=datetime.now(tz=timezone.utc),\n)", "successors": [{"id": 3, "label": "await connection_manager.send_execution_result(result)\nmock_websocket.send_text.assert_called_once_with(\n    WsMessage(\n        method=Methods.EXECUTION_EVENT,\n        channel=\"test_graph\",\n        data=result.model_dump(),\n    ).model_dump_json()\n)", "successors": []}]}]}, {"name": "test_send_execution_result_no_subscribers", "type": "function", "start_line": 97, "end_line": 118, "functions": [], "classes": [], "simplified_code": "async def test_send_execution_result_no_subscribers(\n    connection_manager: ConnectionManager, mock_websocket: AsyncMock\n) -> None:\n    result: ExecutionResult = ExecutionResult(\n        graph_id=\"test_graph\",\n        graph_version=1,\n        graph_exec_id=\"test_exec_id\",\n        node_exec_id=\"test_node_exec_id\",\n        node_id=\"test_node_id\",\n        block_id=\"test_block_id\",\n        status=ExecutionStatus.COMPLETED,\n        input_data={\"input1\": \"value1\"},\n        output_data={\"output1\": [\"result1\"]},\n        add_time=datetime.now(),\n        queue_time=None,\n        start_time=datetime.now(),\n        end_time=datetime.now(),\n    )\n\n    await connection_manager.send_execution_result(result)\n\n    mock_websocket.send_text.assert_not_called()", "blocks": [{"id": 1, "label": "async def test_send_execution_result_no_subscribers(\n    connection_manager: ConnectionManager, mock_websocket: AsyncMock\n) -> None:\n    result: ExecutionResult = ExecutionResult(\n        graph_id=\"test_graph\",\n        graph_version=1,\n        graph_exec_id=\"test_exec_id\",\n        node_exec_id=\"test_node_exec_id\",\n        node_id=\"test_node_id\",\n        block_id=\"test_block_id\",\n        status=ExecutionStatus.COMPLETED,\n        input_data={\"input1\": \"value1\"},\n        output_data={\"output1\": [\"result1\"]},\n        add_time=datetime.now(),\n        queue_time=None,\n        start_time=datetime.now(),\n        end_time=datetime.now(),\n    )", "successors": [{"id": 3, "label": "    await connection_manager.send_execution_result(result)\n    mock_websocket.send_text.assert_not_called()", "successors": []}]}]}], "classes": [], "simplified_code": "from datetime import datetime, timezone\nfrom unittest.mock import AsyncMock\n\nimport pytest\nfrom fastapi import WebSocket\n\nfrom backend.data.execution import ExecutionResult, ExecutionStatus\nfrom backend.server.conn_manager import ConnectionManager\nfrom backend.server.model import Methods, WsMessage\n\n\n@pytest.fixture\n    return ConnectionManager()\n\n\n@pytest.fixture\n    return websocket\n\n\n@pytest.mark.asyncio\n    mock_websocket.accept.assert_called_once()\n\n\n    assert mock_websocket not in connection_manager.subscriptions[\"test_graph\"]\n\n\n@pytest.mark.asyncio\n    assert mock_websocket in connection_manager.subscriptions[\"test_graph\"]\n\n\n@pytest.mark.asyncio\n    assert \"test_graph\" not in connection_manager.subscriptions\n\n\n@pytest.mark.asyncio\n    )\n\n\n@pytest.mark.asyncio\n    mock_websocket.send_text.assert_not_called()", "blocks": [{"id": 1, "label": "from datetime import datetime, timezone\nfrom unittest.mock import AsyncMock\n\nimport pytest\nfrom fastapi import WebSocket\n\nfrom backend.data.execution import ExecutionResult, ExecutionStatus\nfrom backend.server.conn_manager import ConnectionManager\nfrom backend.server.model import Methods, WsMessage\n\n\n@pytest.fixture\n    return ConnectionManager()\n\n\n@pytest.fixture\n    return websocket\n\n\n@pytest.mark.asyncio\n    mock_websocket.accept.assert_called_once()\n\n\n    assert mock_websocket not in connection_manager.subscriptions[\"test_graph\"]\n\n\n@pytest.mark.asyncio\n    assert mock_websocket in connection_manager.subscriptions[\"test_graph\"]\n\n\n@pytest.mark.asyncio\n    assert \"test_graph\" not in connection_manager.subscriptions\n\n\n@pytest.mark.asyncio\n    )\n\n\n@pytest.mark.asyncio\n    mock_websocket.send_text.assert_not_called()", "successors": []}]}
{"file_name": "85.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 184, "functions": [], "classes": [{"name": "GoogleSheetsReadBlock", "type": "class", "start_line": 17, "end_line": 99, "functions": [{"name": "__init__", "type": "function", "start_line": 37, "end_line": 66, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"5724e902-3635-47e9-a108-aaa0263a4988\",\n            description=\"This block reads data from a Google Sheets spreadsheet.\",\n            categories={BlockCategory.DATA},\n            input_schema=GoogleSheetsReadBlock.Input,\n            output_schema=GoogleSheetsReadBlock.Output,\n            disabled=not GOOGLE_OAUTH_IS_CONFIGURED,\n            test_input={\n                \"spreadsheet_id\": \"1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms\",\n                \"range\": \"Sheet1!A1:B2\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\n                    \"result\",\n                    [\n                        [\"Name\", \"Score\"],\n                        [\"Alice\", \"85\"],\n                    ],\n                ),\n            ],\n            test_mock={\n                \"_read_sheet\": lambda *args, **kwargs: [\n                    [\"Name\", \"Score\"],\n                    [\"Alice\", \"85\"],\n                ],\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"5724e902-3635-47e9-a108-aaa0263a4988\",\n    description=\"This block reads data from a Google Sheets spreadsheet.\",\n    categories={BlockCategory.DATA},\n    input_schema=GoogleSheetsReadBlock.Input,\n    output_schema=GoogleSheetsReadBlock.Output,\n    disabled=not GOOGLE_OAUTH_IS_CONFIGURED,\n    test_input={\n        \"spreadsheet_id\": \"1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms\",\n        \"range\": \"Sheet1!A1:B2\",\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\n            \"result\",\n            [\n                [\"Name\", \"Score\"],\n                [\"Alice\", \"85\"],\n            ],\n        ),\n    ],\n    test_mock={\n        \"_read_sheet\": lambda *args, **kwargs: [\n            [\"Name\", \"Score\"],\n            [\"Alice\", \"85\"],\n        ],\n    },\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 68, "end_line": 73, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: GoogleCredentials, **kwargs\n    ) -> BlockOutput:\n        service = self._build_service(credentials, **kwargs)\n        data = self._read_sheet(service, input_data.spreadsheet_id, input_data.range)\n        yield \"result\", data", "blocks": [{"id": 1, "label": "def run( self, input_data: Input, *, credentials: GoogleCredentials, **kwargs ) -> BlockOutput:\n    service = self._build_service(credentials, **kwargs)\n    data = self._read_sheet(service, input_data.spreadsheet_id, input_data.range)\n    yield \"result\", data", "successors": []}]}, {"name": "_build_service", "type": "function", "start_line": 76, "end_line": 93, "functions": [], "classes": [], "simplified_code": "    def _build_service(credentials: GoogleCredentials, **kwargs):\n        creds = Credentials(\n            token=(\n                credentials.access_token.get_secret_value()\n                if credentials.access_token\n                else None\n            ),\n            refresh_token=(\n                credentials.refresh_token.get_secret_value()\n                if credentials.refresh_token\n                else None\n            ),\n            token_uri=\"https://oauth2.googleapis.com/token\",\n            client_id=kwargs.get(\"client_id\"),\n            client_secret=kwargs.get(\"client_secret\"),\n            scopes=credentials.scopes,\n        )\n        return build(\"sheets\", \"v4\", credentials=creds)", "blocks": [{"id": 1, "label": "def _build_service(credentials: GoogleCredentials, **kwargs):\ncreds = Credentials(", "successors": [{"id": 3, "label": "token=(credentials.access_token.get_secret_value() if credentials.access_token else None),\nrefresh_token=(credentials.refresh_token.get_secret_value() if credentials.refresh_token else None),", "successors": [{"id": 5, "label": "token_uri=\"https://oauth2.googleapis.com/token\",\nclient_id=kwargs.get(\"client_id\"),", "successors": [{"id": 7, "label": "client_secret=kwargs.get(\"client_secret\"),\nscopes=credentials.scopes,", "successors": [{"id": 9, "label": ")\nreturn build(\"sheets\", \"v4\", credentials=creds)", "successors": []}]}]}]}]}]}, {"name": "_read_sheet", "type": "function", "start_line": 95, "end_line": 98, "functions": [], "classes": [], "simplified_code": "    def _read_sheet(self, service, spreadsheet_id: str, range: str) -> list[list[str]]:\n        sheet = service.spreadsheets()\n        result = sheet.values().get(spreadsheetId=spreadsheet_id, range=range).execute()\n        return result.get(\"values\", [])", "blocks": [{"id": 1, "label": "def _read_sheet(self, service, spreadsheet_id: str, range: str) -> list[list[str]]:\n    sheet = service.spreadsheets()", "successors": [{"id": 3, "label": "    result = sheet.values().get(spreadsheetId=spreadsheet_id, range=range).execute()\n    return result.get(\"values\", [])", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 18, "end_line": 27, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GoogleCredentialsInput = GoogleCredentialsField(\n            [\"https://www.googleapis.com/auth/spreadsheets.readonly\"]\n        )\n        spreadsheet_id: str = SchemaField(\n            description=\"The ID of the spreadsheet to read from\",\n        )\n        range: str = SchemaField(\n            description=\"The A1 notation of the range to read\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    credentials: GoogleCredentialsInput = GoogleCredentialsField(\n        [\"https://www.googleapis.com/auth/spreadsheets.readonly\"]\n    )", "successors": []}, {"id": 3, "label": "    spreadsheet_id: str = SchemaField(\n        description=\"The ID of the spreadsheet to read from\",\n    )", "successors": []}, {"id": 4, "label": "    range: str = SchemaField(\n        description=\"The A1 notation of the range to read\",\n    )", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 29, "end_line": 35, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        result: list[list[str]] = SchemaField(\n            description=\"The data read from the spreadsheet\",\n        )\n        error: str = SchemaField(\n            description=\"Error message if any\",\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "    result: list[list[str]] = SchemaField(\n        description=\"The data read from the spreadsheet\",\n    )", "successors": []}, {"id": 3, "label": "    error: str = SchemaField(\n        description=\"Error message if any\",\n    )", "successors": []}]}]}], "simplified_code": "class GoogleSheetsReadBlock(Block):\n        )\n\n        )\n\n        )\n\n        yield \"result\", data\n\n    @staticmethod\n        return build(\"sheets\", \"v4\", credentials=creds)\n\n        return result.get(\"values\", [])\n", "blocks": [{"id": 1, "label": "class GoogleSheetsReadBlock(Block):\n", "successors": [{"id": 3, "label": "\nyield \"result\", data", "successors": []}, {"id": 5, "label": "@staticmethod", "successors": [{"id": 6, "label": "return build(\"sheets\", \"v4\", credentials=creds)", "successors": []}, {"id": 7, "label": "return result.get(\"values\", [])", "successors": []}]}]}]}, {"name": "GoogleSheetsWriteBlock", "type": "class", "start_line": 101, "end_line": 184, "functions": [{"name": "__init__", "type": "function", "start_line": 124, "end_line": 155, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"d9291e87-301d-47a8-91fe-907fb55460e5\",\n            description=\"This block writes data to a Google Sheets spreadsheet.\",\n            categories={BlockCategory.DATA},\n            input_schema=GoogleSheetsWriteBlock.Input,\n            output_schema=GoogleSheetsWriteBlock.Output,\n            disabled=not GOOGLE_OAUTH_IS_CONFIGURED,\n            test_input={\n                \"spreadsheet_id\": \"1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms\",\n                \"range\": \"Sheet1!A1:B2\",\n                \"values\": [\n                    [\"Name\", \"Score\"],\n                    [\"Bob\", \"90\"],\n                ],\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\n                    \"result\",\n                    {\"updatedCells\": 4, \"updatedColumns\": 2, \"updatedRows\": 2},\n                ),\n            ],\n            test_mock={\n                \"_write_sheet\": lambda *args, **kwargs: {\n                    \"updatedCells\": 4,\n                    \"updatedColumns\": 2,\n                    \"updatedRows\": 2,\n                },\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"d9291e87-301d-47a8-91fe-907fb55460e5\",\n    description=\"This block writes data to a Google Sheets spreadsheet.\",\n    categories={BlockCategory.DATA},\n    input_schema=GoogleSheetsWriteBlock.Input,\n    output_schema=GoogleSheetsWriteBlock.Output,\n    disabled=not GOOGLE_OAUTH_IS_CONFIGURED,\n    test_input={\n        \"spreadsheet_id\": \"1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms\",\n        \"range\": \"Sheet1!A1:B2\",\n        \"values\": [\n            [\"Name\", \"Score\"],\n            [\"Bob\", \"90\"],\n        ],\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\n            \"result\",\n            {\"updatedCells\": 4, \"updatedColumns\": 2, \"updatedRows\": 2},\n        ),\n    ],\n    test_mock={\n        \"_write_sheet\": lambda *args, **kwargs: {\n            \"updatedCells\": 4,\n            \"updatedColumns\": 2,\n            \"updatedRows\": 2,\n        },\n    },\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 157, "end_line": 167, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: GoogleCredentials, **kwargs\n    ) -> BlockOutput:\n        service = GoogleSheetsReadBlock._build_service(credentials, **kwargs)\n        result = self._write_sheet(\n            service,\n            input_data.spreadsheet_id,\n            input_data.range,\n            input_data.values,\n        )\n        yield \"result\", result", "blocks": [{"id": 1, "label": "def run(     self, input_data: Input, *, credentials: GoogleCredentials, **kwargs ) -> BlockOutput:\nservice = GoogleSheetsReadBlock._build_service(credentials, **kwargs)", "successors": [{"id": 3, "label": "result = self._write_sheet( service, input_data.spreadsheet_id, input_data.range, input_data.values, )\nyield \"result\", result", "successors": []}]}]}, {"name": "_write_sheet", "type": "function", "start_line": 169, "end_line": 184, "functions": [], "classes": [], "simplified_code": "    def _write_sheet(\n        self, service, spreadsheet_id: str, range: str, values: list[list[str]]\n    ) -> dict:\n        body = {\"values\": values}\n        result = (\n            service.spreadsheets()\n            .values()\n            .update(\n                spreadsheetId=spreadsheet_id,\n                range=range,\n                valueInputOption=\"USER_ENTERED\",\n                body=body,\n            )\n            .execute()\n        )\n        return result", "blocks": [{"id": 1, "label": "def _write_sheet(self, service, spreadsheet_id: str, range: str, values: list[list[str]]) -> dict:\n    body = {\"values\": values}\nresult = (service.spreadsheets().values().update(spreadsheetId=spreadsheet_id, range=range, valueInputOption=\"USER_ENTERED\", body=body).execute())", "successors": [{"id": 3, "label": "return result", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 102, "end_line": 114, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GoogleCredentialsInput = GoogleCredentialsField(\n            [\"https://www.googleapis.com/auth/spreadsheets\"]\n        )\n        spreadsheet_id: str = SchemaField(\n            description=\"The ID of the spreadsheet to write to\",\n        )\n        range: str = SchemaField(\n            description=\"The A1 notation of the range to write\",\n        )\n        values: list[list[str]] = SchemaField(\n            description=\"The data to write to the spreadsheet\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: GoogleCredentialsInput = GoogleCredentialsField([\n        \"https://www.googleapis.com/auth/spreadsheets\"\n    ])", "successors": [{"id": 3, "label": "    spreadsheet_id: str = SchemaField(\n        description=\"The ID of the spreadsheet to write to\",\n    )\n    range: str = SchemaField(\n        description=\"The A1 notation of the range to write\",\n    )", "successors": [{"id": 5, "label": "    values: list[list[str]] = SchemaField(\n        description=\"The data to write to the spreadsheet\",\n    )", "successors": []}]}]}]}, {"name": "Output", "type": "class", "start_line": 116, "end_line": 122, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        result: dict = SchemaField(\n            description=\"The result of the write operation\",\n        )\n        error: str = SchemaField(\n            description=\"Error message if any\",\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    result: dict = SchemaField(\n        description=\"The result of the write operation\",\n    )\n    error: str = SchemaField(\n        description=\"Error message if any\",\n    )", "successors": []}]}], "simplified_code": "class GoogleSheetsWriteBlock(Block):\n        )\n\n        )\n\n        )\n\n        yield \"result\", result\n\n        return result", "blocks": [{"id": 1, "label": "class GoogleSheetsWriteBlock(Block):\ndef __init__(self, param):", "successors": [{"id": 3, "label": "self.param = param\ndef execute(self):", "successors": [{"id": 5, "label": "result = \"Executed with \" + self.param", "successors": [{"id": 6, "label": "yield \"result\", result", "successors": []}, {"id": 7, "label": "return result", "successors": []}]}]}]}]}], "simplified_code": "from google.oauth2.credentials import Credentials\nfrom googleapiclient.discovery import build\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\nfrom ._auth import (\n    GOOGLE_OAUTH_IS_CONFIGURED,\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    GoogleCredentials,\n    GoogleCredentialsField,\n    GoogleCredentialsInput,\n)\n\n\n\n\n        return result", "blocks": [{"id": 1, "label": "from google.oauth2.credentials import Credentials\nfrom googleapiclient.discovery import build\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\nfrom ._auth import (\n    GOOGLE_OAUTH_IS_CONFIGURED,\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    GoogleCredentials,\n    GoogleCredentialsField,\n    GoogleCredentialsInput,\n)", "successors": []}]}
{"file_name": "86.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 98, "functions": [{"name": "test_block_credit_usage", "type": "function", "start_line": 17, "end_line": 50, "functions": [], "classes": [], "simplified_code": "async def test_block_credit_usage(server: SpinTestServer):\n    current_credit = await user_credit.get_or_refill_credit(DEFAULT_USER_ID)\n\n    spending_amount_1 = await user_credit.spend_credits(\n        DEFAULT_USER_ID,\n        current_credit,\n        AITextGeneratorBlock().id,\n        {\n            \"model\": \"gpt-4-turbo\",\n            \"credentials\": {\n                \"id\": openai_credentials.id,\n                \"provider\": openai_credentials.provider,\n                \"type\": openai_credentials.type,\n            },\n        },\n        0.0,\n        0.0,\n        validate_balance=False,\n    )\n    assert spending_amount_1 > 0\n\n    spending_amount_2 = await user_credit.spend_credits(\n        DEFAULT_USER_ID,\n        current_credit,\n        AITextGeneratorBlock().id,\n        {\"model\": \"gpt-4-turbo\", \"api_key\": \"owned_api_key\"},\n        0.0,\n        0.0,\n        validate_balance=False,\n    )\n    assert spending_amount_2 == 0\n\n    new_credit = await user_credit.get_or_refill_credit(DEFAULT_USER_ID)\n    assert new_credit == current_credit - spending_amount_1 - spending_amount_2", "blocks": [{"id": 1, "label": "async def test_block_credit_usage(server: SpinTestServer):\ncurrent_credit = await user_credit.get_or_refill_credit(DEFAULT_USER_ID)", "successors": [{"id": 3, "label": "spending_amount_1 = await user_credit.spend_credits(\n    DEFAULT_USER_ID,\n    current_credit,\n    AITextGeneratorBlock().id,\n    {\n        \"model\": \"gpt-4-turbo\",\n        \"credentials\": {\n            \"id\": openai_credentials.id,\n            \"provider\": openai_credentials.provider,\n            \"type\": openai_credentials.type,\n        },\n    },\n    0.0,\n    0.0,\n    validate_balance=False,\n)\nassert spending_amount_1 > 0", "successors": [{"id": 5, "label": "spending_amount_2 = await user_credit.spend_credits(\n    DEFAULT_USER_ID,\n    current_credit,\n    AITextGeneratorBlock().id,\n    {\"model\": \"gpt-4-turbo\", \"api_key\": \"owned_api_key\"},\n    0.0,\n    0.0,\n    validate_balance=False,\n)\nassert spending_amount_2 == 0", "successors": [{"id": 7, "label": "new_credit = await user_credit.get_or_refill_credit(DEFAULT_USER_ID)\nassert new_credit == current_credit - spending_amount_1 - spending_amount_2", "successors": []}]}]}]}]}, {"name": "test_block_credit_top_up", "type": "function", "start_line": 54, "end_line": 60, "functions": [], "classes": [], "simplified_code": "async def test_block_credit_top_up(server: SpinTestServer):\n    current_credit = await user_credit.get_or_refill_credit(DEFAULT_USER_ID)\n\n    await user_credit.top_up_credits(DEFAULT_USER_ID, 100)\n\n    new_credit = await user_credit.get_or_refill_credit(DEFAULT_USER_ID)\n    assert new_credit == current_credit + 100", "blocks": [{"id": 1, "label": "async def test_block_credit_top_up(server: SpinTestServer):\ncurrent_credit = await user_credit.get_or_refill_credit(DEFAULT_USER_ID)", "successors": [{"id": 3, "label": "await user_credit.top_up_credits(DEFAULT_USER_ID, 100)\nnew_credit = await user_credit.get_or_refill_credit(DEFAULT_USER_ID)", "successors": [{"id": 5, "label": "assert new_credit == current_credit + 100", "successors": []}]}]}]}, {"name": "test_block_credit_reset", "type": "function", "start_line": 64, "end_line": 79, "functions": [], "classes": [], "simplified_code": "async def test_block_credit_reset(server: SpinTestServer):\n    month1 = datetime(2022, 1, 15)\n    month2 = datetime(2022, 2, 15)\n\n    user_credit.time_now = lambda: month2\n    month2credit = await user_credit.get_or_refill_credit(DEFAULT_USER_ID)\n\n    # Month 1 result should only affect month 1\n    user_credit.time_now = lambda: month1\n    month1credit = await user_credit.get_or_refill_credit(DEFAULT_USER_ID)\n    await user_credit.top_up_credits(DEFAULT_USER_ID, 100)\n    assert await user_credit.get_or_refill_credit(DEFAULT_USER_ID) == month1credit + 100\n\n    # Month 2 balance is unaffected\n    user_credit.time_now = lambda: month2\n    assert await user_credit.get_or_refill_credit(DEFAULT_USER_ID) == month2credit", "blocks": [{"id": 1, "label": "async def test_block_credit_reset(server: SpinTestServer):\n    month1 = datetime(2022, 1, 15)\n    month2 = datetime(2022, 2, 15)", "successors": [{"id": 3, "label": "    user_credit.time_now = lambda: month2\n    month2credit = await user_credit.get_or_refill_credit(DEFAULT_USER_ID)\n    user_credit.time_now = lambda: month1\n    month1credit = await user_credit.get_or_refill_credit(DEFAULT_USER_ID)\n    await user_credit.top_up_credits(DEFAULT_USER_ID, 100)\n    assert await user_credit.get_or_refill_credit(DEFAULT_USER_ID) == month1credit + 100", "successors": [{"id": 5, "label": "    user_credit.time_now = lambda: month2\n    assert await user_credit.get_or_refill_credit(DEFAULT_USER_ID) == month2credit", "successors": []}]}]}]}, {"name": "test_credit_refill", "type": "function", "start_line": 83, "end_line": 98, "functions": [], "classes": [], "simplified_code": "async def test_credit_refill(server: SpinTestServer):\n    # Clear all transactions within the month\n    await CreditTransaction.prisma().update_many(\n        where={\n            \"userId\": DEFAULT_USER_ID,\n            \"createdAt\": {\n                \"gte\": datetime(2022, 2, 1),\n                \"lt\": datetime(2022, 3, 1),\n            },\n        },\n        data={\"isActive\": False},\n    )\n    user_credit.time_now = lambda: datetime(2022, 2, 15)\n\n    balance = await user_credit.get_or_refill_credit(DEFAULT_USER_ID)\n    assert balance == REFILL_VALUE", "blocks": [{"id": 1, "label": "async def test_credit_refill(server: SpinTestServer):\n    # Clear all transactions within the month\n    await CreditTransaction.prisma().update_many(\n        where={\n            \"userId\": DEFAULT_USER_ID,\n            \"createdAt\": {\n                \"gte\": datetime(2022, 2, 1),\n                \"lt\": datetime(2022, 3, 1),\n            },\n        },\n        data={\"isActive\": False},\n    )\n    user_credit.time_now = lambda: datetime(2022, 2, 15)", "successors": [{"id": 3, "label": "balance = await user_credit.get_or_refill_credit(DEFAULT_USER_ID)\nassert balance == REFILL_VALUE", "successors": []}]}]}], "classes": [], "simplified_code": "from datetime import datetime\n\nimport pytest\nfrom prisma.models import CreditTransaction\n\nfrom backend.blocks.llm import AITextGeneratorBlock\nfrom backend.data.credit import UserCredit\nfrom backend.data.user import DEFAULT_USER_ID\nfrom backend.integrations.credentials_store import openai_credentials\nfrom backend.util.test import SpinTestServer\n\nREFILL_VALUE = 1000\nuser_credit = UserCredit(REFILL_VALUE)\n\n\n@pytest.mark.asyncio(scope=\"session\")\n    assert new_credit == current_credit - spending_amount_1 - spending_amount_2\n\n\n@pytest.mark.asyncio(scope=\"session\")\n    assert new_credit == current_credit + 100\n\n\n@pytest.mark.asyncio(scope=\"session\")\n    assert await user_credit.get_or_refill_credit(DEFAULT_USER_ID) == month2credit\n\n\n@pytest.mark.asyncio(scope=\"session\")\n    assert balance == REFILL_VALUE", "blocks": [{"id": 1, "label": "from datetime import datetime\nimport pytest", "successors": [{"id": 3, "label": "from prisma.models import CreditTransaction\nfrom backend.blocks.llm import AITextGeneratorBlock", "successors": [{"id": 5, "label": "from backend.data.credit import UserCredit\nfrom backend.data.user import DEFAULT_USER_ID", "successors": [{"id": 7, "label": "from backend.integrations.credentials_store import openai_credentials\nfrom backend.util.test import SpinTestServer", "successors": [{"id": 9, "label": "REFILL_VALUE = 1000\nuser_credit = UserCredit(REFILL_VALUE)", "successors": [{"id": 11, "label": "@pytest.mark.asyncio(scope=\"session\")\nassert new_credit == current_credit - spending_amount_1 - spending_amount_2", "successors": [{"id": 13, "label": "@pytest.mark.asyncio(scope=\"session\")\nassert new_credit == current_credit + 100", "successors": [{"id": 15, "label": "@pytest.mark.asyncio(scope=\"session\")\nassert await user_credit.get_or_refill_credit(DEFAULT_USER_ID) == month2credit", "successors": [{"id": 17, "label": "@pytest.mark.asyncio(scope=\"session\")\nassert balance == REFILL_VALUE", "successors": []}]}]}]}]}]}]}]}]}]}
{"file_name": "87.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 170, "functions": [{"name": "create_test_graph", "type": "function", "start_line": 11, "end_line": 141, "functions": [], "classes": [], "simplified_code": "def create_test_graph() -> Graph:\n    \"\"\"\n                    subreddit\n                       ||\n                        v\n        GetRedditPostsBlock (post_id, post_title, post_body)\n                  //     ||     \\\\\n              post_id  post_title  post_body\n                 ||       ||        ||\n                 v        v         v\n              FillTextTemplateBlock (format)\n                      ||\n                      v\n            AIStructuredResponseBlock / TextRelevancy\n                 ||       ||       ||\n            post_id  is_relevant  marketing_text\n               ||       ||        ||\n               v        v         v\n                 MatchTextPatternBlock\n                 ||       ||\n              positive  negative\n                ||\n                v\n        PostRedditCommentBlock\n    \"\"\"\n    # Hardcoded inputs\n    reddit_get_post_input = {\n        \"post_limit\": 3,\n    }\n    text_formatter_input = {\n        \"format\": \"\"\"\nBased on the following post, write your marketing comment:\n* Post ID: {id}\n* Post Subreddit: {subreddit}\n* Post Title: {title}\n* Post Body: {body}\"\"\".strip(),\n    }\n    llm_call_input = {\n        \"sys_prompt\": \"\"\"\nYou are an expert at marketing.\nYou have been tasked with picking Reddit posts that are relevant to your product.\nThe product you are marketing is: Auto-GPT an autonomous AI agent utilizing GPT model.\nYou reply the post that you find it relevant to be replied with marketing text.\nMake sure to only comment on a relevant post.\n\"\"\",\n        \"expected_format\": {\n            \"post_id\": \"str, the reddit post id\",\n            \"is_relevant\": \"bool, whether the post is relevant for marketing\",\n            \"marketing_text\": \"str, marketing text, this is empty on irrelevant posts\",\n        },\n    }\n    text_matcher_input = {\"match\": \"true\", \"case_sensitive\": False}\n    reddit_comment_input = {}\n\n    # Nodes\n    reddit_get_post_node = Node(\n        block_id=GetRedditPostsBlock().id,\n        input_default=reddit_get_post_input,\n    )\n    text_formatter_node = Node(\n        block_id=FillTextTemplateBlock().id,\n        input_default=text_formatter_input,\n    )\n    llm_call_node = Node(\n        block_id=AIStructuredResponseGeneratorBlock().id, input_default=llm_call_input\n    )\n    text_matcher_node = Node(\n        block_id=MatchTextPatternBlock().id,\n        input_default=text_matcher_input,\n    )\n    reddit_comment_node = Node(\n        block_id=PostRedditCommentBlock().id,\n        input_default=reddit_comment_input,\n    )\n\n    nodes = [\n        reddit_get_post_node,\n        text_formatter_node,\n        llm_call_node,\n        text_matcher_node,\n        reddit_comment_node,\n    ]\n\n    # Links\n    links = [\n        Link(\n            source_id=reddit_get_post_node.id,\n            sink_id=text_formatter_node.id,\n            source_name=\"post\",\n            sink_name=\"values\",\n        ),\n        Link(\n            source_id=text_formatter_node.id,\n            sink_id=llm_call_node.id,\n            source_name=\"output\",\n            sink_name=\"prompt\",\n        ),\n        Link(\n            source_id=llm_call_node.id,\n            sink_id=text_matcher_node.id,\n            source_name=\"response\",\n            sink_name=\"data\",\n        ),\n        Link(\n            source_id=llm_call_node.id,\n            sink_id=text_matcher_node.id,\n            source_name=\"response_#_is_relevant\",\n            sink_name=\"text\",\n        ),\n        Link(\n            source_id=text_matcher_node.id,\n            sink_id=reddit_comment_node.id,\n            source_name=\"positive_#_post_id\",\n            sink_name=\"data_#_post_id\",\n        ),\n        Link(\n            source_id=text_matcher_node.id,\n            sink_id=reddit_comment_node.id,\n            source_name=\"positive_#_marketing_text\",\n            sink_name=\"data_#_comment\",\n        ),\n    ]\n\n    # Create graph\n    test_graph = Graph(\n        name=\"RedditMarketingAgent\",\n        description=\"Reddit marketing agent\",\n        nodes=nodes,\n        links=links,\n    )\n    return test_graph", "blocks": [{"id": 1, "label": "def create_test_graph() -> Graph:\n    reddit_get_post_input = {\n        \"post_limit\": 3,\n    }", "successors": [{"id": 3, "label": "    text_formatter_input = {\n        \"format\": \"\"\"\nBased on the following post, write your marketing comment:\n* Post ID: {id}\n* Post Subreddit: {subreddit}\n* Post Title: {title}\n* Post Body: {body}\"\"\".strip(),\n    }\n    llm_call_input = {\n        \"sys_prompt\": \"\"\"\nYou are an expert at marketing.\nYou have been tasked with picking Reddit posts that are relevant to your product.\nThe product you are marketing is: Auto-GPT an autonomous AI agent utilizing GPT model.\nYou reply the post that you find it relevant to be replied with marketing text.\nMake sure to only comment on a relevant post.\n\"\"\",\n        \"expected_format\": {\n            \"post_id\": \"str, the reddit post id\",\n            \"is_relevant\": \"bool, whether the post is relevant for marketing\",\n            \"marketing_text\": \"str, marketing text, this is empty on irrelevant posts\",\n        },\n    }", "successors": [{"id": 5, "label": "    text_matcher_input = {\"match\": \"true\", \"case_sensitive\": False}\n    reddit_comment_input = {}", "successors": [{"id": 7, "label": "    reddit_get_post_node = Node(\n        block_id=GetRedditPostsBlock().id,\n        input_default=reddit_get_post_input,\n    )\n    text_formatter_node = Node(\n        block_id=FillTextTemplateBlock().id,\n        input_default=text_formatter_input,\n    )", "successors": [{"id": 9, "label": "    llm_call_node = Node(\n        block_id=AIStructuredResponseGeneratorBlock().id, input_default=llm_call_input\n    )\n    text_matcher_node = Node(\n        block_id=MatchTextPatternBlock().id,\n        input_default=text_matcher_input,\n    )", "successors": [{"id": 11, "label": "    reddit_comment_node = Node(\n        block_id=PostRedditCommentBlock().id,\n        input_default=reddit_comment_input,\n    )\n    nodes = [\n        reddit_get_post_node,\n        text_formatter_node,\n        llm_call_node,\n        text_matcher_node,\n        reddit_comment_node,\n    ]", "successors": [{"id": 13, "label": "    links = [\n        Link(\n            source_id=reddit_get_post_node.id,\n            sink_id=text_formatter_node.id,\n            source_name=\"post\",\n            sink_name=\"values\",\n        ),\n        Link(\n            source_id=text_formatter_node.id,\n            sink_id=llm_call_node.id,\n            source_name=\"output\",\n            sink_name=\"prompt\",\n        ),\n        Link(\n            source_id=llm_call_node.id,\n            sink_id=text_matcher_node.id,\n            source_name=\"response\",\n            sink_name=\"data\",\n        ),\n        Link(\n            source_id=llm_call_node.id,\n            sink_id=text_matcher_node.id,\n            source_name=\"response_#_is_relevant\",\n            sink_name=\"text\",\n        ),\n        Link(\n            source_id=text_matcher_node.id,\n            sink_id=reddit_comment_node.id,\n            source_name=\"positive_#_post_id\",\n            sink_name=\"data_#_post_id\",\n        ),\n        Link(\n            source_id=text_matcher_node.id,\n            sink_id=reddit_comment_node.id,\n            source_name=\"positive_#_marketing_text\",\n            sink_name=\"data_#_comment\",\n        ),\n    ]\n    test_graph = Graph(\n        name=\"RedditMarketingAgent\",\n        description=\"Reddit marketing agent\",\n        nodes=nodes,\n        links=links,\n    )", "successors": [{"id": 15, "label": "    return test_graph", "successors": []}]}]}]}]}]}]}]}]}, {"name": "create_test_user", "type": "function", "start_line": 144, "end_line": 151, "functions": [], "classes": [], "simplified_code": "async def create_test_user() -> User:\n    test_user_data = {\n        \"sub\": \"ef3b97d7-1161-4eb4-92b2-10c24fb154c1\",\n        \"email\": \"testuser@example.com\",\n        \"name\": \"Test User\",\n    }\n    user = await get_or_create_user(test_user_data)\n    return user", "blocks": [{"id": 1, "label": "async def create_test_user() -> User:\n    test_user_data = {\n        \"sub\": \"ef3b97d7-1161-4eb4-92b2-10c24fb154c1\",\n        \"email\": \"testuser@example.com\",\n        \"name\": \"Test User\",\n    }\n    user = await get_or_create_user(test_user_data)\nreturn user", "successors": []}]}, {"name": "reddit_marketing_agent", "type": "function", "start_line": 154, "end_line": 164, "functions": [], "classes": [], "simplified_code": "async def reddit_marketing_agent():\n    async with SpinTestServer() as server:\n        test_user = await create_test_user()\n        test_graph = await create_graph(create_test_graph(), user_id=test_user.id)\n        input_data = {\"subreddit\": \"AutoGPT\"}\n        response = await server.agent_server.test_execute_graph(\n            test_graph.id, input_data, test_user.id\n        )\n        print(response)\n        result = await wait_execution(test_user.id, test_graph.id, response[\"id\"], 120)\n        print(result)", "blocks": [{"id": 1, "label": "async def reddit_marketing_agent():\nasync with SpinTestServer() as server:", "successors": [{"id": 3, "label": "test_user = await create_test_user()\ntest_graph = await create_graph(create_test_graph(), user_id=test_user.id)\ninput_data = {\"subreddit\": \"AutoGPT\"}\nresponse = await server.agent_server.test_execute_graph(\n    test_graph.id, input_data, test_user.id\n)\nprint(response)\nresult = await wait_execution(test_user.id, test_graph.id, response[\"id\"], 120)\nprint(result)", "successors": []}]}]}], "classes": [], "simplified_code": "from prisma.models import User\n\nfrom backend.blocks.llm import AIStructuredResponseGeneratorBlock\nfrom backend.blocks.reddit import GetRedditPostsBlock, PostRedditCommentBlock\nfrom backend.blocks.text import FillTextTemplateBlock, MatchTextPatternBlock\nfrom backend.data.graph import Graph, Link, Node, create_graph\nfrom backend.data.user import get_or_create_user\nfrom backend.util.test import SpinTestServer, wait_execution\n\n\n    return test_graph\n\n\n    return user\n\n\n        print(result)\n\n\nif __name__ == \"__main__\":\n    import asyncio\n\n    asyncio.run(reddit_marketing_agent())", "blocks": [{"id": 1, "label": "from prisma.models import User\n\nfrom backend.blocks.llm import AIStructuredResponseGeneratorBlock\nfrom backend.blocks.reddit import GetRedditPostsBlock, PostRedditCommentBlock\nfrom backend.blocks.text import FillTextTemplateBlock, MatchTextPatternBlock\nfrom backend.data.graph import Graph, Link, Node, create_graph\nfrom backend.data.user import get_or_create_user\nfrom backend.util.test import SpinTestServer, wait_execution", "successors": [{"id": 2, "label": "def reddit_marketing_agent():\n    test_graph = create_graph()", "successors": [{"id": 4, "label": "    user = get_or_create_user(test_graph)\n    result = await SpinTestServer()\n    await wait_execution()", "successors": [{"id": 6, "label": "    return test_graph", "successors": []}, {"id": 7, "label": "    return user", "successors": []}, {"id": 8, "label": "    print(result)", "successors": []}]}]}, {"id": 9, "label": "if __name__ == \"__main__\":\n    import asyncio", "successors": [{"id": 11, "label": "    asyncio.run(reddit_marketing_agent())", "successors": []}]}]}]}
{"file_name": "88.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 41, "functions": [{"name": "binary_count_setbits", "type": "function", "start_line": 1, "end_line": 35, "functions": [], "classes": [], "simplified_code": "def binary_count_setbits(a: int) -> int:\n    \"\"\"\n    Take in 1 integer, return a number that is\n    the number of 1's in binary representation of that number.\n\n    >>> binary_count_setbits(25)\n    3\n    >>> binary_count_setbits(36)\n    2\n    >>> binary_count_setbits(16)\n    1\n    >>> binary_count_setbits(58)\n    4\n    >>> binary_count_setbits(4294967295)\n    32\n    >>> binary_count_setbits(0)\n    0\n    >>> binary_count_setbits(-10)\n    Traceback (most recent call last):\n        ...\n    ValueError: Input value must be a positive integer\n    >>> binary_count_setbits(0.8)\n    Traceback (most recent call last):\n        ...\n    TypeError: Input value must be a 'int' type\n    >>> binary_count_setbits(\"0\")\n    Traceback (most recent call last):\n        ...\n    TypeError: '<' not supported between instances of 'str' and 'int'\n    \"\"\"\n    if a < 0:\n        raise ValueError(\"Input value must be a positive integer\")\n    elif isinstance(a, float):\n        raise TypeError(\"Input value must be a 'int' type\")\n    return bin(a).count(\"1\")", "blocks": [{"id": 1, "label": "if a < 0:", "successors": [{"id": 2, "label": "    raise ValueError(\"Input value must be a positive integer\")", "successors": []}, {"id": 3, "label": "elif isinstance(a, float):", "successors": [{"id": 4, "label": "    raise TypeError(\"Input value must be a 'int' type\")", "successors": []}, {"id": 5, "label": "return bin(a).count(\"1\")", "successors": []}]}]}]}], "classes": [], "simplified_code": "    return bin(a).count(\"1\")\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()", "blocks": [{"id": 1, "label": "return bin(a).count(\"1\")", "successors": []}]}
{"file_name": "89.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 43, "functions": [{"name": "twos_complement", "type": "function", "start_line": 4, "end_line": 37, "functions": [], "classes": [], "simplified_code": "def twos_complement(number: int) -> str:\n    \"\"\"\n    Take in a negative integer 'number'.\n    Return the two's complement representation of 'number'.\n\n    >>> twos_complement(0)\n    '0b0'\n    >>> twos_complement(-1)\n    '0b11'\n    >>> twos_complement(-5)\n    '0b1011'\n    >>> twos_complement(-17)\n    '0b101111'\n    >>> twos_complement(-207)\n    '0b100110001'\n    >>> twos_complement(1)\n    Traceback (most recent call last):\n        ...\n    ValueError: input must be a negative integer\n    \"\"\"\n    if number > 0:\n        raise ValueError(\"input must be a negative integer\")\n    binary_number_length = len(bin(number)[3:])\n    twos_complement_number = bin(abs(number) - (1 << binary_number_length))[3:]\n    twos_complement_number = (\n        (\n            \"1\"\n            + \"0\" * (binary_number_length - len(twos_complement_number))\n            + twos_complement_number\n        )\n        if number < 0\n        else \"0\"\n    )\n    return \"0b\" + twos_complement_number", "blocks": [{"id": 1, "label": "def twos_complement(number: int) -> str:\nif number > 0:", "successors": [{"id": 3, "label": "raise ValueError(\"input must be a negative integer\")", "successors": []}, {"id": 4, "label": "binary_number_length = len(bin(number)[3:])\ntwos_complement_number = bin(abs(number) - (1 << binary_number_length))[3:]", "successors": [{"id": 6, "label": "twos_complement_number = (\n    (\n        \"1\"\n        + \"0\" * (binary_number_length - len(twos_complement_number))\n        + twos_complement_number\n    )\n    if number < 0\n    else \"0\"\n)\nreturn \"0b\" + twos_complement_number", "successors": []}]}]}]}], "classes": [], "simplified_code": "# Information on 2's complement: https://en.wikipedia.org/wiki/Two%27s_complement\n\n\n    return \"0b\" + twos_complement_number\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()", "blocks": [{"id": 1, "label": "return \"0b\" + twos_complement_number", "successors": []}]}
{"file_name": "90.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 191, "functions": [], "classes": [{"name": "GetCurrentTimeBlock", "type": "class", "start_line": 9, "end_line": 43, "functions": [{"name": "__init__", "type": "function", "start_line": 23, "end_line": 38, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"a892b8d9-3e4e-4e9c-9c1e-75f8efcf1bfa\",\n            description=\"This block outputs the current time.\",\n            categories={BlockCategory.TEXT},\n            input_schema=GetCurrentTimeBlock.Input,\n            output_schema=GetCurrentTimeBlock.Output,\n            test_input=[\n                {\"trigger\": \"Hello\"},\n                {\"trigger\": \"Hello\", \"format\": \"%H:%M\"},\n            ],\n            test_output=[\n                (\"time\", lambda _: time.strftime(\"%H:%M:%S\")),\n                (\"time\", lambda _: time.strftime(\"%H:%M\")),\n            ],\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"a892b8d9-3e4e-4e9c-9c1e-75f8efcf1bfa\",\n    description=\"This block outputs the current time.\",\n    categories={BlockCategory.TEXT},\n    input_schema=GetCurrentTimeBlock.Input,\n    output_schema=GetCurrentTimeBlock.Output,\n    test_input=[\n        {\"trigger\": \"Hello\"},\n        {\"trigger\": \"Hello\", \"format\": \"%H:%M\"},\n    ],\n    test_output=[\n        (\"time\", lambda _: time.strftime(\"%H:%M:%S\")),\n        (\"time\", lambda _: time.strftime(\"%H:%M\")),\n    ],\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 40, "end_line": 42, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        current_time = time.strftime(input_data.format)\n        yield \"time\", current_time", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\n    current_time = time.strftime(input_data.format)", "successors": [{"id": 3, "label": "    yield \"time\", current_time", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 10, "end_line": 16, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        trigger: str = SchemaField(\n            description=\"Trigger any data to output the current time\"\n        )\n        format: str = SchemaField(\n            description=\"Format of the time to output\", default=\"%H:%M:%S\"\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    trigger: str = SchemaField(description=\"Trigger any data to output the current time\")", "successors": [{"id": 3, "label": "    format: str = SchemaField(description=\"Format of the time to output\", default=\"%H:%M:%S\")", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 18, "end_line": 21, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        time: str = SchemaField(\n            description=\"Current time in the specified format (default: %H:%M:%S)\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    time: str = SchemaField(description=\"Current time in the specified format (default: %H:%M:%S)\")", "successors": []}]}], "simplified_code": "class GetCurrentTimeBlock(Block):\n        )\n\n        )\n\n        )\n\n        yield \"time\", current_time\n", "blocks": [{"id": 1, "label": "class GetCurrentTimeBlock(Block):\n)", "successors": [{"id": 3, "label": ")\n)", "successors": [{"id": 5, "label": "yield \"time\", current_time", "successors": []}]}]}]}, {"name": "GetCurrentDateBlock", "type": "class", "start_line": 45, "end_line": 98, "functions": [{"name": "__init__", "type": "function", "start_line": 64, "end_line": 88, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"b29c1b50-5d0e-4d9f-8f9d-1b0e6fcbf0b1\",\n            description=\"This block outputs the current date with an optional offset.\",\n            categories={BlockCategory.TEXT},\n            input_schema=GetCurrentDateBlock.Input,\n            output_schema=GetCurrentDateBlock.Output,\n            test_input=[\n                {\"trigger\": \"Hello\", \"offset\": \"7\"},\n                {\"trigger\": \"Hello\", \"offset\": \"7\", \"format\": \"%m/%d/%Y\"},\n            ],\n            test_output=[\n                (\n                    \"date\",\n                    lambda t: abs(datetime.now() - datetime.strptime(t, \"%Y-%m-%d\"))\n                    < timedelta(days=8),  # 7 days difference + 1 day error margin.\n                ),\n                (\n                    \"date\",\n                    lambda t: abs(datetime.now() - datetime.strptime(t, \"%m/%d/%Y\"))\n                    < timedelta(days=8),\n                    # 7 days difference + 1 day error margin.\n                ),\n            ],\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"b29c1b50-5d0e-4d9f-8f9d-1b0e6fcbf0b1\",\n    description=\"This block outputs the current date with an optional offset.\",\n    categories={BlockCategory.TEXT},\n    input_schema=GetCurrentDateBlock.Input,\n    output_schema=GetCurrentDateBlock.Output,\n    test_input=[\n        {\"trigger\": \"Hello\", \"offset\": \"7\"},\n        {\"trigger\": \"Hello\", \"offset\": \"7\", \"format\": \"%m/%d/%Y\"},\n    ],\n    test_output=[\n        (\n            \"date\",\n            lambda t: abs(datetime.now() - datetime.strptime(t, \"%Y-%m-%d\")) < timedelta(days=8),  # 7 days difference + 1 day error margin.\n        ),\n        (\n            \"date\",\n            lambda t: abs(datetime.now() - datetime.strptime(t, \"%m/%d/%Y\")) < timedelta(days=8),\n            # 7 days difference + 1 day error margin.\n        ),\n    ],\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 90, "end_line": 96, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        try:\n            offset = int(input_data.offset)\n        except ValueError:\n            offset = 0\n        current_date = datetime.now() - timedelta(days=offset)\n        yield \"date\", current_date.strftime(input_data.format)", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\ntry:", "successors": [{"id": 3, "label": "offset = int(input_data.offset)\ncurrent_date = datetime.now() - timedelta(days=offset)\nyield \"date\", current_date.strftime(input_data.format)", "successors": []}, {"id": 4, "label": "except ValueError:\noffset = 0\ncurrent_date = datetime.now() - timedelta(days=offset)\nyield \"date\", current_date.strftime(input_data.format)", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 46, "end_line": 57, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        trigger: str = SchemaField(\n            description=\"Trigger any data to output the current date\"\n        )\n        offset: Union[int, str] = SchemaField(\n            title=\"Days Offset\",\n            description=\"Offset in days from the current date\",\n            default=0,\n        )\n        format: str = SchemaField(\n            description=\"Format of the date to output\", default=\"%Y-%m-%d\"\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    trigger: str = SchemaField(description=\"Trigger any data to output the current date\")", "successors": []}, {"id": 3, "label": "    offset: Union[int, str] = SchemaField(title=\"Days Offset\", description=\"Offset in days from the current date\", default=0)", "successors": []}, {"id": 4, "label": "    format: str = SchemaField(description=\"Format of the date to output\", default=\"%Y-%m-%d\")", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 59, "end_line": 62, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        date: str = SchemaField(\n            description=\"Current date in the specified format (default: YYYY-MM-DD)\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    date: str = SchemaField(\n        description=\"Current date in the specified format (default: YYYY-MM-DD)\"\n    )", "successors": []}]}], "simplified_code": "class GetCurrentDateBlock(Block):\n        )\n\n        )\n\n        )\n\n        yield \"date\", current_date.strftime(input_data.format)\n\n", "blocks": [{"id": 1, "label": "class GetCurrentDateBlock(Block):\nyield \"date\", current_date.strftime(input_data.format)", "successors": []}]}, {"name": "GetCurrentDateAndTimeBlock", "type": "class", "start_line": 99, "end_line": 139, "functions": [{"name": "__init__", "type": "function", "start_line": 114, "end_line": 133, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"716a67b3-6760-42e7-86dc-18645c6e00fc\",\n            description=\"This block outputs the current date and time.\",\n            categories={BlockCategory.TEXT},\n            input_schema=GetCurrentDateAndTimeBlock.Input,\n            output_schema=GetCurrentDateAndTimeBlock.Output,\n            test_input=[\n                {\"trigger\": \"Hello\"},\n            ],\n            test_output=[\n                (\n                    \"date_time\",\n                    lambda t: abs(\n                        datetime.now() - datetime.strptime(t, \"%Y-%m-%d %H:%M:%S\")\n                    )\n                    < timedelta(seconds=10),  # 10 seconds error margin.\n                ),\n            ],\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"716a67b3-6760-42e7-86dc-18645c6e00fc\",\n    description=\"This block outputs the current date and time.\",\n    categories={BlockCategory.TEXT},\n    input_schema=GetCurrentDateAndTimeBlock.Input,\n    output_schema=GetCurrentDateAndTimeBlock.Output,\n    test_input=[\n        {\"trigger\": \"Hello\"},\n    ],\n    test_output=[\n        (\n            \"date_time\",\n            lambda t: abs(\n                datetime.now() - datetime.strptime(t, \"%Y-%m-%d %H:%M:%S\")\n            )\n            < timedelta(seconds=10),  # 10 seconds error margin.\n        ),\n    ],\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 135, "end_line": 137, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        current_date_time = time.strftime(input_data.format)\n        yield \"date_time\", current_date_time", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\ncurrent_date_time = time.strftime(input_data.format)", "successors": [{"id": 3, "label": "yield \"date_time\", current_date_time", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 100, "end_line": 107, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        trigger: str = SchemaField(\n            description=\"Trigger any data to output the current date and time\"\n        )\n        format: str = SchemaField(\n            description=\"Format of the date and time to output\",\n            default=\"%Y-%m-%d %H:%M:%S\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    trigger: str = SchemaField(\n        description=\"Trigger any data to output the current date and time\"\n    )\n    format: str = SchemaField(\n        description=\"Format of the date and time to output\",\n        default=\"%Y-%m-%d %H:%M:%S\",\n    )", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 109, "end_line": 112, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        date_time: str = SchemaField(\n            description=\"Current date and time in the specified format (default: YYYY-MM-DD HH:MM:SS)\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    date_time: str = SchemaField(\n        description=\"Current date and time in the specified format (default: YYYY-MM-DD HH:MM:SS)\"\n    )", "successors": []}]}], "simplified_code": "class GetCurrentDateAndTimeBlock(Block):\n        )\n\n        )\n\n        )\n\n        yield \"date_time\", current_date_time\n\n", "blocks": [{"id": 1, "label": "class GetCurrentDateAndTimeBlock(Block):\npass", "successors": [{"id": 3, "label": "def execute(self):\ncurrent_date_time = datetime.now()", "successors": [{"id": 5, "label": "yield \"date_time\", current_date_time", "successors": []}]}]}]}, {"name": "CountdownTimerBlock", "type": "class", "start_line": 140, "end_line": 191, "functions": [{"name": "__init__", "type": "function", "start_line": 165, "end_line": 180, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"d67a9c52-5e4e-11e2-bcfd-0800200c9a71\",\n            description=\"This block triggers after a specified duration.\",\n            categories={BlockCategory.TEXT},\n            input_schema=CountdownTimerBlock.Input,\n            output_schema=CountdownTimerBlock.Output,\n            test_input=[\n                {\"seconds\": 1},\n                {\"input_message\": \"Custom message\"},\n            ],\n            test_output=[\n                (\"output_message\", \"timer finished\"),\n                (\"output_message\", \"Custom message\"),\n            ],\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"d67a9c52-5e4e-11e2-bcfd-0800200c9a71\",\n    description=\"This block triggers after a specified duration.\",\n    categories={BlockCategory.TEXT},\n    input_schema=CountdownTimerBlock.Input,\n    output_schema=CountdownTimerBlock.Output,\n    test_input=[\n        {\"seconds\": 1},\n        {\"input_message\": \"Custom message\"},\n    ],\n    test_output=[\n        (\"output_message\", \"timer finished\"),\n        (\"output_message\", \"Custom message\"),\n    ],\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 182, "end_line": 191, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        seconds = int(input_data.seconds)\n        minutes = int(input_data.minutes)\n        hours = int(input_data.hours)\n        days = int(input_data.days)\n\n        total_seconds = seconds + minutes * 60 + hours * 3600 + days * 86400\n\n        time.sleep(total_seconds)\n        yield \"output_message\", input_data.input_message", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\nseconds = int(input_data.seconds)\nminutes = int(input_data.minutes)\nhours = int(input_data.hours)\ndays = int(input_data.days)\n\ntotal_seconds = seconds + minutes * 60 + hours * 3600 + days * 86400", "successors": [{"id": 3, "label": "time.sleep(total_seconds)\nyield \"output_message\", input_data.input_message", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 141, "end_line": 158, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        input_message: Any = SchemaField(\n            advanced=False,\n            description=\"Message to output after the timer finishes\",\n            default=\"timer finished\",\n        )\n        seconds: Union[int, str] = SchemaField(\n            advanced=False, description=\"Duration in seconds\", default=0\n        )\n        minutes: Union[int, str] = SchemaField(\n            advanced=False, description=\"Duration in minutes\", default=0\n        )\n        hours: Union[int, str] = SchemaField(\n            advanced=False, description=\"Duration in hours\", default=0\n        )\n        days: Union[int, str] = SchemaField(\n            advanced=False, description=\"Duration in days\", default=0\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    input_message: Any = SchemaField(advanced=False, description=\"Message to output after the timer finishes\", default=\"timer finished\")", "successors": [{"id": 3, "label": "seconds: Union[int, str] = SchemaField(advanced=False, description=\"Duration in seconds\", default=0)\nminutes: Union[int, str] = SchemaField(advanced=False, description=\"Duration in minutes\", default=0)", "successors": [{"id": 5, "label": "hours: Union[int, str] = SchemaField(advanced=False, description=\"Duration in hours\", default=0)\ndays: Union[int, str] = SchemaField(advanced=False, description=\"Duration in days\", default=0)", "successors": []}]}]}]}, {"name": "Output", "type": "class", "start_line": 160, "end_line": 163, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        output_message: Any = SchemaField(\n            description=\"Message after the timer finishes\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    output_message: Any = SchemaField(description=\"Message after the timer finishes\")", "successors": []}]}], "simplified_code": "class CountdownTimerBlock(Block):\n        )\n\n        )\n\n        )\n\n        yield \"output_message\", input_data.input_message", "blocks": [{"id": 1, "label": "class CountdownTimerBlock(Block):\ndef __init__(self, input_data):", "successors": [{"id": 3, "label": "    self.input_data = input_data\ndef execute(self):", "successors": [{"id": 5, "label": "    while self.input_data > 0:", "successors": [{"id": 6, "label": "        self.input_data -= 1\n        print(self.input_data)", "successors": [{"id": 8, "label": "yield \"output_message\", self.input_data\n# Execution ends", "successors": []}]}, {"id": 9, "label": "# Execution ends", "successors": []}]}]}]}]}], "simplified_code": "import time\nfrom datetime import datetime, timedelta\nfrom typing import Any, Union\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\n\n\n\n\n\n        yield \"output_message\", input_data.input_message", "blocks": [{"id": 1, "label": "import time\nfrom datetime import datetime, timedelta\nfrom typing import Any, Union\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\n\n\n\n\n        yield \"output_message\", input_data.input_message", "successors": []}]}
{"file_name": "91.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 33, "functions": [{"name": "run", "type": "function", "start_line": 11, "end_line": 13, "functions": [], "classes": [], "simplified_code": "def run(*command: str) -> None:\n    print(f\">>>>> Running poetry run {' '.join(command)}\")\n    subprocess.run([\"poetry\", \"run\"] + list(command), cwd=directory, check=True)", "blocks": [{"id": 1, "label": "def run(*command: str) -> None:\n    print(f\">>>>> Running poetry run {' '.join(command)}\")", "successors": [{"id": 3, "label": "    subprocess.run([\"poetry\", \"run\"] + list(command), cwd=directory, check=True)", "successors": []}]}]}, {"name": "lint", "type": "function", "start_line": 16, "end_line": 25, "functions": [], "classes": [], "simplified_code": "def lint():\n    try:\n        run(\"ruff\", \"check\", *TARGET_DIRS, \"--exit-zero\")\n        run(\"ruff\", \"format\", \"--diff\", \"--check\", LIBS_DIR)\n        run(\"isort\", \"--diff\", \"--check\", \"--profile\", \"black\", BACKEND_DIR)\n        run(\"black\", \"--diff\", \"--check\", BACKEND_DIR)\n        run(\"pyright\", *TARGET_DIRS)\n    except subprocess.CalledProcessError as e:\n        print(\"Lint failed, try running `poetry run format` to fix the issues: \", e)\n        raise e", "blocks": [{"id": 1, "label": "def lint():\ntry:", "successors": [{"id": 3, "label": "run(\"ruff\", \"check\", *TARGET_DIRS, \"--exit-zero\")\nrun(\"ruff\", \"format\", \"--diff\", \"--check\", LIBS_DIR)\nrun(\"isort\", \"--diff\", \"--check\", \"--profile\", \"black\", BACKEND_DIR)\nrun(\"black\", \"--diff\", \"--check\", BACKEND_DIR)\nrun(\"pyright\", *TARGET_DIRS)", "successors": []}, {"id": 4, "label": "except subprocess.CalledProcessError as e:\nprint(\"Lint failed, try running `poetry run format` to fix the issues: \", e)\nraise e", "successors": []}]}]}, {"name": "format", "type": "function", "start_line": 28, "end_line": 33, "functions": [], "classes": [], "simplified_code": "def format():\n    run(\"ruff\", \"check\", \"--fix\", *TARGET_DIRS)\n    run(\"ruff\", \"format\", LIBS_DIR)\n    run(\"isort\", \"--profile\", \"black\", BACKEND_DIR)\n    run(\"black\", BACKEND_DIR)\n    run(\"pyright\", *TARGET_DIRS)", "blocks": [{"id": 1, "label": "def format():\n    run(\"ruff\", \"check\", \"--fix\", *TARGET_DIRS)\n    run(\"ruff\", \"format\", LIBS_DIR)\n    run(\"isort\", \"--profile\", \"black\", BACKEND_DIR)\n    run(\"black\", BACKEND_DIR)\n    run(\"pyright\", *TARGET_DIRS)", "successors": []}]}], "classes": [], "simplified_code": "import os\nimport subprocess\n\ndirectory = os.path.dirname(os.path.realpath(__file__))\n\nBACKEND_DIR = \".\"\nLIBS_DIR = \"../autogpt_libs\"\nTARGET_DIRS = [BACKEND_DIR, LIBS_DIR]\n\n\n    subprocess.run([\"poetry\", \"run\"] + list(command), cwd=directory, check=True)\n\n\n        raise e\n\n\n    run(\"pyright\", *TARGET_DIRS)", "blocks": [{"id": 1, "label": "import os\nimport subprocess\ndirectory = os.path.dirname(os.path.realpath(__file__))", "successors": [{"id": 3, "label": "BACKEND_DIR = \".\"\nLIBS_DIR = \"../autogpt_libs\"\nTARGET_DIRS = [BACKEND_DIR, LIBS_DIR]\nsubprocess.run([\"poetry\", \"run\"] + list(command), cwd=directory, check=True)", "successors": []}, {"id": 5, "label": "raise e", "successors": []}, {"id": 6, "label": "run(\"pyright\", *TARGET_DIRS)", "successors": []}]}]}
{"file_name": "92.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 52, "functions": [{"name": "binary_xor", "type": "function", "start_line": 4, "end_line": 46, "functions": [], "classes": [], "simplified_code": "def binary_xor(a: int, b: int) -> str:\n    \"\"\"\n    Take in 2 integers, convert them to binary,\n    return a binary number that is the\n    result of a binary xor operation on the integers provided.\n\n    >>> binary_xor(25, 32)\n    '0b111001'\n    >>> binary_xor(37, 50)\n    '0b010111'\n    >>> binary_xor(21, 30)\n    '0b01011'\n    >>> binary_xor(58, 73)\n    '0b1110011'\n    >>> binary_xor(0, 255)\n    '0b11111111'\n    >>> binary_xor(256, 256)\n    '0b000000000'\n    >>> binary_xor(0, -1)\n    Traceback (most recent call last):\n        ...\n    ValueError: the value of both inputs must be positive\n    >>> binary_xor(0, 1.1)\n    Traceback (most recent call last):\n        ...\n    TypeError: 'float' object cannot be interpreted as an integer\n    >>> binary_xor(\"0\", \"1\")\n    Traceback (most recent call last):\n        ...\n    TypeError: '<' not supported between instances of 'str' and 'int'\n    \"\"\"\n    if a < 0 or b < 0:\n        raise ValueError(\"the value of both inputs must be positive\")\n\n    a_binary = str(bin(a))[2:]  # remove the leading \"0b\"\n    b_binary = str(bin(b))[2:]  # remove the leading \"0b\"\n\n    max_len = max(len(a_binary), len(b_binary))\n\n    return \"0b\" + \"\".join(\n        str(int(char_a != char_b))\n        for char_a, char_b in zip(a_binary.zfill(max_len), b_binary.zfill(max_len))\n    )", "blocks": [{"id": 1, "label": "def binary_xor(a: int, b: int) -> str:\n    \"\"\"\n    Take in 2 integers, convert them to binary,\n    return a binary number that is the\n    result of a binary xor operation on the integers provided.\n\n    >>> binary_xor(25, 32)\n    '0b111001'\n    >>> binary_xor(37, 50)\n    '0b010111'\n    >>> binary_xor(21, 30)\n    '0b01011'\n    >>> binary_xor(58, 73)\n    '0b1110011'\n    >>> binary_xor(0, 255)\n    '0b11111111'\n    >>> binary_xor(256, 256)\n    '0b000000000'\n    >>> binary_xor(0, -1)\n    Traceback (most recent call last):\n        ...\n    ValueError: the value of both inputs must be positive\n    >>> binary_xor(0, 1.1)\n    Traceback (most recent call last):\n        ...\n    TypeError: 'float' object cannot be interpreted as an integer\n    >>> binary_xor(\"0\", \"1\")\n    Traceback (most recent call last):\n        ...\n    TypeError: '<' not supported between instances of 'str' and 'int'\n    \"\"\"\n    if a < 0 or b < 0:", "successors": [{"id": 2, "label": "    raise ValueError(\"the value of both inputs must be positive\")", "successors": []}, {"id": 3, "label": "    a_binary = str(bin(a))[2:]  # remove the leading \"0b\"\n    b_binary = str(bin(b))[2:]  # remove the leading \"0b\"\n\n    max_len = max(len(a_binary), len(b_binary))\n    return \"0b\" + \"\".join(\n        str(int(char_a != char_b))\n        for char_a, char_b in zip(a_binary.zfill(max_len), b_binary.zfill(max_len))\n    )", "successors": []}]}]}], "classes": [], "simplified_code": "# https://www.tutorialspoint.com/python3/bitwise_operators_example.htm\n\n\n    )\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()", "blocks": [{"id": 1, "label": "if __name__ == \"__main__\":\n    import doctest", "successors": [{"id": 3, "label": "    doctest.testmod()", "successors": []}]}]}
{"file_name": "93.json", "name": "crossword_script", "type": "CFG", "start_line": 1, "end_line": 131, "functions": [{"name": "is_valid", "type": "function", "start_line": 4, "end_line": 33, "functions": [], "classes": [], "simplified_code": "def is_valid(\n    puzzle: list[list[str]], word: str, row: int, col: int, vertical: bool\n) -> bool:\n    \"\"\"\n    Check if a word can be placed at the given position.\n\n    >>> puzzle = [\n    ...     ['', '', '', ''],\n    ...     ['', '', '', ''],\n    ...     ['', '', '', ''],\n    ...     ['', '', '', '']\n    ... ]\n    >>> is_valid(puzzle, 'word', 0, 0, True)\n    True\n    >>> puzzle = [\n    ...     ['', '', '', ''],\n    ...     ['', '', '', ''],\n    ...     ['', '', '', ''],\n    ...     ['', '', '', '']\n    ... ]\n    >>> is_valid(puzzle, 'word', 0, 0, False)\n    True\n    \"\"\"\n    for i in range(len(word)):\n        if vertical:\n            if row + i >= len(puzzle) or puzzle[row + i][col] != \"\":\n                return False\n        elif col + i >= len(puzzle[0]) or puzzle[row][col + i] != \"\":\n            return False\n    return True", "blocks": [{"id": 1, "label": "for i in range(len(word)):", "successors": [{"id": 2, "label": "if vertical:\nif row + i >= len(puzzle) or puzzle[row + i][col] != '':", "successors": [{"id": 4, "label": "return False", "successors": []}]}, {"id": 5, "label": "elif col + i >= len(puzzle[0]) or puzzle[row][col + i] != '':\nreturn False", "successors": []}]}]}, {"name": "place_word", "type": "function", "start_line": 36, "end_line": 56, "functions": [], "classes": [], "simplified_code": "def place_word(\n    puzzle: list[list[str]], word: str, row: int, col: int, vertical: bool\n) -> None:\n    \"\"\"\n    Place a word at the given position.\n\n    >>> puzzle = [\n    ...     ['', '', '', ''],\n    ...     ['', '', '', ''],\n    ...     ['', '', '', ''],\n    ...     ['', '', '', '']\n    ... ]\n    >>> place_word(puzzle, 'word', 0, 0, True)\n    >>> puzzle\n    [['w', '', '', ''], ['o', '', '', ''], ['r', '', '', ''], ['d', '', '', '']]\n    \"\"\"\n    for i, char in enumerate(word):\n        if vertical:\n            puzzle[row + i][col] = char\n        else:\n            puzzle[row][col + i] = char", "blocks": [{"id": 1, "label": "def place_word(\n    puzzle: list[list[str]], word: str, row: int, col: int, vertical: bool\n) -> None:", "successors": [{"id": 2, "label": "for i, char in enumerate(word):", "successors": [{"id": 3, "label": "if vertical:", "successors": [{"id": 4, "label": "puzzle[row + i][col] = char\nelse:", "successors": [{"id": 5, "label": "puzzle[row][col + i] = char", "successors": [{"id": 2, "label": "for i, char in enumerate(word):", "successors": []}]}]}, {"id": 6, "label": "else:\npuzzle[row][col + i] = char", "successors": [{"id": 2, "label": "for i, char in enumerate(word):", "successors": []}]}]}, {"id": 6, "label": "else:\npuzzle[row][col + i] = char", "successors": [{"id": 2, "label": "for i, char in enumerate(word):", "successors": []}]}]}]}]}, {"name": "remove_word", "type": "function", "start_line": 59, "end_line": 79, "functions": [], "classes": [], "simplified_code": "def remove_word(\n    puzzle: list[list[str]], word: str, row: int, col: int, vertical: bool\n) -> None:\n    \"\"\"\n    Remove a word from the given position.\n\n    >>> puzzle = [\n    ...     ['w', '', '', ''],\n    ...     ['o', '', '', ''],\n    ...     ['r', '', '', ''],\n    ...     ['d', '', '', '']\n    ... ]\n    >>> remove_word(puzzle, 'word', 0, 0, True)\n    >>> puzzle\n    [['', '', '', ''], ['', '', '', ''], ['', '', '', ''], ['', '', '', '']]\n    \"\"\"\n    for i in range(len(word)):\n        if vertical:\n            puzzle[row + i][col] = \"\"\n        else:\n            puzzle[row][col + i] = \"\"", "blocks": [{"id": 1, "label": "def remove_word(    puzzle: list[list[str]], word: str, row: int, col: int, vertical: bool) -> None:", "successors": [{"id": 2, "label": "for i in range(len(word)):", "successors": [{"id": 3, "label": "if vertical:\npuzzle[row + i][col] = \"\"", "successors": [{"id": 6, "label": "\nelse:", "successors": [{"id": 6, "label": "puzzle[row][col + i] = \"\"\n", "successors": []}]}]}]}]}]}, {"name": "solve_crossword", "type": "function", "start_line": 82, "end_line": 119, "functions": [], "classes": [], "simplified_code": "def solve_crossword(puzzle: list[list[str]], words: list[str]) -> bool:\n    \"\"\"\n    Solve the crossword puzzle using backtracking.\n\n    >>> puzzle = [\n    ...     ['', '', '', ''],\n    ...     ['', '', '', ''],\n    ...     ['', '', '', ''],\n    ...     ['', '', '', '']\n    ... ]\n\n    >>> words = ['word', 'four', 'more', 'last']\n    >>> solve_crossword(puzzle, words)\n    True\n    >>> puzzle = [\n    ...     ['', '', '', ''],\n    ...     ['', '', '', ''],\n    ...     ['', '', '', ''],\n    ...     ['', '', '', '']\n    ... ]\n    >>> words = ['word', 'four', 'more', 'paragraphs']\n    >>> solve_crossword(puzzle, words)\n    False\n    \"\"\"\n    for row in range(len(puzzle)):\n        for col in range(len(puzzle[0])):\n            if puzzle[row][col] == \"\":\n                for word in words:\n                    for vertical in [True, False]:\n                        if is_valid(puzzle, word, row, col, vertical):\n                            place_word(puzzle, word, row, col, vertical)\n                            words.remove(word)\n                            if solve_crossword(puzzle, words):\n                                return True\n                            words.append(word)\n                            remove_word(puzzle, word, row, col, vertical)\n                return False\n    return True", "blocks": [{"id": 1, "label": "for row in range(len(puzzle)):\n    for col in range(len(puzzle[0])):", "successors": [{"id": 2, "label": "if puzzle[row][col] == \"\":", "successors": [{"id": 3, "label": "for word in words:\n    for vertical in [True, False]:", "successors": [{"id": 4, "label": "if is_valid(puzzle, word, row, col, vertical):\nplace_word(puzzle, word, row, col, vertical)\nwords.remove(word)", "successors": [{"id": 6, "label": "if solve_crossword(puzzle, words):", "successors": [{"id": 7, "label": "return True", "successors": []}, {"id": 8, "label": "words.append(word)\nremove_word(puzzle, word, row, col, vertical)", "successors": []}]}, {"id": 8, "label": "words.append(word)\nremove_word(puzzle, word, row, col, vertical)", "successors": []}]}]}, {"id": 9, "label": "return False", "successors": []}]}]}]}], "classes": [], "simplified_code": "# https://www.geeksforgeeks.org/solve-crossword-puzzle/\n\n\n    return True\n\n\n            puzzle[row][col + i] = char\n\n\n            puzzle[row][col + i] = \"\"\n\n\n    return True\n\n\nif __name__ == \"__main__\":\n    PUZZLE = [[\"\"] * 3 for _ in range(3)]\n    WORDS = [\"cat\", \"dog\", \"car\"]\n\n    if solve_crossword(PUZZLE, WORDS):\n        print(\"Solution found:\")\n        for row in PUZZLE:\n            print(\" \".join(row))\n    else:\n        print(\"No solution found:\")", "blocks": [{"id": 1, "label": "if __name__ == \"__main__\":\n    PUZZLE = [[\"\"] * 3 for _ in range(3)]\n    WORDS = [\"cat\", \"dog\", \"car\"]", "successors": [{"id": 3, "label": "if solve_crossword(PUZZLE, WORDS):", "successors": [{"id": 4, "label": "    print(\"Solution found:\")\n    for row in PUZZLE:\n        print(\" \".join(row))", "successors": []}, {"id": 5, "label": "else:\n    print(\"No solution found:\")", "successors": []}]}]}]}
{"file_name": "94.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 95, "functions": [{"name": "minimax", "type": "function", "start_line": 16, "end_line": 78, "functions": [], "classes": [], "simplified_code": "def minimax(\n    depth: int, node_index: int, is_max: bool, scores: list[int], height: float\n) -> int:\n    \"\"\"\n    This function implements the minimax algorithm, which helps achieve the optimal\n    score for a player in a two-player game by checking all possible moves.\n    If the player is the maximizer, then the score is maximized.\n    If the player is the minimizer, then the score is minimized.\n\n    Parameters:\n    - depth: Current depth in the game tree.\n    - node_index: Index of the current node in the scores list.\n    - is_max: A boolean indicating whether the current move\n              is for the maximizer (True) or minimizer (False).\n    - scores: A list containing the scores of the leaves of the game tree.\n    - height: The maximum height of the game tree.\n\n    Returns:\n    - An integer representing the optimal score for the current player.\n\n    >>> import math\n    >>> scores = [90, 23, 6, 33, 21, 65, 123, 34423]\n    >>> height = math.log(len(scores), 2)\n    >>> minimax(0, 0, True, scores, height)\n    65\n    >>> minimax(-1, 0, True, scores, height)\n    Traceback (most recent call last):\n        ...\n    ValueError: Depth cannot be less than 0\n    >>> minimax(0, 0, True, [], 2)\n    Traceback (most recent call last):\n        ...\n    ValueError: Scores cannot be empty\n    >>> scores = [3, 5, 2, 9, 12, 5, 23, 23]\n    >>> height = math.log(len(scores), 2)\n    >>> minimax(0, 0, True, scores, height)\n    12\n    \"\"\"\n\n    if depth < 0:\n        raise ValueError(\"Depth cannot be less than 0\")\n    if len(scores) == 0:\n        raise ValueError(\"Scores cannot be empty\")\n\n    # Base case: If the current depth equals the height of the tree,\n    # return the score of the current node.\n    if depth == height:\n        return scores[node_index]\n\n    # If it's the maximizer's turn, choose the maximum score\n    # between the two possible moves.\n    if is_max:\n        return max(\n            minimax(depth + 1, node_index * 2, False, scores, height),\n            minimax(depth + 1, node_index * 2 + 1, False, scores, height),\n        )\n\n    # If it's the minimizer's turn, choose the minimum score\n    # between the two possible moves.\n    return min(\n        minimax(depth + 1, node_index * 2, True, scores, height),\n        minimax(depth + 1, node_index * 2 + 1, True, scores, height),\n    )", "blocks": [{"id": 1, "label": "def minimax(depth: int, node_index: int, is_max: bool, scores: list[int], height: float) -> int:\nif depth < 0:\n    raise ValueError(\"Depth cannot be less than 0\")", "successors": [{"id": 3, "label": "if len(scores) == 0:\n    raise ValueError(\"Scores cannot be empty\")\nif depth == height:\n    return scores[node_index]", "successors": [{"id": 5, "label": "if is_max:", "successors": [{"id": 6, "label": "return max(\n    minimax(depth + 1, node_index * 2, False, scores, height),\n    minimax(depth + 1, node_index * 2 + 1, False, scores, height),\n)", "successors": []}, {"id": 7, "label": "return min(\n    minimax(depth + 1, node_index * 2, True, scores, height),\n    minimax(depth + 1, node_index * 2 + 1, True, scores, height),\n)", "successors": []}]}]}]}]}, {"name": "main", "type": "function", "start_line": 81, "end_line": 88, "functions": [], "classes": [], "simplified_code": "def main() -> None:\n    # Sample scores and height calculation\n    scores = [90, 23, 6, 33, 21, 65, 123, 34423]\n    height = math.log(len(scores), 2)\n\n    # Calculate and print the optimal value using the minimax algorithm\n    print(\"Optimal value : \", end=\"\")\n    print(minimax(0, 0, True, scores, height))", "blocks": [{"id": 1, "label": "def main() -> None:\n    scores = [90, 23, 6, 33, 21, 65, 123, 34423]\n    height = math.log(len(scores), 2)", "successors": [{"id": 3, "label": "    print(\"Optimal value : \", end=\"\")\n    print(minimax(0, 0, True, scores, height))", "successors": []}]}]}], "classes": [], "simplified_code": "\"\"\"\nMinimax helps to achieve maximum score in a game by checking all possible moves\ndepth is current depth in game tree.\n\nnodeIndex is index of current node in scores[].\nif move is of maximizer return true else false\nleaves of game tree is stored in scores[]\nheight is maximum height of Game tree\n\"\"\"\n\nfrom __future__ import annotations\n\nimport math\n\n\n    )\n\n\n    print(minimax(0, 0, True, scores, height))\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()\n    main()", "blocks": [{"id": 1, "label": "from __future__ import annotations\n\nimport math\ndef minimax(depth, nodeIndex, maximizingPlayer, scores, height):\nif depth == height:", "successors": [{"id": 3, "label": "return scores[nodeIndex]", "successors": []}, {"id": 4, "label": "if maximizingPlayer:", "successors": [{"id": 5, "label": "best = -math.inf\nfor i in range(2):", "successors": [{"id": 6, "label": "val = minimax(depth + 1, nodeIndex * 2 + i,\nFalse, scores, height)\nbest = max(best, val)", "successors": []}, {"id": 7, "label": "return best", "successors": []}]}, {"id": 8, "label": "else:\nbest = math.inf\nfor i in range(2):", "successors": [{"id": 10, "label": "val = minimax(depth + 1, nodeIndex * 2 + i,\nTrue, scores, height)\nbest = min(best, val)", "successors": []}, {"id": 11, "label": "return best", "successors": []}]}]}]}]}
{"file_name": "95.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 157, "functions": [{"name": "test_graph_creation", "type": "function", "start_line": 16, "end_line": 66, "functions": [], "classes": [], "simplified_code": "async def test_graph_creation(server: SpinTestServer):\n    \"\"\"\n    Test the creation of a graph with nodes and links.\n\n    This test ensures that:\n    1. A graph can be successfully created with valid connections.\n    2. The created graph has the correct structure and properties.\n\n    Args:\n        server (SpinTestServer): The test server instance.\n    \"\"\"\n    value_block = StoreValueBlock().id\n    input_block = AgentInputBlock().id\n\n    graph = Graph(\n        id=\"test_graph\",\n        name=\"TestGraph\",\n        description=\"Test graph\",\n        nodes=[\n            Node(id=\"node_1\", block_id=value_block),\n            Node(id=\"node_2\", block_id=input_block, input_default={\"name\": \"input\"}),\n            Node(id=\"node_3\", block_id=value_block),\n        ],\n        links=[\n            Link(\n                source_id=\"node_1\",\n                sink_id=\"node_2\",\n                source_name=\"output\",\n                sink_name=\"name\",\n            ),\n        ],\n    )\n    create_graph = CreateGraph(graph=graph)\n    created_graph = await server.agent_server.test_create_graph(\n        create_graph, DEFAULT_USER_ID\n    )\n\n    assert UUID(created_graph.id)\n    assert created_graph.name == \"TestGraph\"\n\n    assert len(created_graph.nodes) == 3\n    assert UUID(created_graph.nodes[0].id)\n    assert UUID(created_graph.nodes[1].id)\n    assert UUID(created_graph.nodes[2].id)\n\n    nodes = created_graph.nodes\n    links = created_graph.links\n    assert len(links) == 1\n    assert links[0].source_id != links[0].sink_id\n    assert links[0].source_id in {nodes[0].id, nodes[1].id, nodes[2].id}\n    assert links[0].sink_id in {nodes[0].id, nodes[1].id, nodes[2].id}", "blocks": [{"id": 1, "label": "async def test_graph_creation(server: SpinTestServer):\nvalue_block = StoreValueBlock().id\ninput_block = AgentInputBlock().id\ngraph = Graph(id=\"test_graph\", name=\"TestGraph\", description=\"Test graph\", nodes=[Node(id=\"node_1\", block_id=value_block), Node(id=\"node_2\", block_id=input_block, input_default={\"name\": \"input\"}), Node(id=\"node_3\", block_id=value_block)], links=[Link(source_id=\"node_1\", sink_id=\"node_2\", source_name=\"output\", sink_name=\"name\")])\ncreate_graph = CreateGraph(graph=graph)\ncreated_graph = await server.agent_server.test_create_graph(create_graph, DEFAULT_USER_ID)", "successors": [{"id": 3, "label": "assert UUID(created_graph.id)\nassert created_graph.name == \"TestGraph\"\nassert len(created_graph.nodes) == 3\nassert UUID(created_graph.nodes[0].id)\nassert UUID(created_graph.nodes[1].id)\nassert UUID(created_graph.nodes[2].id)", "successors": [{"id": 5, "label": "nodes = created_graph.nodes\nlinks = created_graph.links\nassert len(links) == 1\nassert links[0].source_id != links[0].sink_id\nassert links[0].source_id in {nodes[0].id, nodes[1].id, nodes[2].id}\nassert links[0].sink_id in {nodes[0].id, nodes[1].id, nodes[2].id}", "successors": []}]}]}]}, {"name": "test_get_input_schema", "type": "function", "start_line": 70, "end_line": 157, "functions": [], "classes": [{"name": "ExpectedInputSchema", "type": "class", "start_line": 140, "end_line": 142, "functions": [], "classes": [], "simplified_code": "    class ExpectedInputSchema(BlockSchema):\n        in_key_a: Any = SchemaField(title=\"Key A\", default=\"A\", advanced=False)\n        in_key_b: Any = SchemaField(title=\"in_key_b\", advanced=True)", "blocks": [{"id": 1, "label": "class ExpectedInputSchema(BlockSchema):\n    in_key_a: Any = SchemaField(title=\"Key A\", default=\"A\", advanced=False)", "successors": [{"id": 3, "label": "    in_key_b: Any = SchemaField(title=\"in_key_b\", advanced=True)", "successors": []}]}]}, {"name": "ExpectedOutputSchema", "type": "class", "start_line": 144, "end_line": 149, "functions": [], "classes": [], "simplified_code": "    class ExpectedOutputSchema(BlockSchema):\n        out_key: Any = SchemaField(\n            description=\"This is an output key\",\n            title=\"out_key\",\n            advanced=False,\n        )", "blocks": [{"id": 1, "label": "class ExpectedOutputSchema(BlockSchema):\n    out_key: Any = SchemaField(\n        description=\"This is an output key\",\n        title=\"out_key\",\n        advanced=False,\n    )", "successors": []}]}], "simplified_code": "async def test_get_input_schema(server: SpinTestServer):\n    \"\"\"\n    Test the get_input_schema method of a created graph.\n\n    This test ensures that:\n    1. A graph can be created with a single node.\n    2. The input schema of the created graph is correctly generated.\n    3. The input schema contains the expected input name and node id.\n\n    Args:\n        server (SpinTestServer): The test server instance.\n    \"\"\"\n    value_block = StoreValueBlock().id\n    input_block = AgentInputBlock().id\n    output_block = AgentOutputBlock().id\n\n    graph = Graph(\n        name=\"TestInputSchema\",\n        description=\"Test input schema\",\n        nodes=[\n            Node(\n                id=\"node_0_a\",\n                block_id=input_block,\n                input_default={\"name\": \"in_key_a\", \"title\": \"Key A\", \"value\": \"A\"},\n                metadata={\"id\": \"node_0_a\"},\n            ),\n            Node(\n                id=\"node_0_b\",\n                block_id=input_block,\n                input_default={\"name\": \"in_key_b\", \"advanced\": True},\n                metadata={\"id\": \"node_0_b\"},\n            ),\n            Node(id=\"node_1\", block_id=value_block, metadata={\"id\": \"node_1\"}),\n            Node(\n                id=\"node_2\",\n                block_id=output_block,\n                input_default={\n                    \"name\": \"out_key\",\n                    \"description\": \"This is an output key\",\n                },\n                metadata={\"id\": \"node_2\"},\n            ),\n        ],\n        links=[\n            Link(\n                source_id=\"node_0_a\",\n                sink_id=\"node_1\",\n                source_name=\"result\",\n                sink_name=\"input\",\n            ),\n            Link(\n                source_id=\"node_0_b\",\n                sink_id=\"node_1\",\n                source_name=\"result\",\n                sink_name=\"input\",\n            ),\n            Link(\n                source_id=\"node_1\",\n                sink_id=\"node_2\",\n                source_name=\"output\",\n                sink_name=\"value\",\n            ),\n        ],\n    )\n\n    create_graph = CreateGraph(graph=graph)\n    created_graph = await server.agent_server.test_create_graph(\n        create_graph, DEFAULT_USER_ID\n    )\n\n        in_key_b: Any = SchemaField(title=\"in_key_b\", advanced=True)\n\n        )\n\n    input_schema = created_graph.input_schema\n    input_schema[\"title\"] = \"ExpectedInputSchema\"\n    assert input_schema == ExpectedInputSchema.jsonschema()\n\n    output_schema = created_graph.output_schema\n    output_schema[\"title\"] = \"ExpectedOutputSchema\"\n    assert output_schema == ExpectedOutputSchema.jsonschema()", "blocks": [{"id": 1, "label": "async def test_get_input_schema(server: SpinTestServer):\nvalue_block = StoreValueBlock().id\ninput_block = AgentInputBlock().id\noutput_block = AgentOutputBlock().id", "successors": [{"id": 3, "label": "graph = Graph(\n    name=\"TestInputSchema\",\n    description=\"Test input schema\",\n    nodes=[\n        Node(\n            id=\"node_0_a\",\n            block_id=input_block,\n            input_default={\"name\": \"in_key_a\", \"title\": \"Key A\", \"value\": \"A\"},\n            metadata={\"id\": \"node_0_a\"},\n        ),\n        Node(\n            id=\"node_0_b\",\n            block_id=input_block,\n            input_default={\"name\": \"in_key_b\", \"advanced\": True},\n            metadata={\"id\": \"node_0_b\"},\n        ),\n        Node(id=\"node_1\", block_id=value_block, metadata={\"id\": \"node_1\"}),\n        Node(\n            id=\"node_2\",\n            block_id=output_block,\n            input_default={\n                \"name\": \"out_key\",\n                \"description\": \"This is an output key\",\n            },\n            metadata={\"id\": \"node_2\"},\n        ),\n    ],\n    links=[\n        Link(\n            source_id=\"node_0_a\",\n            sink_id=\"node_1\",\n            source_name=\"result\",\n            sink_name=\"input\",\n        ),\n        Link(\n            source_id=\"node_0_b\",\n            sink_id=\"node_1\",\n            source_name=\"result\",\n            sink_name=\"input\",\n        ),\n        Link(\n            source_id=\"node_1\",\n            sink_id=\"node_2\",\n            source_name=\"output\",\n            sink_name=\"value\",\n        ),\n    ],\n)\ncreate_graph = CreateGraph(graph=graph)\ncreated_graph = await server.agent_server.test_create_graph(create_graph, DEFAULT_USER_ID)", "successors": [{"id": 5, "label": "input_schema = created_graph.input_schema\ninput_schema[\"title\"] = \"ExpectedInputSchema\"\nassert input_schema == ExpectedInputSchema.jsonschema()\noutput_schema = created_graph.output_schema\noutput_schema[\"title\"] = \"ExpectedOutputSchema\"\nassert output_schema == ExpectedOutputSchema.jsonschema()", "successors": []}]}]}]}], "classes": [], "simplified_code": "from typing import Any\nfrom uuid import UUID\n\nimport pytest\n\nfrom backend.blocks.basic import AgentInputBlock, AgentOutputBlock, StoreValueBlock\nfrom backend.data.block import BlockSchema\nfrom backend.data.graph import Graph, Link, Node\nfrom backend.data.model import SchemaField\nfrom backend.data.user import DEFAULT_USER_ID\nfrom backend.server.model import CreateGraph\nfrom backend.util.test import SpinTestServer\n\n\n@pytest.mark.asyncio(scope=\"session\")\n    assert links[0].sink_id in {nodes[0].id, nodes[1].id, nodes[2].id}\n\n\n@pytest.mark.asyncio(scope=\"session\")\n    assert output_schema == ExpectedOutputSchema.jsonschema()", "blocks": [{"id": 1, "label": "@pytest.mark.asyncio(scope=\"session\")\nassert links[0].sink_id in {nodes[0].id, nodes[1].id, nodes[2].id}", "successors": []}]}
{"file_name": "96.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 54, "functions": [], "classes": [{"name": "TextSettings", "type": "class", "start_line": 8, "end_line": 18, "functions": [], "simplified_code": "class TextSettings(BaseModel):\n    max_characters: int = SchemaField(\n        default=1000,\n        description=\"Maximum number of characters to return\",\n        placeholder=\"1000\",\n    )\n    include_html_tags: bool = SchemaField(\n        default=False,\n        description=\"Whether to include HTML tags in the text\",\n        placeholder=\"False\",\n    )", "blocks": [{"id": 1, "label": "class TextSettings(BaseModel):\nmax_characters: int = SchemaField(\n    default=1000,\n    description=\"Maximum number of characters to return\",\n    placeholder=\"1000\",\n)", "successors": [{"id": 3, "label": "include_html_tags: bool = SchemaField(\n    default=False,\n    description=\"Whether to include HTML tags in the text\",\n    placeholder=\"False\",\n)", "successors": []}]}]}, {"name": "HighlightSettings", "type": "class", "start_line": 21, "end_line": 31, "functions": [], "simplified_code": "class HighlightSettings(BaseModel):\n    num_sentences: int = SchemaField(\n        default=3,\n        description=\"Number of sentences per highlight\",\n        placeholder=\"3\",\n    )\n    highlights_per_url: int = SchemaField(\n        default=3,\n        description=\"Number of highlights per URL\",\n        placeholder=\"3\",\n    )", "blocks": [{"id": 1, "label": "class HighlightSettings(BaseModel):\n    num_sentences: int = SchemaField(\n        default=3,\n        description=\"Number of sentences per highlight\",\n        placeholder=\"3\",\n    )", "successors": [{"id": 3, "label": "    highlights_per_url: int = SchemaField(\n        default=3,\n        description=\"Number of highlights per URL\",\n        placeholder=\"3\",\n    )", "successors": []}]}]}, {"name": "SummarySettings", "type": "class", "start_line": 34, "end_line": 39, "functions": [], "simplified_code": "class SummarySettings(BaseModel):\n    query: Optional[str] = SchemaField(\n        default=\"\",\n        description=\"Query string for summarization\",\n        placeholder=\"Enter query\",\n    )", "blocks": [{"id": 1, "label": "class SummarySettings(BaseModel):\n    query: Optional[str] = SchemaField(\n        default=\"\",\n        description=\"Query string for summarization\",\n        placeholder=\"Enter query\",\n    )", "successors": []}]}, {"name": "ContentSettings", "type": "class", "start_line": 42, "end_line": 54, "functions": [], "simplified_code": "class ContentSettings(BaseModel):\n    text: TextSettings = SchemaField(\n        default=TextSettings(),\n        description=\"Text content settings\",\n    )\n    highlights: HighlightSettings = SchemaField(\n        default=HighlightSettings(),\n        description=\"Highlight settings\",\n    )\n    summary: SummarySettings = SchemaField(\n        default=SummarySettings(),\n        description=\"Summary settings\",\n    )", "blocks": [{"id": 1, "label": "class ContentSettings(BaseModel):\n    text: TextSettings = SchemaField(\n        default=TextSettings(),\n        description=\"Text content settings\",\n    )", "successors": [{"id": 3, "label": "    highlights: HighlightSettings = SchemaField(\n        default=HighlightSettings(),\n        description=\"Highlight settings\",\n    )\n    summary: SummarySettings = SchemaField(\n        default=SummarySettings(),\n        description=\"Summary settings\",\n    )", "successors": []}]}]}], "simplified_code": "from typing import Optional\n\nfrom pydantic import BaseModel\n\nfrom backend.data.model import SchemaField\n\n\n    )\n\n\n    )\n\n\n    )\n\n\n    )", "blocks": [{"id": 1, "label": "from typing import Optional\nfrom pydantic import BaseModel", "successors": [{"id": 3, "label": "from backend.data.model import SchemaField", "successors": []}]}]}
{"file_name": "98.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 466, "functions": [], "classes": [{"name": "TestValidadeFormat", "type": "class", "start_line": 17, "end_line": 466, "functions": [{"name": "test_error_message_return_and_return_type", "type": "function", "start_line": 19, "end_line": 40, "functions": [], "classes": [], "simplified_code": "    def test_error_message_return_and_return_type(self):\n        line_num_unity = 1\n        line_num_ten = 10\n        line_num_hundred = 100\n        line_num_thousand = 1000\n\n        msg = 'This is a unit test'\n\n        err_msg_unity = error_message(line_num_unity, msg)\n        err_msg_ten = error_message(line_num_ten, msg)\n        err_msg_hundred = error_message(line_num_hundred, msg)\n        err_msg_thousand = error_message(line_num_thousand, msg)\n\n        self.assertIsInstance(err_msg_unity, str)\n        self.assertIsInstance(err_msg_ten, str)\n        self.assertIsInstance(err_msg_hundred, str)\n        self.assertIsInstance(err_msg_thousand, str)\n\n        self.assertEqual(err_msg_unity, '(L002) This is a unit test')\n        self.assertEqual(err_msg_ten, '(L011) This is a unit test')\n        self.assertEqual(err_msg_hundred, '(L101) This is a unit test')\n        self.assertEqual(err_msg_thousand, '(L1001) This is a unit test')", "blocks": [{"id": 1, "label": "def test_error_message_return_and_return_type(self):\nline_num_unity = 1\nline_num_ten = 10\nline_num_hundred = 100\nline_num_thousand = 1000", "successors": [{"id": 3, "label": "msg = 'This is a unit test'\nerr_msg_unity = error_message(line_num_unity, msg)\nerr_msg_ten = error_message(line_num_ten, msg)\nerr_msg_hundred = error_message(line_num_hundred, msg)\nerr_msg_thousand = error_message(line_num_thousand, msg)", "successors": [{"id": 5, "label": "self.assertIsInstance(err_msg_unity, str)\nself.assertIsInstance(err_msg_ten, str)\nself.assertIsInstance(err_msg_hundred, str)\nself.assertIsInstance(err_msg_thousand, str)\nself.assertEqual(err_msg_unity, '(L002) This is a unit test')\nself.assertEqual(err_msg_ten, '(L011) This is a unit test')\nself.assertEqual(err_msg_hundred, '(L101) This is a unit test')\nself.assertEqual(err_msg_thousand, '(L1001) This is a unit test')", "successors": []}]}]}]}, {"name": "test_if_get_categories_content_return_correct_data_of_categories", "type": "function", "start_line": 42, "end_line": 70, "functions": [], "classes": [], "simplified_code": "    def test_if_get_categories_content_return_correct_data_of_categories(self):\n        fake_contents = [\n            '### A',\n            'API | Description | Auth | HTTPS | CORS |',\n            '|---|---|---|---|---|',\n            '| [AA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '| [AB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '',\n            '### B',\n            'API | Description | Auth | HTTPS | CORS |',\n            '|---|---|---|---|---|',\n            '| [BA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '| [BB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |'\n        ]\n\n        result = get_categories_content(fake_contents)\n        self.assertIsInstance(result, tuple)\n\n        categories, category_line_num = result\n        self.assertIsInstance(categories, dict)\n        self.assertIsInstance(category_line_num, dict)\n\n        expected_result = ({'A': ['AA', 'AB'], 'B': ['BA', 'BB']}, {'A': 0, 'B': 6})\n\n        for res, ex_res in zip(result, expected_result):\n\n            with self.subTest():\n                self.assertEqual(res, ex_res)\n", "blocks": [{"id": 1, "label": "def test_if_get_categories_content_return_correct_data_of_categories(self):\nfake_contents = [\n    '### A',\n    'API | Description | Auth | HTTPS | CORS |',\n    '|---|---|---|---|---|',\n    '| [AA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '| [AB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '',\n    '### B',\n    'API | Description | Auth | HTTPS | CORS |',\n    '|---|---|---|---|---|',\n    '| [BA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '| [BB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |'\n]", "successors": [{"id": 3, "label": "result = get_categories_content(fake_contents)\nself.assertIsInstance(result, tuple)", "successors": [{"id": 5, "label": "categories, category_line_num = result\nself.assertIsInstance(categories, dict)", "successors": [{"id": 7, "label": "self.assertIsInstance(category_line_num, dict)\nexpected_result = ({'A': ['AA', 'AB'], 'B': ['BA', 'BB']}, {'A': 0, 'B': 6})", "successors": [{"id": 9, "label": "for res, ex_res in zip(result, expected_result):", "successors": [{"id": 10, "label": "with self.subTest():\nself.assertEqual(res, ex_res)", "successors": []}]}]}]}]}]}]}, {"name": "test_if_check_alphabetical_order_return_correct_msg_error", "type": "function", "start_line": 71, "end_line": 118, "functions": [], "classes": [], "simplified_code": "    def test_if_check_alphabetical_order_return_correct_msg_error(self):\n        correct_lines = [\n            '### A',\n            'API | Description | Auth | HTTPS | CORS |',\n            '|---|---|---|---|---|',\n            '| [AA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '| [AB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '',\n            '### B',\n            'API | Description | Auth | HTTPS | CORS |',\n            '|---|---|---|---|---|',\n            '| [BA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '| [BB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |'\n        ]\n\n        incorrect_lines = [\n            '### A',\n            'API | Description | Auth | HTTPS | CORS |',\n            '|---|---|---|---|---|',\n            '| [AB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '| [AA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '',\n            '### B',\n            'API | Description | Auth | HTTPS | CORS |',\n            '|---|---|---|---|---|',\n            '| [BB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '| [BA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |'\n        ]\n\n\n        err_msgs_1 = check_alphabetical_order(correct_lines)\n        err_msgs_2 = check_alphabetical_order(incorrect_lines)\n\n        self.assertIsInstance(err_msgs_1, list)\n        self.assertIsInstance(err_msgs_2, list)\n\n        self.assertEqual(len(err_msgs_1), 0)\n        self.assertEqual(len(err_msgs_2), 2)\n\n        expected_err_msgs = [\n            '(L001) A category is not alphabetical order',\n            '(L007) B category is not alphabetical order'\n        ]\n\n        for err_msg, ex_err_msg in zip(err_msgs_2, expected_err_msgs):\n\n            with self.subTest():\n                self.assertEqual(err_msg, ex_err_msg)", "blocks": [{"id": 1, "label": "def test_if_check_alphabetical_order_return_correct_msg_error(self):\ncorrect_lines = [\n    '### A',\n    'API | Description | Auth | HTTPS | CORS |',\n    '|---|---|---|---|---|',\n    '| [AA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '| [AB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '',\n    '### B',\n    'API | Description | Auth | HTTPS | CORS |',\n    '|---|---|---|---|---|',\n    '| [BA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '| [BB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |'\n]", "successors": [{"id": 3, "label": "incorrect_lines = [\n    '### A',\n    'API | Description | Auth | HTTPS | CORS |',\n    '|---|---|---|---|---|',\n    '| [AB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '| [AA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '',\n    '### B',\n    'API | Description | Auth | HTTPS | CORS |',\n    '|---|---|---|---|---|',\n    '| [BB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '| [BA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |'\n]\nerr_msgs_1 = check_alphabetical_order(correct_lines)\nerr_msgs_2 = check_alphabetical_order(incorrect_lines)", "successors": [{"id": 5, "label": "self.assertIsInstance(err_msgs_1, list)\nself.assertIsInstance(err_msgs_2, list)\nself.assertEqual(len(err_msgs_1), 0)\nself.assertEqual(len(err_msgs_2), 2)", "successors": [{"id": 7, "label": "expected_err_msgs = [\n    '(L001) A category is not alphabetical order',\n    '(L007) B category is not alphabetical order'\n]", "successors": [{"id": 8, "label": "for err_msg, ex_err_msg in zip(err_msgs_2, expected_err_msgs):", "successors": [{"id": 9, "label": "with self.subTest():\nself.assertEqual(err_msg, ex_err_msg)", "successors": []}]}]}]}]}]}]}, {"name": "test_check_title_with_correct_title", "type": "function", "start_line": 120, "end_line": 127, "functions": [], "classes": [], "simplified_code": "    def test_check_title_with_correct_title(self):\n        raw_title = '[A](https://www.ex.com)'\n\n        err_msgs = check_title(0, raw_title)\n\n        self.assertIsInstance(err_msgs, list)\n        self.assertEqual(len(err_msgs), 0)\n        self.assertEqual(err_msgs, [])", "blocks": [{"id": 1, "label": "def test_check_title_with_correct_title(self):\nraw_title = '[A](https://www.ex.com)'", "successors": [{"id": 3, "label": "err_msgs = check_title(0, raw_title)\nself.assertIsInstance(err_msgs, list)", "successors": [{"id": 5, "label": "self.assertEqual(len(err_msgs), 0)\nself.assertEqual(err_msgs, [])", "successors": []}]}]}]}, {"name": "test_check_title_with_markdown_syntax_incorrect", "type": "function", "start_line": 129, "end_line": 140, "functions": [], "classes": [], "simplified_code": "    def test_check_title_with_markdown_syntax_incorrect(self):\n        raw_title = '[A(https://www.ex.com)'\n\n        err_msgs = check_title(0, raw_title)\n\n        self.assertIsInstance(err_msgs, list)\n        self.assertEqual(len(err_msgs), 1)\n        \n        err_msg = err_msgs[0]\n        expected_err_msg = '(L001) Title syntax should be \"[TITLE](LINK)\"'\n\n        self.assertEqual(err_msg, expected_err_msg)", "blocks": [{"id": 1, "label": "def test_check_title_with_markdown_syntax_incorrect(self):\nraw_title = '[A(https://www.ex.com)'", "successors": [{"id": 3, "label": "err_msgs = check_title(0, raw_title)\nself.assertIsInstance(err_msgs, list)", "successors": [{"id": 5, "label": "self.assertEqual(len(err_msgs), 1)\nerr_msg = err_msgs[0]", "successors": [{"id": 7, "label": "expected_err_msg = '(L001) Title syntax should be \"[TITLE](LINK)\"'\nself.assertEqual(err_msg, expected_err_msg)", "successors": []}]}]}]}]}, {"name": "test_check_title_with_api_at_the_end_of_the_title", "type": "function", "start_line": 142, "end_line": 153, "functions": [], "classes": [], "simplified_code": "    def test_check_title_with_api_at_the_end_of_the_title(self):\n        raw_title = '[A API](https://www.ex.com)'\n\n        err_msgs = check_title(0, raw_title)\n        \n        self.assertIsInstance(err_msgs, list)\n        self.assertEqual(len(err_msgs), 1)\n        \n        err_msg = err_msgs[0]\n        expected_err_msg = '(L001) Title should not end with \"... API\". Every entry is an API here!'\n\n        self.assertEqual(err_msg, expected_err_msg)", "blocks": [{"id": 1, "label": "def test_check_title_with_api_at_the_end_of_the_title(self):\nraw_title = '[A API](https://www.ex.com)'", "successors": [{"id": 3, "label": "err_msgs = check_title(0, raw_title)\nself.assertIsInstance(err_msgs, list)", "successors": [{"id": 5, "label": "self.assertEqual(len(err_msgs), 1)\nerr_msg = err_msgs[0]", "successors": [{"id": 7, "label": "expected_err_msg = '(L001) Title should not end with \"... API\". Every entry is an API here!'\nself.assertEqual(err_msg, expected_err_msg)", "successors": []}]}]}]}]}, {"name": "test_check_description_with_correct_description", "type": "function", "start_line": 155, "end_line": 162, "functions": [], "classes": [], "simplified_code": "    def test_check_description_with_correct_description(self):\n        desc = 'This is a fake description'\n\n        err_msgs = check_description(0, desc)\n\n        self.assertIsInstance(err_msgs, list)\n        self.assertEqual(len(err_msgs), 0)\n        self.assertEqual(err_msgs, [])", "blocks": [{"id": 1, "label": "def test_check_description_with_correct_description(self):\n    desc = 'This is a fake description'\n\n    err_msgs = check_description(0, desc)\n\n    self.assertIsInstance(err_msgs, list)\n    self.assertEqual(len(err_msgs), 0)\n    self.assertEqual(err_msgs, [])", "successors": []}]}, {"name": "test_check_description_with_first_char_is_not_capitalized", "type": "function", "start_line": 164, "end_line": 176, "functions": [], "classes": [], "simplified_code": "    def test_check_description_with_first_char_is_not_capitalized(self):\n        desc = 'this is a fake description'\n\n        err_msgs = check_description(0, desc)\n\n        self.assertIsInstance(err_msgs, list)\n        self.assertEqual(len(err_msgs), 1)\n        \n        err_msg = err_msgs[0]\n        expected_err_msg = '(L001) first character of description is not capitalized'\n\n        self.assertIsInstance(err_msg, str)\n        self.assertEqual(err_msg, expected_err_msg)", "blocks": [{"id": 1, "label": "def test_check_description_with_first_char_is_not_capitalized(self):\n    desc = 'this is a fake description'\nerr_msgs = check_description(0, desc)", "successors": [{"id": 3, "label": "self.assertIsInstance(err_msgs, list)\nself.assertEqual(len(err_msgs), 1)\nerr_msg = err_msgs[0]\nexpected_err_msg = '(L001) first character of description is not capitalized'", "successors": [{"id": 5, "label": "self.assertIsInstance(err_msg, str)\nself.assertEqual(err_msg, expected_err_msg)", "successors": []}]}]}]}, {"name": "test_check_description_with_punctuation_in_the_end", "type": "function", "start_line": 178, "end_line": 195, "functions": [], "classes": [], "simplified_code": "    def test_check_description_with_punctuation_in_the_end(self):\n        base_desc = 'This is a fake description'\n        punctuation = r\"\"\"!\"#$%&'*+,-./:;<=>?@[\\]^_`{|}~\"\"\"\n        desc_with_punc = [base_desc + punc for punc in punctuation]\n        \n        for desc in desc_with_punc:\n\n            with self.subTest():\n                err_msgs = check_description(0, desc)\n\n                self.assertIsInstance(err_msgs, list)\n                self.assertEqual(len(err_msgs), 1)\n        \n                err_msg = err_msgs[0]\n                expected_err_msg = f'(L001) description should not end with {desc[-1]}'\n\n                self.assertIsInstance(err_msg, str)\n                self.assertEqual(err_msg, expected_err_msg)", "blocks": [{"id": 1, "label": "def test_check_description_with_punctuation_in_the_end(self):\nbase_desc = 'This is a fake description'\npunctuation = r\"!\\\"#$%&'*+,-./:;<=>?@[\\]^_`{|}~\"\ndesc_with_punc = [base_desc + punc for punc in punctuation]", "successors": [{"id": 3, "label": "for desc in desc_with_punc:", "successors": [{"id": 4, "label": "with self.subTest():\nerr_msgs = check_description(0, desc)\nself.assertIsInstance(err_msgs, list)\nself.assertEqual(len(err_msgs), 1)\nerr_msg = err_msgs[0]\nexpected_err_msg = f'(L001) description should not end with {desc[-1]}'\nself.assertIsInstance(err_msg, str)\nself.assertEqual(err_msg, expected_err_msg)", "successors": []}]}]}]}, {"name": "test_check_description_that_exceeds_the_character_limit", "type": "function", "start_line": 197, "end_line": 210, "functions": [], "classes": [], "simplified_code": "    def test_check_description_that_exceeds_the_character_limit(self):\n        long_desc = 'Desc' * max_description_length\n        long_desc_length = len(long_desc)\n\n        err_msgs = check_description(0, long_desc)\n\n        self.assertIsInstance(err_msgs, list)\n        self.assertEqual(len(err_msgs), 1)\n\n        err_msg = err_msgs[0]\n        expected_err_msg = f'(L001) description should not exceed {max_description_length} characters (currently {long_desc_length})'\n\n        self.assertIsInstance(err_msg, str)\n        self.assertEqual(err_msg, expected_err_msg)", "blocks": [{"id": 1, "label": "def test_check_description_that_exceeds_the_character_limit(self):\nlong_desc = 'Desc' * max_description_length\nlong_desc_length = len(long_desc)", "successors": [{"id": 3, "label": "err_msgs = check_description(0, long_desc)\nself.assertIsInstance(err_msgs, list)\nself.assertEqual(len(err_msgs), 1)", "successors": [{"id": 5, "label": "err_msg = err_msgs[0]\nexpected_err_msg = f'(L001) description should not exceed {max_description_length} characters (currently {long_desc_length})'\nself.assertIsInstance(err_msg, str)\nself.assertEqual(err_msg, expected_err_msg)", "successors": []}]}]}]}, {"name": "test_check_auth_with_valid_auth", "type": "function", "start_line": 212, "end_line": 221, "functions": [], "classes": [], "simplified_code": "    def test_check_auth_with_valid_auth(self):\n        auth_valid = [f'`{auth}`' for auth in auth_keys if auth != 'No']\n        auth_valid.append('No')\n\n        for auth in auth_valid:\n            with self.subTest():\n                err_msgs = check_auth(0, auth)\n                self.assertIsInstance(err_msgs, list)\n                self.assertEqual(len(err_msgs), 0)\n                self.assertEqual(err_msgs, [])", "blocks": [{"id": 1, "label": "def test_check_auth_with_valid_auth(self):\n    auth_valid = [f'`{auth}`' for auth in auth_keys if auth != 'No']\n    auth_valid.append('No')", "successors": [{"id": 2, "label": "for auth in auth_valid:", "successors": [{"id": 3, "label": "    with self.subTest():\n        err_msgs = check_auth(0, auth)\n        self.assertIsInstance(err_msgs, list)\n        self.assertEqual(len(err_msgs), 0)\n        self.assertEqual(err_msgs, [])", "successors": []}]}]}]}, {"name": "test_check_auth_without_backtick", "type": "function", "start_line": 223, "end_line": 236, "functions": [], "classes": [], "simplified_code": "    def test_check_auth_without_backtick(self):\n        auth_without_backtick = [auth for auth in auth_keys if auth != 'No']\n\n        for auth in auth_without_backtick:\n            with self.subTest():\n                err_msgs = check_auth(0, auth)\n                self.assertIsInstance(err_msgs, list)\n                self.assertEqual(len(err_msgs), 1)\n\n                err_msg = err_msgs[0]\n                expected_err_msg = '(L001) auth value is not enclosed with `backticks`'\n\n                self.assertIsInstance(err_msg, str)\n                self.assertEqual(err_msg, expected_err_msg)", "blocks": [{"id": 1, "label": "auth_without_backtick = [auth for auth in auth_keys if auth != 'No']", "successors": [{"id": 2, "label": "for auth in auth_without_backtick:", "successors": [{"id": 3, "label": "with self.subTest():\nerr_msgs = check_auth(0, auth)\nself.assertIsInstance(err_msgs, list)\nself.assertEqual(len(err_msgs), 1)", "successors": [{"id": 5, "label": "err_msg = err_msgs[0]\nexpected_err_msg = '(L001) auth value is not enclosed with `backticks`'\nself.assertIsInstance(err_msg, str)\nself.assertEqual(err_msg, expected_err_msg)", "successors": []}]}]}]}]}, {"name": "test_check_auth_with_invalid_auth", "type": "function", "start_line": 238, "end_line": 269, "functions": [], "classes": [], "simplified_code": "    def test_check_auth_with_invalid_auth(self):\n        auth_invalid_without_backtick = ['Yes', 'yes', 'no', 'random', 'Unknown']\n        auth_invalid_with_backtick = ['`Yes`', '`yes`', '`no`', '`random`', '`Unknown`']\n\n        for auth in auth_invalid_without_backtick:\n            with self.subTest():\n                err_msgs = check_auth(0, auth)\n                self.assertIsInstance(err_msgs, list)\n                self.assertEqual(len(err_msgs), 2)\n\n                err_msg_1 = err_msgs[0]\n                err_msg_2 = err_msgs[1]\n\n                expected_err_msg_1 = f'(L001) auth value is not enclosed with `backticks`'\n                expected_err_msg_2 = f'(L001) {auth} is not a valid Auth option'\n\n                self.assertIsInstance(err_msg_1, str)\n                self.assertIsInstance(err_msg_2, str)\n                self.assertEqual(err_msg_1, expected_err_msg_1)\n                self.assertEqual(err_msg_2, expected_err_msg_2)\n\n        for auth in auth_invalid_with_backtick:\n            with self.subTest():\n                err_msgs = check_auth(0, auth)\n                self.assertIsInstance(err_msgs, list)\n                self.assertEqual(len(err_msgs), 1)\n\n                err_msg = err_msgs[0]\n                expected_err_msg = f'(L001) {auth} is not a valid Auth option'\n\n                self.assertIsInstance(err_msg, str)\n                self.assertEqual(err_msg, expected_err_msg)", "blocks": [{"id": 1, "label": "def test_check_auth_with_invalid_auth(self):", "successors": [{"id": 2, "label": "auth_invalid_without_backtick = ['Yes', 'yes', 'no', 'random', 'Unknown']\nauth_invalid_with_backtick = ['`Yes`', '`yes`', '`no`', '`random`', '`Unknown`]'\n\nfor auth in auth_invalid_without_backtick:\nwith self.subTest():", "successors": [{"id": 4, "label": "err_msgs = check_auth(0, auth)\nself.assertIsInstance(err_msgs, list)\nself.assertEqual(len(err_msgs), 2)\n\nerr_msg_1 = err_msgs[0]\nerr_msg_2 = err_msgs[1]\n\nexpected_err_msg_1 = f'(L001) auth value is not enclosed with `backticks`'\nexpected_err_msg_2 = f'(L001) {auth} is not a valid Auth option'\n\nself.assertIsInstance(err_msg_1, str)\nself.assertIsInstance(err_msg_2, str)\nself.assertEqual(err_msg_1, expected_err_msg_1)\nself.assertEqual(err_msg_2, expected_err_msg_2)", "successors": []}]}, {"id": 5, "label": "for auth in auth_invalid_with_backtick:", "successors": [{"id": 6, "label": "with self.subTest():\nerr_msgs = check_auth(0, auth)\nself.assertIsInstance(err_msgs, list)\nself.assertEqual(len(err_msgs), 1)\n\nerr_msg = err_msgs[0]\nexpected_err_msg = f'(L001) {auth} is not a valid Auth option'\n\nself.assertIsInstance(err_msg, str)\nself.assertEqual(err_msg, expected_err_msg)", "successors": []}]}]}]}, {"name": "test_check_https_with_valid_https", "type": "function", "start_line": 271, "end_line": 277, "functions": [], "classes": [], "simplified_code": "    def test_check_https_with_valid_https(self):\n        for https in https_keys:\n            with self.subTest():\n                err_msgs = check_https(0, https)\n                self.assertIsInstance(err_msgs, list)\n                self.assertEqual(len(err_msgs), 0)\n                self.assertEqual(err_msgs, [])", "blocks": [{"id": 1, "label": "def test_check_https_with_valid_https(self):", "successors": [{"id": 2, "label": "for https in https_keys:", "successors": [{"id": 3, "label": "with self.subTest():\nerr_msgs = check_https(0, https)\nself.assertIsInstance(err_msgs, list)\nself.assertEqual(len(err_msgs), 0)\nself.assertEqual(err_msgs, [])", "successors": []}]}]}]}, {"name": "test_check_https_with_invalid_https", "type": "function", "start_line": 279, "end_line": 292, "functions": [], "classes": [], "simplified_code": "    def test_check_https_with_invalid_https(self):\n        invalid_https_keys = ['yes', 'no', 'Unknown', 'https', 'http']\n\n        for https in invalid_https_keys:\n            with self.subTest():\n                err_msgs = check_https(0, https)\n                self.assertIsInstance(err_msgs, list)\n                self.assertEqual(len(err_msgs), 1)\n\n                err_msg = err_msgs[0]\n                expected_err_msg = f'(L001) {https} is not a valid HTTPS option'\n\n                self.assertIsInstance(err_msg, str)\n                self.assertEqual(err_msg, expected_err_msg)", "blocks": [{"id": 1, "label": "def test_check_https_with_invalid_https(self):\ninvalid_https_keys = ['yes', 'no', 'Unknown', 'https', 'http']", "successors": [{"id": 3, "label": "for https in invalid_https_keys:", "successors": [{"id": 5, "label": "err_msgs = check_https(0, https)\nself.assertIsInstance(err_msgs, list)\nself.assertEqual(len(err_msgs), 1)\n\nerr_msg = err_msgs[0]\nexpected_err_msg = f'(L001) {https} is not a valid HTTPS option'\n\nself.assertIsInstance(err_msg, str)\nself.assertEqual(err_msg, expected_err_msg)", "successors": [{"id": 3, "label": "for https in invalid_https_keys:", "successors": [{"id": 5, "label": "err_msgs = check_https(0, https)\nself.assertIsInstance(err_msgs, list)\nself.assertEqual(len(err_msgs), 1)\n\nerr_msg = err_msgs[0]\nexpected_err_msg = f'(L001) {https} is not a valid HTTPS option'\n\nself.assertIsInstance(err_msg, str)\nself.assertEqual(err_msg, expected_err_msg)", "successors": []}]}]}, {"id": 6, "label": "err_msgs = check_https(0, https)\nself.assertIsInstance(err_msgs, list)\nself.assertEqual(len(err_msgs), 1)\n\nerr_msg = err_msgs[0]\nexpected_err_msg = f'(L001) {https} is not a valid HTTPS option'\n\nself.assertIsInstance(err_msg, str)\nself.assertEqual(err_msg, expected_err_msg)", "successors": []}]}]}]}, {"name": "test_check_cors_with_valid_cors", "type": "function", "start_line": 294, "end_line": 300, "functions": [], "classes": [], "simplified_code": "    def test_check_cors_with_valid_cors(self):\n        for cors in cors_keys:\n            with self.subTest():\n                err_msgs = check_cors(0, cors)\n                self.assertIsInstance(err_msgs, list)\n                self.assertEqual(len(err_msgs), 0)\n                self.assertEqual(err_msgs, [])", "blocks": [{"id": 1, "label": "def test_check_cors_with_valid_cors(self):", "successors": [{"id": 2, "label": "for cors in cors_keys:", "successors": [{"id": 3, "label": "with self.subTest():\nerr_msgs = check_cors(0, cors)\nself.assertIsInstance(err_msgs, list)\nself.assertEqual(len(err_msgs), 0)\nself.assertEqual(err_msgs, [])", "successors": [{"id": 2, "label": "for cors in cors_keys:", "successors": []}]}]}]}]}, {"name": "test_check_cors_with_invalid_cors", "type": "function", "start_line": 302, "end_line": 315, "functions": [], "classes": [], "simplified_code": "    def test_check_cors_with_invalid_cors(self):\n        invalid_cors_keys = ['yes', 'no', 'unknown', 'cors']\n\n        for cors in invalid_cors_keys:\n            with self.subTest():\n                err_msgs = check_cors(0, cors)\n                self.assertIsInstance(err_msgs, list)\n                self.assertEqual(len(err_msgs), 1)\n\n                err_msg = err_msgs[0]\n                expected_err_msg = f'(L001) {cors} is not a valid CORS option'\n\n                self.assertIsInstance(err_msg, str)\n                self.assertEqual(err_msg, expected_err_msg)", "blocks": [{"id": 1, "label": "invalid_cors_keys = ['yes', 'no', 'unknown', 'cors']", "successors": [{"id": 2, "label": "for cors in invalid_cors_keys:", "successors": [{"id": 3, "label": "with self.subTest():\nerr_msgs = check_cors(0, cors)\nself.assertIsInstance(err_msgs, list)\nself.assertEqual(len(err_msgs), 1)", "successors": [{"id": 5, "label": "err_msg = err_msgs[0]\nexpected_err_msg = f'(L001) {cors} is not a valid CORS option'\nself.assertIsInstance(err_msg, str)\nself.assertEqual(err_msg, expected_err_msg)", "successors": []}]}]}]}]}, {"name": "test_check_entry_with_correct_segments", "type": "function", "start_line": 317, "end_line": 324, "functions": [], "classes": [], "simplified_code": "    def test_check_entry_with_correct_segments(self):\n        correct_segments = ['[A](https://www.ex.com)', 'Desc', '`apiKey`', 'Yes', 'Yes']\n\n        err_msgs = check_entry(0, correct_segments)\n        \n        self.assertIsInstance(err_msgs, list)\n        self.assertEqual(len(err_msgs), 0)\n        self.assertEqual(err_msgs, [])", "blocks": [{"id": 1, "label": "correct_segments = ['[A](https://www.ex.com)', 'Desc', '`apiKey`', 'Yes', 'Yes']\nerr_msgs = check_entry(0, correct_segments)", "successors": [{"id": 3, "label": "self.assertIsInstance(err_msgs, list)\nself.assertEqual(len(err_msgs), 0)", "successors": [{"id": 5, "label": "self.assertEqual(err_msgs, [])", "successors": []}]}]}]}, {"name": "test_check_entry_with_incorrect_segments", "type": "function", "start_line": 326, "end_line": 345, "functions": [], "classes": [], "simplified_code": "    def test_check_entry_with_incorrect_segments(self):\n        incorrect_segments = ['[A API](https://www.ex.com)', 'desc.', 'yes', 'yes', 'yes']\n\n        err_msgs = check_entry(0, incorrect_segments)\n        expected_err_msgs = [\n            '(L001) Title should not end with \"... API\". Every entry is an API here!',\n            '(L001) first character of description is not capitalized',\n            '(L001) description should not end with .',\n            '(L001) auth value is not enclosed with `backticks`',\n            '(L001) yes is not a valid Auth option',\n            '(L001) yes is not a valid HTTPS option',\n            '(L001) yes is not a valid CORS option'\n        ]\n\n        self.assertIsInstance(err_msgs, list)\n        self.assertEqual(len(err_msgs), 7)\n        for err_msg in err_msgs:\n            with self.subTest():\n                self.assertIsInstance(err_msg, str)\n        self.assertEqual(err_msgs, expected_err_msgs)", "blocks": [{"id": 1, "label": "def test_check_entry_with_incorrect_segments(self):\nincorrect_segments = ['[A API](https://www.ex.com)', 'desc.', 'yes', 'yes', 'yes']", "successors": [{"id": 3, "label": "err_msgs = check_entry(0, incorrect_segments)\nexpected_err_msgs = [\n    '(L001) Title should not end with \"... API\". Every entry is an API here!',\n    '(L001) first character of description is not capitalized',\n    '(L001) description should not end with .',\n    '(L001) auth value is not enclosed with `backticks`',\n    '(L001) yes is not a valid Auth option',\n    '(L001) yes is not a valid HTTPS option',\n    '(L001) yes is not a valid CORS option'\n]", "successors": [{"id": 5, "label": "self.assertIsInstance(err_msgs, list)\nself.assertEqual(len(err_msgs), 7)", "successors": [{"id": 7, "label": "for err_msg in err_msgs:", "successors": [{"id": 8, "label": "with self.subTest():\nself.assertIsInstance(err_msg, str)", "successors": [{"id": 10, "label": "self.assertEqual(err_msgs, expected_err_msgs)", "successors": []}]}]}]}]}]}]}, {"name": "test_check_file_format_with_correct_format", "type": "function", "start_line": 347, "end_line": 372, "functions": [], "classes": [], "simplified_code": "    def test_check_file_format_with_correct_format(self):\n        correct_format = [\n            '## Index',\n            '* [A](#a)',\n            '* [B](#b)',\n            '',\n            '### A',\n            'API | Description | Auth | HTTPS | CORS |',\n            '|---|---|---|---|---|',\n            '| [AA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '| [AB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '| [AC](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '',\n            '### B',\n            'API | Description | Auth | HTTPS | CORS |',\n            '|---|---|---|---|---|',\n            '| [BA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '| [BB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '| [BC](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |'\n        ]\n\n        err_msgs = check_file_format(lines=correct_format)\n\n        self.assertIsInstance(err_msgs, list)\n        self.assertEqual(len(err_msgs), 0)\n        self.assertEqual(err_msgs, [])", "blocks": [{"id": 1, "label": "def test_check_file_format_with_correct_format(self):\ncorrect_format = [\n    '## Index',\n    '* [A](#a)',\n    '* [B](#b)',\n    '',\n    '### A',\n    'API | Description | Auth | HTTPS | CORS |',\n    '|---|---|---|---|---|',\n    '| [AA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '| [AB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '| [AC](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '',\n    '### B',\n    'API | Description | Auth | HTTPS | CORS |',\n    '|---|---|---|---|---|',\n    '| [BA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '| [BB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '| [BC](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |'\n]", "successors": [{"id": 3, "label": "err_msgs = check_file_format(lines=correct_format)\nself.assertIsInstance(err_msgs, list)", "successors": [{"id": 5, "label": "self.assertEqual(len(err_msgs), 0)\nself.assertEqual(err_msgs, [])", "successors": []}]}]}]}, {"name": "test_check_file_format_with_category_header_not_added_to_index", "type": "function", "start_line": 374, "end_line": 392, "functions": [], "classes": [], "simplified_code": "    def test_check_file_format_with_category_header_not_added_to_index(self):\n        incorrect_format = [\n            '## Index',\n            '',\n            '### A',\n            'API | Description | Auth | HTTPS | CORS |',\n            '|---|---|---|---|---|',\n            '| [AA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '| [AB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '| [AC](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n        ]\n\n        err_msgs = check_file_format(lines=incorrect_format)\n        expected_err_msg = '(L003) category header (A) not added to Index section'\n\n        self.assertIsInstance(err_msgs, list)\n        self.assertEqual(len(err_msgs), 1)\n        err_msg = err_msgs[0]\n        self.assertEqual(err_msg, expected_err_msg)", "blocks": [{"id": 1, "label": "def test_check_file_format_with_category_header_not_added_to_index(self):\nincorrect_format = [\n    '## Index',\n    '',\n    '### A',\n    'API | Description | Auth | HTTPS | CORS |',\n    '|---|---|---|---|---|',\n    '| [AA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '| [AB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '| [AC](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n]", "successors": [{"id": 3, "label": "err_msgs = check_file_format(lines=incorrect_format)\nexpected_err_msg = '(L003) category header (A) not added to Index section'\nself.assertIsInstance(err_msgs, list)\nself.assertEqual(len(err_msgs), 1)\nerr_msg = err_msgs[0]\nself.assertEqual(err_msg, expected_err_msg)", "successors": []}]}]}, {"name": "test_check_file_format_with_category_without_min_entries", "type": "function", "start_line": 394, "end_line": 422, "functions": [], "classes": [], "simplified_code": "    def test_check_file_format_with_category_without_min_entries(self):\n        incorrect_format = [\n            '## Index',\n            '* [A](#a)',\n            '* [B](#b)',\n            '',\n            '### A',\n            'API | Description | Auth | HTTPS | CORS |',\n            '|---|---|---|---|---|',\n            '| [AA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '',\n            '### B',\n            'API | Description | Auth | HTTPS | CORS |',\n            '|---|---|---|---|---|',\n            '| [BA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '| [BB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '| [BC](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |'\n        ]\n\n        category_with_err = 'A'\n        num_in_category = 1\n\n        err_msgs = check_file_format(lines=incorrect_format)\n        expected_err_msg = f'(L005) {category_with_err} category does not have the minimum {min_entries_per_category} entries (only has {num_in_category})'\n\n        self.assertIsInstance(err_msgs, list)\n        self.assertEqual(len(err_msgs), 1)\n        err_msg = err_msgs[0]\n        self.assertEqual(err_msg, expected_err_msg)", "blocks": [{"id": 1, "label": "def test_check_file_format_with_category_without_min_entries(self):\nincorrect_format = [\n    '## Index',\n    '* [A](#a)',\n    '* [B](#b)',\n    '',\n    '### A',\n    'API | Description | Auth | HTTPS | CORS |',\n    '|---|---|---|---|---|',\n    '| [AA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '',\n    '### B',\n    'API | Description | Auth | HTTPS | CORS |',\n    '|---|---|---|---|---|',\n    '| [BA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '| [BB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '| [BC](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |'\n]", "successors": [{"id": 3, "label": "category_with_err = 'A'\nnum_in_category = 1\nerr_msgs = check_file_format(lines=incorrect_format)", "successors": [{"id": 5, "label": "expected_err_msg = f'(L005) {category_with_err} category does not have the minimum {min_entries_per_category} entries (only has {num_in_category})'\nself.assertIsInstance(err_msgs, list)", "successors": [{"id": 7, "label": "self.assertEqual(len(err_msgs), 1)\nerr_msg = err_msgs[0]", "successors": [{"id": 9, "label": "self.assertEqual(err_msg, expected_err_msg)", "successors": []}]}]}]}]}]}, {"name": "test_check_file_format_entry_without_all_necessary_columns", "type": "function", "start_line": 424, "end_line": 445, "functions": [], "classes": [], "simplified_code": "    def test_check_file_format_entry_without_all_necessary_columns(self):\n        incorrect_format = [\n            '## Index',\n            '* [A](#a)',\n            '',\n            '### A',\n            'API | Description | Auth | HTTPS | CORS |',\n            '|---|---|---|---|---|',\n            '| [AA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '| [AB](https://www.ex.com) | Desc | `apiKey` |',  # missing https and cors\n            '| [AC](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n        ]\n\n        current_segments_num = 3\n\n        err_msgs = check_file_format(lines=incorrect_format)\n        expected_err_msg = f'(L008) entry does not have all the required columns (have {current_segments_num}, need {num_segments})'\n\n        self.assertIsInstance(err_msgs, list)\n        self.assertEqual(len(err_msgs), 1)\n        err_msg = err_msgs[0]\n        self.assertEqual(err_msg, expected_err_msg)", "blocks": [{"id": 1, "label": "def test_check_file_format_entry_without_all_necessary_columns(self):\nincorrect_format = [\n    '## Index',\n    '* [A](#a)',\n    '',\n    '### A',\n    'API | Description | Auth | HTTPS | CORS |',\n    '|---|---|---|---|---|',\n    '| [AA](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '| [AB](https://www.ex.com) | Desc | `apiKey` |',  # missing https and cors\n    '| [AC](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |'\n]", "successors": [{"id": 3, "label": "current_segments_num = 3\nerr_msgs = check_file_format(lines=incorrect_format)\nexpected_err_msg = f'(L008) entry does not have all the required columns (have {current_segments_num}, need {num_segments})'", "successors": [{"id": 5, "label": "self.assertIsInstance(err_msgs, list)\nself.assertEqual(len(err_msgs), 1)", "successors": [{"id": 7, "label": "err_msg = err_msgs[0]\nself.assertEqual(err_msg, expected_err_msg)", "successors": []}]}]}]}]}, {"name": "test_check_file_format_without_1_space_between_the_segments", "type": "function", "start_line": 447, "end_line": 466, "functions": [], "classes": [], "simplified_code": "    def test_check_file_format_without_1_space_between_the_segments(self):\n        incorrect_format = [\n            '## Index',\n            '* [A](#a)',\n            '',\n            '### A',\n            'API | Description | Auth | HTTPS | CORS |',\n            '|---|---|---|---|---|',\n            '| [AA](https://www.ex.com) | Desc |`apiKey`| Yes | Yes |',  # space between segment of auth column missing\n            '| [AB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n            '| [AC](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n        ]\n\n        err_msgs = check_file_format(lines=incorrect_format)\n        expected_err_msg = f'(L007) each segment must start and end with exactly 1 space'\n\n        self.assertIsInstance(err_msgs, list)\n        self.assertEqual(len(err_msgs), 1)\n        err_msg = err_msgs[0]\n        self.assertEqual(err_msg, expected_err_msg)", "blocks": [{"id": 1, "label": "incorrect_format = [\n    '## Index',\n    '* [A](#a)',\n    '',\n    '### A',\n    'API | Description | Auth | HTTPS | CORS |',\n    '|---|---|---|---|---|',\n    '| [AA](https://www.ex.com) | Desc |`apiKey`| Yes | Yes |',  # space between segment of auth column missing\n    '| [AB](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n    '| [AC](https://www.ex.com) | Desc | `apiKey` | Yes | Yes |',\n]\nerr_msgs = check_file_format(lines=incorrect_format)", "successors": [{"id": 3, "label": "expected_err_msg = f'(L007) each segment must start and end with exactly 1 space'\nself.assertIsInstance(err_msgs, list)", "successors": [{"id": 5, "label": "self.assertEqual(len(err_msgs), 1)\nerr_msg = err_msgs[0]", "successors": [{"id": 7, "label": "self.assertEqual(err_msg, expected_err_msg)", "successors": []}]}]}]}]}], "classes": [], "simplified_code": "class TestValidadeFormat(unittest.TestCase):\n    \n        self.assertEqual(err_msg_thousand, '(L1001) This is a unit test')\n\n\n                self.assertEqual(err_msg, ex_err_msg)\n    \n        self.assertEqual(err_msgs, [])\n\n        self.assertEqual(err_msg, expected_err_msg)\n\n        self.assertEqual(err_msg, expected_err_msg)\n\n        self.assertEqual(err_msgs, [])\n    \n        self.assertEqual(err_msg, expected_err_msg)\n    \n                self.assertEqual(err_msg, expected_err_msg)\n\n        self.assertEqual(err_msg, expected_err_msg)\n\n                self.assertEqual(err_msgs, [])\n\n                self.assertEqual(err_msg, expected_err_msg)\n\n                self.assertEqual(err_msg, expected_err_msg)\n\n                self.assertEqual(err_msgs, [])\n\n                self.assertEqual(err_msg, expected_err_msg)\n\n                self.assertEqual(err_msgs, [])\n\n                self.assertEqual(err_msg, expected_err_msg)\n\n        self.assertEqual(err_msgs, [])\n\n        self.assertEqual(err_msgs, expected_err_msgs)\n\n        self.assertEqual(err_msgs, [])\n\n        self.assertEqual(err_msg, expected_err_msg)\n\n        self.assertEqual(err_msg, expected_err_msg)\n\n        self.assertEqual(err_msg, expected_err_msg)\n\n        self.assertEqual(err_msg, expected_err_msg)", "blocks": [{"id": 1, "label": "class TestValidadeFormat(unittest.TestCase):\n    self.assertEqual(err_msg_thousand, '(L1001) This is a unit test')", "successors": [{"id": 3, "label": "    self.assertEqual(err_msg, ex_err_msg)\n    self.assertEqual(err_msgs, [])", "successors": [{"id": 5, "label": "    self.assertEqual(err_msg, expected_err_msg)\n    self.assertEqual(err_msg, expected_err_msg)", "successors": [{"id": 7, "label": "    self.assertEqual(err_msgs, [])\n    self.assertEqual(err_msg, expected_err_msg)", "successors": [{"id": 9, "label": "    self.assertEqual(err_msg, expected_err_msg)\n    self.assertEqual(err_msgs, [])", "successors": [{"id": 11, "label": "    self.assertEqual(err_msg, expected_err_msg)\n    self.assertEqual(err_msg, expected_err_msg)", "successors": [{"id": 13, "label": "    self.assertEqual(err_msgs, [])\n    self.assertEqual(err_msg, expected_err_msg)", "successors": [{"id": 15, "label": "    self.assertEqual(err_msgs, [])\n    self.assertEqual(err_msg, expected_err_msg)", "successors": [{"id": 17, "label": "    self.assertEqual(err_msg, expected_err_msg)\n    self.assertEqual(err_msg, expected_err_msg)", "successors": [{"id": 19, "label": "    self.assertEqual(err_msg, expected_err_msg)", "successors": []}]}]}]}]}]}]}]}]}]}]}], "simplified_code": "# -*- coding: utf-8 -*-\n\nimport unittest\n\nfrom validate.format import error_message\nfrom validate.format import get_categories_content\nfrom validate.format import check_alphabetical_order\nfrom validate.format import check_title\nfrom validate.format import check_description, max_description_length\nfrom validate.format import check_auth, auth_keys\nfrom validate.format import check_https, https_keys\nfrom validate.format import check_cors, cors_keys\nfrom validate.format import check_entry\nfrom validate.format import check_file_format, min_entries_per_category, num_segments\n\n\n        self.assertEqual(err_msg, expected_err_msg)", "blocks": [{"id": 1, "label": "import unittest\nfrom validate.format import error_message", "successors": [{"id": 3, "label": "from validate.format import get_categories_content\nfrom validate.format import check_alphabetical_order", "successors": [{"id": 5, "label": "from validate.format import check_title\nfrom validate.format import check_description, max_description_length", "successors": [{"id": 7, "label": "from validate.format import check_auth, auth_keys\nfrom validate.format import check_https, https_keys", "successors": [{"id": 9, "label": "from validate.format import check_cors, cors_keys\nfrom validate.format import check_entry", "successors": [{"id": 11, "label": "from validate.format import check_file_format, min_entries_per_category, num_segments\nself.assertEqual(err_msg, expected_err_msg)", "successors": []}]}]}]}]}]}]}
{"file_name": "99.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 43, "functions": [], "classes": [{"name": "WordCharacterCountBlock", "type": "class", "start_line": 5, "end_line": 43, "functions": [{"name": "__init__", "type": "function", "start_line": 22, "end_line": 31, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"ab2a782d-22cf-4587-8a70-55b59b3f9f90\",\n            description=\"Counts the number of words and characters in a given text.\",\n            categories={BlockCategory.TEXT},\n            input_schema=WordCharacterCountBlock.Input,\n            output_schema=WordCharacterCountBlock.Output,\n            test_input={\"text\": \"Hello, how are you?\"},\n            test_output=[(\"word_count\", 4), (\"character_count\", 19)],\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"ab2a782d-22cf-4587-8a70-55b59b3f9f90\",\n    description=\"Counts the number of words and characters in a given text.\",\n    categories={BlockCategory.TEXT},\n    input_schema=WordCharacterCountBlock.Input,\n    output_schema=WordCharacterCountBlock.Output,\n    test_input={\"text\": \"Hello, how are you?\"},\n    test_output=[(\"word_count\", 4), (\"character_count\", 19)],\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 33, "end_line": 43, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        try:\n            text = input_data.text\n            word_count = len(text.split())\n            character_count = len(text)\n\n            yield \"word_count\", word_count\n            yield \"character_count\", character_count\n\n        except Exception as e:\n            yield \"error\", str(e)", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\ntry:", "successors": [{"id": 3, "label": "text = input_data.text\nword_count = len(text.split())\ncharacter_count = len(text)\nyield \"word_count\", word_count\nyield \"character_count\", character_count", "successors": []}, {"id": 5, "label": "except Exception as e:\nyield \"error\", str(e)", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 6, "end_line": 11, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        text: str = SchemaField(\n            description=\"Input text to count words and characters\",\n            placeholder=\"Enter your text here\",\n            advanced=False,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    text: str = SchemaField(\n        description=\"Input text to count words and characters\",\n        placeholder=\"Enter your text here\",\n        advanced=False,\n    )", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 13, "end_line": 20, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        word_count: int = SchemaField(description=\"Number of words in the input text\")\n        character_count: int = SchemaField(\n            description=\"Number of characters in the input text\"\n        )\n        error: str = SchemaField(\n            description=\"Error message if the counting operation failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    word_count: int = SchemaField(description=\"Number of words in the input text\")", "successors": [{"id": 3, "label": "    character_count: int = SchemaField(description=\"Number of characters in the input text\")\n    error: str = SchemaField(description=\"Error message if the counting operation failed\")", "successors": []}]}]}], "simplified_code": "class WordCharacterCountBlock(Block):\n        )\n\n        )\n\n        )\n\n            yield \"error\", str(e)", "blocks": [{"id": 1, "label": "class WordCharacterCountBlock(Block):\n    def execute(self, input_text):", "successors": [{"id": 3, "label": "        import re", "successors": [{"id": 4, "label": "        try:\n            word_count = len(re.findall(r\"\\b\\w+\\b\", input_text))", "successors": [{"id": 6, "label": "            character_count = len(input_text)\n            yield \"word_count\", word_count", "successors": [{"id": 8, "label": "            yield \"character_count\", character_count\n        except Exception as e:", "successors": [{"id": 13, "label": "            yield \"error\", str(e)", "successors": []}]}]}]}, {"id": 12, "label": "        except Exception as e:\n            yield \"error\", str(e)", "successors": []}]}]}]}], "simplified_code": "from backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\n\n            yield \"error\", str(e)", "blocks": [{"id": 1, "label": "from backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField", "successors": []}]}
{"file_name": "100.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 67, "functions": [], "classes": [{"name": "JinaChunkingBlock", "type": "class", "start_line": 11, "end_line": 67, "functions": [{"name": "__init__", "type": "function", "start_line": 29, "end_line": 36, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"806fb15e-830f-4796-8692-557d300ff43c\",\n            description=\"Chunks texts using Jina AI's segmentation service\",\n            categories={BlockCategory.AI, BlockCategory.TEXT},\n            input_schema=JinaChunkingBlock.Input,\n            output_schema=JinaChunkingBlock.Output,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"806fb15e-830f-4796-8692-557d300ff43c\",\n    description=\"Chunks texts using Jina AI's segmentation service\",\n    categories={BlockCategory.AI, BlockCategory.TEXT},\n    input_schema=JinaChunkingBlock.Input,\n    output_schema=JinaChunkingBlock.Output,\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 38, "end_line": 67, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: JinaCredentials, **kwargs\n    ) -> BlockOutput:\n        url = \"https://segment.jina.ai/\"\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {credentials.api_key.get_secret_value()}\",\n        }\n\n        all_chunks = []\n        all_tokens = []\n\n        for text in input_data.texts:\n            data = {\n                \"content\": text,\n                \"return_tokens\": str(input_data.return_tokens).lower(),\n                \"return_chunks\": \"true\",\n                \"max_chunk_length\": str(input_data.max_chunk_length),\n            }\n\n            response = requests.post(url, headers=headers, json=data)\n            result = response.json()\n\n            all_chunks.extend(result.get(\"chunks\", []))\n            if input_data.return_tokens:\n                all_tokens.extend(result.get(\"tokens\", []))\n\n        yield \"chunks\", all_chunks\n        if input_data.return_tokens:\n            yield \"tokens\", all_tokens", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: JinaCredentials, **kwargs) -> BlockOutput:\nurl = \"https://segment.jina.ai/\"\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": f\"Bearer {credentials.api_key.get_secret_value()}\",\n}\nall_chunks = []\nall_tokens = []", "successors": [{"id": 3, "label": "for text in input_data.texts:", "successors": [{"id": 4, "label": "data = {\n    \"content\": text,\n    \"return_tokens\": str(input_data.return_tokens).lower(),\n    \"return_chunks\": \"true\",\n    \"max_chunk_length\": str(input_data.max_chunk_length),\n}\nresponse = requests.post(url, headers=headers, json=data)\nresult = response.json()\nall_chunks.extend(result.get(\"chunks\", []))\nif input_data.return_tokens:\n    all_tokens.extend(result.get(\"tokens\", []))", "successors": [{"id": 3, "label": "for text in input_data.texts:", "successors": [{"id": 4, "label": "data = {\n    \"content\": text,\n    \"return_tokens\": str(input_data.return_tokens).lower(),\n    \"return_chunks\": \"true\",\n    \"max_chunk_length\": str(input_data.max_chunk_length),\n}\nresponse = requests.post(url, headers=headers, json=data)\nresult = response.json()\nall_chunks.extend(result.get(\"chunks\", []))\nif input_data.return_tokens:\n    all_tokens.extend(result.get(\"tokens\", []))", "successors": []}]}]}, {"id": 6, "label": "yield \"chunks\", all_chunks\nif input_data.return_tokens:\n    yield \"tokens\", all_tokens", "successors": []}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 12, "end_line": 21, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        texts: list = SchemaField(description=\"List of texts to chunk\")\n\n        credentials: JinaCredentialsInput = JinaCredentialsField()\n        max_chunk_length: int = SchemaField(\n            description=\"Maximum length of each chunk\", default=1000\n        )\n        return_tokens: bool = SchemaField(\n            description=\"Whether to return token information\", default=False\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    texts: list = SchemaField(description=\"List of texts to chunk\")", "successors": [{"id": 3, "label": "    credentials: JinaCredentialsInput = JinaCredentialsField()\n    max_chunk_length: int = SchemaField(\n        description=\"Maximum length of each chunk\", default=1000\n    )", "successors": [{"id": 5, "label": "    return_tokens: bool = SchemaField(\n        description=\"Whether to return token information\", default=False\n    )", "successors": []}]}]}]}, {"name": "Output", "type": "class", "start_line": 23, "end_line": 27, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        chunks: list = SchemaField(description=\"List of chunked texts\")\n        tokens: list = SchemaField(\n            description=\"List of token information for each chunk\", optional=True\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "chunks: list = SchemaField(description=\"List of chunked texts\")", "successors": []}, {"id": 3, "label": "tokens: list = SchemaField(\n    description=\"List of token information for each chunk\", optional=True\n)", "successors": []}]}]}], "simplified_code": "class JinaChunkingBlock(Block):\n        )\n\n        )\n\n        )\n\n            yield \"tokens\", all_tokens", "blocks": [{"id": 1, "label": "class JinaChunkingBlock(Block):\n", "successors": [{"id": 3, "label": "\n", "successors": [{"id": 5, "label": "yield \"tokens\", all_tokens", "successors": []}]}]}]}], "simplified_code": "from backend.blocks.jina._auth import (\n    JinaCredentials,\n    JinaCredentialsField,\n    JinaCredentialsInput,\n)\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\nfrom backend.util.request import requests\n\n\n            yield \"tokens\", all_tokens", "blocks": [{"id": 1, "label": "from backend.blocks.jina._auth import (\n    JinaCredentials,\n    JinaCredentialsField,\n    JinaCredentialsInput,\n)\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema", "successors": [{"id": 3, "label": "from backend.data.model import SchemaField\nfrom backend.util.request import requests", "successors": [{"id": 5, "label": "yield \"tokens\", all_tokens", "successors": []}]}]}]}
{"file_name": "102.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 25, "functions": [], "classes": [{"name": "RemoveDuplicateUrls", "type": "class", "start_line": 6, "end_line": 21, "functions": [{"name": "mapper", "type": "function", "start_line": 8, "end_line": 9, "functions": [], "classes": [], "simplified_code": "    def mapper(self, _, line):\n        yield line, 1", "blocks": [{"id": 1, "label": "def mapper(self, _, line):\n    yield line, 1", "successors": []}]}, {"name": "reducer", "type": "function", "start_line": 11, "end_line": 14, "functions": [], "classes": [], "simplified_code": "    def reducer(self, key, values):\n        total = sum(values)\n        if total == 1:\n            yield key, total", "blocks": [{"id": 1, "label": "def reducer(self, key, values):\ntotal = sum(values)", "successors": [{"id": 3, "label": "if total == 1:\n    yield key, total", "successors": []}]}]}, {"name": "steps", "type": "function", "start_line": 16, "end_line": 21, "functions": [], "classes": [], "simplified_code": "    def steps(self):\n        \"\"\"Run the map and reduce steps.\"\"\"\n        return [\n            self.mr(mapper=self.mapper,\n                    reducer=self.reducer)\n        ]", "blocks": [{"id": 1, "label": "def steps(self):\n\"\"\"Run the map and reduce steps.\"\"\"", "successors": [{"id": 3, "label": "return [\n    self.mr(mapper=self.mapper,\n            reducer=self.reducer)\n]", "successors": []}]}]}], "classes": [], "simplified_code": "class RemoveDuplicateUrls(MRJob):\n\n        yield line, 1\n\n            yield key, total\n\n        ]", "blocks": [{"id": 1, "label": "class RemoveDuplicateUrls(MRJob):", "successors": [{"id": 2, "label": "yield line, 1", "successors": []}, {"id": 3, "label": "yield key, total", "successors": []}]}]}], "simplified_code": "# -*- coding: utf-8 -*-\n\nfrom mrjob.job import MRJob\n\n\n        ]\n\n\nif __name__ == '__main__':\n    RemoveDuplicateUrls.run()", "blocks": [{"id": 1, "label": "from mrjob.job import MRJob\nif __name__ == '__main__':", "successors": [{"id": 3, "label": "    RemoveDuplicateUrls.run()", "successors": []}]}]}
{"file_name": "103.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 309, "functions": [], "classes": [{"name": "IntegrationCredentialsStore", "type": "class", "start_line": 110, "end_line": 309, "functions": [{"name": "__init__", "type": "function", "start_line": 111, "end_line": 114, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        from backend.data.redis import get_redis\n\n        self.locks = RedisKeyedMutex(get_redis())", "blocks": [{"id": 1, "label": "def __init__(self):\nfrom backend.data.redis import get_redis\n\nself.locks = RedisKeyedMutex(get_redis())", "successors": []}]}, {"name": "db_manager", "type": "function", "start_line": 118, "end_line": 122, "functions": [], "classes": [], "simplified_code": "    def db_manager(self) -> \"DatabaseManager\":\n        from backend.executor.database import DatabaseManager\n        from backend.util.service import get_service_client\n\n        return get_service_client(DatabaseManager)", "blocks": [{"id": 1, "label": "from backend.executor.database import DatabaseManager\nfrom backend.util.service import get_service_client", "successors": [{"id": 3, "label": "return get_service_client(DatabaseManager)", "successors": []}]}]}, {"name": "add_creds", "type": "function", "start_line": 124, "end_line": 133, "functions": [], "classes": [], "simplified_code": "    def add_creds(self, user_id: str, credentials: Credentials) -> None:\n        with self.locked_user_integrations(user_id):\n            if self.get_creds_by_id(user_id, credentials.id):\n                raise ValueError(\n                    f\"Can not re-create existing credentials #{credentials.id} \"\n                    f\"for user #{user_id}\"\n                )\n            self._set_user_integration_creds(\n                user_id, [*self.get_all_creds(user_id), credentials]\n            )", "blocks": [{"id": 1, "label": "def add_creds(self, user_id: str, credentials: Credentials) -> None:\nwith self.locked_user_integrations(user_id):", "successors": [{"id": 3, "label": "if self.get_creds_by_id(user_id, credentials.id):", "successors": [{"id": 4, "label": "raise ValueError(f\"Can not re-create existing credentials #{credentials.id} \"\n                    f\"for user #{user_id}\")", "successors": []}, {"id": 5, "label": "self._set_user_integration_creds(\n    user_id, [*self.get_all_creds(user_id), credentials]\n)", "successors": []}]}]}]}, {"name": "get_all_creds", "type": "function", "start_line": 135, "end_line": 158, "functions": [], "classes": [], "simplified_code": "    def get_all_creds(self, user_id: str) -> list[Credentials]:\n        users_credentials = self._get_user_integrations(user_id).credentials\n        all_credentials = users_credentials\n        if settings.secrets.revid_api_key:\n            all_credentials.append(revid_credentials)\n        if settings.secrets.ideogram_api_key:\n            all_credentials.append(ideogram_credentials)\n        if settings.secrets.groq_api_key:\n            all_credentials.append(groq_credentials)\n        if settings.secrets.replicate_api_key:\n            all_credentials.append(replicate_credentials)\n        if settings.secrets.openai_api_key:\n            all_credentials.append(openai_credentials)\n        if settings.secrets.anthropic_api_key:\n            all_credentials.append(anthropic_credentials)\n        if settings.secrets.did_api_key:\n            all_credentials.append(did_credentials)\n        if settings.secrets.jina_api_key:\n            all_credentials.append(jina_credentials)\n        if settings.secrets.unreal_speech_api_key:\n            all_credentials.append(unreal_credentials)\n        if settings.secrets.open_router_api_key:\n            all_credentials.append(open_router_credentials)\n        return all_credentials", "blocks": [{"id": 1, "label": "users_credentials = self._get_user_integrations(user_id).credentials\nall_credentials = users_credentials\nif settings.secrets.revid_api_key:\n    all_credentials.append(revid_credentials)", "successors": [{"id": 3, "label": "if settings.secrets.ideogram_api_key:\n    all_credentials.append(ideogram_credentials)\nif settings.secrets.groq_api_key:\n    all_credentials.append(groq_credentials)", "successors": [{"id": 5, "label": "if settings.secrets.replicate_api_key:\n    all_credentials.append(replicate_credentials)\nif settings.secrets.openai_api_key:\n    all_credentials.append(openai_credentials)", "successors": [{"id": 7, "label": "if settings.secrets.anthropic_api_key:\n    all_credentials.append(anthropic_credentials)\nif settings.secrets.did_api_key:\n    all_credentials.append(did_credentials)", "successors": [{"id": 9, "label": "if settings.secrets.jina_api_key:\n    all_credentials.append(jina_credentials)\nif settings.secrets.unreal_speech_api_key:\n    all_credentials.append(unreal_credentials)", "successors": [{"id": 11, "label": "if settings.secrets.open_router_api_key:\n    all_credentials.append(open_router_credentials)\nreturn all_credentials", "successors": []}]}]}]}]}]}]}, {"name": "get_creds_by_id", "type": "function", "start_line": 160, "end_line": 162, "functions": [], "classes": [], "simplified_code": "    def get_creds_by_id(self, user_id: str, credentials_id: str) -> Credentials | None:\n        all_credentials = self.get_all_creds(user_id)\n        return next((c for c in all_credentials if c.id == credentials_id), None)", "blocks": [{"id": 1, "label": "def get_creds_by_id(self, user_id: str, credentials_id: str) -> Credentials | None:\n    all_credentials = self.get_all_creds(user_id)", "successors": [{"id": 3, "label": "    return next((c for c in all_credentials if c.id == credentials_id), None)", "successors": []}]}]}, {"name": "get_creds_by_provider", "type": "function", "start_line": 164, "end_line": 166, "functions": [], "classes": [], "simplified_code": "    def get_creds_by_provider(self, user_id: str, provider: str) -> list[Credentials]:\n        credentials = self.get_all_creds(user_id)\n        return [c for c in credentials if c.provider == provider]", "blocks": [{"id": 1, "label": "def get_creds_by_provider(self, user_id: str, provider: str) -> list[Credentials]:\n    credentials = self.get_all_creds(user_id)", "successors": [{"id": 3, "label": "    return [c for c in credentials if c.provider == provider]", "successors": []}]}]}, {"name": "get_authorized_providers", "type": "function", "start_line": 168, "end_line": 170, "functions": [], "classes": [], "simplified_code": "    def get_authorized_providers(self, user_id: str) -> list[str]:\n        credentials = self.get_all_creds(user_id)\n        return list(set(c.provider for c in credentials))", "blocks": [{"id": 1, "label": "def get_authorized_providers(self, user_id: str) -> list[str]:\n    credentials = self.get_all_creds(user_id)", "successors": [{"id": 3, "label": "    return list(set(c.provider for c in credentials))", "successors": []}]}]}, {"name": "update_creds", "type": "function", "start_line": 172, "end_line": 204, "functions": [], "classes": [], "simplified_code": "    def update_creds(self, user_id: str, updated: Credentials) -> None:\n        with self.locked_user_integrations(user_id):\n            current = self.get_creds_by_id(user_id, updated.id)\n            if not current:\n                raise ValueError(\n                    f\"Credentials with ID {updated.id} \"\n                    f\"for user with ID {user_id} not found\"\n                )\n            if type(current) is not type(updated):\n                raise TypeError(\n                    f\"Can not update credentials with ID {updated.id} \"\n                    f\"from type {type(current)} \"\n                    f\"to type {type(updated)}\"\n                )\n\n            # Ensure no scopes are removed when updating credentials\n            if (\n                isinstance(updated, OAuth2Credentials)\n                and isinstance(current, OAuth2Credentials)\n                and not set(updated.scopes).issuperset(current.scopes)\n            ):\n                raise ValueError(\n                    f\"Can not update credentials with ID {updated.id} \"\n                    f\"and scopes {current.scopes} \"\n                    f\"to more restrictive set of scopes {updated.scopes}\"\n                )\n\n            # Update the credentials\n            updated_credentials_list = [\n                updated if c.id == updated.id else c\n                for c in self.get_all_creds(user_id)\n            ]\n            self._set_user_integration_creds(user_id, updated_credentials_list)", "blocks": [{"id": 1, "label": "def update_creds(self, user_id: str, updated: Credentials) -> None:\nwith self.locked_user_integrations(user_id):", "successors": [{"id": 3, "label": "current = self.get_creds_by_id(user_id, updated.id)", "successors": [{"id": 4, "label": "if not current:\nraise ValueError(    f\"Credentials with ID {updated.id} \"    f\"for user with ID {user_id} not found\")", "successors": []}, {"id": 6, "label": "if type(current) is not type(updated):\nraise TypeError(    f\"Can not update credentials with ID {updated.id} \"    f\"from type {type(current)} \"    f\"to type {type(updated)}\")", "successors": []}, {"id": 8, "label": "if (    isinstance(updated, OAuth2Credentials)    and isinstance(current, OAuth2Credentials)    and not set(updated.scopes).issuperset(current.scopes)):\nraise ValueError(    f\"Can not update credentials with ID {updated.id} \"    f\"and scopes {current.scopes} \"    f\"to more restrictive set of scopes {updated.scopes}\")", "successors": []}, {"id": 10, "label": "updated_credentials_list = [    updated if c.id == updated.id else c    for c in self.get_all_creds(user_id)]\nself._set_user_integration_creds(user_id, updated_credentials_list)", "successors": []}]}]}]}, {"name": "delete_creds_by_id", "type": "function", "start_line": 206, "end_line": 211, "functions": [], "classes": [], "simplified_code": "    def delete_creds_by_id(self, user_id: str, credentials_id: str) -> None:\n        with self.locked_user_integrations(user_id):\n            filtered_credentials = [\n                c for c in self.get_all_creds(user_id) if c.id != credentials_id\n            ]\n            self._set_user_integration_creds(user_id, filtered_credentials)", "blocks": [{"id": 1, "label": "with self.locked_user_integrations(user_id):\n    filtered_credentials = [\n        c for c in self.get_all_creds(user_id) if c.id != credentials_id\n    ]", "successors": [{"id": 3, "label": "    self._set_user_integration_creds(user_id, filtered_credentials)", "successors": []}]}]}, {"name": "store_state_token", "type": "function", "start_line": 213, "end_line": 234, "functions": [], "classes": [], "simplified_code": "    def store_state_token(self, user_id: str, provider: str, scopes: list[str]) -> str:\n        token = secrets.token_urlsafe(32)\n        expires_at = datetime.now(timezone.utc) + timedelta(minutes=10)\n\n        state = OAuthState(\n            token=token,\n            provider=provider,\n            expires_at=int(expires_at.timestamp()),\n            scopes=scopes,\n        )\n\n        with self.locked_user_integrations(user_id):\n            user_integrations = self._get_user_integrations(user_id)\n            oauth_states = user_integrations.oauth_states\n            oauth_states.append(state)\n            user_integrations.oauth_states = oauth_states\n\n            self.db_manager.update_user_integrations(\n                user_id=user_id, data=user_integrations\n            )\n\n        return token", "blocks": [{"id": 1, "label": "def store_state_token(self, user_id: str, provider: str, scopes: list[str]) -> str:\ntoken = secrets.token_urlsafe(32)\nexpires_at = datetime.now(timezone.utc) + timedelta(minutes=10)\n\nstate = OAuthState(\n    token=token,\n    provider=provider,\n    expires_at=int(expires_at.timestamp()),\n    scopes=scopes,\n)", "successors": [{"id": 3, "label": "with self.locked_user_integrations(user_id):\nuser_integrations = self._get_user_integrations(user_id)\noauth_states = user_integrations.oauth_states\noauth_states.append(state)\nuser_integrations.oauth_states = oauth_states\n\nself.db_manager.update_user_integrations(\n    user_id=user_id, data=user_integrations\n)", "successors": [{"id": 5, "label": "return token", "successors": []}]}]}]}, {"name": "get_any_valid_scopes_from_state_token", "type": "function", "start_line": 236, "end_line": 264, "functions": [], "classes": [], "simplified_code": "    def get_any_valid_scopes_from_state_token(\n        self, user_id: str, token: str, provider: str\n    ) -> list[str]:\n        \"\"\"\n        Get the valid scopes from the OAuth state token. This will return any valid scopes\n        from any OAuth state token for the given provider. If no valid scopes are found,\n        an empty list is returned. DO NOT RELY ON THIS TOKEN TO AUTHENTICATE A USER, AS IT\n        IS TO CHECK IF THE USER HAS GIVEN PERMISSIONS TO THE APPLICATION BEFORE EXCHANGING\n        THE CODE FOR TOKENS.\n        \"\"\"\n        user_integrations = self._get_user_integrations(user_id)\n        oauth_states = user_integrations.oauth_states\n\n        now = datetime.now(timezone.utc)\n        valid_state = next(\n            (\n                state\n                for state in oauth_states\n                if state.token == token\n                and state.provider == provider\n                and state.expires_at > now.timestamp()\n            ),\n            None,\n        )\n\n        if valid_state:\n            return valid_state.scopes\n\n        return []", "blocks": [{"id": 1, "label": "user_integrations = self._get_user_integrations(user_id)\noauth_states = user_integrations.oauth_states\n\nnow = datetime.now(timezone.utc)\nvalid_state = next(\n    (\n        state\n        for state in oauth_states\n        if state.token == token\n        and state.provider == provider\n        and state.expires_at > now.timestamp()\n    ),\n    None,\n)", "successors": [{"id": 2, "label": "if valid_state:\n    return valid_state.scopes", "successors": []}, {"id": 4, "label": "return []", "successors": []}]}]}, {"name": "verify_state_token", "type": "function", "start_line": 266, "end_line": 290, "functions": [], "classes": [], "simplified_code": "    def verify_state_token(self, user_id: str, token: str, provider: str) -> bool:\n        with self.locked_user_integrations(user_id):\n            user_integrations = self._get_user_integrations(user_id)\n            oauth_states = user_integrations.oauth_states\n\n            now = datetime.now(timezone.utc)\n            valid_state = next(\n                (\n                    state\n                    for state in oauth_states\n                    if state.token == token\n                    and state.provider == provider\n                    and state.expires_at > now.timestamp()\n                ),\n                None,\n            )\n\n            if valid_state:\n                # Remove the used state\n                oauth_states.remove(valid_state)\n                user_integrations.oauth_states = oauth_states\n                self.db_manager.update_user_integrations(user_id, user_integrations)\n                return True\n\n        return False", "blocks": [{"id": 1, "label": "def verify_state_token(self, user_id: str, token: str, provider: str) -> bool:\nwith self.locked_user_integrations(user_id):", "successors": [{"id": 3, "label": "user_integrations = self._get_user_integrations(user_id)\noauth_states = user_integrations.oauth_states\n\nnow = datetime.now(timezone.utc)\nvalid_state = next(\n    (\n        state\n        for state in oauth_states\n        if state.token == token\n        and state.provider == provider\n        and state.expires_at > now.timestamp()\n    ),\n    None,\n)", "successors": [{"id": 4, "label": "if valid_state:\noauth_states.remove(valid_state)\nuser_integrations.oauth_states = oauth_states\nself.db_manager.update_user_integrations(user_id, user_integrations)\nreturn True", "successors": []}, {"id": 6, "label": "return False", "successors": []}]}]}]}, {"name": "_set_user_integration_creds", "type": "function", "start_line": 292, "end_line": 299, "functions": [], "classes": [], "simplified_code": "    def _set_user_integration_creds(\n        self, user_id: str, credentials: list[Credentials]\n    ) -> None:\n        integrations = self._get_user_integrations(user_id)\n        # Remove default credentials from the list\n        credentials = [c for c in credentials if c not in DEFAULT_CREDENTIALS]\n        integrations.credentials = credentials\n        self.db_manager.update_user_integrations(user_id, integrations)", "blocks": [{"id": 1, "label": "def _set_user_integration_creds(self, user_id: str, credentials: list[Credentials]) -> None:\nintegrations = self._get_user_integrations(user_id)", "successors": [{"id": 3, "label": "credentials = [c for c in credentials if c not in DEFAULT_CREDENTIALS]\nintegrations.credentials = credentials", "successors": [{"id": 5, "label": "self.db_manager.update_user_integrations(user_id, integrations)", "successors": []}]}]}]}, {"name": "_get_user_integrations", "type": "function", "start_line": 301, "end_line": 305, "functions": [], "classes": [], "simplified_code": "    def _get_user_integrations(self, user_id: str) -> UserIntegrations:\n        integrations: UserIntegrations = self.db_manager.get_user_integrations(\n            user_id=user_id\n        )\n        return integrations", "blocks": [{"id": 1, "label": "def _get_user_integrations(self, user_id: str) -> UserIntegrations:\nintegrations: UserIntegrations = self.db_manager.get_user_integrations(user_id=user_id)", "successors": [{"id": 3, "label": "return integrations", "successors": []}]}]}, {"name": "locked_user_integrations", "type": "function", "start_line": 307, "end_line": 309, "functions": [], "classes": [], "simplified_code": "    def locked_user_integrations(self, user_id: str):\n        key = (f\"user:{user_id}\", \"integrations\")\n        return self.locks.locked(key)", "blocks": [{"id": 1, "label": "def locked_user_integrations(self, user_id: str):\nkey = (f\"user:{user_id}\", \"integrations\")", "successors": [{"id": 3, "label": "return self.locks.locked(key)", "successors": []}]}]}], "simplified_code": "class IntegrationCredentialsStore:\n        self.locks = RedisKeyedMutex(get_redis())\n\n    @property\n    @thread_cached\n        return get_service_client(DatabaseManager)\n\n            )\n\n        return all_credentials\n\n        return next((c for c in all_credentials if c.id == credentials_id), None)\n\n        return [c for c in credentials if c.provider == provider]\n\n        return list(set(c.provider for c in credentials))\n\n            self._set_user_integration_creds(user_id, updated_credentials_list)\n\n            self._set_user_integration_creds(user_id, filtered_credentials)\n\n        return token\n\n        return []\n\n        return False\n\n        self.db_manager.update_user_integrations(user_id, integrations)\n\n        return integrations\n\n        return self.locks.locked(key)", "blocks": [{"id": 1, "label": "class IntegrationCredentialsStore:\nself.locks = RedisKeyedMutex(get_redis())", "successors": []}]}], "simplified_code": "import secrets\nfrom datetime import datetime, timedelta, timezone\nfrom typing import TYPE_CHECKING\n\nfrom pydantic import SecretStr\n\nif TYPE_CHECKING:\n    from backend.executor.database import DatabaseManager\n\nfrom autogpt_libs.utils.cache import thread_cached\nfrom autogpt_libs.utils.synchronize import RedisKeyedMutex\n\nfrom backend.data.model import (\n    APIKeyCredentials,\n    Credentials,\n    OAuth2Credentials,\n    OAuthState,\n    UserIntegrations,\n)\nfrom backend.util.settings import Settings\n\nsettings = Settings()\n\nrevid_credentials = APIKeyCredentials(\n    id=\"fdb7f412-f519-48d1-9b5f-d2f73d0e01fe\",\n    provider=\"revid\",\n    api_key=SecretStr(settings.secrets.revid_api_key),\n    title=\"Use Credits for Revid\",\n    expires_at=None,\n)\nideogram_credentials = APIKeyCredentials(\n    id=\"760f84fc-b270-42de-91f6-08efe1b512d0\",\n    provider=\"ideogram\",\n    api_key=SecretStr(settings.secrets.ideogram_api_key),\n    title=\"Use Credits for Ideogram\",\n    expires_at=None,\n)\nreplicate_credentials = APIKeyCredentials(\n    id=\"6b9fc200-4726-4973-86c9-cd526f5ce5db\",\n    provider=\"replicate\",\n    api_key=SecretStr(settings.secrets.replicate_api_key),\n    title=\"Use Credits for Replicate\",\n    expires_at=None,\n)\nopenai_credentials = APIKeyCredentials(\n    id=\"53c25cb8-e3ee-465c-a4d1-e75a4c899c2a\",\n    provider=\"openai\",\n    api_key=SecretStr(settings.secrets.openai_api_key),\n    title=\"Use Credits for OpenAI\",\n    expires_at=None,\n)\nanthropic_credentials = APIKeyCredentials(\n    id=\"24e5d942-d9e3-4798-8151-90143ee55629\",\n    provider=\"anthropic\",\n    api_key=SecretStr(settings.secrets.anthropic_api_key),\n    title=\"Use Credits for Anthropic\",\n    expires_at=None,\n)\ngroq_credentials = APIKeyCredentials(\n    id=\"4ec22295-8f97-4dd1-b42b-2c6957a02545\",\n    provider=\"groq\",\n    api_key=SecretStr(settings.secrets.groq_api_key),\n    title=\"Use Credits for Groq\",\n    expires_at=None,\n)\ndid_credentials = APIKeyCredentials(\n    id=\"7f7b0654-c36b-4565-8fa7-9a52575dfae2\",\n    provider=\"d_id\",\n    api_key=SecretStr(settings.secrets.did_api_key),\n    title=\"Use Credits for D-ID\",\n    expires_at=None,\n)\njina_credentials = APIKeyCredentials(\n    id=\"7f26de70-ba0d-494e-ba76-238e65e7b45f\",\n    provider=\"jina\",\n    api_key=SecretStr(settings.secrets.jina_api_key),\n    title=\"Use Credits for Jina\",\n    expires_at=None,\n)\nunreal_credentials = APIKeyCredentials(\n    id=\"66f20754-1b81-48e4-91d0-f4f0dd82145f\",\n    provider=\"unreal\",\n    api_key=SecretStr(settings.secrets.unreal_speech_api_key),\n    title=\"Use Credits for Unreal\",\n    expires_at=None,\n)\nopen_router_credentials = APIKeyCredentials(\n    id=\"b5a0e27d-0c98-4df3-a4b9-10193e1f3c40\",\n    provider=\"open_router\",\n    api_key=SecretStr(settings.secrets.open_router_api_key),\n    title=\"Use Credits for Open Router\",\n    expires_at=None,\n)\n\n\nDEFAULT_CREDENTIALS = [\n    revid_credentials,\n    ideogram_credentials,\n    replicate_credentials,\n    openai_credentials,\n    anthropic_credentials,\n    groq_credentials,\n    did_credentials,\n    jina_credentials,\n    unreal_credentials,\n    open_router_credentials,\n]\n\n\n        return self.locks.locked(key)", "blocks": [{"id": 1, "label": "import secrets\nfrom datetime import datetime, timedelta, timezone\nfrom typing import TYPE_CHECKING\n\nfrom pydantic import SecretStr\n\nif TYPE_CHECKING:\n    from backend.executor.database import DatabaseManager\n\nfrom autogpt_libs.utils.cache import thread_cached\nfrom autogpt_libs.utils.synchronize import RedisKeyedMutex\n\nfrom backend.data.model import (\n    APIKeyCredentials,\n    Credentials,\n    OAuth2Credentials,\n    OAuthState,\n    UserIntegrations,\n)\nfrom backend.util.settings import Settings\n\nsettings = Settings()\n\nrevid_credentials = APIKeyCredentials(\n    id=\"fdb7f412-f519-48d1-9b5f-d2f73d0e01fe\",\n    provider=\"revid\",\n    api_key=SecretStr(settings.secrets.revid_api_key),\n    title=\"Use Credits for Revid\",\n    expires_at=None,\n)\nideogram_credentials = APIKeyCredentials(\n    id=\"760f84fc-b270-42de-91f6-08efe1b512d0\",\n    provider=\"ideogram\",\n    api_key=SecretStr(settings.secrets.ideogram_api_key),\n    title=\"Use Credits for Ideogram\",\n    expires_at=None,\n)\nreplicate_credentials = APIKeyCredentials(\n    id=\"6b9fc200-4726-4973-86c9-cd526f5ce5db\",\n    provider=\"replicate\",\n    api_key=SecretStr(settings.secrets.replicate_api_key),\n    title=\"Use Credits for Replicate\",\n    expires_at=None,\n)\nopenai_credentials = APIKeyCredentials(\n    id=\"53c25cb8-e3ee-465c-a4d1-e75a4c899c2a\",\n    provider=\"openai\",\n    api_key=SecretStr(settings.secrets.openai_api_key),\n    title=\"Use Credits for OpenAI\",\n    expires_at=None,\n)\nanthropic_credentials = APIKeyCredentials(\n    id=\"24e5d942-d9e3-4798-8151-90143ee55629\",\n    provider=\"anthropic\",\n    api_key=SecretStr(settings.secrets.anthropic_api_key),\n    title=\"Use Credits for Anthropic\",\n    expires_at=None,\n)\ngroq_credentials = APIKeyCredentials(\n    id=\"4ec22295-8f97-4dd1-b42b-2c6957a02545\",\n    provider=\"groq\",\n    api_key=SecretStr(settings.secrets.groq_api_key),\n    title=\"Use Credits for Groq\",\n    expires_at=None,\n)\ndid_credentials = APIKeyCredentials(\n    id=\"7f7b0654-c36b-4565-8fa7-9a52575dfae2\",\n    provider=\"d_id\",\n    api_key=SecretStr(settings.secrets.did_api_key),\n    title=\"Use Credits for D-ID\",\n    expires_at=None,\n)\njina_credentials = APIKeyCredentials(\n    id=\"7f26de70-ba0d-494e-ba76-238e65e7b45f\",\n    provider=\"jina\",\n    api_key=SecretStr(settings.secrets.jina_api_key),\n    title=\"Use Credits for Jina\",\n    expires_at=None,\n)\nunreal_credentials = APIKeyCredentials(\n    id=\"66f20754-1b81-48e4-91d0-f4f0dd82145f\",\n    provider=\"unreal\",\n    api_key=SecretStr(settings.secrets.unreal_speech_api_key),\n    title=\"Use Credits for Unreal\",\n    expires_at=None,\n)\nopen_router_credentials = APIKeyCredentials(\n    id=\"b5a0e27d-0c98-4df3-a4b9-10193e1f3c40\",\n    provider=\"open_router\",\n    api_key=SecretStr(settings.secrets.open_router_api_key),\n    title=\"Use Credits for Open Router\",\n    expires_at=None,\n)\n\n\nDEFAULT_CREDENTIALS = [\n    revid_credentials,\n    ideogram_credentials,\n    replicate_credentials,\n    openai_credentials,\n    anthropic_credentials,\n    groq_credentials,\n    did_credentials,\n    jina_credentials,\n    unreal_credentials,\n    open_router_credentials,\n]\n\n\n        return self.locks.locked(key)", "successors": []}]}
{"file_name": "104.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 725, "functions": [{"name": "delete_agent", "type": "function", "start_line": 59, "end_line": 80, "functions": [], "classes": [], "simplified_code": "async def delete_agent(agent_id: str) -> prisma.models.Agents | None:\n    \"\"\"\n    Delete an agent from the database.\n\n    Args:\n        agent_id (str): The ID of the agent to delete.\n\n    Returns:\n        prisma.models.Agents | None: The deleted agent if found, None otherwise.\n\n    Raises:\n        AgentQueryError: If there is an error deleting the agent from the database.\n    \"\"\"\n    try:\n        deleted_agent = await prisma.models.Agents.prisma().delete(\n            where={\"id\": agent_id}\n        )\n        return deleted_agent\n    except prisma.errors.PrismaError as e:\n        raise AgentQueryError(f\"Database query failed: {str(e)}\")\n    except Exception as e:\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "blocks": [{"id": 1, "label": "async def delete_agent(agent_id: str) -> prisma.models.Agents | None:\n    try:", "successors": [{"id": 3, "label": "        deleted_agent = await prisma.models.Agents.prisma().delete(where={\"id\": agent_id})\n        return deleted_agent", "successors": []}, {"id": 5, "label": "    except prisma.errors.PrismaError as e:\n        raise AgentQueryError(f\"Database query failed: {str(e)}\")", "successors": []}, {"id": 7, "label": "    except Exception as e:\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "successors": []}]}]}, {"name": "create_agent_entry", "type": "function", "start_line": 83, "end_line": 128, "functions": [], "classes": [], "simplified_code": "async def create_agent_entry(\n    name: str,\n    description: str,\n    author: str,\n    keywords: typing.List[str],\n    categories: typing.List[str],\n    graph: prisma.Json,\n    submission_state: prisma.enums.SubmissionStatus = prisma.enums.SubmissionStatus.PENDING,\n):\n    \"\"\"\n    Create a new agent entry in the database.\n\n    Args:\n        name (str): The name of the agent.\n        description (str): The description of the agent.\n        author (str): The author of the agent.\n        keywords (List[str]): The keywords associated with the agent.\n        categories (List[str]): The categories associated with the agent.\n        graph (dict): The graph data of the agent.\n\n    Returns:\n        dict: The newly created agent entry.\n\n    Raises:\n        AgentQueryError: If there is an error creating the agent entry.\n    \"\"\"\n    try:\n        agent = await prisma.models.Agents.prisma().create(\n            data={\n                \"name\": name,\n                \"description\": description,\n                \"author\": author,\n                \"keywords\": keywords,\n                \"categories\": categories,\n                \"graph\": graph,\n                \"AnalyticsTracker\": {\"create\": {\"downloads\": 0, \"views\": 0}},\n                \"submissionStatus\": submission_state,\n            }\n        )\n\n        return agent\n\n    except prisma.errors.PrismaError as e:\n        raise AgentQueryError(f\"Database query failed: {str(e)}\")\n    except Exception as e:\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "blocks": [{"id": 1, "label": "try:", "successors": [{"id": 2, "label": "    agent = await prisma.models.Agents.prisma().create(\n        data={\n            \"name\": name,\n            \"description\": description,\n            \"author\": author,\n            \"keywords\": keywords,\n            \"categories\": categories,\n            \"graph\": graph,\n            \"AnalyticsTracker\": {\"create\": {\"downloads\": 0, \"views\": 0}},\n            \"submissionStatus\": submission_state,\n        }\n    )\nreturn agent", "successors": []}, {"id": 4, "label": "except prisma.errors.PrismaError as e:\n    raise AgentQueryError(f\"Database query failed: {str(e)}\")", "successors": []}, {"id": 6, "label": "except Exception as e:\n    raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "successors": []}]}]}, {"name": "update_agent_entry", "type": "function", "start_line": 131, "end_line": 161, "functions": [], "classes": [], "simplified_code": "async def update_agent_entry(\n    agent_id: str,\n    version: int,\n    submission_state: prisma.enums.SubmissionStatus,\n    comments: str | None = None,\n) -> prisma.models.Agents | None:\n    \"\"\"\n    Update an existing agent entry in the database.\n\n    Args:\n        agent_id (str): The ID of the agent.\n        version (int): The version of the agent.\n        submission_state (prisma.enums.SubmissionStatus): The submission state of the agent.\n    \"\"\"\n\n    try:\n        agent = await prisma.models.Agents.prisma().update(\n            where={\"id\": agent_id},\n            data={\n                \"version\": version,\n                \"submissionStatus\": submission_state,\n                \"submissionReviewDate\": datetime.datetime.now(datetime.timezone.utc),\n                \"submissionReviewComments\": comments,\n            },\n        )\n\n        return agent\n    except prisma.errors.PrismaError as e:\n        raise AgentQueryError(f\"Agent Update Failed Database query failed: {str(e)}\")\n    except Exception as e:\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "blocks": [{"id": 1, "label": "async def update_agent_entry(\n    agent_id: str,\n    version: int,\n    submission_state: prisma.enums.SubmissionStatus,\n    comments: str | None = None,\n) -> prisma.models.Agents | None:\ntry:", "successors": [{"id": 3, "label": "agent = await prisma.models.Agents.prisma().update(\n    where={\"id\": agent_id},\n    data={\n        \"version\": version,\n        \"submissionStatus\": submission_state,\n        \"submissionReviewDate\": datetime.datetime.now(datetime.timezone.utc),\n        \"submissionReviewComments\": comments,\n    },\n)\n\nreturn agent", "successors": []}, {"id": 4, "label": "except prisma.errors.PrismaError as e:\nraise AgentQueryError(f\"Agent Update Failed Database query failed: {str(e)}\")", "successors": []}, {"id": 6, "label": "except Exception as e:\nraise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "successors": []}]}]}, {"name": "get_agents", "type": "function", "start_line": 164, "end_line": 259, "functions": [], "classes": [], "simplified_code": "async def get_agents(\n    page: int = 1,\n    page_size: int = 10,\n    name: str | None = None,\n    keyword: str | None = None,\n    category: str | None = None,\n    description: str | None = None,\n    description_threshold: int = 60,\n    submission_status: prisma.enums.SubmissionStatus = prisma.enums.SubmissionStatus.APPROVED,\n    sort_by: str = \"createdAt\",\n    sort_order: typing.Literal[\"desc\"] | typing.Literal[\"asc\"] = \"desc\",\n):\n    \"\"\"\n    Retrieve a list of agents from the database based on the provided filters and pagination parameters.\n\n    Args:\n        page (int, optional): The page number to retrieve. Defaults to 1.\n        page_size (int, optional): The number of agents per page. Defaults to 10.\n        name (str, optional): Filter agents by name. Defaults to None.\n        keyword (str, optional): Filter agents by keyword. Defaults to None.\n        category (str, optional): Filter agents by category. Defaults to None.\n        description (str, optional): Filter agents by description. Defaults to None.\n        description_threshold (int, optional): The minimum fuzzy search threshold for the description. Defaults to 60.\n        sort_by (str, optional): The field to sort the agents by. Defaults to \"createdAt\".\n        sort_order (str, optional): The sort order (\"asc\" or \"desc\"). Defaults to \"desc\".\n\n    Returns:\n        dict: A dictionary containing the list of agents, total count, current page number, page size, and total number of pages.\n    \"\"\"\n    try:\n        # Define the base query\n        query = {}\n\n        # Add optional filters\n        if name:\n            query[\"name\"] = {\"contains\": name, \"mode\": \"insensitive\"}\n        if keyword:\n            query[\"keywords\"] = {\"has\": keyword}\n        if category:\n            query[\"categories\"] = {\"has\": category}\n\n        query[\"submissionStatus\"] = submission_status\n\n        # Define sorting\n        order = {sort_by: sort_order}\n\n        # Calculate pagination\n        skip = (page - 1) * page_size\n\n        # Execute the query\n        try:\n            agents = await prisma.models.Agents.prisma().find_many(\n                where=query,  # type: ignore\n                order=order,  # type: ignore\n                skip=skip,\n                take=page_size,\n            )\n        except prisma.errors.PrismaError as e:\n            raise AgentQueryError(f\"Database query failed: {str(e)}\")\n\n        # Apply fuzzy search on description if provided\n        if description:\n            try:\n                filtered_agents = []\n                for agent in agents:\n                    if (\n                        agent.description\n                        and fuzzywuzzy.fuzz.partial_ratio(\n                            description.lower(), agent.description.lower()\n                        )\n                        >= description_threshold\n                    ):\n                        filtered_agents.append(agent)\n                agents = filtered_agents\n            except AttributeError as e:\n                raise AgentQueryError(f\"Error during fuzzy search: {str(e)}\")\n\n        # Get total count for pagination info\n        total_count = len(agents)\n\n        return {\n            \"agents\": agents,\n            \"total_count\": total_count,\n            \"page\": page,\n            \"page_size\": page_size,\n            \"total_pages\": (total_count + page_size - 1) // page_size,\n        }\n\n    except AgentQueryError as e:\n        # Log the error or handle it as needed\n        raise e\n    except ValueError as e:\n        raise AgentQueryError(f\"Invalid input parameter: {str(e)}\")\n    except Exception as e:\n        # Catch any other unexpected exceptions\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "blocks": [{"id": 1, "label": "async def get_agents(...)", "successors": [{"id": 2, "label": "try:\nquery = {}", "successors": [{"id": 4, "label": "if name:", "successors": [{"id": 5, "label": "query[\"name\"] = {\"contains\": name, \"mode\": \"insensitive\"}", "successors": []}, {"id": 6, "label": "if keyword:", "successors": [{"id": 7, "label": "query[\"keywords\"] = {\"has\": keyword}", "successors": []}, {"id": 8, "label": "if category:", "successors": [{"id": 9, "label": "query[\"categories\"] = {\"has\": category}", "successors": []}, {"id": 10, "label": "query[\"submissionStatus\"] = submission_status\norder = {sort_by: sort_order}", "successors": [{"id": 12, "label": "skip = (page - 1) * page_size", "successors": [{"id": 13, "label": "try:\nagents = await prisma.models.Agents.prisma().find_many(...)", "successors": []}, {"id": 15, "label": "except prisma.errors.PrismaError as e:\nraise AgentQueryError(f\"Database query failed: {str(e)}\")", "successors": []}, {"id": 17, "label": "if description:", "successors": [{"id": 18, "label": "try:\nfiltered_agents = []", "successors": [{"id": 20, "label": "for agent in agents:", "successors": [{"id": 21, "label": "if (...) >= description_threshold:\nfiltered_agents.append(agent)", "successors": []}]}, {"id": 23, "label": "agents = filtered_agents", "successors": []}]}, {"id": 24, "label": "except AttributeError as e:\nraise AgentQueryError(f\"Error during fuzzy search: {str(e)}\")", "successors": []}]}, {"id": 26, "label": "total_count = len(agents)\nreturn {...}", "successors": []}]}]}]}]}]}]}, {"id": 28, "label": "except AgentQueryError as e:\nraise e", "successors": []}, {"id": 30, "label": "except ValueError as e:\nraise AgentQueryError(f\"Invalid input parameter: {str(e)}\")", "successors": []}, {"id": 32, "label": "except Exception as e:\nraise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "successors": []}]}]}, {"name": "get_agent_details", "type": "function", "start_line": 262, "end_line": 291, "functions": [], "classes": [], "simplified_code": "async def get_agent_details(agent_id: str, version: int | None = None):\n    \"\"\"\n    Retrieve agent details from the database.\n\n    Args:\n        agent_id (str): The ID of the agent.\n        version (int | None, optional): The version of the agent. Defaults to None.\n\n    Returns:\n        dict: The agent details.\n\n    Raises:\n        AgentQueryError: If the agent is not found or if there is an error querying the database.\n    \"\"\"\n    try:\n        query = {\"id\": agent_id}\n        if version is not None:\n            query[\"version\"] = version  # type: ignore\n\n        agent = await prisma.models.Agents.prisma().find_first(where=query)  # type: ignore\n\n        if not agent:\n            raise AgentQueryError(\"Agent not found\")\n\n        return agent\n\n    except prisma.errors.PrismaError as e:\n        raise AgentQueryError(f\"Database query failed: {str(e)}\")\n    except Exception as e:\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "blocks": [{"id": 1, "label": "try:\nquery = {\"id\": agent_id}", "successors": [{"id": 3, "label": "if version is not None:\n    query[\"version\"] = version  # type: ignore", "successors": [{"id": 5, "label": "agent = await prisma.models.Agents.prisma().find_first(where=query)  # type: ignore\nif not agent:", "successors": [{"id": 7, "label": "    raise AgentQueryError(\"Agent not found\")", "successors": []}, {"id": 8, "label": "return agent", "successors": []}]}]}]}]}, {"name": "search_db", "type": "function", "start_line": 294, "end_line": 407, "functions": [], "classes": [{"name": "CountResponse", "type": "class", "start_line": 377, "end_line": 378, "functions": [], "classes": [], "simplified_code": "        class CountResponse(pydantic.BaseModel):\n            count: int", "blocks": [{"id": 1, "label": "class CountResponse(pydantic.BaseModel):\n count: int", "successors": []}]}], "simplified_code": "async def search_db(\n    query: str,\n    page: int = 1,\n    page_size: int = 10,\n    categories: typing.List[str] | None = None,\n    description_threshold: int = 60,\n    sort_by: str = \"rank\",\n    sort_order: typing.Literal[\"desc\"] | typing.Literal[\"asc\"] = \"desc\",\n    submission_status: prisma.enums.SubmissionStatus = prisma.enums.SubmissionStatus.APPROVED,\n) -> market.model.ListResponse[market.utils.extension_types.AgentsWithRank]:\n    \"\"\"Perform a search for agents based on the provided query string.\n\n    Args:\n        query (str): the search string\n        page (int, optional): page for searching. Defaults to 1.\n        page_size (int, optional): the number of results to return. Defaults to 10.\n        categories (List[str] | None, optional): list of category filters. Defaults to None.\n        description_threshold (int, optional): number of characters to return. Defaults to 60.\n        sort_by (str, optional): sort by option. Defaults to \"rank\".\n        sort_order (\"asc\" | \"desc\", optional): the sort order. Defaults to \"desc\".\n\n    Raises:\n        AgentQueryError: Raises an error if the query fails.\n        AgentQueryError: Raises if an unexpected error occurs.\n\n    Returns:\n        List[AgentsWithRank]: List of agents matching the search criteria.\n    \"\"\"\n    try:\n        offset = (page - 1) * page_size\n\n        category_filter = \"1=1\"\n        if categories:\n            category_conditions = [f\"'{cat}' = ANY(categories)\" for cat in categories]\n            category_filter = \"AND (\" + \" OR \".join(category_conditions) + \")\"\n\n        # Construct the ORDER BY clause based on the sort_by parameter\n        if sort_by in [\"createdAt\", \"updatedAt\"]:\n            order_by_clause = f'\"{sort_by}\" {sort_order.upper()}, rank DESC'\n        elif sort_by == \"name\":\n            order_by_clause = f\"name {sort_order.upper()}, rank DESC\"\n        else:\n            order_by_clause = 'rank DESC, \"createdAt\" DESC'\n\n        submission_status_filter = f\"\"\"\"submissionStatus\" = '{submission_status}'\"\"\"\n\n        sql_query = f\"\"\"\n        WITH query AS (\n            SELECT to_tsquery(string_agg(lexeme || ':*', ' & ' ORDER BY positions)) AS q \n            FROM unnest(to_tsvector('{query}'))\n        )\n        SELECT \n            id, \n            \"createdAt\", \n            \"updatedAt\", \n            version, \n            name, \n            LEFT(description, {description_threshold}) AS description, \n            author, \n            keywords, \n            categories, \n            graph,\n            \"submissionStatus\",\n            \"submissionDate\",\n            CASE \n                WHEN query.q::text = '' THEN 1.0\n                ELSE COALESCE(ts_rank(CAST(search AS tsvector), query.q), 0.0)\n            END AS rank\n        FROM market.\"Agents\", query\n        WHERE \n            (query.q::text = '' OR search @@ query.q)\n            AND {category_filter} \n            AND {submission_status_filter}\n        ORDER BY {order_by_clause}\n        LIMIT {page_size}\n        OFFSET {offset};\n        \"\"\"\n\n        results = await prisma.client.get_client().query_raw(\n            query=sql_query,\n            model=market.utils.extension_types.AgentsWithRank,\n        )\n\n            count: int\n\n        count_query = f\"\"\"\n        WITH query AS (\n            SELECT to_tsquery(string_agg(lexeme || ':*', ' & ' ORDER BY positions)) AS q \n            FROM unnest(to_tsvector('{query}'))\n        )\n        SELECT COUNT(*)\n        FROM market.\"Agents\", query\n        WHERE (search @@ query.q OR query.q = '') AND {category_filter} AND {submission_status_filter};\n        \"\"\"\n\n        total_count = await prisma.client.get_client().query_first(\n            query=count_query,\n            model=CountResponse,\n        )\n        total_count = total_count.count if total_count else 0\n\n        return market.model.ListResponse(\n            items=results,\n            total_count=total_count,\n            page=page,\n            page_size=page_size,\n            total_pages=(total_count + page_size - 1) // page_size,\n        )\n\n    except prisma.errors.PrismaError as e:\n        raise AgentQueryError(f\"Database query failed: {str(e)}\")\n    except Exception as e:\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "blocks": [{"id": 1, "label": "try:\noffset = (page - 1) * page_size\n\n        category_filter = \"1=1\"", "successors": [{"id": 3, "label": "if categories:\n    category_conditions = [f\"'{cat}' = ANY(categories)\" for cat in categories]\n    category_filter = \"AND (\" + \" OR \".join(category_conditions) + \")\"", "successors": []}, {"id": 5, "label": "if sort_by in [\"createdAt\", \"updatedAt\"]:\n    order_by_clause = f'\"{sort_by}\" {sort_order.upper()}, rank DESC'", "successors": []}, {"id": 7, "label": "elif sort_by == \"name\":\n    order_by_clause = f\"name {sort_order.upper()}, rank DESC\"", "successors": []}, {"id": 9, "label": "else:\n    order_by_clause = 'rank DESC, \"createdAt\" DESC'", "successors": []}, {"id": 11, "label": "submission_status_filter = f'\"\"submissionStatus\"\" = '{submission_status}''", "successors": []}, {"id": 12, "label": "sql_query = f\"\"\"\n        WITH query AS (\n            SELECT to_tsquery(string_agg(lexeme || ':*', ' & ' ORDER BY positions)) AS q \n            FROM unnest(to_tsvector('{query}'))\n        )\n        SELECT \n            id, \n            \"createdAt\", \n            \"updatedAt\", \n            version, \n            name, \n            LEFT(description, {description_threshold}) AS description, \n            author, \n            keywords, \n            categories, \n            graph,\n            \"submissionStatus\",\n            \"submissionDate\",\n            CASE \n                WHEN query.q::text = '' THEN 1.0\n                ELSE COALESCE(ts_rank(CAST(search AS tsvector), query.q), 0.0)\n            END AS rank\n        FROM market.\"Agents\", query\n        WHERE \n            (query.q::text = '' OR search @@ query.q)\n            AND {category_filter} \n            AND {submission_status_filter}\n        ORDER BY {order_by_clause}\n        LIMIT {page_size}\n        OFFSET {offset};\n        \"\"\"", "successors": []}, {"id": 13, "label": "results = await prisma.client.get_client().query_raw(\n            query=sql_query,\n            model=market.utils.extension_types.AgentsWithRank,\n        )", "successors": [{"id": 14, "label": "count_query = f\"\"\"\n        WITH query AS (\n            SELECT to_tsquery(string_agg(lexeme || ':*', ' & ' ORDER BY positions)) AS q \n            FROM unnest(to_tsvector('{query}'))\n        )\n        SELECT COUNT(*)\n        FROM market.\"Agents\", query\n        WHERE (search @@ query.q OR query.q = '') AND {category_filter} AND {submission_status_filter};\n        \"\"\"", "successors": []}, {"id": 15, "label": "total_count = await prisma.client.get_client().query_first(\n            query=count_query,\n            model=CountResponse,\n        )\ntotal_count = total_count.count if total_count else 0", "successors": []}, {"id": 16, "label": "return market.model.ListResponse(\n            items=results,\n            total_count=total_count,\n            page=page,\n            page_size=page_size,\n            total_pages=(total_count + page_size - 1) // page_size,\n        )", "successors": []}]}]}]}, {"name": "get_top_agents_by_downloads", "type": "function", "start_line": 410, "end_line": 463, "functions": [], "classes": [], "simplified_code": "async def get_top_agents_by_downloads(\n    page: int = 1,\n    page_size: int = 10,\n    submission_status: prisma.enums.SubmissionStatus = prisma.enums.SubmissionStatus.APPROVED,\n) -> market.model.ListResponse[prisma.models.AnalyticsTracker]:\n    \"\"\"Retrieve the top agents by download count.\n\n    Args:\n        page (int, optional): The page number. Defaults to 1.\n        page_size (int, optional): The number of agents per page. Defaults to 10.\n\n    Returns:\n        dict: A dictionary containing the list of agents, total count, current page number, page size, and total number of pages.\n    \"\"\"\n    try:\n        # Calculate pagination\n        skip = (page - 1) * page_size\n\n        # Execute the query\n        try:\n            # Agents with no downloads will not be included in the results... is this the desired behavior?\n            analytics = await prisma.models.AnalyticsTracker.prisma().find_many(\n                include={\"agent\": True},\n                order={\"downloads\": \"desc\"},\n                where={\"agent\": {\"is\": {\"submissionStatus\": submission_status}}},\n                skip=skip,\n                take=page_size,\n            )\n        except prisma.errors.PrismaError as e:\n            raise AgentQueryError(f\"Database query failed: {str(e)}\")\n\n        try:\n            total_count = await prisma.models.AnalyticsTracker.prisma().count(\n                where={\"agent\": {\"is\": {\"submissionStatus\": submission_status}}},\n            )\n        except prisma.errors.PrismaError as e:\n            raise AgentQueryError(f\"Database query failed: {str(e)}\")\n\n        return market.model.ListResponse(\n            items=analytics,\n            total_count=total_count,\n            page=page,\n            page_size=page_size,\n            total_pages=(total_count + page_size - 1) // page_size,\n        )\n\n    except AgentQueryError as e:\n        # Log the error or handle it as needed\n        raise e from e\n    except ValueError as e:\n        raise AgentQueryError(f\"Invalid input parameter: {str(e)}\") from e\n    except Exception as e:\n        # Catch any other unexpected exceptions\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\") from e", "blocks": [{"id": 1, "label": "async def get_top_agents_by_downloads(\n    page: int = 1,\n    page_size: int = 10,\n    submission_status: prisma.enums.SubmissionStatus = prisma.enums.SubmissionStatus.APPROVED,\n) -> market.model.ListResponse[prisma.models.AnalyticsTracker]:\n    try:", "successors": [{"id": 3, "label": "        skip = (page - 1) * page_size", "successors": [{"id": 4, "label": "        try:\n            analytics = await prisma.models.AnalyticsTracker.prisma().find_many(\n                include={\"agent\": True},\n                order={\"downloads\": \"desc\"},\n                where={\"agent\": {\"is\": {\"submissionStatus\": submission_status}}},\n                skip=skip,\n                take=page_size,\n            )", "successors": [{"id": 8, "label": "        try:\n            total_count = await prisma.models.AnalyticsTracker.prisma().count(\n                where={\"agent\": {\"is\": {\"submissionStatus\": submission_status}}},\n            )", "successors": [{"id": 12, "label": "        return market.model.ListResponse(\n            items=analytics,\n            total_count=total_count,\n            page=page,\n            page_size=page_size,\n            total_pages=(total_count + page_size - 1) // page_size,\n        )", "successors": []}]}, {"id": 10, "label": "        except prisma.errors.PrismaError as e:\n            raise AgentQueryError(f\"Database query failed: {str(e)}\")", "successors": []}]}, {"id": 6, "label": "        except prisma.errors.PrismaError as e:\n            raise AgentQueryError(f\"Database query failed: {str(e)}\")", "successors": []}]}, {"id": 7, "label": "    except AgentQueryError as e:\n        raise e from e", "successors": []}, {"id": 11, "label": "    except ValueError as e:\n        raise AgentQueryError(f\"Invalid input parameter: {str(e)}\") from e", "successors": []}, {"id": 13, "label": "    except Exception as e:\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\") from e", "successors": []}]}]}, {"name": "set_agent_featured", "type": "function", "start_line": 466, "end_line": 502, "functions": [], "classes": [], "simplified_code": "async def set_agent_featured(\n    agent_id: str, is_active: bool = True, featured_categories: list[str] = [\"featured\"]\n) -> prisma.models.FeaturedAgent:\n    \"\"\"Set an agent as featured in the database.\n\n    Args:\n        agent_id (str): The ID of the agent.\n        category (str, optional): The category to set the agent as featured. Defaults to \"featured\".\n\n    Raises:\n        AgentQueryError: If there is an error setting the agent as featured.\n    \"\"\"\n    try:\n        agent = await prisma.models.Agents.prisma().find_unique(where={\"id\": agent_id})\n        if not agent:\n            raise AgentQueryError(f\"Agent with ID {agent_id} not found.\")\n\n        featured = await prisma.models.FeaturedAgent.prisma().upsert(\n            where={\"agentId\": agent_id},\n            data={\n                \"update\": {\n                    \"featuredCategories\": featured_categories,\n                    \"isActive\": is_active,\n                },\n                \"create\": {\n                    \"featuredCategories\": featured_categories,\n                    \"isActive\": is_active,\n                    \"agent\": {\"connect\": {\"id\": agent_id}},\n                },\n            },\n        )\n        return featured\n\n    except prisma.errors.PrismaError as e:\n        raise AgentQueryError(f\"Database query failed: {str(e)}\")\n    except Exception as e:\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "blocks": [{"id": 1, "label": "try:\n    agent = await prisma.models.Agents.prisma().find_unique(where={\"id\": agent_id})", "successors": [{"id": 3, "label": "if not agent:\n    raise AgentQueryError(f\"Agent with ID {agent_id} not found.\")", "successors": []}, {"id": 5, "label": "featured = await prisma.models.FeaturedAgent.prisma().upsert(where={\"agentId\": agent_id}, data={\"update\": {\"featuredCategories\": featured_categories, \"isActive\": is_active}, \"create\": {\"featuredCategories\": featured_categories, \"isActive\": is_active, \"agent\": {\"connect\": {\"id\": agent_id}}}})\nreturn featured", "successors": []}]}]}, {"name": "get_featured_agents", "type": "function", "start_line": 505, "end_line": 558, "functions": [], "classes": [], "simplified_code": "async def get_featured_agents(\n    category: str = \"featured\",\n    page: int = 1,\n    page_size: int = 10,\n    submission_status: prisma.enums.SubmissionStatus = prisma.enums.SubmissionStatus.APPROVED,\n) -> FeaturedAgentResponse:\n    \"\"\"Retrieve a list of featured agents from the database based on the provided category.\n\n    Args:\n        category (str, optional): The category of featured agents to retrieve. Defaults to \"featured\".\n        page (int, optional): The page number to retrieve. Defaults to 1.\n        page_size (int, optional): The number of agents per page. Defaults to 10.\n\n    Returns:\n        dict: A dictionary containing the list of featured agents, total count, current page number, page size, and total number of pages.\n    \"\"\"\n    try:\n        # Calculate pagination\n        skip = (page - 1) * page_size\n\n        # Execute the query\n        try:\n            featured_agents = await prisma.models.FeaturedAgent.prisma().find_many(\n                where={\n                    \"featuredCategories\": {\"has\": category},\n                    \"isActive\": True,\n                    \"agent\": {\"is\": {\"submissionStatus\": submission_status}},\n                },\n                include={\"agent\": {\"include\": {\"AnalyticsTracker\": True}}},\n                skip=skip,\n                take=page_size,\n            )\n        except prisma.errors.PrismaError as e:\n            raise AgentQueryError(f\"Database query failed: {str(e)}\")\n\n        # Get total count for pagination info\n        total_count = len(featured_agents)\n\n        return FeaturedAgentResponse(\n            featured_agents=featured_agents,\n            total_count=total_count,\n            page=page,\n            page_size=page_size,\n            total_pages=(total_count + page_size - 1) // page_size,\n        )\n\n    except AgentQueryError as e:\n        # Log the error or handle it as needed\n        raise e from e\n    except ValueError as e:\n        raise AgentQueryError(f\"Invalid input parameter: {str(e)}\") from e\n    except Exception as e:\n        # Catch any other unexpected exceptions\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\") from e", "blocks": [{"id": 1, "label": "async def get_featured_agents(    category: str = \"featured\",    page: int = 1,    page_size: int = 10,    submission_status: prisma.enums.SubmissionStatus = prisma.enums.SubmissionStatus.APPROVED,) -> FeaturedAgentResponse:\n\"\"\"Retrieve a list of featured agents from the database based on the provided category.\n\n    Args:\n        category (str, optional): The category of featured agents to retrieve. Defaults to \"featured\".\n        page (int, optional): The page number to retrieve. Defaults to 1.\n        page_size (int, optional): The number of agents per page. Defaults to 10.\n\n    Returns:\n        dict: A dictionary containing the list of featured agents, total count, current page number, page size, and total number of pages.\n    \"\"\"\ntry:", "successors": [{"id": 3, "label": "skip = (page - 1) * page_size\ntry:", "successors": [{"id": 5, "label": "featured_agents = await prisma.models.FeaturedAgent.prisma().find_many(    where={\"featuredCategories\": {\"has\": category}, \"isActive\": True, \"agent\": {\"is\": {\"submissionStatus\": submission_status}},},    include={\"agent\": {\"include\": {\"AnalyticsTracker\": True}}},    skip=skip,    take=page_size,)\ntotal_count = len(featured_agents)\n\nreturn FeaturedAgentResponse(    featured_agents=featured_agents,    total_count=total_count,    page=page,    page_size=page_size,    total_pages=(total_count + page_size - 1) // page_size,)", "successors": []}, {"id": 6, "label": "except prisma.errors.PrismaError as e:\n    raise AgentQueryError(f\"Database query failed: {str(e)}\")", "successors": []}]}, {"id": 8, "label": "except AgentQueryError as e:\n    raise e from e", "successors": []}, {"id": 9, "label": "except ValueError as e:\n    raise AgentQueryError(f\"Invalid input parameter: {str(e)}\") from e", "successors": []}, {"id": 10, "label": "except Exception as e:\n    raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\") from e", "successors": []}]}]}, {"name": "remove_featured_category", "type": "function", "start_line": 561, "end_line": 596, "functions": [], "classes": [], "simplified_code": "async def remove_featured_category(\n    agent_id: str, category: str\n) -> prisma.models.FeaturedAgent | None:\n    \"\"\"Adds a featured category to an agent.\n\n    Args:\n        agent_id (str): The ID of the agent.\n        category (str): The category to add to the agent.\n\n    Returns:\n        FeaturedAgentResponse: The updated list of featured agents.\n    \"\"\"\n    try:\n        # get the existing categories\n        featured_agent = await prisma.models.FeaturedAgent.prisma().find_unique(\n            where={\"agentId\": agent_id},\n            include={\"agent\": True},\n        )\n\n        if not featured_agent:\n            raise AgentQueryError(f\"Agent with ID {agent_id} not found.\")\n\n        # remove the category from the list\n        featured_agent.featuredCategories.remove(category)\n\n        featured_agent = await prisma.models.FeaturedAgent.prisma().update(\n            where={\"agentId\": agent_id},\n            data={\"featuredCategories\": featured_agent.featuredCategories},\n        )\n\n        return featured_agent\n\n    except prisma.errors.PrismaError as e:\n        raise AgentQueryError(f\"Database query failed: {str(e)}\")\n    except Exception as e:\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "blocks": [{"id": 1, "label": "async def remove_featured_category(agent_id: str, category: str) -> prisma.models.FeaturedAgent | None:\ntry:", "successors": [{"id": 3, "label": "featured_agent = await prisma.models.FeaturedAgent.prisma().find_unique(where={\"agentId\": agent_id}, include={\"agent\": True})\nif not featured_agent:", "successors": [{"id": 5, "label": "raise AgentQueryError(f\"Agent with ID {agent_id} not found.\")", "successors": []}, {"id": 6, "label": "featured_agent.featuredCategories.remove(category)\nfeatured_agent = await prisma.models.FeaturedAgent.prisma().update(where={\"agentId\": agent_id}, data={\"featuredCategories\": featured_agent.featuredCategories})", "successors": [{"id": 8, "label": "return featured_agent", "successors": []}]}]}, {"id": 9, "label": "except prisma.errors.PrismaError as e:\nraise AgentQueryError(f\"Database query failed: {str(e)}\")", "successors": []}, {"id": 11, "label": "except Exception as e:\nraise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "successors": []}]}]}, {"name": "add_featured_category", "type": "function", "start_line": 599, "end_line": 622, "functions": [], "classes": [], "simplified_code": "async def add_featured_category(\n    agent_id: str, category: str\n) -> prisma.models.FeaturedAgent | None:\n    \"\"\"Removes a featured category from an agent.\n\n    Args:\n        agent_id (str): The ID of the agent.\n        category (str): The category to remove from the agent.\n\n    Returns:\n        FeaturedAgentResponse: The updated list of featured agents.\n    \"\"\"\n    try:\n        featured_agent = await prisma.models.FeaturedAgent.prisma().update(\n            where={\"agentId\": agent_id},\n            data={\"featuredCategories\": {\"push\": [category]}},\n        )\n\n        return featured_agent\n\n    except prisma.errors.PrismaError as e:\n        raise AgentQueryError(f\"Database query failed: {str(e)}\")\n    except Exception as e:\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "blocks": [{"id": 1, "label": "async def add_featured_category(agent_id: str, category: str) -> prisma.models.FeaturedAgent | None:\ntry:", "successors": [{"id": 3, "label": "featured_agent = await prisma.models.FeaturedAgent.prisma().update(where={\"agentId\": agent_id}, data={\"featuredCategories\": {\"push\": [category]}})\nreturn featured_agent", "successors": []}, {"id": 5, "label": "except prisma.errors.PrismaError as e:\nraise AgentQueryError(f\"Database query failed: {str(e)}\")", "successors": []}, {"id": 7, "label": "except Exception as e:\nraise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "successors": []}]}]}, {"name": "get_agent_featured", "type": "function", "start_line": 625, "end_line": 642, "functions": [], "classes": [], "simplified_code": "async def get_agent_featured(agent_id: str) -> prisma.models.FeaturedAgent | None:\n    \"\"\"Retrieve an agent's featured categories from the database.\n\n    Args:\n        agent_id (str): The ID of the agent.\n\n    Returns:\n        FeaturedAgentResponse: The list of featured agents.\n    \"\"\"\n    try:\n        featured_agent = await prisma.models.FeaturedAgent.prisma().find_unique(\n            where={\"agentId\": agent_id},\n        )\n        return featured_agent\n    except prisma.errors.PrismaError as e:\n        raise AgentQueryError(f\"Database query failed: {str(e)}\")\n    except Exception as e:\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "blocks": [{"id": 1, "label": "async def get_agent_featured(agent_id: str) -> prisma.models.FeaturedAgent | None:\ntry:", "successors": [{"id": 3, "label": "featured_agent = await prisma.models.FeaturedAgent.prisma().find_unique(where={\"agentId\": agent_id},)\nreturn featured_agent", "successors": []}, {"id": 4, "label": "except prisma.errors.PrismaError as e:\nraise AgentQueryError(f\"Database query failed: {str(e)}\")", "successors": []}, {"id": 6, "label": "except Exception as e:\nraise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "successors": []}]}]}, {"name": "get_not_featured_agents", "type": "function", "start_line": 645, "end_line": 681, "functions": [], "classes": [], "simplified_code": "async def get_not_featured_agents(\n    page: int = 1, page_size: int = 10\n) -> typing.List[prisma.models.Agents]:\n    \"\"\"\n    Retrieve a list of not featured agents from the database.\n    \"\"\"\n    try:\n        agents = await prisma.client.get_client().query_raw(\n            query=f\"\"\"\n            SELECT \n                \"market\".\"Agents\".id, \n                \"market\".\"Agents\".\"createdAt\", \n                \"market\".\"Agents\".\"updatedAt\", \n                \"market\".\"Agents\".version, \n                \"market\".\"Agents\".name, \n                LEFT(\"market\".\"Agents\".description, 500) AS description, \n                \"market\".\"Agents\".author, \n                \"market\".\"Agents\".keywords, \n                \"market\".\"Agents\".categories, \n                \"market\".\"Agents\".graph,\n                \"market\".\"Agents\".\"submissionStatus\",\n                \"market\".\"Agents\".\"submissionDate\",\n                \"market\".\"Agents\".search::text AS search\n            FROM \"market\".\"Agents\"\n            LEFT JOIN \"market\".\"FeaturedAgent\" ON \"market\".\"Agents\".\"id\" = \"market\".\"FeaturedAgent\".\"agentId\"\n            WHERE (\"market\".\"FeaturedAgent\".\"agentId\" IS NULL OR \"market\".\"FeaturedAgent\".\"featuredCategories\" = '{{}}')\n                AND \"market\".\"Agents\".\"submissionStatus\" = 'APPROVED'\n            ORDER BY \"market\".\"Agents\".\"createdAt\" DESC\n            LIMIT {page_size} OFFSET {page_size * (page - 1)}\n            \"\"\",\n            model=prisma.models.Agents,\n        )\n        return agents\n    except prisma.errors.PrismaError as e:\n        raise AgentQueryError(f\"Database query failed: {str(e)}\")\n    except Exception as e:\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "blocks": [{"id": 1, "label": "async def get_not_featured_agents(\n    page: int = 1, page_size: int = 10\n) -> typing.List[prisma.models.Agents]:\n\"\"\"\n    Retrieve a list of not featured agents from the database.\n    \"\"\"", "successors": [{"id": 3, "label": "try:", "successors": [{"id": 4, "label": "    agents = await prisma.client.get_client().query_raw(\n        query=f\"\"\"\n        SELECT \n            \\\"market\\\".\\\"Agents\\\".id, \n            \\\"market\\\".\\\"Agents\\\".\\\"createdAt\\\", \n            \\\"market\\\".\\\"Agents\\\".\\\"updatedAt\\\", \n            \\\"market\\\".\\\"Agents\\\".version, \n            \\\"market\\\".\\\"Agents\\\".name, \n            LEFT(\\\"market\\\".\\\"Agents\\\".description, 500) AS description, \n            \\\"market\\\".\\\"Agents\\\".author, \n            \\\"market\\\".\\\"Agents\\\".keywords, \n            \\\"market\\\".\\\"Agents\\\".categories, \n            \\\"market\\\".\\\"Agents\\\".graph,\n            \\\"market\\\".\\\"Agents\\\".\\\"submissionStatus\\\",\n            \\\"market\\\".\\\"Agents\\\".\\\"submissionDate\\\",\n            \\\"market\\\".\\\"Agents\\\".search::text AS search\n        FROM \\\"market\\\".\\\"Agents\\\"\n        LEFT JOIN \\\"market\\\".\\\"FeaturedAgent\\\" ON \\\"market\\\".\\\"Agents\\\".\\\"id\\\" = \\\"market\\\".\\\"FeaturedAgent\\\".\\\"agentId\\\"\n        WHERE (\\\"market\\\".\\\"FeaturedAgent\\\".\\\"agentId\\\" IS NULL OR \\\"market\\\".\\\"FeaturedAgent\\\".\\\"featuredCategories\\\" = '{{}}')\n            AND \\\"market\\\".\\\"Agents\\\".\\\"submissionStatus\\\" = 'APPROVED'\n        ORDER BY \\\"market\\\".\\\"Agents\\\".\\\"createdAt\\\" DESC\n        LIMIT {page_size} OFFSET {page_size * (page - 1)}\n        \"\"\",\n        model=prisma.models.Agents,\n    )\nreturn agents", "successors": []}, {"id": 6, "label": "except prisma.errors.PrismaError as e:\n    raise AgentQueryError(f\"Database query failed: {str(e)}\")", "successors": []}, {"id": 8, "label": "except Exception as e:\n    raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "successors": []}]}]}]}, {"name": "get_all_categories", "type": "function", "start_line": 684, "end_line": 706, "functions": [], "classes": [], "simplified_code": "async def get_all_categories() -> market.model.CategoriesResponse:\n    \"\"\"\n    Retrieve all unique categories from the database.\n\n    Returns:\n        CategoriesResponse: A list of unique categories.\n    \"\"\"\n    try:\n        agents = await prisma.models.Agents.prisma().find_many(distinct=[\"categories\"])\n\n        # Aggregate categories on the Python side\n        all_categories = set()\n        for agent in agents:\n            all_categories.update(agent.categories)\n\n        unique_categories = sorted(list(all_categories))\n\n        return market.model.CategoriesResponse(unique_categories=unique_categories)\n    except prisma.errors.PrismaError as e:\n        raise AgentQueryError(f\"Database query failed: {str(e)}\")\n    except Exception:\n        # Return an empty list of categories in case of unexpected errors\n        return market.model.CategoriesResponse(unique_categories=[])", "blocks": [{"id": 1, "label": "async def get_all_categories() -> market.model.CategoriesResponse:\ntry:", "successors": [{"id": 3, "label": "agents = await prisma.models.Agents.prisma().find_many(distinct=[\"categories\"])\n\n# Aggregate categories on the Python side\nall_categories = set()", "successors": [{"id": 4, "label": "for agent in agents:", "successors": [{"id": 5, "label": "all_categories.update(agent.categories)\nunique_categories = sorted(list(all_categories))\n\nreturn market.model.CategoriesResponse(unique_categories=unique_categories)", "successors": []}]}]}, {"id": 7, "label": "except prisma.errors.PrismaError as e:\nraise AgentQueryError(f\"Database query failed: {str(e)}\")", "successors": []}, {"id": 9, "label": "except Exception:\nreturn market.model.CategoriesResponse(unique_categories=[])", "successors": []}]}]}, {"name": "create_agent_installed_event", "type": "function", "start_line": 709, "end_line": 725, "functions": [], "classes": [], "simplified_code": "async def create_agent_installed_event(\n    event_data: market.model.AgentInstalledFromMarketplaceEventData,\n):\n    try:\n        await prisma.models.InstallTracker.prisma().create(\n            data={\n                \"installedAgentId\": event_data.installed_agent_id,\n                \"marketplaceAgentId\": event_data.marketplace_agent_id,\n                \"installationLocation\": prisma.enums.InstallationLocation(\n                    event_data.installation_location.name\n                ),\n            }\n        )\n    except prisma.errors.PrismaError as e:\n        raise AgentQueryError(f\"Database query failed: {str(e)}\")\n    except Exception as e:\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "blocks": [{"id": 1, "label": "async def create_agent_installed_event(\n    event_data: market.model.AgentInstalledFromMarketplaceEventData,\n):\ntry:", "successors": [{"id": 3, "label": "    await prisma.models.InstallTracker.prisma().create(\n        data={\n            \"installedAgentId\": event_data.installed_agent_id,\n            \"marketplaceAgentId\": event_data.marketplace_agent_id,\n            \"installationLocation\": prisma.enums.InstallationLocation(\n                event_data.installation_location.name\n            ),\n        }\n    )", "successors": []}, {"id": 4, "label": "except prisma.errors.PrismaError as e:\n    raise AgentQueryError(f\"Database query failed: {str(e)}\")", "successors": []}, {"id": 6, "label": "except Exception as e:\n    raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "successors": []}]}]}], "classes": [{"name": "AgentQueryError", "type": "class", "start_line": 15, "end_line": 18, "functions": [], "classes": [], "simplified_code": "class AgentQueryError(Exception):\n    \"\"\"Custom exception for agent query errors\"\"\"\n\n    pass", "blocks": [{"id": 1, "label": "class AgentQueryError(Exception):\n    \"\"\"Custom exception for agent query errors\"\"\"\npass", "successors": []}]}, {"name": "TopAgentsDBResponse", "type": "class", "start_line": 21, "end_line": 37, "functions": [], "classes": [], "simplified_code": "class TopAgentsDBResponse(pydantic.BaseModel):\n    \"\"\"\n    Represents a response containing a list of top agents.\n\n    Attributes:\n        analytics (list[AgentResponse]): The list of top agents.\n        total_count (int): The total count of agents.\n        page (int): The current page number.\n        page_size (int): The number of agents per page.\n        total_pages (int): The total number of pages.\n    \"\"\"\n\n    analytics: list[prisma.models.AnalyticsTracker]\n    total_count: int\n    page: int\n    page_size: int\n    total_pages: int", "blocks": [{"id": 1, "label": "class TopAgentsDBResponse(pydantic.BaseModel):\n\"\"\"\nRepresents a response containing a list of top agents.\n\nAttributes:\n    analytics (list[AgentResponse]): The list of top agents.\n    total_count (int): The total count of agents.\n    page (int): The current page number.\n    page_size (int): The number of agents per page.\n    total_pages (int): The total number of pages.\n\"\"\"", "successors": [{"id": 3, "label": "analytics: list[prisma.models.AnalyticsTracker]\ntotal_count: int", "successors": [{"id": 5, "label": "page: int\npage_size: int", "successors": [{"id": 7, "label": "total_pages: int", "successors": []}]}]}]}]}, {"name": "FeaturedAgentResponse", "type": "class", "start_line": 40, "end_line": 56, "functions": [], "classes": [], "simplified_code": "class FeaturedAgentResponse(pydantic.BaseModel):\n    \"\"\"\n    Represents a response containing a list of featured agents.\n\n    Attributes:\n        featured_agents (list[FeaturedAgent]): The list of featured agents.\n        total_count (int): The total count of featured agents.\n        page (int): The current page number.\n        page_size (int): The number of agents per page.\n        total_pages (int): The total number of pages.\n    \"\"\"\n\n    featured_agents: list[prisma.models.FeaturedAgent]\n    total_count: int\n    page: int\n    page_size: int\n    total_pages: int", "blocks": [{"id": 1, "label": "class FeaturedAgentResponse(pydantic.BaseModel):\n\"\"\"\nRepresents a response containing a list of featured agents.\n\nAttributes:\n    featured_agents (list[FeaturedAgent]): The list of featured agents.\n    total_count (int): The total count of featured agents.\n    page (int): The current page number.\n    page_size (int): The number of agents per page.\n    total_pages (int): The total number of pages.\n\"\"\"", "successors": [{"id": 3, "label": "featured_agents: list[prisma.models.FeaturedAgent]\ntotal_count: int", "successors": [{"id": 5, "label": "page: int\npage_size: int", "successors": [{"id": 7, "label": "total_pages: int", "successors": []}]}]}]}]}], "simplified_code": "import datetime\nimport typing\n\nimport fuzzywuzzy.fuzz\nimport prisma.enums\nimport prisma.errors\nimport prisma.models\nimport prisma.types\nimport pydantic\n\nimport market.model\nimport market.utils.extension_types\n\n\n    pass\n\n\n    total_pages: int\n\n\n    total_pages: int\n\n\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")\n\n\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")\n\n\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")\n\n\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")\n\n\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")\n\n\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")\n\n\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\") from e\n\n\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")\n\n\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\") from e\n\n\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")\n\n\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")\n\n\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")\n\n\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")\n\n\n        return market.model.CategoriesResponse(unique_categories=[])\n\n\n        raise AgentQueryError(f\"Unexpected error occurred: {str(e)}\")", "blocks": [{"id": 1, "label": "import datetime\nimport typing", "successors": [{"id": 3, "label": "import fuzzywuzzy.fuzz\nimport prisma.enums", "successors": [{"id": 5, "label": "import prisma.errors\nimport prisma.models", "successors": [{"id": 7, "label": "import prisma.types\nimport pydantic", "successors": [{"id": 9, "label": "import market.model\nimport market.utils.extension_types", "successors": []}]}]}]}]}]}
{"file_name": "105.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 66, "functions": [], "classes": [{"name": "Node", "type": "class", "start_line": 1, "end_line": 5, "functions": [{"name": "__init__", "type": "function", "start_line": 3, "end_line": 5, "functions": [], "classes": [], "simplified_code": "    def __init__(self, results):\n        self.results = results\n        self.next = next", "blocks": [{"id": 1, "label": "def __init__(self, results):\n    self.results = results\n    self.next = next", "successors": []}]}], "simplified_code": "class Node(object):\n\n        self.next = next", "blocks": [{"id": 1, "label": "class Node(object):\ndef __init__(self, value=None, next=None):", "successors": [{"id": 3, "label": "self.value = value\nself.next = next", "successors": []}]}]}, {"name": "LinkedList", "type": "class", "start_line": 8, "end_line": 21, "functions": [{"name": "__init__", "type": "function", "start_line": 10, "end_line": 12, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        self.head = None\n        self.tail = None", "blocks": [{"id": 1, "label": "def __init__(self):\n    self.head = None\n    self.tail = None", "successors": []}]}, {"name": "move_to_front", "type": "function", "start_line": 14, "end_line": 15, "functions": [], "classes": [], "simplified_code": "    def move_to_front(self, node):\n        pass", "blocks": [{"id": 1, "label": "def move_to_front(self, node):\npass", "successors": []}]}, {"name": "append_to_front", "type": "function", "start_line": 17, "end_line": 18, "functions": [], "classes": [], "simplified_code": "    def append_to_front(self, node):\n        pass", "blocks": [{"id": 1, "label": "def append_to_front(self, node):\n    pass", "successors": []}]}, {"name": "remove_from_tail", "type": "function", "start_line": 20, "end_line": 21, "functions": [], "classes": [], "simplified_code": "    def remove_from_tail(self):\n        pass", "blocks": [{"id": 1, "label": "def remove_from_tail(self):\npass", "successors": []}]}], "simplified_code": "class LinkedList(object):\n\n        self.tail = None\n\n        pass\n\n        pass\n\n        pass", "blocks": [{"id": 1, "label": "class LinkedList(object):\nself.tail = None", "successors": [{"id": 3, "label": "pass\npass", "successors": [{"id": 5, "label": "pass", "successors": []}]}]}]}, {"name": "Cache", "type": "class", "start_line": 24, "end_line": 66, "functions": [{"name": "__init__", "type": "function", "start_line": 26, "end_line": 30, "functions": [], "classes": [], "simplified_code": "    def __init__(self, MAX_SIZE):\n        self.MAX_SIZE = MAX_SIZE\n        self.size = 0\n        self.lookup = {}  # key: query, value: node\n        self.linked_list = LinkedList()", "blocks": [{"id": 1, "label": "def __init__(self, MAX_SIZE):\n    self.MAX_SIZE = MAX_SIZE\n    self.size = 0\n    self.lookup = {}\n    self.linked_list = LinkedList()", "successors": []}]}, {"name": "get", "type": "function", "start_line": 32, "end_line": 41, "functions": [], "classes": [], "simplified_code": "    def get(self, query):\n        \"\"\"Get the stored query result from the cache.\n\n        Accessing a node updates its position to the front of the LRU list.\n        \"\"\"\n        node = self.lookup.get(query)\n        if node is None:\n            return None\n        self.linked_list.move_to_front(node)\n        return node.results", "blocks": [{"id": 1, "label": "node = self.lookup.get(query)\nif node is None:", "successors": [{"id": 3, "label": "return None", "successors": []}, {"id": 4, "label": "self.linked_list.move_to_front(node)\nreturn node.results", "successors": []}]}]}, {"name": "set", "type": "function", "start_line": 43, "end_line": 66, "functions": [], "classes": [], "simplified_code": "    def set(self, results, query):\n        \"\"\"Set the result for the given query key in the cache.\n\n        When updating an entry, updates its position to the front of the LRU list.\n        If the entry is new and the cache is at capacity, removes the oldest entry\n        before the new entry is added.\n        \"\"\"\n        node = self.lookup.get(query)\n        if node is not None:\n            # Key exists in cache, update the value\n            node.results = results\n            self.linked_list.move_to_front(node)\n        else:\n            # Key does not exist in cache\n            if self.size == self.MAX_SIZE:\n                # Remove the oldest entry from the linked list and lookup\n                self.lookup.pop(self.linked_list.tail.query, None)\n                self.linked_list.remove_from_tail()\n            else:\n                self.size += 1\n            # Add the new key and value\n            new_node = Node(results)\n            self.linked_list.append_to_front(new_node)\n            self.lookup[query] = new_node", "blocks": [{"id": 1, "label": "node = self.lookup.get(query)\nif node is not None:", "successors": [{"id": 3, "label": "    node.results = results\n    self.linked_list.move_to_front(node)\n", "successors": []}, {"id": 4, "label": "else:\n    if self.size == self.MAX_SIZE:", "successors": [{"id": 6, "label": "        self.lookup.pop(self.linked_list.tail.query, None)\n        self.linked_list.remove_from_tail()\n    new_node = Node(results)\n    self.linked_list.append_to_front(new_node)\n    self.lookup[query] = new_node", "successors": [{"id": 10, "label": "", "successors": []}]}, {"id": 7, "label": "else:\n    self.size += 1", "successors": [{"id": 9, "label": "    new_node = Node(results)\n    self.linked_list.append_to_front(new_node)\n    self.lookup[query] = new_node\n", "successors": []}]}]}]}]}], "simplified_code": "class Cache(object):\n\n        self.linked_list = LinkedList()\n\n        return node.results\n\n            self.lookup[query] = new_node", "blocks": [{"id": 1, "label": "class Cache(object):\n    self.linked_list = LinkedList()", "successors": [{"id": 3, "label": "    return node.results", "successors": []}]}]}], "simplified_code": "        self.next = next\n\n\n        pass\n\n\n            self.lookup[query] = new_node", "blocks": [{"id": 1, "label": "self.next = next\npass", "successors": [{"id": 3, "label": "self.lookup[query] = new_node", "successors": []}]}]}
{"file_name": "106.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 190, "functions": [], "classes": [{"name": "ProgrammingLanguage", "type": "class", "start_line": 31, "end_line": 36, "functions": [], "classes": [], "simplified_code": "class ProgrammingLanguage(Enum):\n    PYTHON = \"python\"\n    JAVASCRIPT = \"js\"\n    BASH = \"bash\"\n    R = \"r\"\n    JAVA = \"java\"", "blocks": [{"id": 1, "label": "class ProgrammingLanguage(Enum):\n    PYTHON = \"python\"", "successors": [{"id": 3, "label": "    JAVASCRIPT = \"js\"\n    BASH = \"bash\"", "successors": [{"id": 5, "label": "    R = \"r\"\n    JAVA = \"java\"", "successors": []}]}]}]}, {"name": "CodeExecutionBlock", "type": "class", "start_line": 39, "end_line": 190, "functions": [{"name": "__init__", "type": "function", "start_line": 97, "end_line": 124, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"0b02b072-abe7-11ef-8372-fb5d162dd712\",\n            description=\"Executes code in an isolated sandbox environment with internet access.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=CodeExecutionBlock.Input,\n            output_schema=CodeExecutionBlock.Output,\n            test_credentials=TEST_CREDENTIALS,\n            test_input={\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n                \"code\": \"print('Hello World')\",\n                \"language\": ProgrammingLanguage.PYTHON.value,\n                \"setup_commands\": [],\n                \"timeout\": 300,\n                \"template_id\": \"\",\n            },\n            test_output=[\n                (\"response\", \"Hello World\"),\n                (\"stdout_logs\", \"Hello World\\n\"),\n            ],\n            test_mock={\n                \"execute_code\": lambda code, language, setup_commands, timeout, api_key, template_id: (\n                    \"Hello World\",\n                    \"Hello World\\n\",\n                    \"\",\n                ),\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\n    super().__init__(\n        id=\"0b02b072-abe7-11ef-8372-fb5d162dd712\",\n        description=\"Executes code in an isolated sandbox environment with internet access.\",\n        categories={BlockCategory.DEVELOPER_TOOLS},\n        input_schema=CodeExecutionBlock.Input,\n        output_schema=CodeExecutionBlock.Output,\n        test_credentials=TEST_CREDENTIALS,\n        test_input={\n            \"credentials\": TEST_CREDENTIALS_INPUT,\n            \"code\": \"print('Hello World')\",\n            \"language\": ProgrammingLanguage.PYTHON.value,\n            \"setup_commands\": [],\n            \"timeout\": 300,\n            \"template_id\": \"\",\n        },\n        test_output=[\n            (\"response\", \"Hello World\"),\n            (\"stdout_logs\", \"Hello World\\n\"),\n        ],\n        test_mock={\n            \"execute_code\": lambda code, language, setup_commands, timeout, api_key, template_id: (\n                \"Hello World\",\n                \"Hello World\\n\",\n                \"\",\n            ),\n        },\n    )", "successors": []}]}, {"name": "execute_code", "type": "function", "start_line": 126, "end_line": 168, "functions": [], "classes": [], "simplified_code": "    def execute_code(\n        self,\n        code: str,\n        language: ProgrammingLanguage,\n        setup_commands: list[str],\n        timeout: int,\n        api_key: str,\n        template_id: str,\n    ):\n        try:\n            sandbox = None\n            if template_id:\n                sandbox = Sandbox(\n                    template=template_id, api_key=api_key, timeout=timeout\n                )\n            else:\n                sandbox = Sandbox(api_key=api_key, timeout=timeout)\n\n            if not sandbox:\n                raise Exception(\"Sandbox not created\")\n\n            # Running setup commands\n            for cmd in setup_commands:\n                sandbox.commands.run(cmd)\n\n            # Executing the code\n            execution = sandbox.run_code(\n                code,\n                language=language.value,\n                on_error=lambda e: sandbox.kill(),  # Kill the sandbox if there is an error\n            )\n\n            if execution.error:\n                raise Exception(execution.error)\n\n            response = execution.text\n            stdout_logs = \"\".join(execution.logs.stdout)\n            stderr_logs = \"\".join(execution.logs.stderr)\n\n            return response, stdout_logs, stderr_logs\n\n        except Exception as e:\n            raise e", "blocks": [{"id": 1, "label": "try:\nsandbox = None", "successors": [{"id": 3, "label": "if template_id:", "successors": [{"id": 4, "label": "sandbox = Sandbox(template=template_id, api_key=api_key, timeout=timeout)\nif not sandbox:", "successors": [{"id": 8, "label": "raise Exception(\"Sandbox not created\")", "successors": [{"id": 9, "label": "for cmd in setup_commands:", "successors": [{"id": 10, "label": "sandbox.commands.run(cmd)\nexecution = sandbox.run_code(code, language=language.value, on_error=lambda e: sandbox.kill())", "successors": [{"id": 12, "label": "if execution.error:", "successors": [{"id": 13, "label": "raise Exception(execution.error)\nresponse = execution.text", "successors": [{"id": 15, "label": "stdout_logs = \"\".join(execution.logs.stdout)\nstderr_logs = \"\".join(execution.logs.stderr)", "successors": [{"id": 17, "label": "return response, stdout_logs, stderr_logs", "successors": []}]}]}, {"id": 14, "label": "response = execution.text\nstdout_logs = \"\".join(execution.logs.stdout)", "successors": [{"id": 16, "label": "stderr_logs = \"\".join(execution.logs.stderr)\nreturn response, stdout_logs, stderr_logs", "successors": []}]}]}]}]}]}, {"id": 9, "label": "for cmd in setup_commands:", "successors": [{"id": 10, "label": "sandbox.commands.run(cmd)\nexecution = sandbox.run_code(code, language=language.value, on_error=lambda e: sandbox.kill())", "successors": [{"id": 12, "label": "if execution.error:", "successors": [{"id": 13, "label": "raise Exception(execution.error)\nresponse = execution.text", "successors": [{"id": 15, "label": "stdout_logs = \"\".join(execution.logs.stdout)\nstderr_logs = \"\".join(execution.logs.stderr)", "successors": [{"id": 17, "label": "return response, stdout_logs, stderr_logs", "successors": []}]}]}, {"id": 14, "label": "response = execution.text\nstdout_logs = \"\".join(execution.logs.stdout)", "successors": [{"id": 16, "label": "stderr_logs = \"\".join(execution.logs.stderr)\nreturn response, stdout_logs, stderr_logs", "successors": []}]}]}]}]}]}, {"id": 5, "label": "sandbox = Sandbox(api_key=api_key, timeout=timeout)\nif not sandbox:", "successors": [{"id": 8, "label": "raise Exception(\"Sandbox not created\")", "successors": [{"id": 9, "label": "for cmd in setup_commands:", "successors": [{"id": 10, "label": "sandbox.commands.run(cmd)\nexecution = sandbox.run_code(code, language=language.value, on_error=lambda e: sandbox.kill())", "successors": [{"id": 12, "label": "if execution.error:", "successors": [{"id": 13, "label": "raise Exception(execution.error)\nresponse = execution.text", "successors": [{"id": 15, "label": "stdout_logs = \"\".join(execution.logs.stdout)\nstderr_logs = \"\".join(execution.logs.stderr)", "successors": [{"id": 17, "label": "return response, stdout_logs, stderr_logs", "successors": []}]}]}, {"id": 14, "label": "response = execution.text\nstdout_logs = \"\".join(execution.logs.stdout)", "successors": [{"id": 16, "label": "stderr_logs = \"\".join(execution.logs.stderr)\nreturn response, stdout_logs, stderr_logs", "successors": []}]}]}]}]}]}, {"id": 9, "label": "for cmd in setup_commands:", "successors": [{"id": 10, "label": "sandbox.commands.run(cmd)\nexecution = sandbox.run_code(code, language=language.value, on_error=lambda e: sandbox.kill())", "successors": [{"id": 12, "label": "if execution.error:", "successors": [{"id": 13, "label": "raise Exception(execution.error)\nresponse = execution.text", "successors": [{"id": 15, "label": "stdout_logs = \"\".join(execution.logs.stdout)\nstderr_logs = \"\".join(execution.logs.stderr)", "successors": [{"id": 17, "label": "return response, stdout_logs, stderr_logs", "successors": []}]}]}, {"id": 14, "label": "response = execution.text\nstdout_logs = \"\".join(execution.logs.stdout)", "successors": [{"id": 16, "label": "stderr_logs = \"\".join(execution.logs.stderr)\nreturn response, stdout_logs, stderr_logs", "successors": []}]}]}]}]}]}]}]}]}, {"name": "run", "type": "function", "start_line": 170, "end_line": 190, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        try:\n            response, stdout_logs, stderr_logs = self.execute_code(\n                input_data.code,\n                input_data.language,\n                input_data.setup_commands,\n                input_data.timeout,\n                credentials.api_key.get_secret_value(),\n                input_data.template_id,\n            )\n\n            if response:\n                yield \"response\", response\n            if stdout_logs:\n                yield \"stdout_logs\", stdout_logs\n            if stderr_logs:\n                yield \"stderr_logs\", stderr_logs\n        except Exception as e:\n            yield \"error\", str(e)", "blocks": [{"id": 1, "label": "try:\nresponse, stdout_logs, stderr_logs = self.execute_code(\n    input_data.code,\n    input_data.language,\n    input_data.setup_commands,\n    input_data.timeout,\n    credentials.api_key.get_secret_value(),\n    input_data.template_id,\n)", "successors": [{"id": 3, "label": "if response:", "successors": [{"id": 4, "label": "yield \"response\", response\nexcept Exception as e:", "successors": [{"id": 9, "label": "yield \"error\", str(e)", "successors": []}]}, {"id": 5, "label": "if stdout_logs:", "successors": [{"id": 6, "label": "yield \"stdout_logs\", stdout_logs\nexcept Exception as e:", "successors": [{"id": 9, "label": "yield \"error\", str(e)", "successors": []}]}, {"id": 7, "label": "if stderr_logs:\nyield \"stderr_logs\", stderr_logs", "successors": [{"id": 8, "label": "except Exception as e:\nyield \"error\", str(e)", "successors": []}]}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 42, "end_line": 87, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: CredentialsMetaInput[\n            Literal[ProviderName.E2B], Literal[\"api_key\"]\n        ] = CredentialsField(\n            description=\"Enter your api key for the E2B Sandbox. You can get it in here - https://e2b.dev/docs\",\n        )\n\n        # Todo : Option to run commond in background\n        setup_commands: list[str] = SchemaField(\n            description=(\n                \"Shell commands to set up the sandbox before running the code. \"\n                \"You can use `curl` or `git` to install your desired Debian based \"\n                \"package manager. `pip` and `npm` are pre-installed.\\n\\n\"\n                \"These commands are executed with `sh`, in the foreground.\"\n            ),\n            placeholder=\"pip install cowsay\",\n            default=[],\n            advanced=False,\n        )\n\n        code: str = SchemaField(\n            description=\"Code to execute in the sandbox\",\n            placeholder=\"print('Hello, World!')\",\n            default=\"\",\n            advanced=False,\n        )\n\n        language: ProgrammingLanguage = SchemaField(\n            description=\"Programming language to execute\",\n            default=ProgrammingLanguage.PYTHON,\n            advanced=False,\n        )\n\n        timeout: int = SchemaField(\n            description=\"Execution timeout in seconds\", default=300\n        )\n\n        template_id: str = SchemaField(\n            description=(\n                \"You can use an E2B sandbox template by entering its ID here. \"\n                \"Check out the E2B docs for more details: \"\n                \"[E2B - Sandbox template](https://e2b.dev/docs/sandbox-template)\"\n            ),\n            default=\"\",\n            advanced=True,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    credentials: CredentialsMetaInput[\n        Literal[ProviderName.E2B], Literal[\"api_key\"]\n    ] = CredentialsField(\n        description=\"Enter your api key for the E2B Sandbox. You can get it in here - https://e2b.dev/docs\",\n    )", "successors": []}, {"id": 3, "label": "    setup_commands: list[str] = SchemaField(\n        description=(\n            \"Shell commands to set up the sandbox before running the code. \"\n            \"You can use `curl` or `git` to install your desired Debian based \"\n            \"package manager. `pip` and `npm` are pre-installed.\\n\\n\"\n            \"These commands are executed with `sh`, in the foreground.\"\n        ),\n        placeholder=\"pip install cowsay\",\n        default=[],\n        advanced=False,\n    )", "successors": []}, {"id": 4, "label": "    code: str = SchemaField(\n        description=\"Code to execute in the sandbox\",\n        placeholder=\"print('Hello, World!')\",\n        default=\"\",\n        advanced=False,\n    )", "successors": []}, {"id": 5, "label": "    language: ProgrammingLanguage = SchemaField(\n        description=\"Programming language to execute\",\n        default=ProgrammingLanguage.PYTHON,\n        advanced=False,\n    )", "successors": []}, {"id": 6, "label": "    timeout: int = SchemaField(\n        description=\"Execution timeout in seconds\", default=300\n    )", "successors": []}, {"id": 7, "label": "    template_id: str = SchemaField(\n        description=(\n            \"You can use an E2B sandbox template by entering its ID here. \"\n            \"Check out the E2B docs for more details: \"\n            \"[E2B - Sandbox template](https://e2b.dev/docs/sandbox-template)\"\n        ),\n        default=\"\",\n        advanced=True,\n    )", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 89, "end_line": 95, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        response: str = SchemaField(description=\"Response from code execution\")\n        stdout_logs: str = SchemaField(\n            description=\"Standard output logs from execution\"\n        )\n        stderr_logs: str = SchemaField(description=\"Standard error logs from execution\")\n        error: str = SchemaField(description=\"Error message if execution failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "response: str = SchemaField(description=\"Response from code execution\")", "successors": []}, {"id": 3, "label": "stdout_logs: str = SchemaField(description=\"Standard output logs from execution\")", "successors": []}, {"id": 4, "label": "stderr_logs: str = SchemaField(description=\"Standard error logs from execution\")", "successors": []}, {"id": 5, "label": "error: str = SchemaField(description=\"Error message if execution failed\")", "successors": []}]}]}], "simplified_code": "class CodeExecutionBlock(Block):\n    # TODO : Add support to upload and download files\n    # Currently, You can customized the CPU and Memory, only by creating a pre customized sandbox template\n        )\n\n        error: str = SchemaField(description=\"Error message if execution failed\")\n\n        )\n\n            raise e\n\n            yield \"error\", str(e)", "blocks": [{"id": 1, "label": "class CodeExecutionBlock(Block):\n# TODO : Add support to upload and download files\n# Currently, You can customized the CPU and Memory, only by creating a pre customized sandbox template\n)", "successors": [{"id": 3, "label": "error: str = SchemaField(description=\"Error message if execution failed\")\n)", "successors": [{"id": 5, "label": "raise e\nyield \"error\", str(e)", "successors": []}]}]}]}], "simplified_code": "from enum import Enum\nfrom typing import Literal\n\nfrom e2b_code_interpreter import Sandbox\nfrom pydantic import SecretStr\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"e2b\",\n    api_key=SecretStr(\"mock-e2b-api-key\"),\n    title=\"Mock E2B API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.type,\n}\n\n\n    JAVA = \"java\"\n\n\n            yield \"error\", str(e)", "blocks": [{"id": 1, "label": "from enum import Enum\nfrom typing import Literal\n\nfrom e2b_code_interpreter import Sandbox\nfrom pydantic import SecretStr\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"e2b\",\n    api_key=SecretStr(\"mock-e2b-api-key\"),\n    title=\"Mock E2B API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.type,\n}", "successors": []}]}
{"file_name": "107.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 73, "functions": [], "classes": [{"name": "StepThroughItemsBlock", "type": "class", "start_line": 8, "end_line": 73, "functions": [{"name": "__init__", "type": "function", "start_line": 35, "end_line": 54, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"f66a3543-28d3-4ab5-8945-9b336371e2ce\",\n            input_schema=StepThroughItemsBlock.Input,\n            output_schema=StepThroughItemsBlock.Output,\n            categories={BlockCategory.LOGIC},\n            description=\"Iterates over a list or dictionary and outputs each item.\",\n            test_input={\"items\": [1, 2, 3, {\"key1\": \"value1\", \"key2\": \"value2\"}]},\n            test_output=[\n                (\"item\", 1),\n                (\"key\", 0),\n                (\"item\", 2),\n                (\"key\", 1),\n                (\"item\", 3),\n                (\"key\", 2),\n                (\"item\", {\"key1\": \"value1\", \"key2\": \"value2\"}),\n                (\"key\", 3),\n            ],\n            test_mock={},\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"f66a3543-28d3-4ab5-8945-9b336371e2ce\",\n    input_schema=StepThroughItemsBlock.Input,\n    output_schema=StepThroughItemsBlock.Output,\n    categories={BlockCategory.LOGIC},\n    description=\"Iterates over a list or dictionary and outputs each item.\",\n    test_input={\"items\": [1, 2, 3, {\"key1\": \"value1\", \"key2\": \"value2\"}]},\n    test_output=[\n        (\"item\", 1),\n        (\"key\", 0),\n        (\"item\", 2),\n        (\"key\", 1),\n        (\"item\", 3),\n        (\"key\", 2),\n        (\"item\", {\"key1\": \"value1\", \"key2\": \"value2\"}),\n        (\"key\", 3),\n    ],\n    test_mock={}\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 56, "end_line": 73, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        for data in [input_data.items, input_data.items_object, input_data.items_str]:\n            if not data:\n                continue\n            if isinstance(data, str):\n                items = json.loads(data)\n            else:\n                items = data\n            if isinstance(items, dict):\n                # If items is a dictionary, iterate over its values\n                for item in items.values():\n                    yield \"item\", item\n                    yield \"key\", item\n            else:\n                # If items is a list, iterate over the list\n                for index, item in enumerate(items):\n                    yield \"item\", item\n                    yield \"key\", index", "blocks": [{"id": 1, "label": "for data in [input_data.items, input_data.items_object, input_data.items_str]:", "successors": [{"id": 2, "label": "if not data:", "successors": [{"id": 3, "label": "continue", "successors": []}, {"id": 4, "label": "if isinstance(data, str):", "successors": [{"id": 5, "label": "items = json.loads(data)\nif isinstance(items, dict):", "successors": [{"id": 8, "label": "for item in items.values():", "successors": [{"id": 9, "label": "yield \"item\", item\nyield \"key\", item", "successors": []}]}, {"id": 10, "label": "for index, item in enumerate(items):", "successors": [{"id": 11, "label": "yield \"item\", item\nyield \"key\", index", "successors": []}]}]}, {"id": 6, "label": "items = data\nif isinstance(items, dict):", "successors": [{"id": 8, "label": "for item in items.values():", "successors": [{"id": 9, "label": "yield \"item\", item\nyield \"key\", item", "successors": []}]}, {"id": 10, "label": "for index, item in enumerate(items):", "successors": [{"id": 11, "label": "yield \"item\", item\nyield \"key\", index", "successors": []}]}]}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 9, "end_line": 27, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        items: list = SchemaField(\n            advanced=False,\n            description=\"The list or dictionary of items to iterate over\",\n            placeholder=\"[1, 2, 3, 4, 5] or {'key1': 'value1', 'key2': 'value2'}\",\n            default=[],\n        )\n        items_object: dict = SchemaField(\n            advanced=False,\n            description=\"The list or dictionary of items to iterate over\",\n            placeholder=\"[1, 2, 3, 4, 5] or {'key1': 'value1', 'key2': 'value2'}\",\n            default={},\n        )\n        items_str: str = SchemaField(\n            advanced=False,\n            description=\"The list or dictionary of items to iterate over\",\n            placeholder=\"[1, 2, 3, 4, 5] or {'key1': 'value1', 'key2': 'value2'}\",\n            default=\"\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    items: list = SchemaField(\n        advanced=False,\n        description=\"The list or dictionary of items to iterate over\",\n        placeholder=\"[1, 2, 3, 4, 5] or {'key1': 'value1', 'key2': 'value2'}\",\n        default=[],\n    )", "successors": [{"id": 3, "label": "    items_object: dict = SchemaField(\n        advanced=False,\n        description=\"The list or dictionary of items to iterate over\",\n        placeholder=\"[1, 2, 3, 4, 5] or {'key1': 'value1', 'key2': 'value2'}\",\n        default={},\n    )\n    items_str: str = SchemaField(\n        advanced=False,\n        description=\"The list or dictionary of items to iterate over\",\n        placeholder=\"[1, 2, 3, 4, 5] or {'key1': 'value1', 'key2': 'value2'}\",\n        default=\"\",\n    )", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 29, "end_line": 33, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        item: Any = SchemaField(description=\"The current item in the iteration\")\n        key: Any = SchemaField(\n            description=\"The key or index of the current item in the iteration\",\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "    item: Any = SchemaField(description=\"The current item in the iteration\")", "successors": []}, {"id": 3, "label": "    key: Any = SchemaField(description=\"The key or index of the current item in the iteration\",)", "successors": []}]}]}], "simplified_code": "class StepThroughItemsBlock(Block):\n        )\n\n        )\n\n        )\n\n                    yield \"key\", index", "blocks": [{"id": 1, "label": "class StepThroughItemsBlock(Block):\n    def __init__(self, mapping):", "successors": [{"id": 3, "label": "        self._keys = list(mapping.keys())\n        self._mapping = mapping", "successors": [{"id": 5, "label": "    def __iter__(self):", "successors": [{"id": 6, "label": "        for index, key in enumerate(self._keys):", "successors": [{"id": 7, "label": "            yield key, index\n    def __len__(self):", "successors": [{"id": 9, "label": "        return len(self._keys)", "successors": []}]}]}]}]}]}]}], "simplified_code": "from typing import Any\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\nfrom backend.util.json import json\n\n\n                    yield \"key\", index", "blocks": [{"id": 1, "label": "from typing import Any\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\nfrom backend.util.json import json\nyield \"key\", index", "successors": []}]}
{"file_name": "108.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 90, "functions": [], "classes": [{"name": "NotionOAuthHandler", "type": "class", "start_line": 11, "end_line": 90, "functions": [{"name": "__init__", "type": "function", "start_line": 22, "end_line": 27, "functions": [], "classes": [], "simplified_code": "    def __init__(self, client_id: str, client_secret: str, redirect_uri: str):\n        self.client_id = client_id\n        self.client_secret = client_secret\n        self.redirect_uri = redirect_uri\n        self.auth_base_url = \"https://api.notion.com/v1/oauth/authorize\"\n        self.token_url = \"https://api.notion.com/v1/oauth/token\"", "blocks": [{"id": 1, "label": "def __init__(self, client_id: str, client_secret: str, redirect_uri: str):\n    self.client_id = client_id\n    self.client_secret = client_secret\n    self.redirect_uri = redirect_uri\n    self.auth_base_url = \"https://api.notion.com/v1/oauth/authorize\"\n    self.token_url = \"https://api.notion.com/v1/oauth/token\"", "successors": []}]}, {"name": "get_login_url", "type": "function", "start_line": 29, "end_line": 37, "functions": [], "classes": [], "simplified_code": "    def get_login_url(self, scopes: list[str], state: str) -> str:\n        params = {\n            \"client_id\": self.client_id,\n            \"redirect_uri\": self.redirect_uri,\n            \"response_type\": \"code\",\n            \"owner\": \"user\",\n            \"state\": state,\n        }\n        return f\"{self.auth_base_url}?{urlencode(params)}\"", "blocks": [{"id": 1, "label": "params = {\n    \"client_id\": self.client_id,\n    \"redirect_uri\": self.redirect_uri,\n    \"response_type\": \"code\",\n    \"owner\": \"user\",\n    \"state\": state,\n}\nreturn f\"{self.auth_base_url}?{urlencode(params)}\"", "successors": []}]}, {"name": "exchange_code_for_tokens", "type": "function", "start_line": 39, "end_line": 78, "functions": [], "classes": [], "simplified_code": "    def exchange_code_for_tokens(\n        self, code: str, scopes: list[str]\n    ) -> OAuth2Credentials:\n        request_body = {\n            \"grant_type\": \"authorization_code\",\n            \"code\": code,\n            \"redirect_uri\": self.redirect_uri,\n        }\n        auth_str = b64encode(f\"{self.client_id}:{self.client_secret}\".encode()).decode()\n        headers = {\n            \"Authorization\": f\"Basic {auth_str}\",\n            \"Accept\": \"application/json\",\n        }\n        response = requests.post(self.token_url, json=request_body, headers=headers)\n        token_data = response.json()\n        # Email is only available for non-bot users\n        email = (\n            token_data[\"owner\"][\"person\"][\"email\"]\n            if \"person\" in token_data[\"owner\"]\n            and \"email\" in token_data[\"owner\"][\"person\"]\n            else None\n        )\n\n        return OAuth2Credentials(\n            provider=self.PROVIDER_NAME,\n            title=token_data.get(\"workspace_name\"),\n            username=email,\n            access_token=token_data[\"access_token\"],\n            refresh_token=None,\n            access_token_expires_at=None,  # Notion tokens don't expire\n            refresh_token_expires_at=None,\n            scopes=[],\n            metadata={\n                \"owner\": token_data[\"owner\"],\n                \"bot_id\": token_data[\"bot_id\"],\n                \"workspace_id\": token_data[\"workspace_id\"],\n                \"workspace_name\": token_data.get(\"workspace_name\"),\n                \"workspace_icon\": token_data.get(\"workspace_icon\"),\n            },\n        )", "blocks": [{"id": 1, "label": "def exchange_code_for_tokens(self, code: str, scopes: list[str]) -> OAuth2Credentials:\nrequest_body = {\n    \"grant_type\": \"authorization_code\",\n    \"code\": code,\n    \"redirect_uri\": self.redirect_uri,\n}", "successors": [{"id": 3, "label": "auth_str = b64encode(f\"{self.client_id}:{self.client_secret}\".encode()).decode()\nheaders = {\n    \"Authorization\": f\"Basic {auth_str}\",\n    \"Accept\": \"application/json\",\n}", "successors": [{"id": 5, "label": "response = requests.post(self.token_url, json=request_body, headers=headers)\ntoken_data = response.json()", "successors": [{"id": 7, "label": "email = (\n    token_data[\"owner\"][\"person\"][\"email\"]\n    if \"person\" in token_data[\"owner\"]\n    and \"email\" in token_data[\"owner\"][\"person\"]\n    else None\n)\nreturn OAuth2Credentials(\n    provider=self.PROVIDER_NAME,\n    title=token_data.get(\"workspace_name\"),\n    username=email,\n    access_token=token_data[\"access_token\"],\n    refresh_token=None,\n    access_token_expires_at=None,  # Notion tokens don't expire\n    refresh_token_expires_at=None,\n    scopes=[],\n    metadata={\n        \"owner\": token_data[\"owner\"],\n        \"bot_id\": token_data[\"bot_id\"],\n        \"workspace_id\": token_data[\"workspace_id\"],\n        \"workspace_name\": token_data.get(\"workspace_name\"),\n        \"workspace_icon\": token_data.get(\"workspace_icon\"),\n    },\n)", "successors": []}]}]}]}]}, {"name": "revoke_tokens", "type": "function", "start_line": 80, "end_line": 82, "functions": [], "classes": [], "simplified_code": "    def revoke_tokens(self, credentials: OAuth2Credentials) -> bool:\n        # Notion doesn't support token revocation\n        return False", "blocks": [{"id": 1, "label": "def revoke_tokens(self, credentials: OAuth2Credentials) -> bool:\n    return False", "successors": []}]}, {"name": "_refresh_tokens", "type": "function", "start_line": 84, "end_line": 86, "functions": [], "classes": [], "simplified_code": "    def _refresh_tokens(self, credentials: OAuth2Credentials) -> OAuth2Credentials:\n        # Notion doesn't support token refresh\n        return credentials", "blocks": [{"id": 1, "label": "def _refresh_tokens(self, credentials: OAuth2Credentials) -> OAuth2Credentials:\n    # Notion doesn't support token refresh\n    return credentials", "successors": []}]}, {"name": "needs_refresh", "type": "function", "start_line": 88, "end_line": 90, "functions": [], "classes": [], "simplified_code": "    def needs_refresh(self, credentials: OAuth2Credentials) -> bool:\n        # Notion access tokens don't expire\n        return False", "blocks": [{"id": 1, "label": "def needs_refresh(self, credentials: OAuth2Credentials) -> bool:\n    # Notion access tokens don't expire", "successors": [{"id": 3, "label": "    return False", "successors": []}]}]}], "simplified_code": "class NotionOAuthHandler(BaseOAuthHandler):\n    \"\"\"\n    Based on the documentation at https://developers.notion.com/docs/authorization\n\n    Notes:\n    - Notion uses non-expiring access tokens and therefore doesn't have a refresh flow\n    - Notion doesn't use scopes\n    \"\"\"\n\n    PROVIDER_NAME = ProviderName.NOTION\n\n        self.token_url = \"https://api.notion.com/v1/oauth/token\"\n\n        return f\"{self.auth_base_url}?{urlencode(params)}\"\n\n        )\n\n        return False\n\n        return credentials\n\n        return False", "blocks": [{"id": 1, "label": "class NotionOAuthHandler(BaseOAuthHandler):\n\"\"\"\nBased on the documentation at https://developers.notion.com/docs/authorization\n\nNotes:\n- Notion uses non-expiring access tokens and therefore doesn't have a refresh flow\n- Notion doesn't use scopes\n\"\"\"", "successors": [{"id": 3, "label": "PROVIDER_NAME = ProviderName.NOTION\nself.token_url = \"https://api.notion.com/v1/oauth/token\"", "successors": [{"id": 5, "label": "return f\"{self.auth_base_url}?{urlencode(params)}\"", "successors": []}, {"id": 6, "label": "return False", "successors": []}, {"id": 7, "label": "return credentials", "successors": []}, {"id": 8, "label": "return False", "successors": []}]}]}]}], "simplified_code": "from base64 import b64encode\nfrom urllib.parse import urlencode\n\nfrom backend.data.model import OAuth2Credentials\nfrom backend.integrations.providers import ProviderName\nfrom backend.util.request import requests\n\nfrom .base import BaseOAuthHandler\n\n\n        return False", "blocks": [{"id": 1, "label": "from base64 import b64encode\nfrom urllib.parse import urlencode\n\nfrom backend.data.model import OAuth2Credentials\nfrom backend.integrations.providers import ProviderName\nfrom backend.util.request import requests\n\nfrom .base import BaseOAuthHandler\nreturn False", "successors": []}]}
{"file_name": "109.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 109, "functions": [{"name": "logical_left_shift", "type": "function", "start_line": 6, "end_line": 33, "functions": [], "classes": [], "simplified_code": "def logical_left_shift(number: int, shift_amount: int) -> str:\n    \"\"\"\n    Take in 2 positive integers.\n    'number' is the integer to be logically left shifted 'shift_amount' times.\n    i.e. (number << shift_amount)\n    Return the shifted binary representation.\n\n    >>> logical_left_shift(0, 1)\n    '0b00'\n    >>> logical_left_shift(1, 1)\n    '0b10'\n    >>> logical_left_shift(1, 5)\n    '0b100000'\n    >>> logical_left_shift(17, 2)\n    '0b1000100'\n    >>> logical_left_shift(1983, 4)\n    '0b111101111110000'\n    >>> logical_left_shift(1, -1)\n    Traceback (most recent call last):\n        ...\n    ValueError: both inputs must be positive integers\n    \"\"\"\n    if number < 0 or shift_amount < 0:\n        raise ValueError(\"both inputs must be positive integers\")\n\n    binary_number = str(bin(number))\n    binary_number += \"0\" * shift_amount\n    return binary_number", "blocks": [{"id": 1, "label": "def logical_left_shift(number: int, shift_amount: int) -> str:\n    \"\"\"\n    Take in 2 positive integers.\n    'number' is the integer to be logically left shifted 'shift_amount' times.\n    i.e. (number << shift_amount)\n    Return the shifted binary representation.\n\n    >>> logical_left_shift(0, 1)\n    '0b00'\n    >>> logical_left_shift(1, 1)\n    '0b10'\n    >>> logical_left_shift(1, 5)\n    '0b100000'\n    >>> logical_left_shift(17, 2)\n    '0b1000100'\n    >>> logical_left_shift(1983, 4)\n    '0b111101111110000'\n    >>> logical_left_shift(1, -1)\n    Traceback (most recent call last):\n        ...\n    ValueError: both inputs must be positive integers\n    \"\"\"\nif number < 0 or shift_amount < 0:", "successors": [{"id": 3, "label": "    raise ValueError(\"both inputs must be positive integers\")", "successors": []}, {"id": 4, "label": "binary_number = str(bin(number))\nbinary_number += \"0\" * shift_amount\nreturn binary_number", "successors": []}]}]}, {"name": "logical_right_shift", "type": "function", "start_line": 36, "end_line": 65, "functions": [], "classes": [], "simplified_code": "def logical_right_shift(number: int, shift_amount: int) -> str:\n    \"\"\"\n    Take in positive 2 integers.\n    'number' is the integer to be logically right shifted 'shift_amount' times.\n    i.e. (number >>> shift_amount)\n    Return the shifted binary representation.\n\n    >>> logical_right_shift(0, 1)\n    '0b0'\n    >>> logical_right_shift(1, 1)\n    '0b0'\n    >>> logical_right_shift(1, 5)\n    '0b0'\n    >>> logical_right_shift(17, 2)\n    '0b100'\n    >>> logical_right_shift(1983, 4)\n    '0b1111011'\n    >>> logical_right_shift(1, -1)\n    Traceback (most recent call last):\n        ...\n    ValueError: both inputs must be positive integers\n    \"\"\"\n    if number < 0 or shift_amount < 0:\n        raise ValueError(\"both inputs must be positive integers\")\n\n    binary_number = str(bin(number))[2:]\n    if shift_amount >= len(binary_number):\n        return \"0b0\"\n    shifted_binary_number = binary_number[: len(binary_number) - shift_amount]\n    return \"0b\" + shifted_binary_number", "blocks": [{"id": 1, "label": "def logical_right_shift(number: int, shift_amount: int) -> str:\nif number < 0 or shift_amount < 0:", "successors": [{"id": 3, "label": "raise ValueError(\"both inputs must be positive integers\")", "successors": []}, {"id": 4, "label": "binary_number = str(bin(number))[2:]\nif shift_amount >= len(binary_number):", "successors": [{"id": 6, "label": "return \"0b0\"", "successors": []}, {"id": 7, "label": "shifted_binary_number = binary_number[: len(binary_number) - shift_amount]\nreturn \"0b\" + shifted_binary_number", "successors": []}]}]}]}, {"name": "arithmetic_right_shift", "type": "function", "start_line": 68, "end_line": 103, "functions": [], "classes": [], "simplified_code": "def arithmetic_right_shift(number: int, shift_amount: int) -> str:\n    \"\"\"\n    Take in 2 integers.\n    'number' is the integer to be arithmetically right shifted 'shift_amount' times.\n    i.e. (number >> shift_amount)\n    Return the shifted binary representation.\n\n    >>> arithmetic_right_shift(0, 1)\n    '0b00'\n    >>> arithmetic_right_shift(1, 1)\n    '0b00'\n    >>> arithmetic_right_shift(-1, 1)\n    '0b11'\n    >>> arithmetic_right_shift(17, 2)\n    '0b000100'\n    >>> arithmetic_right_shift(-17, 2)\n    '0b111011'\n    >>> arithmetic_right_shift(-1983, 4)\n    '0b111110000100'\n    \"\"\"\n    if number >= 0:  # Get binary representation of positive number\n        binary_number = \"0\" + str(bin(number)).strip(\"-\")[2:]\n    else:  # Get binary (2's complement) representation of negative number\n        binary_number_length = len(bin(number)[3:])  # Find 2's complement of number\n        binary_number = bin(abs(number) - (1 << binary_number_length))[3:]\n        binary_number = (\n            \"1\" + \"0\" * (binary_number_length - len(binary_number)) + binary_number\n        )\n\n    if shift_amount >= len(binary_number):\n        return \"0b\" + binary_number[0] * len(binary_number)\n    return (\n        \"0b\"\n        + binary_number[0] * shift_amount\n        + binary_number[: len(binary_number) - shift_amount]\n    )", "blocks": [{"id": 1, "label": "def arithmetic_right_shift(number: int, shift_amount: int) -> str:", "successors": [{"id": 2, "label": "if number >= 0:\n    binary_number = \"0\" + str(bin(number)).strip(\"-\")[2:]", "successors": [{"id": 5, "label": "if shift_amount >= len(binary_number):", "successors": [{"id": 6, "label": "    return \"0b\" + binary_number[0] * len(binary_number)", "successors": []}, {"id": 7, "label": "return (\"0b\" + binary_number[0] * shift_amount + binary_number[: len(binary_number) - shift_amount])", "successors": []}]}]}, {"id": 4, "label": "else:\n    binary_number_length = len(bin(number)[3:])", "successors": [{"id": 9, "label": "    binary_number = bin(abs(number) - (1 << binary_number_length))[3:]\n    binary_number = (\"1\" + \"0\" * (binary_number_length - len(binary_number)) + binary_number)", "successors": [{"id": 5, "label": "if shift_amount >= len(binary_number):", "successors": [{"id": 6, "label": "    return \"0b\" + binary_number[0] * len(binary_number)", "successors": []}, {"id": 7, "label": "return (\"0b\" + binary_number[0] * shift_amount + binary_number[: len(binary_number) - shift_amount])", "successors": []}]}]}]}]}]}], "classes": [], "simplified_code": "# Information on binary shifts:\n# https://docs.python.org/3/library/stdtypes.html#bitwise-operations-on-integer-types\n# https://www.interviewcake.com/concept/java/bit-shift\n\n\n    return binary_number\n\n\n    return \"0b\" + shifted_binary_number\n\n\n    )\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()", "blocks": [{"id": 1, "label": "if __name__ == \"__main__\":\n    import doctest", "successors": [{"id": 3, "label": "    doctest.testmod()", "successors": []}]}]}
{"file_name": "110.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 34, "functions": [], "classes": [], "simplified_code": "import prisma\n\nAGENT_NODE_INCLUDE: prisma.types.AgentNodeInclude = {\n    \"Input\": True,\n    \"Output\": True,\n    \"Webhook\": True,\n    \"AgentBlock\": True,\n}\n\nAGENT_GRAPH_INCLUDE: prisma.types.AgentGraphInclude = {\n    \"AgentNodes\": {\"include\": AGENT_NODE_INCLUDE}  # type: ignore\n}\n\nEXECUTION_RESULT_INCLUDE: prisma.types.AgentNodeExecutionInclude = {\n    \"Input\": True,\n    \"Output\": True,\n    \"AgentNode\": True,\n    \"AgentGraphExecution\": True,\n}\n\nGRAPH_EXECUTION_INCLUDE: prisma.types.AgentGraphExecutionInclude = {\n    \"AgentNodeExecutions\": {\n        \"include\": {\n            \"Input\": True,\n            \"Output\": True,\n            \"AgentNode\": True,\n            \"AgentGraphExecution\": True,\n        }\n    }\n}\n\nINTEGRATION_WEBHOOK_INCLUDE: prisma.types.IntegrationWebhookInclude = {\n    \"AgentNodes\": {\"include\": AGENT_NODE_INCLUDE}  # type: ignore\n}", "blocks": [{"id": 1, "label": "import prisma\nAGENT_NODE_INCLUDE: prisma.types.AgentNodeInclude = {\n    \"Input\": True,\n    \"Output\": True,\n    \"Webhook\": True,\n    \"AgentBlock\": True,\n}", "successors": [{"id": 3, "label": "AGENT_GRAPH_INCLUDE: prisma.types.AgentGraphInclude = {\n    \"AgentNodes\": {\"include\": AGENT_NODE_INCLUDE}  # type: ignore\n}\nEXECUTION_RESULT_INCLUDE: prisma.types.AgentNodeExecutionInclude = {\n    \"Input\": True,\n    \"Output\": True,\n    \"AgentNode\": True,\n    \"AgentGraphExecution\": True,\n}", "successors": [{"id": 5, "label": "GRAPH_EXECUTION_INCLUDE: prisma.types.AgentGraphExecutionInclude = {\n    \"AgentNodeExecutions\": {\n        \"include\": {\n            \"Input\": True,\n            \"Output\": True,\n            \"AgentNode\": True,\n            \"AgentGraphExecution\": True,\n        }\n    }\n}\nINTEGRATION_WEBHOOK_INCLUDE: prisma.types.IntegrationWebhookInclude = {\n    \"AgentNodes\": {\"include\": AGENT_NODE_INCLUDE}  # type: ignore\n}", "successors": []}]}]}]}
{"file_name": "111.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 8, "functions": [{"name": "sentry_init", "type": "function", "start_line": 6, "end_line": 8, "functions": [], "classes": [], "simplified_code": "def sentry_init():\n    sentry_dsn = Settings().secrets.sentry_dsn\n    sentry_sdk.init(dsn=sentry_dsn, traces_sample_rate=1.0, profiles_sample_rate=1.0)", "blocks": [{"id": 1, "label": "def sentry_init():\nsentry_dsn = Settings().secrets.sentry_dsn\nsentry_sdk.init(dsn=sentry_dsn, traces_sample_rate=1.0, profiles_sample_rate=1.0)", "successors": []}]}], "classes": [], "simplified_code": "import sentry_sdk\n\nfrom backend.util.settings import Settings\n\n\n    sentry_sdk.init(dsn=sentry_dsn, traces_sample_rate=1.0, profiles_sample_rate=1.0)", "blocks": [{"id": 1, "label": "import sentry_sdk\nfrom backend.util.settings import Settings", "successors": [{"id": 3, "label": "sentry_sdk.init(dsn=sentry_dsn, traces_sample_rate=1.0, profiles_sample_rate=1.0)", "successors": []}]}]}
{"file_name": "112.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 12, "functions": [], "classes": [{"name": "MockObject", "type": "class", "start_line": 1, "end_line": 12, "functions": [{"name": "__init__", "type": "function", "start_line": 2, "end_line": 3, "functions": [], "classes": [], "simplified_code": "    def __init__(self, **kwargs):\n        self.__dict__.update(kwargs)", "blocks": [{"id": 1, "label": "def __init__(self, **kwargs):\n    self.__dict__.update(kwargs)", "successors": []}]}, {"name": "__getattr__", "type": "function", "start_line": 5, "end_line": 6, "functions": [], "classes": [], "simplified_code": "    def __getattr__(self, name):\n        return self.__dict__.get(name)", "blocks": [{"id": 1, "label": "def __getattr__(self, name):\n    return self.__dict__.get(name)", "successors": []}]}, {"name": "__call__", "type": "function", "start_line": 8, "end_line": 9, "functions": [], "classes": [], "simplified_code": "    def __call__(self, *args, **kwargs):\n        return self", "blocks": [{"id": 1, "label": "def __call__(self, *args, **kwargs):\n    return self", "successors": []}]}, {"name": "__setattr__", "type": "function", "start_line": 11, "end_line": 12, "functions": [], "classes": [], "simplified_code": "    def __setattr__(self, name, value):\n        self.__dict__[name] = value", "blocks": [{"id": 1, "label": "def __setattr__(self, name, value):\n    self.__dict__[name] = value", "successors": []}]}], "simplified_code": "class MockObject:\n        self.__dict__.update(kwargs)\n\n        return self.__dict__.get(name)\n\n        return self\n\n        self.__dict__[name] = value", "blocks": [{"id": 1, "label": "class MockObject:", "successors": [{"id": 2, "label": "self.__dict__.update(kwargs)", "successors": []}, {"id": 3, "label": "return self.__dict__.get(name)", "successors": []}, {"id": 4, "label": "return self", "successors": []}, {"id": 5, "label": "self.__dict__[name] = value", "successors": []}]}]}], "simplified_code": "        self.__dict__[name] = value", "blocks": [{"id": 1, "label": "self.__dict__[name] = value", "successors": []}]}
{"file_name": "113.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 148, "functions": [], "classes": [{"name": "Place", "type": "class", "start_line": 30, "end_line": 36, "functions": [], "simplified_code": "class Place(BaseModel):\n    name: str\n    address: str\n    phone: str\n    rating: float\n    reviews: int\n    website: str", "blocks": [{"id": 1, "label": "class Place(BaseModel):\n    name: str\n    address: str\n    phone: str\n    rating: float\n    reviews: int\n    website: str", "successors": []}]}, {"name": "GoogleMapsSearchBlock", "type": "class", "start_line": 39, "end_line": 148, "functions": [{"name": "__init__", "type": "function", "start_line": 65, "end_line": 104, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"f47ac10b-58cc-4372-a567-0e02b2c3d479\",\n            description=\"This block searches for local businesses using Google Maps API.\",\n            categories={BlockCategory.SEARCH},\n            input_schema=GoogleMapsSearchBlock.Input,\n            output_schema=GoogleMapsSearchBlock.Output,\n            test_input={\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n                \"query\": \"restaurants in new york\",\n                \"radius\": 5000,\n                \"max_results\": 5,\n            },\n            test_output=[\n                (\n                    \"place\",\n                    {\n                        \"name\": \"Test Restaurant\",\n                        \"address\": \"123 Test St, New York, NY 10001\",\n                        \"phone\": \"+1 (555) 123-4567\",\n                        \"rating\": 4.5,\n                        \"reviews\": 100,\n                        \"website\": \"https://testrestaurant.com\",\n                    },\n                ),\n            ],\n            test_mock={\n                \"search_places\": lambda *args, **kwargs: [\n                    {\n                        \"name\": \"Test Restaurant\",\n                        \"address\": \"123 Test St, New York, NY 10001\",\n                        \"phone\": \"+1 (555) 123-4567\",\n                        \"rating\": 4.5,\n                        \"reviews\": 100,\n                        \"website\": \"https://testrestaurant.com\",\n                    }\n                ]\n            },\n            test_credentials=TEST_CREDENTIALS,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"f47ac10b-58cc-4372-a567-0e02b2c3d479\",\n    description=\"This block searches for local businesses using Google Maps API.\",\n    categories={BlockCategory.SEARCH},\n    input_schema=GoogleMapsSearchBlock.Input,\n    output_schema=GoogleMapsSearchBlock.Output,\n    test_input={\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n        \"query\": \"restaurants in new york\",\n        \"radius\": 5000,\n        \"max_results\": 5,\n    },\n    test_output=[\n        (\n            \"place\",\n            {\n                \"name\": \"Test Restaurant\",\n                \"address\": \"123 Test St, New York, NY 10001\",\n                \"phone\": \"+1 (555) 123-4567\",\n                \"rating\": 4.5,\n                \"reviews\": 100,\n                \"website\": \"https://testrestaurant.com\",\n            },\n        ),\n    ],\n    test_mock={\n        \"search_places\": lambda *args, **kwargs: [\n            {\n                \"name\": \"Test Restaurant\",\n                \"address\": \"123 Test St, New York, NY 10001\",\n                \"phone\": \"+1 (555) 123-4567\",\n                \"rating\": 4.5,\n                \"reviews\": 100,\n                \"website\": \"https://testrestaurant.com\",\n            }\n        ]\n    },\n    test_credentials=TEST_CREDENTIALS,\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 106, "end_line": 116, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        places = self.search_places(\n            credentials.api_key,\n            input_data.query,\n            input_data.radius,\n            input_data.max_results,\n        )\n        for place in places:\n            yield \"place\", place", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs) -> BlockOutput:\nplaces = self.search_places(credentials.api_key, input_data.query, input_data.radius, input_data.max_results, )", "successors": [{"id": 3, "label": "for place in places:", "successors": [{"id": 4, "label": "    yield \"place\", place", "successors": []}]}]}]}, {"name": "search_places", "type": "function", "start_line": 118, "end_line": 120, "functions": [], "classes": [], "simplified_code": "    def search_places(self, api_key: SecretStr, query, radius, max_results):\n        client = googlemaps.Client(key=api_key.get_secret_value())\n        return self._search_places(client, query, radius, max_results)", "blocks": [{"id": 1, "label": "def search_places(self, api_key: SecretStr, query, radius, max_results):\n    client = googlemaps.Client(key=api_key.get_secret_value())", "successors": [{"id": 3, "label": "    return self._search_places(client, query, radius, max_results)", "successors": []}]}]}, {"name": "_search_places", "type": "function", "start_line": 122, "end_line": 148, "functions": [], "classes": [], "simplified_code": "    def _search_places(self, client, query, radius, max_results):\n        results = []\n        next_page_token = None\n        while len(results) < max_results:\n            response = client.places(\n                query=query,\n                radius=radius,\n                page_token=next_page_token,\n            )\n            for place in response[\"results\"]:\n                if len(results) >= max_results:\n                    break\n                place_details = client.place(place[\"place_id\"])[\"result\"]\n                results.append(\n                    Place(\n                        name=place_details.get(\"name\", \"\"),\n                        address=place_details.get(\"formatted_address\", \"\"),\n                        phone=place_details.get(\"formatted_phone_number\", \"\"),\n                        rating=place_details.get(\"rating\", 0),\n                        reviews=place_details.get(\"user_ratings_total\", 0),\n                        website=place_details.get(\"website\", \"\"),\n                    )\n                )\n            next_page_token = response.get(\"next_page_token\")\n            if not next_page_token:\n                break\n        return results", "blocks": [{"id": 1, "label": "def _search_places(self, client, query, radius, max_results):\n    results = []\n    next_page_token = None", "successors": [{"id": 2, "label": "while len(results) < max_results:", "successors": [{"id": 3, "label": "    response = client.places(\n        query=query,\n        radius=radius,\n        page_token=next_page_token,\n    )", "successors": [{"id": 4, "label": "for place in response[\"results\"]:", "successors": [{"id": 5, "label": "    if len(results) >= max_results:\n        break", "successors": [{"id": 9, "label": "next_page_token = response.get(\"next_page_token\")\nif not next_page_token:", "successors": [{"id": 11, "label": "    break\nreturn results", "successors": []}, {"id": 12, "label": "return results", "successors": []}]}]}, {"id": 7, "label": "    place_details = client.place(place[\"place_id\"])[\"result\"]\n    results.append(\n        Place(\n            name=place_details.get(\"name\", \"\"),\n            address=place_details.get(\"formatted_address\", \"\"),\n            phone=place_details.get(\"formatted_phone_number\", \"\"),\n            rating=place_details.get(\"rating\", 0),\n            reviews=place_details.get(\"user_ratings_total\", 0),\n            website=place_details.get(\"website\", \"\"),\n        )\n    )\nnext_page_token = response.get(\"next_page_token\")", "successors": [{"id": 10, "label": "if not next_page_token:", "successors": [{"id": 11, "label": "    break\nreturn results", "successors": []}, {"id": 12, "label": "return results", "successors": []}]}]}]}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 40, "end_line": 59, "functions": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: CredentialsMetaInput[\n            Literal[ProviderName.GOOGLE_MAPS], Literal[\"api_key\"]\n        ] = CredentialsField(description=\"Google Maps API Key\")\n        query: str = SchemaField(\n            description=\"Search query for local businesses\",\n            placeholder=\"e.g., 'restaurants in New York'\",\n        )\n        radius: int = SchemaField(\n            description=\"Search radius in meters (max 50000)\",\n            default=5000,\n            ge=1,\n            le=50000,\n        )\n        max_results: int = SchemaField(\n            description=\"Maximum number of results to return (max 60)\",\n            default=20,\n            ge=1,\n            le=60,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\ncredentials: CredentialsMetaInput[\n    Literal[ProviderName.GOOGLE_MAPS], Literal[\"api_key\"]\n] = CredentialsField(description=\"Google Maps API Key\")", "successors": [{"id": 3, "label": "query: str = SchemaField(\n    description=\"Search query for local businesses\",\n    placeholder=\"e.g., 'restaurants in New York'\",\n)\nradius: int = SchemaField(\n    description=\"Search radius in meters (max 50000)\",\n    default=5000,\n    ge=1,\n    le=50000,\n)", "successors": [{"id": 5, "label": "max_results: int = SchemaField(\n    description=\"Maximum number of results to return (max 60)\",\n    default=20,\n    ge=1,\n    le=60,\n)", "successors": []}]}]}]}, {"name": "Output", "type": "class", "start_line": 61, "end_line": 63, "functions": [], "simplified_code": "    class Output(BlockSchema):\n        place: Place = SchemaField(description=\"Place found\")\n        error: str = SchemaField(description=\"Error message if the search failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    place: Place = SchemaField(description=\"Place found\")\n    error: str = SchemaField(description=\"Error message if the search failed\")", "successors": []}]}], "simplified_code": "class GoogleMapsSearchBlock(Block):\n        )\n\n        error: str = SchemaField(description=\"Error message if the search failed\")\n\n        )\n\n            yield \"place\", place\n\n        return self._search_places(client, query, radius, max_results)\n\n        return results", "blocks": [{"id": 1, "label": "class GoogleMapsSearchBlock(Block):\nerror: str = SchemaField(description=\"Error message if the search failed\")", "successors": [{"id": 3, "label": "yield \"place\", place", "successors": [{"id": 4, "label": "return self._search_places(client, query, radius, max_results)", "successors": []}, {"id": 5, "label": "return results", "successors": []}]}]}]}], "simplified_code": "from typing import Literal\n\nimport googlemaps\nfrom pydantic import BaseModel, SecretStr\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"google_maps\",\n    api_key=SecretStr(\"mock-google-maps-api-key\"),\n    title=\"Mock Google Maps API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.type,\n}\n\n\n    website: str\n\n\n        return results", "blocks": [{"id": 1, "label": "from typing import Literal\n\nimport googlemaps\nfrom pydantic import BaseModel, SecretStr\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"google_maps\",\n    api_key=SecretStr(\"mock-google-maps-api-key\"),\n    title=\"Mock Google Maps API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.type,\n}\n\n\n    website: str", "successors": []}]}
{"file_name": "114.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 18, "functions": [{"name": "main", "type": "function", "start_line": 6, "end_line": 14, "functions": [], "classes": [], "simplified_code": "def main():\n    \"\"\"\n    Run all the processes required for the AutoGPT-server REST API.\n    \"\"\"\n    run_processes(\n        DatabaseManager(),\n        ExecutionScheduler(),\n        AgentServer(),\n    )", "blocks": [{"id": 1, "label": "def main():\n\"\"\"\nRun all the processes required for the AutoGPT-server REST API.\n\"\"\"", "successors": [{"id": 3, "label": "run_processes(\n    DatabaseManager(),\n    ExecutionScheduler(),\n    AgentServer(),\n)", "successors": []}]}]}], "classes": [], "simplified_code": "from backend.app import run_processes\nfrom backend.executor import DatabaseManager, ExecutionScheduler\nfrom backend.server.rest_api import AgentServer\n\n\n    )\n\n\nif __name__ == \"__main__\":\n    main()", "blocks": [{"id": 1, "label": "from backend.app import run_processes\nfrom backend.executor import DatabaseManager, ExecutionScheduler\nfrom backend.server.rest_api import AgentServer\nif __name__ == \"__main__\":", "successors": [{"id": 3, "label": "    main()", "successors": []}]}]}
{"file_name": "115.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 37, "functions": [{"name": "JinaCredentialsField", "type": "function", "start_line": 15, "end_line": 22, "functions": [], "classes": [], "simplified_code": "def JinaCredentialsField() -> JinaCredentialsInput:\n    \"\"\"\n    Creates a Jina credentials input on a block.\n\n    \"\"\"\n    return CredentialsField(\n        description=\"The Jina integration can be used with an API Key.\",\n    )", "blocks": [{"id": 1, "label": "def JinaCredentialsField() -> JinaCredentialsInput:\n\"\"\"\n    Creates a Jina credentials input on a block.\n\n    \"\"\"", "successors": [{"id": 3, "label": "return CredentialsField(\n        description=\"The Jina integration can be used with an API Key.\"\n    )", "successors": []}]}]}], "classes": [], "simplified_code": "from typing import Literal\n\nfrom pydantic import SecretStr\n\nfrom backend.data.model import APIKeyCredentials, CredentialsField, CredentialsMetaInput\nfrom backend.integrations.providers import ProviderName\n\nJinaCredentials = APIKeyCredentials\nJinaCredentialsInput = CredentialsMetaInput[\n    Literal[ProviderName.JINA],\n    Literal[\"api_key\"],\n]\n\n\n    )\n\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"jina\",\n    api_key=SecretStr(\"mock-jina-api-key\"),\n    title=\"Mock Jina API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.type,\n}", "blocks": [{"id": 1, "label": "from typing import Literal\nfrom pydantic import SecretStr", "successors": [{"id": 3, "label": "from backend.data.model import APIKeyCredentials, CredentialsField, CredentialsMetaInput\nfrom backend.integrations.providers import ProviderName", "successors": [{"id": 5, "label": "JinaCredentials = APIKeyCredentials\nJinaCredentialsInput = CredentialsMetaInput[Literal[ProviderName.JINA], Literal[\"api_key\"]]", "successors": [{"id": 7, "label": "TEST_CREDENTIALS = APIKeyCredentials(id=\"01234567-89ab-cdef-0123-456789abcdef\", provider=\"jina\", api_key=SecretStr(\"mock-jina-api-key\"), title=\"Mock Jina API key\", expires_at=None)\nTEST_CREDENTIALS_INPUT = {\"provider\": TEST_CREDENTIALS.provider, \"id\": TEST_CREDENTIALS.id, \"type\": TEST_CREDENTIALS.type, \"title\": TEST_CREDENTIALS.type}", "successors": []}]}]}]}]}
{"file_name": "116.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 95, "functions": [], "classes": [{"name": "FancyConsoleFormatter", "type": "class", "start_line": 9, "end_line": 51, "functions": [{"name": "format", "type": "function", "start_line": 29, "end_line": 50, "functions": [], "classes": [], "simplified_code": "    def format(self, record: logging.LogRecord) -> str:\n        # Make sure `msg` is a string\n        if not hasattr(record, \"msg\"):\n            record.msg = \"\"\n        elif type(record.msg) is not str:\n            record.msg = str(record.msg)\n\n        # Determine default color based on error level\n        level_color = \"\"\n        if record.levelno in self.LEVEL_COLOR_MAP:\n            level_color = self.LEVEL_COLOR_MAP[record.levelno]\n            record.levelname = f\"{level_color}{record.levelname}{Style.RESET_ALL}\"\n\n        # Determine color for message\n        color = getattr(record, \"color\", level_color)\n        color_is_specified = hasattr(record, \"color\")\n\n        # Don't color INFO messages unless the color is explicitly specified.\n        if color and (record.levelno != logging.INFO or color_is_specified):\n            record.msg = f\"{color}{record.msg}{Style.RESET_ALL}\"\n\n        return super().format(record)", "blocks": [{"id": 1, "label": "def format(self, record: logging.LogRecord) -> str:", "successors": [{"id": 2, "label": "if not hasattr(record, \"msg\"):\n    record.msg = \"\"", "successors": [{"id": 6, "label": "level_color = \"\"\nif record.levelno in self.LEVEL_COLOR_MAP:", "successors": [{"id": 8, "label": "    level_color = self.LEVEL_COLOR_MAP[record.levelno]\n    record.levelname = f\"{level_color}{record.levelname}{Style.RESET_ALL}\"\ncolor = getattr(record, \"color\", level_color)\ncolor_is_specified = hasattr(record, \"color\")", "successors": [{"id": 12, "label": "if color and (record.levelno != logging.INFO or color_is_specified):", "successors": [{"id": 13, "label": "    record.msg = f\"{color}{record.msg}{Style.RESET_ALL}\"\nreturn super().format(record)", "successors": []}, {"id": 14, "label": "return super().format(record)", "successors": []}]}]}, {"id": 11, "label": "color = getattr(record, \"color\", level_color)\ncolor_is_specified = hasattr(record, \"color\")\nif color and (record.levelno != logging.INFO or color_is_specified):", "successors": [{"id": 13, "label": "    record.msg = f\"{color}{record.msg}{Style.RESET_ALL}\"\nreturn super().format(record)", "successors": []}, {"id": 14, "label": "return super().format(record)", "successors": []}]}]}]}, {"id": 4, "label": "elif type(record.msg) is not str:\n    record.msg = str(record.msg)", "successors": [{"id": 6, "label": "level_color = \"\"\nif record.levelno in self.LEVEL_COLOR_MAP:", "successors": [{"id": 8, "label": "    level_color = self.LEVEL_COLOR_MAP[record.levelno]\n    record.levelname = f\"{level_color}{record.levelname}{Style.RESET_ALL}\"\ncolor = getattr(record, \"color\", level_color)\ncolor_is_specified = hasattr(record, \"color\")", "successors": [{"id": 12, "label": "if color and (record.levelno != logging.INFO or color_is_specified):", "successors": [{"id": 13, "label": "    record.msg = f\"{color}{record.msg}{Style.RESET_ALL}\"\nreturn super().format(record)", "successors": []}, {"id": 14, "label": "return super().format(record)", "successors": []}]}]}, {"id": 11, "label": "color = getattr(record, \"color\", level_color)\ncolor_is_specified = hasattr(record, \"color\")\nif color and (record.levelno != logging.INFO or color_is_specified):", "successors": [{"id": 13, "label": "    record.msg = f\"{color}{record.msg}{Style.RESET_ALL}\"\nreturn super().format(record)", "successors": []}, {"id": 14, "label": "return super().format(record)", "successors": []}]}]}]}, {"id": 6, "label": "level_color = \"\"\nif record.levelno in self.LEVEL_COLOR_MAP:", "successors": [{"id": 8, "label": "    level_color = self.LEVEL_COLOR_MAP[record.levelno]\n    record.levelname = f\"{level_color}{record.levelname}{Style.RESET_ALL}\"\ncolor = getattr(record, \"color\", level_color)\ncolor_is_specified = hasattr(record, \"color\")", "successors": [{"id": 12, "label": "if color and (record.levelno != logging.INFO or color_is_specified):", "successors": [{"id": 13, "label": "    record.msg = f\"{color}{record.msg}{Style.RESET_ALL}\"\nreturn super().format(record)", "successors": []}, {"id": 14, "label": "return super().format(record)", "successors": []}]}]}, {"id": 11, "label": "color = getattr(record, \"color\", level_color)\ncolor_is_specified = hasattr(record, \"color\")\nif color and (record.levelno != logging.INFO or color_is_specified):", "successors": [{"id": 13, "label": "    record.msg = f\"{color}{record.msg}{Style.RESET_ALL}\"\nreturn super().format(record)", "successors": []}, {"id": 14, "label": "return super().format(record)", "successors": []}]}]}]}]}], "simplified_code": "class FancyConsoleFormatter(logging.Formatter):\n    \"\"\"\n    A custom logging formatter designed for console output.\n\n    This formatter enhances the standard logging output with color coding. The color\n    coding is based on the level of the log message, making it easier to distinguish\n    between different types of messages in the console output.\n\n    The color for each level is defined in the LEVEL_COLOR_MAP class attribute.\n    \"\"\"\n\n    # level -> (level & text color, title color)\n    LEVEL_COLOR_MAP = {\n        logging.DEBUG: Fore.LIGHTBLACK_EX,\n        logging.INFO: Fore.BLUE,\n        logging.WARNING: Fore.YELLOW,\n        logging.ERROR: Fore.RED,\n        logging.CRITICAL: Fore.RED + Style.BRIGHT,\n    }\n\n        return super().format(record)\n", "blocks": [{"id": 1, "label": "class FancyConsoleFormatter(logging.Formatter):\n\"\"\"\n    A custom logging formatter designed for console output.\n\n    This formatter enhances the standard logging output with color coding. The color\n    coding is based on the level of the log message, making it easier to distinguish\n    between different types of messages in the console output.\n\n    The color for each level is defined in the LEVEL_COLOR_MAP class attribute.\n    \"\"\"", "successors": [{"id": 3, "label": "LEVEL_COLOR_MAP = {\n    logging.DEBUG: Fore.LIGHTBLACK_EX,\n    logging.INFO: Fore.BLUE,\n    logging.WARNING: Fore.YELLOW,\n    logging.ERROR: Fore.RED,\n    logging.CRITICAL: Fore.RED + Style.BRIGHT,\n}\nreturn super().format(record)", "successors": []}]}]}, {"name": "AGPTFormatter", "type": "class", "start_line": 53, "end_line": 83, "functions": [{"name": "__init__", "type": "function", "start_line": 54, "end_line": 56, "functions": [], "classes": [], "simplified_code": "    def __init__(self, *args, no_color: bool = False, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.no_color = no_color", "blocks": [{"id": 1, "label": "def __init__(self, *args, no_color: bool = False, **kwargs):\nsuper().__init__(*args, **kwargs)", "successors": [{"id": 3, "label": "self.no_color = no_color", "successors": []}]}]}, {"name": "format", "type": "function", "start_line": 58, "end_line": 82, "functions": [], "classes": [], "simplified_code": "    def format(self, record: logging.LogRecord) -> str:\n        # Make sure `msg` is a string\n        if not hasattr(record, \"msg\"):\n            record.msg = \"\"\n        elif type(record.msg) is not str:\n            record.msg = str(record.msg)\n\n        # Strip color from the message to prevent color spoofing\n        if record.msg and not getattr(record, \"preserve_color\", False):\n            record.msg = remove_color_codes(record.msg)\n\n        # Determine color for title\n        title = getattr(record, \"title\", \"\")\n        title_color = getattr(record, \"title_color\", \"\") or self.LEVEL_COLOR_MAP.get(\n            record.levelno, \"\"\n        )\n        if title and title_color:\n            title = f\"{title_color + Style.BRIGHT}{title}{Style.RESET_ALL}\"\n        # Make sure record.title is set, and padded with a space if not empty\n        record.title = f\"{title} \" if title else \"\"\n\n        if self.no_color:\n            return remove_color_codes(super().format(record))\n        else:\n            return super().format(record)", "blocks": [{"id": 1, "label": "def format(self, record: logging.LogRecord) -> str:", "successors": [{"id": 2, "label": "if not hasattr(record, \"msg\"):", "successors": [{"id": 3, "label": "    record.msg = \"\"", "successors": []}, {"id": 4, "label": "elif type(record.msg) is not str:\n    record.msg = str(record.msg)", "successors": []}]}, {"id": 6, "label": "if record.msg and not getattr(record, \"preserve_color\", False):\n    record.msg = remove_color_codes(record.msg)", "successors": []}, {"id": 8, "label": "title = getattr(record, \"title\", \"\")\ntitle_color = getattr(record, \"title_color\", \"\") or self.LEVEL_COLOR_MAP.get(record.levelno, \"\")", "successors": [{"id": 9, "label": "if title and title_color:\n    title = f\"{title_color + Style.BRIGHT}{title}{Style.RESET_ALL}\"", "successors": []}, {"id": 11, "label": "record.title = f\"{title} \" if title else \"\"", "successors": []}]}, {"id": 12, "label": "if self.no_color:", "successors": [{"id": 13, "label": "    return remove_color_codes(super().format(record))", "successors": []}, {"id": 14, "label": "else:\n    return super().format(record)", "successors": []}]}]}]}], "simplified_code": "class AGPTFormatter(FancyConsoleFormatter):\n        self.no_color = no_color\n\n            return super().format(record)\n", "blocks": [{"id": 1, "label": "class AGPTFormatter(FancyConsoleFormatter):\nself.no_color = no_color", "successors": [{"id": 3, "label": "return super().format(record)", "successors": []}]}]}, {"name": "StructuredLoggingFormatter", "type": "class", "start_line": 85, "end_line": 95, "functions": [{"name": "__init__", "type": "function", "start_line": 86, "end_line": 91, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        # Set up CloudLoggingFilter to add diagnostic info to the log records\n        self.cloud_logging_filter = CloudLoggingFilter()\n\n        # Init StructuredLogHandler\n        super().__init__()", "blocks": [{"id": 1, "label": "def __init__(self):\n    self.cloud_logging_filter = CloudLoggingFilter()", "successors": [{"id": 3, "label": "    super().__init__()", "successors": []}]}]}, {"name": "format", "type": "function", "start_line": 93, "end_line": 95, "functions": [], "classes": [], "simplified_code": "    def format(self, record: logging.LogRecord) -> str:\n        self.cloud_logging_filter.filter(record)\n        return super().format(record)", "blocks": [{"id": 1, "label": "def format(self, record: logging.LogRecord) -> str:\n    self.cloud_logging_filter.filter(record)", "successors": [{"id": 3, "label": "    return super().format(record)", "successors": []}]}]}], "simplified_code": "class StructuredLoggingFormatter(StructuredLogHandler, logging.Formatter):\n        super().__init__()\n\n        return super().format(record)", "blocks": [{"id": 1, "label": "class StructuredLoggingFormatter(StructuredLogHandler, logging.Formatter):\nsuper().__init__()", "successors": [{"id": 3, "label": "return super().format(record)", "successors": []}]}]}], "simplified_code": "import logging\n\nfrom colorama import Fore, Style\nfrom google.cloud.logging_v2.handlers import CloudLoggingFilter, StructuredLogHandler\n\nfrom .utils import remove_color_codes\n\n\n\n\n\n\n        return super().format(record)", "blocks": [{"id": 1, "label": "import logging\nfrom colorama import Fore, Style", "successors": [{"id": 3, "label": "from google.cloud.logging_v2.handlers import CloudLoggingFilter, StructuredLogHandler\nfrom .utils import remove_color_codes", "successors": [{"id": 5, "label": "return super().format(record)", "successors": []}]}]}]}
{"file_name": "117.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 11, "functions": [{"name": "test_available_blocks", "type": "function", "start_line": 10, "end_line": 11, "functions": [], "classes": [], "simplified_code": "def test_available_blocks(block: Type[Block]):\n    execute_block_test(block())", "blocks": [{"id": 1, "label": "def test_available_blocks(block: Type[Block]):\nexecute_block_test(block())", "successors": []}]}], "classes": [], "simplified_code": "from typing import Type\n\nimport pytest\n\nfrom backend.data.block import Block, get_blocks\nfrom backend.util.test import execute_block_test\n\n\n@pytest.mark.parametrize(\"block\", get_blocks().values(), ids=lambda b: b.name)\n    execute_block_test(block())", "blocks": [{"id": 1, "label": "from typing import Type\n\nimport pytest\n\nfrom backend.data.block import Block, get_blocks\nfrom backend.util.test import execute_block_test\n\n\n@pytest.mark.parametrize(\"block\", get_blocks().values(), ids=lambda b: b.name)\nexecute_block_test(block())", "successors": []}]}
{"file_name": "118.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 77, "functions": [{"name": "backtrack", "type": "function", "start_line": 11, "end_line": 45, "functions": [], "classes": [], "simplified_code": "def backtrack(\n    partial: str, open_count: int, close_count: int, n: int, result: list[str]\n) -> None:\n    \"\"\"\n    Generate valid combinations of balanced parentheses using recursion.\n\n    :param partial: A string representing the current combination.\n    :param open_count: An integer representing the count of open parentheses.\n    :param close_count: An integer representing the count of close parentheses.\n    :param n: An integer representing the total number of pairs.\n    :param result: A list to store valid combinations.\n    :return: None\n\n    This function uses recursion to explore all possible combinations,\n    ensuring that at each step, the parentheses remain balanced.\n\n    Example:\n    >>> result = []\n    >>> backtrack(\"\", 0, 0, 2, result)\n    >>> result\n    ['(())', '()()']\n    \"\"\"\n    if len(partial) == 2 * n:\n        # When the combination is complete, add it to the result.\n        result.append(partial)\n        return\n\n    if open_count < n:\n        # If we can add an open parenthesis, do so, and recurse.\n        backtrack(partial + \"(\", open_count + 1, close_count, n, result)\n\n    if close_count < open_count:\n        # If we can add a close parenthesis (it won't make the combination invalid),\n        # do so, and recurse.\n        backtrack(partial + \")\", open_count, close_count + 1, n, result)", "blocks": [{"id": 1, "label": "def backtrack(\n    partial: str, open_count: int, close_count: int, n: int, result: list[str]\n) -> None:\n    \"\"\"\n    Generate valid combinations of balanced parentheses using recursion.\n\n    :param partial: A string representing the current combination.\n    :param open_count: An integer representing the count of open parentheses.\n    :param close_count: An integer representing the count of close parentheses.\n    :param n: An integer representing the total number of pairs.\n    :param result: A list to store valid combinations.\n    :return: None\n\n    This function uses recursion to explore all possible combinations,\n    ensuring that at each step, the parentheses remain balanced.\n\n    Example:\n    >>> result = []\n    >>> backtrack(\"\", 0, 0, 2, result)\n    >>> result\n    ['(())', '()()']\n    \"\"\"", "successors": [{"id": 2, "label": "if len(partial) == 2 * n:\nresult.append(partial)\nreturn", "successors": []}, {"id": 4, "label": "if open_count < n:\nbacktrack(partial + \"(\", open_count + 1, close_count, n, result)", "successors": []}, {"id": 6, "label": "if close_count < open_count:\nbacktrack(partial + \")\", open_count, close_count + 1, n, result)", "successors": []}]}]}, {"name": "generate_parenthesis", "type": "function", "start_line": 48, "end_line": 71, "functions": [], "classes": [], "simplified_code": "def generate_parenthesis(n: int) -> list[str]:\n    \"\"\"\n    Generate valid combinations of balanced parentheses for a given n.\n\n    :param n: An integer representing the number of pairs of parentheses.\n    :return: A list of strings with valid combinations.\n\n    This function uses a recursive approach to generate the combinations.\n\n    Time Complexity: O(2^(2n)) - In the worst case, we have 2^(2n) combinations.\n    Space Complexity: O(n) - where 'n' is the number of pairs.\n\n    Example 1:\n    >>> generate_parenthesis(3)\n    ['((()))', '(()())', '(())()', '()(())', '()()()']\n\n    Example 2:\n    >>> generate_parenthesis(1)\n    ['()']\n    \"\"\"\n\n    result: list[str] = []\n    backtrack(\"\", 0, 0, n, result)\n    return result", "blocks": [{"id": 1, "label": "def generate_parenthesis(n: int) -> list[str]:\nresult: list[str] = []", "successors": [{"id": 3, "label": "backtrack(\"\", 0, 0, n, result)\nreturn result", "successors": []}]}]}], "classes": [], "simplified_code": "\"\"\"\nauthor: Aayush Soni\nGiven n pairs of parentheses, write a function to generate all\ncombinations of well-formed parentheses.\nInput: n = 2\nOutput: [\"(())\",\"()()\"]\nLeetcode link: https://leetcode.com/problems/generate-parentheses/description/\n\"\"\"\n\n\n        backtrack(partial + \")\", open_count, close_count + 1, n, result)\n\n\n    return result\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()", "blocks": [{"id": 1, "label": "backtrack(partial + \")\", open_count, close_count + 1, n, result)\nreturn result", "successors": []}]}
{"file_name": "119.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 93, "functions": [{"name": "get_set_bits_count_using_brian_kernighans_algorithm", "type": "function", "start_line": 4, "end_line": 30, "functions": [], "classes": [], "simplified_code": "def get_set_bits_count_using_brian_kernighans_algorithm(number: int) -> int:\n    \"\"\"\n    Count the number of set bits in a 32 bit integer\n    >>> get_set_bits_count_using_brian_kernighans_algorithm(25)\n    3\n    >>> get_set_bits_count_using_brian_kernighans_algorithm(37)\n    3\n    >>> get_set_bits_count_using_brian_kernighans_algorithm(21)\n    3\n    >>> get_set_bits_count_using_brian_kernighans_algorithm(58)\n    4\n    >>> get_set_bits_count_using_brian_kernighans_algorithm(0)\n    0\n    >>> get_set_bits_count_using_brian_kernighans_algorithm(256)\n    1\n    >>> get_set_bits_count_using_brian_kernighans_algorithm(-1)\n    Traceback (most recent call last):\n        ...\n    ValueError: the value of input must not be negative\n    \"\"\"\n    if number < 0:\n        raise ValueError(\"the value of input must not be negative\")\n    result = 0\n    while number:\n        number &= number - 1\n        result += 1\n    return result", "blocks": [{"id": 1, "label": "def get_set_bits_count_using_brian_kernighans_algorithm(number: int) -> int:\nif number < 0:", "successors": [{"id": 3, "label": "raise ValueError(\"the value of input must not be negative\")", "successors": []}, {"id": 4, "label": "result = 0", "successors": [{"id": 5, "label": "while number:", "successors": [{"id": 6, "label": "number &= number - 1\nresult += 1", "successors": [{"id": 5, "label": "while number:", "successors": [{"id": 6, "label": "number &= number - 1\nresult += 1", "successors": []}]}]}, {"id": 7, "label": "return result", "successors": []}]}]}]}]}, {"name": "get_set_bits_count_using_modulo_operator", "type": "function", "start_line": 33, "end_line": 60, "functions": [], "classes": [], "simplified_code": "def get_set_bits_count_using_modulo_operator(number: int) -> int:\n    \"\"\"\n    Count the number of set bits in a 32 bit integer\n    >>> get_set_bits_count_using_modulo_operator(25)\n    3\n    >>> get_set_bits_count_using_modulo_operator(37)\n    3\n    >>> get_set_bits_count_using_modulo_operator(21)\n    3\n    >>> get_set_bits_count_using_modulo_operator(58)\n    4\n    >>> get_set_bits_count_using_modulo_operator(0)\n    0\n    >>> get_set_bits_count_using_modulo_operator(256)\n    1\n    >>> get_set_bits_count_using_modulo_operator(-1)\n    Traceback (most recent call last):\n        ...\n    ValueError: the value of input must not be negative\n    \"\"\"\n    if number < 0:\n        raise ValueError(\"the value of input must not be negative\")\n    result = 0\n    while number:\n        if number % 2 == 1:\n            result += 1\n        number >>= 1\n    return result", "blocks": [{"id": 1, "label": "def get_set_bits_count_using_modulo_operator(number: int) -> int:", "successors": [{"id": 2, "label": "if number < 0:\nraise ValueError(\"the value of input must not be negative\")", "successors": []}, {"id": 4, "label": "result = 0", "successors": [{"id": 5, "label": "while number:", "successors": [{"id": 6, "label": "if number % 2 == 1:\nresult += 1", "successors": [{"id": 8, "label": "number >>= 1", "successors": [{"id": 5, "label": "while number:", "successors": []}]}]}, {"id": 8, "label": "number >>= 1", "successors": [{"id": 5, "label": "while number:", "successors": []}]}]}, {"id": 9, "label": "return result", "successors": []}]}]}]}, {"name": "benchmark", "type": "function", "start_line": 63, "end_line": 86, "functions": [{"name": "do_benchmark", "type": "function", "start_line": 69, "end_line": 82, "functions": [], "classes": [], "simplified_code": "    def do_benchmark(number: int) -> None:\n        setup = \"import __main__ as z\"\n        print(f\"Benchmark when {number = }:\")\n        print(f\"{get_set_bits_count_using_modulo_operator(number) = }\")\n        timing = timeit(\n            f\"z.get_set_bits_count_using_modulo_operator({number})\", setup=setup\n        )\n        print(f\"timeit() runs in {timing} seconds\")\n        print(f\"{get_set_bits_count_using_brian_kernighans_algorithm(number) = }\")\n        timing = timeit(\n            f\"z.get_set_bits_count_using_brian_kernighans_algorithm({number})\",\n            setup=setup,\n        )\n        print(f\"timeit() runs in {timing} seconds\")", "blocks": [{"id": 1, "label": "def do_benchmark(number: int) -> None:\n    setup = \"import __main__ as z\"\n    print(f\"Benchmark when {number = }:\")\n    print(f\"{get_set_bits_count_using_modulo_operator(number) = }\")", "successors": [{"id": 3, "label": "    timing = timeit(\n        f\"z.get_set_bits_count_using_modulo_operator({number})\", setup=setup\n    )\n    print(f\"timeit() runs in {timing} seconds\")\n    print(f\"{get_set_bits_count_using_brian_kernighans_algorithm(number) = }\")", "successors": [{"id": 5, "label": "    timing = timeit(\n        f\"z.get_set_bits_count_using_brian_kernighans_algorithm({number})\",\n        setup=setup,\n    )\n    print(f\"timeit() runs in {timing} seconds\")", "successors": []}]}]}]}], "classes": [], "simplified_code": "def benchmark() -> None:\n    \"\"\"\n    Benchmark code for comparing 2 functions, with different length int values.\n    Brian Kernighan's algorithm is consistently faster than using modulo_operator.\n    \"\"\"\n\n        print(f\"timeit() runs in {timing} seconds\")\n\n    for number in (25, 37, 58, 0):\n        do_benchmark(number)\n        print()", "blocks": [{"id": 1, "label": "def benchmark() -> None:\n    \"\"\"\n    Benchmark code for comparing 2 functions, with different length int values.\n    Brian Kernighan's algorithm is consistently faster than using modulo_operator.\n    \"\"\"\n\n    print(f\"timeit() runs in {timing} seconds\")", "successors": [{"id": 2, "label": "for number in (25, 37, 58, 0):", "successors": [{"id": 3, "label": "    do_benchmark(number)\n    print()", "successors": [{"id": 5, "label": "", "successors": []}]}, {"id": 5, "label": "", "successors": []}]}]}]}], "classes": [], "simplified_code": "from timeit import timeit\n\n\n    return result\n\n\n    return result\n\n\n        print()\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()\n    benchmark()", "blocks": [{"id": 1, "label": "from timeit import timeit\nif __name__ == \"__main__\":", "successors": [{"id": 3, "label": "    import doctest\n    doctest.testmod()", "successors": [{"id": 5, "label": "    benchmark()", "successors": []}]}]}]}
{"file_name": "120.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 462, "functions": [{"name": "get_blocks", "type": "function", "start_line": 418, "end_line": 421, "functions": [], "classes": [], "simplified_code": "def get_blocks() -> dict[str, Type[Block]]:\n    from backend.blocks import AVAILABLE_BLOCKS  # noqa: E402\n\n    return AVAILABLE_BLOCKS", "blocks": [{"id": 1, "label": "def get_blocks() -> dict[str, Type[Block]]:\n    from backend.blocks import AVAILABLE_BLOCKS  # noqa: E402", "successors": [{"id": 3, "label": "    return AVAILABLE_BLOCKS", "successors": []}]}]}, {"name": "initialize_blocks", "type": "function", "start_line": 424, "end_line": 457, "functions": [], "classes": [], "simplified_code": "async def initialize_blocks() -> None:\n    for cls in get_blocks().values():\n        block = cls()\n        existing_block = await AgentBlock.prisma().find_first(\n            where={\"OR\": [{\"id\": block.id}, {\"name\": block.name}]}\n        )\n        if not existing_block:\n            await AgentBlock.prisma().create(\n                data={\n                    \"id\": block.id,\n                    \"name\": block.name,\n                    \"inputSchema\": json.dumps(block.input_schema.jsonschema()),\n                    \"outputSchema\": json.dumps(block.output_schema.jsonschema()),\n                }\n            )\n            continue\n\n        input_schema = json.dumps(block.input_schema.jsonschema())\n        output_schema = json.dumps(block.output_schema.jsonschema())\n        if (\n            block.id != existing_block.id\n            or block.name != existing_block.name\n            or input_schema != existing_block.inputSchema\n            or output_schema != existing_block.outputSchema\n        ):\n            await AgentBlock.prisma().update(\n                where={\"id\": existing_block.id},\n                data={\n                    \"id\": block.id,\n                    \"name\": block.name,\n                    \"inputSchema\": input_schema,\n                    \"outputSchema\": output_schema,\n                },\n            )", "blocks": [{"id": 1, "label": "async def initialize_blocks() -> None:", "successors": [{"id": 2, "label": "for cls in get_blocks().values():", "successors": [{"id": 3, "label": "block = cls()\nexisting_block = await AgentBlock.prisma().find_first(where={\"OR\": [{\"id\": block.id}, {\"name\": block.name}]})", "successors": [{"id": 4, "label": "if not existing_block:", "successors": [{"id": 5, "label": "await AgentBlock.prisma().create(data={\"id\": block.id, \"name\": block.name, \"inputSchema\": json.dumps(block.input_schema.jsonschema()), \"outputSchema\": json.dumps(block.output_schema.jsonschema())})\ncontinue", "successors": [{"id": 2, "label": "for cls in get_blocks().values():", "successors": [{"id": 3, "label": "block = cls()\nexisting_block = await AgentBlock.prisma().find_first(where={\"OR\": [{\"id\": block.id}, {\"name\": block.name}]})", "successors": [{"id": 4, "label": "if not existing_block:", "successors": [{"id": 5, "label": "await AgentBlock.prisma().create(data={\"id\": block.id, \"name\": block.name, \"inputSchema\": json.dumps(block.input_schema.jsonschema()), \"outputSchema\": json.dumps(block.output_schema.jsonschema())})\ncontinue", "successors": [{"id": 2, "label": "for cls in get_blocks().values():", "successors": []}]}, {"id": 6, "label": "input_schema = json.dumps(block.input_schema.jsonschema())\noutput_schema = json.dumps(block.output_schema.jsonschema())\nawait AgentBlock.prisma().update(where={\"id\": existing_block.id}, data={\"id\": block.id, \"name\": block.name, \"inputSchema\": input_schema, \"outputSchema\": output_schema})", "successors": [{"id": 2, "label": "for cls in get_blocks().values():", "successors": []}]}]}, {"id": 6, "label": "input_schema = json.dumps(block.input_schema.jsonschema())\noutput_schema = json.dumps(block.output_schema.jsonschema())", "successors": []}]}]}]}, {"id": 6, "label": "input_schema = json.dumps(block.input_schema.jsonschema())\noutput_schema = json.dumps(block.output_schema.jsonschema())\nawait AgentBlock.prisma().update(where={\"id\": existing_block.id}, data={\"id\": block.id, \"name\": block.name, \"inputSchema\": input_schema, \"outputSchema\": output_schema})", "successors": [{"id": 2, "label": "for cls in get_blocks().values():", "successors": []}]}]}, {"id": 6, "label": "input_schema = json.dumps(block.input_schema.jsonschema())\noutput_schema = json.dumps(block.output_schema.jsonschema())", "successors": []}]}]}]}]}, {"name": "get_block", "type": "function", "start_line": 460, "end_line": 462, "functions": [], "classes": [], "simplified_code": "def get_block(block_id: str) -> Block | None:\n    cls = get_blocks().get(block_id)\n    return cls() if cls else None", "blocks": [{"id": 1, "label": "def get_block(block_id: str) -> Block | None:\ncls = get_blocks().get(block_id)", "successors": [{"id": 3, "label": "return cls() if cls else None", "successors": []}]}]}], "classes": [{"name": "BlockType", "type": "class", "start_line": 39, "end_line": 46, "functions": [], "classes": [], "simplified_code": "class BlockType(Enum):\n    STANDARD = \"Standard\"\n    INPUT = \"Input\"\n    OUTPUT = \"Output\"\n    NOTE = \"Note\"\n    WEBHOOK = \"Webhook\"\n    WEBHOOK_MANUAL = \"Webhook (manual)\"\n    AGENT = \"Agent\"", "blocks": [{"id": 1, "label": "class BlockType(Enum):\n    STANDARD = \"Standard\"\n    INPUT = \"Input\"\n    OUTPUT = \"Output\"\n    NOTE = \"Note\"\n    WEBHOOK = \"Webhook\"\n    WEBHOOK_MANUAL = \"Webhook (manual)\"\n    AGENT = \"Agent\"", "successors": []}]}, {"name": "BlockCategory", "type": "class", "start_line": 49, "end_line": 66, "functions": [{"name": "dict", "type": "function", "start_line": 65, "end_line": 66, "functions": [], "classes": [], "simplified_code": "    def dict(self) -> dict[str, str]:\n        return {\"category\": self.name, \"description\": self.value}", "blocks": [{"id": 1, "label": "def dict(self) -> dict[str, str]:\nreturn {\"category\": self.name, \"description\": self.value}", "successors": []}]}], "classes": [], "simplified_code": "class BlockCategory(Enum):\n    AI = \"Block that leverages AI to perform a task.\"\n    SOCIAL = \"Block that interacts with social media platforms.\"\n    TEXT = \"Block that processes text data.\"\n    SEARCH = \"Block that searches or extracts information from the internet.\"\n    BASIC = \"Block that performs basic operations.\"\n    INPUT = \"Block that interacts with input of the graph.\"\n    OUTPUT = \"Block that interacts with output of the graph.\"\n    LOGIC = \"Programming logic to control the flow of your agent\"\n    COMMUNICATION = \"Block that interacts with communication platforms.\"\n    DEVELOPER_TOOLS = \"Developer tools such as GitHub blocks.\"\n    DATA = \"Block that interacts with structured data.\"\n    HARDWARE = \"Block that interacts with hardware.\"\n    AGENT = \"Block that interacts with other agents.\"\n    CRM = \"Block that interacts with CRM services.\"\n\n        return {\"category\": self.name, \"description\": self.value}", "blocks": [{"id": 1, "label": "class BlockCategory(Enum):\nAI = \"Block that leverages AI to perform a task.\"", "successors": [{"id": 3, "label": "SOCIAL = \"Block that interacts with social media platforms.\"\nTEXT = \"Block that processes text data.\"", "successors": [{"id": 5, "label": "SEARCH = \"Block that searches or extracts information from the internet.\"\nBASIC = \"Block that performs basic operations.\"", "successors": [{"id": 7, "label": "INPUT = \"Block that interacts with input of the graph.\"\nOUTPUT = \"Block that interacts with output of the graph.\"", "successors": [{"id": 9, "label": "LOGIC = \"Programming logic to control the flow of your agent\"\nCOMMUNICATION = \"Block that interacts with communication platforms.\"", "successors": [{"id": 11, "label": "DEVELOPER_TOOLS = \"Developer tools such as GitHub blocks.\"\nDATA = \"Block that interacts with structured data.\"", "successors": [{"id": 13, "label": "HARDWARE = \"Block that interacts with hardware.\"\nAGENT = \"Block that interacts with other agents.\"", "successors": [{"id": 15, "label": "CRM = \"Block that interacts with CRM services.\"\nreturn {\"category\": self.name, \"description\": self.value}", "successors": []}]}]}]}]}]}]}]}]}, {"name": "BlockSchema", "type": "class", "start_line": 69, "end_line": 190, "functions": [{"name": "jsonschema", "type": "function", "start_line": 73, "end_line": 105, "functions": [{"name": "ref_to_dict", "type": "function", "start_line": 79, "end_line": 96, "functions": [], "classes": [], "simplified_code": "        def ref_to_dict(obj):\n            if isinstance(obj, dict):\n                # OpenAPI <3.1 does not support sibling fields that has a $ref key\n                # So sometimes, the schema has an \"allOf\"/\"anyOf\"/\"oneOf\" with 1 item.\n                keys = {\"allOf\", \"anyOf\", \"oneOf\"}\n                one_key = next((k for k in keys if k in obj and len(obj[k]) == 1), None)\n                if one_key:\n                    obj.update(obj[one_key][0])\n\n                return {\n                    key: ref_to_dict(value)\n                    for key, value in obj.items()\n                    if not key.startswith(\"$\") and key != one_key\n                }\n            elif isinstance(obj, list):\n                return [ref_to_dict(item) for item in obj]\n\n            return obj", "blocks": [{"id": 1, "label": "def ref_to_dict(obj):\nif isinstance(obj, dict):", "successors": [{"id": 3, "label": "    keys = {\"allOf\", \"anyOf\", \"oneOf\"}\n    one_key = next((k for k in keys if k in obj and len(obj[k]) == 1), None)\nif one_key:", "successors": [{"id": 5, "label": "    obj.update(obj[one_key][0])\nreturn {\n    key: ref_to_dict(value)\n    for key, value in obj.items()\n    if not key.startswith(\"$\") and key != one_key\n}", "successors": []}, {"id": 6, "label": "return {\n    key: ref_to_dict(value)\n    for key, value in obj.items()\n    if not key.startswith(\"$\") and key != one_key\n}", "successors": []}]}, {"id": 7, "label": "elif isinstance(obj, list):\n    return [ref_to_dict(item) for item in obj]", "successors": []}, {"id": 9, "label": "return obj", "successors": []}]}]}], "classes": [], "simplified_code": "    def jsonschema(cls) -> dict[str, Any]:\n        if cls.cached_jsonschema:\n            return cls.cached_jsonschema\n\n        model = jsonref.replace_refs(cls.model_json_schema(), merge_props=True)\n\n            return obj\n\n        cls.cached_jsonschema = cast(dict[str, Any], ref_to_dict(model))\n\n        # Set default properties values\n        for field in cls.cached_jsonschema.get(\"properties\", {}).values():\n            if isinstance(field, dict) and \"advanced\" not in field:\n                field[\"advanced\"] = True\n\n        return cls.cached_jsonschema", "blocks": [{"id": 1, "label": "def jsonschema(cls) -> dict[str, Any]:\nif cls.cached_jsonschema:", "successors": [{"id": 3, "label": "    return cls.cached_jsonschema", "successors": []}, {"id": 4, "label": "model = jsonref.replace_refs(cls.model_json_schema(), merge_props=True)\ncls.cached_jsonschema = cast(dict[str, Any], ref_to_dict(model))", "successors": [{"id": 6, "label": "for field in cls.cached_jsonschema.get(\"properties\", {}).values():", "successors": [{"id": 7, "label": "if isinstance(field, dict) and \"advanced\" not in field:\n    field[\"advanced\"] = True", "successors": []}]}, {"id": 9, "label": "return cls.cached_jsonschema", "successors": []}]}]}]}, {"name": "validate_data", "type": "function", "start_line": 108, "end_line": 109, "functions": [], "classes": [], "simplified_code": "    def validate_data(cls, data: BlockInput) -> str | None:\n        return json.validate_with_jsonschema(schema=cls.jsonschema(), data=data)", "blocks": [{"id": 1, "label": "def validate_data(cls, data: BlockInput) -> str | None:\nreturn json.validate_with_jsonschema(schema=cls.jsonschema(), data=data)", "successors": []}]}, {"name": "validate_field", "type": "function", "start_line": 112, "end_line": 129, "functions": [], "classes": [], "simplified_code": "    def validate_field(cls, field_name: str, data: BlockInput) -> str | None:\n        \"\"\"\n        Validate the data against a specific property (one of the input/output name).\n        Returns the validation error message if the data does not match the schema.\n        \"\"\"\n        model_schema = cls.jsonschema().get(\"properties\", {})\n        if not model_schema:\n            return f\"Invalid model schema {cls}\"\n\n        property_schema = model_schema.get(field_name)\n        if not property_schema:\n            return f\"Invalid property name {field_name}\"\n\n        try:\n            jsonschema.validate(json.to_dict(data), property_schema)\n            return None\n        except jsonschema.ValidationError as e:\n            return str(e)", "blocks": [{"id": 1, "label": "def validate_field(cls, field_name: str, data: BlockInput) -> str | None:\n    model_schema = cls.jsonschema().get(\"properties\", {})", "successors": [{"id": 3, "label": "    if not model_schema:\n        return f\"Invalid model schema {cls}\"", "successors": []}, {"id": 5, "label": "    property_schema = model_schema.get(field_name)", "successors": [{"id": 6, "label": "    if not property_schema:\n        return f\"Invalid property name {field_name}\"", "successors": []}, {"id": 8, "label": "    try:", "successors": [{"id": 9, "label": "        jsonschema.validate(json.to_dict(data), property_schema)\n        return None", "successors": []}, {"id": 11, "label": "    except jsonschema.ValidationError as e:\n        return str(e)", "successors": []}]}]}]}]}, {"name": "get_fields", "type": "function", "start_line": 132, "end_line": 133, "functions": [], "classes": [], "simplified_code": "    def get_fields(cls) -> set[str]:\n        return set(cls.model_fields.keys())", "blocks": [{"id": 1, "label": "def get_fields(cls) -> set[str]:\n    return set(cls.model_fields.keys())", "successors": []}]}, {"name": "get_required_fields", "type": "function", "start_line": 136, "end_line": 141, "functions": [], "classes": [], "simplified_code": "    def get_required_fields(cls) -> set[str]:\n        return {\n            field\n            for field, field_info in cls.model_fields.items()\n            if field_info.is_required()\n        }", "blocks": [{"id": 1, "label": "def get_required_fields(cls) -> set[str]:\nreturn {", "successors": [{"id": 3, "label": "field\nfor field, field_info in cls.model_fields.items()\nif field_info.is_required()", "successors": []}]}]}, {"name": "__pydantic_init_subclass__", "type": "function", "start_line": 144, "end_line": 190, "functions": [], "classes": [], "simplified_code": "    def __pydantic_init_subclass__(cls, **kwargs):\n        \"\"\"Validates the schema definition. Rules:\n        - Only one `CredentialsMetaInput` field may be present.\n          - This field MUST be called `credentials`.\n        - A field that is called `credentials` MUST be a `CredentialsMetaInput`.\n        \"\"\"\n        super().__pydantic_init_subclass__(**kwargs)\n\n        # Reset cached JSON schema to prevent inheriting it from parent class\n        cls.cached_jsonschema = {}\n\n        credentials_fields = [\n            field_name\n            for field_name, info in cls.model_fields.items()\n            if (\n                inspect.isclass(info.annotation)\n                and issubclass(\n                    get_origin(info.annotation) or info.annotation,\n                    CredentialsMetaInput,\n                )\n            )\n        ]\n        if len(credentials_fields) > 1:\n            raise ValueError(\n                f\"{cls.__qualname__} can only have one CredentialsMetaInput field\"\n            )\n        elif (\n            len(credentials_fields) == 1\n            and credentials_fields[0] != CREDENTIALS_FIELD_NAME\n        ):\n            raise ValueError(\n                f\"CredentialsMetaInput field on {cls.__qualname__} \"\n                \"must be named 'credentials'\"\n            )\n        elif (\n            len(credentials_fields) == 0\n            and CREDENTIALS_FIELD_NAME in cls.model_fields.keys()\n        ):\n            raise TypeError(\n                f\"Field 'credentials' on {cls.__qualname__} \"\n                f\"must be of type {CredentialsMetaInput.__name__}\"\n            )\n        if credentials_field := cls.model_fields.get(CREDENTIALS_FIELD_NAME):\n            credentials_input_type = cast(\n                CredentialsMetaInput, credentials_field.annotation\n            )\n            credentials_input_type.validate_credentials_field_schema(cls)", "blocks": [{"id": 1, "label": "def __pydantic_init_subclass__(cls, **kwargs):\nsuper().__pydantic_init_subclass__(**kwargs)", "successors": [{"id": 3, "label": "cls.cached_jsonschema = {}\ncredentials_fields = [\n    field_name\n    for field_name, info in cls.model_fields.items()\n    if (\n        inspect.isclass(info.annotation)\n        and issubclass(\n            get_origin(info.annotation) or info.annotation,\n            CredentialsMetaInput,\n        )\n    )\n]", "successors": [{"id": 5, "label": "if len(credentials_fields) > 1:\nraise ValueError(\n    f\"{cls.__qualname__} can only have one CredentialsMetaInput field\"\n)", "successors": []}, {"id": 7, "label": "elif (\n    len(credentials_fields) == 1\n    and credentials_fields[0] != CREDENTIALS_FIELD_NAME\n):\nraise ValueError(\n    f\"CredentialsMetaInput field on {cls.__qualname__} \"\n    \"must be named 'credentials'\"\n)", "successors": []}, {"id": 9, "label": "elif (\n    len(credentials_fields) == 0\n    and CREDENTIALS_FIELD_NAME in cls.model_fields.keys()\n):\nraise TypeError(\n    f\"Field 'credentials' on {cls.__qualname__} \"\n    f\"must be of type {CredentialsMetaInput.__name__}\"\n)", "successors": []}, {"id": 11, "label": "if credentials_field := cls.model_fields.get(CREDENTIALS_FIELD_NAME):\ncredentials_input_type = cast(\n    CredentialsMetaInput, credentials_field.annotation\n)", "successors": [{"id": 13, "label": "credentials_input_type.validate_credentials_field_schema(cls)", "successors": []}]}]}]}]}], "classes": [], "simplified_code": "class BlockSchema(BaseModel):\n    cached_jsonschema: ClassVar[dict[str, Any]]\n\n    @classmethod\n        return cls.cached_jsonschema\n\n    @classmethod\n        return json.validate_with_jsonschema(schema=cls.jsonschema(), data=data)\n\n    @classmethod\n            return str(e)\n\n    @classmethod\n        return set(cls.model_fields.keys())\n\n    @classmethod\n        }\n\n    @classmethod\n            credentials_input_type.validate_credentials_field_schema(cls)", "blocks": [{"id": 1, "label": "class BlockSchema(BaseModel):\ncached_jsonschema: ClassVar[dict[str, Any]]", "successors": [{"id": 3, "label": "@classmethod\ndef cached_schema(cls):\n    return cls.cached_jsonschema\n@classmethod\ndef validate_schema(cls, data):\n    try:\n        return json.validate_with_jsonschema(schema=cls.jsonschema(), data=data)", "successors": [{"id": 5, "label": "except Exception as e:\n    return str(e)\n@classmethod\ndef get_field_names(cls):\n    return set(cls.model_fields.keys())", "successors": [{"id": 7, "label": "@classmethod\ndef validate_credentials(cls):\n    try:\n        credentials_input_type.validate_credentials_field_schema(cls)\nexcept Exception:\n    pass", "successors": []}]}]}]}]}, {"name": "EmptySchema", "type": "class", "start_line": 197, "end_line": 198, "functions": [], "classes": [], "simplified_code": "class EmptySchema(BlockSchema):\n    pass", "blocks": [{"id": 1, "label": "pass", "successors": []}]}, {"name": "BlockManualWebhookConfig", "type": "class", "start_line": 202, "end_line": 230, "functions": [], "classes": [], "simplified_code": "class BlockManualWebhookConfig(BaseModel):\n    \"\"\"\n    Configuration model for webhook-triggered blocks on which\n    the user has to manually set up the webhook at the provider.\n    \"\"\"\n\n    provider: str\n    \"\"\"The service provider that the webhook connects to\"\"\"\n\n    webhook_type: str\n    \"\"\"\n    Identifier for the webhook type. E.g. GitHub has repo and organization level hooks.\n\n    Only for use in the corresponding `WebhooksManager`.\n    \"\"\"\n\n    event_filter_input: str = \"\"\n    \"\"\"\n    Name of the block's event filter input.\n    Leave empty if the corresponding webhook doesn't have distinct event/payload types.\n    \"\"\"\n\n    event_format: str = \"{event}\"\n    \"\"\"\n    Template string for the event(s) that a block instance subscribes to.\n    Applied individually to each event selected in the event filter input.\n\n    Example: `\"pull_request.{event}\"` -> `\"pull_request.opened\"`\n    \"\"\"", "blocks": [{"id": 1, "label": "class BlockManualWebhookConfig(BaseModel):\n\"\"\"\nConfiguration model for webhook-triggered blocks on which\nthe user has to manually set up the webhook at the provider.\n\"\"\"", "successors": [{"id": 3, "label": "provider: str\n\"\"\"The service provider that the webhook connects to\"\"\"\nwebhook_type: str\n\"\"\"\nIdentifier for the webhook type. E.g. GitHub has repo and organization level hooks.\n\nOnly for use in the corresponding `WebhooksManager`.\n\"\"\"", "successors": [{"id": 5, "label": "event_filter_input: str = \"\"\n\"\"\"\nName of the block's event filter input.\nLeave empty if the corresponding webhook doesn't have distinct event/payload types.\n\"\"\"\nevent_format: str = \"{event}\"\n\"\"\"\nTemplate string for the event(s) that a block instance subscribes to.\nApplied individually to each event selected in the event filter input.\n\nExample: `\"pull_request.{event}\"` -> `\"pull_request.opened\"`\n\"\"\"", "successors": []}]}]}]}, {"name": "BlockWebhookConfig", "type": "class", "start_line": 233, "end_line": 247, "functions": [], "classes": [], "simplified_code": "class BlockWebhookConfig(BlockManualWebhookConfig):\n    \"\"\"\n    Configuration model for webhook-triggered blocks for which\n    the webhook can be automatically set up through the provider's API.\n    \"\"\"\n\n    resource_format: str\n    \"\"\"\n    Template string for the resource that a block instance subscribes to.\n    Fields will be filled from the block's inputs (except `payload`).\n\n    Example: `f\"{repo}/pull_requests\"` (note: not how it's actually implemented)\n\n    Only for use in the corresponding `WebhooksManager`.\n    \"\"\"", "blocks": [{"id": 1, "label": "class BlockWebhookConfig(BlockManualWebhookConfig):\n\"\"\"\nConfiguration model for webhook-triggered blocks for which\nthe webhook can be automatically set up through the provider's API.\n\"\"\"", "successors": [{"id": 3, "label": "resource_format: str\n\"\"\"\nTemplate string for the resource that a block instance subscribes to.\nFields will be filled from the block's inputs (except `payload`).\n\nExample: `f\"{repo}/pull_requests\"` (note: not how it's actually implemented)\n\nOnly for use in the corresponding `WebhooksManager`.\n\"\"\"", "successors": []}]}]}, {"name": "Block", "type": "class", "start_line": 251, "end_line": 412, "functions": [{"name": "__init__", "type": "function", "start_line": 252, "end_line": 339, "functions": [], "classes": [], "simplified_code": "    def __init__(\n        self,\n        id: str = \"\",\n        description: str = \"\",\n        contributors: list[ContributorDetails] = [],\n        categories: set[BlockCategory] | None = None,\n        input_schema: Type[BlockSchemaInputType] = EmptySchema,\n        output_schema: Type[BlockSchemaOutputType] = EmptySchema,\n        test_input: BlockInput | list[BlockInput] | None = None,\n        test_output: BlockData | list[BlockData] | None = None,\n        test_mock: dict[str, Any] | None = None,\n        test_credentials: Optional[Credentials] = None,\n        disabled: bool = False,\n        static_output: bool = False,\n        block_type: BlockType = BlockType.STANDARD,\n        webhook_config: Optional[BlockWebhookConfig | BlockManualWebhookConfig] = None,\n    ):\n        \"\"\"\n        Initialize the block with the given schema.\n\n        Args:\n            id: The unique identifier for the block, this value will be persisted in the\n                DB. So it should be a unique and constant across the application run.\n                Use the UUID format for the ID.\n            description: The description of the block, explaining what the block does.\n            contributors: The list of contributors who contributed to the block.\n            input_schema: The schema, defined as a Pydantic model, for the input data.\n            output_schema: The schema, defined as a Pydantic model, for the output data.\n            test_input: The list or single sample input data for the block, for testing.\n            test_output: The list or single expected output if the test_input is run.\n            test_mock: function names on the block implementation to mock on test run.\n            disabled: If the block is disabled, it will not be available for execution.\n            static_output: Whether the output links of the block are static by default.\n        \"\"\"\n        self.id = id\n        self.input_schema = input_schema\n        self.output_schema = output_schema\n        self.test_input = test_input\n        self.test_output = test_output\n        self.test_mock = test_mock\n        self.test_credentials = test_credentials\n        self.description = description\n        self.categories = categories or set()\n        self.contributors = contributors or set()\n        self.disabled = disabled\n        self.static_output = static_output\n        self.block_type = block_type\n        self.webhook_config = webhook_config\n        self.execution_stats = {}\n\n        if self.webhook_config:\n            if isinstance(self.webhook_config, BlockWebhookConfig):\n                # Enforce presence of credentials field on auto-setup webhook blocks\n                if CREDENTIALS_FIELD_NAME not in self.input_schema.model_fields:\n                    raise TypeError(\n                        \"credentials field is required on auto-setup webhook blocks\"\n                    )\n                self.block_type = BlockType.WEBHOOK\n            else:\n                self.block_type = BlockType.WEBHOOK_MANUAL\n\n            # Enforce shape of webhook event filter, if present\n            if self.webhook_config.event_filter_input:\n                event_filter_field = self.input_schema.model_fields[\n                    self.webhook_config.event_filter_input\n                ]\n                if not (\n                    isinstance(event_filter_field.annotation, type)\n                    and issubclass(event_filter_field.annotation, BaseModel)\n                    and all(\n                        field.annotation is bool\n                        for field in event_filter_field.annotation.model_fields.values()\n                    )\n                ):\n                    raise NotImplementedError(\n                        f\"{self.name} has an invalid webhook event selector: \"\n                        \"field must be a BaseModel and all its fields must be boolean\"\n                    )\n\n            # Enforce presence of 'payload' input\n            if \"payload\" not in self.input_schema.model_fields:\n                raise TypeError(\n                    f\"{self.name} is webhook-triggered but has no 'payload' input\"\n                )\n\n            # Disable webhook-triggered block if webhook functionality not available\n            if not app_config.platform_base_url:\n                self.disabled = True", "blocks": [{"id": 1, "label": "self.id = id\nself.input_schema = input_schema\nself.output_schema = output_schema\nself.test_input = test_input\nself.test_output = test_output\nself.test_mock = test_mock\nself.test_credentials = test_credentials\nself.description = description\nself.categories = categories or set()\nself.contributors = contributors or set()\nself.disabled = disabled\nself.static_output = static_output\nself.block_type = block_type\nself.webhook_config = webhook_config\nself.execution_stats = {}\nif self.webhook_config:", "successors": [{"id": 3, "label": "if isinstance(self.webhook_config, BlockWebhookConfig):", "successors": [{"id": 4, "label": "if CREDENTIALS_FIELD_NAME not in self.input_schema.model_fields:\n    raise TypeError(\"credentials field is required on auto-setup webhook blocks\")\nself.block_type = BlockType.WEBHOOK", "successors": []}, {"id": 5, "label": "else:\n    self.block_type = BlockType.WEBHOOK_MANUAL", "successors": []}]}, {"id": 6, "label": "if self.webhook_config.event_filter_input:\nevent_filter_field = self.input_schema.model_fields[self.webhook_config.event_filter_input]\nif not (isinstance(event_filter_field.annotation, type) and issubclass(event_filter_field.annotation, BaseModel) and all(field.annotation is bool for field in event_filter_field.annotation.model_fields.values())):\n    raise NotImplementedError(f\"{self.name} has an invalid webhook event selector: field must be a BaseModel and all its fields must be boolean\")", "successors": []}, {"id": 8, "label": "if \"payload\" not in self.input_schema.model_fields:\n    raise TypeError(f\"{self.name} is webhook-triggered but has no 'payload' input\")", "successors": []}, {"id": 9, "label": "if not app_config.platform_base_url:\n    self.disabled = True", "successors": []}]}]}, {"name": "create", "type": "function", "start_line": 342, "end_line": 343, "functions": [], "classes": [], "simplified_code": "    def create(cls: Type[\"Block\"]) -> \"Block\":\n        return cls()", "blocks": [{"id": 1, "label": "def create(cls: Type[\"Block\"]) -> \"Block\":\n    return cls()", "successors": []}]}, {"name": "run", "type": "function", "start_line": 346, "end_line": 356, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: BlockSchemaInputType, **kwargs) -> BlockOutput:\n        \"\"\"\n        Run the block with the given input data.\n        Args:\n            input_data: The input data with the structure of input_schema.\n        Returns:\n            A Generator that yields (output_name, output_data).\n            output_name: One of the output name defined in Block's output_schema.\n            output_data: The data for the output_name, matching the defined schema.\n        \"\"\"\n        pass", "blocks": [{"id": 1, "label": "def run(self, input_data: BlockSchemaInputType, **kwargs) -> BlockOutput:\n\"\"\"\n        Run the block with the given input data.\n        Args:\n            input_data: The input data with the structure of input_schema.\n        Returns:\n            A Generator that yields (output_name, output_data).\n            output_name: One of the output name defined in Block's output_schema.\n            output_data: The data for the output_name, matching the defined schema.\n        \"\"\"", "successors": [{"id": 3, "label": "pass", "successors": []}]}]}, {"name": "run_once", "type": "function", "start_line": 358, "end_line": 362, "functions": [], "classes": [], "simplified_code": "    def run_once(self, input_data: BlockSchemaInputType, output: str, **kwargs) -> Any:\n        for name, data in self.run(input_data, **kwargs):\n            if name == output:\n                return data\n        raise ValueError(f\"{self.name} did not produce any output for {output}\")", "blocks": [{"id": 1, "label": "def run_once(self, input_data: BlockSchemaInputType, output: str, **kwargs) -> Any:", "successors": [{"id": 2, "label": "for name, data in self.run(input_data, **kwargs):", "successors": [{"id": 3, "label": "if name == output:\nreturn data", "successors": []}]}, {"id": 5, "label": "raise ValueError(f\"{self.name} did not produce any output for {output}\")", "successors": []}]}]}, {"name": "merge_stats", "type": "function", "start_line": 364, "end_line": 376, "functions": [], "classes": [], "simplified_code": "    def merge_stats(self, stats: dict[str, Any]) -> dict[str, Any]:\n        for key, value in stats.items():\n            if isinstance(value, dict):\n                self.execution_stats.setdefault(key, {}).update(value)\n            elif isinstance(value, (int, float)):\n                self.execution_stats.setdefault(key, 0)\n                self.execution_stats[key] += value\n            elif isinstance(value, list):\n                self.execution_stats.setdefault(key, [])\n                self.execution_stats[key].extend(value)\n            else:\n                self.execution_stats[key] = value\n        return self.execution_stats", "blocks": [{"id": 1, "label": "def merge_stats(self, stats: dict[str, Any]) -> dict[str, Any]:", "successors": [{"id": 2, "label": "for key, value in stats.items():", "successors": [{"id": 3, "label": "if isinstance(value, dict):\nself.execution_stats.setdefault(key, {}).update(value)", "successors": [{"id": 10, "label": "return self.execution_stats", "successors": []}, {"id": 2, "label": "for key, value in stats.items():", "successors": [{"id": 3, "label": "if isinstance(value, dict):", "successors": []}, {"id": 5, "label": "elif isinstance(value, (int, float)):", "successors": []}, {"id": 7, "label": "elif isinstance(value, list):", "successors": []}, {"id": 9, "label": "else:", "successors": []}]}]}, {"id": 5, "label": "elif isinstance(value, (int, float)):\nself.execution_stats.setdefault(key, 0)\nself.execution_stats[key] += value", "successors": [{"id": 10, "label": "return self.execution_stats", "successors": []}, {"id": 2, "label": "for key, value in stats.items():", "successors": [{"id": 3, "label": "if isinstance(value, dict):", "successors": []}, {"id": 5, "label": "elif isinstance(value, (int, float)):", "successors": []}, {"id": 7, "label": "elif isinstance(value, list):", "successors": []}, {"id": 9, "label": "else:", "successors": []}]}]}, {"id": 7, "label": "elif isinstance(value, list):\nself.execution_stats.setdefault(key, [])\nself.execution_stats[key].extend(value)", "successors": [{"id": 10, "label": "return self.execution_stats", "successors": []}, {"id": 2, "label": "for key, value in stats.items():", "successors": [{"id": 3, "label": "if isinstance(value, dict):", "successors": []}, {"id": 5, "label": "elif isinstance(value, (int, float)):", "successors": []}, {"id": 7, "label": "elif isinstance(value, list):", "successors": []}, {"id": 9, "label": "else:", "successors": []}]}]}, {"id": 9, "label": "else:", "successors": [{"id": 10, "label": "self.execution_stats[key] = value\nreturn self.execution_stats", "successors": []}, {"id": 2, "label": "for key, value in stats.items():", "successors": []}]}]}, {"id": 10, "label": "return self.execution_stats", "successors": []}]}]}, {"name": "name", "type": "function", "start_line": 379, "end_line": 380, "functions": [], "classes": [], "simplified_code": "    def name(self):\n        return self.__class__.__name__", "blocks": [{"id": 1, "label": "def name(self):\nreturn self.__class__.__name__", "successors": []}]}, {"name": "to_dict", "type": "function", "start_line": 382, "end_line": 395, "functions": [], "classes": [], "simplified_code": "    def to_dict(self):\n        return {\n            \"id\": self.id,\n            \"name\": self.name,\n            \"inputSchema\": self.input_schema.jsonschema(),\n            \"outputSchema\": self.output_schema.jsonschema(),\n            \"description\": self.description,\n            \"categories\": [category.dict() for category in self.categories],\n            \"contributors\": [\n                contributor.model_dump() for contributor in self.contributors\n            ],\n            \"staticOutput\": self.static_output,\n            \"uiType\": self.block_type.value,\n        }", "blocks": [{"id": 1, "label": "def to_dict(self):\nreturn {\n    \"id\": self.id,\n    \"name\": self.name,\n    \"inputSchema\": self.input_schema.jsonschema(),\n    \"outputSchema\": self.output_schema.jsonschema(),\n    \"description\": self.description,\n    \"categories\": [category.dict() for category in self.categories],\n    \"contributors\": [\n        contributor.model_dump() for contributor in self.contributors\n    ],\n    \"staticOutput\": self.static_output,\n    \"uiType\": self.block_type.value,\n}", "successors": []}]}, {"name": "execute", "type": "function", "start_line": 397, "end_line": 412, "functions": [], "classes": [], "simplified_code": "    def execute(self, input_data: BlockInput, **kwargs) -> BlockOutput:\n        if error := self.input_schema.validate_data(input_data):\n            raise ValueError(\n                f\"Unable to execute block with invalid input data: {error}\"\n            )\n\n        for output_name, output_data in self.run(\n            self.input_schema(**input_data), **kwargs\n        ):\n            if output_name == \"error\":\n                raise RuntimeError(output_data)\n            if self.block_type == BlockType.STANDARD and (\n                error := self.output_schema.validate_field(output_name, output_data)\n            ):\n                raise ValueError(f\"Block produced an invalid output data: {error}\")\n            yield output_name, output_data", "blocks": [{"id": 1, "label": "def execute(self, input_data: BlockInput, **kwargs) -> BlockOutput:\nif error := self.input_schema.validate_data(input_data):", "successors": [{"id": 3, "label": "raise ValueError(f\"Unable to execute block with invalid input data: {error}\")", "successors": []}, {"id": 4, "label": "for output_name, output_data in self.run(self.input_schema(**input_data), **kwargs):", "successors": [{"id": 5, "label": "if output_name == \"error\":", "successors": [{"id": 6, "label": "raise RuntimeError(output_data)", "successors": []}, {"id": 7, "label": "if self.block_type == BlockType.STANDARD and (error := self.output_schema.validate_field(output_name, output_data)):", "successors": [{"id": 8, "label": "raise ValueError(f\"Block produced an invalid output data: {error}\")", "successors": []}, {"id": 9, "label": "yield output_name, output_data", "successors": []}]}]}]}]}]}], "classes": [], "simplified_code": "class Block(ABC, Generic[BlockSchemaInputType, BlockSchemaOutputType]):\n                self.disabled = True\n\n    @classmethod\n        return cls()\n\n    @abstractmethod\n        pass\n\n        raise ValueError(f\"{self.name} did not produce any output for {output}\")\n\n        return self.execution_stats\n\n    @property\n        return self.__class__.__name__\n\n        }\n\n            yield output_name, output_data", "blocks": [{"id": 1, "label": "class Block(ABC, Generic[BlockSchemaInputType, BlockSchemaOutputType]):\n    self.disabled = True", "successors": []}]}], "simplified_code": "import inspect\nfrom abc import ABC, abstractmethod\nfrom enum import Enum\nfrom typing import (\n    Any,\n    ClassVar,\n    Generator,\n    Generic,\n    Optional,\n    Type,\n    TypeVar,\n    cast,\n    get_origin,\n)\n\nimport jsonref\nimport jsonschema\nfrom prisma.models import AgentBlock\nfrom pydantic import BaseModel\n\nfrom backend.util import json\nfrom backend.util.settings import Config\n\nfrom .model import (\n    CREDENTIALS_FIELD_NAME,\n    ContributorDetails,\n    Credentials,\n    CredentialsMetaInput,\n)\n\napp_config = Config()\n\nBlockData = tuple[str, Any]  # Input & Output data should be a tuple of (name, data).\nBlockInput = dict[str, Any]  # Input: 1 input pin consumes 1 data.\nBlockOutput = Generator[BlockData, None, None]  # Output: 1 output pin produces n data.\nCompletedBlockOutput = dict[str, list[Any]]  # Completed stream, collected as a dict.\n\n\n    AGENT = \"Agent\"\n\n\n        return {\"category\": self.name, \"description\": self.value}\n\n\n            credentials_input_type.validate_credentials_field_schema(cls)\n\n\nBlockSchemaInputType = TypeVar(\"BlockSchemaInputType\", bound=BlockSchema)\nBlockSchemaOutputType = TypeVar(\"BlockSchemaOutputType\", bound=BlockSchema)\n\n\n    pass\n\n\n# --8<-- [start:BlockWebhookConfig]\n    \"\"\"\n\n\n    \"\"\"\n    # --8<-- [end:BlockWebhookConfig]\n\n\n            yield output_name, output_data\n\n\n# ======================= Block Helper Functions ======================= #\n\n\n    return AVAILABLE_BLOCKS\n\n\n            )\n\n\n    return cls() if cls else None", "blocks": [{"id": 1, "label": "import inspect\nfrom abc import ABC, abstractmethod\nfrom enum import Enum\nfrom typing import (\n    Any,\n    ClassVar,\n    Generator,\n    Generic,\n    Optional,\n    Type,\n    TypeVar,\n    cast,\n    get_origin,\n)\n\nimport jsonref\nimport jsonschema\nfrom prisma.models import AgentBlock\nfrom pydantic import BaseModel\n\nfrom backend.util import json\nfrom backend.util.settings import Config\n\nfrom .model import (\n    CREDENTIALS_FIELD_NAME,\n    ContributorDetails,\n    Credentials,\n    CredentialsMetaInput,\n)\n\napp_config = Config()\n\nBlockData = tuple[str, Any]  # Input & Output data should be a tuple of (name, data).\nBlockInput = dict[str, Any]  # Input: 1 input pin consumes 1 data.\nBlockOutput = Generator[BlockData, None, None]  # Output: 1 output pin produces n data.\nCompletedBlockOutput = dict[str, list[Any]]  # Completed stream, collected as a dict.\n\n    AGENT = \"Agent\"\n\n        return {\"category\": self.name, \"description\": self.value}\n\n            credentials_input_type.validate_credentials_field_schema(cls)\n\nBlockSchemaInputType = TypeVar(\"BlockSchemaInputType\", bound=BlockSchema)\nBlockSchemaOutputType = TypeVar(\"BlockSchemaOutputType\", bound=BlockSchema)\n\n    pass\n\n# --8<-- [start:BlockWebhookConfig]\n    \"\"\"\n\n\n    \"\"\"\n    # --8<-- [end:BlockWebhookConfig]\n\n            yield output_name, output_data\n\n# ======================= Block Helper Functions ======================= #\n\n    return AVAILABLE_BLOCKS\n\n            )\n\n    return cls() if cls else None\n", "successors": []}]}
{"file_name": "121.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 26, "functions": [{"name": "example_function", "type": "function", "start_line": 7, "end_line": 9, "functions": [], "classes": [], "simplified_code": "def example_function(a: int, b: int, c: int) -> int:\n    time.sleep(0.5)\n    return a + b + c", "blocks": [{"id": 1, "label": "def example_function(a: int, b: int, c: int) -> int:\n    time.sleep(0.5)", "successors": [{"id": 3, "label": "    return a + b + c", "successors": []}]}]}, {"name": "example_function_with_error", "type": "function", "start_line": 13, "end_line": 14, "functions": [], "classes": [], "simplified_code": "def example_function_with_error(a: int, b: int, c: int) -> int:\n    raise ValueError(\"This is a test error\")", "blocks": [{"id": 1, "label": "def example_function_with_error(a: int, b: int, c: int) -> int:\nraise ValueError(\"This is a test error\")", "successors": []}]}, {"name": "test_timer_decorator", "type": "function", "start_line": 17, "end_line": 21, "functions": [], "classes": [], "simplified_code": "def test_timer_decorator():\n    info, res = example_function(1, 2, 3)\n    assert info.cpu_time >= 0\n    assert info.wall_time >= 0.4\n    assert res == 6", "blocks": [{"id": 1, "label": "info, res = example_function(1, 2, 3)\nassert info.cpu_time >= 0", "successors": [{"id": 3, "label": "assert info.wall_time >= 0.4\nassert res == 6", "successors": []}]}]}, {"name": "test_error_decorator", "type": "function", "start_line": 24, "end_line": 26, "functions": [], "classes": [], "simplified_code": "def test_error_decorator():\n    res = example_function_with_error(1, 2, 3)\n    assert res is None", "blocks": [{"id": 1, "label": "def test_error_decorator():\nres = example_function_with_error(1, 2, 3)", "successors": [{"id": 3, "label": "assert res is None", "successors": []}]}]}], "classes": [], "simplified_code": "import time\n\nfrom backend.util.decorator import error_logged, time_measured\n\n\n@time_measured\n    return a + b + c\n\n\n@error_logged\n    raise ValueError(\"This is a test error\")\n\n\n    assert res == 6\n\n\n    assert res is None", "blocks": [{"id": 1, "label": "import time\nfrom backend.util.decorator import error_logged, time_measured", "successors": []}]}
{"file_name": "122.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 484, "functions": [{"name": "create_graph_execution", "type": "function", "start_line": 134, "end_line": 173, "functions": [], "classes": [], "simplified_code": "async def create_graph_execution(\n    graph_id: str,\n    graph_version: int,\n    nodes_input: list[tuple[str, BlockInput]],\n    user_id: str,\n) -> tuple[str, list[ExecutionResult]]:\n    \"\"\"\n    Create a new AgentGraphExecution record.\n    Returns:\n        The id of the AgentGraphExecution and the list of ExecutionResult for each node.\n    \"\"\"\n    result = await AgentGraphExecution.prisma().create(\n        data={\n            \"agentGraphId\": graph_id,\n            \"agentGraphVersion\": graph_version,\n            \"executionStatus\": ExecutionStatus.QUEUED,\n            \"AgentNodeExecutions\": {\n                \"create\": [  # type: ignore\n                    {\n                        \"agentNodeId\": node_id,\n                        \"executionStatus\": ExecutionStatus.INCOMPLETE,\n                        \"Input\": {\n                            \"create\": [\n                                {\"name\": name, \"data\": json.dumps(data)}\n                                for name, data in node_input.items()\n                            ]\n                        },\n                    }\n                    for node_id, node_input in nodes_input\n                ]\n            },\n            \"userId\": user_id,\n        },\n        include=GRAPH_EXECUTION_INCLUDE,\n    )\n\n    return result.id, [\n        ExecutionResult.from_db(execution)\n        for execution in result.AgentNodeExecutions or []\n    ]", "blocks": [{"id": 1, "label": "async def create_graph_execution(\n    graph_id: str,\n    graph_version: int,\n    nodes_input: list[tuple[str, BlockInput]],\n    user_id: str,\n) -> tuple[str, list[ExecutionResult]]:\n\"\"\"\n    Create a new AgentGraphExecution record.\n    Returns:\n        The id of the AgentGraphExecution and the list of ExecutionResult for each node.\n    \"\"\"", "successors": [{"id": 3, "label": "result = await AgentGraphExecution.prisma().create(\n    data={\n        \"agentGraphId\": graph_id,\n        \"agentGraphVersion\": graph_version,\n        \"executionStatus\": ExecutionStatus.QUEUED,\n        \"AgentNodeExecutions\": {\n            \"create\": [  # type: ignore\n                {\n                    \"agentNodeId\": node_id,\n                    \"executionStatus\": ExecutionStatus.INCOMPLETE,\n                    \"Input\": {\n                        \"create\": [\n                            {\"name\": name, \"data\": json.dumps(data)}\n                            for name, data in node_input.items()\n                        ]\n                    },\n                }\n                for node_id, node_input in nodes_input\n            ]\n        },\n        \"userId\": user_id,\n    },\n    include=GRAPH_EXECUTION_INCLUDE,\n)\nreturn result.id, [\n    ExecutionResult.from_db(execution)\n    for execution in result.AgentNodeExecutions or []\n]", "successors": []}]}]}, {"name": "upsert_execution_input", "type": "function", "start_line": 176, "end_line": 241, "functions": [], "classes": [], "simplified_code": "async def upsert_execution_input(\n    node_id: str,\n    graph_exec_id: str,\n    input_name: str,\n    input_data: Any,\n    node_exec_id: str | None = None,\n) -> tuple[str, BlockInput]:\n    \"\"\"\n    Insert AgentNodeExecutionInputOutput record for as one of AgentNodeExecution.Input.\n    If there is no AgentNodeExecution that has no `input_name` as input, create new one.\n\n    Args:\n        node_id: The id of the AgentNode.\n        graph_exec_id: The id of the AgentGraphExecution.\n        input_name: The name of the input data.\n        input_data: The input data to be inserted.\n        node_exec_id: [Optional] The id of the AgentNodeExecution that has no `input_name` as input. If not provided, it will find the eligible incomplete AgentNodeExecution or create a new one.\n\n    Returns:\n        * The id of the created or existing AgentNodeExecution.\n        * Dict of node input data, key is the input name, value is the input data.\n    \"\"\"\n    existing_execution = await AgentNodeExecution.prisma().find_first(\n        where={  # type: ignore\n            **({\"id\": node_exec_id} if node_exec_id else {}),\n            \"agentNodeId\": node_id,\n            \"agentGraphExecutionId\": graph_exec_id,\n            \"executionStatus\": ExecutionStatus.INCOMPLETE,\n            \"Input\": {\"every\": {\"name\": {\"not\": input_name}}},\n        },\n        order={\"addedTime\": \"asc\"},\n        include={\"Input\": True},\n    )\n    json_input_data = json.dumps(input_data)\n\n    if existing_execution:\n        await AgentNodeExecutionInputOutput.prisma().create(\n            data={\n                \"name\": input_name,\n                \"data\": json_input_data,\n                \"referencedByInputExecId\": existing_execution.id,\n            }\n        )\n        return existing_execution.id, {\n            **{\n                input_data.name: json.loads(input_data.data)\n                for input_data in existing_execution.Input or []\n            },\n            input_name: input_data,\n        }\n\n    elif not node_exec_id:\n        result = await AgentNodeExecution.prisma().create(\n            data={\n                \"agentNodeId\": node_id,\n                \"agentGraphExecutionId\": graph_exec_id,\n                \"executionStatus\": ExecutionStatus.INCOMPLETE,\n                \"Input\": {\"create\": {\"name\": input_name, \"data\": json_input_data}},\n            }\n        )\n        return result.id, {input_name: input_data}\n\n    else:\n        raise ValueError(\n            f\"NodeExecution {node_exec_id} not found or already has input {input_name}.\"\n        )", "blocks": [{"id": 1, "label": "async def upsert_execution_input(\n    node_id: str,\n    graph_exec_id: str,\n    input_name: str,\n    input_data: Any,\n    node_exec_id: str | None = None,\n) -> tuple[str, BlockInput]:\n\"\"\"\n    Insert AgentNodeExecutionInputOutput record for as one of AgentNodeExecution.Input.\n    If there is no AgentNodeExecution that has no `input_name` as input, create new one.\n\n    Args:\n        node_id: The id of the AgentNode.\n        graph_exec_id: The id of the AgentGraphExecution.\n        input_name: The name of the input data.\n        input_data: The input data to be inserted.\n        node_exec_id: [Optional] The id of the AgentNodeExecution that has no `input_name` as input. If not provided, it will find the eligible incomplete AgentNodeExecution or create a new one.\n\n    Returns:\n        * The id of the created or existing AgentNodeExecution.\n        * Dict of node input data, key is the input name, value is the input data.\n    \"\"\"", "successors": [{"id": 3, "label": "existing_execution = await AgentNodeExecution.prisma().find_first(\n    where={  # type: ignore\n        **({\"id\": node_exec_id} if node_exec_id else {}),\n        \"agentNodeId\": node_id,\n        \"agentGraphExecutionId\": graph_exec_id,\n        \"executionStatus\": ExecutionStatus.INCOMPLETE,\n        \"Input\": {\"every\": {\"name\": {\"not\": input_name}}},\n    },\n    order={\"addedTime\": \"asc\"},\n    include={\"Input\": True},\n)\njson_input_data = json.dumps(input_data)\nif existing_execution:", "successors": [{"id": 5, "label": "    await AgentNodeExecutionInputOutput.prisma().create(\n        data={\n            \"name\": input_name,\n            \"data\": json_input_data,\n            \"referencedByInputExecId\": existing_execution.id,\n        }\n    )\n    return existing_execution.id, {\n        **{\n            input_data.name: json.loads(input_data.data)\n            for input_data in existing_execution.Input or []\n        },\n        input_name: input_data,\n    }", "successors": []}, {"id": 6, "label": "elif not node_exec_id:", "successors": [{"id": 7, "label": "    result = await AgentNodeExecution.prisma().create(\n        data={\n            \"agentNodeId\": node_id,\n            \"agentGraphExecutionId\": graph_exec_id,\n            \"executionStatus\": ExecutionStatus.INCOMPLETE,\n            \"Input\": {\"create\": {\"name\": input_name, \"data\": json_input_data}},\n        }\n    )\n    return result.id, {input_name: input_data}", "successors": []}, {"id": 8, "label": "else:\n    raise ValueError(\n        f\"NodeExecution {node_exec_id} not found or already has input {input_name}.\"\n    )", "successors": []}]}]}]}]}, {"name": "upsert_execution_output", "type": "function", "start_line": 244, "end_line": 258, "functions": [], "classes": [], "simplified_code": "async def upsert_execution_output(\n    node_exec_id: str,\n    output_name: str,\n    output_data: Any,\n) -> None:\n    \"\"\"\n    Insert AgentNodeExecutionInputOutput record for as one of AgentNodeExecution.Output.\n    \"\"\"\n    await AgentNodeExecutionInputOutput.prisma().create(\n        data={\n            \"name\": output_name,\n            \"data\": json.dumps(output_data),\n            \"referencedByOutputExecId\": node_exec_id,\n        }\n    )", "blocks": [{"id": 1, "label": "async def upsert_execution_output(\n    node_exec_id: str,\n    output_name: str,\n    output_data: Any,\n) -> None:\n    \"\"\"\n    Insert AgentNodeExecutionInputOutput record for as one of AgentNodeExecution.Output.\n    \"\"\"", "successors": [{"id": 3, "label": "    await AgentNodeExecutionInputOutput.prisma().create(\n        data={\n            \"name\": output_name,\n            \"data\": json.dumps(output_data),\n            \"referencedByOutputExecId\": node_exec_id,\n        }\n    )", "successors": []}]}]}, {"name": "update_graph_execution_start_time", "type": "function", "start_line": 261, "end_line": 268, "functions": [], "classes": [], "simplified_code": "async def update_graph_execution_start_time(graph_exec_id: str):\n    await AgentGraphExecution.prisma().update(\n        where={\"id\": graph_exec_id},\n        data={\n            \"executionStatus\": ExecutionStatus.RUNNING,\n            \"startedAt\": datetime.now(tz=timezone.utc),\n        },\n    )", "blocks": [{"id": 1, "label": "async def update_graph_execution_start_time(graph_exec_id: str):\nawait AgentGraphExecution.prisma().update(\n    where={\"id\": graph_exec_id},\n    data={\n        \"executionStatus\": ExecutionStatus.RUNNING,\n        \"startedAt\": datetime.now(tz=timezone.utc),\n    },\n)", "successors": []}]}, {"name": "update_graph_execution_stats", "type": "function", "start_line": 271, "end_line": 286, "functions": [], "classes": [], "simplified_code": "async def update_graph_execution_stats(\n    graph_exec_id: str,\n    stats: dict[str, Any],\n) -> ExecutionResult:\n    status = ExecutionStatus.FAILED if stats.get(\"error\") else ExecutionStatus.COMPLETED\n    res = await AgentGraphExecution.prisma().update(\n        where={\"id\": graph_exec_id},\n        data={\n            \"executionStatus\": status,\n            \"stats\": json.dumps(stats),\n        },\n    )\n    if not res:\n        raise ValueError(f\"Execution {graph_exec_id} not found.\")\n\n    return ExecutionResult.from_graph(res)", "blocks": [{"id": 1, "label": "async def update_graph_execution_stats(\n    graph_exec_id: str,\n    stats: dict[str, Any],\n) -> ExecutionResult:\n    status = ExecutionStatus.FAILED if stats.get(\"error\") else ExecutionStatus.COMPLETED\n    res = await AgentGraphExecution.prisma().update(\n        where={\"id\": graph_exec_id},\n        data={\n            \"executionStatus\": status,\n            \"stats\": json.dumps(stats),\n        },\n    )", "successors": [{"id": 3, "label": "if not res:", "successors": [{"id": 4, "label": "    raise ValueError(f\"Execution {graph_exec_id} not found.\")", "successors": []}, {"id": 5, "label": "return ExecutionResult.from_graph(res)", "successors": []}]}]}]}, {"name": "update_node_execution_stats", "type": "function", "start_line": 289, "end_line": 293, "functions": [], "classes": [], "simplified_code": "async def update_node_execution_stats(node_exec_id: str, stats: dict[str, Any]):\n    await AgentNodeExecution.prisma().update(\n        where={\"id\": node_exec_id},\n        data={\"stats\": json.dumps(stats)},\n    )", "blocks": [{"id": 1, "label": "async def update_node_execution_stats(node_exec_id: str, stats: dict[str, Any]):\nawait AgentNodeExecution.prisma().update(\n    where={\"id\": node_exec_id},\n    data={\"stats\": json.dumps(stats)},\n)", "successors": []}]}, {"name": "update_execution_status", "type": "function", "start_line": 296, "end_line": 324, "functions": [], "classes": [], "simplified_code": "async def update_execution_status(\n    node_exec_id: str,\n    status: ExecutionStatus,\n    execution_data: BlockInput | None = None,\n    stats: dict[str, Any] | None = None,\n) -> ExecutionResult:\n    if status == ExecutionStatus.QUEUED and execution_data is None:\n        raise ValueError(\"Execution data must be provided when queuing an execution.\")\n\n    now = datetime.now(tz=timezone.utc)\n    data = {\n        **({\"executionStatus\": status}),\n        **({\"queuedTime\": now} if status == ExecutionStatus.QUEUED else {}),\n        **({\"startedTime\": now} if status == ExecutionStatus.RUNNING else {}),\n        **({\"endedTime\": now} if status == ExecutionStatus.FAILED else {}),\n        **({\"endedTime\": now} if status == ExecutionStatus.COMPLETED else {}),\n        **({\"executionData\": json.dumps(execution_data)} if execution_data else {}),\n        **({\"stats\": json.dumps(stats)} if stats else {}),\n    }\n\n    res = await AgentNodeExecution.prisma().update(\n        where={\"id\": node_exec_id},\n        data=data,  # type: ignore\n        include=EXECUTION_RESULT_INCLUDE,\n    )\n    if not res:\n        raise ValueError(f\"Execution {node_exec_id} not found.\")\n\n    return ExecutionResult.from_db(res)", "blocks": [{"id": 1, "label": "async def update_execution_status(\n    node_exec_id: str,\n    status: ExecutionStatus,\n    execution_data: BlockInput | None = None,\n    stats: dict[str, Any] | None = None,\n) -> ExecutionResult:", "successors": [{"id": 2, "label": "if status == ExecutionStatus.QUEUED and execution_data is None:\n    raise ValueError(\"Execution data must be provided when queuing an execution.\")", "successors": []}, {"id": 4, "label": "now = datetime.now(tz=timezone.utc)\ndata = {\n    **({\"executionStatus\": status}),\n    **({\"queuedTime\": now} if status == ExecutionStatus.QUEUED else {}),\n    **({\"startedTime\": now} if status == ExecutionStatus.RUNNING else {}),\n    **({\"endedTime\": now} if status == ExecutionStatus.FAILED else {}),\n    **({\"endedTime\": now} if status == ExecutionStatus.COMPLETED else {}),\n    **({\"executionData\": json.dumps(execution_data)} if execution_data else {}),\n    **({\"stats\": json.dumps(stats)} if stats else {}),\n}\nres = await AgentNodeExecution.prisma().update(\n    where={\"id\": node_exec_id},\n    data=data,  # type: ignore\n    include=EXECUTION_RESULT_INCLUDE,\n)", "successors": [{"id": 6, "label": "if not res:\n    raise ValueError(f\"Execution {node_exec_id} not found.\")", "successors": []}, {"id": 8, "label": "return ExecutionResult.from_db(res)", "successors": []}]}]}]}, {"name": "get_execution_results", "type": "function", "start_line": 327, "end_line": 337, "functions": [], "classes": [], "simplified_code": "async def get_execution_results(graph_exec_id: str) -> list[ExecutionResult]:\n    executions = await AgentNodeExecution.prisma().find_many(\n        where={\"agentGraphExecutionId\": graph_exec_id},\n        include=EXECUTION_RESULT_INCLUDE,\n        order=[\n            {\"queuedTime\": \"asc\"},\n            {\"addedTime\": \"asc\"},  # Fallback: Incomplete execs has no queuedTime.\n        ],\n    )\n    res = [ExecutionResult.from_db(execution) for execution in executions]\n    return res", "blocks": [{"id": 1, "label": "async def get_execution_results(graph_exec_id: str) -> list[ExecutionResult]:\nexecutions = await AgentNodeExecution.prisma().find_many(\n    where={\"agentGraphExecutionId\": graph_exec_id},\n    include=EXECUTION_RESULT_INCLUDE,\n    order=[\n        {\"queuedTime\": \"asc\"},\n        {\"addedTime\": \"asc\"},  # Fallback: Incomplete execs has no queuedTime.\n    ],\n)", "successors": [{"id": 3, "label": "res = [ExecutionResult.from_db(execution) for execution in executions]\nreturn res", "successors": []}]}]}, {"name": "parse_execution_output", "type": "function", "start_line": 345, "end_line": 370, "functions": [], "classes": [], "simplified_code": "def parse_execution_output(output: BlockData, name: str) -> Any | None:\n    # Allow extracting partial output data by name.\n    output_name, output_data = output\n\n    if name == output_name:\n        return output_data\n\n    if name.startswith(f\"{output_name}{LIST_SPLIT}\"):\n        index = int(name.split(LIST_SPLIT)[1])\n        if not isinstance(output_data, list) or len(output_data) <= index:\n            return None\n        return output_data[int(name.split(LIST_SPLIT)[1])]\n\n    if name.startswith(f\"{output_name}{DICT_SPLIT}\"):\n        index = name.split(DICT_SPLIT)[1]\n        if not isinstance(output_data, dict) or index not in output_data:\n            return None\n        return output_data[index]\n\n    if name.startswith(f\"{output_name}{OBJC_SPLIT}\"):\n        index = name.split(OBJC_SPLIT)[1]\n        if isinstance(output_data, object) and hasattr(output_data, index):\n            return getattr(output_data, index)\n        return None\n\n    return None", "blocks": [{"id": 1, "label": "def parse_execution_output(output: BlockData, name: str) -> Any | None:\noutput_name, output_data = output", "successors": [{"id": 3, "label": "if name == output_name:", "successors": [{"id": 4, "label": "return output_data", "successors": []}, {"id": 5, "label": "if name.startswith(f\"{output_name}{LIST_SPLIT}\"):", "successors": [{"id": 6, "label": "index = int(name.split(LIST_SPLIT)[1])\nif not isinstance(output_data, list) or len(output_data) <= index:", "successors": [{"id": 8, "label": "return None", "successors": []}, {"id": 9, "label": "return output_data[int(name.split(LIST_SPLIT)[1])]", "successors": []}]}, {"id": 10, "label": "if name.startswith(f\"{output_name}{DICT_SPLIT}\"):", "successors": [{"id": 11, "label": "index = name.split(DICT_SPLIT)[1]\nif not isinstance(output_data, dict) or index not in output_data:", "successors": [{"id": 13, "label": "return None", "successors": []}, {"id": 14, "label": "return output_data[index]", "successors": []}]}, {"id": 15, "label": "if name.startswith(f\"{output_name}{OBJC_SPLIT}\"):\nindex = name.split(OBJC_SPLIT)[1]", "successors": [{"id": 17, "label": "if isinstance(output_data, object) and hasattr(output_data, index):", "successors": [{"id": 18, "label": "return getattr(output_data, index)", "successors": []}, {"id": 19, "label": "return None", "successors": []}]}]}, {"id": 20, "label": "return None", "successors": []}]}]}]}]}]}, {"name": "merge_execution_input", "type": "function", "start_line": 373, "end_line": 415, "functions": [], "classes": [], "simplified_code": "def merge_execution_input(data: BlockInput) -> BlockInput:\n    \"\"\"\n    Merge all dynamic input pins which described by the following pattern:\n    - <input_name>_$_<index> for list input.\n    - <input_name>_#_<index> for dict input.\n    - <input_name>_@_<index> for object input.\n    This function will construct pins with the same name into a single list/dict/object.\n    \"\"\"\n\n    # Merge all input with <input_name>_$_<index> into a single list.\n    items = list(data.items())\n\n    for key, value in items:\n        if LIST_SPLIT not in key:\n            continue\n        name, index = key.split(LIST_SPLIT)\n        if not index.isdigit():\n            raise ValueError(f\"Invalid key: {key}, #{index} index must be an integer.\")\n\n        data[name] = data.get(name, [])\n        if int(index) >= len(data[name]):\n            # Pad list with empty string on missing indices.\n            data[name].extend([\"\"] * (int(index) - len(data[name]) + 1))\n        data[name][int(index)] = value\n\n    # Merge all input with <input_name>_#_<index> into a single dict.\n    for key, value in items:\n        if DICT_SPLIT not in key:\n            continue\n        name, index = key.split(DICT_SPLIT)\n        data[name] = data.get(name, {})\n        data[name][index] = value\n\n    # Merge all input with <input_name>_@_<index> into a single object.\n    for key, value in items:\n        if OBJC_SPLIT not in key:\n            continue\n        name, index = key.split(OBJC_SPLIT)\n        if name not in data or not isinstance(data[name], object):\n            data[name] = mock.MockObject()\n        setattr(data[name], index, value)\n\n    return data", "blocks": [{"id": 1, "label": "items = list(data.items())", "successors": [{"id": 2, "label": "for key, value in items:", "successors": [{"id": 3, "label": "if LIST_SPLIT not in key:\ncontinue", "successors": [{"id": 5, "label": "if DICT_SPLIT not in key:\ncontinue", "successors": [{"id": 7, "label": "if OBJC_SPLIT not in key:\ncontinue", "successors": [{"id": 25, "label": "return data", "successors": []}]}, {"id": 9, "label": "name, index = key.split(OBJC_SPLIT)", "successors": [{"id": 10, "label": "if name not in data or not isinstance(data[name], object):\ndata[name] = mock.MockObject()", "successors": [{"id": 12, "label": "setattr(data[name], index, value)\nreturn data", "successors": []}]}, {"id": 12, "label": "setattr(data[name], index, value)\nreturn data", "successors": []}]}]}, {"id": 13, "label": "name, index = key.split(DICT_SPLIT)\ndata[name] = data.get(name, {})", "successors": [{"id": 15, "label": "data[name][index] = value\nreturn data", "successors": []}]}]}, {"id": 16, "label": "name, index = key.split(LIST_SPLIT)", "successors": [{"id": 17, "label": "if not index.isdigit():\nraise ValueError(f\"Invalid key: {key}, #{index} index must be an integer.\")", "successors": []}, {"id": 19, "label": "data[name] = data.get(name, [])", "successors": [{"id": 20, "label": "if int(index) >= len(data[name]):\ndata[name].extend([\"\"\"] * (int(index) - len(data[name]) + 1))", "successors": [{"id": 22, "label": "data[name][int(index)] = value\nreturn data", "successors": []}]}, {"id": 22, "label": "data[name][int(index)] = value\nreturn data", "successors": []}]}]}]}]}]}, {"name": "get_latest_execution", "type": "function", "start_line": 418, "end_line": 431, "functions": [], "classes": [], "simplified_code": "async def get_latest_execution(node_id: str, graph_eid: str) -> ExecutionResult | None:\n    execution = await AgentNodeExecution.prisma().find_first(\n        where={\n            \"agentNodeId\": node_id,\n            \"agentGraphExecutionId\": graph_eid,\n            \"executionStatus\": {\"not\": ExecutionStatus.INCOMPLETE},\n            \"executionData\": {\"not\": None},  # type: ignore\n        },\n        order={\"queuedTime\": \"desc\"},\n        include=EXECUTION_RESULT_INCLUDE,\n    )\n    if not execution:\n        return None\n    return ExecutionResult.from_db(execution)", "blocks": [{"id": 1, "label": "execution = await AgentNodeExecution.prisma().find_first(\n    where={\n        \"agentNodeId\": node_id,\n        \"agentGraphExecutionId\": graph_eid,\n        \"executionStatus\": {\"not\": ExecutionStatus.INCOMPLETE},\n        \"executionData\": {\"not\": None},  # type: ignore\n    },\n    order={\"queuedTime\": \"desc\"},\n    include=EXECUTION_RESULT_INCLUDE,\n)\nif not execution:", "successors": [{"id": 3, "label": "    return None", "successors": []}, {"id": 4, "label": "return ExecutionResult.from_db(execution)", "successors": []}]}]}, {"name": "get_incomplete_executions", "type": "function", "start_line": 434, "end_line": 445, "functions": [], "classes": [], "simplified_code": "async def get_incomplete_executions(\n    node_id: str, graph_eid: str\n) -> list[ExecutionResult]:\n    executions = await AgentNodeExecution.prisma().find_many(\n        where={\n            \"agentNodeId\": node_id,\n            \"agentGraphExecutionId\": graph_eid,\n            \"executionStatus\": ExecutionStatus.INCOMPLETE,\n        },\n        include=EXECUTION_RESULT_INCLUDE,\n    )\n    return [ExecutionResult.from_db(execution) for execution in executions]", "blocks": [{"id": 1, "label": "async def get_incomplete_executions(\n    node_id: str, graph_eid: str\n) -> list[ExecutionResult]:\nexecutions = await AgentNodeExecution.prisma().find_many(\n    where={\n        \"agentNodeId\": node_id,\n        \"agentGraphExecutionId\": graph_eid,\n        \"executionStatus\": ExecutionStatus.INCOMPLETE,\n    },\n    include=EXECUTION_RESULT_INCLUDE,\n)", "successors": [{"id": 3, "label": "return [ExecutionResult.from_db(execution) for execution in executions]", "successors": []}]}]}], "classes": [{"name": "GraphExecutionEntry", "type": "class", "start_line": 21, "end_line": 25, "functions": [], "classes": [], "simplified_code": "class GraphExecutionEntry(BaseModel):\n    user_id: str\n    graph_exec_id: str\n    graph_id: str\n    start_node_execs: list[\"NodeExecutionEntry\"]", "blocks": [{"id": 1, "label": "class GraphExecutionEntry(BaseModel):\n    user_id: str\n    graph_exec_id: str\n    graph_id: str\n    start_node_execs: list[\"NodeExecutionEntry\"]", "successors": []}]}, {"name": "NodeExecutionEntry", "type": "class", "start_line": 28, "end_line": 34, "functions": [], "classes": [], "simplified_code": "class NodeExecutionEntry(BaseModel):\n    user_id: str\n    graph_exec_id: str\n    graph_id: str\n    node_exec_id: str\n    node_id: str\n    data: BlockInput", "blocks": [{"id": 1, "label": "class NodeExecutionEntry(BaseModel):\n    user_id: str", "successors": [{"id": 3, "label": "    graph_exec_id: str\n    graph_id: str", "successors": [{"id": 5, "label": "    node_exec_id: str\n    node_id: str", "successors": [{"id": 7, "label": "    data: BlockInput", "successors": []}]}]}]}]}, {"name": "ExecutionQueue", "type": "class", "start_line": 42, "end_line": 58, "functions": [{"name": "__init__", "type": "function", "start_line": 48, "end_line": 49, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        self.queue = Manager().Queue()", "blocks": [{"id": 1, "label": "def __init__(self):\n    self.queue = Manager().Queue()", "successors": []}]}, {"name": "add", "type": "function", "start_line": 51, "end_line": 53, "functions": [], "classes": [], "simplified_code": "    def add(self, execution: T) -> T:\n        self.queue.put(execution)\n        return execution", "blocks": [{"id": 1, "label": "def add(self, execution: T) -> T:\n    self.queue.put(execution)", "successors": [{"id": 3, "label": "    return execution", "successors": []}]}]}, {"name": "get", "type": "function", "start_line": 55, "end_line": 56, "functions": [], "classes": [], "simplified_code": "    def get(self) -> T:\n        return self.queue.get()", "blocks": [{"id": 1, "label": "def get(self) -> T:\nreturn self.queue.get()", "successors": []}]}, {"name": "empty", "type": "function", "start_line": 58, "end_line": 59, "functions": [], "classes": [], "simplified_code": "    def empty(self) -> bool:\n        return self.queue.empty()", "blocks": [{"id": 1, "label": "def empty(self) -> bool:\n    return self.queue.empty()", "successors": []}]}], "classes": [], "simplified_code": "class ExecutionQueue(Generic[T]):\n    \"\"\"\n    Queue for managing the execution of agents.\n    This will be shared between different processes\n    \"\"\"\n\n        self.queue = Manager().Queue()\n\n        return execution\n\n        return self.queue.get()\n", "blocks": [{"id": 1, "label": "class ExecutionQueue(Generic[T]):\n\"\"\"\nQueue for managing the execution of agents.\nThis will be shared between different processes\n\"\"\"", "successors": [{"id": 3, "label": "self.queue = Manager().Queue()", "successors": [{"id": 4, "label": "return execution", "successors": []}, {"id": 5, "label": "return self.queue.get()", "successors": []}]}]}]}, {"name": "ExecutionResult", "type": "class", "start_line": 62, "end_line": 128, "functions": [{"name": "from_graph", "type": "function", "start_line": 78, "end_line": 95, "functions": [], "classes": [], "simplified_code": "    def from_graph(graph: AgentGraphExecution):\n        return ExecutionResult(\n            graph_id=graph.agentGraphId,\n            graph_version=graph.agentGraphVersion,\n            graph_exec_id=graph.id,\n            node_exec_id=\"\",\n            node_id=\"\",\n            block_id=\"\",\n            status=graph.executionStatus,\n            # TODO: Populate input_data & output_data from AgentNodeExecutions\n            #       Input & Output comes AgentInputBlock & AgentOutputBlock.\n            input_data={},\n            output_data={},\n            add_time=graph.createdAt,\n            queue_time=graph.createdAt,\n            start_time=graph.startedAt,\n            end_time=graph.updatedAt,\n        )", "blocks": [{"id": 1, "label": "def from_graph(graph: AgentGraphExecution):\nreturn ExecutionResult(\n    graph_id=graph.agentGraphId,\n    graph_version=graph.agentGraphVersion,\n    graph_exec_id=graph.id,\n    node_exec_id=\"\",\n    node_id=\"\",\n    block_id=\"\",\n    status=graph.executionStatus,\n    # TODO: Populate input_data & output_data from AgentNodeExecutions\n    #       Input & Output comes AgentInputBlock & AgentOutputBlock.\n    input_data={},\n    output_data={},\n    add_time=graph.createdAt,\n    queue_time=graph.createdAt,\n    start_time=graph.startedAt,\n    end_time=graph.updatedAt,\n)", "successors": []}]}, {"name": "from_db", "type": "function", "start_line": 98, "end_line": 128, "functions": [], "classes": [], "simplified_code": "    def from_db(execution: AgentNodeExecution):\n        if execution.executionData:\n            # Execution that has been queued for execution will persist its data.\n            input_data = json.loads(execution.executionData, target_type=dict[str, Any])\n        else:\n            # For incomplete execution, executionData will not be yet available.\n            input_data: BlockInput = defaultdict()\n            for data in execution.Input or []:\n                input_data[data.name] = json.loads(data.data)\n\n        output_data: CompletedBlockOutput = defaultdict(list)\n        for data in execution.Output or []:\n            output_data[data.name].append(json.loads(data.data))\n\n        graph_execution: AgentGraphExecution | None = execution.AgentGraphExecution\n\n        return ExecutionResult(\n            graph_id=graph_execution.agentGraphId if graph_execution else \"\",\n            graph_version=graph_execution.agentGraphVersion if graph_execution else 0,\n            graph_exec_id=execution.agentGraphExecutionId,\n            block_id=execution.AgentNode.agentBlockId if execution.AgentNode else \"\",\n            node_exec_id=execution.id,\n            node_id=execution.agentNodeId,\n            status=execution.executionStatus,\n            input_data=input_data,\n            output_data=output_data,\n            add_time=execution.addedTime,\n            queue_time=execution.queuedTime,\n            start_time=execution.startedTime,\n            end_time=execution.endedTime,\n        )", "blocks": [{"id": 1, "label": "def from_db(execution: AgentNodeExecution):\nif execution.executionData:", "successors": [{"id": 3, "label": "input_data = json.loads(execution.executionData, target_type=dict[str, Any])\noutput_data: CompletedBlockOutput = defaultdict(list)", "successors": [{"id": 9, "label": "for data in execution.Output or []:", "successors": [{"id": 10, "label": "output_data[data.name].append(json.loads(data.data))\ngraph_execution: AgentGraphExecution | None = execution.AgentGraphExecution", "successors": [{"id": 12, "label": "return ExecutionResult(\n    graph_id=graph_execution.agentGraphId if graph_execution else \"\",\n    graph_version=graph_execution.agentGraphVersion if graph_execution else 0,\n    graph_exec_id=execution.agentGraphExecutionId,\n    block_id=execution.AgentNode.agentBlockId if execution.AgentNode else \"\",\n    node_exec_id=execution.id,\n    node_id=execution.agentNodeId,\n    status=execution.executionStatus,\n    input_data=input_data,\n    output_data=output_data,\n    add_time=execution.addedTime,\n    queue_time=execution.queuedTime,\n    start_time=execution.startedTime,\n    end_time=execution.endedTime,\n)", "successors": []}]}]}]}, {"id": 4, "label": "input_data: BlockInput = defaultdict()", "successors": [{"id": 5, "label": "for data in execution.Input or []:", "successors": [{"id": 6, "label": "input_data[data.name] = json.loads(data.data)\noutput_data: CompletedBlockOutput = defaultdict(list)", "successors": [{"id": 9, "label": "for data in execution.Output or []:", "successors": [{"id": 10, "label": "output_data[data.name].append(json.loads(data.data))\ngraph_execution: AgentGraphExecution | None = execution.AgentGraphExecution", "successors": [{"id": 12, "label": "return ExecutionResult(\n    graph_id=graph_execution.agentGraphId if graph_execution else \"\",\n    graph_version=graph_execution.agentGraphVersion if graph_execution else 0,\n    graph_exec_id=execution.agentGraphExecutionId,\n    block_id=execution.AgentNode.agentBlockId if execution.AgentNode else \"\",\n    node_exec_id=execution.id,\n    node_id=execution.agentNodeId,\n    status=execution.executionStatus,\n    input_data=input_data,\n    output_data=output_data,\n    add_time=execution.addedTime,\n    queue_time=execution.queuedTime,\n    start_time=execution.startedTime,\n    end_time=execution.endedTime,\n)", "successors": []}]}]}]}]}]}]}]}], "classes": [], "simplified_code": "class ExecutionResult(BaseModel):\n    graph_id: str\n    graph_version: int\n    graph_exec_id: str\n    node_exec_id: str\n    node_id: str\n    block_id: str\n    status: ExecutionStatus\n    input_data: BlockInput\n    output_data: CompletedBlockOutput\n    add_time: datetime\n    queue_time: datetime | None\n    start_time: datetime | None\n    end_time: datetime | None\n\n    @staticmethod\n        )\n\n    @staticmethod\n        )", "blocks": [{"id": 1, "label": "class ExecutionResult(BaseModel):\n graph_id: str\n graph_version: int\n graph_exec_id: str\n node_exec_id: str\n node_id: str\n block_id: str\n status: ExecutionStatus\n input_data: BlockInput\n output_data: CompletedBlockOutput\n add_time: datetime\n queue_time: datetime | None\n start_time: datetime | None\n end_time: datetime | None", "successors": [{"id": 3, "label": "@staticmethod\n def get_node_info() -> List[str]:\n return [\"node_id\", \"block_id\", \"status\"]", "successors": []}, {"id": 5, "label": "@staticmethod\n def get_timing_info() -> List[str]:\n return [\"add_time\", \"queue_time\", \"start_time\", \"end_time\"]", "successors": []}]}]}, {"name": "RedisExecutionEventBus", "type": "class", "start_line": 453, "end_line": 467, "functions": [{"name": "event_bus_name", "type": "function", "start_line": 457, "end_line": 458, "functions": [], "classes": [], "simplified_code": "    def event_bus_name(self) -> str:\n        return config.execution_event_bus_name", "blocks": [{"id": 1, "label": "def event_bus_name(self) -> str:\n    return config.execution_event_bus_name", "successors": []}]}, {"name": "publish", "type": "function", "start_line": 460, "end_line": 461, "functions": [], "classes": [], "simplified_code": "    def publish(self, res: ExecutionResult):\n        self.publish_event(res, f\"{res.graph_id}/{res.graph_exec_id}\")", "blocks": [{"id": 1, "label": "def publish(self, res: ExecutionResult):\nself.publish_event(res, f\"{res.graph_id}/{res.graph_exec_id}\")", "successors": []}]}, {"name": "listen", "type": "function", "start_line": 463, "end_line": 467, "functions": [], "classes": [], "simplified_code": "    def listen(\n        self, graph_id: str = \"*\", graph_exec_id: str = \"*\"\n    ) -> Generator[ExecutionResult, None, None]:\n        for execution_result in self.listen_events(f\"{graph_id}/{graph_exec_id}\"):\n            yield execution_result", "blocks": [{"id": 1, "label": "def listen(self, graph_id: str = \"*\", graph_exec_id: str = \"*\") -> Generator[ExecutionResult, None, None]:", "successors": [{"id": 2, "label": "for execution_result in self.listen_events(f\"{graph_id}/{graph_exec_id}\"):", "successors": [{"id": 3, "label": "    yield execution_result", "successors": []}]}]}]}], "classes": [], "simplified_code": "class RedisExecutionEventBus(RedisEventBus[ExecutionResult]):\n    Model = ExecutionResult\n\n    @property\n        return config.execution_event_bus_name\n\n        self.publish_event(res, f\"{res.graph_id}/{res.graph_exec_id}\")\n\n            yield execution_result", "blocks": [{"id": 1, "label": "class RedisExecutionEventBus(RedisEventBus[ExecutionResult]):", "successors": [{"id": 2, "label": "    Model = ExecutionResult", "successors": []}, {"id": 3, "label": "@property\ndef fetch_event_name(_):", "successors": [{"id": 5, "label": "return config.execution_event_bus_name", "successors": []}]}, {"id": 6, "label": "    def publish_event(self, res, identifier):\nself.publish_event(res, f\"{res.graph_id}/{res.graph_exec_id}\")", "successors": []}, {"id": 8, "label": "def consume_events(self):\nyield execution_result", "successors": []}]}]}, {"name": "AsyncRedisExecutionEventBus", "type": "class", "start_line": 470, "end_line": 484, "functions": [{"name": "event_bus_name", "type": "function", "start_line": 474, "end_line": 475, "functions": [], "classes": [], "simplified_code": "    def event_bus_name(self) -> str:\n        return config.execution_event_bus_name", "blocks": [{"id": 1, "label": "def event_bus_name(self) -> str:\nreturn config.execution_event_bus_name", "successors": []}]}, {"name": "publish", "type": "function", "start_line": 477, "end_line": 478, "functions": [], "classes": [], "simplified_code": "    async def publish(self, res: ExecutionResult):\n        await self.publish_event(res, f\"{res.graph_id}/{res.graph_exec_id}\")", "blocks": [{"id": 1, "label": "async def publish(self, res: ExecutionResult):\n    await self.publish_event(res, f\"{res.graph_id}/{res.graph_exec_id}\")", "successors": []}]}, {"name": "listen", "type": "function", "start_line": 480, "end_line": 483, "functions": [], "classes": [], "simplified_code": "    async def listen(\n        self, graph_id: str = \"*\", graph_exec_id: str = \"*\"\n    ) -> AsyncGenerator[ExecutionResult, None]:\n        async for execution_result in self.listen_events(f\"{graph_id}/{graph_exec_id}\"):", "blocks": [{"id": 1, "label": "async def listen(self, graph_id: str = \"*\", graph_exec_id: str = \"*\") -> AsyncGenerator[ExecutionResult, None]:\n    async for execution_result in self.listen_events(f\"{graph_id}/{graph_exec_id}\"):", "successors": []}]}], "classes": [], "simplified_code": "class AsyncRedisExecutionEventBus(AsyncRedisEventBus[ExecutionResult]):\n    Model = ExecutionResult\n\n    @property\n        return config.execution_event_bus_name\n\n        await self.publish_event(res, f\"{res.graph_id}/{res.graph_exec_id}\")\n\n        async for execution_result in self.listen_events(f\"{graph_id}/{graph_exec_id}\"):\n            yield execution_result", "blocks": [{"id": 1, "label": "class AsyncRedisExecutionEventBus(AsyncRedisEventBus[ExecutionResult]):\n    Model = ExecutionResult", "successors": [{"id": 3, "label": "@property\n    def event_bus_name(self):\n        return config.execution_event_bus_name\nasync def publish_event(self, res, f\"{res.graph_id}/{res.graph_exec_id}\"):\n        await self.publish_event(res, f\"{res.graph_id}/{res.graph_exec_id}\")", "successors": [{"id": 5, "label": "async def listen_and_yield(self, graph_id, graph_exec_id):\n        async for execution_result in self.listen_events(f\"{graph_id}/{graph_exec_id}\"):\n            yield execution_result", "successors": []}]}]}]}], "simplified_code": "from collections import defaultdict\nfrom datetime import datetime, timezone\nfrom multiprocessing import Manager\nfrom typing import Any, AsyncGenerator, Generator, Generic, TypeVar\n\nfrom prisma.enums import AgentExecutionStatus\nfrom prisma.models import (\n    AgentGraphExecution,\n    AgentNodeExecution,\n    AgentNodeExecutionInputOutput,\n)\nfrom pydantic import BaseModel\n\nfrom backend.data.block import BlockData, BlockInput, CompletedBlockOutput\nfrom backend.data.includes import EXECUTION_RESULT_INCLUDE, GRAPH_EXECUTION_INCLUDE\nfrom backend.data.queue import AsyncRedisEventBus, RedisEventBus\nfrom backend.util import json, mock\nfrom backend.util.settings import Config\n\n\n    start_node_execs: list[\"NodeExecutionEntry\"]\n\n\n    data: BlockInput\n\n\nExecutionStatus = AgentExecutionStatus\n\nT = TypeVar(\"T\")\n\n\n    def empty(self) -> bool:\n        return self.queue.empty()\n\n\n        )\n\n\n# --------------------- Model functions --------------------- #\n\n\n    ]\n\n\n        )\n\n\n    )\n\n\n    )\n\n\n    return ExecutionResult.from_graph(res)\n\n\n    )\n\n\n    return ExecutionResult.from_db(res)\n\n\n    return res\n\n\nLIST_SPLIT = \"_$_\"\nDICT_SPLIT = \"_#_\"\nOBJC_SPLIT = \"_@_\"\n\n\n    return None\n\n\n    return data\n\n\n    return ExecutionResult.from_db(execution)\n\n\n    return [ExecutionResult.from_db(execution) for execution in executions]\n\n\n# --------------------- Event Bus --------------------- #\n\nconfig = Config()\n\n\n            yield execution_result\n\n\n            yield execution_result", "blocks": [{"id": 1, "label": "from collections import defaultdict\nfrom datetime import datetime, timezone\nfrom multiprocessing import Manager\nfrom typing import Any, AsyncGenerator, Generator, Generic, TypeVar\n\nfrom prisma.enums import AgentExecutionStatus\nfrom prisma.models import (\n    AgentGraphExecution,\n    AgentNodeExecution,\n    AgentNodeExecutionInputOutput,\n)\nfrom pydantic import BaseModel\n\nfrom backend.data.block import BlockData, BlockInput, CompletedBlockOutput\nfrom backend.data.includes import EXECUTION_RESULT_INCLUDE, GRAPH_EXECUTION_INCLUDE\nfrom backend.data.queue import AsyncRedisEventBus, RedisEventBus\nfrom backend.util import json, mock\nfrom backend.util.settings import Config\n\n\n    start_node_execs: list[\"NodeExecutionEntry\"]\n\n\n    data: BlockInput\n\n\nExecutionStatus = AgentExecutionStatus\n\nT = TypeVar(\"T\")\n\n\n    def empty(self) -> bool:\n        return self.queue.empty()\n\n\n        )\n\n\n# --------------------- Model functions --------------------- #\n\n\n    ]\n\n\n        )\n\n\n    )\n\n\n    )\n\n\n    return ExecutionResult.from_graph(res)\n\n\n    )", "successors": [{"id": 2, "label": "return ExecutionResult.from_db(res)", "successors": []}, {"id": 3, "label": "return res", "successors": []}, {"id": 4, "label": "LIST_SPLIT = \"_$_\",\nDICT_SPLIT = \"_#_\",\nOBJC_SPLIT = \"_@_\"", "successors": []}, {"id": 5, "label": "return None", "successors": []}, {"id": 6, "label": "return data", "successors": []}, {"id": 7, "label": "return ExecutionResult.from_db(execution)", "successors": []}, {"id": 8, "label": "return [ExecutionResult.from_db(execution) for execution in executions]", "successors": []}, {"id": 9, "label": "# --------------------- Event Bus --------------------- #\n\nconfig = Config()", "successors": []}, {"id": 10, "label": "yield execution_result", "successors": []}, {"id": 11, "label": "yield execution_result", "successors": []}]}]}
{"file_name": "123.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 418, "functions": [], "classes": [{"name": "Slant3DCreateOrderBlock", "type": "class", "start_line": 22, "end_line": 95, "functions": [{"name": "__init__", "type": "function", "start_line": 44, "end_line": 77, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"f73007d6-f48f-4aaf-9e6b-6883998a09b4\",\n            description=\"Create a new print order\",\n            input_schema=self.Input,\n            output_schema=self.Output,\n            test_input={\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n                \"order_number\": \"TEST-001\",\n                \"customer\": {\n                    \"name\": \"John Doe\",\n                    \"email\": \"john@example.com\",\n                    \"phone\": \"123-456-7890\",\n                    \"address\": \"123 Test St\",\n                    \"city\": \"Test City\",\n                    \"state\": \"TS\",\n                    \"zip\": \"12345\",\n                },\n                \"items\": [\n                    {\n                        \"file_url\": \"https://example.com/model.stl\",\n                        \"quantity\": \"1\",\n                        \"color\": \"black\",\n                        \"profile\": \"PLA\",\n                    }\n                ],\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[(\"order_id\", \"314144241\")],\n            test_mock={\n                \"_make_request\": lambda *args, **kwargs: {\"orderId\": \"314144241\"},\n                \"_convert_to_color\": lambda *args, **kwargs: \"black\",\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"f73007d6-f48f-4aaf-9e6b-6883998a09b4\",\n    description=\"Create a new print order\",\n    input_schema=self.Input,\n    output_schema=self.Output,\n    test_input={\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n        \"order_number\": \"TEST-001\",\n        \"customer\": {\n            \"name\": \"John Doe\",\n            \"email\": \"john@example.com\",\n            \"phone\": \"123-456-7890\",\n            \"address\": \"123 Test St\",\n            \"city\": \"Test City\",\n            \"state\": \"TS\",\n            \"zip\": \"12345\",\n        },\n        \"items\": [\n            {\n                \"file_url\": \"https://example.com/model.stl\",\n                \"quantity\": \"1\",\n                \"color\": \"black\",\n                \"profile\": \"PLA\",\n            }\n        ],\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[(\"order_id\", \"314144241\")],\n    test_mock={\n        \"_make_request\": lambda *args, **kwargs: {\"orderId\": \"314144241\"},\n        \"_convert_to_color\": lambda *args, **kwargs: \"black\",\n    },\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 79, "end_line": 95, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        try:\n            order_data = self._format_order_data(\n                input_data.customer,\n                input_data.order_number,\n                input_data.items,\n                credentials.api_key.get_secret_value(),\n            )\n            result = self._make_request(\n                \"POST\", \"order\", credentials.api_key.get_secret_value(), json=order_data\n            )\n            yield \"order_id\", result[\"orderId\"]\n        except Exception as e:\n            yield \"error\", str(e)\n            raise", "blocks": [{"id": 1, "label": "def run(\n    self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n) -> BlockOutput:\ntry:", "successors": [{"id": 3, "label": "order_data = self._format_order_data(\n    input_data.customer,\n    input_data.order_number,\n    input_data.items,\n    credentials.api_key.get_secret_value(),\n)\nresult = self._make_request(\n    \"POST\", \"order\", credentials.api_key.get_secret_value(), json=order_data\n)", "successors": [{"id": 5, "label": "yield \"order_id\", result[\"orderId\"]", "successors": []}]}, {"id": 6, "label": "except Exception as e:\nyield \"error\", str(e)", "successors": [{"id": 8, "label": "raise", "successors": []}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 25, "end_line": 38, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: Slant3DCredentialsInput = Slant3DCredentialsField()\n        order_number: str = SchemaField(\n            description=\"Your custom order number (or leave blank for a random one)\",\n            default_factory=lambda: str(uuid.uuid4()),\n        )\n        customer: CustomerDetails = SchemaField(\n            description=\"Customer details for where to ship the item\",\n            advanced=False,\n        )\n        items: List[OrderItem] = SchemaField(\n            description=\"List of items to print\",\n            advanced=False,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "credentials: Slant3DCredentialsInput = Slant3DCredentialsField()", "successors": []}, {"id": 3, "label": "order_number: str = SchemaField(description=\"Your custom order number (or leave blank for a random one)\", default_factory=lambda: str(uuid.uuid4()))", "successors": []}, {"id": 4, "label": "customer: CustomerDetails = SchemaField(description=\"Customer details for where to ship the item\", advanced=False)", "successors": []}, {"id": 5, "label": "items: List[OrderItem] = SchemaField(description=\"List of items to print\", advanced=False)", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 40, "end_line": 42, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        order_id: str = SchemaField(description=\"Slant3D order ID\")\n        error: str = SchemaField(description=\"Error message if order failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    order_id: str = SchemaField(description=\"Slant3D order ID\")\n    error: str = SchemaField(description=\"Error message if order failed\")", "successors": []}]}], "simplified_code": "class Slant3DCreateOrderBlock(Slant3DBlockBase):\n    \"\"\"Block for creating new orders\"\"\"\n\n        )\n\n        error: str = SchemaField(description=\"Error message if order failed\")\n\n        )\n\n            raise", "blocks": [{"id": 1, "label": "class Slant3DCreateOrderBlock(Slant3DBlockBase):\n\"\"\"Block for creating new orders\"\"\"", "successors": [{"id": 3, "label": "error: str = SchemaField(description=\"Error message if order failed\")\nraise", "successors": []}]}]}, {"name": "Slant3DEstimateOrderBlock", "type": "class", "start_line": 98, "end_line": 186, "functions": [{"name": "__init__", "type": "function", "start_line": 122, "end_line": 163, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"bf8823d6-b42a-48c7-b558-d7c117f2ae85\",\n            description=\"Get order cost estimate\",\n            input_schema=self.Input,\n            output_schema=self.Output,\n            test_input={\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n                \"order_number\": \"TEST-001\",\n                \"customer\": {\n                    \"name\": \"John Doe\",\n                    \"email\": \"john@example.com\",\n                    \"phone\": \"123-456-7890\",\n                    \"address\": \"123 Test St\",\n                    \"city\": \"Test City\",\n                    \"state\": \"TS\",\n                    \"zip\": \"12345\",\n                },\n                \"items\": [\n                    {\n                        \"file_url\": \"https://example.com/model.stl\",\n                        \"quantity\": \"1\",\n                        \"color\": \"black\",\n                        \"profile\": \"PLA\",\n                    }\n                ],\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\"total_price\", 9.31),\n                (\"shipping_cost\", 5.56),\n                (\"printing_cost\", 3.75),\n            ],\n            test_mock={\n                \"_make_request\": lambda *args, **kwargs: {\n                    \"totalPrice\": 9.31,\n                    \"shippingCost\": 5.56,\n                    \"printingCost\": 3.75,\n                },\n                \"_convert_to_color\": lambda *args, **kwargs: \"black\",\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"bf8823d6-b42a-48c7-b558-d7c117f2ae85\",\n    description=\"Get order cost estimate\",\n    input_schema=self.Input,\n    output_schema=self.Output,\n    test_input={\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n        \"order_number\": \"TEST-001\",\n        \"customer\": {\n            \"name\": \"John Doe\",\n            \"email\": \"john@example.com\",\n            \"phone\": \"123-456-7890\",\n            \"address\": \"123 Test St\",\n            \"city\": \"Test City\",\n            \"state\": \"TS\",\n            \"zip\": \"12345\",\n        },\n        \"items\": [\n            {\n                \"file_url\": \"https://example.com/model.stl\",\n                \"quantity\": \"1\",\n                \"color\": \"black\",\n                \"profile\": \"PLA\",\n            }\n        ],\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\"total_price\", 9.31),\n        (\"shipping_cost\", 5.56),\n        (\"printing_cost\", 3.75),\n    ],\n    test_mock={\n        \"_make_request\": lambda *args, **kwargs: {\n            \"totalPrice\": 9.31,\n            \"shippingCost\": 5.56,\n            \"printingCost\": 3.75,\n        },\n        \"_convert_to_color\": lambda *args, **kwargs: \"black\",\n    },\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 165, "end_line": 186, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        order_data = self._format_order_data(\n            input_data.customer,\n            input_data.order_number,\n            input_data.items,\n            credentials.api_key.get_secret_value(),\n        )\n        try:\n            result = self._make_request(\n                \"POST\",\n                \"order/estimate\",\n                credentials.api_key.get_secret_value(),\n                json=order_data,\n            )\n            yield \"total_price\", result[\"totalPrice\"]\n            yield \"shipping_cost\", result[\"shippingCost\"]\n            yield \"printing_cost\", result[\"printingCost\"]\n        except baserequests.HTTPError as e:\n            yield \"error\", str(f\"Error estimating order: {e} {e.response.text}\")\n            raise", "blocks": [{"id": 1, "label": "def run(\n    self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n) -> BlockOutput:\n    order_data = self._format_order_data(\n        input_data.customer,\n        input_data.order_number,\n        input_data.items,\n        credentials.api_key.get_secret_value(),\n    )", "successors": [{"id": 3, "label": "try:", "successors": [{"id": 4, "label": "    result = self._make_request(\n        \"POST\",\n        \"order/estimate\",\n        credentials.api_key.get_secret_value(),\n        json=order_data,\n    )\n    yield \"total_price\", result[\"totalPrice\"]", "successors": [{"id": 6, "label": "    yield \"shipping_cost\", result[\"shippingCost\"]\n    yield \"printing_cost\", result[\"printingCost\"]", "successors": []}]}, {"id": 8, "label": "except baserequests.HTTPError as e:\n    yield \"error\", str(f\"Error estimating order: {e} {e.response.text}\")", "successors": [{"id": 10, "label": "    raise", "successors": []}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 101, "end_line": 114, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: Slant3DCredentialsInput = Slant3DCredentialsField()\n        order_number: str = SchemaField(\n            description=\"Your custom order number (or leave blank for a random one)\",\n            default_factory=lambda: str(uuid.uuid4()),\n        )\n        customer: CustomerDetails = SchemaField(\n            description=\"Customer details for where to ship the item\",\n            advanced=False,\n        )\n        items: List[OrderItem] = SchemaField(\n            description=\"List of items to print\",\n            advanced=False,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: Slant3DCredentialsInput = Slant3DCredentialsField()", "successors": [{"id": 3, "label": "    order_number: str = SchemaField(\n        description=\"Your custom order number (or leave blank for a random one)\",\n        default_factory=lambda: str(uuid.uuid4()),\n    )\n    customer: CustomerDetails = SchemaField(\n        description=\"Customer details for where to ship the item\",\n        advanced=False,\n    )", "successors": [{"id": 5, "label": "    items: List[OrderItem] = SchemaField(\n        description=\"List of items to print\",\n        advanced=False,\n    )", "successors": []}]}]}]}, {"name": "Output", "type": "class", "start_line": 116, "end_line": 120, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        total_price: float = SchemaField(description=\"Total price in USD\")\n        shipping_cost: float = SchemaField(description=\"Shipping cost\")\n        printing_cost: float = SchemaField(description=\"Printing cost\")\n        error: str = SchemaField(description=\"Error message if estimation failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    total_price: float = SchemaField(description=\"Total price in USD\")", "successors": [{"id": 3, "label": "    shipping_cost: float = SchemaField(description=\"Shipping cost\")\n    printing_cost: float = SchemaField(description=\"Printing cost\")", "successors": [{"id": 5, "label": "    error: str = SchemaField(description=\"Error message if estimation failed\")", "successors": []}]}]}]}], "simplified_code": "class Slant3DEstimateOrderBlock(Slant3DBlockBase):\n    \"\"\"Block for getting order cost estimates\"\"\"\n\n        )\n\n        error: str = SchemaField(description=\"Error message if estimation failed\")\n\n        )\n\n            raise", "blocks": []}, {"name": "Slant3DEstimateShippingBlock", "type": "class", "start_line": 189, "end_line": 269, "functions": [{"name": "__init__", "type": "function", "start_line": 211, "end_line": 247, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"00aae2a1-caf6-4a74-8175-39a0615d44e1\",\n            description=\"Get shipping cost estimate\",\n            input_schema=self.Input,\n            output_schema=self.Output,\n            test_input={\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n                \"order_number\": \"TEST-001\",\n                \"customer\": {\n                    \"name\": \"John Doe\",\n                    \"email\": \"john@example.com\",\n                    \"phone\": \"123-456-7890\",\n                    \"address\": \"123 Test St\",\n                    \"city\": \"Test City\",\n                    \"state\": \"TS\",\n                    \"zip\": \"12345\",\n                },\n                \"items\": [\n                    {\n                        \"file_url\": \"https://example.com/model.stl\",\n                        \"quantity\": \"1\",\n                        \"color\": \"black\",\n                        \"profile\": \"PLA\",\n                    }\n                ],\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[(\"shipping_cost\", 4.81), (\"currency_code\", \"usd\")],\n            test_mock={\n                \"_make_request\": lambda *args, **kwargs: {\n                    \"shippingCost\": 4.81,\n                    \"currencyCode\": \"usd\",\n                },\n                \"_convert_to_color\": lambda *args, **kwargs: \"black\",\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"00aae2a1-caf6-4a74-8175-39a0615d44e1\",\n    description=\"Get shipping cost estimate\",\n    input_schema=self.Input,\n    output_schema=self.Output,\n    test_input={\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n        \"order_number\": \"TEST-001\",\n        \"customer\": {\n            \"name\": \"John Doe\",\n            \"email\": \"john@example.com\",\n            \"phone\": \"123-456-7890\",\n            \"address\": \"123 Test St\",\n            \"city\": \"Test City\",\n            \"state\": \"TS\",\n            \"zip\": \"12345\",\n        },\n        \"items\": [\n            {\n                \"file_url\": \"https://example.com/model.stl\",\n                \"quantity\": \"1\",\n                \"color\": \"black\",\n                \"profile\": \"PLA\",\n            }\n        ],\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[(\"shipping_cost\", 4.81), (\"currency_code\", \"usd\")],\n    test_mock={\n        \"_make_request\": lambda *args, **kwargs: {\n            \"shippingCost\": 4.81,\n            \"currencyCode\": \"usd\",\n        },\n        \"_convert_to_color\": lambda *args, **kwargs: \"black\",\n    },\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 249, "end_line": 269, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        try:\n            order_data = self._format_order_data(\n                input_data.customer,\n                input_data.order_number,\n                input_data.items,\n                credentials.api_key.get_secret_value(),\n            )\n            result = self._make_request(\n                \"POST\",\n                \"order/estimateShipping\",\n                credentials.api_key.get_secret_value(),\n                json=order_data,\n            )\n            yield \"shipping_cost\", result[\"shippingCost\"]\n            yield \"currency_code\", result[\"currencyCode\"]\n        except Exception as e:\n            yield \"error\", str(e)\n            raise", "blocks": [{"id": 1, "label": "try:", "successors": [{"id": 2, "label": "order_data = self._format_order_data(\n    input_data.customer,\n    input_data.order_number,\n    input_data.items,\n    credentials.api_key.get_secret_value(),\n)\nresult = self._make_request(\n    \"POST\",\n    \"order/estimateShipping\",\n    credentials.api_key.get_secret_value(),\n    json=order_data,\n)", "successors": [{"id": 4, "label": "yield \"shipping_cost\", result[\"shippingCost\"]\nyield \"currency_code\", result[\"currencyCode\"]", "successors": []}]}, {"id": 5, "label": "except Exception as e:\nyield \"error\", str(e)\nraise", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 192, "end_line": 204, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: Slant3DCredentialsInput = Slant3DCredentialsField()\n        order_number: str = SchemaField(\n            description=\"Your custom order number (or leave blank for a random one)\",\n            default_factory=lambda: str(uuid.uuid4()),\n        )\n        customer: CustomerDetails = SchemaField(\n            description=\"Customer details for where to ship the item\"\n        )\n        items: List[OrderItem] = SchemaField(\n            description=\"List of items to print\",\n            advanced=False,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    credentials: Slant3DCredentialsInput = Slant3DCredentialsField()\n    order_number: str = SchemaField(", "successors": [{"id": 4, "label": "        description=\"Your custom order number (or leave blank for a random one)\",\n        default_factory=lambda: str(uuid.uuid4()),", "successors": []}]}, {"id": 6, "label": "    customer: CustomerDetails = SchemaField(\n        description=\"Customer details for where to ship the item\"", "successors": []}, {"id": 8, "label": "    items: List[OrderItem] = SchemaField(\n        description=\"List of items to print\",", "successors": [{"id": 10, "label": "        advanced=False,", "successors": []}]}]}]}, {"name": "Output", "type": "class", "start_line": 206, "end_line": 209, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        shipping_cost: float = SchemaField(description=\"Estimated shipping cost\")\n        currency_code: str = SchemaField(description=\"Currency code (e.g., 'usd')\")\n        error: str = SchemaField(description=\"Error message if estimation failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    shipping_cost: float = SchemaField(description=\"Estimated shipping cost\")\n    currency_code: str = SchemaField(description=\"Currency code (e.g., 'usd')\")\n    error: str = SchemaField(description=\"Error message if estimation failed\")", "successors": []}]}], "simplified_code": "class Slant3DEstimateShippingBlock(Slant3DBlockBase):\n    \"\"\"Block for getting shipping cost estimates\"\"\"\n\n        )\n\n        error: str = SchemaField(description=\"Error message if estimation failed\")\n\n        )\n\n            raise", "blocks": [{"id": 1, "label": "class Slant3DEstimateShippingBlock(Slant3DBlockBase):", "successors": [{"id": 2, "label": "\"\"\"Block for getting shipping cost estimates\"\"\"", "successors": []}, {"id": 3, "label": "error: str = SchemaField(description=\"Error message if estimation failed\")", "successors": []}, {"id": 4, "label": "raise", "successors": []}]}]}, {"name": "Slant3DGetOrdersBlock", "type": "class", "start_line": 272, "end_line": 325, "functions": [{"name": "__init__", "type": "function", "start_line": 282, "end_line": 313, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"42283bf5-8a32-4fb4-92a2-60a9ea48e105\",\n            description=\"Get all orders for the account\",\n            input_schema=self.Input,\n            output_schema=self.Output,\n            # This block is disabled for cloud hosted because it allows access to all orders for the account\n            disabled=settings.Settings().config.behave_as == BehaveAs.CLOUD,\n            test_input={\"credentials\": TEST_CREDENTIALS_INPUT},\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\n                    \"orders\",\n                    [\n                        \"1234567890\",\n                    ],\n                )\n            ],\n            test_mock={\n                \"_make_request\": lambda *args, **kwargs: {\n                    \"ordersData\": [\n                        {\n                            \"orderId\": 1234567890,\n                            \"orderTimestamp\": {\n                                \"_seconds\": 1719510986,\n                                \"_nanoseconds\": 710000000,\n                            },\n                        }\n                    ]\n                }\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"42283bf5-8a32-4fb4-92a2-60a9ea48e105\",\n    description=\"Get all orders for the account\",\n    input_schema=self.Input,\n    output_schema=self.Output,\n    # This block is disabled for cloud hosted because it allows access to all orders for the account\n    disabled=settings.Settings().config.behave_as == BehaveAs.CLOUD,\n    test_input={\"credentials\": TEST_CREDENTIALS_INPUT},\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\n            \"orders\",\n            [\n                \"1234567890\",\n            ],\n        )\n    ],\n    test_mock={\n        \"_make_request\": lambda *args, **kwargs: {\n            \"ordersData\": [\n                {\n                    \"orderId\": 1234567890,\n                    \"orderTimestamp\": {\n                        \"_seconds\": 1719510986,\n                        \"_nanoseconds\": 710000000,\n                    },\n                }\n            ]\n        }\n    },\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 315, "end_line": 325, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        try:\n            result = self._make_request(\n                \"GET\", \"order\", credentials.api_key.get_secret_value()\n            )\n            yield \"orders\", [str(order[\"orderId\"]) for order in result[\"ordersData\"]]\n        except Exception as e:\n            yield \"error\", str(e)\n            raise", "blocks": [{"id": 1, "label": "try:", "successors": [{"id": 2, "label": "    result = self._make_request(\n        \"GET\", \"order\", credentials.api_key.get_secret_value()\n    )\n    yield \"orders\", [str(order[\"orderId\"]) for order in result[\"ordersData\"]]", "successors": []}, {"id": 3, "label": "except Exception as e:\n    yield \"error\", str(e)\n    raise", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 275, "end_line": 276, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: Slant3DCredentialsInput = Slant3DCredentialsField()", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: Slant3DCredentialsInput = Slant3DCredentialsField()", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 278, "end_line": 280, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        orders: List[str] = SchemaField(description=\"List of orders with their details\")\n        error: str = SchemaField(description=\"Error message if request failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\norders: List[str] = SchemaField(description=\"List of orders with their details\")", "successors": [{"id": 3, "label": "error: str = SchemaField(description=\"Error message if request failed\")", "successors": []}]}]}], "simplified_code": "class Slant3DGetOrdersBlock(Slant3DBlockBase):\n    \"\"\"Block for retrieving all orders\"\"\"\n\n        credentials: Slant3DCredentialsInput = Slant3DCredentialsField()\n\n        error: str = SchemaField(description=\"Error message if request failed\")\n\n        )\n\n            raise", "blocks": [{"id": 1, "label": "        self.get_orders()", "successors": []}]}, {"name": "Slant3DTrackingBlock", "type": "class", "start_line": 328, "end_line": 375, "functions": [{"name": "__init__", "type": "function", "start_line": 342, "end_line": 360, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"dd7c0293-c5af-4551-ba3e-fc162fb1fb89\",\n            description=\"Track order status and shipping\",\n            input_schema=self.Input,\n            output_schema=self.Output,\n            test_input={\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n                \"order_id\": \"314144241\",\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[(\"status\", \"awaiting_shipment\"), (\"tracking_numbers\", [])],\n            test_mock={\n                \"_make_request\": lambda *args, **kwargs: {\n                    \"status\": \"awaiting_shipment\",\n                    \"trackingNumbers\": [],\n                }\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"dd7c0293-c5af-4551-ba3e-fc162fb1fb89\",\n    description=\"Track order status and shipping\",\n    input_schema=self.Input,\n    output_schema=self.Output,\n    test_input={\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n        \"order_id\": \"314144241\",\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[(\"status\", \"awaiting_shipment\"), (\"tracking_numbers\", [])],\n    test_mock={\n        \"_make_request\": lambda *args, **kwargs: {\n            \"status\": \"awaiting_shipment\",\n            \"trackingNumbers\": [],\n        }\n    },\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 362, "end_line": 375, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        try:\n            result = self._make_request(\n                \"GET\",\n                f\"order/{input_data.order_id}/get-tracking\",\n                credentials.api_key.get_secret_value(),\n            )\n            yield \"status\", result[\"status\"]\n            yield \"tracking_numbers\", result[\"trackingNumbers\"]\n        except Exception as e:\n            yield \"error\", str(e)\n            raise", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs) -> BlockOutput:", "successors": [{"id": 2, "label": "try:\nresult = self._make_request(\n    \"GET\",\n    f\"order/{input_data.order_id}/get-tracking\",\n    credentials.api_key.get_secret_value(),\n)", "successors": [{"id": 4, "label": "yield \"status\", result[\"status\"]\nyield \"tracking_numbers\", result[\"trackingNumbers\"]", "successors": []}]}, {"id": 6, "label": "except Exception as e:\nyield \"error\", str(e)", "successors": [{"id": 8, "label": "raise", "successors": []}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 331, "end_line": 333, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: Slant3DCredentialsInput = Slant3DCredentialsField()\n        order_id: str = SchemaField(description=\"Slant3D order ID to track\")", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    credentials: Slant3DCredentialsInput = Slant3DCredentialsField()", "successors": []}, {"id": 3, "label": "    order_id: str = SchemaField(description=\"Slant3D order ID to track\")", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 335, "end_line": 340, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        status: str = SchemaField(description=\"Order status\")\n        tracking_numbers: List[str] = SchemaField(\n            description=\"List of tracking numbers\"\n        )\n        error: str = SchemaField(description=\"Error message if tracking failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    status: str = SchemaField(description=\"Order status\")", "successors": [{"id": 3, "label": "    tracking_numbers: List[str] = SchemaField(description=\"List of tracking numbers\")\n    error: str = SchemaField(description=\"Error message if tracking failed\")", "successors": []}]}]}], "simplified_code": "class Slant3DTrackingBlock(Slant3DBlockBase):\n    \"\"\"Block for tracking order status and shipping\"\"\"\n\n        order_id: str = SchemaField(description=\"Slant3D order ID to track\")\n\n        error: str = SchemaField(description=\"Error message if tracking failed\")\n\n        )\n\n            raise", "blocks": [{"id": 1, "label": "class Slant3DTrackingBlock(Slant3DBlockBase):\n    \"\"\"Block for tracking order status and shipping\"\"\"", "successors": [{"id": 3, "label": "    order_id: str = SchemaField(description=\"Slant3D order ID to track\")\n    error: str = SchemaField(description=\"Error message if tracking failed\")", "successors": []}]}]}, {"name": "Slant3DCancelOrderBlock", "type": "class", "start_line": 378, "end_line": 418, "functions": [{"name": "__init__", "type": "function", "start_line": 389, "end_line": 404, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"54de35e1-407f-450b-b5fa-3b5e2eba8185\",\n            description=\"Cancel an existing order\",\n            input_schema=self.Input,\n            output_schema=self.Output,\n            test_input={\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n                \"order_id\": \"314144241\",\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[(\"status\", \"Order cancelled\")],\n            test_mock={\n                \"_make_request\": lambda *args, **kwargs: {\"status\": \"Order cancelled\"}\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"54de35e1-407f-450b-b5fa-3b5e2eba8185\",\n    description=\"Cancel an existing order\",\n    input_schema=self.Input,\n    output_schema=self.Output,\n    test_input={\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n        \"order_id\": \"314144241\",\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[(\"status\", \"Order cancelled\")],\n    test_mock={\n        \"_make_request\": lambda *args, **kwargs: {\"status\": \"Order cancelled\"}\n    },\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 406, "end_line": 418, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        try:\n            result = self._make_request(\n                \"DELETE\",\n                f\"order/{input_data.order_id}\",\n                credentials.api_key.get_secret_value(),\n            )\n            yield \"status\", result[\"status\"]\n        except Exception as e:\n            yield \"error\", str(e)\n            raise", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs) -> BlockOutput:\ntry:", "successors": [{"id": 3, "label": "result = self._make_request(\"DELETE\", f\"order/{input_data.order_id}\", credentials.api_key.get_secret_value())\nyield \"status\", result[\"status\"]", "successors": []}, {"id": 5, "label": "except Exception as e:\nyield \"error\", str(e)", "successors": [{"id": 7, "label": "raise", "successors": []}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 381, "end_line": 383, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: Slant3DCredentialsInput = Slant3DCredentialsField()\n        order_id: str = SchemaField(description=\"Slant3D order ID to cancel\")", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: Slant3DCredentialsInput = Slant3DCredentialsField()", "successors": [{"id": 3, "label": "    order_id: str = SchemaField(description=\"Slant3D order ID to cancel\")", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 385, "end_line": 387, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        status: str = SchemaField(description=\"Cancellation status message\")\n        error: str = SchemaField(description=\"Error message if cancellation failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    status: str = SchemaField(description=\"Cancellation status message\")", "successors": [{"id": 3, "label": "    error: str = SchemaField(description=\"Error message if cancellation failed\")", "successors": []}]}]}], "simplified_code": "class Slant3DCancelOrderBlock(Slant3DBlockBase):\n    \"\"\"Block for canceling orders\"\"\"\n\n        order_id: str = SchemaField(description=\"Slant3D order ID to cancel\")\n\n        error: str = SchemaField(description=\"Error message if cancellation failed\")\n\n        )\n\n            raise", "blocks": [{"id": 1, "label": "class Slant3DCancelOrderBlock(Slant3DBlockBase):\n\"\"\"Block for canceling orders\"\"\"", "successors": [{"id": 3, "label": "order_id: str = SchemaField(description=\"Slant3D order ID to cancel\")\nerror: str = SchemaField(description=\"Error message if cancellation failed\")", "successors": [{"id": 5, "label": "raise", "successors": []}]}]}]}], "simplified_code": "import uuid\nfrom typing import List\n\nimport requests as baserequests\n\nfrom backend.data.block import BlockOutput, BlockSchema\nfrom backend.data.model import APIKeyCredentials, SchemaField\nfrom backend.util import settings\nfrom backend.util.settings import BehaveAs\n\nfrom ._api import (\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    CustomerDetails,\n    OrderItem,\n    Slant3DCredentialsField,\n    Slant3DCredentialsInput,\n)\nfrom .base import Slant3DBlockBase\n\n\n            raise\n\n\n            raise\n\n\n            raise\n\n\n            raise\n\n\n            raise\n\n\n            raise", "blocks": [{"id": 1, "label": "import uuid\nfrom typing import List\n\nimport requests as baserequests\n\nfrom backend.data.block import BlockOutput, BlockSchema\nfrom backend.data.model import APIKeyCredentials, SchemaField\nfrom backend.util import settings\nfrom backend.util.settings import BehaveAs\n\nfrom ._api import (\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    CustomerDetails,\n    OrderItem,\n    Slant3DCredentialsField,\n    Slant3DCredentialsInput,\n)\nfrom .base import Slant3DBlockBase", "successors": [{"id": 2, "label": "raise", "successors": []}, {"id": 3, "label": "raise", "successors": []}, {"id": 4, "label": "raise", "successors": []}, {"id": 5, "label": "raise", "successors": []}, {"id": 6, "label": "raise", "successors": []}, {"id": 7, "label": "raise", "successors": []}]}]}
{"file_name": "124.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 181, "functions": [{"name": "extract_github_error_msg", "type": "function", "start_line": 169, "end_line": 181, "functions": [], "classes": [], "simplified_code": "def extract_github_error_msg(response: requests.Response) -> str:\n    error_msgs = []\n    resp = response.json()\n    if resp.get(\"message\"):\n        error_msgs.append(resp[\"message\"])\n    if resp.get(\"errors\"):\n        error_msgs.extend(f\"* {err.get('message', err)}\" for err in resp[\"errors\"])\n    if resp.get(\"error\"):\n        if isinstance(resp[\"error\"], dict):\n            error_msgs.append(resp[\"error\"].get(\"message\", resp[\"error\"]))\n        else:\n            error_msgs.append(resp[\"error\"])\n    return \"\\n\".join(error_msgs)", "blocks": [{"id": 1, "label": "def extract_github_error_msg(response: requests.Response) -> str:\nerror_msgs = []\nresp = response.json()", "successors": [{"id": 3, "label": "if resp.get(\"message\"):", "successors": [{"id": 4, "label": "error_msgs.append(resp[\"message\"])", "successors": [{"id": 6, "label": "if resp.get(\"errors\"):\nerror_msgs.extend(f\"* {err.get('message', err)}\" for err in resp[\"errors\"])", "successors": [{"id": 9, "label": "if resp.get(\"error\"):", "successors": [{"id": 10, "label": "if isinstance(resp[\"error\"], dict):", "successors": [{"id": 11, "label": "error_msgs.append(resp[\"error\"].get(\"message\", resp[\"error\"]))\nreturn \"\\n\".join(error_msgs)", "successors": []}, {"id": 12, "label": "error_msgs.append(resp[\"error\"])\nreturn \"\\n\".join(error_msgs)", "successors": []}]}, {"id": 13, "label": "return \"\\n\".join(error_msgs)", "successors": []}]}]}, {"id": 6, "label": "if resp.get(\"errors\"):\nerror_msgs.extend(f\"* {err.get('message', err)}\" for err in resp[\"errors\"])", "successors": [{"id": 9, "label": "if resp.get(\"error\"):", "successors": [{"id": 10, "label": "if isinstance(resp[\"error\"], dict):", "successors": [{"id": 11, "label": "error_msgs.append(resp[\"error\"].get(\"message\", resp[\"error\"]))\nreturn \"\\n\".join(error_msgs)", "successors": []}, {"id": 12, "label": "error_msgs.append(resp[\"error\"])\nreturn \"\\n\".join(error_msgs)", "successors": []}]}, {"id": 13, "label": "return \"\\n\".join(error_msgs)", "successors": []}]}]}]}, {"id": 9, "label": "if resp.get(\"error\"):", "successors": [{"id": 10, "label": "if isinstance(resp[\"error\"], dict):", "successors": [{"id": 11, "label": "error_msgs.append(resp[\"error\"].get(\"message\", resp[\"error\"]))\nreturn \"\\n\".join(error_msgs)", "successors": []}, {"id": 12, "label": "error_msgs.append(resp[\"error\"])\nreturn \"\\n\".join(error_msgs)", "successors": []}]}, {"id": 13, "label": "return \"\\n\".join(error_msgs)", "successors": []}]}]}]}]}], "classes": [{"name": "GithubWebhookType", "type": "class", "start_line": 19, "end_line": 20, "functions": [], "classes": [], "simplified_code": "class GithubWebhookType(StrEnum):\n    REPO = \"repo\"", "blocks": [{"id": 1, "label": "class GithubWebhookType(StrEnum):\n    REPO = \"repo\"", "successors": []}]}, {"name": "GithubWebhooksManager", "type": "class", "start_line": 23, "end_line": 166, "functions": [{"name": "validate_payload", "type": "function", "start_line": 31, "end_line": 60, "functions": [], "classes": [], "simplified_code": "    @classmethod\n    async def validate_payload(\n        cls, webhook: integrations.Webhook, request: Request\n    ) -> tuple[dict, str]:\n        if not (event_type := request.headers.get(\"X-GitHub-Event\")):\n            raise HTTPException(\n                status_code=400, detail=\"X-GitHub-Event header is missing!\"\n            )\n\n        if not (signature_header := request.headers.get(\"X-Hub-Signature-256\")):\n            raise HTTPException(\n                status_code=403, detail=\"X-Hub-Signature-256 header is missing!\"\n            )\n\n        payload_body = await request.body()\n        hash_object = hmac.new(\n            webhook.secret.encode(\"utf-8\"), msg=payload_body, digestmod=hashlib.sha256\n        )\n        expected_signature = \"sha256=\" + hash_object.hexdigest()\n\n        if not hmac.compare_digest(expected_signature, signature_header):\n            raise HTTPException(\n                status_code=403, detail=\"Request signatures didn't match!\"\n            )\n\n        payload = await request.json()\n        if action := payload.get(\"action\"):\n            event_type += f\".{action}\"\n\n        return payload, event_type", "blocks": [{"id": 1, "label": "if not (event_type := request.headers.get(\"X-GitHub-Event\")):", "successors": [{"id": 2, "label": "    raise HTTPException(status_code=400, detail=\"X-GitHub-Event header is missing!\")", "successors": []}, {"id": 3, "label": "if not (signature_header := request.headers.get(\"X-Hub-Signature-256\")):", "successors": [{"id": 4, "label": "    raise HTTPException(status_code=403, detail=\"X-Hub-Signature-256 header is missing!\")", "successors": []}, {"id": 5, "label": "payload_body = await request.body()\nhash_object = hmac.new(webhook.secret.encode(\"utf-8\"), msg=payload_body, digestmod=hashlib.sha256)\nexpected_signature = \"sha256=\" + hash_object.hexdigest()\nif not hmac.compare_digest(expected_signature, signature_header):", "successors": [{"id": 7, "label": "    raise HTTPException(status_code=403, detail=\"Request signatures didn't match!\")", "successors": []}, {"id": 8, "label": "payload = await request.json()\nif action := payload.get(\"action\"):\n    event_type += f\".{action}\"\n\nreturn payload, event_type", "successors": []}]}]}]}]}, {"name": "trigger_ping", "type": "function", "start_line": 62, "end_line": 80, "functions": [], "classes": [], "simplified_code": "    async def trigger_ping(\n        self, webhook: integrations.Webhook, credentials: Credentials | None\n    ) -> None:\n        if not credentials:\n            raise ValueError(\"Credentials are required but were not passed\")\n\n        headers = {\n            **self.GITHUB_API_DEFAULT_HEADERS,\n            \"Authorization\": credentials.bearer(),\n        }\n\n        repo, github_hook_id = webhook.resource, webhook.provider_webhook_id\n        ping_url = f\"{self.GITHUB_API_URL}/repos/{repo}/hooks/{github_hook_id}/pings\"\n\n        response = requests.post(ping_url, headers=headers)\n\n        if response.status_code != 204:\n            error_msg = extract_github_error_msg(response)\n            raise ValueError(f\"Failed to ping GitHub webhook: {error_msg}\")", "blocks": [{"id": 1, "label": "async def trigger_ping(\n    self, webhook: integrations.Webhook, credentials: Credentials | None\n) -> None:\nif not credentials:", "successors": [{"id": 3, "label": "    raise ValueError(\"Credentials are required but were not passed\")", "successors": []}, {"id": 4, "label": "headers = {\n    **self.GITHUB_API_DEFAULT_HEADERS,\n    \"Authorization\": credentials.bearer(),\n}\nrepo, github_hook_id = webhook.resource, webhook.provider_webhook_id\nping_url = f\"{self.GITHUB_API_URL}/repos/{repo}/hooks/{github_hook_id}/pings\"", "successors": [{"id": 6, "label": "response = requests.post(ping_url, headers=headers)\nif response.status_code != 204:", "successors": [{"id": 8, "label": "    error_msg = extract_github_error_msg(response)\n    raise ValueError(f\"Failed to ping GitHub webhook: {error_msg}\")", "successors": []}, {"id": 9, "label": "", "successors": []}]}]}]}]}, {"name": "_register_webhook", "type": "function", "start_line": 82, "end_line": 132, "functions": [], "classes": [], "simplified_code": "    async def _register_webhook(\n        self,\n        credentials: Credentials,\n        webhook_type: GithubWebhookType,\n        resource: str,\n        events: list[str],\n        ingress_url: str,\n        secret: str,\n    ) -> tuple[str, dict]:\n        if webhook_type == self.WebhookType.REPO and resource.count(\"/\") > 1:\n            raise ValueError(\"Invalid repo format: expected 'owner/repo'\")\n\n        # Extract main event, e.g. `pull_request.opened` -> `pull_request`\n        github_events = list({event.split(\".\")[0] for event in events})\n\n        headers = {\n            **self.GITHUB_API_DEFAULT_HEADERS,\n            \"Authorization\": credentials.bearer(),\n        }\n        webhook_data = {\n            \"name\": \"web\",\n            \"active\": True,\n            \"events\": github_events,\n            \"config\": {\n                \"url\": ingress_url,\n                \"content_type\": \"json\",\n                \"insecure_ssl\": \"0\",\n                \"secret\": secret,\n            },\n        }\n\n        response = requests.post(\n            f\"{self.GITHUB_API_URL}/repos/{resource}/hooks\",\n            headers=headers,\n            json=webhook_data,\n        )\n\n        if response.status_code != 201:\n            error_msg = extract_github_error_msg(response)\n            if \"not found\" in error_msg.lower():\n                error_msg = (\n                    f\"{error_msg} \"\n                    \"(Make sure the GitHub account or API key has 'repo' or \"\n                    f\"webhook create permissions to '{resource}')\"\n                )\n            raise ValueError(f\"Failed to create GitHub webhook: {error_msg}\")\n\n        webhook_id = response.json()[\"id\"]\n        config = response.json()[\"config\"]\n\n        return str(webhook_id), config", "blocks": [{"id": 1, "label": "async def _register_webhook(...)", "successors": [{"id": 2, "label": "if webhook_type == self.WebhookType.REPO and resource.count(\"/\") > 1:\nraise ValueError(\"Invalid repo format: expected 'owner/repo'\")", "successors": []}, {"id": 4, "label": "github_events = list({event.split(\".\")[0] for event in events})\nheaders = {...}", "successors": [{"id": 6, "label": "webhook_data = {...}\nresponse = requests.post(...)", "successors": [{"id": 8, "label": "if response.status_code != 201:\nerror_msg = extract_github_error_msg(response)", "successors": [{"id": 10, "label": "if \"not found\" in error_msg.lower():\nerror_msg = ...", "successors": []}, {"id": 12, "label": "raise ValueError(f\"Failed to create GitHub webhook: {error_msg}\")", "successors": []}]}, {"id": 13, "label": "webhook_id = response.json()[\"id\"]\nconfig = response.json()[\"config\"]", "successors": [{"id": 15, "label": "return str(webhook_id), config", "successors": []}]}]}]}]}]}, {"name": "_deregister_webhook", "type": "function", "start_line": 134, "end_line": 161, "functions": [], "classes": [], "simplified_code": "    async def _deregister_webhook(\n        self, webhook: integrations.Webhook, credentials: Credentials\n    ) -> None:\n        webhook_type = self.WebhookType(webhook.webhook_type)\n        if webhook.credentials_id != credentials.id:\n            raise ValueError(\n                f\"Webhook #{webhook.id} does not belong to credentials {credentials.id}\"\n            )\n\n        headers = {\n            **self.GITHUB_API_DEFAULT_HEADERS,\n            \"Authorization\": credentials.bearer(),\n        }\n\n        if webhook_type == self.WebhookType.REPO:\n            repo = webhook.resource\n            delete_url = f\"{self.GITHUB_API_URL}/repos/{repo}/hooks/{webhook.provider_webhook_id}\"  # noqa\n        else:\n            raise NotImplementedError(\n                f\"Unsupported webhook type '{webhook.webhook_type}'\"\n            )\n\n        response = requests.delete(delete_url, headers=headers)\n\n        if response.status_code not in [204, 404]:\n            # 204 means successful deletion, 404 means the webhook was already deleted\n            error_msg = extract_github_error_msg(response)\n            raise ValueError(f\"Failed to delete GitHub webhook: {error_msg}\")", "blocks": [{"id": 1, "label": "async def _deregister_webhook(\n    self, webhook: integrations.Webhook, credentials: Credentials\n) -> None:\nwebhook_type = self.WebhookType(webhook.webhook_type)", "successors": [{"id": 3, "label": "if webhook.credentials_id != credentials.id:", "successors": [{"id": 4, "label": "    raise ValueError(\n        f\"Webhook #{webhook.id} does not belong to credentials {credentials.id}\"\n    )", "successors": []}, {"id": 5, "label": "headers = {\n    **self.GITHUB_API_DEFAULT_HEADERS,\n    \"Authorization\": credentials.bearer(),\n}\nif webhook_type == self.WebhookType.REPO:", "successors": [{"id": 7, "label": "    repo = webhook.resource\n    delete_url = f\"{self.GITHUB_API_URL}/repos/{repo}/hooks/{webhook.provider_webhook_id}\"  # noqa\nresponse = requests.delete(delete_url, headers=headers)", "successors": [{"id": 10, "label": "if response.status_code not in [204, 404]:\n    error_msg = extract_github_error_msg(response)\n    raise ValueError(f\"Failed to delete GitHub webhook: {error_msg}\")", "successors": []}]}, {"id": 8, "label": "    raise NotImplementedError(\n        f\"Unsupported webhook type '{webhook.webhook_type}'\"\n    )", "successors": []}]}]}]}]}], "classes": [], "simplified_code": "class GithubWebhooksManager(BaseWebhooksManager):\n    PROVIDER_NAME = ProviderName.GITHUB\n\n    WebhookType = GithubWebhookType\n\n    GITHUB_API_URL = \"https://api.github.com\"\n    GITHUB_API_DEFAULT_HEADERS = {\"Accept\": \"application/vnd.github.v3+json\"}\n\n        return payload, event_type\n\n            raise ValueError(f\"Failed to ping GitHub webhook: {error_msg}\")\n\n        return str(webhook_id), config\n\n            raise ValueError(f\"Failed to delete GitHub webhook: {error_msg}\")\n\n        # If we reach here, the webhook was successfully deleted or didn't exist\n\n\n# --8<-- [end:GithubWebhooksManager]", "blocks": [{"id": 1, "label": "class GithubWebhooksManager(BaseWebhooksManager):", "successors": [{"id": 2, "label": "PROVIDER_NAME = ProviderName.GITHUB", "successors": []}, {"id": 3, "label": "WebhookType = GithubWebhookType", "successors": []}, {"id": 4, "label": "GITHUB_API_URL = \"https://api.github.com\"", "successors": []}, {"id": 5, "label": "GITHUB_API_DEFAULT_HEADERS = {\"Accept\": \"application/vnd.github.v3+json\"}", "successors": []}, {"id": 6, "label": "return payload, event_type", "successors": []}, {"id": 7, "label": "raise ValueError(f\"Failed to ping GitHub webhook: {error_msg}\")", "successors": []}, {"id": 8, "label": "return str(webhook_id), config", "successors": []}, {"id": 9, "label": "raise ValueError(f\"Failed to delete GitHub webhook: {error_msg}\")", "successors": []}, {"id": 10, "label": "# If we reach here, the webhook was successfully deleted or didn't exist", "successors": []}]}]}], "simplified_code": "import hashlib\nimport hmac\nimport logging\n\nimport requests\nfrom fastapi import HTTPException, Request\nfrom strenum import StrEnum\n\nfrom backend.data import integrations\nfrom backend.data.model import Credentials\nfrom backend.integrations.providers import ProviderName\n\nfrom ._base import BaseWebhooksManager\n\nlogger = logging.getLogger(__name__)\n\n\n# --8<-- [start:GithubWebhooksManager]\n    REPO = \"repo\"\n\n\n# --8<-- [end:GithubWebhooksManager]\n\n\n    return \"\\n\".join(error_msgs)", "blocks": [{"id": 1, "label": "import hashlib\nimport hmac\nimport logging\n\nimport requests\nfrom fastapi import HTTPException, Request\nfrom strenum import StrEnum\n\nfrom backend.data import integrations\nfrom backend.data.model import Credentials\nfrom backend.integrations.providers import ProviderName\n\nfrom ._base import BaseWebhooksManager\n\nlogger = logging.getLogger(__name__)", "successors": []}]}
{"file_name": "125.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 199, "functions": [], "classes": [{"name": "FalModel", "type": "class", "start_line": 21, "end_line": 23, "functions": [], "classes": [], "simplified_code": "class FalModel(str, Enum):\n    MOCHI = \"fal-ai/mochi-v1\"\n    LUMA = \"fal-ai/luma-dream-machine\"", "blocks": [{"id": 1, "label": "class FalModel(str, Enum):", "successors": [{"id": 2, "label": "    MOCHI = \"fal-ai/mochi-v1\"", "successors": []}, {"id": 3, "label": "    LUMA = \"fal-ai/luma-dream-machine\"", "successors": []}]}]}, {"name": "AIVideoGeneratorBlock", "type": "class", "start_line": 26, "end_line": 199, "functions": [{"name": "__init__", "type": "function", "start_line": 48, "end_line": 65, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"530cf046-2ce0-4854-ae2c-659db17c7a46\",\n            description=\"Generate videos using FAL AI models.\",\n            categories={BlockCategory.AI},\n            input_schema=self.Input,\n            output_schema=self.Output,\n            test_input={\n                \"prompt\": \"A dog running in a field.\",\n                \"model\": FalModel.MOCHI,\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[(\"video_url\", \"https://fal.media/files/example/video.mp4\")],\n            test_mock={\n                \"generate_video\": lambda *args, **kwargs: \"https://fal.media/files/example/video.mp4\"\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"530cf046-2ce0-4854-ae2c-659db17c7a46\",\n    description=\"Generate videos using FAL AI models.\",\n    categories={BlockCategory.AI},\n    input_schema=self.Input,\n    output_schema=self.Output,\n    test_input={\n        \"prompt\": \"A dog running in a field.\",\n        \"model\": FalModel.MOCHI,\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[(\"video_url\", \"https://fal.media/files/example/video.mp4\")],\n    test_mock={\n        \"generate_video\": lambda *args, **kwargs: \"https://fal.media/files/example/video.mp4\"\n    },\n)", "successors": []}]}, {"name": "_get_headers", "type": "function", "start_line": 67, "end_line": 72, "functions": [], "classes": [], "simplified_code": "    def _get_headers(self, api_key: str) -> dict[str, str]:\n        \"\"\"Get headers for FAL API requests.\"\"\"\n        return {\n            \"Authorization\": f\"Key {api_key}\",\n            \"Content-Type\": \"application/json\",\n        }", "blocks": [{"id": 1, "label": "def _get_headers(self, api_key: str) -> dict[str, str]:\n    return {\"Authorization\": f\"Key {api_key}\", \"Content-Type\": \"application/json\", }", "successors": []}]}, {"name": "_submit_request", "type": "function", "start_line": 74, "end_line": 84, "functions": [], "classes": [], "simplified_code": "    def _submit_request(\n        self, url: str, headers: dict[str, str], data: dict[str, Any]\n    ) -> dict[str, Any]:\n        \"\"\"Submit a request to the FAL API.\"\"\"\n        try:\n            response = httpx.post(url, headers=headers, json=data)\n            response.raise_for_status()\n            return response.json()\n        except httpx.HTTPError as e:\n            logger.error(f\"FAL API request failed: {str(e)}\")\n            raise RuntimeError(f\"Failed to submit request: {str(e)}\")", "blocks": [{"id": 1, "label": "def _submit_request(\n    self, url: str, headers: dict[str, str], data: dict[str, Any]\n) -> dict[str, Any]:\n\"\"\"Submit a request to the FAL API.\"\"\"", "successors": [{"id": 3, "label": "try:", "successors": [{"id": 4, "label": "    response = httpx.post(url, headers=headers, json=data)\n    response.raise_for_status()\n    return response.json()", "successors": []}, {"id": 5, "label": "except httpx.HTTPError as e:\n    logger.error(f\"FAL API request failed: {str(e)}\")\n    raise RuntimeError(f\"Failed to submit request: {str(e)}\")", "successors": []}]}]}]}, {"name": "_poll_status", "type": "function", "start_line": 86, "end_line": 94, "functions": [], "classes": [], "simplified_code": "    def _poll_status(self, status_url: str, headers: dict[str, str]) -> dict[str, Any]:\n        \"\"\"Poll the status endpoint until completion or failure.\"\"\"\n        try:\n            response = httpx.get(status_url, headers=headers)\n            response.raise_for_status()\n            return response.json()\n        except httpx.HTTPError as e:\n            logger.error(f\"Failed to get status: {str(e)}\")\n            raise RuntimeError(f\"Failed to get status: {str(e)}\")", "blocks": [{"id": 1, "label": "def _poll_status(self, status_url: str, headers: dict[str, str]) -> dict[str, Any]:\n    \"\"\"Poll the status endpoint until completion or failure.\"\"\"\ntry:", "successors": [{"id": 3, "label": "    response = httpx.get(status_url, headers=headers)\n    response.raise_for_status()\n    return response.json()", "successors": []}, {"id": 4, "label": "except httpx.HTTPError as e:\n    logger.error(f\"Failed to get status: {str(e)}\")\n    raise RuntimeError(f\"Failed to get status: {str(e)}\")", "successors": []}]}]}, {"name": "generate_video", "type": "function", "start_line": 96, "end_line": 189, "functions": [], "classes": [], "simplified_code": "    def generate_video(self, input_data: Input, credentials: FalCredentials) -> str:\n        \"\"\"Generate video using the specified FAL model.\"\"\"\n        base_url = \"https://queue.fal.run\"\n        api_key = credentials.api_key.get_secret_value()\n        headers = self._get_headers(api_key)\n\n        # Submit generation request\n        submit_url = f\"{base_url}/{input_data.model.value}\"\n        submit_data = {\"prompt\": input_data.prompt}\n\n        seen_logs = set()\n\n        try:\n            # Submit request to queue\n            submit_response = httpx.post(submit_url, headers=headers, json=submit_data)\n            submit_response.raise_for_status()\n            request_data = submit_response.json()\n\n            # Get request_id and urls from initial response\n            request_id = request_data.get(\"request_id\")\n            status_url = request_data.get(\"status_url\")\n            result_url = request_data.get(\"response_url\")\n\n            if not all([request_id, status_url, result_url]):\n                raise ValueError(\"Missing required data in submission response\")\n\n            # Poll for status with exponential backoff\n            max_attempts = 30\n            attempt = 0\n            base_wait_time = 5\n\n            while attempt < max_attempts:\n                status_response = httpx.get(f\"{status_url}?logs=1\", headers=headers)\n                status_response.raise_for_status()\n                status_data = status_response.json()\n\n                # Process new logs only\n                logs = status_data.get(\"logs\", [])\n                if logs and isinstance(logs, list):\n                    for log in logs:\n                        if isinstance(log, dict):\n                            # Create a unique key for this log entry\n                            log_key = (\n                                f\"{log.get('timestamp', '')}-{log.get('message', '')}\"\n                            )\n                            if log_key not in seen_logs:\n                                seen_logs.add(log_key)\n                                message = log.get(\"message\", \"\")\n                                if message:\n                                    logger.debug(\n                                        f\"[FAL Generation] [{log.get('level', 'INFO')}] [{log.get('source', '')}] [{log.get('timestamp', '')}] {message}\"\n                                    )\n\n                status = status_data.get(\"status\")\n                if status == \"COMPLETED\":\n                    # Get the final result\n                    result_response = httpx.get(result_url, headers=headers)\n                    result_response.raise_for_status()\n                    result_data = result_response.json()\n\n                    if \"video\" not in result_data or not isinstance(\n                        result_data[\"video\"], dict\n                    ):\n                        raise ValueError(\"Invalid response format - missing video data\")\n\n                    video_url = result_data[\"video\"].get(\"url\")\n                    if not video_url:\n                        raise ValueError(\"No video URL in response\")\n\n                    return video_url\n\n                elif status == \"FAILED\":\n                    error_msg = status_data.get(\"error\", \"No error details provided\")\n                    raise RuntimeError(f\"Video generation failed: {error_msg}\")\n                elif status == \"IN_QUEUE\":\n                    position = status_data.get(\"queue_position\", \"unknown\")\n                    logger.debug(\n                        f\"[FAL Generation] Status: In queue, position: {position}\"\n                    )\n                elif status == \"IN_PROGRESS\":\n                    logger.debug(\n                        \"[FAL Generation] Status: Request is being processed...\"\n                    )\n                else:\n                    logger.info(f\"[FAL Generation] Status: Unknown status: {status}\")\n\n                wait_time = min(base_wait_time * (2**attempt), 60)  # Cap at 60 seconds\n                time.sleep(wait_time)\n                attempt += 1\n\n            raise RuntimeError(\"Maximum polling attempts reached\")\n\n        except httpx.HTTPError as e:\n            raise RuntimeError(f\"API request failed: {str(e)}\")", "blocks": [{"id": 1, "label": "def generate_video(self, input_data: Input, credentials: FalCredentials) -> str:\nbase_url = \"https://queue.fal.run\"\napi_key = credentials.api_key.get_secret_value()\nheaders = self._get_headers(api_key)\n\n# Submit generation request\nsubmit_url = f\"{base_url}/{input_data.model.value}\"\nsubmit_data = {\"prompt\": input_data.prompt}\n\nseen_logs = set()", "successors": [{"id": 3, "label": "try:", "successors": [{"id": 4, "label": "submit_response = httpx.post(submit_url, headers=headers, json=submit_data)\nsubmit_response.raise_for_status()\nrequest_data = submit_response.json()\n\n# Get request_id and urls from initial response\nrequest_id = request_data.get(\"request_id\")\nstatus_url = request_data.get(\"status_url\")\nresult_url = request_data.get(\"response_url\")", "successors": [{"id": 5, "label": "if not all([request_id, status_url, result_url]):\nraise ValueError(\"Missing required data in submission response\")", "successors": []}, {"id": 7, "label": "# Poll for status with exponential backoff\nmax_attempts = 30\nattempt = 0\nbase_wait_time = 5", "successors": [{"id": 8, "label": "while attempt < max_attempts:", "successors": [{"id": 9, "label": "status_response = httpx.get(f\"{status_url}?logs=1\", headers=headers)\nstatus_response.raise_for_status()\nstatus_data = status_response.json()\n# Process new logs only\nlogs = status_data.get(\"logs\", [])\nif logs and isinstance(logs, list):\n    for log in logs:\n        if isinstance(log, dict):\n            # Create a unique key for this log entry\n            log_key = (\n                f\"{log.get('timestamp', '')}-{log.get('message', '')}\"\n            )\n            if log_key not in seen_logs:\n                seen_logs.add(log_key)\n                message = log.get(\"message\", \"\")\n                if message:\n                    logger.debug(\n                        f\"[FAL Generation] [{log.get('level', 'INFO')}] [{log.get('source', '')}] [{log.get('timestamp', '')}] {message}\"\n                    )", "successors": [{"id": 11, "label": "status = status_data.get(\"status\")\nif status == \"COMPLETED\":", "successors": [{"id": 12, "label": "result_response = httpx.get(result_url, headers=headers)\nresult_response.raise_for_status()\nresult_data = result_response.json()\n\nif \"video\" not in result_data or not isinstance(\n    result_data[\"video\"], dict\n):\n    raise ValueError(\"Invalid response format - missing video data\")\n\nvideo_url = result_data[\"video\"].get(\"url\")\nif not video_url:\n    raise ValueError(\"No video URL in response\")\n\nreturn video_url", "successors": []}, {"id": 13, "label": "elif status == \"FAILED\":\nerror_msg = status_data.get(\"error\", \"No error details provided\")\nraise RuntimeError(f\"Video generation failed: {error_msg}\")", "successors": []}, {"id": 15, "label": "elif status == \"IN_QUEUE\":\nposition = status_data.get(\"queue_position\", \"unknown\")\nlogger.debug(\n    f\"[FAL Generation] Status: In queue, position: {position}\"\n)", "successors": []}, {"id": 17, "label": "elif status == \"IN_PROGRESS\":\nlogger.debug(\n    \"[FAL Generation] Status: Request is being processed...\"\n)", "successors": []}, {"id": 19, "label": "else:\nlogger.info(f\"[FAL Generation] Status: Unknown status: {status}\")", "successors": []}, {"id": 21, "label": "wait_time = min(base_wait_time * (2**attempt), 60)  # Cap at 60 seconds\ntime.sleep(wait_time)\nattempt += 1", "successors": []}]}]}]}, {"id": 22, "label": "raise RuntimeError(\"Maximum polling attempts reached\")", "successors": []}]}]}, {"id": 23, "label": "except httpx.HTTPError as e:\nraise RuntimeError(f\"API request failed: {str(e)}\")", "successors": []}]}]}]}, {"name": "run", "type": "function", "start_line": 191, "end_line": 199, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: FalCredentials, **kwargs\n    ) -> BlockOutput:\n        try:\n            video_url = self.generate_video(input_data, credentials)\n            yield \"video_url\", video_url\n        except Exception as e:\n            error_message = str(e)\n            yield \"error\", error_message", "blocks": [{"id": 1, "label": "def run(\n        self, input_data: Input, *, credentials: FalCredentials, **kwargs\n    ) -> BlockOutput:\ntry:", "successors": [{"id": 3, "label": "    video_url = self.generate_video(input_data, credentials)\n    yield \"video_url\", video_url\n", "successors": []}, {"id": 4, "label": "except Exception as e:\n    error_message = str(e)\n    yield \"error\", error_message", "successors": [{"id": 5, "label": "", "successors": []}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 27, "end_line": 37, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        prompt: str = SchemaField(\n            description=\"Description of the video to generate.\",\n            placeholder=\"A dog running in a field.\",\n        )\n        model: FalModel = SchemaField(\n            title=\"FAL Model\",\n            default=FalModel.MOCHI,\n            description=\"The FAL model to use for video generation.\",\n        )\n        credentials: FalCredentialsInput = FalCredentialsField()", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\nprompt: str = SchemaField(description=\"Description of the video to generate.\", placeholder=\"A dog running in a field.\")", "successors": [{"id": 3, "label": "model: FalModel = SchemaField(title=\"FAL Model\", default=FalModel.MOCHI, description=\"The FAL model to use for video generation.\")\ncredentials: FalCredentialsInput = FalCredentialsField()", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 39, "end_line": 46, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        video_url: str = SchemaField(description=\"The URL of the generated video.\")\n        error: str = SchemaField(\n            description=\"Error message if video generation failed.\"\n        )\n        logs: list[str] = SchemaField(\n            description=\"Generation progress logs.\", optional=True\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "    video_url: str = SchemaField(description=\"The URL of the generated video.\")", "successors": []}, {"id": 3, "label": "    error: str = SchemaField(description=\"Error message if video generation failed.\")", "successors": []}, {"id": 4, "label": "    logs: list[str] = SchemaField(description=\"Generation progress logs.\", optional=True)", "successors": []}]}]}], "simplified_code": "class AIVideoGeneratorBlock(Block):\n        credentials: FalCredentialsInput = FalCredentialsField()\n\n        )\n\n        )\n\n        }\n\n            raise RuntimeError(f\"Failed to submit request: {str(e)}\")\n\n            raise RuntimeError(f\"Failed to get status: {str(e)}\")\n\n            raise RuntimeError(f\"API request failed: {str(e)}\")\n\n            yield \"error\", error_message", "blocks": [{"id": 1, "label": "class AIVideoGeneratorBlock(Block):\ncredentials: FalCredentialsInput = FalCredentialsField()", "successors": []}]}], "simplified_code": "import logging\nimport time\nfrom enum import Enum\nfrom typing import Any\n\nimport httpx\n\nfrom backend.blocks.fal._auth import (\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    FalCredentials,\n    FalCredentialsField,\n    FalCredentialsInput,\n)\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\nlogger = logging.getLogger(__name__)\n\n\n    LUMA = \"fal-ai/luma-dream-machine\"\n\n\n            yield \"error\", error_message", "blocks": [{"id": 1, "label": "import logging\nimport time\nfrom enum import Enum\nfrom typing import Any\n\nimport httpx\n\nfrom backend.blocks.fal._auth import (\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    FalCredentials,\n    FalCredentialsField,\n    FalCredentialsInput,\n)\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\nlogger = logging.getLogger(__name__)\n\nLUMA = \"fal-ai/luma-dream-machine\"", "successors": []}]}
{"file_name": "126.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 30, "functions": [{"name": "find_previous_power_of_two", "type": "function", "start_line": 1, "end_line": 24, "functions": [], "classes": [], "simplified_code": "def find_previous_power_of_two(number: int) -> int:\n    \"\"\"\n    Find the largest power of two that is less than or equal to a given integer.\n    https://stackoverflow.com/questions/1322510\n\n    >>> [find_previous_power_of_two(i) for i in range(18)]\n    [0, 1, 2, 2, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 16, 16]\n    >>> find_previous_power_of_two(-5)\n    Traceback (most recent call last):\n        ...\n    ValueError: Input must be a non-negative integer\n    >>> find_previous_power_of_two(10.5)\n    Traceback (most recent call last):\n        ...\n    ValueError: Input must be a non-negative integer\n    \"\"\"\n    if not isinstance(number, int) or number < 0:\n        raise ValueError(\"Input must be a non-negative integer\")\n    if number == 0:\n        return 0\n    power = 1\n    while power <= number:\n        power <<= 1  # Equivalent to multiplying by 2\n    return power >> 1 if number > 1 else 1", "blocks": [{"id": 1, "label": "def find_previous_power_of_two(number: int) -> int:", "successors": [{"id": 2, "label": "if not isinstance(number, int) or number < 0:\nraise ValueError(\"Input must be a non-negative integer\")", "successors": []}, {"id": 4, "label": "if number == 0:\nreturn 0", "successors": []}, {"id": 6, "label": "power = 1", "successors": [{"id": 7, "label": "while power <= number:", "successors": [{"id": 8, "label": "power <<= 1", "successors": [{"id": 7, "label": "while power <= number:", "successors": [{"id": 8, "label": "power <<= 1", "successors": []}]}]}]}, {"id": 9, "label": "return power >> 1 if number > 1 else 1", "successors": []}]}]}]}], "classes": [], "simplified_code": "    return power >> 1 if number > 1 else 1\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()", "blocks": [{"id": 1, "label": "return power >> 1 if number > 1 else 1", "successors": []}]}
{"file_name": "127.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 197, "functions": [{"name": "solve_maze", "type": "function", "start_line": 4, "end_line": 136, "functions": [], "classes": [], "simplified_code": "def solve_maze(\n    maze: list[list[int]],\n    source_row: int,\n    source_column: int,\n    destination_row: int,\n    destination_column: int,\n) -> list[list[int]]:\n    \"\"\"\n    This method solves the \"rat in maze\" problem.\n    Parameters :\n        - maze: A two dimensional matrix of zeros and ones.\n        - source_row: The row index of the starting point.\n        - source_column: The column index of the starting point.\n        - destination_row: The row index of the destination point.\n        - destination_column: The column index of the destination point.\n    Returns:\n        - solution: A 2D matrix representing the solution path if it exists.\n    Raises:\n        - ValueError: If no solution exists or if the source or\n            destination coordinates are invalid.\n    Description:\n        This method navigates through a maze represented as an n by n matrix,\n        starting from a specified source cell and\n        aiming to reach a destination cell.\n        The maze consists of walls (1s) and open paths (0s).\n        By providing custom row and column values, the source and destination\n        cells can be adjusted.\n    >>> maze = [[0, 1, 0, 1, 1],\n    ...         [0, 0, 0, 0, 0],\n    ...         [1, 0, 1, 0, 1],\n    ...         [0, 0, 1, 0, 0],\n    ...         [1, 0, 0, 1, 0]]\n    >>> solve_maze(maze,0,0,len(maze)-1,len(maze)-1)    # doctest: +NORMALIZE_WHITESPACE\n    [[0, 1, 1, 1, 1],\n    [0, 0, 0, 0, 1],\n    [1, 1, 1, 0, 1],\n    [1, 1, 1, 0, 0],\n    [1, 1, 1, 1, 0]]\n\n    Note:\n        In the output maze, the zeros (0s) represent one of the possible\n        paths from the source to the destination.\n\n    >>> maze = [[0, 1, 0, 1, 1],\n    ...         [0, 0, 0, 0, 0],\n    ...         [0, 0, 0, 0, 1],\n    ...         [0, 0, 0, 0, 0],\n    ...         [0, 0, 0, 0, 0]]\n    >>> solve_maze(maze,0,0,len(maze)-1,len(maze)-1)    # doctest: +NORMALIZE_WHITESPACE\n    [[0, 1, 1, 1, 1],\n    [0, 1, 1, 1, 1],\n    [0, 1, 1, 1, 1],\n    [0, 1, 1, 1, 1],\n    [0, 0, 0, 0, 0]]\n\n    >>> maze = [[0, 0, 0],\n    ...         [0, 1, 0],\n    ...         [1, 0, 0]]\n    >>> solve_maze(maze,0,0,len(maze)-1,len(maze)-1)    # doctest: +NORMALIZE_WHITESPACE\n    [[0, 0, 0],\n    [1, 1, 0],\n    [1, 1, 0]]\n\n    >>> maze = [[1, 0, 0],\n    ...         [0, 1, 0],\n    ...         [1, 0, 0]]\n    >>> solve_maze(maze,0,1,len(maze)-1,len(maze)-1)    # doctest: +NORMALIZE_WHITESPACE\n    [[1, 0, 0],\n    [1, 1, 0],\n    [1, 1, 0]]\n\n    >>> maze = [[1, 1, 0, 0, 1, 0, 0, 1],\n    ...         [1, 0, 1, 0, 0, 1, 1, 1],\n    ...         [0, 1, 0, 1, 0, 0, 1, 0],\n    ...         [1, 1, 1, 0, 0, 1, 0, 1],\n    ...         [0, 1, 0, 0, 1, 0, 1, 1],\n    ...         [0, 0, 0, 1, 1, 1, 0, 1],\n    ...         [0, 1, 0, 1, 0, 1, 1, 1],\n    ...         [1, 1, 0, 0, 0, 0, 0, 1]]\n    >>> solve_maze(maze,0,2,len(maze)-1,2)  # doctest: +NORMALIZE_WHITESPACE\n    [[1, 1, 0, 0, 1, 1, 1, 1],\n    [1, 1, 1, 0, 0, 1, 1, 1],\n    [1, 1, 1, 1, 0, 1, 1, 1],\n    [1, 1, 1, 0, 0, 1, 1, 1],\n    [1, 1, 0, 0, 1, 1, 1, 1],\n    [1, 1, 0, 1, 1, 1, 1, 1],\n    [1, 1, 0, 1, 1, 1, 1, 1],\n    [1, 1, 0, 1, 1, 1, 1, 1]]\n    >>> maze = [[1, 0, 0],\n    ...         [0, 1, 1],\n    ...         [1, 0, 1]]\n    >>> solve_maze(maze,0,1,len(maze)-1,len(maze)-1)\n    Traceback (most recent call last):\n        ...\n    ValueError: No solution exists!\n\n    >>> maze = [[0, 0],\n    ...         [1, 1]]\n    >>> solve_maze(maze,0,0,len(maze)-1,len(maze)-1)\n    Traceback (most recent call last):\n        ...\n    ValueError: No solution exists!\n\n    >>> maze = [[0, 1],\n    ...         [1, 0]]\n    >>> solve_maze(maze,2,0,len(maze)-1,len(maze)-1)\n    Traceback (most recent call last):\n        ...\n    ValueError: Invalid source or destination coordinates\n\n    >>> maze = [[1, 0, 0],\n    ...         [0, 1, 0],\n    ...         [1, 0, 0]]\n    >>> solve_maze(maze,0,1,len(maze),len(maze)-1)\n    Traceback (most recent call last):\n        ...\n    ValueError: Invalid source or destination coordinates\n    \"\"\"\n    size = len(maze)\n    # Check if source and destination coordinates are Invalid.\n    if not (0 <= source_row <= size - 1 and 0 <= source_column <= size - 1) or (\n        not (0 <= destination_row <= size - 1 and 0 <= destination_column <= size - 1)\n    ):\n        raise ValueError(\"Invalid source or destination coordinates\")\n    # We need to create solution object to save path.\n    solutions = [[1 for _ in range(size)] for _ in range(size)]\n    solved = run_maze(\n        maze, source_row, source_column, destination_row, destination_column, solutions\n    )\n    if solved:\n        return solutions\n    else:\n        raise ValueError(\"No solution exists!\")", "blocks": [{"id": 1, "label": "def solve_maze(maze: list[list[int]], source_row: int, source_column: int, destination_row: int, destination_column: int) -> list[list[int]]:\nsize = len(maze)", "successors": [{"id": 3, "label": "if not (0 <= source_row <= size - 1 and 0 <= source_column <= size - 1) or (not (0 <= destination_row <= size - 1 and 0 <= destination_column <= size - 1)):\nraise ValueError(\"Invalid source or destination coordinates\")", "successors": []}, {"id": 5, "label": "solutions = [[1 for _ in range(size)] for _ in range(size)]\nsolved = run_maze(maze, source_row, source_column, destination_row, destination_column, solutions)", "successors": [{"id": 7, "label": "if solved:\nreturn solutions", "successors": []}, {"id": 9, "label": "else:\nraise ValueError(\"No solution exists!\")", "successors": []}]}]}]}, {"name": "run_maze", "type": "function", "start_line": 139, "end_line": 191, "functions": [], "classes": [], "simplified_code": "def run_maze(\n    maze: list[list[int]],\n    i: int,\n    j: int,\n    destination_row: int,\n    destination_column: int,\n    solutions: list[list[int]],\n) -> bool:\n    \"\"\"\n    This method is recursive starting from (i, j) and going in one of four directions:\n    up, down, left, right.\n    If a path is found to destination it returns True otherwise it returns False.\n    Parameters\n        maze: A two dimensional matrix of zeros and ones.\n        i, j : coordinates of matrix\n        solutions: A two dimensional matrix of solutions.\n    Returns:\n        Boolean if path is found True, Otherwise False.\n    \"\"\"\n    size = len(maze)\n    # Final check point.\n    if i == destination_row and j == destination_column and maze[i][j] == 0:\n        solutions[i][j] = 0\n        return True\n\n    lower_flag = (not i < 0) and (not j < 0)  # Check lower bounds\n    upper_flag = (i < size) and (j < size)  # Check upper bounds\n\n    if lower_flag and upper_flag:\n        # check for already visited and block points.\n        block_flag = (solutions[i][j]) and (not maze[i][j])\n        if block_flag:\n            # check visited\n            solutions[i][j] = 0\n\n            # check for directions\n            if (\n                run_maze(maze, i + 1, j, destination_row, destination_column, solutions)\n                or run_maze(\n                    maze, i, j + 1, destination_row, destination_column, solutions\n                )\n                or run_maze(\n                    maze, i - 1, j, destination_row, destination_column, solutions\n                )\n                or run_maze(\n                    maze, i, j - 1, destination_row, destination_column, solutions\n                )\n            ):\n                return True\n\n            solutions[i][j] = 1\n            return False\n    return False", "blocks": [{"id": 1, "label": "size = len(maze)", "successors": [{"id": 2, "label": "if i == destination_row and j == destination_column and maze[i][j] == 0:\n    solutions[i][j] = 0\n    return True", "successors": []}, {"id": 4, "label": "lower_flag = (not i < 0) and (not j < 0)\nupper_flag = (i < size) and (j < size)\nif lower_flag and upper_flag:", "successors": [{"id": 6, "label": "    block_flag = (solutions[i][j]) and (not maze[i][j])\nif block_flag:", "successors": [{"id": 8, "label": "    solutions[i][j] = 0", "successors": [{"id": 9, "label": "if (run_maze(maze, i + 1, j, destination_row, destination_column, solutions)\n    or run_maze(maze, i, j + 1, destination_row, destination_column, solutions)\n    or run_maze(maze, i - 1, j, destination_row, destination_column, solutions)\n    or run_maze(maze, i, j - 1,destination_row, destination_column, solutions)):\n    return True", "successors": []}, {"id": 11, "label": "solutions[i][j] = 1\nreturn False", "successors": []}]}]}]}]}]}], "classes": [], "simplified_code": "from __future__ import annotations\n\n\n        raise ValueError(\"No solution exists!\")\n\n\n    return False\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod(optionflags=doctest.NORMALIZE_WHITESPACE)", "blocks": [{"id": 1, "label": "raise ValueError(\"No solution exists!\")\nreturn False", "successors": []}]}
{"file_name": "128.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 84, "functions": [], "classes": [{"name": "BaseOAuthHandler", "type": "class", "start_line": 12, "end_line": 84, "functions": [{"name": "__init__", "type": "function", "start_line": 20, "end_line": 20, "functions": [], "classes": [], "simplified_code": "    def __init__(self, client_id: str, client_secret: str, redirect_uri: str): ...", "blocks": [{"id": 1, "label": "def __init__(self, client_id: str, client_secret: str, redirect_uri: str): ...", "successors": []}]}, {"name": "get_login_url", "type": "function", "start_line": 26, "end_line": 29, "functions": [], "classes": [], "simplified_code": "    def get_login_url(self, scopes: list[str], state: str) -> str:\n        # --8<-- [end:BaseOAuthHandler3]\n        \"\"\"Constructs a login URL that the user can be redirected to\"\"\"\n        ...", "blocks": [{"id": 1, "label": "def get_login_url(self, scopes: list[str], state: str) -> str:\n\"\"\"Constructs a login URL that the user can be redirected to\"\"\"", "successors": [{"id": 3, "label": "...", "successors": []}]}]}, {"name": "exchange_code_for_tokens", "type": "function", "start_line": 33, "end_line": 38, "functions": [], "classes": [], "simplified_code": "    def exchange_code_for_tokens(\n        self, code: str, scopes: list[str]\n    ) -> OAuth2Credentials:\n        # --8<-- [end:BaseOAuthHandler4]\n        \"\"\"Exchanges the acquired authorization code from login for a set of tokens\"\"\"\n        ...", "blocks": [{"id": 1, "label": "def exchange_code_for_tokens(\n    self, code: str, scopes: list[str]\n) -> OAuth2Credentials:\n\"\"\"Exchanges the acquired authorization code from login for a set of tokens\"\"\"", "successors": [{"id": 3, "label": "...", "successors": []}]}]}, {"name": "_refresh_tokens", "type": "function", "start_line": 42, "end_line": 45, "functions": [], "classes": [], "simplified_code": "    def _refresh_tokens(self, credentials: OAuth2Credentials) -> OAuth2Credentials:\n        # --8<-- [end:BaseOAuthHandler5]\n        \"\"\"Implements the token refresh mechanism\"\"\"\n        ...", "blocks": [{"id": 1, "label": "def _refresh_tokens(self, credentials: OAuth2Credentials) -> OAuth2Credentials:\n\"\"\"Implements the token refresh mechanism\"\"\"", "successors": [{"id": 3, "label": "...", "successors": []}]}]}, {"name": "revoke_tokens", "type": "function", "start_line": 49, "end_line": 53, "functions": [], "classes": [], "simplified_code": "    def revoke_tokens(self, credentials: OAuth2Credentials) -> bool:\n        # --8<-- [end:BaseOAuthHandler6]\n        \"\"\"Revokes the given token at provider,\n        returns False provider does not support it\"\"\"\n        ...", "blocks": [{"id": 1, "label": "def revoke_tokens(self, credentials: OAuth2Credentials) -> bool:", "successors": []}]}, {"name": "refresh_tokens", "type": "function", "start_line": 55, "end_line": 61, "functions": [], "classes": [], "simplified_code": "    def refresh_tokens(self, credentials: OAuth2Credentials) -> OAuth2Credentials:\n        if credentials.provider != self.PROVIDER_NAME:\n            raise ValueError(\n                f\"{self.__class__.__name__} can not refresh tokens \"\n                f\"for other provider '{credentials.provider}'\"\n            )\n        return self._refresh_tokens(credentials)", "blocks": [{"id": 1, "label": "def refresh_tokens(self, credentials: OAuth2Credentials) -> OAuth2Credentials:\nif credentials.provider != self.PROVIDER_NAME:", "successors": [{"id": 3, "label": "raise ValueError(f\"{self.__class__.__name__} can not refresh tokens \"\n                f\"for other provider '{credentials.provider}'\")", "successors": []}, {"id": 4, "label": "return self._refresh_tokens(credentials)", "successors": []}]}]}, {"name": "get_access_token", "type": "function", "start_line": 63, "end_line": 67, "functions": [], "classes": [], "simplified_code": "    def get_access_token(self, credentials: OAuth2Credentials) -> str:\n        \"\"\"Returns a valid access token, refreshing it first if needed\"\"\"\n        if self.needs_refresh(credentials):\n            credentials = self.refresh_tokens(credentials)\n        return credentials.access_token.get_secret_value()", "blocks": [{"id": 1, "label": "def get_access_token(self, credentials: OAuth2Credentials) -> str:\n    \"\"\"Returns a valid access token, refreshing it first if needed\"\"\"", "successors": [{"id": 3, "label": "    if self.needs_refresh(credentials):\n        credentials = self.refresh_tokens(credentials)", "successors": []}, {"id": 5, "label": "    return credentials.access_token.get_secret_value()", "successors": []}]}]}, {"name": "needs_refresh", "type": "function", "start_line": 69, "end_line": 74, "functions": [], "classes": [], "simplified_code": "    def needs_refresh(self, credentials: OAuth2Credentials) -> bool:\n        \"\"\"Indicates whether the given tokens need to be refreshed\"\"\"\n        return (\n            credentials.access_token_expires_at is not None\n            and credentials.access_token_expires_at < int(time.time()) + 300\n        )", "blocks": [{"id": 1, "label": "def needs_refresh(self, credentials: OAuth2Credentials) -> bool:\n\"\"\"Indicates whether the given tokens need to be refreshed\"\"\"", "successors": [{"id": 3, "label": "return ( credentials.access_token_expires_at is not None and credentials.access_token_expires_at < int(time.time()) + 300 )", "successors": []}]}]}, {"name": "handle_default_scopes", "type": "function", "start_line": 76, "end_line": 84, "functions": [], "classes": [], "simplified_code": "    def handle_default_scopes(self, scopes: list[str]) -> list[str]:\n        \"\"\"Handles the default scopes for the provider\"\"\"\n        # If scopes are empty, use the default scopes for the provider\n        if not scopes:\n            logger.debug(\n                f\"Using default scopes for provider {self.PROVIDER_NAME.value}\"\n            )\n            scopes = self.DEFAULT_SCOPES\n        return scopes", "blocks": [{"id": 1, "label": "def handle_default_scopes(self, scopes: list[str]) -> list[str]:\n\"\"\"Handles the default scopes for the provider\"\"\"", "successors": [{"id": 3, "label": "if not scopes:", "successors": [{"id": 4, "label": "logger.debug(\n    f\"Using default scopes for provider {self.PROVIDER_NAME.value}\"\n)\nscopes = self.DEFAULT_SCOPES\nreturn scopes", "successors": []}, {"id": 5, "label": "return scopes", "successors": []}]}]}]}], "classes": [], "simplified_code": "class BaseOAuthHandler(ABC):\n    # --8<-- [start:BaseOAuthHandler1]\n    PROVIDER_NAME: ClassVar[ProviderName]\n    DEFAULT_SCOPES: ClassVar[list[str]] = []\n    # --8<-- [end:BaseOAuthHandler1]\n\n    @abstractmethod\n    # --8<-- [start:BaseOAuthHandler2]\n    def __init__(self, client_id: str, client_secret: str, redirect_uri: str): ...\n\n    # --8<-- [end:BaseOAuthHandler2]\n\n    @abstractmethod\n    # --8<-- [start:BaseOAuthHandler3]\n        ...\n\n    @abstractmethod\n    # --8<-- [start:BaseOAuthHandler4]\n        ...\n\n    @abstractmethod\n    # --8<-- [start:BaseOAuthHandler5]\n        ...\n\n    @abstractmethod\n    # --8<-- [start:BaseOAuthHandler6]\n        ...\n\n        return self._refresh_tokens(credentials)\n\n        return credentials.access_token.get_secret_value()\n\n        )\n\n        return scopes", "blocks": [{"id": 1, "label": "class BaseOAuthHandler(ABC):", "successors": [{"id": 2, "label": "PROVIDER_NAME: ClassVar[ProviderName]\nDEFAULT_SCOPES: ClassVar[list[str]] = []", "successors": []}, {"id": 3, "label": "@abstractmethod\ndef __init__(self, client_id: str, client_secret: str, redirect_uri: str): ...", "successors": []}, {"id": 4, "label": "@abstractmethod\n...", "successors": []}, {"id": 5, "label": "@abstractmethod\n...", "successors": []}, {"id": 6, "label": "@abstractmethod\n...", "successors": []}, {"id": 7, "label": "@abstractmethod\n...", "successors": []}, {"id": 8, "label": "return self._refresh_tokens(credentials)", "successors": []}, {"id": 9, "label": "return credentials.access_token.get_secret_value()", "successors": []}, {"id": 10, "label": ")", "successors": []}, {"id": 11, "label": "return scopes", "successors": []}]}]}], "simplified_code": "import logging\nimport time\nfrom abc import ABC, abstractmethod\nfrom typing import ClassVar\n\nfrom backend.data.model import OAuth2Credentials\nfrom backend.integrations.providers import ProviderName\n\nlogger = logging.getLogger(__name__)\n\n\n        return scopes", "blocks": [{"id": 1, "label": "import logging\nimport time\nfrom abc import ABC, abstractmethod\nfrom typing import ClassVar\n\nfrom backend.data.model import OAuth2Credentials\nfrom backend.integrations.providers import ProviderName\n\nlogger = logging.getLogger(__name__)", "successors": []}]}
{"file_name": "129.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 195, "functions": [{"name": "test_pagination", "type": "function", "start_line": 8, "end_line": 15, "functions": [], "classes": [], "simplified_code": "def test_pagination():\n    pagination = backend.server.v2.store.model.Pagination(\n        total_items=100, total_pages=5, current_page=2, page_size=20\n    )\n    assert pagination.total_items == 100\n    assert pagination.total_pages == 5\n    assert pagination.current_page == 2\n    assert pagination.page_size == 20", "blocks": [{"id": 1, "label": "pagination = backend.server.v2.store.model.Pagination(\n    total_items=100, total_pages=5, current_page=2, page_size=20\n)\nassert pagination.total_items == 100", "successors": [{"id": 3, "label": "assert pagination.total_pages == 5\nassert pagination.current_page == 2", "successors": [{"id": 5, "label": "assert pagination.page_size == 20", "successors": []}]}]}]}, {"name": "test_store_agent", "type": "function", "start_line": 18, "end_line": 33, "functions": [], "classes": [], "simplified_code": "def test_store_agent():\n    agent = backend.server.v2.store.model.StoreAgent(\n        slug=\"test-agent\",\n        agent_name=\"Test Agent\",\n        agent_image=\"test.jpg\",\n        creator=\"creator1\",\n        creator_avatar=\"avatar.jpg\",\n        sub_heading=\"Test subheading\",\n        description=\"Test description\",\n        runs=50,\n        rating=4.5,\n    )\n    assert agent.slug == \"test-agent\"\n    assert agent.agent_name == \"Test Agent\"\n    assert agent.runs == 50\n    assert agent.rating == 4.5", "blocks": [{"id": 1, "label": "agent = backend.server.v2.store.model.StoreAgent(\n    slug=\"test-agent\",\n    agent_name=\"Test Agent\",\n    agent_image=\"test.jpg\",\n    creator=\"creator1\",\n    creator_avatar=\"avatar.jpg\",\n    sub_heading=\"Test subheading\",\n    description=\"Test description\",\n    runs=50,\n    rating=4.5,\n)\nassert agent.slug == \"test-agent\"", "successors": [{"id": 3, "label": "assert agent.agent_name == \"Test Agent\"\nassert agent.runs == 50", "successors": [{"id": 5, "label": "assert agent.rating == 4.5", "successors": []}]}]}]}, {"name": "test_store_agents_response", "type": "function", "start_line": 36, "end_line": 56, "functions": [], "classes": [], "simplified_code": "def test_store_agents_response():\n    response = backend.server.v2.store.model.StoreAgentsResponse(\n        agents=[\n            backend.server.v2.store.model.StoreAgent(\n                slug=\"test-agent\",\n                agent_name=\"Test Agent\",\n                agent_image=\"test.jpg\",\n                creator=\"creator1\",\n                creator_avatar=\"avatar.jpg\",\n                sub_heading=\"Test subheading\",\n                description=\"Test description\",\n                runs=50,\n                rating=4.5,\n            )\n        ],\n        pagination=backend.server.v2.store.model.Pagination(\n            total_items=1, total_pages=1, current_page=1, page_size=20\n        ),\n    )\n    assert len(response.agents) == 1\n    assert response.pagination.total_items == 1", "blocks": [{"id": 1, "label": "response = backend.server.v2.store.model.StoreAgentsResponse(\n    agents=[\n        backend.server.v2.store.model.StoreAgent(\n            slug=\"test-agent\",\n            agent_name=\"Test Agent\",\n            agent_image=\"test.jpg\",\n            creator=\"creator1\",\n            creator_avatar=\"avatar.jpg\",\n            sub_heading=\"Test subheading\",\n            description=\"Test description\",\n            runs=50,\n            rating=4.5,\n        )\n    ],\n    pagination=backend.server.v2.store.model.Pagination(\n        total_items=1, total_pages=1, current_page=1, page_size=20\n    ),\n)\nassert len(response.agents) == 1", "successors": [{"id": 3, "label": "assert response.pagination.total_items == 1", "successors": []}]}]}, {"name": "test_store_agent_details", "type": "function", "start_line": 59, "end_line": 79, "functions": [], "classes": [], "simplified_code": "def test_store_agent_details():\n    details = backend.server.v2.store.model.StoreAgentDetails(\n        store_listing_version_id=\"version123\",\n        slug=\"test-agent\",\n        agent_name=\"Test Agent\",\n        agent_video=\"video.mp4\",\n        agent_image=[\"image1.jpg\", \"image2.jpg\"],\n        creator=\"creator1\",\n        creator_avatar=\"avatar.jpg\",\n        sub_heading=\"Test subheading\",\n        description=\"Test description\",\n        categories=[\"cat1\", \"cat2\"],\n        runs=50,\n        rating=4.5,\n        versions=[\"1.0\", \"2.0\"],\n        last_updated=datetime.datetime.now(),\n    )\n    assert details.slug == \"test-agent\"\n    assert len(details.agent_image) == 2\n    assert len(details.categories) == 2\n    assert len(details.versions) == 2", "blocks": [{"id": 1, "label": "def test_store_agent_details():\n    details = backend.server.v2.store.model.StoreAgentDetails(\n        store_listing_version_id=\"version123\",\n        slug=\"test-agent\",\n        agent_name=\"Test Agent\",\n        agent_video=\"video.mp4\",\n        agent_image=[\"image1.jpg\", \"image2.jpg\"],\n        creator=\"creator1\",\n        creator_avatar=\"avatar.jpg\",\n        sub_heading=\"Test subheading\",\n        description=\"Test description\",\n        categories=[\"cat1\", \"cat2\"],\n        runs=50,\n        rating=4.5,\n        versions=[\"1.0\", \"2.0\"],\n        last_updated=datetime.datetime.now()\n    )\nassert details.slug == \"test-agent\"", "successors": [{"id": 3, "label": "assert len(details.agent_image) == 2\nassert len(details.categories) == 2", "successors": [{"id": 5, "label": "assert len(details.versions) == 2", "successors": []}]}]}]}, {"name": "test_creator", "type": "function", "start_line": 82, "end_line": 94, "functions": [], "classes": [], "simplified_code": "def test_creator():\n    creator = backend.server.v2.store.model.Creator(\n        agent_rating=4.8,\n        agent_runs=1000,\n        name=\"Test Creator\",\n        username=\"creator1\",\n        description=\"Test description\",\n        avatar_url=\"avatar.jpg\",\n        num_agents=5,\n        is_featured=False,\n    )\n    assert creator.name == \"Test Creator\"\n    assert creator.num_agents == 5", "blocks": [{"id": 1, "label": "creator = backend.server.v2.store.model.Creator(\n    agent_rating=4.8,\n    agent_runs=1000,\n    name=\"Test Creator\",\n    username=\"creator1\",\n    description=\"Test description\",\n    avatar_url=\"avatar.jpg\",\n    num_agents=5,\n    is_featured=False,\n)\nassert creator.name == \"Test Creator\"", "successors": [{"id": 3, "label": "assert creator.num_agents == 5", "successors": []}]}]}, {"name": "test_creators_response", "type": "function", "start_line": 97, "end_line": 116, "functions": [], "classes": [], "simplified_code": "def test_creators_response():\n    response = backend.server.v2.store.model.CreatorsResponse(\n        creators=[\n            backend.server.v2.store.model.Creator(\n                agent_rating=4.8,\n                agent_runs=1000,\n                name=\"Test Creator\",\n                username=\"creator1\",\n                description=\"Test description\",\n                avatar_url=\"avatar.jpg\",\n                num_agents=5,\n                is_featured=False,\n            )\n        ],\n        pagination=backend.server.v2.store.model.Pagination(\n            total_items=1, total_pages=1, current_page=1, page_size=20\n        ),\n    )\n    assert len(response.creators) == 1\n    assert response.pagination.total_items == 1", "blocks": [{"id": 1, "label": "response = backend.server.v2.store.model.CreatorsResponse(...)\nassert len(response.creators) == 1", "successors": [{"id": 3, "label": "assert response.pagination.total_items == 1", "successors": []}]}]}, {"name": "test_creator_details", "type": "function", "start_line": 119, "end_line": 133, "functions": [], "classes": [], "simplified_code": "def test_creator_details():\n    details = backend.server.v2.store.model.CreatorDetails(\n        name=\"Test Creator\",\n        username=\"creator1\",\n        description=\"Test description\",\n        links=[\"link1.com\", \"link2.com\"],\n        avatar_url=\"avatar.jpg\",\n        agent_rating=4.8,\n        agent_runs=1000,\n        top_categories=[\"cat1\", \"cat2\"],\n    )\n    assert details.name == \"Test Creator\"\n    assert len(details.links) == 2\n    assert details.agent_rating == 4.8\n    assert len(details.top_categories) == 2", "blocks": [{"id": 1, "label": "def test_creator_details():\ndetails = backend.server.v2.store.model.CreatorDetails(\n    name=\"Test Creator\",\n    username=\"creator1\",\n    description=\"Test description\",\n    links=[\"link1.com\", \"link2.com\"],\n    avatar_url=\"avatar.jpg\",\n    agent_rating=4.8,\n    agent_runs=1000,\n    top_categories=[\"cat1\", \"cat2\"],\n)", "successors": [{"id": 3, "label": "assert details.name == \"Test Creator\"\nassert len(details.links) == 2", "successors": [{"id": 5, "label": "assert details.agent_rating == 4.8\nassert len(details.top_categories) == 2", "successors": []}]}]}]}, {"name": "test_store_submission", "type": "function", "start_line": 136, "end_line": 152, "functions": [], "classes": [], "simplified_code": "def test_store_submission():\n    submission = backend.server.v2.store.model.StoreSubmission(\n        agent_id=\"agent123\",\n        agent_version=1,\n        sub_heading=\"Test subheading\",\n        name=\"Test Agent\",\n        slug=\"test-agent\",\n        description=\"Test description\",\n        image_urls=[\"image1.jpg\", \"image2.jpg\"],\n        date_submitted=datetime.datetime(2023, 1, 1),\n        status=prisma.enums.SubmissionStatus.PENDING,\n        runs=50,\n        rating=4.5,\n    )\n    assert submission.name == \"Test Agent\"\n    assert len(submission.image_urls) == 2\n    assert submission.status == prisma.enums.SubmissionStatus.PENDING", "blocks": [{"id": 1, "label": "submission = backend.server.v2.store.model.StoreSubmission(\n    agent_id=\"agent123\",\n    agent_version=1,\n    sub_heading=\"Test subheading\",\n    name=\"Test Agent\",\n    slug=\"test-agent\",\n    description=\"Test description\",\n    image_urls=[\"image1.jpg\", \"image2.jpg\"],\n    date_submitted=datetime.datetime(2023, 1, 1),\n    status=prisma.enums.SubmissionStatus.PENDING,\n    runs=50,\n    rating=4.5,\n)\nassert submission.name == \"Test Agent\"", "successors": [{"id": 3, "label": "assert len(submission.image_urls) == 2\nassert submission.status == prisma.enums.SubmissionStatus.PENDING", "successors": []}]}]}, {"name": "test_store_submissions_response", "type": "function", "start_line": 155, "end_line": 177, "functions": [], "classes": [], "simplified_code": "def test_store_submissions_response():\n    response = backend.server.v2.store.model.StoreSubmissionsResponse(\n        submissions=[\n            backend.server.v2.store.model.StoreSubmission(\n                agent_id=\"agent123\",\n                agent_version=1,\n                sub_heading=\"Test subheading\",\n                name=\"Test Agent\",\n                slug=\"test-agent\",\n                description=\"Test description\",\n                image_urls=[\"image1.jpg\"],\n                date_submitted=datetime.datetime(2023, 1, 1),\n                status=prisma.enums.SubmissionStatus.PENDING,\n                runs=50,\n                rating=4.5,\n            )\n        ],\n        pagination=backend.server.v2.store.model.Pagination(\n            total_items=1, total_pages=1, current_page=1, page_size=20\n        ),\n    )\n    assert len(response.submissions) == 1\n    assert response.pagination.total_items == 1", "blocks": [{"id": 1, "label": "response = backend.server.v2.store.model.StoreSubmissionsResponse(\n    submissions=[\n        backend.server.v2.store.model.StoreSubmission(\n            agent_id=\"agent123\",\n            agent_version=1,\n            sub_heading=\"Test subheading\",\n            name=\"Test Agent\",\n            slug=\"test-agent\",\n            description=\"Test description\",\n            image_urls=[\"image1.jpg\"],\n            date_submitted=datetime.datetime(2023, 1, 1),\n            status=prisma.enums.SubmissionStatus.PENDING,\n            runs=50,\n            rating=4.5,\n        )\n    ],\n    pagination=backend.server.v2.store.model.Pagination(\n        total_items=1, total_pages=1, current_page=1, page_size=20\n    ),\n)\nassert len(response.submissions) == 1", "successors": [{"id": 3, "label": "assert response.pagination.total_items == 1", "successors": []}]}]}, {"name": "test_store_submission_request", "type": "function", "start_line": 180, "end_line": 195, "functions": [], "classes": [], "simplified_code": "def test_store_submission_request():\n    request = backend.server.v2.store.model.StoreSubmissionRequest(\n        agent_id=\"agent123\",\n        agent_version=1,\n        slug=\"test-agent\",\n        name=\"Test Agent\",\n        sub_heading=\"Test subheading\",\n        video_url=\"video.mp4\",\n        image_urls=[\"image1.jpg\", \"image2.jpg\"],\n        description=\"Test description\",\n        categories=[\"cat1\", \"cat2\"],\n    )\n    assert request.agent_id == \"agent123\"\n    assert request.agent_version == 1\n    assert len(request.image_urls) == 2\n    assert len(request.categories) == 2", "blocks": [{"id": 1, "label": "request = backend.server.v2.store.model.StoreSubmissionRequest(\n    agent_id=\"agent123\",\n    agent_version=1,\n    slug=\"test-agent\",\n    name=\"Test Agent\",\n    sub_heading=\"Test subheading\",\n    video_url=\"video.mp4\",\n    image_urls=[\"image1.jpg\", \"image2.jpg\"],\n    description=\"Test description\",\n    categories=[\"cat1\", \"cat2\"],\n)\nassert request.agent_id == \"agent123\"", "successors": [{"id": 3, "label": "assert request.agent_version == 1\nassert len(request.image_urls) == 2", "successors": [{"id": 5, "label": "assert len(request.categories) == 2", "successors": []}]}]}]}], "classes": [], "simplified_code": "import datetime\n\nimport prisma.enums\n\nimport backend.server.v2.store.model\n\n\n    assert pagination.page_size == 20\n\n\n    assert agent.rating == 4.5\n\n\n    assert response.pagination.total_items == 1\n\n\n    assert len(details.versions) == 2\n\n\n    assert creator.num_agents == 5\n\n\n    assert response.pagination.total_items == 1\n\n\n    assert len(details.top_categories) == 2\n\n\n    assert submission.status == prisma.enums.SubmissionStatus.PENDING\n\n\n    assert response.pagination.total_items == 1\n\n\n    assert len(request.categories) == 2", "blocks": [{"id": 1, "label": "import datetime\nimport prisma.enums", "successors": [{"id": 3, "label": "import backend.server.v2.store.model\nassert pagination.page_size == 20", "successors": [{"id": 5, "label": "assert agent.rating == 4.5\nassert response.pagination.total_items == 1", "successors": [{"id": 7, "label": "assert len(details.versions) == 2\nassert creator.num_agents == 5", "successors": [{"id": 9, "label": "assert response.pagination.total_items == 1\nassert len(details.top_categories) == 2", "successors": [{"id": 11, "label": "assert submission.status == prisma.enums.SubmissionStatus.PENDING\nassert response.pagination.total_items == 1", "successors": [{"id": 13, "label": "assert len(request.categories) == 2", "successors": []}]}]}]}]}]}]}]}
{"file_name": "131.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 196, "functions": [{"name": "create_webhook", "type": "function", "start_line": 66, "end_line": 81, "functions": [], "classes": [], "simplified_code": "async def create_webhook(webhook: Webhook) -> Webhook:\n    created_webhook = await IntegrationWebhook.prisma().create(\n        data={\n            \"id\": webhook.id,\n            \"userId\": webhook.user_id,\n            \"provider\": webhook.provider.value,\n            \"credentialsId\": webhook.credentials_id,\n            \"webhookType\": webhook.webhook_type,\n            \"resource\": webhook.resource,\n            \"events\": webhook.events,\n            \"config\": Json(webhook.config),\n            \"secret\": webhook.secret,\n            \"providerWebhookId\": webhook.provider_webhook_id,\n        }\n    )\n    return Webhook.from_db(created_webhook)", "blocks": [{"id": 1, "label": "created_webhook = await IntegrationWebhook.prisma().create(\n        data={\n            \"id\": webhook.id,\n            \"userId\": webhook.user_id,\n            \"provider\": webhook.provider.value,\n            \"credentialsId\": webhook.credentials_id,\n            \"webhookType\": webhook.webhook_type,\n            \"resource\": webhook.resource,\n            \"events\": webhook.events,\n            \"config\": Json(webhook.config),\n            \"secret\": webhook.secret,\n            \"providerWebhookId\": webhook.provider_webhook_id,\n        }\n    )\nreturn Webhook.from_db(created_webhook)", "successors": []}]}, {"name": "get_webhook", "type": "function", "start_line": 84, "end_line": 90, "functions": [], "classes": [], "simplified_code": "async def get_webhook(webhook_id: str) -> Webhook:\n    \"\"\"\u26a0\ufe0f No `user_id` check: DO NOT USE without check in user-facing endpoints.\"\"\"\n    webhook = await IntegrationWebhook.prisma().find_unique_or_raise(\n        where={\"id\": webhook_id},\n        include=INTEGRATION_WEBHOOK_INCLUDE,\n    )\n    return Webhook.from_db(webhook)", "blocks": [{"id": 1, "label": "async def get_webhook(webhook_id: str) -> Webhook:\n\"\"\"\u26a0\ufe0f No `user_id` check: DO NOT USE without check in user-facing endpoints.\"\"\"", "successors": [{"id": 3, "label": "webhook = await IntegrationWebhook.prisma().find_unique_or_raise(\n    where={\"id\": webhook_id},\n    include=INTEGRATION_WEBHOOK_INCLUDE,\n)\nreturn Webhook.from_db(webhook)", "successors": []}]}]}, {"name": "get_all_webhooks_by_creds", "type": "function", "start_line": 93, "end_line": 101, "functions": [], "classes": [], "simplified_code": "async def get_all_webhooks_by_creds(credentials_id: str) -> list[Webhook]:\n    \"\"\"\u26a0\ufe0f No `user_id` check: DO NOT USE without check in user-facing endpoints.\"\"\"\n    if not credentials_id:\n        raise ValueError(\"credentials_id must not be empty\")\n    webhooks = await IntegrationWebhook.prisma().find_many(\n        where={\"credentialsId\": credentials_id},\n        include=INTEGRATION_WEBHOOK_INCLUDE,\n    )\n    return [Webhook.from_db(webhook) for webhook in webhooks]", "blocks": [{"id": 1, "label": "async def get_all_webhooks_by_creds(credentials_id: str) -> list[Webhook]:\n    \"\"\"\u26a0\ufe0f No `user_id` check: DO NOT USE without check in user-facing endpoints.\"\"\"\n    if not credentials_id:", "successors": [{"id": 2, "label": "        raise ValueError(\"credentials_id must not be empty\")", "successors": []}, {"id": 3, "label": "    webhooks = await IntegrationWebhook.prisma().find_many(\n        where={\"credentialsId\": credentials_id},\n        include=INTEGRATION_WEBHOOK_INCLUDE,\n    )\n    return [Webhook.from_db(webhook) for webhook in webhooks]", "successors": []}]}]}, {"name": "find_webhook_by_credentials_and_props", "type": "function", "start_line": 104, "end_line": 117, "functions": [], "classes": [], "simplified_code": "async def find_webhook_by_credentials_and_props(\n    credentials_id: str, webhook_type: str, resource: str, events: list[str]\n) -> Webhook | None:\n    \"\"\"\u26a0\ufe0f No `user_id` check: DO NOT USE without check in user-facing endpoints.\"\"\"\n    webhook = await IntegrationWebhook.prisma().find_first(\n        where={\n            \"credentialsId\": credentials_id,\n            \"webhookType\": webhook_type,\n            \"resource\": resource,\n            \"events\": {\"has_every\": events},\n        },\n        include=INTEGRATION_WEBHOOK_INCLUDE,\n    )\n    return Webhook.from_db(webhook) if webhook else None", "blocks": [{"id": 1, "label": "async def find_webhook_by_credentials_and_props(\n    credentials_id: str, webhook_type: str, resource: str, events: list[str]\n) -> Webhook | None:\nwebhook = await IntegrationWebhook.prisma().find_first(\n    where={\n        \"credentialsId\": credentials_id,\n        \"webhookType\": webhook_type,\n        \"resource\": resource,\n        \"events\": {\"has_every\": events},\n    },\n    include=INTEGRATION_WEBHOOK_INCLUDE,\n)", "successors": [{"id": 3, "label": "return Webhook.from_db(webhook) if webhook else None", "successors": []}]}]}, {"name": "find_webhook_by_graph_and_props", "type": "function", "start_line": 120, "end_line": 133, "functions": [], "classes": [], "simplified_code": "async def find_webhook_by_graph_and_props(\n    graph_id: str, provider: str, webhook_type: str, events: list[str]\n) -> Webhook | None:\n    \"\"\"\u26a0\ufe0f No `user_id` check: DO NOT USE without check in user-facing endpoints.\"\"\"\n    webhook = await IntegrationWebhook.prisma().find_first(\n        where={\n            \"provider\": provider,\n            \"webhookType\": webhook_type,\n            \"events\": {\"has_every\": events},\n            \"AgentNodes\": {\"some\": {\"agentGraphId\": graph_id}},\n        },\n        include=INTEGRATION_WEBHOOK_INCLUDE,\n    )\n    return Webhook.from_db(webhook) if webhook else None", "blocks": [{"id": 1, "label": "async def find_webhook_by_graph_and_props(\n    graph_id: str, provider: str, webhook_type: str, events: list[str]\n) -> Webhook | None:\n\"\"\"\u26a0\ufe0f No `user_id` check: DO NOT USE without check in user-facing endpoints.\"\"\"", "successors": [{"id": 3, "label": "webhook = await IntegrationWebhook.prisma().find_first(\n    where={\n        \"provider\": provider,\n        \"webhookType\": webhook_type,\n        \"events\": {\"has_every\": events},\n        \"AgentNodes\": {\"some\": {\"agentGraphId\": graph_id}},\n    },\n    include=INTEGRATION_WEBHOOK_INCLUDE,\n)\nreturn Webhook.from_db(webhook) if webhook else None", "successors": []}]}]}, {"name": "update_webhook_config", "type": "function", "start_line": 136, "end_line": 145, "functions": [], "classes": [], "simplified_code": "async def update_webhook_config(webhook_id: str, updated_config: dict) -> Webhook:\n    \"\"\"\u26a0\ufe0f No `user_id` check: DO NOT USE without check in user-facing endpoints.\"\"\"\n    _updated_webhook = await IntegrationWebhook.prisma().update(\n        where={\"id\": webhook_id},\n        data={\"config\": Json(updated_config)},\n        include=INTEGRATION_WEBHOOK_INCLUDE,\n    )\n    if _updated_webhook is None:\n        raise ValueError(f\"Webhook #{webhook_id} not found\")\n    return Webhook.from_db(_updated_webhook)", "blocks": [{"id": 1, "label": "async def update_webhook_config(webhook_id: str, updated_config: dict) -> Webhook:\n    \"\"\"\u26a0\ufe0f No `user_id` check: DO NOT USE without check in user-facing endpoints.\"\"\"\n_updated_webhook = await IntegrationWebhook.prisma().update(\n        where={\"id\": webhook_id},\n        data={\"config\": Json(updated_config)},\n        include=INTEGRATION_WEBHOOK_INCLUDE,\n    )", "successors": [{"id": 3, "label": "if _updated_webhook is None:\n    raise ValueError(f\"Webhook #{webhook_id} not found\")", "successors": []}, {"id": 5, "label": "return Webhook.from_db(_updated_webhook)", "successors": []}]}]}, {"name": "delete_webhook", "type": "function", "start_line": 148, "end_line": 152, "functions": [], "classes": [], "simplified_code": "async def delete_webhook(webhook_id: str) -> None:\n    \"\"\"\u26a0\ufe0f No `user_id` check: DO NOT USE without check in user-facing endpoints.\"\"\"\n    deleted = await IntegrationWebhook.prisma().delete(where={\"id\": webhook_id})\n    if not deleted:\n        raise ValueError(f\"Webhook #{webhook_id} not found\")", "blocks": [{"id": 1, "label": "async def delete_webhook(webhook_id: str) -> None:\n    \"\"\"\u26a0\ufe0f No `user_id` check: DO NOT USE without check in user-facing endpoints.\"\"\"\n    deleted = await IntegrationWebhook.prisma().delete(where={\"id\": webhook_id})\nif not deleted:", "successors": [{"id": 3, "label": "    raise ValueError(f\"Webhook #{webhook_id} not found\")", "successors": []}]}]}, {"name": "publish_webhook_event", "type": "function", "start_line": 176, "end_line": 179, "functions": [], "classes": [], "simplified_code": "async def publish_webhook_event(event: WebhookEvent):\n    await _webhook_event_bus.publish_event(\n        event, f\"{event.webhook_id}/{event.event_type}\"\n    )", "blocks": [{"id": 1, "label": "async def publish_webhook_event(event: WebhookEvent):\nawait _webhook_event_bus.publish_event(\n    event, f\"{event.webhook_id}/{event.event_type}\"\n)", "successors": []}]}, {"name": "listen_for_webhook_events", "type": "function", "start_line": 182, "end_line": 188, "functions": [], "classes": [], "simplified_code": "async def listen_for_webhook_events(\n    webhook_id: str, event_type: Optional[str] = None\n) -> AsyncGenerator[WebhookEvent, None]:\n    async for event in _webhook_event_bus.listen_events(\n        f\"{webhook_id}/{event_type or '*'}\"\n    ):\n        yield event", "blocks": [{"id": 1, "label": "async def listen_for_webhook_events(\n    webhook_id: str, event_type: Optional[str] = None\n) -> AsyncGenerator[WebhookEvent, None]:\nasync for event in _webhook_event_bus.listen_events(\n    f\"{webhook_id}/{event_type or '*'}\"\n):", "successors": [{"id": 3, "label": "yield event", "successors": []}]}]}, {"name": "wait_for_webhook_event", "type": "function", "start_line": 191, "end_line": 196, "functions": [], "classes": [], "simplified_code": "async def wait_for_webhook_event(\n    webhook_id: str, event_type: Optional[str] = None, timeout: Optional[float] = None\n) -> WebhookEvent | None:\n    return await _webhook_event_bus.wait_for_event(\n        f\"{webhook_id}/{event_type or '*'}\", timeout\n    )", "blocks": [{"id": 1, "label": "async def wait_for_webhook_event(\n    webhook_id: str, event_type: Optional[str] = None, timeout: Optional[float] = None\n) -> WebhookEvent | None:\n    return await _webhook_event_bus.wait_for_event(\n        f\"{webhook_id}/{event_type or '*'}\", timeout\n    )", "successors": []}]}], "classes": [{"name": "Webhook", "type": "class", "start_line": 21, "end_line": 60, "functions": [{"name": "url", "type": "function", "start_line": 37, "end_line": 38, "functions": [], "classes": [], "simplified_code": "    def url(self) -> str:\n        return webhook_ingress_url(self.provider.value, self.id)", "blocks": [{"id": 1, "label": "def url(self) -> str:\n    return webhook_ingress_url(self.provider.value, self.id)", "successors": []}]}, {"name": "from_db", "type": "function", "start_line": 41, "end_line": 60, "functions": [], "classes": [], "simplified_code": "    def from_db(webhook: IntegrationWebhook):\n        from .graph import NodeModel\n\n        return Webhook(\n            id=webhook.id,\n            user_id=webhook.userId,\n            provider=ProviderName(webhook.provider),\n            credentials_id=webhook.credentialsId,\n            webhook_type=webhook.webhookType,\n            resource=webhook.resource,\n            events=webhook.events,\n            config=dict(webhook.config),\n            secret=webhook.secret,\n            provider_webhook_id=webhook.providerWebhookId,\n            attached_nodes=(\n                [NodeModel.from_db(node) for node in webhook.AgentNodes]\n                if webhook.AgentNodes is not None\n                else None\n            ),\n        )", "blocks": [{"id": 1, "label": "def from_db(webhook: IntegrationWebhook):\n    from .graph import NodeModel", "successors": [{"id": 3, "label": "    return Webhook(\n        id=webhook.id,", "successors": [{"id": 5, "label": "        user_id=webhook.userId,\n        provider=ProviderName(webhook.provider),", "successors": [{"id": 7, "label": "        credentials_id=webhook.credentialsId,\n        webhook_type=webhook.webhookType,", "successors": [{"id": 9, "label": "        resource=webhook.resource,\n        events=webhook.events,", "successors": [{"id": 11, "label": "        config=dict(webhook.config),\n        secret=webhook.secret,", "successors": [{"id": 13, "label": "        provider_webhook_id=webhook.providerWebhookId,\n        attached_nodes=(", "successors": [{"id": 15, "label": "            [NodeModel.from_db(node) for node in webhook.AgentNodes]\n            if webhook.AgentNodes is not None", "successors": [{"id": 17, "label": "            else None", "successors": []}]}]}]}]}]}]}]}]}]}], "simplified_code": "class Webhook(BaseDbModel):\n    user_id: str\n    provider: ProviderName\n    credentials_id: str\n    webhook_type: str\n    resource: str\n    events: list[str]\n    config: dict = Field(default_factory=dict)\n    secret: str\n\n    provider_webhook_id: str\n\n    attached_nodes: Optional[list[\"NodeModel\"]] = None\n\n    @computed_field\n    @property\n        return webhook_ingress_url(self.provider.value, self.id)\n\n    @staticmethod\n        )", "blocks": [{"id": 1, "label": "class Webhook(BaseDbModel):\n    user_id: str\n    provider: ProviderName\n    credentials_id: str\n    webhook_type: str\n    resource: str\n    events: list[str]\n    config: dict = Field(default_factory=dict)\n    secret: str\n\n    provider_webhook_id: str\n\n    attached_nodes: Optional[list[\"NodeModel\"]] = None\n@computed_field\n    @property\n    def url(self) -> str:\n        return webhook_ingress_url(self.provider.value, self.id)", "successors": [{"id": 3, "label": "@staticmethod\n    def some_static_method():\n        pass", "successors": []}]}]}, {"name": "WebhookEvent", "type": "class", "start_line": 158, "end_line": 162, "functions": [], "classes": [], "simplified_code": "class WebhookEvent(BaseDbModel):\n    provider: str\n    webhook_id: str\n    event_type: str\n    payload: dict", "blocks": [{"id": 1, "label": "class WebhookEvent(BaseDbModel):\nprovider: str\nwebhook_id: str\nevent_type: str\npayload: dict", "successors": []}]}, {"name": "WebhookEventBus", "type": "class", "start_line": 165, "end_line": 170, "functions": [{"name": "event_bus_name", "type": "function", "start_line": 169, "end_line": 170, "functions": [], "classes": [], "simplified_code": "    def event_bus_name(self) -> str:\n        return \"webhooks\"", "blocks": [{"id": 1, "label": "def event_bus_name(self) -> str:\nreturn \"webhooks\"", "successors": []}]}], "simplified_code": "class WebhookEventBus(AsyncRedisEventBus[WebhookEvent]):\n    Model = WebhookEvent\n\n    @property\n        return \"webhooks\"", "blocks": [{"id": 1, "label": "class WebhookEventBus(AsyncRedisEventBus[WebhookEvent]):\n    Model = WebhookEvent", "successors": [{"id": 3, "label": "    @property\n    def some_method(self):", "successors": [{"id": 5, "label": "        return \"webhooks\"", "successors": []}]}]}]}], "simplified_code": "import logging\nfrom typing import TYPE_CHECKING, AsyncGenerator, Optional\n\nfrom prisma import Json\nfrom prisma.models import IntegrationWebhook\nfrom pydantic import Field, computed_field\n\nfrom backend.data.includes import INTEGRATION_WEBHOOK_INCLUDE\nfrom backend.data.queue import AsyncRedisEventBus\nfrom backend.integrations.providers import ProviderName\nfrom backend.integrations.webhooks.utils import webhook_ingress_url\n\nfrom .db import BaseDbModel\n\nif TYPE_CHECKING:\n    from .graph import NodeModel\n\nlogger = logging.getLogger(__name__)\n\n\n        )\n\n\n# --------------------- CRUD functions --------------------- #\n\n\n    return Webhook.from_db(created_webhook)\n\n\n    return Webhook.from_db(webhook)\n\n\n    return [Webhook.from_db(webhook) for webhook in webhooks]\n\n\n    return Webhook.from_db(webhook) if webhook else None\n\n\n    return Webhook.from_db(webhook) if webhook else None\n\n\n    return Webhook.from_db(_updated_webhook)\n\n\n        raise ValueError(f\"Webhook #{webhook_id} not found\")\n\n\n# --------------------- WEBHOOK EVENTS --------------------- #\n\n\n    payload: dict\n\n\n        return \"webhooks\"\n\n\n_webhook_event_bus = WebhookEventBus()\n\n\n    )\n\n\n        yield event\n\n\n    )", "blocks": [{"id": 1, "label": "import logging\nfrom typing import TYPE_CHECKING, AsyncGenerator, Optional\n\nfrom prisma import Json\nfrom prisma.models import IntegrationWebhook\nfrom pydantic import Field, computed_field\n\nfrom backend.data.includes import INTEGRATION_WEBHOOK_INCLUDE\nfrom backend.data.queue import AsyncRedisEventBus\nfrom backend.integrations.providers import ProviderName\nfrom backend.integrations.webhooks.utils import webhook_ingress_url\n\nfrom .db import BaseDbModel\n\nif TYPE_CHECKING:\n    from .graph import NodeModel\n\nlogger = logging.getLogger(__name__)", "successors": []}]}
{"file_name": "132.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 46, "functions": [{"name": "get_1s_count", "type": "function", "start_line": 1, "end_line": 40, "functions": [], "classes": [], "simplified_code": "def get_1s_count(number: int) -> int:\n    \"\"\"\n    Count the number of set bits in a 32 bit integer using Brian Kernighan's way.\n    Ref - https://graphics.stanford.edu/~seander/bithacks.html#CountBitsSetKernighan\n    >>> get_1s_count(25)\n    3\n    >>> get_1s_count(37)\n    3\n    >>> get_1s_count(21)\n    3\n    >>> get_1s_count(58)\n    4\n    >>> get_1s_count(0)\n    0\n    >>> get_1s_count(256)\n    1\n    >>> get_1s_count(-1)\n    Traceback (most recent call last):\n        ...\n    ValueError: Input must be a non-negative integer\n    >>> get_1s_count(0.8)\n    Traceback (most recent call last):\n        ...\n    ValueError: Input must be a non-negative integer\n    >>> get_1s_count(\"25\")\n    Traceback (most recent call last):\n        ...\n    ValueError: Input must be a non-negative integer\n    \"\"\"\n    if not isinstance(number, int) or number < 0:\n        raise ValueError(\"Input must be a non-negative integer\")\n\n    count = 0\n    while number:\n        # This way we arrive at next set bit (next 1) instead of looping\n        # through each bit and checking for 1s hence the\n        # loop won't run 32 times it will only run the number of `1` times\n        number &= number - 1\n        count += 1\n    return count", "blocks": [{"id": 1, "label": "def get_1s_count(number: int) -> int:\nif not isinstance(number, int) or number < 0:", "successors": [{"id": 3, "label": "raise ValueError(\"Input must be a non-negative integer\")", "successors": []}, {"id": 4, "label": "count = 0", "successors": [{"id": 5, "label": "while number:", "successors": [{"id": 6, "label": "number &= number - 1\ncount += 1", "successors": [{"id": 5, "label": "while number:", "successors": []}]}, {"id": 7, "label": "return count", "successors": []}]}]}]}]}], "classes": [], "simplified_code": "    return count\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()", "blocks": [{"id": 1, "label": "return count", "successors": []}]}
{"file_name": "133.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 436, "functions": [{"name": "get_image", "type": "function", "start_line": 42, "end_line": 46, "functions": [], "classes": [], "simplified_code": "def get_image():\n    url = faker.image_url()\n    while \"placekitten.com\" in url:\n        url = faker.image_url()\n    return url", "blocks": [{"id": 1, "label": "def get_image():\nurl = faker.image_url()", "successors": [{"id": 3, "label": "while \"placekitten.com\" in url:", "successors": [{"id": 4, "label": "    url = faker.image_url()", "successors": [{"id": 3, "label": "while \"placekitten.com\" in url:", "successors": []}]}, {"id": 5, "label": "return url", "successors": []}]}]}]}, {"name": "main", "type": "function", "start_line": 49, "end_line": 432, "functions": [], "classes": [], "simplified_code": "async def main():\n    db = Prisma()\n    await db.connect()\n\n    # Insert Users\n    print(f\"Inserting {NUM_USERS} users\")\n    users = []\n    for _ in range(NUM_USERS):\n        user = await db.user.create(\n            data={\n                \"id\": str(faker.uuid4()),\n                \"email\": faker.unique.email(),\n                \"name\": faker.name(),\n                \"metadata\": prisma.Json({}),\n                \"integrations\": \"\",\n            }\n        )\n        users.append(user)\n\n    # Insert AgentBlocks\n    agent_blocks = []\n    print(f\"Inserting {NUM_AGENT_BLOCKS} agent blocks\")\n    for _ in range(NUM_AGENT_BLOCKS):\n        block = await db.agentblock.create(\n            data={\n                \"name\": f\"{faker.word()}_{str(faker.uuid4())[:8]}\",\n                \"inputSchema\": \"{}\",\n                \"outputSchema\": \"{}\",\n            }\n        )\n        agent_blocks.append(block)\n\n    # Insert AgentGraphs\n    agent_graphs = []\n    print(f\"Inserting {NUM_USERS * MAX_GRAPHS_PER_USER} agent graphs\")\n    for user in users:\n        for _ in range(\n            random.randint(MIN_GRAPHS_PER_USER, MAX_GRAPHS_PER_USER)\n        ):  # Adjust the range to create more graphs per user if desired\n            graph = await db.agentgraph.create(\n                data={\n                    \"name\": faker.sentence(nb_words=3),\n                    \"description\": faker.text(max_nb_chars=200),\n                    \"userId\": user.id,\n                    \"isActive\": True,\n                    \"isTemplate\": False,\n                }\n            )\n            agent_graphs.append(graph)\n\n    # Insert AgentNodes\n    agent_nodes = []\n    print(\n        f\"Inserting {NUM_USERS * MAX_GRAPHS_PER_USER * MAX_NODES_PER_GRAPH} agent nodes\"\n    )\n    for graph in agent_graphs:\n        num_nodes = random.randint(MIN_NODES_PER_GRAPH, MAX_NODES_PER_GRAPH)\n        for _ in range(num_nodes):  # Create 5 AgentNodes per graph\n            block = random.choice(agent_blocks)\n            node = await db.agentnode.create(\n                data={\n                    \"agentBlockId\": block.id,\n                    \"agentGraphId\": graph.id,\n                    \"agentGraphVersion\": graph.version,\n                    \"constantInput\": \"{}\",\n                    \"metadata\": \"{}\",\n                }\n            )\n            agent_nodes.append(node)\n\n    # Insert AgentPresets\n    agent_presets = []\n    print(f\"Inserting {NUM_USERS * MAX_PRESETS_PER_USER} agent presets\")\n    for user in users:\n        num_presets = random.randint(MIN_PRESETS_PER_USER, MAX_PRESETS_PER_USER)\n        for _ in range(num_presets):  # Create 1 AgentPreset per user\n            graph = random.choice(agent_graphs)\n            preset = await db.agentpreset.create(\n                data={\n                    \"name\": faker.sentence(nb_words=3),\n                    \"description\": faker.text(max_nb_chars=200),\n                    \"userId\": user.id,\n                    \"agentId\": graph.id,\n                    \"agentVersion\": graph.version,\n                    \"isActive\": True,\n                }\n            )\n            agent_presets.append(preset)\n\n    # Insert UserAgents\n    user_agents = []\n    print(f\"Inserting {NUM_USERS * MAX_AGENTS_PER_USER} user agents\")\n    for user in users:\n        num_agents = random.randint(MIN_AGENTS_PER_USER, MAX_AGENTS_PER_USER)\n        for _ in range(num_agents):  # Create 1 UserAgent per user\n            graph = random.choice(agent_graphs)\n            preset = random.choice(agent_presets)\n            user_agent = await db.useragent.create(\n                data={\n                    \"userId\": user.id,\n                    \"agentId\": graph.id,\n                    \"agentVersion\": graph.version,\n                    \"agentPresetId\": preset.id,\n                    \"isFavorite\": random.choice([True, False]),\n                    \"isCreatedByUser\": random.choice([True, False]),\n                    \"isArchived\": random.choice([True, False]),\n                    \"isDeleted\": random.choice([True, False]),\n                }\n            )\n            user_agents.append(user_agent)\n\n    # Insert AgentGraphExecutions\n    # Insert AgentGraphExecutions\n    agent_graph_executions = []\n    print(\n        f\"Inserting {NUM_USERS * MAX_GRAPHS_PER_USER * MAX_EXECUTIONS_PER_GRAPH} agent graph executions\"\n    )\n    graph_execution_data = []\n    for graph in agent_graphs:\n        user = random.choice(users)\n        num_executions = random.randint(\n            MIN_EXECUTIONS_PER_GRAPH, MAX_EXECUTIONS_PER_GRAPH\n        )\n        for _ in range(num_executions):\n            matching_presets = [p for p in agent_presets if p.agentId == graph.id]\n            preset = (\n                random.choice(matching_presets)\n                if matching_presets and random.random() < 0.5\n                else None\n            )\n\n            graph_execution_data.append(\n                {\n                    \"agentGraphId\": graph.id,\n                    \"agentGraphVersion\": graph.version,\n                    \"userId\": user.id,\n                    \"executionStatus\": prisma.enums.AgentExecutionStatus.COMPLETED,\n                    \"startedAt\": faker.date_time_this_year(),\n                    \"agentPresetId\": preset.id if preset else None,\n                }\n            )\n\n    agent_graph_executions = await db.agentgraphexecution.create_many(\n        data=graph_execution_data\n    )\n    # Need to fetch the created records since create_many doesn't return them\n    agent_graph_executions = await db.agentgraphexecution.find_many()\n\n    # Insert AgentNodeExecutions\n    print(\n        f\"Inserting {NUM_USERS * MAX_GRAPHS_PER_USER * MAX_EXECUTIONS_PER_GRAPH} agent node executions\"\n    )\n    node_execution_data = []\n    for execution in agent_graph_executions:\n        nodes = [\n            node for node in agent_nodes if node.agentGraphId == execution.agentGraphId\n        ]\n        for node in nodes:\n            node_execution_data.append(\n                {\n                    \"agentGraphExecutionId\": execution.id,\n                    \"agentNodeId\": node.id,\n                    \"executionStatus\": prisma.enums.AgentExecutionStatus.COMPLETED,\n                    \"addedTime\": datetime.now(),\n                }\n            )\n\n    agent_node_executions = await db.agentnodeexecution.create_many(\n        data=node_execution_data\n    )\n    # Need to fetch the created records since create_many doesn't return them\n    agent_node_executions = await db.agentnodeexecution.find_many()\n\n    # Insert AgentNodeExecutionInputOutput\n    print(\n        f\"Inserting {NUM_USERS * MAX_GRAPHS_PER_USER * MAX_EXECUTIONS_PER_GRAPH} agent node execution input/outputs\"\n    )\n    input_output_data = []\n    for node_execution in agent_node_executions:\n        # Input data\n        input_output_data.append(\n            {\n                \"name\": \"input1\",\n                \"data\": \"{}\",\n                \"time\": datetime.now(),\n                \"referencedByInputExecId\": node_execution.id,\n            }\n        )\n        # Output data\n        input_output_data.append(\n            {\n                \"name\": \"output1\",\n                \"data\": \"{}\",\n                \"time\": datetime.now(),\n                \"referencedByOutputExecId\": node_execution.id,\n            }\n        )\n\n    await db.agentnodeexecutioninputoutput.create_many(data=input_output_data)\n\n    # Insert AgentNodeLinks\n    print(f\"Inserting {NUM_USERS * MAX_GRAPHS_PER_USER} agent node links\")\n    for graph in agent_graphs:\n        nodes = [node for node in agent_nodes if node.agentGraphId == graph.id]\n        if len(nodes) >= 2:\n            source_node = nodes[0]\n            sink_node = nodes[1]\n            await db.agentnodelink.create(\n                data={\n                    \"agentNodeSourceId\": source_node.id,\n                    \"sourceName\": \"output1\",\n                    \"agentNodeSinkId\": sink_node.id,\n                    \"sinkName\": \"input1\",\n                    \"isStatic\": False,\n                }\n            )\n\n    # Insert AnalyticsDetails\n    print(f\"Inserting {NUM_USERS} analytics details\")\n    for user in users:\n        for _ in range(1):\n            await db.analyticsdetails.create(\n                data={\n                    \"userId\": user.id,\n                    \"type\": faker.word(),\n                    \"data\": prisma.Json({}),\n                    \"dataIndex\": faker.word(),\n                }\n            )\n\n    # Insert AnalyticsMetrics\n    print(f\"Inserting {NUM_USERS} analytics metrics\")\n    for user in users:\n        for _ in range(1):\n            await db.analyticsmetrics.create(\n                data={\n                    \"userId\": user.id,\n                    \"analyticMetric\": faker.word(),\n                    \"value\": random.uniform(0, 100),\n                    \"dataString\": faker.word(),\n                }\n            )\n\n    # Insert CreditTransaction (formerly UserBlockCredit)\n    print(f\"Inserting {NUM_USERS} credit transactions\")\n    for user in users:\n        for _ in range(1):\n            block = random.choice(agent_blocks)\n            await db.credittransaction.create(\n                data={\n                    \"transactionKey\": str(faker.uuid4()),\n                    \"userId\": user.id,\n                    \"blockId\": block.id,\n                    \"amount\": random.randint(1, 100),\n                    \"type\": (\n                        prisma.enums.CreditTransactionType.TOP_UP\n                        if random.random() < 0.5\n                        else prisma.enums.CreditTransactionType.USAGE\n                    ),\n                    \"metadata\": prisma.Json({}),\n                }\n            )\n\n    # Insert Profiles\n    profiles = []\n    print(f\"Inserting {NUM_USERS} profiles\")\n    for user in users:\n        profile = await db.profile.create(\n            data={\n                \"userId\": user.id,\n                \"name\": user.name or faker.name(),\n                \"username\": faker.unique.user_name(),\n                \"description\": faker.text(),\n                \"links\": [faker.url() for _ in range(3)],\n                \"avatarUrl\": get_image(),\n            }\n        )\n        profiles.append(profile)\n\n    # Insert StoreListings\n    store_listings = []\n    print(f\"Inserting {NUM_USERS} store listings\")\n    for graph in agent_graphs:\n        user = random.choice(users)\n        listing = await db.storelisting.create(\n            data={\n                \"agentId\": graph.id,\n                \"agentVersion\": graph.version,\n                \"owningUserId\": user.id,\n                \"isApproved\": random.choice([True, False]),\n            }\n        )\n        store_listings.append(listing)\n\n    # Insert StoreListingVersions\n    store_listing_versions = []\n    print(f\"Inserting {NUM_USERS} store listing versions\")\n    for listing in store_listings:\n        graph = [g for g in agent_graphs if g.id == listing.agentId][0]\n        version = await db.storelistingversion.create(\n            data={\n                \"agentId\": graph.id,\n                \"agentVersion\": graph.version,\n                \"slug\": faker.slug(),\n                \"name\": graph.name or faker.sentence(nb_words=3),\n                \"subHeading\": faker.sentence(),\n                \"videoUrl\": faker.url(),\n                \"imageUrls\": [get_image() for _ in range(3)],\n                \"description\": faker.text(),\n                \"categories\": [faker.word() for _ in range(3)],\n                \"isFeatured\": random.choice([True, False]),\n                \"isAvailable\": True,\n                \"isApproved\": random.choice([True, False]),\n                \"storeListingId\": listing.id,\n            }\n        )\n        store_listing_versions.append(version)\n\n    # Insert StoreListingReviews\n    print(f\"Inserting {NUM_USERS * MAX_REVIEWS_PER_VERSION} store listing reviews\")\n    for version in store_listing_versions:\n        # Create a copy of users list and shuffle it to avoid duplicates\n        available_reviewers = users.copy()\n        random.shuffle(available_reviewers)\n\n        # Limit number of reviews to available unique reviewers\n        num_reviews = min(\n            random.randint(MIN_REVIEWS_PER_VERSION, MAX_REVIEWS_PER_VERSION),\n            len(available_reviewers),\n        )\n\n        # Take only the first num_reviews reviewers\n        for reviewer in available_reviewers[:num_reviews]:\n            await db.storelistingreview.create(\n                data={\n                    \"storeListingVersionId\": version.id,\n                    \"reviewByUserId\": reviewer.id,\n                    \"score\": random.randint(1, 5),\n                    \"comments\": faker.text(),\n                }\n            )\n\n    # Insert StoreListingSubmissions\n    print(f\"Inserting {NUM_USERS} store listing submissions\")\n    for listing in store_listings:\n        version = random.choice(store_listing_versions)\n        reviewer = random.choice(users)\n        status: prisma.enums.SubmissionStatus = random.choice(\n            [\n                prisma.enums.SubmissionStatus.PENDING,\n                prisma.enums.SubmissionStatus.APPROVED,\n                prisma.enums.SubmissionStatus.REJECTED,\n            ]\n        )\n        await db.storelistingsubmission.create(\n            data={\n                \"storeListingId\": listing.id,\n                \"storeListingVersionId\": version.id,\n                \"reviewerId\": reviewer.id,\n                \"Status\": status,\n                \"reviewComments\": faker.text(),\n            }\n        )\n\n    # Insert APIKeys\n    print(f\"Inserting {NUM_USERS} api keys\")\n    for user in users:\n        await db.apikey.create(\n            data={\n                \"name\": faker.word(),\n                \"prefix\": str(faker.uuid4())[:8],\n                \"postfix\": str(faker.uuid4())[-8:],\n                \"key\": str(faker.sha256()),\n                \"status\": prisma.enums.APIKeyStatus.ACTIVE,\n                \"permissions\": [\n                    prisma.enums.APIKeyPermission.EXECUTE_GRAPH,\n                    prisma.enums.APIKeyPermission.READ_GRAPH,\n                ],\n                \"description\": faker.text(),\n                \"userId\": user.id,\n            }\n        )\n\n    await db.disconnect()", "blocks": [{"id": 1, "label": "async def main():\ndb = Prisma()\nawait db.connect()", "successors": [{"id": 3, "label": "print(f\"Inserting {NUM_USERS} users\")\nusers = []", "successors": [{"id": 4, "label": "for _ in range(NUM_USERS):", "successors": [{"id": 5, "label": "user = await db.user.create(\n    data={\n        \"id\": str(faker.uuid4()),\n        \"email\": faker.unique.email(),\n        \"name\": faker.name(),\n        \"metadata\": prisma.Json({}),\n        \"integrations\": \"\",\n    }\n)\nusers.append(user)", "successors": []}]}, {"id": 6, "label": "agent_blocks = []\nprint(f\"Inserting {NUM_AGENT_BLOCKS} agent blocks\")", "successors": [{"id": 7, "label": "for _ in range(NUM_AGENT_BLOCKS):", "successors": [{"id": 8, "label": "block = await db.agentblock.create(\n    data={\n        \"name\": f\"{faker.word()}_{str(faker.uuid4())[:8]}\",\n        \"inputSchema\": \"{}\",\n        \"outputSchema\": \"{}\",\n    }\n)\nagent_blocks.append(block)", "successors": []}]}, {"id": 9, "label": "agent_graphs = []\nprint(f\"Inserting {NUM_USERS * MAX_GRAPHS_PER_USER} agent graphs\")", "successors": [{"id": 10, "label": "for user in users:", "successors": [{"id": 11, "label": "for _ in range(random.randint(MIN_GRAPHS_PER_USER, MAX_GRAPHS_PER_USER)):\n    graph = await db.agentgraph.create(\n        data={\n            \"name\": faker.sentence(nb_words=3),\n            \"description\": faker.text(max_nb_chars=200),\n            \"userId\": user.id,\n            \"isActive\": True,\n            \"isTemplate\": False,\n        }\n    )\n    agent_graphs.append(graph)", "successors": []}]}, {"id": 12, "label": "agent_nodes = []\nprint(f\"Inserting {NUM_USERS * MAX_GRAPHS_PER_USER * MAX_NODES_PER_GRAPH} agent nodes\")", "successors": [{"id": 13, "label": "for graph in agent_graphs:", "successors": [{"id": 14, "label": "num_nodes = random.randint(MIN_NODES_PER_GRAPH, MAX_NODES_PER_GRAPH)\nfor _ in range(num_nodes):\n    block = random.choice(agent_blocks)\n    node = await db.agentnode.create(\n        data={\n            \"agentBlockId\": block.id,\n            \"agentGraphId\": graph.id,\n            \"agentGraphVersion\": graph.version,\n            \"constantInput\": \"{}\",\n            \"metadata\": \"{}\",\n        }\n    )\n    agent_nodes.append(node)", "successors": []}]}, {"id": 15, "label": "agent_presets = []\nprint(f\"Inserting {NUM_USERS * MAX_PRESETS_PER_USER} agent presets\")", "successors": [{"id": 16, "label": "for user in users:", "successors": [{"id": 17, "label": "num_presets = random.randint(MIN_PRESETS_PER_USER, MAX_PRESETS_PER_USER)\nfor _ in range(num_presets):\n    graph = random.choice(agent_graphs)\n    preset = await db.agentpreset.create(\n        data={\n            \"name\": faker.sentence(nb_words=3),\n            \"description\": faker.text(max_nb_chars=200),\n            \"userId\": user.id,\n            \"agentId\": graph.id,\n            \"agentVersion\": graph.version,\n            \"isActive\": True,\n        }\n    )\n    agent_presets.append(preset)", "successors": []}]}, {"id": 18, "label": "user_agents = []\nprint(f\"Inserting {NUM_USERS * MAX_AGENTS_PER_USER} user agents\")", "successors": [{"id": 19, "label": "for user in users:", "successors": [{"id": 20, "label": "num_agents = random.randint(MIN_AGENTS_PER_USER, MAX_AGENTS_PER_USER)\nfor _ in range(num_agents):\n    graph = random.choice(agent_graphs)\n    preset = random.choice(agent_presets)\n    user_agent = await db.useragent.create(\n        data={\n            \"userId\": user.id,\n            \"agentId\": graph.id,\n            \"agentVersion\": graph.version,\n            \"agentPresetId\": preset.id,\n            \"isFavorite\": random.choice([True, False]),\n            \"isCreatedByUser\": random.choice([True, False]),\n            \"isArchived\": random.choice([True, False]),\n            \"isDeleted\": random.choice([True, False]),\n        }\n    )\n    user_agents.append(user_agent)", "successors": []}]}, {"id": 21, "label": "agent_graph_executions = []\nprint(f\"Inserting {NUM_USERS * MAX_GRAPHS_PER_USER * MAX_EXECUTIONS_PER_GRAPH} agent graph executions\")\ngraph_execution_data = []", "successors": [{"id": 22, "label": "for graph in agent_graphs:", "successors": [{"id": 23, "label": "user = random.choice(users)\nnum_executions = random.randint(MIN_EXECUTIONS_PER_GRAPH, MAX_EXECUTIONS_PER_GRAPH)\nfor _ in range(num_executions):\n    matching_presets = [p for p in agent_presets if p.agentId == graph.id]\n    preset = (\n        random.choice(matching_presets)\n        if matching_presets and random.random() < 0.5\n        else None\n    )\n\n    graph_execution_data.append(\n        {\n            \"agentGraphId\": graph.id,\n            \"agentGraphVersion\": graph.version,\n            \"userId\": user.id,\n            \"executionStatus\": prisma.enums.AgentExecutionStatus.COMPLETED,\n            \"startedAt\": faker.date_time_this_year(),\n            \"agentPresetId\": preset.id if preset else None,\n        }\n    )", "successors": []}]}, {"id": 24, "label": "agent_graph_executions = await db.agentgraphexecution.create_many(\n    data=graph_execution_data\n)\nagent_graph_executions = await db.agentgraphexecution.find_many()\nprint(f\"Inserting {NUM_USERS * MAX_GRAPHS_PER_USER * MAX_EXECUTIONS_PER_GRAPH} agent node executions\")\nnode_execution_data = []", "successors": [{"id": 26, "label": "for execution in agent_graph_executions:", "successors": [{"id": 27, "label": "nodes = [\n    node for node in agent_nodes if node.agentGraphId == execution.agentGraphId\n]\nfor node in nodes:\n    node_execution_data.append(\n        {\n            \"agentGraphExecutionId\": execution.id,\n            \"agentNodeId\": node.id,\n            \"executionStatus\": prisma.enums.AgentExecutionStatus.COMPLETED,\n            \"addedTime\": datetime.now(),\n        }\n    )", "successors": []}]}, {"id": 28, "label": "agent_node_executions = await db.agentnodeexecution.create_many(data=node_execution_data)\nagent_node_executions = await db.agentnodeexecution.find_many()\nprint(f\"Inserting {NUM_USERS * MAX_GRAPHS_PER_USER * MAX_EXECUTIONS_PER_GRAPH} agent node execution input/outputs\")\ninput_output_data = []", "successors": [{"id": 30, "label": "for node_execution in agent_node_executions:", "successors": [{"id": 31, "label": "input_output_data.append(\n    {\n        \"name\": \"input1\",\n        \"data\": \"{}\",\n        \"time\": datetime.now(),\n        \"referencedByInputExecId\": node_execution.id,\n    }\n)\ninput_output_data.append(\n    {\n        \"name\": \"output1\",\n        \"data\": \"{}\",\n        \"time\": datetime.now(),\n        \"referencedByOutputExecId\": node_execution.id,\n    }\n)", "successors": []}]}, {"id": 32, "label": "await db.agentnodeexecutioninputoutput.create_many(data=input_output_data)", "successors": [{"id": 33, "label": "print(f\"Inserting {NUM_USERS * MAX_GRAPHS_PER_USER} agent node links\")\nfor graph in agent_graphs:\nnodes = [node for node in agent_nodes if node.agentGraphId == graph.id]\nif len(nodes) >= 2:\n    source_node = nodes[0]\n    sink_node = nodes[1]\n    await db.agentnodelink.create(\n        data={\n            \"agentNodeSourceId\": source_node.id,\n            \"sourceName\": \"output1\",\n            \"agentNodeSinkId\": sink_node.id,\n            \"sinkName\": \"input1\",\n            \"isStatic\": False,\n        }\n    )", "successors": []}, {"id": 35, "label": "print(f\"Inserting {NUM_USERS} analytics details\")\nfor user in users:", "successors": [{"id": 36, "label": "for _ in range(1):\n    await db.analyticsdetails.create(\n        data={\n            \"userId\": user.id,\n            \"type\": faker.word(),\n            \"data\": prisma.Json({}),\n            \"dataIndex\": faker.word(),\n        }\n    )", "successors": []}]}, {"id": 37, "label": "print(f\"Inserting {NUM_USERS} analytics metrics\")\nfor user in users:", "successors": [{"id": 38, "label": "for _ in range(1):\n    await db.analyticsmetrics.create(\n        data={\n            \"userId\": user.id,\n            \"analyticMetric\": faker.word(),\n            \"value\": random.uniform(0, 100),\n            \"dataString\": faker.word(),\n        }\n    )", "successors": []}]}, {"id": 39, "label": "print(f\"Inserting {NUM_USERS} credit transactions\")\nfor user in users:", "successors": [{"id": 40, "label": "for _ in range(1):\n    block = random.choice(agent_blocks)\n    await db.credittransaction.create(\n        data={\n            \"transactionKey\": str(faker.uuid4()),\n            \"userId\": user.id,\n            \"blockId\": block.id,\n            \"amount\": random.randint(1, 100),\n            \"type\": (\n                prisma.enums.CreditTransactionType.TOP_UP\n                if random.random() < 0.5\n                else prisma.enums.CreditTransactionType.USAGE\n            ),\n            \"metadata\": prisma.Json({}),\n        }\n    )", "successors": []}]}, {"id": 41, "label": "profiles = []\nprint(f\"Inserting {NUM_USERS} profiles\")\nfor user in users:\nprofile = await db.profile.create(\n    data={\n        \"userId\": user.id,\n        \"name\": user.name or faker.name(),\n        \"username\": faker.unique.user_name(),\n        \"description\": faker.text(),\n        \"links\": [faker.url() for _ in range(3)],\n        \"avatarUrl\": get_image(),\n    }\n)\nprofiles.append(profile)", "successors": []}, {"id": 43, "label": "store_listings = []\nprint(f\"Inserting {NUM_USERS} store listings\")\nfor graph in agent_graphs:\nuser = random.choice(users)\nlisting = await db.storelisting.create(\n    data={\n        \"agentId\": graph.id,\n        \"agentVersion\": graph.version,\n        \"owningUserId\": user.id,\n        \"isApproved\": random.choice([True, False]),\n    }\n)\nstore_listings.append(listing)", "successors": []}, {"id": 45, "label": "store_listing_versions = []\nprint(f\"Inserting {NUM_USERS} store listing versions\")\nfor listing in store_listings:\ngraph = [g for g in agent_graphs if g.id == listing.agentId][0]\nversion = await db.storelistingversion.create(\n    data={\n        \"agentId\": graph.id,\n        \"agentVersion\": graph.version,\n        \"slug\": faker.slug(),\n        \"name\": graph.name or faker.sentence(nb_words=3),\n        \"subHeading\": faker.sentence(),\n        \"videoUrl\": faker.url(),\n        \"imageUrls\": [get_image() for _ in range(3)],\n        \"description\": faker.text(),\n        \"categories\": [faker.word() for _ in range(3)],\n        \"isFeatured\": random.choice([True, False]),\n        \"isAvailable\": True,\n        \"isApproved\": random.choice([True, False]),\n        \"storeListingId\": listing.id,\n    }\n)\nstore_listing_versions.append(version)", "successors": []}, {"id": 47, "label": "print(f\"Inserting {NUM_USERS * MAX_REVIEWS_PER_VERSION} store listing reviews\")\nfor version in store_listing_versions:\navailable_reviewers = users.copy()\nrandom.shuffle(available_reviewers)\nnum_reviews = min(\n    random.randint(MIN_REVIEWS_PER_VERSION, MAX_REVIEWS_PER_VERSION),\n    len(available_reviewers),\n)\nfor reviewer in available_reviewers[:num_reviews]:\n    await db.storelistingreview.create(\n        data={\n            \"storeListingVersionId\": version.id,\n            \"reviewByUserId\": reviewer.id,\n            \"score\": random.randint(1, 5),\n            \"comments\": faker.text(),\n        }\n    )", "successors": []}, {"id": 49, "label": "print(f\"Inserting {NUM_USERS} store listing submissions\")\nfor listing in store_listings:\nversion = random.choice(store_listing_versions)\nreviewer = random.choice(users)\nstatus: prisma.enums.SubmissionStatus = random.choice(\n    [\n        prisma.enums.SubmissionStatus.PENDING,\n        prisma.enums.SubmissionStatus.APPROVED,\n        prisma.enums.SubmissionStatus.REJECTED,\n    ]\n)\nawait db.storelistingsubmission.create(\n    data={\n        \"storeListingId\": listing.id,\n        \"storeListingVersionId\": version.id,\n        \"reviewerId\": reviewer.id,\n        \"Status\": status,\n        \"reviewComments\": faker.text(),\n    }\n)", "successors": []}, {"id": 51, "label": "print(f\"Inserting {NUM_USERS} api keys\")\nfor user in users:\nawait db.apikey.create(\n    data={\n        \"name\": faker.word(),\n        \"prefix\": str(faker.uuid4())[:8],\n        \"postfix\": str(faker.uuid4())[-8:],\n        \"key\": str(faker.sha256()),\n        \"status\": prisma.enums.APIKeyStatus.ACTIVE,\n        \"permissions\": [\n            prisma.enums.APIKeyPermission.EXECUTE_GRAPH,\n            prisma.enums.APIKeyPermission.READ_GRAPH,\n        ],\n        \"description\": faker.text(),\n        \"userId\": user.id,\n    }\n)", "successors": []}, {"id": 53, "label": "await db.disconnect()", "successors": []}]}]}]}]}]}]}]}]}]}]}]}]}], "classes": [], "simplified_code": "import asyncio\nimport random\nfrom datetime import datetime\n\nimport prisma.enums\nfrom faker import Faker\nfrom prisma import Prisma\n\nfaker = Faker()\n\n# Constants for data generation limits\n\n# Base entities\nNUM_USERS = 100  # Creates 100 user records\nNUM_AGENT_BLOCKS = 100  # Creates 100 agent block templates\n\n# Per-user entities\nMIN_GRAPHS_PER_USER = 1  # Each user will have between 1-5 graphs\nMAX_GRAPHS_PER_USER = 5  # Total graphs: 500-2500 (NUM_USERS * MIN/MAX_GRAPHS)\n\n# Per-graph entities\nMIN_NODES_PER_GRAPH = 2  # Each graph will have between 2-5 nodes\nMAX_NODES_PER_GRAPH = (\n    5  # Total nodes: 1000-2500 (GRAPHS_PER_USER * NUM_USERS * MIN/MAX_NODES)\n)\n\n# Additional per-user entities\nMIN_PRESETS_PER_USER = 1  # Each user will have between 1-2 presets\nMAX_PRESETS_PER_USER = 5  # Total presets: 500-2500 (NUM_USERS * MIN/MAX_PRESETS)\nMIN_AGENTS_PER_USER = 1  # Each user will have between 1-2 agents\nMAX_AGENTS_PER_USER = 10  # Total agents: 500-5000 (NUM_USERS * MIN/MAX_AGENTS)\n\n# Execution and review records\nMIN_EXECUTIONS_PER_GRAPH = 1  # Each graph will have between 1-5 execution records\nMAX_EXECUTIONS_PER_GRAPH = (\n    20  # Total executions: 1000-5000 (TOTAL_GRAPHS * MIN/MAX_EXECUTIONS)\n)\nMIN_REVIEWS_PER_VERSION = 1  # Each version will have between 1-3 reviews\nMAX_REVIEWS_PER_VERSION = 5  # Total reviews depends on number of versions created\n\n\n    return url\n\n\n    await db.disconnect()\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())", "blocks": [{"id": 1, "label": "import asyncio\nimport random\nfrom datetime import datetime\n\nimport prisma.enums\nfrom faker import Faker\nfrom prisma import Prisma\n\nfaker = Faker()\n\n# Constants for data generation limits\n\n# Base entities\nNUM_USERS = 100  # Creates 100 user records\nNUM_AGENT_BLOCKS = 100  # Creates 100 agent block templates\n\n# Per-user entities\nMIN_GRAPHS_PER_USER = 1  # Each user will have between 1-5 graphs\nMAX_GRAPHS_PER_USER = 5  # Total graphs: 500-2500 (NUM_USERS * MIN/MAX_GRAPHS)\n\n# Per-graph entities\nMIN_NODES_PER_GRAPH = 2  # Each graph will have between 2-5 nodes\nMAX_NODES_PER_GRAPH = (\n    5  # Total nodes: 1000-2500 (GRAPHS_PER_USER * NUM_USERS * MIN/MAX_NODES)\n)\n\n# Additional per-user entities\nMIN_PRESETS_PER_USER = 1  # Each user will have between 1-2 presets\nMAX_PRESETS_PER_USER = 5  # Total presets: 500-2500 (NUM_USERS * MIN/MAX_PRESETS)\nMIN_AGENTS_PER_USER = 1  # Each user will have between 1-2 agents\nMAX_AGENTS_PER_USER = 10  # Total agents: 500-5000 (NUM_USERS * MIN/MAX_AGENTS)\n\n# Execution and review records\nMIN_EXECUTIONS_PER_GRAPH = 1  # Each graph will have between 1-5 execution records\nMAX_EXECUTIONS_PER_GRAPH = (\n    20  # Total executions: 1000-5000 (TOTAL_GRAPHS * MIN/MAX_EXECUTIONS)\n)\nMIN_REVIEWS_PER_VERSION = 1  # Each version will have between 1-3 reviews\nMAX_REVIEWS_PER_VERSION = 5  # Total reviews depends on number of versions created\n\n\n    return url\n\n\n    await db.disconnect()\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())", "successors": []}]}
{"file_name": "134.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 158, "functions": [], "classes": [{"name": "GitHubTriggerBase", "type": "class", "start_line": 27, "end_line": 58, "functions": [{"name": "run", "type": "function", "start_line": 55, "end_line": 57, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        yield \"payload\", input_data.payload\n        yield \"triggered_by_user\", input_data.payload[\"sender\"]", "blocks": [{"id": 1, "label": "yield \"payload\", input_data.payload\nyield \"triggered_by_user\", input_data.payload[\"sender\"]", "successors": []}]}], "classes": [{"name": "Input", "type": "class", "start_line": 28, "end_line": 40, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        repo: str = SchemaField(\n            description=(\n                \"Repository to subscribe to.\\n\\n\"\n                \"**Note:** Make sure your GitHub credentials have permissions \"\n                \"to create webhooks on this repo.\"\n            ),\n            placeholder=\"{owner}/{repo}\",\n        )\n        # --8<-- [start:example-payload-field]\n        payload: dict = SchemaField(hidden=True, default={})\n        # --8<-- [end:example-payload-field]", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")", "successors": [{"id": 3, "label": "    repo: str = SchemaField(description=(\"Repository to subscribe to.\\n\\n\"\n\"**Note:** Make sure your GitHub credentials have permissions \"\n\"to create webhooks on this repo.\"), placeholder=\"{owner}/{repo}\",)\n    payload: dict = SchemaField(hidden=True, default={})", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 42, "end_line": 53, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        payload: dict = SchemaField(\n            description=\"The complete webhook payload that was received from GitHub. \"\n            \"Includes information about the affected resource (e.g. pull request), \"\n            \"the event, and the user who triggered the event.\"\n        )\n        triggered_by_user: dict = SchemaField(\n            description=\"Object representing the GitHub user who triggered the event\"\n        )\n        error: str = SchemaField(\n            description=\"Error message if the payload could not be processed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    payload: dict = SchemaField(description=\"The complete webhook payload that was received from GitHub. Includes information about the affected resource (e.g. pull request), the event, and the user who triggered the event.\")", "successors": [{"id": 3, "label": "    triggered_by_user: dict = SchemaField(description=\"Object representing the GitHub user who triggered the event\")\n    error: str = SchemaField(description=\"Error message if the payload could not be processed\")", "successors": []}]}]}], "simplified_code": "class GitHubTriggerBase:\n        # --8<-- [end:example-payload-field]\n\n        )\n\n        yield \"triggered_by_user\", input_data.payload[\"sender\"]\n", "blocks": [{"id": 1, "label": "class GitHubTriggerBase:\n)", "successors": [{"id": 3, "label": "yield \"triggered_by_user\", input_data.payload[\"sender\"]", "successors": []}]}]}, {"name": "GithubPullRequestTriggerBlock", "type": "class", "start_line": 60, "end_line": 155, "functions": [{"name": "__init__", "type": "function", "start_line": 111, "end_line": 148, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        from backend.integrations.webhooks.github import GithubWebhookType\n\n        example_payload = json.loads(\n            self.EXAMPLE_PAYLOAD_FILE.read_text(encoding=\"utf-8\")\n        )\n\n        super().__init__(\n            id=\"6c60ec01-8128-419e-988f-96a063ee2fea\",\n            description=\"This block triggers on pull request events and outputs the event type and payload.\",\n            categories={BlockCategory.DEVELOPER_TOOLS, BlockCategory.INPUT},\n            input_schema=GithubPullRequestTriggerBlock.Input,\n            output_schema=GithubPullRequestTriggerBlock.Output,\n            # --8<-- [start:example-webhook_config]\n            webhook_config=BlockWebhookConfig(\n                provider=\"github\",\n                webhook_type=GithubWebhookType.REPO,\n                resource_format=\"{repo}\",\n                event_filter_input=\"events\",\n                event_format=\"pull_request.{event}\",\n            ),\n            # --8<-- [end:example-webhook_config]\n            test_input={\n                \"repo\": \"Significant-Gravitas/AutoGPT\",\n                \"events\": {\"opened\": True, \"synchronize\": True},\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n                \"payload\": example_payload,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\"payload\", example_payload),\n                (\"triggered_by_user\", example_payload[\"sender\"]),\n                (\"event\", example_payload[\"action\"]),\n                (\"number\", example_payload[\"number\"]),\n                (\"pull_request\", example_payload[\"pull_request\"]),\n                (\"pull_request_url\", example_payload[\"pull_request\"][\"html_url\"]),\n            ],\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nfrom backend.integrations.webhooks.github import GithubWebhookType", "successors": [{"id": 3, "label": "example_payload = json.loads(self.EXAMPLE_PAYLOAD_FILE.read_text(encoding=\"utf-8\"))\nsuper().__init__(id=\"6c60ec01-8128-419e-988f-96a063ee2fea\", description=\"This block triggers on pull request events and outputs the event type and payload.\", categories={BlockCategory.DEVELOPER_TOOLS, BlockCategory.INPUT}, input_schema=GithubPullRequestTriggerBlock.Input, output_schema=GithubPullRequestTriggerBlock.Output, webhook_config=BlockWebhookConfig(provider=\"github\", webhook_type=GithubWebhookType.REPO, resource_format=\"{repo}\", event_filter_input=\"events\", event_format=\"pull_request.{event}\"), test_input={\"repo\": \"Significant-Gravitas/AutoGPT\", \"events\": {\"opened\": True, \"synchronize\": True}, \"credentials\": TEST_CREDENTIALS_INPUT, \"payload\": example_payload}, test_credentials=TEST_CREDENTIALS, test_output=[(\"payload\", example_payload), (\"triggered_by_user\", example_payload[\"sender\"]), (\"event\", example_payload[\"action\"]), (\"number\", example_payload[\"number\"]), (\"pull_request\", example_payload[\"pull_request\"]), (\"pull_request_url\", example_payload[\"pull_request\"][\"html_url\"])])", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 150, "end_line": 155, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:  # type: ignore\n        yield from super().run(input_data, **kwargs)\n        yield \"event\", input_data.payload[\"action\"]\n        yield \"number\", input_data.payload[\"number\"]\n        yield \"pull_request\", input_data.payload[\"pull_request\"]\n        yield \"pull_request_url\", input_data.payload[\"pull_request\"][\"html_url\"]", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:  # type: ignore\nyield from super().run(input_data, **kwargs)", "successors": [{"id": 3, "label": "yield \"event\", input_data.payload[\"action\"]\nyield \"number\", input_data.payload[\"number\"]", "successors": [{"id": 5, "label": "yield \"pull_request\", input_data.payload[\"pull_request\"]\nyield \"pull_request_url\", input_data.payload[\"pull_request\"][\"html_url\"]", "successors": []}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 66, "end_line": 96, "functions": [], "classes": [{"name": "EventsFilter", "type": "class", "start_line": 67, "end_line": 92, "functions": [], "classes": [], "simplified_code": "        class EventsFilter(BaseModel):\n            \"\"\"\n            https://docs.github.com/en/webhooks/webhook-events-and-payloads#pull_request\n            \"\"\"\n\n            opened: bool = False\n            edited: bool = False\n            closed: bool = False\n            reopened: bool = False\n            synchronize: bool = False\n            assigned: bool = False\n            unassigned: bool = False\n            labeled: bool = False\n            unlabeled: bool = False\n            converted_to_draft: bool = False\n            locked: bool = False\n            unlocked: bool = False\n            enqueued: bool = False\n            dequeued: bool = False\n            milestoned: bool = False\n            demilestoned: bool = False\n            ready_for_review: bool = False\n            review_requested: bool = False\n            review_request_removed: bool = False\n            auto_merge_enabled: bool = False\n            auto_merge_disabled: bool = False", "blocks": [{"id": 1, "label": "class EventsFilter(BaseModel):\n    \"\"\"\n    https://docs.github.com/en/webhooks/webhook-events-and-payloads#pull_request\n    \"\"\"", "successors": [{"id": 3, "label": "    opened: bool = False\n    edited: bool = False", "successors": [{"id": 5, "label": "    closed: bool = False\n    reopened: bool = False", "successors": [{"id": 7, "label": "    synchronize: bool = False\n    assigned: bool = False", "successors": [{"id": 9, "label": "    unassigned: bool = False\n    labeled: bool = False", "successors": [{"id": 11, "label": "    unlabeled: bool = False\n    converted_to_draft: bool = False", "successors": [{"id": 13, "label": "    locked: bool = False\n    unlocked: bool = False", "successors": [{"id": 15, "label": "    enqueued: bool = False\n    dequeued: bool = False", "successors": [{"id": 17, "label": "    milestoned: bool = False\n    demilestoned: bool = False", "successors": [{"id": 19, "label": "    ready_for_review: bool = False\n    review_requested: bool = False", "successors": [{"id": 21, "label": "    review_request_removed: bool = False\n    auto_merge_enabled: bool = False", "successors": [{"id": 23, "label": "    auto_merge_disabled: bool = False", "successors": []}]}]}]}]}]}]}]}]}]}]}]}]}], "simplified_code": "    class Input(GitHubTriggerBase.Input):\n            auto_merge_disabled: bool = False\n\n        events: EventsFilter = SchemaField(\n            title=\"Events\", description=\"The events to subscribe to\"\n        )", "blocks": [{"id": 1, "label": "class Input(GitHubTriggerBase.Input):\n    auto_merge_disabled: bool = False", "successors": [{"id": 3, "label": "    events: EventsFilter = SchemaField(\n        title=\"Events\", description=\"The events to subscribe to\"\n    )", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 99, "end_line": 109, "functions": [], "classes": [], "simplified_code": "    class Output(GitHubTriggerBase.Output):\n        event: str = SchemaField(\n            description=\"The PR event that triggered the webhook (e.g. 'opened')\"\n        )\n        number: int = SchemaField(description=\"The number of the affected pull request\")\n        pull_request: dict = SchemaField(\n            description=\"Object representing the affected pull request\"\n        )\n        pull_request_url: str = SchemaField(\n            description=\"The URL of the affected pull request\"\n        )", "blocks": [{"id": 1, "label": "class Output(GitHubTriggerBase.Output):\n    event: str = SchemaField(description=\"The PR event that triggered the webhook (e.g. 'opened')\")", "successors": [{"id": 3, "label": "    number: int = SchemaField(description=\"The number of the affected pull request\")\n    pull_request: dict = SchemaField(description=\"Object representing the affected pull request\")", "successors": [{"id": 5, "label": "    pull_request_url: str = SchemaField(description=\"The URL of the affected pull request\")", "successors": []}]}]}]}], "simplified_code": "class GithubPullRequestTriggerBlock(GitHubTriggerBase, Block):\n    EXAMPLE_PAYLOAD_FILE = (\n        Path(__file__).parent / \"example_payloads\" / \"pull_request.synchronize.json\"\n    )\n\n    # --8<-- [start:example-event-filter]\n        )\n        # --8<-- [end:example-event-filter]\n\n        )\n\n        )\n\n        yield \"pull_request_url\", input_data.payload[\"pull_request\"][\"html_url\"]", "blocks": [{"id": 1, "label": "class GithubPullRequestTriggerBlock(GitHubTriggerBase, Block):\n    EXAMPLE_PAYLOAD_FILE = Path(__file__).parent / \"example_payloads\" / \"pull_request.synchronize.json\"", "successors": [{"id": 3, "label": "    yield \"pull_request_url\", input_data.payload[\"pull_request\"][\"html_url\"]", "successors": []}]}]}], "simplified_code": "import json\nimport logging\nfrom pathlib import Path\n\nfrom pydantic import BaseModel\n\nfrom backend.data.block import (\n    Block,\n    BlockCategory,\n    BlockOutput,\n    BlockSchema,\n    BlockWebhookConfig,\n)\nfrom backend.data.model import SchemaField\n\nfrom ._auth import (\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    GithubCredentialsField,\n    GithubCredentialsInput,\n)\n\nlogger = logging.getLogger(__name__)\n\n\n# --8<-- [start:GithubTriggerExample]\n\n\n        yield \"pull_request_url\", input_data.payload[\"pull_request\"][\"html_url\"]\n\n\n# --8<-- [end:GithubTriggerExample]", "blocks": [{"id": 1, "label": "import json\nimport logging\nfrom pathlib import Path\n\nfrom pydantic import BaseModel\n\nfrom backend.data.block import (\n    Block,\n    BlockCategory,\n    BlockOutput,\n    BlockSchema,\n    BlockWebhookConfig,\n)\nfrom backend.data.model import SchemaField\n\nfrom ._auth import (\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    GithubCredentialsField,\n    GithubCredentialsInput,\n)\n\nlogger = logging.getLogger(__name__)\n\n\n# --8<-- [start:GithubTriggerExample]\n\n\nyield \"pull_request_url\", input_data.payload[\"pull_request\"][\"html_url\"]\n\n\n# --8<-- [end:GithubTriggerExample]", "successors": []}]}
{"file_name": "135.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 46, "functions": [], "classes": [{"name": "HitCounts", "type": "class", "start_line": 6, "end_line": 46, "functions": [{"name": "extract_url", "type": "function", "start_line": 8, "end_line": 10, "functions": [], "classes": [], "simplified_code": "    def extract_url(self, line):\n        \"\"\"Extract the generated url from the log line.\"\"\"\n        pass", "blocks": [{"id": 1, "label": "def extract_url(self, line):\n\"\"\"Extract the generated url from the log line.\"\"\"\npass", "successors": []}]}, {"name": "extract_year_month", "type": "function", "start_line": 12, "end_line": 14, "functions": [], "classes": [], "simplified_code": "    def extract_year_month(self, line):\n        \"\"\"Return the year and month portions of the timestamp.\"\"\"\n        pass", "blocks": [{"id": 1, "label": "def extract_year_month(self, line):\n\"\"\"Return the year and month portions of the timestamp.\"\"\"", "successors": [{"id": 3, "label": "pass", "successors": []}]}]}, {"name": "mapper", "type": "function", "start_line": 16, "end_line": 27, "functions": [], "classes": [], "simplified_code": "    def mapper(self, _, line):\n        \"\"\"Parse each log line, extract and transform relevant lines.\n\n        Emit key value pairs of the form:\n\n        (2016-01, url0), 1\n        (2016-01, url0), 1\n        (2016-01, url1), 1\n        \"\"\"\n        url = self.extract_url(line)\n        period = self.extract_year_month(line)\n        yield (period, url), 1", "blocks": [{"id": 1, "label": "def mapper(self, _, line):\nurl = self.extract_url(line)\nperiod = self.extract_year_month(line)\nyield (period, url), 1", "successors": []}]}, {"name": "reducer", "type": "function", "start_line": 29, "end_line": 35, "functions": [], "classes": [], "simplified_code": "    def reducer(self, key, values):\n        \"\"\"Sum values for each key.\n\n        (2016-01, url0), 2\n        (2016-01, url1), 1\n        \"\"\"\n        yield key, sum(values)", "blocks": [{"id": 1, "label": "def reducer(self, key, values):\n    \"\"\"Sum values for each key.\n\n    (2016-01, url0), 2\n    (2016-01, url1), 1\n    \"\"\"\n    yield key, sum(values)", "successors": []}]}, {"name": "steps", "type": "function", "start_line": 37, "end_line": 42, "functions": [], "classes": [], "simplified_code": "    def steps(self):\n        \"\"\"Run the map and reduce steps.\"\"\"\n        return [\n            self.mr(mapper=self.mapper,\n                    reducer=self.reducer)\n        ]", "blocks": [{"id": 1, "label": "def steps(self):\n\"\"\"Run the map and reduce steps.\"\"\"", "successors": [{"id": 3, "label": "return [\n    self.mr(mapper=self.mapper,\n            reducer=self.reducer)\n]", "successors": []}]}]}], "simplified_code": "class HitCounts(MRJob):\n\n        pass\n\n        pass\n\n        yield (period, url), 1\n\n        yield key, sum(values)\n\n        ]\n\n\nif __name__ == '__main__':\n    HitCounts.run()", "blocks": [{"id": 1, "label": "class HitCounts(MRJob):", "successors": [{"id": 2, "label": "    pass", "successors": []}, {"id": 3, "label": "    pass", "successors": []}, {"id": 4, "label": "    yield (period, url), 1", "successors": []}, {"id": 5, "label": "    yield key, sum(values)", "successors": []}]}]}], "simplified_code": "# -*- coding: utf-8 -*-\n\nfrom mrjob.job import MRJob\n\n\n    HitCounts.run()", "blocks": [{"id": 1, "label": "from mrjob.job import MRJob\nHitCounts.run()", "successors": []}]}
{"file_name": "136.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 99, "functions": [], "classes": [{"name": "Slant3DWebhooksManager", "type": "class", "start_line": 14, "end_line": 99, "functions": [{"name": "_register_webhook", "type": "function", "start_line": 20, "end_line": 57, "functions": [], "classes": [], "simplified_code": "    async def _register_webhook(\n        self,\n        credentials: Credentials,\n        webhook_type: str,\n        resource: str,\n        events: list[str],\n        ingress_url: str,\n        secret: str,\n    ) -> tuple[str, dict]:\n        \"\"\"Register a new webhook with Slant3D\"\"\"\n\n        if not isinstance(credentials, APIKeyCredentials):\n            raise ValueError(\"API key is required to register a webhook\")\n\n        headers = {\n            \"api-key\": credentials.api_key.get_secret_value(),\n            \"Content-Type\": \"application/json\",\n        }\n\n        # Slant3D's API doesn't use events list, just register for all order updates\n        payload = {\"endPoint\": ingress_url}\n\n        response = requests.post(\n            f\"{self.BASE_URL}/customer/webhookSubscribe\", headers=headers, json=payload\n        )\n\n        if not response.ok:\n            error = response.json().get(\"error\", \"Unknown error\")\n            raise RuntimeError(f\"Failed to register webhook: {error}\")\n\n        webhook_config = {\n            \"endpoint\": ingress_url,\n            \"provider\": self.PROVIDER_NAME,\n            \"events\": [\"order.shipped\"],  # Currently the only supported event\n            \"type\": webhook_type,\n        }\n\n        return \"\", webhook_config", "blocks": [{"id": 1, "label": "async def _register_webhook(\n        self,\n        credentials: Credentials,\n        webhook_type: str,\n        resource: str,\n        events: list[str],\n        ingress_url: str,\n        secret: str,\n    ) -> tuple[str, dict]:", "successors": [{"id": 2, "label": "if not isinstance(credentials, APIKeyCredentials):\nraise ValueError(\"API key is required to register a webhook\")", "successors": []}, {"id": 4, "label": "headers = {\n    \"api-key\": credentials.api_key.get_secret_value(),\n    \"Content-Type\": \"application/json\",\n}\npayload = {\"endPoint\": ingress_url}", "successors": [{"id": 6, "label": "response = requests.post(\n    f\"{self.BASE_URL}/customer/webhookSubscribe\", headers=headers, json=payload\n)", "successors": [{"id": 7, "label": "if not response.ok:\nerror = response.json().get(\"error\", \"Unknown error\")", "successors": [{"id": 9, "label": "raise RuntimeError(f\"Failed to register webhook: {error}\")", "successors": []}]}, {"id": 10, "label": "webhook_config = {\n    \"endpoint\": ingress_url,\n    \"provider\": self.PROVIDER_NAME,\n    \"events\": [\"order.shipped\"],\n    \"type\": webhook_type,\n}\nreturn \"\", webhook_config", "successors": []}]}]}]}]}, {"name": "validate_payload", "type": "function", "start_line": 60, "end_line": 86, "functions": [], "classes": [], "simplified_code": "    async def validate_payload(\n        cls, webhook: integrations.Webhook, request: Request\n    ) -> tuple[dict, str]:\n        \"\"\"Validate incoming webhook payload from Slant3D\"\"\"\n\n        payload = await request.json()\n\n        # Validate required fields from Slant3D API spec\n        required_fields = [\"orderId\", \"status\", \"trackingNumber\", \"carrierCode\"]\n        missing_fields = [field for field in required_fields if field not in payload]\n\n        if missing_fields:\n            raise ValueError(f\"Missing required fields: {', '.join(missing_fields)}\")\n\n        # Normalize payload structure\n        normalized_payload = {\n            \"orderId\": payload[\"orderId\"],\n            \"status\": payload[\"status\"],\n            \"trackingNumber\": payload[\"trackingNumber\"],\n            \"carrierCode\": payload[\"carrierCode\"],\n        }\n\n        # Currently Slant3D only sends shipping notifications\n        # Convert status to lowercase for event format compatibility\n        event_type = f\"order.{payload['status'].lower()}\"\n\n        return normalized_payload, event_type", "blocks": [{"id": 1, "label": "async def validate_payload(cls, webhook: integrations.Webhook, request: Request) -> tuple[dict, str]:\n\"\"\"Validate incoming webhook payload from Slant3D\"\"\"\n\npayload = await request.json()", "successors": [{"id": 3, "label": "required_fields = [\"orderId\", \"status\", \"trackingNumber\", \"carrierCode\"]\nmissing_fields = [field for field in required_fields if field not in payload]\nif missing_fields:", "successors": [{"id": 5, "label": "raise ValueError(f\"Missing required fields: {', '.join(missing_fields)}\")", "successors": []}, {"id": 6, "label": "normalized_payload = {\n    \"orderId\": payload[\"orderId\"],\n    \"status\": payload[\"status\"],\n    \"trackingNumber\": payload[\"trackingNumber\"],\n    \"carrierCode\": payload[\"carrierCode\"],\n}\n\n# Currently Slant3D only sends shipping notifications\n# Convert status to lowercase for event format compatibility\nevent_type = f\"order.{payload['status'].lower()}\"\n\nreturn normalized_payload, event_type", "successors": []}]}]}]}, {"name": "_deregister_webhook", "type": "function", "start_line": 88, "end_line": 99, "functions": [], "classes": [], "simplified_code": "    async def _deregister_webhook(\n        self, webhook: integrations.Webhook, credentials: Credentials\n    ) -> None:\n        \"\"\"\n        Note: Slant3D API currently doesn't provide a deregistration endpoint.\n        This would need to be handled through support.\n        \"\"\"\n        # Log warning since we can't properly deregister\n        logger.warning(\n            f\"Warning: Manual deregistration required for webhook {webhook.id}\"\n        )\n        pass", "blocks": [{"id": 1, "label": "async def _deregister_webhook(self, webhook: integrations.Webhook, credentials: Credentials) -> None:\n\"\"\"\nNote: Slant3D API currently doesn't provide a deregistration endpoint.\nThis would need to be handled through support.\n\"\"\"", "successors": [{"id": 3, "label": "logger.warning(f\"Warning: Manual deregistration required for webhook {webhook.id}\")\npass", "successors": []}]}]}], "simplified_code": "class Slant3DWebhooksManager(BaseWebhooksManager):\n    \"\"\"Manager for Slant3D webhooks\"\"\"\n\n    PROVIDER_NAME = ProviderName.SLANT3D\n    BASE_URL = \"https://www.slant3dapi.com/api\"\n\n        return \"\", webhook_config\n\n    @classmethod\n        return normalized_payload, event_type\n\n        pass", "blocks": [{"id": 1, "label": "class Slant3DWebhooksManager(BaseWebhooksManager):\n    \"\"\"Manager for Slant3D webhooks\"\"\"", "successors": [{"id": 3, "label": "    PROVIDER_NAME = ProviderName.SLANT3D\n    BASE_URL = \"https://www.slant3dapi.com/api\"", "successors": [{"id": 5, "label": "    def __init__(self, some_parameter):\n        self.some_parameter = some_parameter", "successors": [{"id": 7, "label": "    def some_method(self):\n        return \"\", webhook_config", "successors": []}, {"id": 9, "label": "    @classmethod\n    def another_method(cls):", "successors": [{"id": 11, "label": "        return normalized_payload, event_type", "successors": []}]}, {"id": 12, "label": "    pass", "successors": []}]}]}]}]}], "simplified_code": "import logging\n\nimport requests\nfrom fastapi import Request\n\nfrom backend.data import integrations\nfrom backend.data.model import APIKeyCredentials, Credentials\nfrom backend.integrations.providers import ProviderName\nfrom backend.integrations.webhooks._base import BaseWebhooksManager\n\nlogger = logging.getLogger(__name__)\n\n\n        pass", "blocks": [{"id": 1, "label": "import logging\n\nimport requests\nfrom fastapi import Request\n\nfrom backend.data import integrations\nfrom backend.data.model import APIKeyCredentials, Credentials\nfrom backend.integrations.providers import ProviderName\nfrom backend.integrations.webhooks._base import BaseWebhooksManager\n\nlogger = logging.getLogger(__name__)\n\n\n pass", "successors": []}]}
{"file_name": "137.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 198, "functions": [{"name": "check_media_exists", "type": "function", "start_line": 18, "end_line": 51, "functions": [], "classes": [], "simplified_code": "async def check_media_exists(user_id: str, filename: str) -> str | None:\n    \"\"\"\n    Check if a media file exists in storage for the given user.\n    Tries both images and videos directories.\n\n    Args:\n        user_id (str): ID of the user who uploaded the file\n        filename (str): Name of the file to check\n\n    Returns:\n        str | None: URL of the blob if it exists, None otherwise\n    \"\"\"\n    try:\n        settings = Settings()\n        storage_client = storage.Client()\n        bucket = storage_client.bucket(settings.config.media_gcs_bucket_name)\n\n        # Check images\n        image_path = f\"users/{user_id}/images/{filename}\"\n        image_blob = bucket.blob(image_path)\n        if image_blob.exists():\n            return image_blob.public_url\n\n        # Check videos\n        video_path = f\"users/{user_id}/videos/{filename}\"\n\n        video_blob = bucket.blob(video_path)\n        if video_blob.exists():\n            return video_blob.public_url\n\n        return None\n    except Exception as e:\n        logger.error(f\"Error checking if media file exists: {str(e)}\")\n        return None", "blocks": [{"id": 1, "label": "try:\nsettings = Settings()\nstorage_client = storage.Client()\nbucket = storage_client.bucket(settings.config.media_gcs_bucket_name)", "successors": [{"id": 3, "label": "# Check images\nimage_path = f\"users/{user_id}/images/{filename}\"\nimage_blob = bucket.blob(image_path)\nif image_blob.exists():\nreturn image_blob.public_url", "successors": []}, {"id": 5, "label": "# Check videos\nvideo_path = f\"users/{user_id}/videos/{filename}\"\n\nvideo_blob = bucket.blob(video_path)\nif video_blob.exists():\nreturn video_blob.public_url", "successors": []}, {"id": 7, "label": "return None", "successors": []}]}]}, {"name": "upload_media", "type": "function", "start_line": 54, "end_line": 198, "functions": [], "classes": [], "simplified_code": "async def upload_media(\n    user_id: str, file: fastapi.UploadFile, use_file_name: bool = False\n) -> str:\n\n    # Get file content for deeper validation\n    try:\n        content = await file.read(1024)  # Read first 1KB for validation\n        await file.seek(0)  # Reset file pointer\n    except Exception as e:\n        logger.error(f\"Error reading file content: {str(e)}\")\n        raise backend.server.v2.store.exceptions.FileReadError(\n            \"Failed to read file content\"\n        ) from e\n\n    # Validate file signature/magic bytes\n    if file.content_type in ALLOWED_IMAGE_TYPES:\n        # Check image file signatures\n        if content.startswith(b\"\\xFF\\xD8\\xFF\"):  # JPEG\n            if file.content_type != \"image/jpeg\":\n                raise backend.server.v2.store.exceptions.InvalidFileTypeError(\n                    \"File signature does not match content type\"\n                )\n        elif content.startswith(b\"\\x89PNG\\r\\n\\x1a\\n\"):  # PNG\n            if file.content_type != \"image/png\":\n                raise backend.server.v2.store.exceptions.InvalidFileTypeError(\n                    \"File signature does not match content type\"\n                )\n        elif content.startswith(b\"GIF87a\") or content.startswith(b\"GIF89a\"):  # GIF\n            if file.content_type != \"image/gif\":\n                raise backend.server.v2.store.exceptions.InvalidFileTypeError(\n                    \"File signature does not match content type\"\n                )\n        elif content.startswith(b\"RIFF\") and content[8:12] == b\"WEBP\":  # WebP\n            if file.content_type != \"image/webp\":\n                raise backend.server.v2.store.exceptions.InvalidFileTypeError(\n                    \"File signature does not match content type\"\n                )\n        else:\n            raise backend.server.v2.store.exceptions.InvalidFileTypeError(\n                \"Invalid image file signature\"\n            )\n\n    elif file.content_type in ALLOWED_VIDEO_TYPES:\n        # Check video file signatures\n        if content.startswith(b\"\\x00\\x00\\x00\") and (content[4:8] == b\"ftyp\"):  # MP4\n            if file.content_type != \"video/mp4\":\n                raise backend.server.v2.store.exceptions.InvalidFileTypeError(\n                    \"File signature does not match content type\"\n                )\n        elif content.startswith(b\"\\x1a\\x45\\xdf\\xa3\"):  # WebM\n            if file.content_type != \"video/webm\":\n                raise backend.server.v2.store.exceptions.InvalidFileTypeError(\n                    \"File signature does not match content type\"\n                )\n        else:\n            raise backend.server.v2.store.exceptions.InvalidFileTypeError(\n                \"Invalid video file signature\"\n            )\n\n    settings = Settings()\n\n    # Check required settings first before doing any file processing\n    if not settings.config.media_gcs_bucket_name:\n        logger.error(\"Missing GCS bucket name setting\")\n        raise backend.server.v2.store.exceptions.StorageConfigError(\n            \"Missing storage bucket configuration\"\n        )\n\n    try:\n        # Validate file type\n        content_type = file.content_type\n        if content_type is None:\n            content_type = \"image/jpeg\"\n\n        if (\n            content_type not in ALLOWED_IMAGE_TYPES\n            and content_type not in ALLOWED_VIDEO_TYPES\n        ):\n            logger.warning(f\"Invalid file type attempted: {content_type}\")\n            raise backend.server.v2.store.exceptions.InvalidFileTypeError(\n                f\"File type not supported. Must be jpeg, png, gif, webp, mp4 or webm. Content type: {content_type}\"\n            )\n\n        # Validate file size\n        file_size = 0\n        chunk_size = 8192  # 8KB chunks\n\n        try:\n            while chunk := await file.read(chunk_size):\n                file_size += len(chunk)\n                if file_size > MAX_FILE_SIZE:\n                    logger.warning(f\"File size too large: {file_size} bytes\")\n                    raise backend.server.v2.store.exceptions.FileSizeTooLargeError(\n                        \"File too large. Maximum size is 50MB\"\n                    )\n        except backend.server.v2.store.exceptions.FileSizeTooLargeError:\n            raise\n        except Exception as e:\n            logger.error(f\"Error reading file chunks: {str(e)}\")\n            raise backend.server.v2.store.exceptions.FileReadError(\n                \"Failed to read uploaded file\"\n            ) from e\n\n        # Reset file pointer\n        await file.seek(0)\n\n        # Generate unique filename\n        filename = file.filename or \"\"\n        file_ext = os.path.splitext(filename)[1].lower()\n        if use_file_name:\n            unique_filename = filename\n        else:\n            unique_filename = f\"{uuid.uuid4()}{file_ext}\"\n\n        # Construct storage path\n        media_type = \"images\" if content_type in ALLOWED_IMAGE_TYPES else \"videos\"\n        storage_path = f\"users/{user_id}/{media_type}/{unique_filename}\"\n\n        try:\n            storage_client = storage.Client()\n            bucket = storage_client.bucket(settings.config.media_gcs_bucket_name)\n            blob = bucket.blob(storage_path)\n            blob.content_type = content_type\n\n            file_bytes = await file.read()\n            blob.upload_from_string(file_bytes, content_type=content_type)\n\n            public_url = blob.public_url\n\n            logger.info(f\"Successfully uploaded file to: {storage_path}\")\n            return public_url\n\n        except Exception as e:\n            logger.error(f\"GCS storage error: {str(e)}\")\n            raise backend.server.v2.store.exceptions.StorageUploadError(\n                \"Failed to upload file to storage\"\n            ) from e\n\n    except backend.server.v2.store.exceptions.MediaUploadError:\n        raise\n    except Exception as e:\n        logger.exception(\"Unexpected error in upload_media\")\n        raise backend.server.v2.store.exceptions.MediaUploadError(\n            \"Unexpected error during media upload\"\n        ) from e", "blocks": [{"id": 1, "label": "async def upload_media(\n    user_id: str, file: fastapi.UploadFile, use_file_name: bool = False\n) -> str:", "successors": [{"id": 2, "label": "try:\n    content = await file.read(1024)  # Read first 1KB for validation\n    await file.seek(0)  # Reset file pointer", "successors": [{"id": 3, "label": "except Exception as e:\n    logger.error(f\"Error reading file content: {str(e)}\")\n    raise backend.server.v2.store.exceptions.FileReadError(\n        \"Failed to read file content\"\n    ) from e", "successors": []}, {"id": 4, "label": "if file.content_type in ALLOWED_IMAGE_TYPES:", "successors": [{"id": 5, "label": "if content.startswith(b\"\\xFF\\xD8\\xFF\"):  # JPEG\n    if file.content_type != \"image/jpeg\":\n        raise backend.server.v2.store.exceptions.InvalidFileTypeError(\n            \"File signature does not match content type\"\n        )", "successors": []}, {"id": 6, "label": "elif content.startswith(b\"\\x89PNG\\r\\n\\x1a\\n\"):  # PNG\n    if file.content_type != \"image/png\":\n        raise backend.server.v2.store.exceptions.InvalidFileTypeError(\n            \"File signature does not match content type\"\n        )", "successors": []}, {"id": 7, "label": "elif content.startswith(b\"GIF87a\") or content.startswith(b\"GIF89a\"):  # GIF\n    if file.content_type != \"image/gif\":\n        raise backend.server.v2.store.exceptions.InvalidFileTypeError(\n            \"File signature does not match content type\"\n        )", "successors": []}, {"id": 8, "label": "elif content.startswith(b\"RIFF\") and content[8:12] == b\"WEBP\":  # WebP\n    if file.content_type != \"image/webp\":\n        raise backend.server.v2.store.exceptions.InvalidFileTypeError(\n            \"File signature does not match content type\"\n        )", "successors": []}, {"id": 9, "label": "else:\n    raise backend.server.v2.store.exceptions.InvalidFileTypeError(\n        \"Invalid image file signature\"\n    )", "successors": []}]}, {"id": 10, "label": "elif file.content_type in ALLOWED_VIDEO_TYPES:", "successors": [{"id": 11, "label": "if content.startswith(b\"\\x00\\x00\\x00\") and (content[4:8] == b\"ftyp\"):  # MP4\n    if file.content_type != \"video/mp4\":\n        raise backend.server.v2.store.exceptions.InvalidFileTypeError(\n            \"File signature does not match content type\"\n        )", "successors": []}, {"id": 12, "label": "elif content.startswith(b\"\\x1a\\x45\\xdf\\xa3\"):  # WebM\n    if file.content_type != \"video/webm\":\n        raise backend.server.v2.store.exceptions.InvalidFileTypeError(\n            \"File signature does not match content type\"\n        )", "successors": []}, {"id": 13, "label": "else:\n    raise backend.server.v2.store.exceptions.InvalidFileTypeError(\n        \"Invalid video file signature\"\n    )", "successors": []}]}, {"id": 14, "label": "settings = Settings()", "successors": []}, {"id": 15, "label": "if not settings.config.media_gcs_bucket_name:\n    logger.error(\"Missing GCS bucket name setting\")\n    raise backend.server.v2.store.exceptions.StorageConfigError(\n        \"Missing storage bucket configuration\"\n    )", "successors": []}, {"id": 16, "label": "try:\n    content_type = file.content_type\n    if content_type is None:\n        content_type = \"image/jpeg\"\n\n    if (\n        content_type not in ALLOWED_IMAGE_TYPES\n        and content_type not in ALLOWED_VIDEO_TYPES\n    ):\n        logger.warning(f\"Invalid file type attempted: {content_type}\")\n        raise backend.server.v2.store.exceptions.InvalidFileTypeError(\n            f\"File type not supported. Must be jpeg, png, gif, webp, mp4 or webm. Content type: {content_type}\"\n        )", "successors": []}, {"id": 17, "label": "file_size = 0\nchunk_size = 8192  # 8KB chunks\n\ntry:\n    while chunk := await file.read(chunk_size):\n        file_size += len(chunk)\n        if file_size > MAX_FILE_SIZE:\n            logger.warning(f\"File size too large: {file_size} bytes\")\n            raise backend.server.v2.store.exceptions.FileSizeTooLargeError(\n                \"File too large. Maximum size is 50MB\"\n            )", "successors": [{"id": 18, "label": "except backend.server.v2.store.exceptions.FileSizeTooLargeError:\n    raise", "successors": []}, {"id": 19, "label": "except Exception as e:\n    logger.error(f\"Error reading file chunks: {str(e)}\")\n    raise backend.server.v2.store.exceptions.FileReadError(\n        \"Failed to read uploaded file\"\n    ) from e", "successors": []}]}, {"id": 20, "label": "await file.seek(0)", "successors": []}, {"id": 21, "label": "filename = file.filename or \"\"\nfile_ext = os.path.splitext(filename)[1].lower()\nif use_file_name:\n    unique_filename = filename\nelse:\n    unique_filename = f\"{uuid.uuid4()}{file_ext}\"", "successors": []}, {"id": 22, "label": "media_type = \"images\" if content_type in ALLOWED_IMAGE_TYPES else \"videos\"\nstorage_path = f\"users/{user_id}/{media_type}/{unique_filename}\"", "successors": []}, {"id": 23, "label": "try:\n    storage_client = storage.Client()\n    bucket = storage_client.bucket(settings.config.media_gcs_bucket_name)\n    blob = bucket.blob(storage_path)\n    blob.content_type = content_type\n\n    file_bytes = await file.read()\n    blob.upload_from_string(file_bytes, content_type=content_type)\n\n    public_url = blob.public_url\n\n    logger.info(f\"Successfully uploaded file to: {storage_path}\")\n    return public_url", "successors": []}, {"id": 24, "label": "except Exception as e:\n    logger.error(f\"GCS storage error: {str(e)}\")\n    raise backend.server.v2.store.exceptions.StorageUploadError(\n        \"Failed to upload file to storage\"\n    ) from e", "successors": []}]}, {"id": 25, "label": "except backend.server.v2.store.exceptions.MediaUploadError:\n    raise", "successors": []}, {"id": 26, "label": "except Exception as e:\n    logger.exception(\"Unexpected error in upload_media\")\n    raise backend.server.v2.store.exceptions.MediaUploadError(\n        \"Unexpected error during media upload\"\n    ) from e", "successors": []}]}]}], "classes": [], "simplified_code": "import logging\nimport os\nimport uuid\n\nimport fastapi\nfrom google.cloud import storage\n\nimport backend.server.v2.store.exceptions\nfrom backend.util.settings import Settings\n\nlogger = logging.getLogger(__name__)\n\nALLOWED_IMAGE_TYPES = {\"image/jpeg\", \"image/png\", \"image/gif\", \"image/webp\"}\nALLOWED_VIDEO_TYPES = {\"video/mp4\", \"video/webm\"}\nMAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB\n\n\n        return None\n\n\n        ) from e", "blocks": [{"id": 1, "label": "import logging\nimport os\nimport uuid\n\nimport fastapi\nfrom google.cloud import storage\n\nimport backend.server.v2.store.exceptions\nfrom backend.util.settings import Settings\n\nlogger = logging.getLogger(__name__)\n\nALLOWED_IMAGE_TYPES = {\"image/jpeg\", \"image/png\", \"image/gif\", \"image/webp\"}\nALLOWED_VIDEO_TYPES = {\"video/mp4\", \"video/webm\"}\nMAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB", "successors": []}]}
{"file_name": "138.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 172, "functions": [], "classes": [{"name": "CreateTalkingAvatarVideoBlock", "type": "class", "start_line": 31, "end_line": 172, "functions": [{"name": "__init__", "type": "function", "start_line": 77, "end_line": 114, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"98c6f503-8c47-4b1c-a96d-351fc7c87dab\",\n            description=\"This block integrates with D-ID to create video clips and retrieve their URLs.\",\n            categories={BlockCategory.AI},\n            input_schema=CreateTalkingAvatarVideoBlock.Input,\n            output_schema=CreateTalkingAvatarVideoBlock.Output,\n            test_input={\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n                \"script_input\": \"Welcome to AutoGPT\",\n                \"voice_id\": \"en-US-JennyNeural\",\n                \"presenter_id\": \"amy-Aq6OmGZnMt\",\n                \"driver_id\": \"Vcq0R4a8F0\",\n                \"result_format\": \"mp4\",\n                \"crop_type\": \"wide\",\n                \"subtitles\": False,\n                \"ssml\": False,\n                \"max_polling_attempts\": 5,\n                \"polling_interval\": 5,\n            },\n            test_output=[\n                (\n                    \"video_url\",\n                    \"https://d-id.com/api/clips/abcd1234-5678-efgh-ijkl-mnopqrstuvwx/video\",\n                ),\n            ],\n            test_mock={\n                \"create_clip\": lambda *args, **kwargs: {\n                    \"id\": \"abcd1234-5678-efgh-ijkl-mnopqrstuvwx\",\n                    \"status\": \"created\",\n                },\n                \"get_clip_status\": lambda *args, **kwargs: {\n                    \"status\": \"done\",\n                    \"result_url\": \"https://d-id.com/api/clips/abcd1234-5678-efgh-ijkl-mnopqrstuvwx/video\",\n                },\n            },\n            test_credentials=TEST_CREDENTIALS,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"98c6f503-8c47-4b1c-a96d-351fc7c87dab\",\n    description=\"This block integrates with D-ID to create video clips and retrieve their URLs.\",\n    categories={BlockCategory.AI},\n    input_schema=CreateTalkingAvatarVideoBlock.Input,\n    output_schema=CreateTalkingAvatarVideoBlock.Output,\n    test_input={\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n        \"script_input\": \"Welcome to AutoGPT\",\n        \"voice_id\": \"en-US-JennyNeural\",\n        \"presenter_id\": \"amy-Aq6OmGZnMt\",\n        \"driver_id\": \"Vcq0R4a8F0\",\n        \"result_format\": \"mp4\",\n        \"crop_type\": \"wide\",\n        \"subtitles\": False,\n        \"ssml\": False,\n        \"max_polling_attempts\": 5,\n        \"polling_interval\": 5,\n    },\n    test_output=[\n        (\n            \"video_url\",\n            \"https://d-id.com/api/clips/abcd1234-5678-efgh-ijkl-mnopqrstuvwx/video\",\n        ),\n    ],\n    test_mock={\n        \"create_clip\": lambda *args, **kwargs: {\n            \"id\": \"abcd1234-5678-efgh-ijkl-mnopqrstuvwx\",\n            \"status\": \"created\",\n        },\n        \"get_clip_status\": lambda *args, **kwargs: {\n            \"status\": \"done\",\n            \"result_url\": \"https://d-id.com/api/clips/abcd1234-5678-efgh-ijkl-mnopqrstuvwx/video\",\n        },\n    },\n    test_credentials=TEST_CREDENTIALS,\n)", "successors": []}]}, {"name": "create_clip", "type": "function", "start_line": 116, "end_line": 124, "functions": [], "classes": [], "simplified_code": "    def create_clip(self, api_key: SecretStr, payload: dict) -> dict:\n        url = \"https://api.d-id.com/clips\"\n        headers = {\n            \"accept\": \"application/json\",\n            \"content-type\": \"application/json\",\n            \"authorization\": f\"Basic {api_key.get_secret_value()}\",\n        }\n        response = requests.post(url, json=payload, headers=headers)\n        return response.json()", "blocks": [{"id": 1, "label": "def create_clip(self, api_key: SecretStr, payload: dict) -> dict:\nurl = \"https://api.d-id.com/clips\"\nheaders = {\n    \"accept\": \"application/json\",\n    \"content-type\": \"application/json\",\n    \"authorization\": f\"Basic {api_key.get_secret_value()}\",\n}\nresponse = requests.post(url, json=payload, headers=headers)", "successors": [{"id": 3, "label": "return response.json()", "successors": []}]}]}, {"name": "get_clip_status", "type": "function", "start_line": 126, "end_line": 133, "functions": [], "classes": [], "simplified_code": "    def get_clip_status(self, api_key: SecretStr, clip_id: str) -> dict:\n        url = f\"https://api.d-id.com/clips/{clip_id}\"\n        headers = {\n            \"accept\": \"application/json\",\n            \"authorization\": f\"Basic {api_key.get_secret_value()}\",\n        }\n        response = requests.get(url, headers=headers)\n        return response.json()", "blocks": [{"id": 1, "label": "def get_clip_status(self, api_key: SecretStr, clip_id: str) -> dict:\n    url = f\"https://api.d-id.com/clips/{clip_id}\"", "successors": [{"id": 3, "label": "    headers = {\"accept\": \"application/json\", \"authorization\": f\"Basic {api_key.get_secret_value()}\"}\n    response = requests.get(url, headers=headers)", "successors": [{"id": 5, "label": "    return response.json()", "successors": []}]}]}]}, {"name": "run", "type": "function", "start_line": 135, "end_line": 172, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        # Create the clip\n        payload = {\n            \"script\": {\n                \"type\": \"text\",\n                \"subtitles\": str(input_data.subtitles).lower(),\n                \"provider\": {\n                    \"type\": input_data.provider,\n                    \"voice_id\": input_data.voice_id,\n                },\n                \"ssml\": str(input_data.ssml).lower(),\n                \"input\": input_data.script_input,\n            },\n            \"config\": {\"result_format\": input_data.result_format},\n            \"presenter_config\": {\"crop\": {\"type\": input_data.crop_type}},\n            \"presenter_id\": input_data.presenter_id,\n            \"driver_id\": input_data.driver_id,\n        }\n\n        response = self.create_clip(credentials.api_key, payload)\n        clip_id = response[\"id\"]\n\n        # Poll for clip status\n        for _ in range(input_data.max_polling_attempts):\n            status_response = self.get_clip_status(credentials.api_key, clip_id)\n            if status_response[\"status\"] == \"done\":\n                yield \"video_url\", status_response[\"result_url\"]\n                return\n            elif status_response[\"status\"] == \"error\":\n                raise RuntimeError(\n                    f\"Clip creation failed: {status_response.get('error', 'Unknown error')}\"\n                )\n\n            time.sleep(input_data.polling_interval)\n\n        raise TimeoutError(\"Clip creation timed out\")", "blocks": [{"id": 1, "label": "def run( self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs ) -> BlockOutput:\npayload = { \"script\": { \"type\": \"text\", \"subtitles\": str(input_data.subtitles).lower(), \"provider\": { \"type\": input_data.provider, \"voice_id\": input_data.voice_id, }, \"ssml\": str(input_data.ssml).lower(), \"input\": input_data.script_input, }, \"config\": {\"result_format\": input_data.result_format}, \"presenter_config\": {\"crop\": {\"type\": input_data.crop_type}}, \"presenter_id\": input_data.presenter_id, \"driver_id\": input_data.driver_id, }", "successors": [{"id": 3, "label": "response = self.create_clip(credentials.api_key, payload) clip_id = response[\"id\"]", "successors": [{"id": 4, "label": "for _ in range(input_data.max_polling_attempts):", "successors": [{"id": 5, "label": "status_response = self.get_clip_status(credentials.api_key, clip_id) if status_response[\"status\"] == \"done\":\nyield \"video_url\", status_response[\"result_url\"] return", "successors": []}, {"id": 7, "label": "elif status_response[\"status\"] == \"error\":\nraise RuntimeError( f\"Clip creation failed: {status_response.get('error', 'Unknown error')}\" )", "successors": []}, {"id": 9, "label": "time.sleep(input_data.polling_interval)\nraise TimeoutError(\"Clip creation timed out\")", "successors": []}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 32, "end_line": 71, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: CredentialsMetaInput[\n            Literal[ProviderName.D_ID], Literal[\"api_key\"]\n        ] = CredentialsField(\n            description=\"The D-ID integration can be used with \"\n            \"any API key with sufficient permissions for the blocks it is used on.\",\n        )\n        script_input: str = SchemaField(\n            description=\"The text input for the script\",\n            placeholder=\"Welcome to AutoGPT\",\n        )\n        provider: Literal[\"microsoft\", \"elevenlabs\", \"amazon\"] = SchemaField(\n            description=\"The voice provider to use\", default=\"microsoft\"\n        )\n        voice_id: str = SchemaField(\n            description=\"The voice ID to use, get list of voices [here](https://docs.agpt.co/server/d_id)\",\n            default=\"en-US-JennyNeural\",\n        )\n        presenter_id: str = SchemaField(\n            description=\"The presenter ID to use\", default=\"amy-Aq6OmGZnMt\"\n        )\n        driver_id: str = SchemaField(\n            description=\"The driver ID to use\", default=\"Vcq0R4a8F0\"\n        )\n        result_format: Literal[\"mp4\", \"gif\", \"wav\"] = SchemaField(\n            description=\"The desired result format\", default=\"mp4\"\n        )\n        crop_type: Literal[\"wide\", \"square\", \"vertical\"] = SchemaField(\n            description=\"The crop type for the presenter\", default=\"wide\"\n        )\n        subtitles: bool = SchemaField(\n            description=\"Whether to include subtitles\", default=False\n        )\n        ssml: bool = SchemaField(description=\"Whether the input is SSML\", default=False)\n        max_polling_attempts: int = SchemaField(\n            description=\"Maximum number of polling attempts\", default=30, ge=5\n        )\n        polling_interval: int = SchemaField(\n            description=\"Interval between polling attempts in seconds\", default=10, ge=5\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\ncredentials: CredentialsMetaInput[Literal[ProviderName.D_ID], Literal[\"api_key\"]] = CredentialsField(description=\"The D-ID integration can be used with any API key with sufficient permissions for the blocks it is used on.\")", "successors": [{"id": 3, "label": "script_input: str = SchemaField(description=\"The text input for the script\", placeholder=\"Welcome to AutoGPT\")\nprovider: Literal[\"microsoft\", \"elevenlabs\", \"amazon\"] = SchemaField(description=\"The voice provider to use\", default=\"microsoft\")", "successors": [{"id": 5, "label": "voice_id: str = SchemaField(description=\"The voice ID to use, get list of voices [here](https://docs.agpt.co/server/d_id)\", default=\"en-US-JennyNeural\")\npresenter_id: str = SchemaField(description=\"The presenter ID to use\", default=\"amy-Aq6OmGZnMt\")", "successors": [{"id": 7, "label": "driver_id: str = SchemaField(description=\"The driver ID to use\", default=\"Vcq0R4a8F0\")\nresult_format: Literal[\"mp4\", \"gif\", \"wav\"] = SchemaField(description=\"The desired result format\", default=\"mp4\")", "successors": [{"id": 9, "label": "crop_type: Literal[\"wide\", \"square\", \"vertical\"] = SchemaField(description=\"The crop type for the presenter\", default=\"wide\")\nsubtitles: bool = SchemaField(description=\"Whether to include subtitles\", default=False)", "successors": [{"id": 11, "label": "ssml: bool = SchemaField(description=\"Whether the input is SSML\", default=False)\nmax_polling_attempts: int = SchemaField(description=\"Maximum number of polling attempts\", default=30, ge=5)", "successors": [{"id": 13, "label": "polling_interval: int = SchemaField(description=\"Interval between polling attempts in seconds\", default=10, ge=5)", "successors": []}]}]}]}]}]}]}]}, {"name": "Output", "type": "class", "start_line": 73, "end_line": 75, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        video_url: str = SchemaField(description=\"The URL of the created video\")\n        error: str = SchemaField(description=\"Error message if the request failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\nvideo_url: str = SchemaField(description=\"The URL of the created video\")\nerror: str = SchemaField(description=\"Error message if the request failed\")", "successors": []}]}], "simplified_code": "class CreateTalkingAvatarVideoBlock(Block):\n        )\n\n        error: str = SchemaField(description=\"Error message if the request failed\")\n\n        )\n\n        return response.json()\n\n        return response.json()\n\n        raise TimeoutError(\"Clip creation timed out\")", "blocks": [{"id": 1, "label": "class CreateTalkingAvatarVideoBlock(Block):\nerror: str = SchemaField(description=\"Error message if the request failed\")", "successors": [{"id": 3, "label": "return response.json()\nreturn response.json()", "successors": [{"id": 5, "label": "raise TimeoutError(\"Clip creation timed out\")", "successors": []}]}]}]}], "simplified_code": "import time\nfrom typing import Literal\n\nfrom pydantic import SecretStr\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\nfrom backend.util.request import requests\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"d_id\",\n    api_key=SecretStr(\"mock-d-id-api-key\"),\n    title=\"Mock D-ID API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.type,\n}\n\n\n        raise TimeoutError(\"Clip creation timed out\")", "blocks": [{"id": 1, "label": "import time\nfrom typing import Literal\n\nfrom pydantic import SecretStr\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\nfrom backend.util.request import requests\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"d_id\",\n    api_key=SecretStr(\"mock-d-id-api-key\"),\n    title=\"Mock D-ID API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.type,\n}\n\n\nraise TimeoutError(\"Clip creation timed out\")", "successors": []}]}
{"file_name": "139.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 125, "functions": [], "classes": [{"name": "Slant3DTriggerBase", "type": "class", "start_line": 22, "end_line": 42, "functions": [{"name": "run", "type": "function", "start_line": 39, "end_line": 41, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        yield \"payload\", input_data.payload\n        yield \"order_id\", input_data.payload[\"orderId\"]", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\nyield \"payload\", input_data.payload\nyield \"order_id\", input_data.payload[\"orderId\"]", "successors": []}]}], "classes": [{"name": "Input", "type": "class", "start_line": 25, "end_line": 28, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: Slant3DCredentialsInput = Slant3DCredentialsField()\n        # Webhook URL is handled by the webhook system\n        payload: dict = SchemaField(hidden=True, default={})", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    credentials: Slant3DCredentialsInput = Slant3DCredentialsField()", "successors": []}, {"id": 3, "label": "    payload: dict = SchemaField(hidden=True, default={})", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 30, "end_line": 37, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        payload: dict = SchemaField(\n            description=\"The complete webhook payload received from Slant3D\"\n        )\n        order_id: str = SchemaField(description=\"The ID of the affected order\")\n        error: str = SchemaField(\n            description=\"Error message if payload processing failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "payload: dict = SchemaField(description=\"The complete webhook payload received from Slant3D\")", "successors": []}, {"id": 3, "label": "order_id: str = SchemaField(description=\"The ID of the affected order\")", "successors": []}, {"id": 4, "label": "error: str = SchemaField(description=\"Error message if payload processing failed\")", "successors": []}]}]}], "simplified_code": "class Slant3DTriggerBase:\n    \"\"\"Base class for Slant3D webhook triggers\"\"\"\n\n        payload: dict = SchemaField(hidden=True, default={})\n\n        )\n\n        yield \"order_id\", input_data.payload[\"orderId\"]\n", "blocks": [{"id": 1, "label": "class Slant3DTriggerBase:\n    \"\"\"Base class for Slant3D webhook triggers\"\"\"", "successors": [{"id": 3, "label": "    payload: dict = SchemaField(hidden=True, default={})", "successors": []}]}]}, {"name": "Slant3DOrderWebhookBlock", "type": "class", "start_line": 44, "end_line": 125, "functions": [{"name": "__init__", "type": "function", "start_line": 69, "end_line": 117, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"8a74c2ad-0104-4640-962f-26c6b69e58cd\",\n            description=(\n                \"This block triggers on Slant3D order status updates and outputs \"\n                \"the event details, including tracking information when orders are shipped.\"\n            ),\n            # All webhooks are currently subscribed to for all orders. This works for self hosted, but not for cloud hosted prod\n            disabled=(\n                settings.Settings().config.behave_as == BehaveAs.CLOUD\n                and settings.Settings().config.app_env != AppEnvironment.LOCAL\n            ),\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=self.Input,\n            output_schema=self.Output,\n            webhook_config=BlockWebhookConfig(\n                provider=\"slant3d\",\n                webhook_type=\"orders\",  # Only one type for now\n                resource_format=\"\",  # No resource format needed\n                event_filter_input=\"events\",\n                event_format=\"order.{event}\",\n            ),\n            test_input={\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n                \"events\": {\"shipped\": True},\n                \"payload\": {\n                    \"orderId\": \"1234567890\",\n                    \"status\": \"SHIPPED\",\n                    \"trackingNumber\": \"ABCDEF123456\",\n                    \"carrierCode\": \"usps\",\n                },\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\n                    \"payload\",\n                    {\n                        \"orderId\": \"1234567890\",\n                        \"status\": \"SHIPPED\",\n                        \"trackingNumber\": \"ABCDEF123456\",\n                        \"carrierCode\": \"usps\",\n                    },\n                ),\n                (\"order_id\", \"1234567890\"),\n                (\"status\", \"SHIPPED\"),\n                (\"tracking_number\", \"ABCDEF123456\"),\n                (\"carrier_code\", \"usps\"),\n            ],\n        )", "blocks": [{"id": 1, "label": "def __init__(self):", "successors": [{"id": 2, "label": "super().__init__(", "successors": []}, {"id": 3, "label": "    id=\"8a74c2ad-0104-4640-962f-26c6b69e58cd\",", "successors": []}, {"id": 4, "label": "    description=(", "successors": []}, {"id": 5, "label": "        \"This block triggers on Slant3D order status updates and outputs \"", "successors": []}, {"id": 6, "label": "        \"the event details, including tracking information when orders are shipped.\"", "successors": []}, {"id": 7, "label": "    ),", "successors": []}, {"id": 8, "label": "# All webhooks are currently subscribed to for all orders. This works for self hosted, but not for cloud hosted prod", "successors": []}, {"id": 9, "label": "disabled=(", "successors": []}, {"id": 10, "label": "    settings.Settings().config.behave_as == BehaveAs.CLOUD", "successors": []}, {"id": 11, "label": "    and settings.Settings().config.app_env != AppEnvironment.LOCAL", "successors": []}, {"id": 12, "label": "),", "successors": []}, {"id": 13, "label": "categories={BlockCategory.DEVELOPER_TOOLS},", "successors": []}, {"id": 14, "label": "input_schema=self.Input,", "successors": []}, {"id": 15, "label": "output_schema=self.Output,", "successors": []}, {"id": 16, "label": "webhook_config=BlockWebhookConfig(", "successors": []}, {"id": 17, "label": "    provider=\"slant3d\",", "successors": []}, {"id": 18, "label": "    webhook_type=\"orders\",  # Only one type for now", "successors": []}, {"id": 19, "label": "    resource_format=\"\",  # No resource format needed", "successors": []}, {"id": 20, "label": "    event_filter_input=\"events\",", "successors": []}, {"id": 21, "label": "    event_format=\"order.{event}\",", "successors": []}, {"id": 22, "label": "),", "successors": []}, {"id": 23, "label": "test_input={", "successors": []}, {"id": 24, "label": "    \"credentials\": TEST_CREDENTIALS_INPUT,", "successors": []}, {"id": 25, "label": "    \"events\": {\"shipped\": True},", "successors": []}, {"id": 26, "label": "    \"payload\": {", "successors": []}, {"id": 27, "label": "        \"orderId\": \"1234567890\",", "successors": []}, {"id": 28, "label": "        \"status\": \"SHIPPED\",", "successors": []}, {"id": 29, "label": "        \"trackingNumber\": \"ABCDEF123456\",", "successors": []}, {"id": 30, "label": "        \"carrierCode\": \"usps\",", "successors": []}, {"id": 31, "label": "    },", "successors": []}, {"id": 32, "label": "},", "successors": []}, {"id": 33, "label": "test_credentials=TEST_CREDENTIALS,", "successors": []}, {"id": 34, "label": "test_output=[", "successors": []}, {"id": 35, "label": "    (", "successors": []}, {"id": 36, "label": "        \"payload\",", "successors": []}, {"id": 37, "label": "        {", "successors": []}, {"id": 38, "label": "            \"orderId\": \"1234567890\",", "successors": []}, {"id": 39, "label": "            \"status\": \"SHIPPED\",", "successors": []}, {"id": 40, "label": "            \"trackingNumber\": \"ABCDEF123456\",", "successors": []}, {"id": 41, "label": "            \"carrierCode\": \"usps\",", "successors": []}, {"id": 42, "label": "        },", "successors": []}, {"id": 43, "label": "    ),", "successors": []}, {"id": 44, "label": "    (\"order_id\", \"1234567890\"),", "successors": []}, {"id": 45, "label": "    (\"status\", \"SHIPPED\"),", "successors": []}, {"id": 46, "label": "    (\"tracking_number\", \"ABCDEF123456\"),", "successors": []}, {"id": 47, "label": "    (\"carrier_code\", \"usps\"),", "successors": []}, {"id": 48, "label": "],", "successors": []}, {"id": 49, "label": ")", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 119, "end_line": 125, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:  # type: ignore\n        yield from super().run(input_data, **kwargs)\n\n        # Extract and normalize values from the payload\n        yield \"status\", input_data.payload[\"status\"]\n        yield \"tracking_number\", input_data.payload[\"trackingNumber\"]\n        yield \"carrier_code\", input_data.payload[\"carrierCode\"]", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:  # type: ignore\nyield from super().run(input_data, **kwargs)", "successors": [{"id": 3, "label": "yield \"status\", input_data.payload[\"status\"]\nyield \"tracking_number\", input_data.payload[\"trackingNumber\"]", "successors": [{"id": 5, "label": "yield \"carrier_code\", input_data.payload[\"carrierCode\"]", "successors": []}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 47, "end_line": 60, "functions": [], "classes": [{"name": "EventsFilter", "type": "class", "start_line": 48, "end_line": 54, "functions": [], "classes": [], "simplified_code": "        class EventsFilter(BaseModel):\n            \"\"\"\n            Currently Slant3D only supports 'SHIPPED' status updates\n            Could be expanded in the future with more status types\n            \"\"\"\n\n            shipped: bool = True", "blocks": [{"id": 1, "label": "class EventsFilter(BaseModel):\n\"\"\"\nCurrently Slant3D only supports 'SHIPPED' status updates\nCould be expanded in the future with more status types\n\"\"\"", "successors": [{"id": 3, "label": "shipped: bool = True", "successors": []}]}]}], "simplified_code": "    class Input(Slant3DTriggerBase.Input):\n            shipped: bool = True\n\n        events: EventsFilter = SchemaField(\n            title=\"Events\",\n            description=\"Order status events to subscribe to\",\n            default=EventsFilter(shipped=True),\n        )", "blocks": [{"id": 1, "label": "class Input(Slant3DTriggerBase.Input):\nshipped: bool = True", "successors": [{"id": 3, "label": "events: EventsFilter = SchemaField(title=\"Events\", description=\"Order status events to subscribe to\", default=EventsFilter(shipped=True))", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 62, "end_line": 67, "functions": [], "classes": [], "simplified_code": "    class Output(Slant3DTriggerBase.Output):\n        status: str = SchemaField(description=\"The new status of the order\")\n        tracking_number: str = SchemaField(\n            description=\"The tracking number for the shipment\"\n        )\n        carrier_code: str = SchemaField(description=\"The carrier code (e.g., 'usps')\")", "blocks": [{"id": 1, "label": "class Output(Slant3DTriggerBase.Output):", "successors": [{"id": 2, "label": "    status: str = SchemaField(description=\"The new status of the order\")", "successors": []}, {"id": 3, "label": "    tracking_number: str = SchemaField(description=\"The tracking number for the shipment\")", "successors": []}, {"id": 4, "label": "    carrier_code: str = SchemaField(description=\"The carrier code (e.g., 'usps')\")", "successors": []}]}]}], "simplified_code": "class Slant3DOrderWebhookBlock(Slant3DTriggerBase, Block):\n    \"\"\"Block for handling Slant3D order webhooks\"\"\"\n\n        )\n\n        carrier_code: str = SchemaField(description=\"The carrier code (e.g., 'usps')\")\n\n        )\n\n        yield \"carrier_code\", input_data.payload[\"carrierCode\"]", "blocks": [{"id": 1, "label": "class Slant3DOrderWebhookBlock(Slant3DTriggerBase, Block):\n\"\"\"Block for handling Slant3D order webhooks\"\"\"", "successors": [{"id": 3, "label": "carrier_code: str = SchemaField(description=\"The carrier code (e.g., 'usps')\")\nyield \"carrier_code\", input_data.payload[\"carrierCode\"]", "successors": []}]}]}], "simplified_code": "from pydantic import BaseModel\n\nfrom backend.data.block import (\n    Block,\n    BlockCategory,\n    BlockOutput,\n    BlockSchema,\n    BlockWebhookConfig,\n)\nfrom backend.data.model import SchemaField\nfrom backend.util import settings\nfrom backend.util.settings import AppEnvironment, BehaveAs\n\nfrom ._api import (\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    Slant3DCredentialsField,\n    Slant3DCredentialsInput,\n)\n\n\n\n\n        yield \"carrier_code\", input_data.payload[\"carrierCode\"]", "blocks": [{"id": 1, "label": "from pydantic import BaseModel\n\nfrom backend.data.block import (\n    Block,\n    BlockCategory,\n    BlockOutput,\n    BlockSchema,\n    BlockWebhookConfig,\n)\nfrom backend.data.model import SchemaField\nfrom backend.util import settings\nfrom backend.util.settings import AppEnvironment, BehaveAs\n\nfrom ._api import (\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    Slant3DCredentialsField,\n    Slant3DCredentialsInput,\n)\n\n\n\n\n        yield \"carrier_code\", input_data.payload[\"carrierCode\"]", "successors": []}]}
{"file_name": "140.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 193, "functions": [{"name": "__convert_list", "type": "function", "start_line": 9, "end_line": 24, "functions": [], "classes": [], "simplified_code": "def __convert_list(value: Any) -> list:\n    if isinstance(value, (list, tuple, set)):\n        return list(value)\n    elif isinstance(value, dict):\n        return list(value.items())\n    elif isinstance(value, str):\n        value = value.strip()\n        if value.startswith(\"[\") and value.endswith(\"]\"):\n            try:\n                return json.loads(value)\n            except json.JSONDecodeError:\n                return [value]\n        else:\n            return [value]\n    else:\n        return [value]", "blocks": [{"id": 1, "label": "def __convert_list(value: Any) -> list:", "successors": [{"id": 2, "label": "if isinstance(value, (list, tuple, set)):\nreturn list(value)", "successors": []}, {"id": 4, "label": "elif isinstance(value, dict):\nreturn list(value.items())", "successors": []}, {"id": 6, "label": "elif isinstance(value, str):\nvalue = value.strip()", "successors": [{"id": 8, "label": "if value.startswith(\"[\") and value.endswith(\"]\"):", "successors": [{"id": 9, "label": "try:\nreturn json.loads(value)", "successors": []}, {"id": 11, "label": "except json.JSONDecodeError:\nreturn [value]", "successors": []}]}, {"id": 13, "label": "else:\nreturn [value]", "successors": []}]}, {"id": 15, "label": "else:\nreturn [value]", "successors": []}]}]}, {"name": "__convert_dict", "type": "function", "start_line": 27, "end_line": 44, "functions": [], "classes": [], "simplified_code": "def __convert_dict(value: Any) -> dict:\n    if isinstance(value, str):\n        try:\n            result = json.loads(value)\n            if isinstance(result, dict):\n                return result\n            else:\n                return {\"value\": result}\n        except json.JSONDecodeError:\n            return {\"value\": value}  # Fallback conversion\n    elif isinstance(value, list):\n        return {i: value[i] for i in range(len(value))}\n    elif isinstance(value, tuple):\n        return {i: value[i] for i in range(len(value))}\n    elif isinstance(value, dict):\n        return value\n    else:\n        return {\"value\": value}", "blocks": [{"id": 1, "label": "if isinstance(value, str):\ntry:", "successors": [{"id": 3, "label": "result = json.loads(value)\nif isinstance(result, dict):", "successors": [{"id": 5, "label": "return result", "successors": []}, {"id": 6, "label": "return {\"value\": result}", "successors": []}]}, {"id": 7, "label": "except json.JSONDecodeError:\nreturn {\"value\": value}  # Fallback conversion", "successors": []}]}]}, {"name": "__convert_tuple", "type": "function", "start_line": 47, "end_line": 57, "functions": [], "classes": [], "simplified_code": "def __convert_tuple(value: Any) -> tuple:\n    if isinstance(value, (str, list, set)):\n        return tuple(value)\n    elif isinstance(value, dict):\n        return tuple(value.items())\n    elif isinstance(value, (int, float, bool)):\n        return (value,)\n    elif isinstance(value, tuple):\n        return value\n    else:\n        return (value,)", "blocks": [{"id": 1, "label": "def __convert_tuple(value: Any) -> tuple:\nif isinstance(value, (str, list, set)):", "successors": [{"id": 3, "label": "return tuple(value)", "successors": []}, {"id": 4, "label": "elif isinstance(value, dict):", "successors": [{"id": 5, "label": "return tuple(value.items())", "successors": []}, {"id": 6, "label": "elif isinstance(value, (int, float, bool)):", "successors": [{"id": 7, "label": "return (value,)", "successors": []}, {"id": 8, "label": "elif isinstance(value, tuple):", "successors": [{"id": 9, "label": "return value", "successors": []}, {"id": 10, "label": "else:\nreturn (value,)", "successors": []}]}]}]}]}]}, {"name": "__convert_set", "type": "function", "start_line": 60, "end_line": 68, "functions": [], "classes": [], "simplified_code": "def __convert_set(value: Any) -> set:\n    if isinstance(value, (str, list, tuple)):\n        return set(value)\n    elif isinstance(value, dict):\n        return set(value.items())\n    elif isinstance(value, set):\n        return value\n    else:\n        return {value}", "blocks": [{"id": 1, "label": "if isinstance(value, (str, list, tuple)):", "successors": [{"id": 2, "label": "    return set(value)", "successors": []}, {"id": 3, "label": "elif isinstance(value, dict):", "successors": [{"id": 4, "label": "    return set(value.items())", "successors": []}, {"id": 5, "label": "elif isinstance(value, set):", "successors": [{"id": 6, "label": "    return value", "successors": []}, {"id": 7, "label": "else:\n    return {value}", "successors": []}]}]}]}]}, {"name": "__convert_str", "type": "function", "start_line": 71, "end_line": 75, "functions": [], "classes": [], "simplified_code": "def __convert_str(value: Any) -> str:\n    if isinstance(value, str):\n        return value\n    else:\n        return json.dumps(value)", "blocks": [{"id": 1, "label": "def __convert_str(value: Any) -> str:\nif isinstance(value, str):", "successors": [{"id": 3, "label": "return value", "successors": []}, {"id": 4, "label": "else:\nreturn json.dumps(value)", "successors": []}]}]}, {"name": "__convert_num", "type": "function", "start_line": 81, "end_line": 90, "functions": [], "classes": [], "simplified_code": "def __convert_num(value: Any, num_type: Type[NUM]) -> NUM:\n    if isinstance(value, (list, dict, tuple, set)):\n        return num_type(len(value))\n    elif isinstance(value, num_type):\n        return value\n    else:\n        try:\n            return num_type(float(value))\n        except (ValueError, TypeError):\n            return num_type(0)  # Fallback conversion", "blocks": [{"id": 1, "label": "def __convert_num(value: Any, num_type: Type[NUM]) -> NUM:\nif isinstance(value, (list, dict, tuple, set)):", "successors": [{"id": 3, "label": "return num_type(len(value))", "successors": []}, {"id": 4, "label": "elif isinstance(value, num_type):", "successors": [{"id": 5, "label": "return value", "successors": []}, {"id": 6, "label": "else:\ntry:", "successors": [{"id": 8, "label": "return num_type(float(value))", "successors": []}, {"id": 9, "label": "except (ValueError, TypeError):\nreturn num_type(0)  # Fallback conversion", "successors": []}]}]}]}]}, {"name": "__convert_bool", "type": "function", "start_line": 93, "end_line": 102, "functions": [], "classes": [], "simplified_code": "def __convert_bool(value: Any) -> bool:\n    if isinstance(value, bool):\n        return value\n    elif isinstance(value, str):\n        if value.lower() in [\"true\", \"1\"]:\n            return True\n        else:\n            return False\n    else:\n        return bool(value)", "blocks": [{"id": 1, "label": "def __convert_bool(value: Any) -> bool:\nif isinstance(value, bool):", "successors": [{"id": 3, "label": "return value", "successors": []}, {"id": 4, "label": "elif isinstance(value, str):\nif value.lower() in [\"true\", \"1\"]:", "successors": [{"id": 6, "label": "return True", "successors": []}, {"id": 7, "label": "else:\nreturn False", "successors": []}]}, {"id": 9, "label": "else:\nreturn bool(value)", "successors": []}]}]}, {"name": "_try_convert", "type": "function", "start_line": 105, "end_line": 179, "functions": [], "classes": [], "simplified_code": "def _try_convert(value: Any, target_type: Type, raise_on_mismatch: bool) -> Any:\n    origin = get_origin(target_type)\n    args = get_args(target_type)\n    if origin is None:\n        origin = target_type\n    if origin not in [list, dict, tuple, str, set, int, float, bool]:\n        return value\n\n    # Handle the case when value is already of the target type\n    if isinstance(value, origin):\n        if not args:\n            return value\n        else:\n            # Need to convert elements\n            if origin is list:\n                return [convert(v, args[0]) for v in value]\n            elif origin is tuple:\n                # Tuples can have multiple types\n                if len(args) == 1:\n                    return tuple(convert(v, args[0]) for v in value)\n                else:\n                    return tuple(convert(v, t) for v, t in zip(value, args))\n            elif origin is dict:\n                key_type, val_type = args\n                return {\n                    convert(k, key_type): convert(v, val_type) for k, v in value.items()\n                }\n            elif origin is set:\n                return {convert(v, args[0]) for v in value}\n            else:\n                return value\n    elif raise_on_mismatch:\n        raise TypeError(f\"Value {value} is not of expected type {target_type}\")\n    else:\n        # Need to convert value to the origin type\n        if origin is list:\n            value = __convert_list(value)\n            if args:\n                return [convert(v, args[0]) for v in value]\n            else:\n                return value\n        elif origin is dict:\n            value = __convert_dict(value)\n            if args:\n                key_type, val_type = args\n                return {\n                    convert(k, key_type): convert(v, val_type) for k, v in value.items()\n                }\n            else:\n                return value\n        elif origin is tuple:\n            value = __convert_tuple(value)\n            if args:\n                if len(args) == 1:\n                    return tuple(convert(v, args[0]) for v in value)\n                else:\n                    return tuple(convert(v, t) for v, t in zip(value, args))\n            else:\n                return value\n        elif origin is str:\n            return __convert_str(value)\n        elif origin is set:\n            value = __convert_set(value)\n            if args:\n                return {convert(v, args[0]) for v in value}\n            else:\n                return value\n        elif origin is int:\n            return __convert_num(value, int)\n        elif origin is float:\n            return __convert_num(value, float)\n        elif origin is bool:\n            return __convert_bool(value)\n        else:\n            return value", "blocks": [{"id": 1, "label": "def _try_convert(value: Any, target_type: Type, raise_on_mismatch: bool) -> Any:\norigin = get_origin(target_type)\nargs = get_args(target_type)\nif origin is None:\n    origin = target_type", "successors": [{"id": 3, "label": "if origin not in [list, dict, tuple, str, set, int, float, bool]:\n    return value", "successors": [{"id": 4, "label": "if isinstance(value, origin):\nif not args:\n    return value", "successors": [{"id": 6, "label": "else:\n    if origin is list:\n        return [convert(v, args[0]) for v in value]", "successors": []}, {"id": 7, "label": "elif origin is tuple:\n    if len(args) == 1:\n        return tuple(convert(v, args[0]) for v in value)\n    else:\n        return tuple(convert(v, t) for v, t in zip(value, args))", "successors": []}, {"id": 8, "label": "elif origin is dict:\n    key_type, val_type = args\n    return {\n        convert(k, key_type): convert(v, val_type) for k, v in value.items()\n    }", "successors": []}, {"id": 9, "label": "elif origin is set:\n    return {convert(v, args[0]) for v in value}", "successors": []}, {"id": 10, "label": "else:\n    return value", "successors": []}]}, {"id": 11, "label": "elif raise_on_mismatch:\n    raise TypeError(f\"Value {value} is not of expected type {target_type}\")", "successors": []}, {"id": 12, "label": "else:", "successors": [{"id": 13, "label": "if origin is list:\n    value = __convert_list(value)\n    if args:\n        return [convert(v, args[0]) for v in value]\n    else:\n        return value", "successors": []}, {"id": 14, "label": "elif origin is dict:\n    value = __convert_dict(value)\n    if args:\n        key_type, val_type = args\n        return {\n            convert(k, key_type): convert(v, val_type) for k, v in value.items()\n        }\n    else:\n        return value", "successors": []}, {"id": 15, "label": "elif origin is tuple:\n    value = __convert_tuple(value)\n    if args:\n        if len(args) == 1:\n            return tuple(convert(v, args[0]) for v in value)\n        else:\n            return tuple(convert(v, t) for v, t in zip(value, args))\n    else:\n        return value", "successors": []}, {"id": 16, "label": "elif origin is str:\n    return __convert_str(value)", "successors": []}, {"id": 17, "label": "elif origin is set:\n    value = __convert_set(value)\n    if args:\n        return {convert(v, args[0]) for v in value}\n    else:\n        return value", "successors": []}, {"id": 18, "label": "elif origin is int:\n    return __convert_num(value, int)", "successors": []}, {"id": 19, "label": "elif origin is float:\n    return __convert_num(value, float)", "successors": []}, {"id": 20, "label": "elif origin is bool:\n    return __convert_bool(value)", "successors": []}, {"id": 21, "label": "else:\n    return value", "successors": []}]}]}]}]}, {"name": "type_match", "type": "function", "start_line": 185, "end_line": 186, "functions": [], "classes": [], "simplified_code": "def type_match(value: Any, target_type: Type[T]) -> T:\n    return cast(T, _try_convert(value, target_type, raise_on_mismatch=True))", "blocks": [{"id": 1, "label": "def type_match(value: Any, target_type: Type[T]) -> T:\n    return cast(T, _try_convert(value, target_type, raise_on_mismatch=True))", "successors": []}]}, {"name": "convert", "type": "function", "start_line": 189, "end_line": 193, "functions": [], "classes": [], "simplified_code": "def convert(value: Any, target_type: Type[T]) -> T:\n    try:\n        return cast(T, _try_convert(value, target_type, raise_on_mismatch=False))\n    except Exception as e:\n        raise ConversionError(f\"Failed to convert {value} to {target_type}\") from e", "blocks": [{"id": 1, "label": "def convert(value: Any, target_type: Type[T]) -> T:\ntry:", "successors": [{"id": 3, "label": "return cast(T, _try_convert(value, target_type, raise_on_mismatch=False))", "successors": []}, {"id": 4, "label": "except Exception as e:\nraise ConversionError(f\"Failed to convert {value} to {target_type}\") from e", "successors": []}]}]}], "classes": [{"name": "ConversionError", "type": "class", "start_line": 5, "end_line": 6, "functions": [], "classes": [], "simplified_code": "class ConversionError(ValueError):\n    pass", "blocks": [{"id": 1, "label": "class ConversionError(ValueError):\n    pass", "successors": []}]}], "simplified_code": "import json\nfrom typing import Any, Type, TypeVar, cast, get_args, get_origin\n\n\n    pass\n\n\n        return [value]\n\n\n        return {\"value\": value}\n\n\n        return (value,)\n\n\n        return {value}\n\n\n        return json.dumps(value)\n\n\nNUM = TypeVar(\"NUM\", int, float)\n\n\n            return num_type(0)  # Fallback conversion\n\n\n        return bool(value)\n\n\n            return value\n\n\nT = TypeVar(\"T\")\n\n\n    return cast(T, _try_convert(value, target_type, raise_on_mismatch=True))\n\n\n        raise ConversionError(f\"Failed to convert {value} to {target_type}\") from e", "blocks": [{"id": 1, "label": "import json\nfrom typing import Any, Type, TypeVar, cast, get_args, get_origin\npass", "successors": [{"id": 3, "label": "return [value]\nreturn {\"value\": value}", "successors": [{"id": 5, "label": "return (value,)\nreturn {value}", "successors": [{"id": 7, "label": "return json.dumps(value)\nNUM = TypeVar(\"NUM\", int, float)", "successors": [{"id": 9, "label": "return num_type(0)  # Fallback conversion\nreturn bool(value)", "successors": [{"id": 11, "label": "return value\nT = TypeVar(\"T\")", "successors": [{"id": 13, "label": "return cast(T, _try_convert(value, target_type, raise_on_mismatch=True))\nraise ConversionError(f\"Failed to convert {value} to {target_type}\") from e", "successors": []}]}]}]}]}]}]}]}
{"file_name": "141.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 514, "functions": [{"name": "prepare_pr_api_url", "type": "function", "start_line": 506, "end_line": 514, "functions": [], "classes": [], "simplified_code": "def prepare_pr_api_url(pr_url: str, path: str) -> str:\n    # Pattern to capture the base repository URL and the pull request number\n    pattern = r\"^(?:https?://)?([^/]+/[^/]+/[^/]+)/pull/(\\d+)\"\n    match = re.match(pattern, pr_url)\n    if not match:\n        return pr_url\n\n    base_url, pr_number = match.groups()\n    return f\"{base_url}/pulls/{pr_number}/{path}\"", "blocks": [{"id": 1, "label": "def prepare_pr_api_url(pr_url: str, path: str) -> str:\n    pattern = r\"^(?:https?://)?([^/]+/[^/]+/[^/]+)/pull/(\\d+)\"", "successors": [{"id": 3, "label": "    match = re.match(pattern, pr_url)\n    if not match:", "successors": [{"id": 5, "label": "        return pr_url", "successors": []}, {"id": 6, "label": "    base_url, pr_number = match.groups()\n    return f\"{base_url}/pulls/{pr_number}/{path}\"", "successors": []}]}]}]}], "classes": [{"name": "GithubListPullRequestsBlock", "type": "class", "start_line": 18, "end_line": 90, "functions": [{"name": "__init__", "type": "function", "start_line": 36, "end_line": 65, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"ffef3c4c-6cd0-48dd-817d-459f975219f4\",\n            description=\"This block lists all pull requests for a specified GitHub repository.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubListPullRequestsBlock.Input,\n            output_schema=GithubListPullRequestsBlock.Output,\n            test_input={\n                \"repo_url\": \"https://github.com/owner/repo\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\n                    \"pull_request\",\n                    {\n                        \"title\": \"Pull request 1\",\n                        \"url\": \"https://github.com/owner/repo/pull/1\",\n                    },\n                )\n            ],\n            test_mock={\n                \"list_prs\": lambda *args, **kwargs: [\n                    {\n                        \"title\": \"Pull request 1\",\n                        \"url\": \"https://github.com/owner/repo/pull/1\",\n                    }\n                ]\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"ffef3c4c-6cd0-48dd-817d-459f975219f4\",\n    description=\"This block lists all pull requests for a specified GitHub repository.\",\n    categories={BlockCategory.DEVELOPER_TOOLS},\n    input_schema=GithubListPullRequestsBlock.Input,\n    output_schema=GithubListPullRequestsBlock.Output,\n    test_input={\n        \"repo_url\": \"https://github.com/owner/repo\",\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\n            \"pull_request\",\n            {\n                \"title\": \"Pull request 1\",\n                \"url\": \"https://github.com/owner/repo/pull/1\",\n            },\n        )\n    ],\n    test_mock={\n        \"list_prs\": lambda *args, **kwargs: [\n            {\n                \"title\": \"Pull request 1\",\n                \"url\": \"https://github.com/owner/repo/pull/1\",\n            }\n        ]\n    },\n)", "successors": []}]}, {"name": "list_prs", "type": "function", "start_line": 68, "end_line": 76, "functions": [], "classes": [], "simplified_code": "    def list_prs(credentials: GithubCredentials, repo_url: str) -> list[Output.PRItem]:\n        api = get_api(credentials)\n        pulls_url = repo_url + \"/pulls\"\n        response = api.get(pulls_url)\n        data = response.json()\n        pull_requests: list[GithubListPullRequestsBlock.Output.PRItem] = [\n            {\"title\": pr[\"title\"], \"url\": pr[\"html_url\"]} for pr in data\n        ]\n        return pull_requests", "blocks": [{"id": 1, "label": "def list_prs(credentials: GithubCredentials, repo_url: str) -> list[Output.PRItem]:\napi = get_api(credentials)\npulls_url = repo_url + \"/pulls\"\nresponse = api.get(pulls_url)\ndata = response.json()\npull_requests: list[GithubListPullRequestsBlock.Output.PRItem] = [\n    {\"title\": pr[\"title\"], \"url\": pr[\"html_url\"]} for pr in data\n]", "successors": [{"id": 3, "label": "return pull_requests", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 78, "end_line": 89, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        pull_requests = self.list_prs(\n            credentials,\n            input_data.repo_url,\n        )\n        yield from ((\"pull_request\", pr) for pr in pull_requests)", "blocks": [{"id": 1, "label": "def run(\n    self,\n    input_data: Input,\n    *,\n    credentials: GithubCredentials,\n    **kwargs,\n) -> BlockOutput:\npull_requests = self.list_prs(\n    credentials,\n    input_data.repo_url,\n)", "successors": [{"id": 3, "label": "yield from ((\"pull_request\", pr) for pr in pull_requests)", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 19, "end_line": 24, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        repo_url: str = SchemaField(\n            description=\"URL of the GitHub repository\",\n            placeholder=\"https://github.com/owner/repo\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")", "successors": [{"id": 3, "label": "    repo_url: str = SchemaField(\n        description=\"URL of the GitHub repository\",\n        placeholder=\"https://github.com/owner/repo\",\n    )", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 26, "end_line": 34, "functions": [], "classes": [{"name": "PRItem", "type": "class", "start_line": 27, "end_line": 29, "functions": [], "classes": [], "simplified_code": "        class PRItem(TypedDict):\n            title: str\n            url: str", "blocks": [{"id": 1, "label": "class PRItem(TypedDict):\n    title: str\n    url: str", "successors": []}]}], "simplified_code": "    class Output(BlockSchema):\n            url: str\n\n        pull_request: PRItem = SchemaField(\n            title=\"Pull Request\", description=\"PRs with their title and URL\"\n        )\n        error: str = SchemaField(description=\"Error message if listing issues failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\nurl: str", "successors": [{"id": 3, "label": "pull_request: PRItem = SchemaField( title=\"Pull Request\", description=\"PRs with their title and URL\" )\nerror: str = SchemaField(description=\"Error message if listing issues failed\")", "successors": []}]}]}], "simplified_code": "class GithubListPullRequestsBlock(Block):\n        )\n\n        error: str = SchemaField(description=\"Error message if listing issues failed\")\n\n        )\n\n    @staticmethod\n        return pull_requests\n\n        yield from ((\"pull_request\", pr) for pr in pull_requests)\n", "blocks": [{"id": 1, "label": "class GithubListPullRequestsBlock(Block):", "successors": [{"id": 2, "label": "error: str = SchemaField(description=\"Error message if listing issues failed\")", "successors": []}, {"id": 3, "label": "@staticmethod\ndef list_pull_requests():\npull_requests = []", "successors": [{"id": 5, "label": "return pull_requests", "successors": []}, {"id": 6, "label": "yield from ((\"pull_request\", pr) for pr in pull_requests)", "successors": []}]}]}]}, {"name": "GithubMakePullRequestBlock", "type": "class", "start_line": 92, "end_line": 191, "functions": [{"name": "__init__", "type": "function", "start_line": 127, "end_line": 153, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"dfb987f8-f197-4b2e-bf19-111812afd692\",\n            description=\"This block creates a new pull request on a specified GitHub repository.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubMakePullRequestBlock.Input,\n            output_schema=GithubMakePullRequestBlock.Output,\n            test_input={\n                \"repo_url\": \"https://github.com/owner/repo\",\n                \"title\": \"Test Pull Request\",\n                \"body\": \"This is a test pull request.\",\n                \"head\": \"feature-branch\",\n                \"base\": \"main\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\"number\", 1),\n                (\"url\", \"https://github.com/owner/repo/pull/1\"),\n            ],\n            test_mock={\n                \"create_pr\": lambda *args, **kwargs: (\n                    1,\n                    \"https://github.com/owner/repo/pull/1\",\n                )\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"dfb987f8-f197-4b2e-bf19-111812afd692\",\n    description=\"This block creates a new pull request on a specified GitHub repository.\",\n    categories={BlockCategory.DEVELOPER_TOOLS},\n    input_schema=GithubMakePullRequestBlock.Input,\n    output_schema=GithubMakePullRequestBlock.Output,\n    test_input={\n        \"repo_url\": \"https://github.com/owner/repo\",\n        \"title\": \"Test Pull Request\",\n        \"body\": \"This is a test pull request.\",\n        \"head\": \"feature-branch\",\n        \"base\": \"main\",\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\"number\", 1),\n        (\"url\", \"https://github.com/owner/repo/pull/1\"),\n    ],\n    test_mock={\n        \"create_pr\": lambda *args, **kwargs: (\n            1,\n            \"https://github.com/owner/repo/pull/1\",\n        )\n    },\n)", "successors": []}]}, {"name": "create_pr", "type": "function", "start_line": 156, "end_line": 169, "functions": [], "classes": [], "simplified_code": "    def create_pr(\n        credentials: GithubCredentials,\n        repo_url: str,\n        title: str,\n        body: str,\n        head: str,\n        base: str,\n    ) -> tuple[int, str]:\n        api = get_api(credentials)\n        pulls_url = repo_url + \"/pulls\"\n        data = {\"title\": title, \"body\": body, \"head\": head, \"base\": base}\n        response = api.post(pulls_url, json=data)\n        pr_data = response.json()\n        return pr_data[\"number\"], pr_data[\"html_url\"]", "blocks": [{"id": 1, "label": "def create_pr(\n    credentials: GithubCredentials,\n    repo_url: str,\n    title: str,\n    body: str,\n    head: str,\n    base: str,\n) -> tuple[int, str]:\n    api = get_api(credentials)\n    pulls_url = repo_url + \"/pulls\"\n    data = {\"title\": title, \"body\": body, \"head\": head, \"base\": base}\n    response = api.post(pulls_url, json=data)\n    pr_data = response.json()", "successors": [{"id": 3, "label": "    return pr_data[\"number\"], pr_data[\"html_url\"]", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 171, "end_line": 190, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        try:\n            number, url = self.create_pr(\n                credentials,\n                input_data.repo_url,\n                input_data.title,\n                input_data.body,\n                input_data.head,\n                input_data.base,\n            )\n            yield \"number\", number\n            yield \"url\", url\n        except Exception as e:\n            yield \"error\", str(e)", "blocks": [{"id": 1, "label": "try:", "successors": [{"id": 2, "label": "number, url = self.create_pr(\n    credentials,\n    input_data.repo_url,\n    input_data.title,\n    input_data.body,\n    input_data.head,\n    input_data.base,\n)\nyield \"number\", number\nyield \"url\", url", "successors": []}, {"id": 4, "label": "except Exception as e:\nyield \"error\", str(e)", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 93, "end_line": 118, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        repo_url: str = SchemaField(\n            description=\"URL of the GitHub repository\",\n            placeholder=\"https://github.com/owner/repo\",\n        )\n        title: str = SchemaField(\n            description=\"Title of the pull request\",\n            placeholder=\"Enter the pull request title\",\n        )\n        body: str = SchemaField(\n            description=\"Body of the pull request\",\n            placeholder=\"Enter the pull request body\",\n        )\n        head: str = SchemaField(\n            description=(\n                \"The name of the branch where your changes are implemented. \"\n                \"For cross-repository pull requests in the same network, \"\n                \"namespace head with a user like this: username:branch.\"\n            ),\n            placeholder=\"Enter the head branch\",\n        )\n        base: str = SchemaField(\n            description=\"The name of the branch you want the changes pulled into.\",\n            placeholder=\"Enter the base branch\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")", "successors": []}, {"id": 3, "label": "    repo_url: str = SchemaField(description=\"URL of the GitHub repository\", placeholder=\"https://github.com/owner/repo\")", "successors": []}, {"id": 4, "label": "    title: str = SchemaField(description=\"Title of the pull request\", placeholder=\"Enter the pull request title\")", "successors": []}, {"id": 5, "label": "    body: str = SchemaField(description=\"Body of the pull request\", placeholder=\"Enter the pull request body\")", "successors": []}, {"id": 6, "label": "    head: str = SchemaField(description=(\"The name of the branch where your changes are implemented. \" \"For cross-repository pull requests in the same network, \" \"namespace head with a user like this: username:branch.\"), placeholder=\"Enter the head branch\")", "successors": []}, {"id": 7, "label": "    base: str = SchemaField(description=\"The name of the branch you want the changes pulled into.\", placeholder=\"Enter the base branch\")", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 120, "end_line": 125, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        number: int = SchemaField(description=\"Number of the created pull request\")\n        url: str = SchemaField(description=\"URL of the created pull request\")\n        error: str = SchemaField(\n            description=\"Error message if the pull request creation failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\nnumber: int = SchemaField(description=\"Number of the created pull request\")", "successors": [{"id": 3, "label": "url: str = SchemaField(description=\"URL of the created pull request\")\nerror: str = SchemaField(description=\"Error message if the pull request creation failed\")", "successors": []}]}]}], "simplified_code": "class GithubMakePullRequestBlock(Block):\n        )\n\n        )\n\n        )\n\n    @staticmethod\n        return pr_data[\"number\"], pr_data[\"html_url\"]\n\n            yield \"error\", str(e)\n", "blocks": [{"id": 1, "label": "class GithubMakePullRequestBlock(Block):\n@staticmethod", "successors": [{"id": 3, "label": "return pr_data[\"number\"], pr_data[\"html_url\"]", "successors": []}, {"id": 4, "label": "yield \"error\", str(e)", "successors": []}]}]}, {"name": "GithubReadPullRequestBlock", "type": "class", "start_line": 193, "end_line": 290, "functions": [{"name": "__init__", "type": "function", "start_line": 214, "end_line": 241, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"bf94b2a4-1a30-4600-a783-a8a44ee31301\",\n            description=\"This block reads the body, title, user, and changes of a specified GitHub pull request.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubReadPullRequestBlock.Input,\n            output_schema=GithubReadPullRequestBlock.Output,\n            test_input={\n                \"pr_url\": \"https://github.com/owner/repo/pull/1\",\n                \"include_pr_changes\": True,\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\"title\", \"Title of the pull request\"),\n                (\"body\", \"This is the body of the pull request.\"),\n                (\"author\", \"username\"),\n                (\"changes\", \"List of changes made in the pull request.\"),\n            ],\n            test_mock={\n                \"read_pr\": lambda *args, **kwargs: (\n                    \"Title of the pull request\",\n                    \"This is the body of the pull request.\",\n                    \"username\",\n                ),\n                \"read_pr_changes\": lambda *args, **kwargs: \"List of changes made in the pull request.\",\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\n    super().__init__(\n        id=\"bf94b2a4-1a30-4600-a783-a8a44ee31301\",\n        description=\"This block reads the body, title, user, and changes of a specified GitHub pull request.\",\n        categories={BlockCategory.DEVELOPER_TOOLS},\n        input_schema=GithubReadPullRequestBlock.Input,\n        output_schema=GithubReadPullRequestBlock.Output,\n        test_input={\n            \"pr_url\": \"https://github.com/owner/repo/pull/1\",\n            \"include_pr_changes\": True,\n            \"credentials\": TEST_CREDENTIALS_INPUT,\n        },\n        test_credentials=TEST_CREDENTIALS,\n        test_output=[\n            (\"title\", \"Title of the pull request\"),\n            (\"body\", \"This is the body of the pull request.\"),\n            (\"author\", \"username\"),\n            (\"changes\", \"List of changes made in the pull request.\"),\n        ],\n        test_mock={\n            \"read_pr\": lambda *args, **kwargs: (\n                \"Title of the pull request\",\n                \"This is the body of the pull request.\",\n                \"username\",\n            ),\n            \"read_pr_changes\": lambda *args, **kwargs: \"List of changes made in the pull request.\",\n        },\n    )", "successors": []}]}, {"name": "read_pr", "type": "function", "start_line": 244, "end_line": 253, "functions": [], "classes": [], "simplified_code": "    def read_pr(credentials: GithubCredentials, pr_url: str) -> tuple[str, str, str]:\n        api = get_api(credentials)\n        # Adjust the URL to access the issue endpoint for PR metadata\n        issue_url = pr_url.replace(\"/pull/\", \"/issues/\")\n        response = api.get(issue_url)\n        data = response.json()\n        title = data.get(\"title\", \"No title found\")\n        body = data.get(\"body\", \"No body content found\")\n        author = data.get(\"user\", {}).get(\"login\", \"No user found\")\n        return title, body, author", "blocks": [{"id": 1, "label": "def read_pr(credentials: GithubCredentials, pr_url: str) -> tuple[str, str, str]:\n    api = get_api(credentials)", "successors": [{"id": 3, "label": "    issue_url = pr_url.replace(\"/pull/\", \"/issues/\")\n    response = api.get(issue_url)", "successors": [{"id": 5, "label": "    data = response.json()\n    title = data.get(\"title\", \"No title found\")", "successors": [{"id": 7, "label": "    body = data.get(\"body\", \"No body content found\")\n    author = data.get(\"user\", {}).get(\"login\", \"No user found\")", "successors": [{"id": 9, "label": "    return title, body, author", "successors": []}]}]}]}]}]}, {"name": "read_pr_changes", "type": "function", "start_line": 256, "end_line": 267, "functions": [], "classes": [], "simplified_code": "    def read_pr_changes(credentials: GithubCredentials, pr_url: str) -> str:\n        api = get_api(credentials)\n        files_url = prepare_pr_api_url(pr_url=pr_url, path=\"files\")\n        response = api.get(files_url)\n        files = response.json()\n        changes = []\n        for file in files:\n            filename = file.get(\"filename\")\n            patch = file.get(\"patch\")\n            if filename and patch:\n                changes.append(f\"File: {filename}\\n{patch}\")\n        return \"\\n\\n\".join(changes)", "blocks": [{"id": 1, "label": "def read_pr_changes(credentials: GithubCredentials, pr_url: str) -> str:\n    api = get_api(credentials)\n    files_url = prepare_pr_api_url(pr_url=pr_url, path=\"files\")\n    response = api.get(files_url)\n    files = response.json()\n    changes = []", "successors": [{"id": 2, "label": "for file in files:", "successors": [{"id": 3, "label": "    filename = file.get(\"filename\")\n    patch = file.get(\"patch\")\nif filename and patch:", "successors": [{"id": 5, "label": "    changes.append(f\"File: {filename}\\n{patch}\")", "successors": []}]}]}, {"id": 6, "label": "return \"\\n\\n\".join(changes)", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 269, "end_line": 289, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        title, body, author = self.read_pr(\n            credentials,\n            input_data.pr_url,\n        )\n        yield \"title\", title\n        yield \"body\", body\n        yield \"author\", author\n\n        if input_data.include_pr_changes:\n            changes = self.read_pr_changes(\n                credentials,\n                input_data.pr_url,\n            )\n            yield \"changes\", changes", "blocks": [{"id": 1, "label": "def run( self, input_data: Input, *, credentials: GithubCredentials, **kwargs, ) -> BlockOutput:\ntitle, body, author = self.read_pr( credentials, input_data.pr_url, )", "successors": [{"id": 3, "label": "yield \"title\", title\nyield \"body\", body\nyield \"author\", author\nif input_data.include_pr_changes:", "successors": [{"id": 5, "label": "changes = self.read_pr_changes( credentials, input_data.pr_url, )\nyield \"changes\", changes", "successors": []}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 194, "end_line": 203, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        pr_url: str = SchemaField(\n            description=\"URL of the GitHub pull request\",\n            placeholder=\"https://github.com/owner/repo/pull/1\",\n        )\n        include_pr_changes: bool = SchemaField(\n            description=\"Whether to include the changes made in the pull request\",\n            default=False,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n    pr_url: str = SchemaField(\n        description=\"URL of the GitHub pull request\",\n        placeholder=\"https://github.com/owner/repo/pull/1\",\n    )\n    include_pr_changes: bool = SchemaField(\n        description=\"Whether to include the changes made in the pull request\",\n        default=False,\n    )", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 205, "end_line": 212, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        title: str = SchemaField(description=\"Title of the pull request\")\n        body: str = SchemaField(description=\"Body of the pull request\")\n        author: str = SchemaField(description=\"User who created the pull request\")\n        changes: str = SchemaField(description=\"Changes made in the pull request\")\n        error: str = SchemaField(\n            description=\"Error message if reading the pull request failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "    title: str = SchemaField(description=\"Title of the pull request\")", "successors": []}, {"id": 3, "label": "    body: str = SchemaField(description=\"Body of the pull request\")", "successors": []}, {"id": 4, "label": "    author: str = SchemaField(description=\"User who created the pull request\")", "successors": []}, {"id": 5, "label": "    changes: str = SchemaField(description=\"Changes made in the pull request\")", "successors": []}, {"id": 6, "label": "    error: str = SchemaField(description=\"Error message if reading the pull request failed\")", "successors": []}]}]}], "simplified_code": "class GithubReadPullRequestBlock(Block):\n        )\n\n        )\n\n        )\n\n    @staticmethod\n        return title, body, author\n\n    @staticmethod\n        return \"\\n\\n\".join(changes)\n\n            yield \"changes\", changes\n", "blocks": [{"id": 1, "label": "class GithubReadPullRequestBlock(Block):", "successors": [{"id": 2, "label": "@staticmethod\nreturn title, body, author", "successors": []}, {"id": 3, "label": "@staticmethod\nreturn \"\\n\\n\".join(changes)", "successors": []}, {"id": 4, "label": "yield \"changes\", changes", "successors": []}]}]}, {"name": "GithubAssignPRReviewerBlock", "type": "class", "start_line": 292, "end_line": 357, "functions": [{"name": "__init__", "type": "function", "start_line": 312, "end_line": 329, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"c0d22c5e-e688-43e3-ba43-d5faba7927fd\",\n            description=\"This block assigns a reviewer to a specified GitHub pull request.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubAssignPRReviewerBlock.Input,\n            output_schema=GithubAssignPRReviewerBlock.Output,\n            test_input={\n                \"pr_url\": \"https://github.com/owner/repo/pull/1\",\n                \"reviewer\": \"reviewer_username\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[(\"status\", \"Reviewer assigned successfully\")],\n            test_mock={\n                \"assign_reviewer\": lambda *args, **kwargs: \"Reviewer assigned successfully\"\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"c0d22c5e-e688-43e3-ba43-d5faba7927fd\",\n    description=\"This block assigns a reviewer to a specified GitHub pull request.\",\n    categories={BlockCategory.DEVELOPER_TOOLS},\n    input_schema=GithubAssignPRReviewerBlock.Input,\n    output_schema=GithubAssignPRReviewerBlock.Output,\n    test_input={\n        \"pr_url\": \"https://github.com/owner/repo/pull/1\",\n        \"reviewer\": \"reviewer_username\",\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[(\"status\", \"Reviewer assigned successfully\")],\n    test_mock={\n        \"assign_reviewer\": lambda *args, **kwargs: \"Reviewer assigned successfully\"\n    },\n)", "successors": []}]}, {"name": "assign_reviewer", "type": "function", "start_line": 332, "end_line": 339, "functions": [], "classes": [], "simplified_code": "    def assign_reviewer(\n        credentials: GithubCredentials, pr_url: str, reviewer: str\n    ) -> str:\n        api = get_api(credentials)\n        reviewers_url = prepare_pr_api_url(pr_url=pr_url, path=\"requested_reviewers\")\n        data = {\"reviewers\": [reviewer]}\n        api.post(reviewers_url, json=data)\n        return \"Reviewer assigned successfully\"", "blocks": [{"id": 1, "label": "def assign_reviewer(\n    credentials: GithubCredentials, pr_url: str, reviewer: str\n) -> str:\napi = get_api(credentials)\nreviewers_url = prepare_pr_api_url(pr_url=pr_url, path=\"requested_reviewers\")\ndata = {\"reviewers\": [reviewer]}\napi.post(reviewers_url, json=data)", "successors": [{"id": 3, "label": "return \"Reviewer assigned successfully\"", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 341, "end_line": 355, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        try:\n            status = self.assign_reviewer(\n                credentials,\n                input_data.pr_url,\n                input_data.reviewer,\n            )\n            yield \"status\", status\n        except Exception as e:", "blocks": [{"id": 1, "label": "def run(\n    self,\n    input_data: Input,\n    *,\n    credentials: GithubCredentials,\n    **kwargs,\n) -> BlockOutput:\ntry:", "successors": [{"id": 3, "label": "    status = self.assign_reviewer(\n        credentials,\n        input_data.pr_url,\n        input_data.reviewer,\n    )\n    yield \"status\", status", "successors": []}, {"id": 4, "label": "except Exception as e:", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 293, "end_line": 302, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        pr_url: str = SchemaField(\n            description=\"URL of the GitHub pull request\",\n            placeholder=\"https://github.com/owner/repo/pull/1\",\n        )\n        reviewer: str = SchemaField(\n            description=\"Username of the reviewer to assign\",\n            placeholder=\"Enter the reviewer's username\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n    pr_url: str = SchemaField(\n        description=\"URL of the GitHub pull request\",\n        placeholder=\"https://github.com/owner/repo/pull/1\",\n    )\n    reviewer: str = SchemaField(\n        description=\"Username of the reviewer to assign\",\n        placeholder=\"Enter the reviewer's username\",\n    )", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 304, "end_line": 310, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        status: str = SchemaField(\n            description=\"Status of the reviewer assignment operation\"\n        )\n        error: str = SchemaField(\n            description=\"Error message if the reviewer assignment failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\nstatus: str = SchemaField(\n    description=\"Status of the reviewer assignment operation\"\n)", "successors": [{"id": 3, "label": "error: str = SchemaField(\n    description=\"Error message if the reviewer assignment failed\"\n)", "successors": []}]}]}], "simplified_code": "class GithubAssignPRReviewerBlock(Block):\n        )\n\n        )\n\n        )\n\n    @staticmethod\n        return \"Reviewer assigned successfully\"\n\n        except Exception as e:\n            yield \"error\", str(e)\n", "blocks": [{"id": 1, "label": "class GithubAssignPRReviewerBlock(Block):\n@staticmethod", "successors": [{"id": 3, "label": "return \"Reviewer assigned successfully\"\nexcept Exception as e:", "successors": [{"id": 5, "label": "yield \"error\", str(e)", "successors": []}]}]}]}, {"name": "GithubUnassignPRReviewerBlock", "type": "class", "start_line": 359, "end_line": 424, "functions": [{"name": "__init__", "type": "function", "start_line": 379, "end_line": 396, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"9637945d-c602-4875-899a-9c22f8fd30de\",\n            description=\"This block unassigns a reviewer from a specified GitHub pull request.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubUnassignPRReviewerBlock.Input,\n            output_schema=GithubUnassignPRReviewerBlock.Output,\n            test_input={\n                \"pr_url\": \"https://github.com/owner/repo/pull/1\",\n                \"reviewer\": \"reviewer_username\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[(\"status\", \"Reviewer unassigned successfully\")],\n            test_mock={\n                \"unassign_reviewer\": lambda *args, **kwargs: \"Reviewer unassigned successfully\"\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"9637945d-c602-4875-899a-9c22f8fd30de\",\n    description=\"This block unassigns a reviewer from a specified GitHub pull request.\",\n    categories={BlockCategory.DEVELOPER_TOOLS},\n    input_schema=GithubUnassignPRReviewerBlock.Input,\n    output_schema=GithubUnassignPRReviewerBlock.Output,\n    test_input={\n        \"pr_url\": \"https://github.com/owner/repo/pull/1\",\n        \"reviewer\": \"reviewer_username\",\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[(\"status\", \"Reviewer unassigned successfully\")],\n    test_mock={\n        \"unassign_reviewer\": lambda *args, **kwargs: \"Reviewer unassigned successfully\"\n    },\n)", "successors": []}]}, {"name": "unassign_reviewer", "type": "function", "start_line": 399, "end_line": 406, "functions": [], "classes": [], "simplified_code": "    def unassign_reviewer(\n        credentials: GithubCredentials, pr_url: str, reviewer: str\n    ) -> str:\n        api = get_api(credentials)\n        reviewers_url = prepare_pr_api_url(pr_url=pr_url, path=\"requested_reviewers\")\n        data = {\"reviewers\": [reviewer]}\n        api.delete(reviewers_url, json=data)\n        return \"Reviewer unassigned successfully\"", "blocks": [{"id": 1, "label": "def unassign_reviewer(\n    credentials: GithubCredentials, pr_url: str, reviewer: str\n) -> str:\n    api = get_api(credentials)\n    reviewers_url = prepare_pr_api_url(pr_url=pr_url, path=\"requested_reviewers\")\n    data = {\"reviewers\": [reviewer]}\n    api.delete(reviewers_url, json=data)", "successors": [{"id": 3, "label": "    return \"Reviewer unassigned successfully\"", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 408, "end_line": 423, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        try:\n            status = self.unassign_reviewer(\n                credentials,\n                input_data.pr_url,\n                input_data.reviewer,\n            )\n            yield \"status\", status\n        except Exception as e:\n            yield \"error\", str(e)", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: GithubCredentials, **kwargs) -> BlockOutput:\ntry:", "successors": [{"id": 3, "label": "status = self.unassign_reviewer(credentials, input_data.pr_url, input_data.reviewer)\nyield \"status\", status", "successors": []}, {"id": 5, "label": "except Exception as e:\nyield \"error\", str(e)", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 360, "end_line": 369, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        pr_url: str = SchemaField(\n            description=\"URL of the GitHub pull request\",\n            placeholder=\"https://github.com/owner/repo/pull/1\",\n        )\n        reviewer: str = SchemaField(\n            description=\"Username of the reviewer to unassign\",\n            placeholder=\"Enter the reviewer's username\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")", "successors": [{"id": 3, "label": "    pr_url: str = SchemaField(description=\"URL of the GitHub pull request\", placeholder=\"https://github.com/owner/repo/pull/1\")\n    reviewer: str = SchemaField(description=\"Username of the reviewer to unassign\", placeholder=\"Enter the reviewer's username\")", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 371, "end_line": 377, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        status: str = SchemaField(\n            description=\"Status of the reviewer unassignment operation\"\n        )\n        error: str = SchemaField(\n            description=\"Error message if the reviewer unassignment failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    status: str = SchemaField(\n        description=\"Status of the reviewer unassignment operation\"\n    )", "successors": [{"id": 3, "label": "    error: str = SchemaField(\n        description=\"Error message if the reviewer unassignment failed\"\n    )", "successors": []}]}]}], "simplified_code": "class GithubUnassignPRReviewerBlock(Block):\n        )\n\n        )\n\n        )\n\n    @staticmethod\n        return \"Reviewer unassigned successfully\"\n\n            yield \"error\", str(e)\n", "blocks": [{"id": 1, "label": "class GithubUnassignPRReviewerBlock(Block):\n@staticmethod", "successors": [{"id": 3, "label": "return \"Reviewer unassigned successfully\"", "successors": []}, {"id": 4, "label": "yield \"error\", str(e)", "successors": []}]}]}, {"name": "GithubListPRReviewersBlock", "type": "class", "start_line": 426, "end_line": 504, "functions": [{"name": "__init__", "type": "function", "start_line": 447, "end_line": 476, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"2646956e-96d5-4754-a3df-034017e7ed96\",\n            description=\"This block lists all reviewers for a specified GitHub pull request.\",\n            categories={BlockCategory.DEVELOPER_TOOLS},\n            input_schema=GithubListPRReviewersBlock.Input,\n            output_schema=GithubListPRReviewersBlock.Output,\n            test_input={\n                \"pr_url\": \"https://github.com/owner/repo/pull/1\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\n                    \"reviewer\",\n                    {\n                        \"username\": \"reviewer1\",\n                        \"url\": \"https://github.com/reviewer1\",\n                    },\n                )\n            ],\n            test_mock={\n                \"list_reviewers\": lambda *args, **kwargs: [\n                    {\n                        \"username\": \"reviewer1\",\n                        \"url\": \"https://github.com/reviewer1\",\n                    }\n                ]\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"2646956e-96d5-4754-a3df-034017e7ed96\",\n    description=\"This block lists all reviewers for a specified GitHub pull request.\",\n    categories={BlockCategory.DEVELOPER_TOOLS},\n    input_schema=GithubListPRReviewersBlock.Input,\n    output_schema=GithubListPRReviewersBlock.Output,\n    test_input={\n        \"pr_url\": \"https://github.com/owner/repo/pull/1\",\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\n            \"reviewer\",\n            {\n                \"username\": \"reviewer1\",\n                \"url\": \"https://github.com/reviewer1\",\n            },\n        )\n    ],\n    test_mock={\n        \"list_reviewers\": lambda *args, **kwargs: [\n            {\n                \"username\": \"reviewer1\",\n                \"url\": \"https://github.com/reviewer1\",\n            }\n        ]\n    },\n)", "successors": []}]}, {"name": "list_reviewers", "type": "function", "start_line": 479, "end_line": 490, "functions": [], "classes": [], "simplified_code": "    def list_reviewers(\n        credentials: GithubCredentials, pr_url: str\n    ) -> list[Output.ReviewerItem]:\n        api = get_api(credentials)\n        reviewers_url = prepare_pr_api_url(pr_url=pr_url, path=\"requested_reviewers\")\n        response = api.get(reviewers_url)\n        data = response.json()\n        reviewers: list[GithubListPRReviewersBlock.Output.ReviewerItem] = [\n            {\"username\": reviewer[\"login\"], \"url\": reviewer[\"html_url\"]}\n            for reviewer in data.get(\"users\", [])\n        ]\n        return reviewers", "blocks": [{"id": 1, "label": "def list_reviewers(\n    credentials: GithubCredentials, pr_url: str\n) -> list[Output.ReviewerItem]:\n    api = get_api(credentials)\n    reviewers_url = prepare_pr_api_url(pr_url=pr_url, path=\"requested_reviewers\")\n    response = api.get(reviewers_url)\n    data = response.json()\n    reviewers: list[GithubListPRReviewersBlock.Output.ReviewerItem] = [\n        {\"username\": reviewer[\"login\"], \"url\": reviewer[\"html_url\"]}\n        for reviewer in data.get(\"users\", [])\n    ]", "successors": [{"id": 3, "label": "    return reviewers", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 492, "end_line": 503, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: GithubCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        reviewers = self.list_reviewers(\n            credentials,\n            input_data.pr_url,\n        )\n        yield from ((\"reviewer\", reviewer) for reviewer in reviewers)", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: GithubCredentials, **kwargs) -> BlockOutput:\nreviewers = self.list_reviewers(credentials, input_data.pr_url)", "successors": [{"id": 3, "label": "yield from (\"reviewer\", reviewer) for reviewer in reviewers", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 427, "end_line": 432, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")\n        pr_url: str = SchemaField(\n            description=\"URL of the GitHub pull request\",\n            placeholder=\"https://github.com/owner/repo/pull/1\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\ncredentials: GithubCredentialsInput = GithubCredentialsField(\"repo\")", "successors": [{"id": 3, "label": "pr_url: str = SchemaField(\n    description=\"URL of the GitHub pull request\",\n    placeholder=\"https://github.com/owner/repo/pull/1\",\n)", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 434, "end_line": 445, "functions": [], "classes": [{"name": "ReviewerItem", "type": "class", "start_line": 435, "end_line": 437, "functions": [], "classes": [], "simplified_code": "        class ReviewerItem(TypedDict):\n            username: str\n            url: str", "blocks": [{"id": 1, "label": "class ReviewerItem(TypedDict):\n    username: str\n    url: str", "successors": []}]}], "simplified_code": "    class Output(BlockSchema):\n            url: str\n\n        reviewer: ReviewerItem = SchemaField(\n            title=\"Reviewer\",\n            description=\"Reviewers with their username and profile URL\",\n        )\n        error: str = SchemaField(\n            description=\"Error message if listing reviewers failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\nurl: str", "successors": [{"id": 3, "label": "reviewer: ReviewerItem = SchemaField( title=\"Reviewer\", description=\"Reviewers with their username and profile URL\", )\nerror: str = SchemaField( description=\"Error message if listing reviewers failed\" )", "successors": []}]}]}], "simplified_code": "class GithubListPRReviewersBlock(Block):\n        )\n\n        )\n\n        )\n\n    @staticmethod\n        return reviewers\n\n        yield from ((\"reviewer\", reviewer) for reviewer in reviewers)\n", "blocks": [{"id": 1, "label": "class GithubListPRReviewersBlock(Block):\n@staticmethod", "successors": [{"id": 3, "label": "return reviewers\nyield from ((\"reviewer\", reviewer) for reviewer in reviewers)", "successors": []}]}]}], "simplified_code": "import re\n\nfrom typing_extensions import TypedDict\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\nfrom ._api import get_api\nfrom ._auth import (\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    GithubCredentials,\n    GithubCredentialsField,\n    GithubCredentialsInput,\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    return f\"{base_url}/pulls/{pr_number}/{path}\"", "blocks": [{"id": 1, "label": "import re", "successors": []}]}
{"file_name": "142.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 95, "functions": [], "classes": [{"name": "EmailCredentials", "type": "class", "start_line": 11, "end_line": 19, "functions": [], "classes": [], "simplified_code": "class EmailCredentials(BaseModel):\n    smtp_server: str = SchemaField(\n        default=\"smtp.gmail.com\", description=\"SMTP server address\"\n    )\n    smtp_port: int = SchemaField(default=25, description=\"SMTP port number\")\n    smtp_username: BlockSecret = SecretField(key=\"smtp_username\")\n    smtp_password: BlockSecret = SecretField(key=\"smtp_password\")\n\n    model_config = ConfigDict(title=\"Email Credentials\")", "blocks": [{"id": 1, "label": "class EmailCredentials(BaseModel):\nsmtp_server: str = SchemaField(\n        default=\"smtp.gmail.com\", description=\"SMTP server address\"\n    )", "successors": [{"id": 3, "label": "smtp_port: int = SchemaField(default=25, description=\"SMTP port number\")\nsmtp_username: BlockSecret = SecretField(key=\"smtp_username\")", "successors": [{"id": 5, "label": "smtp_password: BlockSecret = SecretField(key=\"smtp_password\")\nmodel_config = ConfigDict(title=\"Email Credentials\")", "successors": []}]}]}]}, {"name": "SendEmailBlock", "type": "class", "start_line": 22, "end_line": 95, "functions": [{"name": "__init__", "type": "function", "start_line": 44, "end_line": 65, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            disabled=True,\n            id=\"4335878a-394e-4e67-adf2-919877ff49ae\",\n            description=\"This block sends an email using the provided SMTP credentials.\",\n            categories={BlockCategory.OUTPUT},\n            input_schema=SendEmailBlock.Input,\n            output_schema=SendEmailBlock.Output,\n            test_input={\n                \"to_email\": \"recipient@example.com\",\n                \"subject\": \"Test Email\",\n                \"body\": \"This is a test email.\",\n                \"creds\": {\n                    \"smtp_server\": \"smtp.gmail.com\",\n                    \"smtp_port\": 25,\n                    \"smtp_username\": \"your-email@gmail.com\",\n                    \"smtp_password\": \"your-gmail-password\",\n                },\n            },\n            test_output=[(\"status\", \"Email sent successfully\")],\n            test_mock={\"send_email\": lambda *args, **kwargs: \"Email sent successfully\"},\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    disabled=True,\n    id=\"4335878a-394e-4e67-adf2-919877ff49ae\",\n    description=\"This block sends an email using the provided SMTP credentials.\",\n    categories={BlockCategory.OUTPUT},\n    input_schema=SendEmailBlock.Input,\n    output_schema=SendEmailBlock.Output,\n    test_input={\n        \"to_email\": \"recipient@example.com\",\n        \"subject\": \"Test Email\",\n        \"body\": \"This is a test email.\",\n        \"creds\": {\n            \"smtp_server\": \"smtp.gmail.com\",\n            \"smtp_port\": 25,\n            \"smtp_username\": \"your-email@gmail.com\",\n            \"smtp_password\": \"your-gmail-password\",\n        },\n    },\n    test_output=[(\"status\", \"Email sent successfully\")],\n    test_mock={\"send_email\": lambda *args, **kwargs: \"Email sent successfully\"},\n)", "successors": []}]}, {"name": "send_email", "type": "function", "start_line": 68, "end_line": 87, "functions": [], "classes": [], "simplified_code": "    def send_email(\n        creds: EmailCredentials, to_email: str, subject: str, body: str\n    ) -> str:\n        smtp_server = creds.smtp_server\n        smtp_port = creds.smtp_port\n        smtp_username = creds.smtp_username.get_secret_value()\n        smtp_password = creds.smtp_password.get_secret_value()\n\n        msg = MIMEMultipart()\n        msg[\"From\"] = smtp_username\n        msg[\"To\"] = to_email\n        msg[\"Subject\"] = subject\n        msg.attach(MIMEText(body, \"plain\"))\n\n        with smtplib.SMTP(smtp_server, smtp_port) as server:\n            server.starttls()\n            server.login(smtp_username, smtp_password)\n            server.sendmail(smtp_username, to_email, msg.as_string())\n\n        return \"Email sent successfully\"", "blocks": [{"id": 1, "label": "def send_email(\n        creds: EmailCredentials, to_email: str, subject: str, body: str\n    ) -> str:\nsmtp_server = creds.smtp_server\nsmtp_port = creds.smtp_port\nsmtp_username = creds.smtp_username.get_secret_value()\nsmtp_password = creds.smtp_password.get_secret_value()\n\nmsg = MIMEMultipart()\nmsg[\"From\"] = smtp_username\nmsg[\"To\"] = to_email\nmsg[\"Subject\"] = subject\nmsg.attach(MIMEText(body, \"plain\"))", "successors": [{"id": 3, "label": "with smtplib.SMTP(smtp_server, smtp_port) as server:\nserver.starttls()\nserver.login(smtp_username, smtp_password)\nserver.sendmail(smtp_username, to_email, msg.as_string())", "successors": []}, {"id": 5, "label": "return \"Email sent successfully\"", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 89, "end_line": 95, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        yield \"status\", self.send_email(\n            input_data.creds,\n            input_data.to_email,\n            input_data.subject,\n            input_data.body,\n        )", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\nyield \"status\", self.send_email(input_data.creds, input_data.to_email, input_data.subject, input_data.body)", "successors": []}]}], "classes": [{"name": "Input", "type": "class", "start_line": 23, "end_line": 36, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        to_email: str = SchemaField(\n            description=\"Recipient email address\", placeholder=\"recipient@example.com\"\n        )\n        subject: str = SchemaField(\n            description=\"Subject of the email\", placeholder=\"Enter the email subject\"\n        )\n        body: str = SchemaField(\n            description=\"Body of the email\", placeholder=\"Enter the email body\"\n        )\n        creds: EmailCredentials = SchemaField(\n            description=\"SMTP credentials\",\n            default=EmailCredentials(),\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    to_email: str = SchemaField(description=\"Recipient email address\", placeholder=\"recipient@example.com\")", "successors": []}, {"id": 3, "label": "    subject: str = SchemaField(description=\"Subject of the email\", placeholder=\"Enter the email subject\")", "successors": []}, {"id": 4, "label": "    body: str = SchemaField(description=\"Body of the email\", placeholder=\"Enter the email body\")", "successors": []}, {"id": 5, "label": "    creds: EmailCredentials = SchemaField(description=\"SMTP credentials\", default=EmailCredentials())", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 38, "end_line": 42, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        status: str = SchemaField(description=\"Status of the email sending operation\")\n        error: str = SchemaField(\n            description=\"Error message if the email sending failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "    status: str = SchemaField(description=\"Status of the email sending operation\")", "successors": []}, {"id": 3, "label": "    error: str = SchemaField(description=\"Error message if the email sending failed\")", "successors": []}]}]}], "simplified_code": "class SendEmailBlock(Block):\n        )\n\n        )\n\n        )\n\n    @staticmethod\n        return \"Email sent successfully\"\n\n        )", "blocks": [{"id": 1, "label": "class SendEmailBlock(Block):\n@staticmethod", "successors": [{"id": 3, "label": "return \"Email sent successfully\"", "successors": []}]}]}], "simplified_code": "import smtplib\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\n\nfrom pydantic import BaseModel, ConfigDict\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import BlockSecret, SchemaField, SecretField\n\n\n    model_config = ConfigDict(title=\"Email Credentials\")\n\n\n        )", "blocks": [{"id": 1, "label": "import smtplib\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\n\nfrom pydantic import BaseModel, ConfigDict\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import BlockSecret, SchemaField, SecretField\n\n\nmodel_config = ConfigDict(title=\"Email Credentials\")\n\n", "successors": []}]}
{"file_name": "143.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 153, "functions": [{"name": "launch_darkly_context", "type": "function", "start_line": 31, "end_line": 39, "functions": [], "classes": [], "simplified_code": "def launch_darkly_context():\n    if settings.config.app_env != backend.util.settings.AppEnvironment.LOCAL:\n        initialize_launchdarkly()\n        try:\n            yield\n        finally:\n            shutdown_launchdarkly()\n    else:\n        yield", "blocks": [{"id": 1, "label": "def launch_darkly_context():\nif settings.config.app_env != backend.util.settings.AppEnvironment.LOCAL:", "successors": [{"id": 3, "label": "initialize_launchdarkly()\ntry:", "successors": [{"id": 5, "label": "yield", "successors": []}, {"id": 6, "label": "finally:\nshutdown_launchdarkly()", "successors": []}]}, {"id": 8, "label": "yield", "successors": []}]}]}, {"name": "lifespan_context", "type": "function", "start_line": 43, "end_line": 50, "functions": [], "classes": [], "simplified_code": "async def lifespan_context(app: fastapi.FastAPI):\n    await backend.data.db.connect()\n    await backend.data.block.initialize_blocks()\n    await backend.data.user.migrate_and_encrypt_user_integrations()\n    await backend.data.graph.fix_llm_provider_credentials()\n    with launch_darkly_context():\n        yield\n    await backend.data.db.disconnect()", "blocks": [{"id": 1, "label": "async def lifespan_context(app: fastapi.FastAPI):\nawait backend.data.db.connect()\nawait backend.data.block.initialize_blocks()\nawait backend.data.user.migrate_and_encrypt_user_integrations()\nawait backend.data.graph.fix_llm_provider_credentials()", "successors": [{"id": 3, "label": "with launch_darkly_context():\nyield", "successors": []}, {"id": 5, "label": "await backend.data.db.disconnect()", "successors": []}]}]}, {"name": "handle_internal_http_error", "type": "function", "start_line": 72, "end_line": 84, "functions": [{"name": "handler", "type": "function", "start_line": 73, "end_line": 82, "functions": [], "classes": [], "simplified_code": "    def handler(request: fastapi.Request, exc: Exception):\n        if log_error:\n            logger.exception(f\"{request.method} {request.url.path} failed: {exc}\")\n        return fastapi.responses.JSONResponse(\n            content={\n                \"message\": f\"{request.method} {request.url.path} failed\",\n                \"detail\": str(exc),\n            },\n            status_code=status_code,\n        )", "blocks": [{"id": 1, "label": "def handler(request: fastapi.Request, exc: Exception):", "successors": [{"id": 2, "label": "if log_error:\nlogger.exception(f\"{request.method} {request.url.path} failed: {exc}\")", "successors": []}, {"id": 4, "label": "return fastapi.responses.JSONResponse(\n    content={\n        \"message\": f\"{request.method} {request.url.path} failed\",\n        \"detail\": str(exc),\n    },\n    status_code=status_code,\n)", "successors": []}]}]}], "classes": [], "simplified_code": "def handle_internal_http_error(status_code: int = 500, log_error: bool = True):\n        )\n\n    return handler", "blocks": [{"id": 1, "label": "def handle_internal_http_error(status_code: int = 500, log_error: bool = True):\n    def handler(req, exc): pass", "successors": [{"id": 3, "label": "    if log_error:", "successors": [{"id": 4, "label": "        print(\"Error logged\")\n    return handler", "successors": []}, {"id": 5, "label": "    return handler", "successors": []}]}]}]}, {"name": "health", "type": "function", "start_line": 99, "end_line": 100, "functions": [], "classes": [], "simplified_code": "async def health():\n    return {\"status\": \"healthy\"}", "blocks": [{"id": 1, "label": "async def health():\n    return {\"status\": \"healthy\"}", "successors": []}]}], "classes": [{"name": "AgentServer", "type": "class", "start_line": 103, "end_line": 153, "functions": [{"name": "run", "type": "function", "start_line": 104, "end_line": 116, "functions": [], "classes": [], "simplified_code": "    def run(self):\n        server_app = starlette.middleware.cors.CORSMiddleware(\n            app=app,\n            allow_origins=settings.config.backend_cors_allow_origins,\n            allow_credentials=True,\n            allow_methods=[\"*\"],  # Allows all methods\n            allow_headers=[\"*\"],  # Allows all headers\n        )\n        uvicorn.run(\n            server_app,\n            host=backend.util.settings.Config().agent_api_host,\n            port=backend.util.settings.Config().agent_api_port,\n        )", "blocks": [{"id": 1, "label": "def run(self):\nserver_app = starlette.middleware.cors.CORSMiddleware(\n    app=app,\n    allow_origins=settings.config.backend_cors_allow_origins,\n    allow_credentials=True,\n    allow_methods=[\"*\"],  # Allows all methods\n    allow_headers=[\"*\"],  # Allows all headers\n)", "successors": [{"id": 3, "label": "uvicorn.run(\n    server_app,\n    host=backend.util.settings.Config().agent_api_host,\n    port=backend.util.settings.Config().agent_api_port,\n)", "successors": []}]}]}, {"name": "test_execute_graph", "type": "function", "start_line": 119, "end_line": 122, "functions": [], "classes": [], "simplified_code": "    async def test_execute_graph(\n        graph_id: str, node_input: dict[typing.Any, typing.Any], user_id: str\n    ):\n        return backend.server.routers.v1.execute_graph(graph_id, node_input, user_id)", "blocks": [{"id": 1, "label": "async def test_execute_graph(\n    graph_id: str, node_input: dict[typing.Any, typing.Any], user_id: str\n):\n    return backend.server.routers.v1.execute_graph(graph_id, node_input, user_id)", "successors": []}]}, {"name": "test_create_graph", "type": "function", "start_line": 125, "end_line": 129, "functions": [], "classes": [], "simplified_code": "    async def test_create_graph(\n        create_graph: backend.server.routers.v1.CreateGraph,\n        user_id: str,\n    ):\n        return await backend.server.routers.v1.create_new_graph(create_graph, user_id)", "blocks": [{"id": 1, "label": "async def test_create_graph(\n    create_graph: backend.server.routers.v1.CreateGraph,\n    user_id: str,\n):\n    return await backend.server.routers.v1.create_new_graph(create_graph, user_id)", "successors": []}]}, {"name": "test_get_graph_run_status", "type": "function", "start_line": 132, "end_line": 138, "functions": [], "classes": [], "simplified_code": "    async def test_get_graph_run_status(graph_exec_id: str, user_id: str):\n        execution = await backend.data.graph.get_execution(\n            user_id=user_id, execution_id=graph_exec_id\n        )\n        if not execution:\n            raise ValueError(f\"Execution {graph_exec_id} not found\")\n        return execution.status", "blocks": [{"id": 1, "label": "async def test_get_graph_run_status(graph_exec_id: str, user_id: str):\nexecution = await backend.data.graph.get_execution(user_id=user_id, execution_id=graph_exec_id)", "successors": [{"id": 3, "label": "if not execution:", "successors": [{"id": 4, "label": "raise ValueError(f\"Execution {graph_exec_id} not found\")", "successors": []}, {"id": 5, "label": "return execution.status", "successors": []}]}]}]}, {"name": "test_get_graph_run_node_execution_results", "type": "function", "start_line": 141, "end_line": 146, "functions": [], "classes": [], "simplified_code": "    async def test_get_graph_run_node_execution_results(\n        graph_id: str, graph_exec_id: str, user_id: str\n    ):\n        return await backend.server.routers.v1.get_graph_run_node_execution_results(\n            graph_id, graph_exec_id, user_id\n        )", "blocks": [{"id": 1, "label": "async def test_get_graph_run_node_execution_results(\n    graph_id: str, graph_exec_id: str, user_id: str\n):\nreturn await backend.server.routers.v1.get_graph_run_node_execution_results(\n    graph_id, graph_exec_id, user_id\n)", "successors": []}]}, {"name": "test_delete_graph", "type": "function", "start_line": 149, "end_line": 150, "functions": [], "classes": [], "simplified_code": "    async def test_delete_graph(graph_id: str, user_id: str):\n        return await backend.server.routers.v1.delete_graph(graph_id, user_id)", "blocks": [{"id": 1, "label": "async def test_delete_graph(graph_id: str, user_id: str):\nreturn await backend.server.routers.v1.delete_graph(graph_id, user_id)", "successors": []}]}, {"name": "set_test_dependency_overrides", "type": "function", "start_line": 152, "end_line": 153, "functions": [], "classes": [], "simplified_code": "    def set_test_dependency_overrides(self, overrides: dict):\n        app.dependency_overrides.update(overrides)", "blocks": [{"id": 1, "label": "def set_test_dependency_overrides(self, overrides: dict):\napp.dependency_overrides.update(overrides)", "successors": []}]}], "classes": [], "simplified_code": "class AgentServer(backend.util.service.AppProcess):\n        )\n\n    @staticmethod\n        return backend.server.routers.v1.execute_graph(graph_id, node_input, user_id)\n\n    @staticmethod\n        return await backend.server.routers.v1.create_new_graph(create_graph, user_id)\n\n    @staticmethod\n        return execution.status\n\n    @staticmethod\n        )\n\n    @staticmethod\n        return await backend.server.routers.v1.delete_graph(graph_id, user_id)\n\n        app.dependency_overrides.update(overrides)", "blocks": [{"id": 1, "label": "class AgentServer(backend.util.service.AppProcess):", "successors": [{"id": 2, "label": "@staticmethod\nreturn backend.server.routers.v1.execute_graph(graph_id, node_input, user_id)", "successors": []}, {"id": 3, "label": "@staticmethod\nreturn await backend.server.routers.v1.create_new_graph(create_graph, user_id)", "successors": []}, {"id": 4, "label": "@staticmethod\nreturn execution.status", "successors": []}, {"id": 5, "label": "@staticmethod", "successors": []}, {"id": 6, "label": "@staticmethod\nreturn await backend.server.routers.v1.delete_graph(graph_id, user_id)", "successors": []}, {"id": 7, "label": "app.dependency_overrides.update(overrides)", "successors": []}]}]}], "simplified_code": "import contextlib\nimport logging\nimport typing\n\nimport fastapi\nimport fastapi.responses\nimport starlette.middleware.cors\nimport uvicorn\nfrom autogpt_libs.feature_flag.client import (\n    initialize_launchdarkly,\n    shutdown_launchdarkly,\n)\n\nimport backend.data.block\nimport backend.data.db\nimport backend.data.graph\nimport backend.data.user\nimport backend.server.routers.v1\nimport backend.server.v2.library.routes\nimport backend.server.v2.store.routes\nimport backend.util.service\nimport backend.util.settings\n\nsettings = backend.util.settings.Settings()\nlogger = logging.getLogger(__name__)\n\nlogging.getLogger(\"autogpt_libs\").setLevel(logging.INFO)\n\n\n@contextlib.contextmanager\n        yield\n\n\n@contextlib.asynccontextmanager\n    await backend.data.db.disconnect()\n\n\ndocs_url = (\n    \"/docs\"\n    if settings.config.app_env == backend.util.settings.AppEnvironment.LOCAL\n    else None\n)\n\napp = fastapi.FastAPI(\n    title=\"AutoGPT Agent Server\",\n    description=(\n        \"This server is used to execute agents that are created by the \"\n        \"AutoGPT system.\"\n    ),\n    summary=\"AutoGPT Agent Server\",\n    version=\"0.1\",\n    lifespan=lifespan_context,\n    docs_url=docs_url,\n)\n\n\n    return handler\n\n\napp.add_exception_handler(ValueError, handle_internal_http_error(400))\napp.add_exception_handler(Exception, handle_internal_http_error(500))\napp.include_router(backend.server.routers.v1.v1_router, tags=[\"v1\"], prefix=\"/api\")\napp.include_router(\n    backend.server.v2.store.routes.router, tags=[\"v2\"], prefix=\"/api/store\"\n)\napp.include_router(\n    backend.server.v2.library.routes.router, tags=[\"v2\"], prefix=\"/api/library\"\n)\n\n\n@app.get(path=\"/health\", tags=[\"health\"], dependencies=[])\n    return {\"status\": \"healthy\"}\n\n\n        app.dependency_overrides.update(overrides)", "blocks": [{"id": 1, "label": "import contextlib\nimport logging\nimport typing\n\nimport fastapi\nimport fastapi.responses\nimport starlette.middleware.cors\nimport uvicorn\nfrom autogpt_libs.feature_flag.client import (initialize_launchdarkly, shutdown_launchdarkly,)\n\nimport backend.data.block\nimport backend.data.db\nimport backend.data.graph\nimport backend.data.user\nimport backend.server.routers.v1\nimport backend.server.v2.library.routes\nimport backend.server.v2.store.routes\nimport backend.util.service\nimport backend.util.settings\n\nsettings = backend.util.settings.Settings()\nlogger = logging.getLogger(__name__)\n\nlogging.getLogger(\"autogpt_libs\").setLevel(logging.INFO)\n@contextlib.contextmanager", "successors": [{"id": 3, "label": "yield\n@contextlib.asynccontextmanager", "successors": [{"id": 5, "label": "await backend.data.db.disconnect()\ndocs_url = (\"/docs\" if settings.config.app_env == backend.util.settings.AppEnvironment.LOCAL else None)", "successors": [{"id": 7, "label": "app = fastapi.FastAPI(title=\"AutoGPT Agent Server\", description=(\"This server is used to execute agents that are created by the \" \"AutoGPT system.\"), summary=\"AutoGPT Agent Server\", version=\"0.1\", lifespan=lifespan_context, docs_url=docs_url)\nreturn handler", "successors": [{"id": 9, "label": "app.add_exception_handler(ValueError, handle_internal_http_error(400))\napp.add_exception_handler(Exception, handle_internal_http_error(500))\napp.include_router(backend.server.routers.v1.v1_router, tags=[\"v1\"], prefix=\"/api\")\napp.include_router(backend.server.v2.store.routes.router, tags=[\"v2\"], prefix=\"/api/store\")\napp.include_router(backend.server.v2.library.routes.router, tags=[\"v2\"], prefix=\"/api/library\")\n@app.get(path=\"/health\", tags=[\"health\"], dependencies=[])", "successors": [{"id": 11, "label": "return {\"status\": \"healthy\"}\napp.dependency_overrides.update(overrides)", "successors": []}]}]}]}]}]}]}
{"file_name": "144.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 14, "functions": [], "classes": [{"name": "JsonFileHandler", "type": "class", "start_line": 7, "end_line": 14, "functions": [{"name": "format", "type": "function", "start_line": 8, "end_line": 10, "functions": [], "classes": [], "simplified_code": "    def format(self, record: logging.LogRecord) -> str:\n        record.json_data = json.loads(record.getMessage())\n        return json.dumps(getattr(record, \"json_data\"), ensure_ascii=False, indent=4)", "blocks": [{"id": 1, "label": "def format(self, record: logging.LogRecord) -> str:\nrecord.json_data = json.loads(record.getMessage())", "successors": [{"id": 3, "label": "return json.dumps(getattr(record, \"json_data\"), ensure_ascii=False, indent=4)", "successors": []}]}]}, {"name": "emit", "type": "function", "start_line": 12, "end_line": 14, "functions": [], "classes": [], "simplified_code": "    def emit(self, record: logging.LogRecord) -> None:\n        with open(self.baseFilename, \"w\", encoding=\"utf-8\") as f:\n            f.write(self.format(record))", "blocks": [{"id": 1, "label": "def emit(self, record: logging.LogRecord) -> None:\nwith open(self.baseFilename, \"w\", encoding=\"utf-8\") as f:", "successors": [{"id": 3, "label": "f.write(self.format(record))", "successors": []}]}]}], "simplified_code": "class JsonFileHandler(logging.FileHandler):\n        return json.dumps(getattr(record, \"json_data\"), ensure_ascii=False, indent=4)\n\n            f.write(self.format(record))", "blocks": [{"id": 1, "label": "class JsonFileHandler(logging.FileHandler):", "successors": [{"id": 2, "label": "return json.dumps(getattr(record, \"json_data\"), ensure_ascii=False, indent=4)", "successors": []}, {"id": 3, "label": "f.write(self.format(record))", "successors": []}]}]}], "simplified_code": "from __future__ import annotations\n\nimport json\nimport logging\n\n\n            f.write(self.format(record))", "blocks": [{"id": 1, "label": "from __future__ import annotations\n\nimport json\nimport logging\n        f.write(self.format(record))", "successors": []}]}
{"file_name": "145.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 117, "functions": [], "classes": [{"name": "Suit", "type": "class", "start_line": 6, "end_line": 11, "functions": [], "simplified_code": "class Suit(Enum):\n\n    HEART = 0\n    DIAMOND = 1\n    CLUBS = 2\n    SPADE = 3", "blocks": [{"id": 1, "label": "class Suit(Enum):\n    HEART = 0\n    DIAMOND = 1\n    CLUBS = 2\n    SPADE = 3", "successors": []}]}, {"name": "Card", "type": "class", "start_line": 14, "end_line": 29, "functions": [{"name": "__init__", "type": "function", "start_line": 16, "end_line": 19, "functions": [], "classes": [], "simplified_code": "    def __init__(self, value, suit):\n        self.value = value\n        self.suit = suit\n        self.is_available = True", "blocks": [{"id": 1, "label": "def __init__(self, value, suit):\nself.value = value\nself.suit = suit\nself.is_available = True", "successors": []}]}, {"name": "value", "type": "function", "start_line": 23, "end_line": 24, "functions": [], "classes": [], "simplified_code": "    def value(self):\n        pass", "blocks": [{"id": 1, "label": "def value(self):\npass", "successors": []}]}, {"name": "value", "type": "function", "start_line": 28, "end_line": 29, "functions": [], "classes": [], "simplified_code": "    def value(self, other):\n        pass", "blocks": [{"id": 1, "label": "def value(self, other):\n    pass", "successors": []}]}], "simplified_code": "class Card(metaclass=ABCMeta):\n\n        self.is_available = True\n\n    @property\n    @abstractmethod\n        pass\n\n    @value.setter\n    @abstractmethod\n        pass", "blocks": [{"id": 1, "label": "class Card(metaclass=ABCMeta):", "successors": [{"id": 2, "label": "self.is_available = True", "successors": []}, {"id": 3, "label": "@property\n@abstractmethod\npass", "successors": []}, {"id": 4, "label": "@value.setter\n@abstractmethod\npass", "successors": []}]}]}, {"name": "BlackJackCard", "type": "class", "start_line": 32, "end_line": 58, "functions": [{"name": "__init__", "type": "function", "start_line": 34, "end_line": 35, "functions": [], "classes": [], "simplified_code": "    def __init__(self, value, suit):\n        super(BlackJackCard, self).__init__(value, suit)", "blocks": [{"id": 1, "label": "def __init__(self, value, suit):\n    super(BlackJackCard, self).__init__(value, suit)", "successors": []}]}, {"name": "is_ace", "type": "function", "start_line": 37, "end_line": 38, "functions": [], "classes": [], "simplified_code": "    def is_ace(self):\n        return True if self._value == 1 else False", "blocks": [{"id": 1, "label": "def is_ace(self):\nreturn True if self._value == 1 else False", "successors": []}]}, {"name": "is_face_card", "type": "function", "start_line": 40, "end_line": 42, "functions": [], "classes": [], "simplified_code": "    def is_face_card(self):\n        \"\"\"Jack = 11, Queen = 12, King = 13\"\"\"\n        return True if 10 < self._value <= 13 else False", "blocks": [{"id": 1, "label": "def is_face_card(self):\n\"\"\"Jack = 11, Queen = 12, King = 13\"\"\"", "successors": [{"id": 3, "label": "return True if 10 < self._value <= 13 else False", "successors": []}]}]}, {"name": "value", "type": "function", "start_line": 45, "end_line": 51, "functions": [], "classes": [], "simplified_code": "    def value(self):\n        if self.is_ace() == 1:\n            return 1\n        elif self.is_face_card():\n            return 10\n        else:\n            return self._value", "blocks": [{"id": 1, "label": "def value(self):\nif self.is_ace() == 1:", "successors": [{"id": 3, "label": "return 1", "successors": []}, {"id": 4, "label": "elif self.is_face_card():", "successors": [{"id": 5, "label": "return 10", "successors": []}, {"id": 6, "label": "else:\nreturn self._value", "successors": []}]}]}]}, {"name": "value", "type": "function", "start_line": 54, "end_line": 58, "functions": [], "classes": [], "simplified_code": "    def value(self, new_value):\n        if 1 <= new_value <= 13:\n            self._value = new_value\n        else:\n            raise ValueError('Invalid card value: {}'.format(new_value))", "blocks": [{"id": 1, "label": "def value(self, new_value):\nif 1 <= new_value <= 13:", "successors": [{"id": 3, "label": "self._value = new_value", "successors": []}, {"id": 4, "label": "raise ValueError('Invalid card value: {}'.format(new_value))", "successors": []}]}]}], "simplified_code": "class BlackJackCard(Card):\n\n        super(BlackJackCard, self).__init__(value, suit)\n\n        return True if self._value == 1 else False\n\n        return True if 10 < self._value <= 13 else False\n\n    @property\n            return self._value\n\n    @value.setter\n            raise ValueError('Invalid card value: {}'.format(new_value))", "blocks": [{"id": 1, "label": "class BlackJackCard(Card):", "successors": [{"id": 2, "label": "super(BlackJackCard, self).__init__(value, suit)", "successors": [{"id": 3, "label": "return True if self._value == 1 else False", "successors": []}, {"id": 4, "label": "return True if 10 < self._value <= 13 else False", "successors": []}]}, {"id": 5, "label": "@property\nreturn self._value", "successors": [{"id": 7, "label": "@value.setter\nraise ValueError('Invalid card value: {}'.format(new_value))", "successors": []}]}]}]}, {"name": "Hand", "type": "class", "start_line": 61, "end_line": 73, "functions": [{"name": "__init__", "type": "function", "start_line": 63, "end_line": 64, "functions": [], "classes": [], "simplified_code": "    def __init__(self, cards):\n        self.cards = cards", "blocks": [{"id": 1, "label": "def __init__(self, cards):\n    self.cards = cards", "successors": []}]}, {"name": "add_card", "type": "function", "start_line": 66, "end_line": 67, "functions": [], "classes": [], "simplified_code": "    def add_card(self, card):\n        self.cards.append(card)", "blocks": [{"id": 1, "label": "def add_card(self, card):\n    self.cards.append(card)", "successors": []}]}, {"name": "score", "type": "function", "start_line": 69, "end_line": 73, "functions": [], "classes": [], "simplified_code": "    def score(self):\n        total_value = 0\n        for card in self.cards:\n            total_value += card.value\n        return total_value", "blocks": [{"id": 1, "label": "total_value = 0", "successors": [{"id": 2, "label": "for card in self.cards:", "successors": [{"id": 3, "label": "    total_value += card.value\nreturn total_value", "successors": []}, {"id": 4, "label": "return total_value", "successors": []}]}]}]}], "simplified_code": "class Hand(object):\n\n        self.cards = cards\n\n        self.cards.append(card)\n\n        return total_value", "blocks": [{"id": 1, "label": "class Hand(object):\nself.cards = cards", "successors": [{"id": 3, "label": "self.cards.append(card)\nreturn total_value", "successors": []}]}]}, {"name": "BlackJackHand", "type": "class", "start_line": 76, "end_line": 95, "functions": [{"name": "__init__", "type": "function", "start_line": 80, "end_line": 81, "functions": [], "classes": [], "simplified_code": "    def __init__(self, cards):\n        super(BlackJackHand, self).__init__(cards)", "blocks": [{"id": 1, "label": "def __init__(self, cards):\nsuper(BlackJackHand, self).__init__(cards)", "successors": []}]}, {"name": "score", "type": "function", "start_line": 83, "end_line": 91, "functions": [], "classes": [], "simplified_code": "    def score(self):\n        min_over = sys.MAXSIZE\n        max_under = -sys.MAXSIZE\n        for score in self.possible_scores():\n            if self.BLACKJACK < score < min_over:\n                min_over = score\n            elif max_under < score <= self.BLACKJACK:\n                max_under = score\n        return max_under if max_under != -sys.MAXSIZE else min_over", "blocks": [{"id": 1, "label": "min_over = sys.MAXSIZE\nmax_under = -sys.MAXSIZE", "successors": [{"id": 2, "label": "for score in self.possible_scores():", "successors": [{"id": 3, "label": "if self.BLACKJACK < score < min_over:\nmin_over = score", "successors": [{"id": 6, "label": "return max_under if max_under != -sys.MAXSIZE else min_over", "successors": []}]}, {"id": 5, "label": "elif max_under < score <= self.BLACKJACK:\nmax_under = score", "successors": [{"id": 6, "label": "return max_under if max_under != -sys.MAXSIZE else min_over", "successors": []}]}]}]}]}, {"name": "possible_scores", "type": "function", "start_line": 93, "end_line": 95, "functions": [], "classes": [], "simplified_code": "    def possible_scores(self):\n        \"\"\"Return a list of possible scores, taking Aces into account.\"\"\"\n        pass", "blocks": [{"id": 1, "label": "def possible_scores(self):\n\"\"\"Return a list of possible scores, taking Aces into account.\"\"\"", "successors": [{"id": 3, "label": "pass", "successors": []}]}]}], "simplified_code": "class BlackJackHand(Hand):\n\n    BLACKJACK = 21\n\n        super(BlackJackHand, self).__init__(cards)\n\n        return max_under if max_under != -sys.MAXSIZE else min_over\n\n        pass", "blocks": [{"id": 1, "label": "class BlackJackHand(Hand):", "successors": [{"id": 2, "label": "BLACKJACK = 21", "successors": []}, {"id": 3, "label": "super(BlackJackHand, self).__init__(cards)", "successors": []}, {"id": 4, "label": "return max_under if max_under != -sys.MAXSIZE else min_over", "successors": []}, {"id": 5, "label": "pass", "successors": []}]}]}, {"name": "Deck", "type": "class", "start_line": 98, "end_line": 117, "functions": [{"name": "__init__", "type": "function", "start_line": 100, "end_line": 102, "functions": [], "classes": [], "simplified_code": "    def __init__(self, cards):\n        self.cards = cards\n        self.deal_index = 0", "blocks": [{"id": 1, "label": "def __init__(self, cards):", "successors": [{"id": 2, "label": "    self.cards = cards", "successors": []}, {"id": 3, "label": "    self.deal_index = 0", "successors": []}]}]}, {"name": "remaining_cards", "type": "function", "start_line": 104, "end_line": 105, "functions": [], "classes": [], "simplified_code": "    def remaining_cards(self):\n        return len(self.cards) - self.deal_index", "blocks": [{"id": 1, "label": "def remaining_cards(self):\nreturn len(self.cards) - self.deal_index", "successors": []}]}, {"name": "deal_card", "type": "function", "start_line": 107, "end_line": 114, "functions": [], "classes": [], "simplified_code": "    def deal_card(self):\n        try:\n            card = self.cards[self.deal_index]\n            card.is_available = False\n            self.deal_index += 1\n        except IndexError:\n            return None\n        return card", "blocks": [{"id": 1, "label": "def deal_card(self):\ntry:", "successors": [{"id": 3, "label": "card = self.cards[self.deal_index]\ncard.is_available = False\nself.deal_index += 1\nreturn card", "successors": []}, {"id": 4, "label": "except IndexError:\nreturn None", "successors": []}]}]}, {"name": "shuffle", "type": "function", "start_line": 116, "end_line": 117, "functions": [], "classes": [], "simplified_code": "    def shuffle(self):\n        pass", "blocks": [{"id": 1, "label": "def shuffle(self):\npass", "successors": []}]}], "simplified_code": "class Deck(object):\n\n        self.deal_index = 0\n\n        return len(self.cards) - self.deal_index\n\n        return card\n\n        pass", "blocks": [{"id": 1, "label": "self.deal_index = 0\nreturn len(self.cards) - self.deal_index", "successors": []}]}], "simplified_code": "from abc import ABCMeta, abstractmethod\nfrom enum import Enum\nimport sys\n\n\n    SPADE = 3\n\n\n        pass\n\n\n            raise ValueError('Invalid card value: {}'.format(new_value))\n\n\n        return total_value\n\n\n        pass\n\n\n        pass", "blocks": [{"id": 1, "label": "from abc import ABCMeta, abstractmethod\nfrom enum import Enum\nimport sys\nSPADE = 3", "successors": [{"id": 3, "label": "pass", "successors": []}]}]}
{"file_name": "146.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 577, "functions": [{"name": "get_profile", "type": "function", "start_line": 31, "end_line": 47, "functions": [], "classes": [], "simplified_code": "async def get_profile(\n    user_id: typing.Annotated[\n        str, fastapi.Depends(autogpt_libs.auth.depends.get_user_id)\n    ]\n):\n    \"\"\"\n    Get the profile details for the authenticated user.\n    \"\"\"\n    try:\n        profile = await backend.server.v2.store.db.get_user_profile(user_id)\n        return profile\n    except Exception:\n        logger.exception(\"Exception occurred whilst getting user profile\")\n        return fastapi.responses.JSONResponse(\n            status_code=500,\n            content={\"detail\": \"An error occurred while retrieving the user profile\"},\n        )", "blocks": [{"id": 1, "label": "async def get_profile(\n    user_id: typing.Annotated[\n        str, fastapi.Depends(autogpt_libs.auth.depends.get_user_id)\n    ]\n):\ntry:", "successors": [{"id": 3, "label": "    profile = await backend.server.v2.store.db.get_user_profile(user_id)\n    return profile", "successors": []}, {"id": 4, "label": "except Exception:\n    logger.exception(\"Exception occurred whilst getting user profile\")\n    return fastapi.responses.JSONResponse(\n        status_code=500,\n        content={\"detail\": \"An error occurred while retrieving the user profile\"},\n    )", "successors": []}]}]}, {"name": "update_or_create_profile", "type": "function", "start_line": 56, "end_line": 85, "functions": [], "classes": [], "simplified_code": "async def update_or_create_profile(\n    profile: backend.server.v2.store.model.Profile,\n    user_id: typing.Annotated[\n        str, fastapi.Depends(autogpt_libs.auth.depends.get_user_id)\n    ],\n):\n    \"\"\"\n    Update the store profile for the authenticated user.\n\n    Args:\n        profile (Profile): The updated profile details\n        user_id (str): ID of the authenticated user\n\n    Returns:\n        CreatorDetails: The updated profile\n\n    Raises:\n        HTTPException: If there is an error updating the profile\n    \"\"\"\n    try:\n        updated_profile = await backend.server.v2.store.db.update_or_create_profile(\n            user_id=user_id, profile=profile\n        )\n        return updated_profile\n    except Exception:\n        logger.exception(\"Exception occurred whilst updating profile\")\n        return fastapi.responses.JSONResponse(\n            status_code=500,\n            content={\"detail\": \"An error occurred while updating the user profile\"},\n        )", "blocks": [{"id": 1, "label": "async def update_or_create_profile(\n    profile: backend.server.v2.store.model.Profile,\n    user_id: typing.Annotated[\n        str, fastapi.Depends(autogpt_libs.auth.depends.get_user_id)\n    ],\n):\n    try:", "successors": [{"id": 3, "label": "        updated_profile = await backend.server.v2.store.db.update_or_create_profile(\n            user_id=user_id, profile=profile\n        )\n        return updated_profile", "successors": []}, {"id": 5, "label": "    except Exception:\n        logger.exception(\"Exception occurred whilst updating profile\")", "successors": [{"id": 7, "label": "        return fastapi.responses.JSONResponse(\n            status_code=500,\n            content={\"detail\": \"An error occurred while updating the user profile\"},\n        )", "successors": []}]}]}]}, {"name": "get_agents", "type": "function", "start_line": 98, "end_line": 159, "functions": [], "classes": [], "simplified_code": "async def get_agents(\n    featured: bool = False,\n    creator: str | None = None,\n    sorted_by: str | None = None,\n    search_query: str | None = None,\n    category: str | None = None,\n    page: int = 1,\n    page_size: int = 20,\n):\n    \"\"\"\n    Get a paginated list of agents from the store with optional filtering and sorting.\n\n    Args:\n        featured (bool, optional): Filter to only show featured agents. Defaults to False.\n        creator (str | None, optional): Filter agents by creator username. Defaults to None.\n        sorted_by (str | None, optional): Sort agents by \"runs\" or \"rating\". Defaults to None.\n        search_query (str | None, optional): Search agents by name, subheading and description. Defaults to None.\n        category (str | None, optional): Filter agents by category. Defaults to None.\n        page (int, optional): Page number for pagination. Defaults to 1.\n        page_size (int, optional): Number of agents per page. Defaults to 20.\n\n    Returns:\n        StoreAgentsResponse: Paginated list of agents matching the filters\n\n    Raises:\n        HTTPException: If page or page_size are less than 1\n\n    Used for:\n    - Home Page Featured Agents\n    - Home Page Top Agents\n    - Search Results\n    - Agent Details - Other Agents By Creator\n    - Agent Details - Similar Agents\n    - Creator Details - Agents By Creator\n    \"\"\"\n    if page < 1:\n        raise fastapi.HTTPException(\n            status_code=422, detail=\"Page must be greater than 0\"\n        )\n\n    if page_size < 1:\n        raise fastapi.HTTPException(\n            status_code=422, detail=\"Page size must be greater than 0\"\n        )\n\n    try:\n        agents = await backend.server.v2.store.db.get_store_agents(\n            featured=featured,\n            creator=creator,\n            sorted_by=sorted_by,\n            search_query=search_query,\n            category=category,\n            page=page,\n            page_size=page_size,\n        )\n        return agents\n    except Exception:\n        logger.exception(\"Exception occured whilst getting store agents\")\n        return fastapi.responses.JSONResponse(\n            status_code=500,\n            content={\"detail\": \"An error occurred while retrieving the store agents\"},\n        )", "blocks": [{"id": 1, "label": "if page < 1:", "successors": [{"id": 2, "label": "    raise fastapi.HTTPException(\n        status_code=422, detail=\"Page must be greater than 0\"\n    )", "successors": []}, {"id": 3, "label": "if page_size < 1:", "successors": [{"id": 4, "label": "    raise fastapi.HTTPException(\n        status_code=422, detail=\"Page size must be greater than 0\"\n    )", "successors": []}, {"id": 5, "label": "try:", "successors": [{"id": 6, "label": "    agents = await backend.server.v2.store.db.get_store_agents(\n        featured=featured,\n        creator=creator,\n        sorted_by=sorted_by,\n        search_query=search_query,\n        category=category,\n        page=page,\n        page_size=page_size,\n    )\n    return agents", "successors": []}, {"id": 8, "label": "except Exception:\n    logger.exception(\"Exception occured whilst getting store agents\")", "successors": [{"id": 10, "label": "    return fastapi.responses.JSONResponse(\n        status_code=500,\n        content={\"detail\": \"An error occurred while retrieving the store agents\"},\n    )", "successors": []}]}]}]}]}]}, {"name": "get_agent", "type": "function", "start_line": 167, "end_line": 188, "functions": [], "classes": [], "simplified_code": "async def get_agent(username: str, agent_name: str):\n    \"\"\"\n    This is only used on the AgentDetails Page\n\n    It returns the store listing agents details.\n    \"\"\"\n    try:\n        username = urllib.parse.unquote(username).lower()\n        # URL decode the agent name since it comes from the URL path\n        agent_name = urllib.parse.unquote(agent_name).lower()\n        agent = await backend.server.v2.store.db.get_store_agent_details(\n            username=username, agent_name=agent_name\n        )\n        return agent\n    except Exception:\n        logger.exception(\"Exception occurred whilst getting store agent details\")\n        return fastapi.responses.JSONResponse(\n            status_code=500,\n            content={\n                \"detail\": \"An error occurred while retrieving the store agent details\"\n            },\n        )", "blocks": [{"id": 1, "label": "async def get_agent(username: str, agent_name: str):\ntry:", "successors": [{"id": 3, "label": "username = urllib.parse.unquote(username).lower()\nagent_name = urllib.parse.unquote(agent_name).lower()\nagent = await backend.server.v2.store.db.get_store_agent_details(\n    username=username, agent_name=agent_name\n)\nreturn agent", "successors": []}, {"id": 4, "label": "except Exception:\nlogger.exception(\"Exception occurred whilst getting store agent details\")\nreturn fastapi.responses.JSONResponse(\n    status_code=500,\n    content={\n        \"detail\": \"An error occurred while retrieving the store agent details\"\n    },\n)", "successors": []}]}]}, {"name": "create_review", "type": "function", "start_line": 197, "end_line": 234, "functions": [], "classes": [], "simplified_code": "async def create_review(\n    username: str,\n    agent_name: str,\n    review: backend.server.v2.store.model.StoreReviewCreate,\n    user_id: typing.Annotated[\n        str, fastapi.Depends(autogpt_libs.auth.depends.get_user_id)\n    ],\n):\n    \"\"\"\n    Create a review for a store agent.\n\n    Args:\n        username: Creator's username\n        agent_name: Name/slug of the agent\n        review: Review details including score and optional comments\n        user_id: ID of authenticated user creating the review\n\n    Returns:\n        The created review\n    \"\"\"\n    try:\n        username = urllib.parse.unquote(username).lower()\n        agent_name = urllib.parse.unquote(agent_name)\n        # Create the review\n        created_review = await backend.server.v2.store.db.create_store_review(\n            user_id=user_id,\n            store_listing_version_id=review.store_listing_version_id,\n            score=review.score,\n            comments=review.comments,\n        )\n\n        return created_review\n    except Exception:\n        logger.exception(\"Exception occurred whilst creating store review\")\n        return fastapi.responses.JSONResponse(\n            status_code=500,\n            content={\"detail\": \"An error occurred while creating the store review\"},\n        )", "blocks": [{"id": 1, "label": "async def create_review(\n    username: str,\n    agent_name: str,\n    review: backend.server.v2.store.model.StoreReviewCreate,\n    user_id: typing.Annotated[\n        str, fastapi.Depends(autogpt_libs.auth.depends.get_user_id)\n    ],\n):\n    \"\"\"\n    Create a review for a store agent.\n\n    Args:\n        username: Creator's username\n        agent_name: Name/slug of the agent\n        review: Review details including score and optional comments\n        user_id: ID of authenticated user creating the review\n\n    Returns:\n        The created review\n    \"\"\"\n    try:", "successors": [{"id": 2, "label": "username = urllib.parse.unquote(username).lower()\nagent_name = urllib.parse.unquote(agent_name)\n# Create the review\ncreated_review = await backend.server.v2.store.db.create_store_review(\n    user_id=user_id,\n    store_listing_version_id=review.store_listing_version_id,\n    score=review.score,\n    comments=review.comments,\n)\n\nreturn created_review", "successors": []}, {"id": 3, "label": "except Exception:\nlogger.exception(\"Exception occurred whilst creating store review\")\nreturn fastapi.responses.JSONResponse(\n    status_code=500,\n    content={\"detail\": \"An error occurred while creating the store review\"},\n)", "successors": []}]}]}, {"name": "get_creators", "type": "function", "start_line": 247, "end_line": 290, "functions": [], "classes": [], "simplified_code": "async def get_creators(\n    featured: bool = False,\n    search_query: str | None = None,\n    sorted_by: str | None = None,\n    page: int = 1,\n    page_size: int = 20,\n):\n    \"\"\"\n    This is needed for:\n    - Home Page Featured Creators\n    - Search Results Page\n\n    ---\n\n    To support this functionality we need:\n    - featured: bool - to limit the list to just featured agents\n    - search_query: str - vector search based on the creators profile description.\n    - sorted_by: [agent_rating, agent_runs] -\n    \"\"\"\n    if page < 1:\n        raise fastapi.HTTPException(\n            status_code=422, detail=\"Page must be greater than 0\"\n        )\n\n    if page_size < 1:\n        raise fastapi.HTTPException(\n            status_code=422, detail=\"Page size must be greater than 0\"\n        )\n\n    try:\n        creators = await backend.server.v2.store.db.get_store_creators(\n            featured=featured,\n            search_query=search_query,\n            sorted_by=sorted_by,\n            page=page,\n            page_size=page_size,\n        )\n        return creators\n    except Exception:\n        logger.exception(\"Exception occurred whilst getting store creators\")\n        return fastapi.responses.JSONResponse(\n            status_code=500,\n            content={\"detail\": \"An error occurred while retrieving the store creators\"},\n        )", "blocks": [{"id": 1, "label": "async def get_creators(\n    featured: bool = False,\n    search_query: str | None = None,\n    sorted_by: str | None = None,\n    page: int = 1,\n    page_size: int = 20,\n):", "successors": [{"id": 2, "label": "if page < 1:\nraise fastapi.HTTPException(\n    status_code=422, detail=\"Page must be greater than 0\"\n)", "successors": []}, {"id": 4, "label": "if page_size < 1:\nraise fastapi.HTTPException(\n    status_code=422, detail=\"Page size must be greater than 0\"\n)", "successors": []}, {"id": 6, "label": "try:", "successors": [{"id": 7, "label": "creators = await backend.server.v2.store.db.get_store_creators(\n    featured=featured,\n    search_query=search_query,\n    sorted_by=sorted_by,\n    page=page,\n    page_size=page_size,\n)\nreturn creators", "successors": []}, {"id": 9, "label": "except Exception:\nlogger.exception(\"Exception occurred whilst getting store creators\")", "successors": [{"id": 11, "label": "return fastapi.responses.JSONResponse(\n    status_code=500,\n    content={\"detail\": \"An error occurred while retrieving the store creators\"},\n)", "successors": []}]}]}]}]}, {"name": "get_creator", "type": "function", "start_line": 298, "end_line": 318, "functions": [], "classes": [], "simplified_code": "async def get_creator(\n    username: str,\n):\n    \"\"\"\n    Get the details of a creator\n    - Creator Details Page\n    \"\"\"\n    try:\n        username = urllib.parse.unquote(username).lower()\n        creator = await backend.server.v2.store.db.get_store_creator_details(\n            username=username.lower()\n        )\n        return creator\n    except Exception:\n        logger.exception(\"Exception occurred whilst getting creator details\")\n        return fastapi.responses.JSONResponse(\n            status_code=500,\n            content={\n                \"detail\": \"An error occurred while retrieving the creator details\"\n            },\n        )", "blocks": [{"id": 1, "label": "async def get_creator(\n    username: str,\n):\ntry:", "successors": [{"id": 3, "label": "    username = urllib.parse.unquote(username).lower()\n    creator = await backend.server.v2.store.db.get_store_creator_details(\n        username=username.lower()\n    )\n    return creator", "successors": []}, {"id": 4, "label": "except Exception:\n    logger.exception(\"Exception occurred whilst getting creator details\")\n    return fastapi.responses.JSONResponse(\n        status_code=500,\n        content={\n            \"detail\": \"An error occurred while retrieving the creator details\"\n        },\n    )", "successors": []}]}]}, {"name": "get_my_agents", "type": "function", "start_line": 330, "end_line": 343, "functions": [], "classes": [], "simplified_code": "async def get_my_agents(\n    user_id: typing.Annotated[\n        str, fastapi.Depends(autogpt_libs.auth.depends.get_user_id)\n    ]\n):\n    try:\n        agents = await backend.server.v2.store.db.get_my_agents(user_id)\n        return agents\n    except Exception:\n        logger.exception(\"Exception occurred whilst getting my agents\")\n        return fastapi.responses.JSONResponse(\n            status_code=500,\n            content={\"detail\": \"An error occurred while retrieving the my agents\"},\n        )", "blocks": [{"id": 1, "label": "async def get_my_agents(\n    user_id: typing.Annotated[\n        str, fastapi.Depends(autogpt_libs.auth.depends.get_user_id)\n    ]\n):\ntry:", "successors": [{"id": 3, "label": "    agents = await backend.server.v2.store.db.get_my_agents(user_id)\n    return agents", "successors": []}, {"id": 4, "label": "except Exception:\n    logger.exception(\"Exception occurred whilst getting my agents\")\n    return fastapi.responses.JSONResponse(\n        status_code=500,\n        content={\"detail\": \"An error occurred while retrieving the my agents\"},\n    )", "successors": []}]}]}, {"name": "delete_submission", "type": "function", "start_line": 352, "end_line": 379, "functions": [], "classes": [], "simplified_code": "async def delete_submission(\n    user_id: typing.Annotated[\n        str, fastapi.Depends(autogpt_libs.auth.depends.get_user_id)\n    ],\n    submission_id: str,\n):\n    \"\"\"\n    Delete a store listing submission.\n\n    Args:\n        user_id (str): ID of the authenticated user\n        submission_id (str): ID of the submission to be deleted\n\n    Returns:\n        bool: True if the submission was successfully deleted, False otherwise\n    \"\"\"\n    try:\n        result = await backend.server.v2.store.db.delete_store_submission(\n            user_id=user_id,\n            submission_id=submission_id,\n        )\n        return result\n    except Exception:\n        logger.exception(\"Exception occurred whilst deleting store submission\")\n        return fastapi.responses.JSONResponse(\n            status_code=500,\n            content={\"detail\": \"An error occurred while deleting the store submission\"},\n        )", "blocks": [{"id": 1, "label": "async def delete_submission(...):\ntry:", "successors": [{"id": 3, "label": "result = await backend.server.v2.store.db.delete_store_submission(...)\nreturn result", "successors": []}, {"id": 4, "label": "except Exception:\nlogger.exception(\"Exception occurred whilst deleting store submission\")\nreturn fastapi.responses.JSONResponse(...)", "successors": []}]}]}, {"name": "get_submissions", "type": "function", "start_line": 388, "end_line": 432, "functions": [], "classes": [], "simplified_code": "async def get_submissions(\n    user_id: typing.Annotated[\n        str, fastapi.Depends(autogpt_libs.auth.depends.get_user_id)\n    ],\n    page: int = 1,\n    page_size: int = 20,\n):\n    \"\"\"\n    Get a paginated list of store submissions for the authenticated user.\n\n    Args:\n        user_id (str): ID of the authenticated user\n        page (int, optional): Page number for pagination. Defaults to 1.\n        page_size (int, optional): Number of submissions per page. Defaults to 20.\n\n    Returns:\n        StoreListingsResponse: Paginated list of store submissions\n\n    Raises:\n        HTTPException: If page or page_size are less than 1\n    \"\"\"\n    if page < 1:\n        raise fastapi.HTTPException(\n            status_code=422, detail=\"Page must be greater than 0\"\n        )\n\n    if page_size < 1:\n        raise fastapi.HTTPException(\n            status_code=422, detail=\"Page size must be greater than 0\"\n        )\n    try:\n        listings = await backend.server.v2.store.db.get_store_submissions(\n            user_id=user_id,\n            page=page,\n            page_size=page_size,\n        )\n        return listings\n    except Exception:\n        logger.exception(\"Exception occurred whilst getting store submissions\")\n        return fastapi.responses.JSONResponse(\n            status_code=500,\n            content={\n                \"detail\": \"An error occurred while retrieving the store submissions\"\n            },\n        )", "blocks": [{"id": 1, "label": "async def get_submissions( user_id: typing.Annotated[ str, fastapi.Depends(autogpt_libs.auth.depends.get_user_id) ], page: int = 1, page_size: int = 20, ):", "successors": [{"id": 2, "label": "if page < 1:\nraise fastapi.HTTPException( status_code=422, detail=\"Page must be greater than 0\" )", "successors": []}, {"id": 4, "label": "if page_size < 1:\nraise fastapi.HTTPException( status_code=422, detail=\"Page size must be greater than 0\" )", "successors": []}, {"id": 6, "label": "try:", "successors": [{"id": 7, "label": "listings = await backend.server.v2.store.db.get_store_submissions( user_id=user_id, page=page, page_size=page_size, )\nreturn listings", "successors": []}, {"id": 9, "label": "except Exception:\nlogger.exception(\"Exception occurred whilst getting store submissions\")", "successors": [{"id": 11, "label": "return fastapi.responses.JSONResponse( status_code=500, content={ \"detail\": \"An error occurred while retrieving the store submissions\" }, )", "successors": []}]}]}]}]}, {"name": "create_submission", "type": "function", "start_line": 441, "end_line": 479, "functions": [], "classes": [], "simplified_code": "async def create_submission(\n    submission_request: backend.server.v2.store.model.StoreSubmissionRequest,\n    user_id: typing.Annotated[\n        str, fastapi.Depends(autogpt_libs.auth.depends.get_user_id)\n    ],\n):\n    \"\"\"\n    Create a new store listing submission.\n\n    Args:\n        submission_request (StoreSubmissionRequest): The submission details\n        user_id (str): ID of the authenticated user submitting the listing\n\n    Returns:\n        StoreSubmission: The created store submission\n\n    Raises:\n        HTTPException: If there is an error creating the submission\n    \"\"\"\n    try:\n        submission = await backend.server.v2.store.db.create_store_submission(\n            user_id=user_id,\n            agent_id=submission_request.agent_id,\n            agent_version=submission_request.agent_version,\n            slug=submission_request.slug,\n            name=submission_request.name,\n            video_url=submission_request.video_url,\n            image_urls=submission_request.image_urls,\n            description=submission_request.description,\n            sub_heading=submission_request.sub_heading,\n            categories=submission_request.categories,\n        )\n        return submission\n    except Exception:\n        logger.exception(\"Exception occurred whilst creating store submission\")\n        return fastapi.responses.JSONResponse(\n            status_code=500,\n            content={\"detail\": \"An error occurred while creating the store submission\"},\n        )", "blocks": [{"id": 1, "label": "async def create_submission(\n    submission_request: backend.server.v2.store.model.StoreSubmissionRequest,\n    user_id: typing.Annotated[\n        str, fastapi.Depends(autogpt_libs.auth.depends.get_user_id)\n    ],\n):\n    try:", "successors": [{"id": 3, "label": "        submission = await backend.server.v2.store.db.create_store_submission(\n            user_id=user_id,\n            agent_id=submission_request.agent_id,\n            agent_version=submission_request.agent_version,\n            slug=submission_request.slug,\n            name=submission_request.name,\n            video_url=submission_request.video_url,\n            image_urls=submission_request.image_urls,\n            description=submission_request.description,\n            sub_heading=submission_request.sub_heading,\n            categories=submission_request.categories,\n        )\n        return submission", "successors": []}, {"id": 5, "label": "    except Exception:\n        logger.exception(\"Exception occurred whilst creating store submission\")", "successors": [{"id": 7, "label": "        return fastapi.responses.JSONResponse(\n            status_code=500,\n            content={\"detail\": \"An error occurred while creating the store submission\"},\n        )", "successors": []}]}]}]}, {"name": "upload_submission_media", "type": "function", "start_line": 487, "end_line": 516, "functions": [], "classes": [], "simplified_code": "async def upload_submission_media(\n    file: fastapi.UploadFile,\n    user_id: typing.Annotated[\n        str, fastapi.Depends(autogpt_libs.auth.depends.get_user_id)\n    ],\n):\n    \"\"\"\n    Upload media (images/videos) for a store listing submission.\n\n    Args:\n        file (UploadFile): The media file to upload\n        user_id (str): ID of the authenticated user uploading the media\n\n    Returns:\n        str: URL of the uploaded media file\n\n    Raises:\n        HTTPException: If there is an error uploading the media\n    \"\"\"\n    try:\n        media_url = await backend.server.v2.store.media.upload_media(\n            user_id=user_id, file=file\n        )\n        return media_url\n    except Exception:\n        logger.exception(\"Exception occurred whilst uploading submission media\")\n        return fastapi.responses.JSONResponse(\n            status_code=500,\n            content={\"detail\": \"An error occurred while uploading the media file\"},\n        )", "blocks": [{"id": 1, "label": "async def upload_submission_media(\n    file: fastapi.UploadFile,\n    user_id: typing.Annotated[\n        str, fastapi.Depends(autogpt_libs.auth.depends.get_user_id)\n    ],\n):\ntry:", "successors": [{"id": 3, "label": "media_url = await backend.server.v2.store.media.upload_media(\n    user_id=user_id, file=file\n)\nreturn media_url", "successors": []}, {"id": 5, "label": "except Exception:\nlogger.exception(\"Exception occurred whilst uploading submission media\")", "successors": [{"id": 7, "label": "return fastapi.responses.JSONResponse(\n    status_code=500,\n    content={\"detail\": \"An error occurred while uploading the media file\"},\n)", "successors": []}]}]}]}, {"name": "generate_image", "type": "function", "start_line": 524, "end_line": 577, "functions": [], "classes": [], "simplified_code": "async def generate_image(\n    agent_id: str,\n    user_id: typing.Annotated[\n        str, fastapi.Depends(autogpt_libs.auth.depends.get_user_id)\n    ],\n) -> fastapi.responses.Response:\n    \"\"\"\n    Generate an image for a store listing submission.\n\n    Args:\n        agent_id (str): ID of the agent to generate an image for\n        user_id (str): ID of the authenticated user\n\n    Returns:\n        JSONResponse: JSON containing the URL of the generated image\n    \"\"\"\n    try:\n        agent = await backend.data.graph.get_graph(agent_id, user_id=user_id)\n\n        if not agent:\n            raise fastapi.HTTPException(\n                status_code=404, detail=f\"Agent with ID {agent_id} not found\"\n            )\n        # Use .jpeg here since we are generating JPEG images\n        filename = f\"agent_{agent_id}.jpeg\"\n\n        existing_url = await backend.server.v2.store.media.check_media_exists(\n            user_id, filename\n        )\n        if existing_url:\n            logger.info(f\"Using existing image for agent {agent_id}\")\n            return fastapi.responses.JSONResponse(content={\"image_url\": existing_url})\n        # Generate agent image as JPEG\n        image = await backend.server.v2.store.image_gen.generate_agent_image(\n            agent=agent\n        )\n\n        # Create UploadFile with the correct filename and content_type\n        image_file = fastapi.UploadFile(\n            file=image,\n            filename=filename,\n        )\n\n        image_url = await backend.server.v2.store.media.upload_media(\n            user_id=user_id, file=image_file, use_file_name=True\n        )\n\n        return fastapi.responses.JSONResponse(content={\"image_url\": image_url})\n    except Exception:\n        logger.exception(\"Exception occurred whilst generating submission image\")\n        return fastapi.responses.JSONResponse(\n            status_code=500,\n            content={\"detail\": \"An error occurred while generating the image\"},\n        )", "blocks": [{"id": 1, "label": "async def generate_image(...) -> fastapi.responses.Response:", "successors": [{"id": 2, "label": "try:\nagent = await backend.data.graph.get_graph(agent_id, user_id=user_id)", "successors": [{"id": 4, "label": "if not agent:", "successors": [{"id": 5, "label": "raise fastapi.HTTPException(...)", "successors": []}, {"id": 6, "label": "filename = f\"agent_{agent_id}.jpeg\"\nexisting_url = await backend.server.v2.store.media.check_media_exists(user_id, filename)", "successors": [{"id": 8, "label": "if existing_url:", "successors": [{"id": 9, "label": "logger.info(f\"Using existing image for agent {agent_id}\")\nreturn fastapi.responses.JSONResponse(content={\"image_url\": existing_url})", "successors": []}, {"id": 11, "label": "image = await backend.server.v2.store.image_gen.generate_agent_image(agent=agent)\nimage_file = fastapi.UploadFile(file=image, filename=filename)", "successors": [{"id": 13, "label": "image_url = await backend.server.v2.store.media.upload_media(user_id=user_id, file=image_file, use_file_name=True)\nreturn fastapi.responses.JSONResponse(content={\"image_url\": image_url})", "successors": []}]}]}]}]}]}, {"id": 15, "label": "except Exception:\nlogger.exception(\"Exception occurred whilst generating submission image\")", "successors": [{"id": 17, "label": "return fastapi.responses.JSONResponse(status_code=500, content={\"detail\": \"An error occurred while generating the image\"})", "successors": []}]}]}]}], "classes": [], "simplified_code": "import logging\nimport typing\nimport urllib.parse\n\nimport autogpt_libs.auth.depends\nimport autogpt_libs.auth.middleware\nimport fastapi\nimport fastapi.responses\n\nimport backend.data.graph\nimport backend.server.v2.store.db\nimport backend.server.v2.store.image_gen\nimport backend.server.v2.store.media\nimport backend.server.v2.store.model\n\nlogger = logging.getLogger(__name__)\n\nrouter = fastapi.APIRouter()\n\n\n##############################################\n############### Profile Endpoints ############\n##############################################\n\n\n@router.get(\n    \"/profile\",\n    tags=[\"store\", \"private\"],\n    response_model=backend.server.v2.store.model.ProfileDetails,\n)\n        )\n\n\n@router.post(\n    \"/profile\",\n    tags=[\"store\", \"private\"],\n    dependencies=[fastapi.Depends(autogpt_libs.auth.middleware.auth_middleware)],\n    response_model=backend.server.v2.store.model.CreatorDetails,\n)\n        )\n\n\n##############################################\n############### Agent Endpoints ##############\n##############################################\n\n\n@router.get(\n    \"/agents\",\n    tags=[\"store\", \"public\"],\n    response_model=backend.server.v2.store.model.StoreAgentsResponse,\n)\n        )\n\n\n@router.get(\n    \"/agents/{username}/{agent_name}\",\n    tags=[\"store\", \"public\"],\n    response_model=backend.server.v2.store.model.StoreAgentDetails,\n)\n        )\n\n\n@router.post(\n    \"/agents/{username}/{agent_name}/review\",\n    tags=[\"store\"],\n    dependencies=[fastapi.Depends(autogpt_libs.auth.middleware.auth_middleware)],\n    response_model=backend.server.v2.store.model.StoreReview,\n)\n        )\n\n\n##############################################\n############# Creator Endpoints #############\n##############################################\n\n\n@router.get(\n    \"/creators\",\n    tags=[\"store\", \"public\"],\n    response_model=backend.server.v2.store.model.CreatorsResponse,\n)\n        )\n\n\n@router.get(\n    \"/creator/{username}\",\n    tags=[\"store\", \"public\"],\n    response_model=backend.server.v2.store.model.CreatorDetails,\n)\n        )\n\n\n############################################\n############# Store Submissions ###############\n############################################\n@router.get(\n    \"/myagents\",\n    tags=[\"store\", \"private\"],\n    dependencies=[fastapi.Depends(autogpt_libs.auth.middleware.auth_middleware)],\n    response_model=backend.server.v2.store.model.MyAgentsResponse,\n)\n        )\n\n\n@router.delete(\n    \"/submissions/{submission_id}\",\n    tags=[\"store\", \"private\"],\n    dependencies=[fastapi.Depends(autogpt_libs.auth.middleware.auth_middleware)],\n    response_model=bool,\n)\n        )\n\n\n@router.get(\n    \"/submissions\",\n    tags=[\"store\", \"private\"],\n    dependencies=[fastapi.Depends(autogpt_libs.auth.middleware.auth_middleware)],\n    response_model=backend.server.v2.store.model.StoreSubmissionsResponse,\n)\n        )\n\n\n@router.post(\n    \"/submissions\",\n    tags=[\"store\", \"private\"],\n    dependencies=[fastapi.Depends(autogpt_libs.auth.middleware.auth_middleware)],\n    response_model=backend.server.v2.store.model.StoreSubmission,\n)\n        )\n\n\n@router.post(\n    \"/submissions/media\",\n    tags=[\"store\", \"private\"],\n    dependencies=[fastapi.Depends(autogpt_libs.auth.middleware.auth_middleware)],\n)\n        )\n\n\n@router.post(\n    \"/submissions/generate_image\",\n    tags=[\"store\", \"private\"],\n    dependencies=[fastapi.Depends(autogpt_libs.auth.middleware.auth_middleware)],\n)\n        )", "blocks": [{"id": 1, "label": "import logging\nimport typing\nimport urllib.parse\n\nimport autogpt_libs.auth.depends\nimport autogpt_libs.auth.middleware\nimport fastapi\nimport fastapi.responses\n\nimport backend.data.graph\nimport backend.server.v2.store.db\nimport backend.server.v2.store.image_gen\nimport backend.server.v2.store.media\nimport backend.server.v2.store.model\n\nlogger = logging.getLogger(__name__)\n\nrouter = fastapi.APIRouter()", "successors": []}]}
{"file_name": "147.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 90, "functions": [], "classes": [{"name": "QueryApi", "type": "class", "start_line": 4, "end_line": 23, "functions": [{"name": "__init__", "type": "function", "start_line": 6, "end_line": 8, "functions": [], "classes": [], "simplified_code": "    def __init__(self, memory_cache, reverse_index_cluster):\n        self.memory_cache = memory_cache\n        self.reverse_index_cluster = reverse_index_cluster", "blocks": [{"id": 1, "label": "def __init__(self, memory_cache, reverse_index_cluster):\n    self.memory_cache = memory_cache\n    self.reverse_index_cluster = reverse_index_cluster", "successors": []}]}, {"name": "parse_query", "type": "function", "start_line": 10, "end_line": 14, "functions": [], "classes": [], "simplified_code": "    def parse_query(self, query):\n        \"\"\"Remove markup, break text into terms, deal with typos,\n        normalize capitalization, convert to use boolean operations.\n        \"\"\"\n        ...", "blocks": [{"id": 1, "label": "def parse_query(self, query):", "successors": [{"id": 2, "label": "\"\"\"Remove markup, break text into terms, deal with typos,\nnormalize capitalization, convert to use boolean operations.\n\"\"\"", "successors": []}, {"id": 3, "label": "...", "successors": []}]}]}, {"name": "process_query", "type": "function", "start_line": 16, "end_line": 22, "functions": [], "classes": [], "simplified_code": "    def process_query(self, query):\n        query = self.parse_query(query)\n        results = self.memory_cache.get(query)\n        if results is None:\n            results = self.reverse_index_cluster.process_search(query)\n            self.memory_cache.set(query, results)\n        return results", "blocks": [{"id": 1, "label": "def process_query(self, query):\n    query = self.parse_query(query)\n    results = self.memory_cache.get(query)\nif results is None:", "successors": [{"id": 3, "label": "    results = self.reverse_index_cluster.process_search(query)\n    self.memory_cache.set(query, results)\nreturn results", "successors": []}, {"id": 4, "label": "return results", "successors": []}]}]}], "simplified_code": "class QueryApi(object):\n\n        self.reverse_index_cluster = reverse_index_cluster\n\n        ...\n\n        return results\n", "blocks": [{"id": 1, "label": "class QueryApi(object):\nself.reverse_index_cluster = reverse_index_cluster", "successors": [{"id": 3, "label": "return results", "successors": []}]}]}, {"name": "Node", "type": "class", "start_line": 25, "end_line": 31, "functions": [{"name": "__init__", "type": "function", "start_line": 27, "end_line": 29, "functions": [], "classes": [], "simplified_code": "    def __init__(self, query, results):\n        self.query = query\n        self.results = results", "blocks": [{"id": 1, "label": "def __init__(self, query, results):\nself.query = query\nself.results = results", "successors": []}]}], "simplified_code": "class Node(object):\n\n        self.results = results\n\n", "blocks": [{"id": 1, "label": "class Node(object):\n    self.results = results", "successors": []}]}, {"name": "LinkedList", "type": "class", "start_line": 32, "end_line": 47, "functions": [{"name": "__init__", "type": "function", "start_line": 34, "end_line": 36, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        self.head = None\n        self.tail = None", "blocks": [{"id": 1, "label": "def __init__(self):\n    self.head = None\n    self.tail = None", "successors": []}]}, {"name": "move_to_front", "type": "function", "start_line": 38, "end_line": 39, "functions": [], "classes": [], "simplified_code": "    def move_to_front(self, node):\n        ...", "blocks": [{"id": 1, "label": "def move_to_front(self, node):\n    if self.head == node:", "successors": [{"id": 3, "label": "        return", "successors": []}, {"id": 4, "label": "    if node.prev:\n        node.prev.next = node.next", "successors": [{"id": 6, "label": "        if node.next:", "successors": [{"id": 7, "label": "            node.next.prev = node.prev\n        else:", "successors": [{"id": 9, "label": "            self.tail = node.prev", "successors": []}]}, {"id": 10, "label": "    node.next = self.head\n    node.prev = None", "successors": [{"id": 12, "label": "    self.head.prev = node\n    self.head = node", "successors": []}]}]}]}]}]}, {"name": "append_to_front", "type": "function", "start_line": 41, "end_line": 42, "functions": [], "classes": [], "simplified_code": "    def append_to_front(self, node):\n        ...", "blocks": [{"id": 1, "label": "def append_to_front(self, node):\nnode.prev = None", "successors": [{"id": 3, "label": "if self.head is None:", "successors": [{"id": 4, "label": "self.head = node\nself.tail = node", "successors": []}, {"id": 5, "label": "node.next = self.head\nself.head.prev = node\nself.head = node", "successors": []}]}]}]}, {"name": "remove_from_tail", "type": "function", "start_line": 44, "end_line": 45, "functions": [], "classes": [], "simplified_code": "    def remove_from_tail(self):\n        ...", "blocks": [{"id": 1, "label": "def remove_from_tail(self):\nif self.tail is None:", "successors": [{"id": 3, "label": "    return", "successors": []}, {"id": 4, "label": "if self.head == self.tail:", "successors": [{"id": 5, "label": "    self.head = None\n    self.tail = None", "successors": []}, {"id": 7, "label": "else:\n    current = self.head", "successors": [{"id": 9, "label": "    while current.next is not self.tail:", "successors": [{"id": 10, "label": "        current = current.next", "successors": [{"id": 9, "label": "while current.next is not self.tail:", "successors": []}]}, {"id": 11, "label": "    current.next = None\n    self.tail = current", "successors": []}]}]}]}]}]}], "simplified_code": "class LinkedList(object):\n\n        self.tail = None\n\n        ...\n\n        ...\n\n        ...\n\n", "blocks": [{"id": 1, "label": "class LinkedList(object):\nself.tail = None", "successors": []}]}, {"name": "Cache", "type": "class", "start_line": 48, "end_line": 90, "functions": [{"name": "__init__", "type": "function", "start_line": 50, "end_line": 54, "functions": [], "classes": [], "simplified_code": "    def __init__(self, MAX_SIZE):\n        self.MAX_SIZE = MAX_SIZE\n        self.size = 0\n        self.lookup = {}\n        self.linked_list = LinkedList()", "blocks": [{"id": 1, "label": "def __init__(self, MAX_SIZE):\n    self.MAX_SIZE = MAX_SIZE\n    self.size = 0\n    self.lookup = {}\n    self.linked_list = LinkedList()", "successors": []}]}, {"name": "get", "type": "function", "start_line": 56, "end_line": 65, "functions": [], "classes": [], "simplified_code": "    def get(self, query):\n        \"\"\"Get the stored query result from the cache.\n\n        Accessing a node updates its position to the front of the LRU list.\n        \"\"\"\n        node = self.lookup[query]\n        if node is None:\n            return None\n        self.linked_list.move_to_front(node)\n        return node.results", "blocks": [{"id": 1, "label": "node = self.lookup[query]\nif node is None:", "successors": [{"id": 3, "label": "    return None", "successors": []}, {"id": 4, "label": "self.linked_list.move_to_front(node)\nreturn node.results", "successors": []}]}]}, {"name": "set", "type": "function", "start_line": 67, "end_line": 90, "functions": [], "classes": [], "simplified_code": "    def set(self, results, query):\n        \"\"\"Set the result for the given query key in the cache.\n\n        When updating an entry, updates its position to the front of the LRU list.\n        If the entry is new and the cache is at capacity, removes the oldest entry\n        before the new entry is added.\n        \"\"\"\n        node = self.map[query]\n        if node is not None:\n            # Key exists in cache, update the value\n            node.results = results\n            self.linked_list.move_to_front(node)\n        else:\n            # Key does not exist in cache\n            if self.size == self.MAX_SIZE:\n                # Remove the oldest entry from the linked list and lookup\n                self.lookup.pop(self.linked_list.tail.query, None)\n                self.linked_list.remove_from_tail()\n            else:\n                self.size += 1\n            # Add the new key and value\n            new_node = Node(query, results)\n            self.linked_list.append_to_front(new_node)\n            self.lookup[query] = new_node", "blocks": [{"id": 1, "label": "node = self.map[query]", "successors": [{"id": 2, "label": "if node is not None:", "successors": [{"id": 3, "label": "    node.results = results\n    self.linked_list.move_to_front(node)", "successors": []}, {"id": 4, "label": "    if self.size == self.MAX_SIZE:", "successors": [{"id": 5, "label": "        self.lookup.pop(self.linked_list.tail.query, None)\n        self.linked_list.remove_from_tail()", "successors": []}, {"id": 6, "label": "        self.size += 1", "successors": []}]}]}, {"id": 7, "label": "new_node = Node(query, results)\nself.linked_list.append_to_front(new_node)\nself.lookup[query] = new_node", "successors": []}]}]}], "simplified_code": "class Cache(object):\n\n        self.linked_list = LinkedList()\n\n        return node.results\n\n            self.lookup[query] = new_node", "blocks": [{"id": 1, "label": "class Cache(object):", "successors": [{"id": 2, "label": "self.linked_list = LinkedList()", "successors": []}, {"id": 3, "label": "return node.results", "successors": []}, {"id": 4, "label": "self.lookup[query] = new_node", "successors": []}]}]}], "simplified_code": "# -*- coding: utf-8 -*-\n\n\n\n\n\n\n            self.lookup[query] = new_node", "blocks": [{"id": 1, "label": "self.lookup[query] = new_node", "successors": []}]}
{"file_name": "148.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 104, "functions": [], "classes": [{"name": "UserService", "type": "class", "start_line": 5, "end_line": 24, "functions": [{"name": "__init__", "type": "function", "start_line": 7, "end_line": 8, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        self.users_by_id = {}  # key: user id, value: User", "blocks": [{"id": 1, "label": "def __init__(self):\nself.users_by_id = {}  # key: user id, value: User", "successors": []}]}, {"name": "add_user", "type": "function", "start_line": 10, "end_line": 11, "functions": [], "classes": [], "simplified_code": "    def add_user(self, user_id, name, pass_hash):\n        pass", "blocks": [{"id": 1, "label": "def add_user(self, user_id, name, pass_hash):\npass", "successors": []}]}, {"name": "remove_user", "type": "function", "start_line": 13, "end_line": 14, "functions": [], "classes": [], "simplified_code": "    def remove_user(self, user_id):\n        pass", "blocks": [{"id": 1, "label": "def remove_user(self, user_id):\n    pass", "successors": []}]}, {"name": "add_friend_request", "type": "function", "start_line": 16, "end_line": 17, "functions": [], "classes": [], "simplified_code": "    def add_friend_request(self, from_user_id, to_user_id):\n        pass", "blocks": [{"id": 1, "label": "def add_friend_request(self, from_user_id, to_user_id):\npass", "successors": []}]}, {"name": "approve_friend_request", "type": "function", "start_line": 19, "end_line": 20, "functions": [], "classes": [], "simplified_code": "    def approve_friend_request(self, from_user_id, to_user_id):\n        pass", "blocks": [{"id": 1, "label": "def approve_friend_request(self, from_user_id, to_user_id):\npass", "successors": []}]}, {"name": "reject_friend_request", "type": "function", "start_line": 22, "end_line": 23, "functions": [], "classes": [], "simplified_code": "    def reject_friend_request(self, from_user_id, to_user_id):\n        pass", "blocks": [{"id": 1, "label": "def reject_friend_request(self, from_user_id, to_user_id):\n    pass", "successors": []}]}], "simplified_code": "class UserService(object):\n\n        self.users_by_id = {}  # key: user id, value: User\n\n        pass\n\n        pass\n\n        pass\n\n        pass\n\n        pass\n", "blocks": [{"id": 1, "label": "class UserService(object):\n    self.users_by_id = {}  # key: user id, value: User", "successors": [{"id": 3, "label": "pass\npass", "successors": [{"id": 5, "label": "pass\npass", "successors": [{"id": 7, "label": "pass", "successors": []}]}]}]}]}, {"name": "User", "type": "class", "start_line": 26, "end_line": 54, "functions": [{"name": "__init__", "type": "function", "start_line": 28, "end_line": 36, "functions": [], "classes": [], "simplified_code": "    def __init__(self, user_id, name, pass_hash):\n        self.user_id = user_id\n        self.name = name\n        self.pass_hash = pass_hash\n        self.friends_by_id = {}  # key: friend id, value: User\n        self.friend_ids_to_private_chats = {}  # key: friend id, value: private chats\n        self.group_chats_by_id = {}  # key: chat id, value: GroupChat\n        self.received_friend_requests_by_friend_id = {}  # key: friend id, value: AddRequest\n        self.sent_friend_requests_by_friend_id = {}  # key: friend id, value: AddRequest", "blocks": [{"id": 1, "label": "def __init__(self, user_id, name, pass_hash):\n    self.user_id = user_id\n    self.name = name\n    self.pass_hash = pass_hash\n    self.friends_by_id = {}\n    self.friend_ids_to_private_chats = {}\n    self.group_chats_by_id = {}\n    self.received_friend_requests_by_friend_id = {}\n    self.sent_friend_requests_by_friend_id = {}", "successors": []}]}, {"name": "message_user", "type": "function", "start_line": 38, "end_line": 39, "functions": [], "classes": [], "simplified_code": "    def message_user(self, friend_id, message):\n        pass", "blocks": [{"id": 1, "label": "def message_user(self, friend_id, message):\n    pass", "successors": []}]}, {"name": "message_group", "type": "function", "start_line": 41, "end_line": 42, "functions": [], "classes": [], "simplified_code": "    def message_group(self, group_id, message):\n        pass", "blocks": [{"id": 1, "label": "def message_group(self, group_id, message):\npass", "successors": []}]}, {"name": "send_friend_request", "type": "function", "start_line": 44, "end_line": 45, "functions": [], "classes": [], "simplified_code": "    def send_friend_request(self, friend_id):\n        pass", "blocks": []}, {"name": "receive_friend_request", "type": "function", "start_line": 47, "end_line": 48, "functions": [], "classes": [], "simplified_code": "    def receive_friend_request(self, friend_id):\n        pass", "blocks": [{"id": 1, "label": "def receive_friend_request(self, friend_id):\n    pass", "successors": []}]}, {"name": "approve_friend_request", "type": "function", "start_line": 50, "end_line": 51, "functions": [], "classes": [], "simplified_code": "    def approve_friend_request(self, friend_id):\n        pass", "blocks": [{"id": 1, "label": "def approve_friend_request(self, friend_id):\n    pass", "successors": []}]}, {"name": "reject_friend_request", "type": "function", "start_line": 53, "end_line": 54, "functions": [], "classes": [], "simplified_code": "    def reject_friend_request(self, friend_id):\n        pass", "blocks": [{"id": 1, "label": "def reject_friend_request(self, friend_id):\n    pass", "successors": []}]}], "simplified_code": "class User(object):\n\n        self.sent_friend_requests_by_friend_id = {}  # key: friend id, value: AddRequest\n\n        pass\n\n        pass\n\n        pass\n\n        pass\n\n        pass\n\n        pass", "blocks": [{"id": 1, "label": "class User(object):\n\n        self.sent_friend_requests_by_friend_id = {}  # key: friend id, value: AddRequest\n\n        pass\n\n        pass\n\n        pass\n\n        pass\n\n        pass\n\n        pass", "successors": []}]}, {"name": "Chat", "type": "class", "start_line": 57, "end_line": 62, "functions": [{"name": "__init__", "type": "function", "start_line": 59, "end_line": 62, "functions": [], "classes": [], "simplified_code": "    def __init__(self, chat_id):\n        self.chat_id = chat_id\n        self.users = []\n        self.messages = []", "blocks": [{"id": 1, "label": "def __init__(self, chat_id):\n    self.chat_id = chat_id\n    self.users = []\n    self.messages = []", "successors": []}]}], "simplified_code": "class Chat(metaclass=ABCMeta):\n\n        self.messages = []", "blocks": [{"id": 1, "label": "class Chat(metaclass=ABCMeta):\nself.messages = []", "successors": []}]}, {"name": "PrivateChat", "type": "class", "start_line": 65, "end_line": 70, "functions": [{"name": "__init__", "type": "function", "start_line": 67, "end_line": 70, "functions": [], "classes": [], "simplified_code": "    def __init__(self, first_user, second_user):\n        super(PrivateChat, self).__init__()\n        self.users.append(first_user)\n        self.users.append(second_user)", "blocks": [{"id": 1, "label": "def __init__(self, first_user, second_user):\nsuper(PrivateChat, self).__init__()", "successors": [{"id": 3, "label": "self.users.append(first_user)\nself.users.append(second_user)", "successors": []}]}]}], "simplified_code": "class PrivateChat(Chat):\n\n        self.users.append(second_user)", "blocks": [{"id": 1, "label": "class PrivateChat(Chat):\n    self.users.append(second_user)", "successors": []}]}, {"name": "GroupChat", "type": "class", "start_line": 73, "end_line": 79, "functions": [{"name": "add_user", "type": "function", "start_line": 75, "end_line": 76, "functions": [], "classes": [], "simplified_code": "    def add_user(self, user):\n        pass", "blocks": [{"id": 1, "label": "def add_user(self, user):\n    pass", "successors": []}]}, {"name": "remove_user", "type": "function", "start_line": 78, "end_line": 79, "functions": [], "classes": [], "simplified_code": "    def remove_user(self, user):\n        pass", "blocks": [{"id": 1, "label": "def remove_user(self, user):\npass", "successors": []}]}], "simplified_code": "class GroupChat(Chat):\n\n        pass\n\n        pass", "blocks": [{"id": 1, "label": "class GroupChat(Chat):\n    pass", "successors": [{"id": 3, "label": "    pass", "successors": []}]}]}, {"name": "Message", "type": "class", "start_line": 82, "end_line": 87, "functions": [{"name": "__init__", "type": "function", "start_line": 84, "end_line": 87, "functions": [], "classes": [], "simplified_code": "    def __init__(self, message_id, message, timestamp):\n        self.message_id = message_id\n        self.message = message\n        self.timestamp = timestamp", "blocks": [{"id": 1, "label": "def __init__(self, message_id, message, timestamp):\nself.message_id = message_id\nself.message = message\nself.timestamp = timestamp", "successors": []}]}], "simplified_code": "class Message(object):\n\n        self.timestamp = timestamp", "blocks": [{"id": 1, "label": "class Message(object):\n    def __init__(self, timestamp):", "successors": [{"id": 3, "label": "        self.timestamp = timestamp", "successors": []}]}]}, {"name": "AddRequest", "type": "class", "start_line": 90, "end_line": 96, "functions": [{"name": "__init__", "type": "function", "start_line": 92, "end_line": 96, "functions": [], "classes": [], "simplified_code": "    def __init__(self, from_user_id, to_user_id, request_status, timestamp):\n        self.from_user_id = from_user_id\n        self.to_user_id = to_user_id\n        self.request_status = request_status\n        self.timestamp = timestamp", "blocks": [{"id": 1, "label": "def __init__(self, from_user_id, to_user_id, request_status, timestamp):\n    self.from_user_id = from_user_id\n    self.to_user_id = to_user_id\n    self.request_status = request_status\n    self.timestamp = timestamp", "successors": []}]}], "simplified_code": "class AddRequest(object):\n\n        self.timestamp = timestamp", "blocks": [{"id": 1, "label": "class AddRequest(object):\nself.timestamp = timestamp", "successors": []}]}, {"name": "RequestStatus", "type": "class", "start_line": 99, "end_line": 104, "functions": [], "simplified_code": "class RequestStatus(Enum):\n\n    UNREAD = 0\n    READ = 1\n    ACCEPTED = 2\n    REJECTED = 3", "blocks": [{"id": 1, "label": "class RequestStatus(Enum):", "successors": [{"id": 2, "label": "UNREAD = 0", "successors": []}, {"id": 3, "label": "READ = 1", "successors": []}, {"id": 4, "label": "ACCEPTED = 2", "successors": []}, {"id": 5, "label": "REJECTED = 3", "successors": []}]}]}], "simplified_code": "from abc import ABCMeta\nfrom enum import Enum\n\n\n\n\n        pass\n\n\n        self.messages = []\n\n\n        self.users.append(second_user)\n\n\n        pass\n\n\n        self.timestamp = timestamp\n\n\n        self.timestamp = timestamp\n\n\n    REJECTED = 3", "blocks": [{"id": 1, "label": "from abc import ABCMeta\nfrom enum import Enum", "successors": [{"id": 3, "label": "pass\nself.messages = []", "successors": [{"id": 5, "label": "self.users.append(second_user)\npass", "successors": [{"id": 7, "label": "self.timestamp = timestamp\nself.timestamp = timestamp", "successors": [{"id": 9, "label": "REJECTED = 3", "successors": []}]}]}]}]}]}
{"file_name": "149.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 30, "functions": [], "classes": [{"name": "CompassWebhookType", "type": "class", "start_line": 14, "end_line": 16, "functions": [], "classes": [], "simplified_code": "class CompassWebhookType(StrEnum):\n    TRANSCRIPTION = \"transcription\"\n    TASK = \"task\"", "blocks": [{"id": 1, "label": "class CompassWebhookType(StrEnum):\n    TRANSCRIPTION = \"transcription\"\n    TASK = \"task\"", "successors": []}]}, {"name": "CompassWebhookManager", "type": "class", "start_line": 19, "end_line": 30, "functions": [{"name": "validate_payload", "type": "function", "start_line": 24, "end_line": 30, "functions": [], "classes": [], "simplified_code": "    async def validate_payload(\n        cls, webhook: integrations.Webhook, request: Request\n    ) -> tuple[dict, str]:\n        payload = await request.json()\n        event_type = CompassWebhookType.TRANSCRIPTION  # currently the only type\n\n        return payload, event_type", "blocks": [{"id": 1, "label": "async def validate_payload(cls, webhook: integrations.Webhook, request: Request) -> tuple[dict, str]:\n    payload = await request.json()\n    event_type = CompassWebhookType.TRANSCRIPTION\nreturn payload, event_type", "successors": []}]}], "classes": [], "simplified_code": "class CompassWebhookManager(ManualWebhookManagerBase):\n    PROVIDER_NAME = ProviderName.COMPASS\n    WebhookType = CompassWebhookType\n\n    @classmethod\n        return payload, event_type", "blocks": [{"id": 1, "label": "class CompassWebhookManager(ManualWebhookManagerBase):", "successors": [{"id": 2, "label": "    PROVIDER_NAME = ProviderName.COMPASS\n    WebhookType = CompassWebhookType", "successors": []}, {"id": 3, "label": "    @classmethod\n    def get_event_from_payload(cls, request):", "successors": [{"id": 5, "label": "        if not cls.is_valid_secret(request.GET):\n            raise APIException('Invalid request')", "successors": []}, {"id": 7, "label": "        payload = cls.parse_request(request)", "successors": []}, {"id": 8, "label": "        event_type = cls.identify_event(payload)", "successors": []}, {"id": 9, "label": "        return payload, event_type", "successors": []}]}]}]}], "simplified_code": "import logging\n\nfrom fastapi import Request\nfrom strenum import StrEnum\n\nfrom backend.data import integrations\nfrom backend.integrations.providers import ProviderName\n\nfrom ._manual_base import ManualWebhookManagerBase\n\nlogger = logging.getLogger(__name__)\n\n\n    TASK = \"task\"\n\n\n        return payload, event_type", "blocks": [{"id": 1, "label": "import logging\nfrom fastapi import Request", "successors": [{"id": 3, "label": "from strenum import StrEnum\nfrom backend.data import integrations", "successors": [{"id": 5, "label": "from backend.integrations.providers import ProviderName\nfrom ._manual_base import ManualWebhookManagerBase", "successors": [{"id": 7, "label": "logger = logging.getLogger(__name__)\nTASK = \"task\"", "successors": [{"id": 9, "label": "return payload, event_type", "successors": []}]}]}]}]}]}
{"file_name": "150.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 158, "functions": [{"name": "depth_first_search", "type": "function", "start_line": 82, "end_line": 138, "functions": [], "classes": [], "simplified_code": "def depth_first_search(\n    possible_board: list[int],\n    diagonal_right_collisions: list[int],\n    diagonal_left_collisions: list[int],\n    boards: list[list[str]],\n    n: int,\n) -> None:\n    \"\"\"\n    >>> boards = []\n    >>> depth_first_search([], [], [], boards, 4)\n    >>> for board in boards:\n    ...     print(board)\n    ['. Q . . ', '. . . Q ', 'Q . . . ', '. . Q . ']\n    ['. . Q . ', 'Q . . . ', '. . . Q ', '. Q . . ']\n    \"\"\"\n\n    # Get next row in the current board (possible_board) to fill it with a queen\n    row = len(possible_board)\n\n    # If row is equal to the size of the board it means there are a queen in each row in\n    # the current board (possible_board)\n    if row == n:\n        # We convert the variable possible_board that looks like this: [1, 3, 0, 2] to\n        # this: ['. Q . . ', '. . . Q ', 'Q . . . ', '. . Q . ']\n        boards.append([\". \" * i + \"Q \" + \". \" * (n - 1 - i) for i in possible_board])\n        return\n\n    # We iterate each column in the row to find all possible results in each row\n    for col in range(n):\n        # We apply that we learned previously. First we check that in the current board\n        # (possible_board) there are not other same value because if there is it means\n        # that there are a collision in vertical. Then we apply the two formulas we\n        # learned before:\n        #\n        # 45\u00ba: y - x = b or 45: row - col = b\n        # 135\u00ba: y + x = b or row + col = b.\n        #\n        # And we verify if the results of this two formulas not exist in their variables\n        # respectively.  (diagonal_right_collisions, diagonal_left_collisions)\n        #\n        # If any or these are True it means there is a collision so we continue to the\n        # next value in the for loop.\n        if (\n            col in possible_board\n            or row - col in diagonal_right_collisions\n            or row + col in diagonal_left_collisions\n        ):\n            continue\n\n        # If it is False we call dfs function again and we update the inputs\n        depth_first_search(\n            [*possible_board, col],\n            [*diagonal_right_collisions, row - col],\n            [*diagonal_left_collisions, row + col],\n            boards,\n            n,\n        )", "blocks": [{"id": 1, "label": "row = len(possible_board)\nif row == n:", "successors": [{"id": 3, "label": "    boards.append(['. ' * i + 'Q ' + '. ' * (n - 1 - i) for i in possible_board])\n    return", "successors": []}, {"id": 5, "label": "for col in range(n):", "successors": [{"id": 6, "label": "    if (col in possible_board or row - col in diagonal_right_collisions or row + col in diagonal_left_collisions):", "successors": [{"id": 7, "label": "        continue", "successors": [{"id": 5, "label": "for col in range(n):", "successors": []}]}, {"id": 8, "label": "    depth_first_search([*possible_board, col], [*diagonal_right_collisions, row - col], [*diagonal_left_collisions, row + col], boards, n)", "successors": [{"id": 5, "label": "for col in range(n):", "successors": []}]}]}]}]}]}, {"name": "n_queens_solution", "type": "function", "start_line": 141, "end_line": 151, "functions": [], "classes": [], "simplified_code": "def n_queens_solution(n: int) -> None:\n    boards: list[list[str]] = []\n    depth_first_search([], [], [], boards, n)\n\n    # Print all the boards\n    for board in boards:\n        for column in board:\n            print(column)\n        print(\"\")\n\n    print(len(boards), \"solutions were found.\")", "blocks": [{"id": 1, "label": "def n_queens_solution(n: int) -> None:\n    boards: list[list[str]] = []\n    depth_first_search([], [], [], boards, n)", "successors": [{"id": 3, "label": "    for board in boards:", "successors": [{"id": 4, "label": "        for column in board:", "successors": [{"id": 5, "label": "            print(column)\n        print(\"\")", "successors": []}]}, {"id": 6, "label": "        print(\"\")", "successors": []}]}, {"id": 7, "label": "    print(len(boards), \"solutions were found.\")", "successors": []}]}]}], "classes": [], "simplified_code": "r\"\"\"\nProblem:\n\nThe n queens problem is: placing N queens on a N * N chess board such that no queen\ncan attack any other queens placed on that chess board.  This means that one queen\ncannot have any other queen on its horizontal, vertical and diagonal lines.\n\nSolution:\n\nTo solve this problem we will use simple math. First we know the queen can move in all\nthe possible ways, we can simplify it in this: vertical, horizontal, diagonal left and\n diagonal right.\n\nWe can visualize it like this:\n\nleft diagonal = \\\nright diagonal = /\n\nOn a chessboard vertical movement could be the rows and horizontal movement could be\nthe columns.\n\nIn programming we can use an array, and in this array each index could be the rows and\neach value in the array could be the column. For example:\n\n    . Q . .     We have this chessboard with one queen in each column and each queen\n    . . . Q     can't attack to each other.\n    Q . . .     The array for this example would look like this: [1, 3, 0, 2]\n    . . Q .\n\nSo if we use an array and we verify that each value in the array is different to each\nother we know that at least the queens can't attack each other in horizontal and\nvertical.\n\nAt this point we have it halfway completed and we will treat the chessboard as a\nCartesian plane.  Hereinafter we are going to remember basic math, so in the school we\nlearned this formula:\n\n    Slope of a line:\n\n           y2 - y1\n     m = ----------\n          x2 - x1\n\nThis formula allow us to get the slope. For the angles 45\u00ba (right diagonal) and 135\u00ba\n(left diagonal) this formula gives us m = 1, and m = -1 respectively.\n\nSee::\nhttps://www.enotes.com/homework-help/write-equation-line-that-hits-origin-45-degree-1474860\n\nThen we have this other formula:\n\nSlope intercept:\n\ny = mx + b\n\nb is where the line crosses the Y axis (to get more information see:\nhttps://www.mathsisfun.com/y_intercept.html), if we change the formula to solve for b\nwe would have:\n\ny - mx = b\n\nAnd since we already have the m values for the angles 45\u00ba and 135\u00ba, this formula would\nlook like this:\n\n45\u00ba: y - (1)x = b\n45\u00ba: y - x = b\n\n135\u00ba: y - (-1)x = b\n135\u00ba: y + x = b\n\ny = row\nx = column\n\nApplying these two formulas we can check if a queen in some position is being attacked\nfor another one or vice versa.\n\n\"\"\"\n\nfrom __future__ import annotations\n\n\n        )\n\n\n    print(len(boards), \"solutions were found.\")\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()\n    n_queens_solution(4)", "blocks": [{"id": 1, "label": "# Example input code\nr\"\"\"\nProblem:\n\nThe n queens problem is: placing N queens on a N * N chess board such that no queen\ncan attack any other queens placed on that chess board.  This means that one queen\ncannot have any other queen on its horizontal, vertical and diagonal lines.\n\nSolution:\n\nTo solve this problem we will use simple math. First we know the queen can move in all\nthe possible ways, we can simplify it in this: vertical, horizontal, diagonal left and\ndiagonal right.\n\nWe can visualize it like this:\n\nleft diagonal = \\\nright diagonal = /\n\nOn a chessboard vertical movement could be the rows and horizontal movement could be\nthe columns.\n\nIn programming we can use an array, and in this array each index could be the rows and\neach value in the array could be the column. For example:\n\n    . Q . .     We have this chessboard with one queen in each column and each queen\n    . . . Q     can't attack to each other.\n    Q . . .     The array for this example would look like this: [1, 3, 0, 2]\n    . . Q .\n\nSo if we use an array and we verify that each value in the array is different to each\nother we know that at least the queens can't attack each other in horizontal and\nvertical.\n\nAt this point we have it halfway completed and we will treat the chessboard as a\nCartesian plane.  Hereinafter we are going to remember basic math, so in the school we\nlearned this formula:\n\n    Slope of a line:\n\n           y2 - y1\n     m = ----------\n          x2 - x1\n\nThis formula allow us to get the slope. For the angles 45\u00ba (right diagonal) and 135\u00ba\n(left diagonal) this formula gives us m = 1, and m = -1 respectively.\n\nSee::\nhttps://www.enotes.com/homework-help/write-equation-line-that-hits-origin-45-degree-1474860\n\nThen we have this other formula:\n\nSlope intercept:\n\ny = mx + b\n\nb is where the line crosses the Y axis (to get more information see:\nhttps://www.mathsisfun.com/y_intercept.html), if we change the formula to solve for b\nwe would have:\n\ny - mx = b\n\nAnd since we already have the m values for the angles 45\u00ba and 135\u00ba, this formula would\nlook like this:\n\n45\u00ba: y - (1)x = b\n45\u00ba: y - x = b\n\n135\u00ba: y - (-1)x = b\n135\u00ba: y + x = b\n\ny = row\nx = column\n\nApplying these two formulas we can check if a queen in some position is being attacked\nfor another one or vice versa.\n\"\"\"\n\nfrom __future__ import annotations\n\n        )\nprint(len(boards), \"solutions were found.\")", "successors": [{"id": 3, "label": "if __name__ == \"__main__\":\nimport doctest\n\ndoctest.testmod()\nn_queens_solution(4)", "successors": []}]}]}
{"file_name": "151.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 592, "functions": [], "classes": [{"name": "StoreValueBlock", "type": "class", "start_line": 11, "end_line": 52, "functions": [{"name": "__init__", "type": "function", "start_line": 32, "end_line": 48, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"1ff065e9-88e8-4358-9d82-8dc91f622ba9\",\n            description=\"This block forwards an input value as output, allowing reuse without change.\",\n            categories={BlockCategory.BASIC},\n            input_schema=StoreValueBlock.Input,\n            output_schema=StoreValueBlock.Output,\n            test_input=[\n                {\"input\": \"Hello, World!\"},\n                {\"input\": \"Hello, World!\", \"data\": \"Existing Data\"},\n            ],\n            test_output=[\n                (\"output\", \"Hello, World!\"),  # No data provided, so trigger is returned\n                (\"output\", \"Existing Data\"),  # Data is provided, so data is returned.\n            ],\n            static_output=True,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"1ff065e9-88e8-4358-9d82-8dc91f622ba9\",\n    description=\"This block forwards an input value as output, allowing reuse without change.\",\n    categories={BlockCategory.BASIC},\n    input_schema=StoreValueBlock.Input,\n    output_schema=StoreValueBlock.Output,\n    test_input=[\n        {\"input\": \"Hello, World!\"},\n        {\"input\": \"Hello, World!\", \"data\": \"Existing Data\"},\n    ],\n    test_output=[\n        (\"output\", \"Hello, World!\"),  # No data provided, so trigger is returned\n        (\"output\", \"Existing Data\"),  # Data is provided, so data is returned.\n    ],\n    static_output=True,\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 50, "end_line": 51, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        yield \"output\", input_data.data or input_data.input", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\nyield \"output\", input_data.data or input_data.input", "successors": []}]}], "classes": [{"name": "Input", "type": "class", "start_line": 18, "end_line": 27, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        input: Any = SchemaField(\n            description=\"Trigger the block to produce the output. \"\n            \"The value is only used when `data` is None.\"\n        )\n        data: Any = SchemaField(\n            description=\"The constant data to be retained in the block. \"\n            \"This value is passed as `output`.\",\n            default=None,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    input: Any = SchemaField(description=\"Trigger the block to produce the output. \"\n    \"The value is only used when `data` is None.\")", "successors": []}, {"id": 3, "label": "    data: Any = SchemaField(description=\"The constant data to be retained in the block. \"\n    \"This value is passed as `output`.\",\n    default=None,)", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 29, "end_line": 30, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        output: Any = SchemaField(description=\"The stored data retained in the block.\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\noutput: Any = SchemaField(description=\"The stored data retained in the block.\")", "successors": []}]}], "simplified_code": "class StoreValueBlock(Block):\n    \"\"\"\n    This block allows you to provide a constant value as a block, in a stateless manner.\n    The common use-case is simply pass the `input` data, it will `output` the same data.\n    The block output will be static, the output can be consumed multiple times.\n    \"\"\"\n\n        )\n\n        output: Any = SchemaField(description=\"The stored data retained in the block.\")\n\n        )\n\n        yield \"output\", input_data.data or input_data.input\n", "blocks": [{"id": 1, "label": "class StoreValueBlock(Block):\n\"\"\"\n    This block allows you to provide a constant value as a block, in a stateless manner.\n    The common use-case is simply pass the `input` data, it will `output` the same data.\n    The block output will be static, the output can be consumed multiple times.\n    \"\"\"", "successors": [{"id": 3, "label": "output: Any = SchemaField(description=\"The stored data retained in the block.\")\nyield \"output\", input_data.data or input_data.input", "successors": []}]}]}, {"name": "PrintToConsoleBlock", "type": "class", "start_line": 54, "end_line": 75, "functions": [{"name": "__init__", "type": "function", "start_line": 61, "end_line": 70, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"f3b1c1b2-4c4f-4f0d-8d2f-4c4f0d8d2f4c\",\n            description=\"Print the given text to the console, this is used for a debugging purpose.\",\n            categories={BlockCategory.BASIC},\n            input_schema=PrintToConsoleBlock.Input,\n            output_schema=PrintToConsoleBlock.Output,\n            test_input={\"text\": \"Hello, World!\"},\n            test_output=(\"status\", \"printed\"),\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"f3b1c1b2-4c4f-4f0d-8d2f-4c4f0d8d2f4c\",\n    description=\"Print the given text to the console, this is used for a debugging purpose.\",\n    categories={BlockCategory.BASIC},\n    input_schema=PrintToConsoleBlock.Input,\n    output_schema=PrintToConsoleBlock.Output,\n    test_input={\"text\": \"Hello, World!\"},\n    test_output=(\"status\", \"printed\"),\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 72, "end_line": 74, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        print(\">>>>> Print: \", input_data.text)\n        yield \"status\", \"printed\"", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\nprint(\">>>>> Print: \", input_data.text)", "successors": [{"id": 3, "label": "yield \"status\", \"printed\"", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 55, "end_line": 56, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        text: str = SchemaField(description=\"The text to print to the console.\")", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\ntext: str = SchemaField(description=\"The text to print to the console.\")", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 58, "end_line": 59, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        status: str = SchemaField(description=\"The status of the print operation.\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    status: str = SchemaField(description=\"The status of the print operation.\")", "successors": []}]}], "simplified_code": "class PrintToConsoleBlock(Block):\n        text: str = SchemaField(description=\"The text to print to the console.\")\n\n        status: str = SchemaField(description=\"The status of the print operation.\")\n\n        )\n\n        yield \"status\", \"printed\"\n", "blocks": [{"id": 1, "label": "class PrintToConsoleBlock(Block):\n    text: str = SchemaField(description=\"The text to print to the console.\")", "successors": [{"id": 3, "label": "    status: str = SchemaField(description=\"The status of the print operation.\")\n    yield \"status\", \"printed\"", "successors": []}]}]}, {"name": "FindInDictionaryBlock", "type": "class", "start_line": 77, "end_line": 132, "functions": [{"name": "__init__", "type": "function", "start_line": 88, "end_line": 111, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"0e50422c-6dee-4145-83d6-3a5a392f65de\",\n            description=\"Lookup the given key in the input dictionary/object/list and return the value.\",\n            input_schema=FindInDictionaryBlock.Input,\n            output_schema=FindInDictionaryBlock.Output,\n            test_input=[\n                {\"input\": {\"apple\": 1, \"banana\": 2, \"cherry\": 3}, \"key\": \"banana\"},\n                {\"input\": {\"x\": 10, \"y\": 20, \"z\": 30}, \"key\": \"w\"},\n                {\"input\": [1, 2, 3], \"key\": 1},\n                {\"input\": [1, 2, 3], \"key\": 3},\n                {\"input\": MockObject(value=\"!!\", key=\"key\"), \"key\": \"key\"},\n                {\"input\": [{\"k1\": \"v1\"}, {\"k2\": \"v2\"}, {\"k1\": \"v3\"}], \"key\": \"k1\"},\n            ],\n            test_output=[\n                (\"output\", 2),\n                (\"missing\", {\"x\": 10, \"y\": 20, \"z\": 30}),\n                (\"output\", 2),\n                (\"missing\", [1, 2, 3]),\n                (\"output\", \"key\"),\n                (\"output\", [\"v1\", \"v3\"]),\n            ],\n            categories={BlockCategory.BASIC},\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"0e50422c-6dee-4145-83d6-3a5a392f65de\",\n    description=\"Lookup the given key in the input dictionary/object/list and return the value.\",\n    input_schema=FindInDictionaryBlock.Input,\n    output_schema=FindInDictionaryBlock.Output,\n    test_input=[\n        {\"input\": {\"apple\": 1, \"banana\": 2, \"cherry\": 3}, \"key\": \"banana\"},\n        {\"input\": {\"x\": 10, \"y\": 20, \"z\": 30}, \"key\": \"w\"},\n        {\"input\": [1, 2, 3], \"key\": 1},\n        {\"input\": [1, 2, 3], \"key\": 3},\n        {\"input\": MockObject(value=\"!!\", key=\"key\"), \"key\": \"key\"},\n        {\"input\": [{\"k1\": \"v1\"}, {\"k2\": \"v2\"}, {\"k1\": \"v3\"}], \"key\": \"k1\"},\n    ],\n    test_output=[\n        (\"output\", 2),\n        (\"missing\", {\"x\": 10, \"y\": 20, \"z\": 30}),\n        (\"output\", 2),\n        (\"missing\", [1, 2, 3]),\n        (\"output\", \"key\"),\n        (\"output\", [\"v1\", \"v3\"]),\n    ],\n    categories={BlockCategory.BASIC},\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 113, "end_line": 131, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        obj = input_data.input\n        key = input_data.key\n\n        if isinstance(obj, dict) and key in obj:\n            yield \"output\", obj[key]\n        elif isinstance(obj, list) and isinstance(key, int) and 0 <= key < len(obj):\n            yield \"output\", obj[key]\n        elif isinstance(obj, list) and isinstance(key, str):\n            if len(obj) == 0:\n                yield \"output\", []\n            elif isinstance(obj[0], dict) and key in obj[0]:\n                yield \"output\", [item[key] for item in obj if key in item]\n            else:\n                yield \"output\", [getattr(val, key) for val in obj if hasattr(val, key)]\n        elif isinstance(obj, object) and isinstance(key, str) and hasattr(obj, key):\n            yield \"output\", getattr(obj, key)\n        else:\n            yield \"missing\", input_data.input", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\n    obj = input_data.input\n    key = input_data.key\nif isinstance(obj, dict) and key in obj:", "successors": [{"id": 3, "label": "    yield \"output\", obj[key]", "successors": []}, {"id": 4, "label": "elif isinstance(obj, list) and isinstance(key, int) and 0 <= key < len(obj):", "successors": [{"id": 5, "label": "    yield \"output\", obj[key]", "successors": []}, {"id": 6, "label": "elif isinstance(obj, list) and isinstance(key, str):\n    if len(obj) == 0:", "successors": [{"id": 8, "label": "        yield \"output\", []", "successors": []}, {"id": 9, "label": "    elif isinstance(obj[0], dict) and key in obj[0]:", "successors": [{"id": 10, "label": "        yield \"output\", [item[key] for item in obj if key in item]", "successors": []}, {"id": 11, "label": "    else:\n        yield \"output\", [getattr(val, key) for val in obj if hasattr(val, key)]", "successors": []}]}]}, {"id": 13, "label": "elif isinstance(obj, object) and isinstance(key, str) and hasattr(obj, key):", "successors": [{"id": 14, "label": "    yield \"output\", getattr(obj, key)", "successors": []}, {"id": 15, "label": "else:\n    yield \"missing\", input_data.input", "successors": []}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 78, "end_line": 80, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        input: Any = SchemaField(description=\"Dictionary to lookup from\")\n        key: str | int = SchemaField(description=\"Key to lookup in the dictionary\")", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "input: Any = SchemaField(description=\"Dictionary to lookup from\")", "successors": []}, {"id": 3, "label": "key: str | int = SchemaField(description=\"Key to lookup in the dictionary\")", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 82, "end_line": 86, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        output: Any = SchemaField(description=\"Value found for the given key\")\n        missing: Any = SchemaField(\n            description=\"Value of the input that missing the key\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "    output: Any = SchemaField(description=\"Value found for the given key\")", "successors": []}, {"id": 3, "label": "    missing: Any = SchemaField(description=\"Value of the input that missing the key\")", "successors": []}]}]}], "simplified_code": "class FindInDictionaryBlock(Block):\n        key: str | int = SchemaField(description=\"Key to lookup in the dictionary\")\n\n        )\n\n        )\n\n            yield \"missing\", input_data.input\n", "blocks": [{"id": 1, "label": "class FindInDictionaryBlock(Block):\n    key: str | int = SchemaField(description=\"Key to lookup in the dictionary\")", "successors": []}]}, {"name": "AgentInputBlock", "type": "class", "start_line": 134, "end_line": 215, "functions": [{"name": "__init__", "type": "function", "start_line": 181, "end_line": 210, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"c0a8e994-ebf1-4a9c-a4d8-89d09c86741b\",\n            description=\"This block is used to provide input to the graph.\",\n            input_schema=AgentInputBlock.Input,\n            output_schema=AgentInputBlock.Output,\n            test_input=[\n                {\n                    \"value\": \"Hello, World!\",\n                    \"name\": \"input_1\",\n                    \"description\": \"This is a test input.\",\n                    \"placeholder_values\": [],\n                    \"limit_to_placeholder_values\": False,\n                },\n                {\n                    \"value\": \"Hello, World!\",\n                    \"name\": \"input_2\",\n                    \"description\": \"This is a test input.\",\n                    \"placeholder_values\": [\"Hello, World!\"],\n                    \"limit_to_placeholder_values\": True,\n                },\n            ],\n            test_output=[\n                (\"result\", \"Hello, World!\"),\n                (\"result\", \"Hello, World!\"),\n            ],\n            categories={BlockCategory.INPUT, BlockCategory.BASIC},\n            block_type=BlockType.INPUT,\n            static_output=True,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\n    super().__init__(\n        id=\"c0a8e994-ebf1-4a9c-a4d8-89d09c86741b\",\n        description=\"This block is used to provide input to the graph.\",\n        input_schema=AgentInputBlock.Input,\n        output_schema=AgentInputBlock.Output,\n        test_input=[\n            {\n                \"value\": \"Hello, World!\",\n                \"name\": \"input_1\",\n                \"description\": \"This is a test input.\",\n                \"placeholder_values\": [],\n                \"limit_to_placeholder_values\": False,\n            },\n            {\n                \"value\": \"Hello, World!\",\n                \"name\": \"input_2\",\n                \"description\": \"This is a test input.\",\n                \"placeholder_values\": [\"Hello, World!\"],\n                \"limit_to_placeholder_values\": True,\n            },\n        ],\n        test_output=[\n            (\"result\", \"Hello, World!\"),\n            (\"result\", \"Hello, World!\"),\n        ],\n        categories={BlockCategory.INPUT, BlockCategory.BASIC},\n        block_type=BlockType.INPUT,\n        static_output=True,\n    )", "successors": []}]}, {"name": "run", "type": "function", "start_line": 212, "end_line": 213, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        yield \"result\", input_data.value", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\nyield \"result\", input_data.value", "successors": []}]}], "classes": [{"name": "Input", "type": "class", "start_line": 143, "end_line": 176, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        name: str = SchemaField(description=\"The name of the input.\")\n        value: Any = SchemaField(\n            description=\"The value to be passed as input.\",\n            default=None,\n        )\n        title: str | None = SchemaField(\n            description=\"The title of the input.\", default=None, advanced=True\n        )\n        description: str | None = SchemaField(\n            description=\"The description of the input.\",\n            default=None,\n            advanced=True,\n        )\n        placeholder_values: List[Any] = SchemaField(\n            description=\"The placeholder values to be passed as input.\",\n            default=[],\n            advanced=True,\n        )\n        limit_to_placeholder_values: bool = SchemaField(\n            description=\"Whether to limit the selection to placeholder values.\",\n            default=False,\n            advanced=True,\n        )\n        advanced: bool = SchemaField(\n            description=\"Whether to show the input in the advanced section, if the field is not required.\",\n            default=False,\n            advanced=True,\n        )\n        secret: bool = SchemaField(\n            description=\"Whether the input should be treated as a secret.\",\n            default=False,\n            advanced=True,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\nname: str = SchemaField(description=\"The name of the input.\")", "successors": [{"id": 3, "label": "value: Any = SchemaField(description=\"The value to be passed as input.\", default=None,)\ntitle: str | None = SchemaField(description=\"The title of the input.\", default=None, advanced=True)", "successors": [{"id": 5, "label": "description: str | None = SchemaField(description=\"The description of the input.\", default=None, advanced=True,)\nplaceholder_values: List[Any] = SchemaField(description=\"The placeholder values to be passed as input.\", default=[], advanced=True,)", "successors": [{"id": 7, "label": "limit_to_placeholder_values: bool = SchemaField(description=\"Whether to limit the selection to placeholder values.\", default=False, advanced=True,)\nadvanced: bool = SchemaField(description=\"Whether to show the input in the advanced section, if the field is not required.\", default=False, advanced=True,)", "successors": [{"id": 9, "label": "secret: bool = SchemaField(description=\"Whether the input should be treated as a secret.\", default=False, advanced=True,)", "successors": []}]}]}]}]}]}, {"name": "Output", "type": "class", "start_line": 178, "end_line": 179, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        result: Any = SchemaField(description=\"The value passed as input.\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    result: Any = SchemaField(description=\"The value passed as input.\")", "successors": []}]}], "simplified_code": "class AgentInputBlock(Block):\n    \"\"\"\n    This block is used to provide input to the graph.\n\n    It takes in a value, name, description, default values list and bool to limit selection to default values.\n\n    It Outputs the value passed as input.\n    \"\"\"\n\n        )\n\n        result: Any = SchemaField(description=\"The value passed as input.\")\n\n        )\n\n        yield \"result\", input_data.value\n\n", "blocks": [{"id": 1, "label": "class AgentInputBlock(Block):\n    \"\"\"\n    This block is used to provide input to the graph.\n\n    It takes in a value, name, description, default values list and bool to limit selection to default values.\n\n    It Outputs the value passed as input.\n    \"\"\"\nresult: Any = SchemaField(description=\"The value passed as input.\")", "successors": [{"id": 3, "label": "yield \"result\", input_data.value", "successors": []}]}]}, {"name": "AgentOutputBlock", "type": "class", "start_line": 216, "end_line": 312, "functions": [{"name": "__init__", "type": "function", "start_line": 262, "end_line": 296, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"363ae599-353e-4804-937e-b2ee3cef3da4\",\n            description=\"Stores the output of the graph for users to see.\",\n            input_schema=AgentOutputBlock.Input,\n            output_schema=AgentOutputBlock.Output,\n            test_input=[\n                {\n                    \"value\": \"Hello, World!\",\n                    \"name\": \"output_1\",\n                    \"description\": \"This is a test output.\",\n                    \"format\": \"{{ output_1 }}!!\",\n                },\n                {\n                    \"value\": \"42\",\n                    \"name\": \"output_2\",\n                    \"description\": \"This is another test output.\",\n                    \"format\": \"{{ output_2 }}\",\n                },\n                {\n                    \"value\": MockObject(value=\"!!\", key=\"key\"),\n                    \"name\": \"output_3\",\n                    \"description\": \"This is a test output with a mock object.\",\n                    \"format\": \"{{ output_3 }}\",\n                },\n            ],\n            test_output=[\n                (\"output\", \"Hello, World!!!\"),\n                (\"output\", \"42\"),\n                (\"output\", MockObject(value=\"!!\", key=\"key\")),\n            ],\n            categories={BlockCategory.OUTPUT, BlockCategory.BASIC},\n            block_type=BlockType.OUTPUT,\n            static_output=True,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"363ae599-353e-4804-937e-b2ee3cef3da4\",\n    description=\"Stores the output of the graph for users to see.\",\n    input_schema=AgentOutputBlock.Input,\n    output_schema=AgentOutputBlock.Output,\n    test_input=[\n        {\n            \"value\": \"Hello, World!\",\n            \"name\": \"output_1\",\n            \"description\": \"This is a test output.\",\n            \"format\": \"{{ output_1 }}!!\",\n        },\n        {\n            \"value\": \"42\",\n            \"name\": \"output_2\",\n            \"description\": \"This is another test output.\",\n            \"format\": \"{{ output_2 }}\",\n        },\n        {\n            \"value\": MockObject(value=\"!!\", key=\"key\"),\n            \"name\": \"output_3\",\n            \"description\": \"This is a test output with a mock object.\",\n            \"format\": \"{{ output_3 }}\",\n        },\n    ],\n    test_output=[\n        (\"output\", \"Hello, World!!!\"),\n        (\"output\", \"42\"),\n        (\"output\", MockObject(value=\"!!\", key=\"key\")),\n    ],\n    categories={BlockCategory.OUTPUT, BlockCategory.BASIC},\n    block_type=BlockType.OUTPUT,\n    static_output=True,\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 298, "end_line": 311, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        \"\"\"\n        Attempts to format the recorded_value using the fmt_string if provided.\n        If formatting fails or no fmt_string is given, returns the original recorded_value.\n        \"\"\"\n        if input_data.format:\n            try:\n                yield \"output\", formatter.format_string(\n                    input_data.format, {input_data.name: input_data.value}\n                )\n            except Exception as e:\n                yield \"output\", f\"Error: {e}, {input_data.value}\"\n        else:\n            yield \"output\", input_data.value", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:", "successors": [{"id": 2, "label": "if input_data.format:\ntry:", "successors": [{"id": 4, "label": "yield \"output\", formatter.format_string(input_data.format, {input_data.name: input_data.value})\nyield \"output\", input_data.value", "successors": []}, {"id": 5, "label": "except Exception as e:\nyield \"output\", f\"Error: {e}, {input_data.value}\"", "successors": [{"id": 6, "label": "yield \"output\", input_data.value", "successors": []}]}]}, {"id": 6, "label": "yield \"output\", input_data.value", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 226, "end_line": 257, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        value: Any = SchemaField(\n            description=\"The value to be recorded as output.\",\n            default=None,\n            advanced=False,\n        )\n        name: str = SchemaField(description=\"The name of the output.\")\n        title: str | None = SchemaField(\n            description=\"The title of the output.\",\n            default=None,\n            advanced=True,\n        )\n        description: str | None = SchemaField(\n            description=\"The description of the output.\",\n            default=None,\n            advanced=True,\n        )\n        format: str = SchemaField(\n            description=\"The format string to be used to format the recorded_value.\",\n            default=\"\",\n            advanced=True,\n        )\n        advanced: bool = SchemaField(\n            description=\"Whether to treat the output as advanced.\",\n            default=False,\n            advanced=True,\n        )\n        secret: bool = SchemaField(\n            description=\"Whether the output should be treated as a secret.\",\n            default=False,\n            advanced=True,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    value: Any = SchemaField(description=\"The value to be recorded as output.\", default=None, advanced=False,)", "successors": []}, {"id": 3, "label": "    name: str = SchemaField(description=\"The name of the output.\")", "successors": []}, {"id": 4, "label": "    title: str | None = SchemaField(description=\"The title of the output.\", default=None, advanced=True,)", "successors": []}, {"id": 5, "label": "    description: str | None = SchemaField(description=\"The description of the output.\", default=None, advanced=True,)", "successors": []}, {"id": 6, "label": "    format: str = SchemaField(description=\"The format string to be used to format the recorded_value.\", default=\"\", advanced=True,)", "successors": []}, {"id": 7, "label": "    advanced: bool = SchemaField(description=\"Whether to treat the output as advanced.\", default=False, advanced=True,)", "successors": []}, {"id": 8, "label": "    secret: bool = SchemaField(description=\"Whether the output should be treated as a secret.\", default=False, advanced=True,)", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 259, "end_line": 260, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        output: Any = SchemaField(description=\"The value recorded as output.\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\noutput: Any = SchemaField(description=\"The value recorded as output.\")", "successors": []}]}], "simplified_code": "class AgentOutputBlock(Block):\n    \"\"\"\n    Records the output of the graph for users to see.\n\n    Behavior:\n        If `format` is provided and the `value` is of a type that can be formatted,\n        the block attempts to format the recorded_value using the `format`.\n        If formatting fails or no `format` is provided, the raw `value` is output.\n    \"\"\"\n\n        )\n\n        output: Any = SchemaField(description=\"The value recorded as output.\")\n\n        )\n\n            yield \"output\", input_data.value\n", "blocks": [{"id": 1, "label": "class AgentOutputBlock(Block):\n\"\"\"\nRecords the output of the graph for users to see.\n\nBehavior:\n    If `format` is provided and the `value` is of a type that can be formatted,\n    the block attempts to format the recorded_value using the `format`.\n    If formatting fails or no `format` is provided, the raw `value` is output.\n\"\"\"", "successors": [{"id": 3, "label": "output: Any = SchemaField(description=\"The value recorded as output.\")\nyield \"output\", input_data.value", "successors": []}]}]}, {"name": "AddToDictionaryBlock", "type": "class", "start_line": 314, "end_line": 391, "functions": [{"name": "__init__", "type": "function", "start_line": 344, "end_line": 378, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"31d1064e-7446-4693-a7d4-65e5ca1180d1\",\n            description=\"Adds a new key-value pair to a dictionary. If no dictionary is provided, a new one is created.\",\n            categories={BlockCategory.BASIC},\n            input_schema=AddToDictionaryBlock.Input,\n            output_schema=AddToDictionaryBlock.Output,\n            test_input=[\n                {\n                    \"dictionary\": {\"existing_key\": \"existing_value\"},\n                    \"key\": \"new_key\",\n                    \"value\": \"new_value\",\n                },\n                {\"key\": \"first_key\", \"value\": \"first_value\"},\n                {\n                    \"dictionary\": {\"existing_key\": \"existing_value\"},\n                    \"entries\": {\"new_key\": \"new_value\", \"first_key\": \"first_value\"},\n                },\n            ],\n            test_output=[\n                (\n                    \"updated_dictionary\",\n                    {\"existing_key\": \"existing_value\", \"new_key\": \"new_value\"},\n                ),\n                (\"updated_dictionary\", {\"first_key\": \"first_value\"}),\n                (\n                    \"updated_dictionary\",\n                    {\n                        \"existing_key\": \"existing_value\",\n                        \"new_key\": \"new_value\",\n                        \"first_key\": \"first_value\",\n                    },\n                ),\n            ],\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\n    super().__init__(\n        id=\"31d1064e-7446-4693-a7d4-65e5ca1180d1\",\n        description=\"Adds a new key-value pair to a dictionary. If no dictionary is provided, a new one is created.\",\n        categories={BlockCategory.BASIC},\n        input_schema=AddToDictionaryBlock.Input,\n        output_schema=AddToDictionaryBlock.Output,\n        test_input=[\n            {\n                \"dictionary\": {\"existing_key\": \"existing_value\"},\n                \"key\": \"new_key\",\n                \"value\": \"new_value\",\n            },\n            {\"key\": \"first_key\", \"value\": \"first_value\"},\n            {\n                \"dictionary\": {\"existing_key\": \"existing_value\"},\n                \"entries\": {\"new_key\": \"new_value\", \"first_key\": \"first_value\"},\n            },\n        ],\n        test_output=[\n            (\n                \"updated_dictionary\",\n                {\"existing_key\": \"existing_value\", \"new_key\": \"new_value\"},\n            ),\n            (\"updated_dictionary\", {\"first_key\": \"first_value\"}),\n            (\n                \"updated_dictionary\",\n                {\n                    \"existing_key\": \"existing_value\",\n                    \"new_key\": \"new_value\",\n                    \"first_key\": \"first_value\",\n                },\n            ),\n        ],\n    )", "successors": []}]}, {"name": "run", "type": "function", "start_line": 380, "end_line": 389, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        updated_dict = input_data.dictionary.copy()\n\n        if input_data.value is not None and input_data.key:\n            updated_dict[input_data.key] = input_data.value\n\n        for key, value in input_data.entries.items():\n            updated_dict[key] = value\n\n        yield \"updated_dictionary\", updated_dict", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\nupdated_dict = input_data.dictionary.copy()", "successors": [{"id": 3, "label": "if input_data.value is not None and input_data.key:", "successors": [{"id": 4, "label": "    updated_dict[input_data.key] = input_data.value", "successors": [{"id": 5, "label": "for key, value in input_data.entries.items():", "successors": [{"id": 6, "label": "    updated_dict[key] = value", "successors": [{"id": 7, "label": "yield \"updated_dictionary\", updated_dict", "successors": []}, {"id": 5, "label": "for key, value in input_data.entries.items():", "successors": []}]}]}]}, {"id": 5, "label": "for key, value in input_data.entries.items():", "successors": [{"id": 6, "label": "    updated_dict[key] = value", "successors": [{"id": 7, "label": "yield \"updated_dictionary\", updated_dict", "successors": []}, {"id": 5, "label": "for key, value in input_data.entries.items():", "successors": []}]}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 315, "end_line": 336, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        dictionary: dict[Any, Any] = SchemaField(\n            default={},\n            description=\"The dictionary to add the entry to. If not provided, a new dictionary will be created.\",\n        )\n        key: str = SchemaField(\n            default=\"\",\n            description=\"The key for the new entry.\",\n            placeholder=\"new_key\",\n            advanced=False,\n        )\n        value: Any = SchemaField(\n            default=None,\n            description=\"The value for the new entry.\",\n            placeholder=\"new_value\",\n            advanced=False,\n        )\n        entries: dict[Any, Any] = SchemaField(\n            default={},\n            description=\"The entries to add to the dictionary. This is the batch version of the `key` and `value` fields.\",\n            advanced=True,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    dictionary: dict[Any, Any] = SchemaField(\n        default={},\n        description=\"The dictionary to add the entry to. If not provided, a new dictionary will be created.\",\n    )", "successors": []}, {"id": 3, "label": "    key: str = SchemaField(\n        default=\"\",\n        description=\"The key for the new entry.\",\n        placeholder=\"new_key\",\n        advanced=False,\n    )", "successors": []}, {"id": 4, "label": "    value: Any = SchemaField(\n        default=None,\n        description=\"The value for the new entry.\",\n        placeholder=\"new_value\",\n        advanced=False,\n    )", "successors": []}, {"id": 5, "label": "    entries: dict[Any, Any] = SchemaField(\n        default={},\n        description=\"The entries to add to the dictionary. This is the batch version of the `key` and `value` fields.\",\n        advanced=True,\n    )", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 338, "end_line": 342, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        updated_dictionary: dict = SchemaField(\n            description=\"The dictionary with the new entry added.\"\n        )\n        error: str = SchemaField(description=\"Error message if the operation failed.\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "    updated_dictionary: dict = SchemaField(description=\"The dictionary with the new entry added.\")", "successors": []}, {"id": 3, "label": "    error: str = SchemaField(description=\"Error message if the operation failed.\")", "successors": []}]}]}], "simplified_code": "class AddToDictionaryBlock(Block):\n        )\n\n        error: str = SchemaField(description=\"Error message if the operation failed.\")\n\n        )\n\n        yield \"updated_dictionary\", updated_dict\n\n", "blocks": [{"id": 1, "label": "class AddToDictionaryBlock(Block):", "successors": [{"id": 2, "label": ")", "successors": []}, {"id": 3, "label": "error: str = SchemaField(description=\"Error message if the operation failed.\")", "successors": []}, {"id": 4, "label": ")", "successors": []}, {"id": 5, "label": "yield \"updated_dictionary\", updated_dict", "successors": []}]}]}, {"name": "AddToListBlock", "type": "class", "start_line": 392, "end_line": 471, "functions": [{"name": "__init__", "type": "function", "start_line": 420, "end_line": 456, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"aeb08fc1-2fc1-4141-bc8e-f758f183a822\",\n            description=\"Adds a new entry to a list. The entry can be of any type. If no list is provided, a new one is created.\",\n            categories={BlockCategory.BASIC},\n            input_schema=AddToListBlock.Input,\n            output_schema=AddToListBlock.Output,\n            test_input=[\n                {\n                    \"list\": [1, \"string\", {\"existing_key\": \"existing_value\"}],\n                    \"entry\": {\"new_key\": \"new_value\"},\n                    \"position\": 1,\n                },\n                {\"entry\": \"first_entry\"},\n                {\"list\": [\"a\", \"b\", \"c\"], \"entry\": \"d\"},\n                {\n                    \"entry\": \"e\",\n                    \"entries\": [\"f\", \"g\"],\n                    \"list\": [\"a\", \"b\"],\n                    \"position\": 1,\n                },\n            ],\n            test_output=[\n                (\n                    \"updated_list\",\n                    [\n                        1,\n                        {\"new_key\": \"new_value\"},\n                        \"string\",\n                        {\"existing_key\": \"existing_value\"},\n                    ],\n                ),\n                (\"updated_list\", [\"first_entry\"]),\n                (\"updated_list\", [\"a\", \"b\", \"c\", \"d\"]),\n                (\"updated_list\", [\"a\", \"f\", \"g\", \"e\", \"b\"]),\n            ],\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(id=\"aeb08fc1-2fc1-4141-bc8e-f758f183a822\", description=\"Adds a new entry to a list. The entry can be of any type. If no list is provided, a new one is created.\", categories={BlockCategory.BASIC}, input_schema=AddToListBlock.Input, output_schema=AddToListBlock.Output, test_input=[ { \"list\": [1, \"string\", {\"existing_key\": \"existing_value\"}], \"entry\": {\"new_key\": \"new_value\"}, \"position\": 1, }, {\"entry\": \"first_entry\"}, {\"list\": [\"a\", \"b\", \"c\"], \"entry\": \"d\"}, { \"entry\": \"e\", \"entries\": [\"f\", \"g\"], \"list\": [\"a\", \"b\"], \"position\": 1, }, ], test_output=[ ( \"updated_list\", [ 1, {\"new_key\": \"new_value\"}, \"string\", {\"existing_key\": \"existing_value\"}, ], ), (\"updated_list\", [\"first_entry\"]), (\"updated_list\", [\"a\", \"b\", \"c\", \"d\"]), (\"updated_list\", [\"a\", \"f\", \"g\", \"e\", \"b\"]), ], )", "successors": []}]}, {"name": "run", "type": "function", "start_line": 458, "end_line": 469, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        entries_added = input_data.entries.copy()\n        if input_data.entry:\n            entries_added.append(input_data.entry)\n\n        updated_list = input_data.list.copy()\n        if (pos := input_data.position) is not None:\n            updated_list = updated_list[:pos] + entries_added + updated_list[pos:]\n        else:\n            updated_list += entries_added\n\n        yield \"updated_list\", updated_list", "blocks": [{"id": 1, "label": "entries_added = input_data.entries.copy()\nif input_data.entry:", "successors": [{"id": 3, "label": "    entries_added.append(input_data.entry)\nupdated_list = input_data.list.copy()", "successors": [{"id": 5, "label": "if (pos := input_data.position) is not None:", "successors": [{"id": 6, "label": "    updated_list = updated_list[:pos] + entries_added + updated_list[pos:]\nyield \"updated_list\", updated_list", "successors": []}, {"id": 7, "label": "    updated_list += entries_added\nyield \"updated_list\", updated_list", "successors": []}]}]}, {"id": 4, "label": "updated_list = input_data.list.copy()\nif (pos := input_data.position) is not None:", "successors": [{"id": 6, "label": "    updated_list = updated_list[:pos] + entries_added + updated_list[pos:]\nyield \"updated_list\", updated_list", "successors": []}, {"id": 7, "label": "    updated_list += entries_added\nyield \"updated_list\", updated_list", "successors": []}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 393, "end_line": 412, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        list: List[Any] = SchemaField(\n            default=[],\n            advanced=False,\n            description=\"The list to add the entry to. If not provided, a new list will be created.\",\n        )\n        entry: Any = SchemaField(\n            description=\"The entry to add to the list. Can be of any type (string, int, dict, etc.).\",\n            advanced=False,\n            default=None,\n        )\n        entries: List[Any] = SchemaField(\n            default=[],\n            description=\"The entries to add to the list. This is the batch version of the `entry` field.\",\n            advanced=True,\n        )\n        position: int | None = SchemaField(\n            default=None,\n            description=\"The position to insert the new entry. If not provided, the entry will be appended to the end of the list.\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    list: List[Any] = SchemaField(\n        default=[],\n        advanced=False,\n        description=\"The list to add the entry to. If not provided, a new list will be created.\"\n    )", "successors": []}, {"id": 3, "label": "    entry: Any = SchemaField(\n        description=\"The entry to add to the list. Can be of any type (string, int, dict, etc.)\",\n        advanced=False,\n        default=None\n    )", "successors": []}, {"id": 4, "label": "    entries: List[Any] = SchemaField(\n        default=[],\n        description=\"The entries to add to the list. This is the batch version of the `entry` field.\",\n        advanced=True\n    )", "successors": []}, {"id": 5, "label": "    position: int | None = SchemaField(\n        default=None,\n        description=\"The position to insert the new entry. If not provided, the entry will be appended to the end of the list.\"\n    )", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 414, "end_line": 418, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        updated_list: List[Any] = SchemaField(\n            description=\"The list with the new entry added.\"\n        )\n        error: str = SchemaField(description=\"Error message if the operation failed.\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\nupdated_list: List[Any] = SchemaField(description=\"The list with the new entry added.\")", "successors": [{"id": 3, "label": "error: str = SchemaField(description=\"Error message if the operation failed.\")", "successors": []}]}]}], "simplified_code": "class AddToListBlock(Block):\n        )\n\n        error: str = SchemaField(description=\"Error message if the operation failed.\")\n\n        )\n\n        yield \"updated_list\", updated_list\n\n", "blocks": [{"id": 1, "label": "class AddToListBlock(Block):\n    pass", "successors": []}]}, {"name": "NoteBlock", "type": "class", "start_line": 472, "end_line": 496, "functions": [{"name": "__init__", "type": "function", "start_line": 479, "end_line": 491, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"cc10ff7b-7753-4ff2-9af6-9399b1a7eddc\",\n            description=\"This block is used to display a sticky note with the given text.\",\n            categories={BlockCategory.BASIC},\n            input_schema=NoteBlock.Input,\n            output_schema=NoteBlock.Output,\n            test_input={\"text\": \"Hello, World!\"},\n            test_output=[\n                (\"output\", \"Hello, World!\"),\n            ],\n            block_type=BlockType.NOTE,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"cc10ff7b-7753-4ff2-9af6-9399b1a7eddc\",\n    description=\"This block is used to display a sticky note with the given text.\",\n    categories={BlockCategory.BASIC},\n    input_schema=NoteBlock.Input,\n    output_schema=NoteBlock.Output,\n    test_input={\"text\": \"Hello, World!\"},\n    test_output=[\n        (\"output\", \"Hello, World!\"),\n    ],\n    block_type=BlockType.NOTE,\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 493, "end_line": 494, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        yield \"output\", input_data.text", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\n    yield \"output\", input_data.text", "successors": []}]}], "classes": [{"name": "Input", "type": "class", "start_line": 473, "end_line": 474, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        text: str = SchemaField(description=\"The text to display in the sticky note.\")", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    text: str = SchemaField(description=\"The text to display in the sticky note.\")", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 476, "end_line": 477, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        output: str = SchemaField(description=\"The text to display in the sticky note.\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    output: str = SchemaField(description=\"The text to display in the sticky note.\")", "successors": []}]}], "simplified_code": "class NoteBlock(Block):\n        text: str = SchemaField(description=\"The text to display in the sticky note.\")\n\n        output: str = SchemaField(description=\"The text to display in the sticky note.\")\n\n        )\n\n        yield \"output\", input_data.text\n\n", "blocks": [{"id": 1, "label": "class NoteBlock(Block):\n    text: str = SchemaField(description=\"The text to display in the sticky note.\")", "successors": [{"id": 3, "label": "    output: str = SchemaField(description=\"The text to display in the sticky note.\")\n    yield \"output\", input_data.text", "successors": []}]}]}, {"name": "CreateDictionaryBlock", "type": "class", "start_line": 497, "end_line": 546, "functions": [{"name": "__init__", "type": "function", "start_line": 512, "end_line": 537, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"b924ddf4-de4f-4b56-9a85-358930dcbc91\",\n            description=\"Creates a dictionary with the specified key-value pairs. Use this when you know all the values you want to add upfront.\",\n            categories={BlockCategory.DATA},\n            input_schema=CreateDictionaryBlock.Input,\n            output_schema=CreateDictionaryBlock.Output,\n            test_input=[\n                {\n                    \"values\": {\"name\": \"Alice\", \"age\": 25, \"city\": \"New York\"},\n                },\n                {\n                    \"values\": {\"numbers\": [1, 2, 3], \"active\": True, \"score\": 95.5},\n                },\n            ],\n            test_output=[\n                (\n                    \"dictionary\",\n                    {\"name\": \"Alice\", \"age\": 25, \"city\": \"New York\"},\n                ),\n                (\n                    \"dictionary\",\n                    {\"numbers\": [1, 2, 3], \"active\": True, \"score\": 95.5},\n                ),\n            ],\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"b924ddf4-de4f-4b56-9a85-358930dcbc91\",\n    description=\"Creates a dictionary with the specified key-value pairs. Use this when you know all the values you want to add upfront.\",\n    categories={BlockCategory.DATA},\n    input_schema=CreateDictionaryBlock.Input,\n    output_schema=CreateDictionaryBlock.Output,\n    test_input=[\n        {\n            \"values\": {\"name\": \"Alice\", \"age\": 25, \"city\": \"New York\"},\n        },\n        {\n            \"values\": {\"numbers\": [1, 2, 3], \"active\": True, \"score\": 95.5},\n        },\n    ],\n    test_output=[\n        (\n            \"dictionary\",\n            {\"name\": \"Alice\", \"age\": 25, \"city\": \"New York\"},\n        ),\n        (\n            \"dictionary\",\n            {\"numbers\": [1, 2, 3], \"active\": True, \"score\": 95.5},\n        ),\n    ],\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 539, "end_line": 544, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        try:\n            # The values are already validated by Pydantic schema\n            yield \"dictionary\", input_data.values\n        except Exception as e:\n            yield \"error\", f\"Failed to create dictionary: {str(e)}\"", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\ntry:", "successors": [{"id": 3, "label": "    yield \"dictionary\", input_data.values", "successors": []}, {"id": 4, "label": "except Exception as e:\n    yield \"error\", f\"Failed to create dictionary: {str(e)}\"", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 498, "end_line": 502, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        values: dict[str, Any] = SchemaField(\n            description=\"Key-value pairs to create the dictionary with\",\n            placeholder=\"e.g., {'name': 'Alice', 'age': 25}\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    values: dict[str, Any] = SchemaField(description=\"Key-value pairs to create the dictionary with\", placeholder=\"e.g., {'name': 'Alice', 'age': 25}\")", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 504, "end_line": 510, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        dictionary: dict[str, Any] = SchemaField(\n            description=\"The created dictionary containing the specified key-value pairs\"\n        )\n        error: str = SchemaField(\n            description=\"Error message if dictionary creation failed\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\ndictionary: dict[str, Any] = SchemaField(description=\"The created dictionary containing the specified key-value pairs\")", "successors": [{"id": 3, "label": "error: str = SchemaField(description=\"Error message if dictionary creation failed\")", "successors": []}]}]}], "simplified_code": "class CreateDictionaryBlock(Block):\n        )\n\n        )\n\n        )\n\n            yield \"error\", f\"Failed to create dictionary: {str(e)}\"\n\n", "blocks": [{"id": 1, "label": "class CreateDictionaryBlock(Block):\ndef execute(self):", "successors": [{"id": 3, "label": "dictionary = {}\ntry:", "successors": [{"id": 5, "label": "dictionary['key'] = 'value'\nreturn dictionary", "successors": []}, {"id": 7, "label": "except Exception as e:\nyield \"error\", f\"Failed to create dictionary: {str(e)}\"", "successors": []}]}]}]}, {"name": "CreateListBlock", "type": "class", "start_line": 547, "end_line": 592, "functions": [{"name": "__init__", "type": "function", "start_line": 560, "end_line": 585, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"a912d5c7-6e00-4542-b2a9-8034136930e4\",\n            description=\"Creates a list with the specified values. Use this when you know all the values you want to add upfront.\",\n            categories={BlockCategory.DATA},\n            input_schema=CreateListBlock.Input,\n            output_schema=CreateListBlock.Output,\n            test_input=[\n                {\n                    \"values\": [\"Alice\", 25, True],\n                },\n                {\n                    \"values\": [1, 2, 3, \"four\", {\"key\": \"value\"}],\n                },\n            ],\n            test_output=[\n                (\n                    \"list\",\n                    [\"Alice\", 25, True],\n                ),\n                (\n                    \"list\",\n                    [1, 2, 3, \"four\", {\"key\": \"value\"}],\n                ),\n            ],\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\n    super().__init__(\n        id=\"a912d5c7-6e00-4542-b2a9-8034136930e4\",\n        description=\"Creates a list with the specified values. Use this when you know all the values you want to add upfront.\",\n        categories={BlockCategory.DATA},\n        input_schema=CreateListBlock.Input,\n        output_schema=CreateListBlock.Output,\n        test_input=[\n            {\n                \"values\": [\"Alice\", 25, True],\n            },\n            {\n                \"values\": [1, 2, 3, \"four\", {\"key\": \"value\"}],\n            },\n        ],\n        test_output=[\n            (\n                \"list\",\n                [\"Alice\", 25, True],\n            ),\n            (\n                \"list\",\n                [1, 2, 3, \"four\", {\"key\": \"value\"}],\n            ),\n        ],\n    )", "successors": []}]}, {"name": "run", "type": "function", "start_line": 587, "end_line": 592, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        try:\n            # The values are already validated by Pydantic schema\n            yield \"list\", input_data.values\n        except Exception as e:\n            yield \"error\", f\"Failed to create list: {str(e)}\"", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\ntry:", "successors": [{"id": 3, "label": "    yield \"list\", input_data.values", "successors": []}, {"id": 4, "label": "except Exception as e:\n    yield \"error\", f\"Failed to create list: {str(e)}\"", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 548, "end_line": 552, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        values: List[Any] = SchemaField(\n            description=\"A list of values to be combined into a new list.\",\n            placeholder=\"e.g., ['Alice', 25, True]\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    values: List[Any] = SchemaField(description=\"A list of values to be combined into a new list.\", placeholder=\"e.g., ['Alice', 25, True]\")", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 554, "end_line": 558, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        list: List[Any] = SchemaField(\n            description=\"The created list containing the specified values.\"\n        )\n        error: str = SchemaField(description=\"Error message if list creation failed.\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    list: List[Any] = SchemaField(description=\"The created list containing the specified values.\")", "successors": [{"id": 3, "label": "    error: str = SchemaField(description=\"Error message if list creation failed.\")", "successors": []}]}]}], "simplified_code": "class CreateListBlock(Block):\n        )\n\n        error: str = SchemaField(description=\"Error message if list creation failed.\")\n\n        )\n\n            yield \"error\", f\"Failed to create list: {str(e)}\"", "blocks": [{"id": 1, "label": "class CreateListBlock(Block):", "successors": [{"id": 2, "label": "error: str = SchemaField(description=\"Error message if list creation failed.\")", "successors": []}, {"id": 3, "label": "yield \"error\", f\"Failed to create list: {str(e)}\"", "successors": []}]}]}], "simplified_code": "from typing import Any, List\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema, BlockType\nfrom backend.data.model import SchemaField\nfrom backend.util.mock import MockObject\nfrom backend.util.text import TextFormatter\n\nformatter = TextFormatter()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n            yield \"error\", f\"Failed to create list: {str(e)}\"", "blocks": [{"id": 1, "label": "from typing import Any, List\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema, BlockType\nfrom backend.data.model import SchemaField\nfrom backend.util.mock import MockObject\nfrom backend.util.text import TextFormatter\n\nformatter = TextFormatter()", "successors": []}]}
{"file_name": "152.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 71, "functions": [{"name": "wait_for_postgres", "type": "function", "start_line": 6, "end_line": 34, "functions": [], "classes": [], "simplified_code": "def wait_for_postgres(max_retries=5, delay=5):\n    for _ in range(max_retries):\n        try:\n            result = subprocess.run(\n                [\n                    \"docker\",\n                    \"compose\",\n                    \"-f\",\n                    \"docker-compose.test.yaml\",\n                    \"exec\",\n                    \"postgres-test\",\n                    \"pg_isready\",\n                    \"-U\",\n                    \"postgres\",\n                    \"-d\",\n                    \"postgres\",\n                ],\n                check=True,\n                capture_output=True,\n                text=True,\n            )\n            if \"accepting connections\" in result.stdout:\n                print(\"PostgreSQL is ready.\")\n                return True\n        except subprocess.CalledProcessError:\n            print(f\"PostgreSQL is not ready yet. Retrying in {delay} seconds...\")\n            time.sleep(delay)\n    print(\"Failed to connect to PostgreSQL.\")\n    return False", "blocks": [{"id": 1, "label": "def wait_for_postgres(max_retries=5, delay=5):", "successors": [{"id": 2, "label": "for _ in range(max_retries):", "successors": [{"id": 3, "label": "try:\nresult = subprocess.run(\n    [\n        \"docker\",\n        \"compose\",\n        \"-f\",\n        \"docker-compose.test.yaml\",\n        \"exec\",\n        \"postgres-test\",\n        \"pg_isready\",\n        \"-U\",\n        \"postgres\",\n        \"-d\",\n        \"postgres\",\n    ],\n    check=True,\n    capture_output=True,\n    text=True,\n)", "successors": [{"id": 5, "label": "if \"accepting connections\" in result.stdout:\nprint(\"PostgreSQL is ready.\")", "successors": [{"id": 7, "label": "return True", "successors": []}]}]}, {"id": 8, "label": "except subprocess.CalledProcessError:\nprint(f\"PostgreSQL is not ready yet. Retrying in {delay} seconds...\")", "successors": [{"id": 10, "label": "time.sleep(delay)", "successors": []}]}]}, {"id": 11, "label": "print(\"Failed to connect to PostgreSQL.\")\nreturn False", "successors": []}]}]}, {"name": "run_command", "type": "function", "start_line": 37, "end_line": 42, "functions": [], "classes": [], "simplified_code": "def run_command(command, check=True):\n    try:\n        subprocess.run(command, check=check)\n    except subprocess.CalledProcessError as e:\n        print(f\"Command failed: {e}\")\n        sys.exit(1)", "blocks": [{"id": 1, "label": "def run_command(command, check=True):\ntry:", "successors": [{"id": 3, "label": "subprocess.run(command, check=check)\n", "successors": []}, {"id": 4, "label": "except subprocess.CalledProcessError as e:\nprint(f\"Command failed: {e}\")\nsys.exit(1)", "successors": []}]}]}, {"name": "test", "type": "function", "start_line": 45, "end_line": 71, "functions": [], "classes": [], "simplified_code": "def test():\n    # Start PostgreSQL with Docker Compose\n    run_command(\n        [\n            \"docker\",\n            \"compose\",\n            \"-f\",\n            \"docker-compose.test.yaml\",\n            \"up\",\n            \"-d\",\n            \"postgres-test\",\n        ]\n    )\n\n    if not wait_for_postgres():\n        run_command([\"docker\", \"compose\", \"-f\", \"docker-compose.test.yaml\", \"down\"])\n        sys.exit(1)\n\n    # Run Prisma migrations\n    run_command([\"prisma\", \"migrate\", \"dev\"])\n\n    # Run the tests\n    result = subprocess.run([\"pytest\"] + sys.argv[1:], check=False)\n\n    run_command([\"docker\", \"compose\", \"-f\", \"docker-compose.test.yaml\", \"down\"])\n\n    sys.exit(result.returncode)", "blocks": [{"id": 1, "label": "def test():\nrun_command([\n    \"docker\",\n    \"compose\",\n    \"-f\",\n    \"docker-compose.test.yaml\",\n    \"up\",\n    \"-d\",\n    \"postgres-test\",\n])", "successors": [{"id": 3, "label": "if not wait_for_postgres():", "successors": [{"id": 4, "label": "    run_command([\"docker\", \"compose\", \"-f\", \"docker-compose.test.yaml\", \"down\"])\n    sys.exit(1)", "successors": []}, {"id": 5, "label": "run_command([\"prisma\", \"migrate\", \"dev\"])\nresult = subprocess.run([\"pytest\"] + sys.argv[1:], check=False)", "successors": [{"id": 7, "label": "run_command([\"docker\", \"compose\", \"-f\", \"docker-compose.test.yaml\", \"down\"])\nsys.exit(result.returncode)", "successors": []}]}]}]}]}], "classes": [], "simplified_code": "import subprocess\nimport sys\nimport time\n\n\n    return False\n\n\n        sys.exit(1)\n\n\n    sys.exit(result.returncode)", "blocks": [{"id": 1, "label": "import subprocess\nimport sys\nimport time\ntry:", "successors": [{"id": 3, "label": "    result = subprocess.run(['python', '--version'], check=True)", "successors": [{"id": 4, "label": "except subprocess.CalledProcessError:\n        return False", "successors": []}, {"id": 6, "label": "if result.returncode != 0:\n        sys.exit(1)", "successors": []}, {"id": 8, "label": "    sys.exit(result.returncode)", "successors": []}]}]}]}
{"file_name": "153.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 174, "functions": [{"name": "get_praw", "type": "function", "start_line": 34, "end_line": 46, "functions": [], "classes": [], "simplified_code": "def get_praw(creds: RedditCredentials) -> praw.Reddit:\n    client = praw.Reddit(\n        client_id=creds.client_id.get_secret_value(),\n        client_secret=creds.client_secret.get_secret_value(),\n        username=creds.username.get_secret_value(),\n        password=creds.password.get_secret_value(),\n        user_agent=creds.user_agent,\n    )\n    me = client.user.me()\n    if not me:\n        raise ValueError(\"Invalid Reddit credentials.\")\n    print(f\"Logged in as Reddit user: {me.name}\")\n    return client", "blocks": [{"id": 1, "label": "def get_praw(creds: RedditCredentials) -> praw.Reddit:\nclient = praw.Reddit(\n    client_id=creds.client_id.get_secret_value(),\n    client_secret=creds.client_secret.get_secret_value(),\n    username=creds.username.get_secret_value(),\n    password=creds.password.get_secret_value(),\n    user_agent=creds.user_agent,\n)", "successors": [{"id": 3, "label": "me = client.user.me()\nif not me:", "successors": [{"id": 5, "label": "    raise ValueError(\"Invalid Reddit credentials.\")", "successors": []}, {"id": 6, "label": "print(f\"Logged in as Reddit user: {me.name}\")\nreturn client", "successors": []}]}]}]}], "classes": [{"name": "RedditCredentials", "type": "class", "start_line": 12, "end_line": 19, "functions": [], "classes": [], "simplified_code": "class RedditCredentials(BaseModel):\n    client_id: BlockSecret = SecretField(key=\"reddit_client_id\")\n    client_secret: BlockSecret = SecretField(key=\"reddit_client_secret\")\n    username: BlockSecret = SecretField(key=\"reddit_username\")\n    password: BlockSecret = SecretField(key=\"reddit_password\")\n    user_agent: str = \"AutoGPT:1.0 (by /u/autogpt)\"\n\n    model_config = ConfigDict(title=\"Reddit Credentials\")", "blocks": [{"id": 1, "label": "class RedditCredentials(BaseModel):", "successors": [{"id": 2, "label": "    client_id: BlockSecret = SecretField(key=\"reddit_client_id\")", "successors": []}, {"id": 3, "label": "    client_secret: BlockSecret = SecretField(key=\"reddit_client_secret\")", "successors": []}, {"id": 4, "label": "    username: BlockSecret = SecretField(key=\"reddit_username\")", "successors": []}, {"id": 5, "label": "    password: BlockSecret = SecretField(key=\"reddit_password\")", "successors": []}, {"id": 6, "label": "    user_agent: str = \"AutoGPT:1.0 (by /u/autogpt)\"", "successors": []}, {"id": 7, "label": "    model_config = ConfigDict(title=\"Reddit Credentials\")", "successors": []}]}]}, {"name": "RedditPost", "type": "class", "start_line": 22, "end_line": 26, "functions": [], "classes": [], "simplified_code": "class RedditPost(BaseModel):\n    id: str\n    subreddit: str\n    title: str\n    body: str", "blocks": [{"id": 1, "label": "class RedditPost(BaseModel):", "successors": [{"id": 2, "label": "    id: str", "successors": []}, {"id": 3, "label": "    subreddit: str", "successors": []}, {"id": 4, "label": "    title: str", "successors": []}, {"id": 5, "label": "    body: str", "successors": []}]}]}, {"name": "RedditComment", "type": "class", "start_line": 29, "end_line": 31, "functions": [], "classes": [], "simplified_code": "class RedditComment(BaseModel):\n    post_id: str\n    comment: str", "blocks": [{"id": 1, "label": "class RedditComment(BaseModel):\npost_id: str\ncomment: str", "successors": []}]}, {"name": "GetRedditPostsBlock", "type": "class", "start_line": 49, "end_line": 139, "functions": [{"name": "__init__", "type": "function", "start_line": 71, "end_line": 112, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            disabled=True,\n            id=\"c6731acb-4285-4ee1-bc9b-03d0766c370f\",\n            description=\"This block fetches Reddit posts from a defined subreddit name.\",\n            categories={BlockCategory.SOCIAL},\n            input_schema=GetRedditPostsBlock.Input,\n            output_schema=GetRedditPostsBlock.Output,\n            test_input={\n                \"creds\": {\n                    \"client_id\": \"client_id\",\n                    \"client_secret\": \"client_secret\",\n                    \"username\": \"username\",\n                    \"password\": \"password\",\n                    \"user_agent\": \"user_agent\",\n                },\n                \"subreddit\": \"subreddit\",\n                \"last_post\": \"id3\",\n                \"post_limit\": 2,\n            },\n            test_output=[\n                (\n                    \"post\",\n                    RedditPost(\n                        id=\"id1\", subreddit=\"subreddit\", title=\"title1\", body=\"body1\"\n                    ),\n                ),\n                (\n                    \"post\",\n                    RedditPost(\n                        id=\"id2\", subreddit=\"subreddit\", title=\"title2\", body=\"body2\"\n                    ),\n                ),\n            ],\n            test_mock={\n                \"get_posts\": lambda _: [\n                    MockObject(id=\"id1\", title=\"title1\", selftext=\"body1\"),\n                    MockObject(id=\"id2\", title=\"title2\", selftext=\"body2\"),\n                    MockObject(id=\"id3\", title=\"title2\", selftext=\"body2\"),\n                ]\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    disabled=True,\n    id=\"c6731acb-4285-4ee1-bc9b-03d0766c370f\",\n    description=\"This block fetches Reddit posts from a defined subreddit name.\",\n    categories={BlockCategory.SOCIAL},\n    input_schema=GetRedditPostsBlock.Input,\n    output_schema=GetRedditPostsBlock.Output,\n    test_input={\n        \"creds\": {\n            \"client_id\": \"client_id\",\n            \"client_secret\": \"client_secret\",\n            \"username\": \"username\",\n            \"password\": \"password\",\n            \"user_agent\": \"user_agent\",\n        },\n        \"subreddit\": \"subreddit\",\n        \"last_post\": \"id3\",\n        \"post_limit\": 2,\n    },\n    test_output=[\n        (\n            \"post\",\n            RedditPost(\n                id=\"id1\", subreddit=\"subreddit\", title=\"title1\", body=\"body1\"\n            ),\n        ),\n        (\n            \"post\",\n            RedditPost(\n                id=\"id2\", subreddit=\"subreddit\", title=\"title2\", body=\"body2\"\n            ),\n        ),\n    ],\n    test_mock={\n        \"get_posts\": lambda _: [\n            MockObject(id=\"id1\", title=\"title1\", selftext=\"body1\"),\n            MockObject(id=\"id2\", title=\"title2\", selftext=\"body2\"),\n            MockObject(id=\"id3\", title=\"title2\", selftext=\"body2\"),\n        ]\n    },\n)", "successors": []}]}, {"name": "get_posts", "type": "function", "start_line": 115, "end_line": 118, "functions": [], "classes": [], "simplified_code": "    def get_posts(input_data: Input) -> Iterator[praw.reddit.Submission]:\n        client = get_praw(input_data.creds)\n        subreddit = client.subreddit(input_data.subreddit)\n        return subreddit.new(limit=input_data.post_limit or 10)", "blocks": [{"id": 1, "label": "def get_posts(input_data: Input) -> Iterator[praw.reddit.Submission]:\nclient = get_praw(input_data.creds)", "successors": [{"id": 3, "label": "subreddit = client.subreddit(input_data.subreddit)\nreturn subreddit.new(limit=input_data.post_limit or 10)", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 120, "end_line": 139, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        current_time = datetime.now(tz=timezone.utc)\n        for post in self.get_posts(input_data):\n            if input_data.last_minutes:\n                post_datetime = datetime.fromtimestamp(\n                    post.created_utc, tz=timezone.utc\n                )\n                time_difference = current_time - post_datetime\n                if time_difference.total_seconds() / 60 > input_data.last_minutes:\n                    continue\n\n            if input_data.last_post and post.id == input_data.last_post:\n                break\n\n            yield \"post\", RedditPost(\n                id=post.id,\n                subreddit=input_data.subreddit,\n                title=post.title,\n                body=post.selftext,\n            )", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\n    current_time = datetime.now(tz=timezone.utc)", "successors": [{"id": 2, "label": "for post in self.get_posts(input_data):", "successors": [{"id": 3, "label": "if input_data.last_minutes:", "successors": [{"id": 4, "label": "post_datetime = datetime.fromtimestamp(\n    post.created_utc, tz=timezone.utc\n)\ntime_difference = current_time - post_datetime\nif time_difference.total_seconds() / 60 > input_data.last_minutes:", "successors": [{"id": 5, "label": "continue\nyield \"post\", RedditPost(\n    id=post.id,\n    subreddit=input_data.subreddit,\n    title=post.title,\n    body=post.selftext,\n)", "successors": []}, {"id": 6, "label": "if input_data.last_post and post.id == input_data.last_post:", "successors": [{"id": 7, "label": "break", "successors": []}, {"id": 9, "label": "yield \"post\", RedditPost(\n    id=post.id,\n    subreddit=input_data.subreddit,\n    title=post.title,\n    body=post.selftext,\n)", "successors": []}]}, {"id": 9, "label": "yield \"post\", RedditPost(\n    id=post.id,\n    subreddit=input_data.subreddit,\n    title=post.title,\n    body=post.selftext,\n)", "successors": []}]}, {"id": 6, "label": "if input_data.last_post and post.id == input_data.last_post:", "successors": [{"id": 7, "label": "break", "successors": []}, {"id": 9, "label": "yield \"post\", RedditPost(\n    id=post.id,\n    subreddit=input_data.subreddit,\n    title=post.title,\n    body=post.selftext,\n)", "successors": []}]}, {"id": 9, "label": "yield \"post\", RedditPost(\n    id=post.id,\n    subreddit=input_data.subreddit,\n    title=post.title,\n    body=post.selftext,\n)", "successors": []}]}, {"id": 6, "label": "if input_data.last_post and post.id == input_data.last_post:", "successors": [{"id": 7, "label": "break", "successors": []}, {"id": 9, "label": "yield \"post\", RedditPost(\n    id=post.id,\n    subreddit=input_data.subreddit,\n    title=post.title,\n    body=post.selftext,\n)", "successors": []}]}, {"id": 9, "label": "yield \"post\", RedditPost(\n    id=post.id,\n    subreddit=input_data.subreddit,\n    title=post.title,\n    body=post.selftext,\n)", "successors": []}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 50, "end_line": 66, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        subreddit: str = SchemaField(description=\"Subreddit name\")\n        creds: RedditCredentials = SchemaField(\n            description=\"Reddit credentials\",\n            default=RedditCredentials(),\n        )\n        last_minutes: int | None = SchemaField(\n            description=\"Post time to stop minutes ago while fetching posts\",\n            default=None,\n        )\n        last_post: str | None = SchemaField(\n            description=\"Post ID to stop when reached while fetching posts\",\n            default=None,\n        )\n        post_limit: int | None = SchemaField(\n            description=\"Number of posts to fetch\", default=10\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\nsubreddit: str = SchemaField(description=\"Subreddit name\")", "successors": [{"id": 3, "label": "creds: RedditCredentials = SchemaField(description=\"Reddit credentials\", default=RedditCredentials())\nlast_minutes: int | None = SchemaField(description=\"Post time to stop minutes ago while fetching posts\", default=None)", "successors": [{"id": 5, "label": "last_post: str | None = SchemaField(description=\"Post ID to stop when reached while fetching posts\", default=None)\npost_limit: int | None = SchemaField(description=\"Number of posts to fetch\", default=10)", "successors": []}]}]}]}, {"name": "Output", "type": "class", "start_line": 68, "end_line": 69, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        post: RedditPost = SchemaField(description=\"Reddit post\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\npost: RedditPost = SchemaField(description=\"Reddit post\")", "successors": []}]}], "simplified_code": "class GetRedditPostsBlock(Block):\n        )\n\n        post: RedditPost = SchemaField(description=\"Reddit post\")\n\n        )\n\n    @staticmethod\n        return subreddit.new(limit=input_data.post_limit or 10)\n\n            )", "blocks": [{"id": 1, "label": "class GetRedditPostsBlock(Block):\npost: RedditPost = SchemaField(description=\"Reddit post\")", "successors": [{"id": 3, "label": "@staticmethod\nreturn subreddit.new(limit=input_data.post_limit or 10)", "successors": []}]}]}, {"name": "PostRedditCommentBlock", "type": "class", "start_line": 142, "end_line": 174, "functions": [{"name": "__init__", "type": "function", "start_line": 152, "end_line": 162, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"4a92261b-701e-4ffb-8970-675fd28e261f\",\n            description=\"This block posts a Reddit comment on a specified Reddit post.\",\n            categories={BlockCategory.SOCIAL},\n            input_schema=PostRedditCommentBlock.Input,\n            output_schema=PostRedditCommentBlock.Output,\n            test_input={\"data\": {\"post_id\": \"id\", \"comment\": \"comment\"}},\n            test_output=[(\"comment_id\", \"dummy_comment_id\")],\n            test_mock={\"reply_post\": lambda creds, comment: \"dummy_comment_id\"},\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\n    super().__init__(\n        id=\"4a92261b-701e-4ffb-8970-675fd28e261f\",\n        description=\"This block posts a Reddit comment on a specified Reddit post.\",\n        categories={BlockCategory.SOCIAL},\n        input_schema=PostRedditCommentBlock.Input,\n        output_schema=PostRedditCommentBlock.Output,\n        test_input={\"data\": {\"post_id\": \"id\", \"comment\": \"comment\"}},\n        test_output=[(\"comment_id\", \"dummy_comment_id\")],\n        test_mock={\"reply_post\": lambda creds, comment: \"dummy_comment_id\"},\n    )", "successors": []}]}, {"name": "reply_post", "type": "function", "start_line": 165, "end_line": 171, "functions": [], "classes": [], "simplified_code": "    def reply_post(creds: RedditCredentials, comment: RedditComment) -> str:\n        client = get_praw(creds)\n        submission = client.submission(id=comment.post_id)\n        new_comment = submission.reply(comment.comment)\n        if not new_comment:\n            raise ValueError(\"Failed to post comment.\")\n        return new_comment.id", "blocks": [{"id": 1, "label": "client = get_praw(creds)\nsubmission = client.submission(id=comment.post_id)\nnew_comment = submission.reply(comment.comment)", "successors": [{"id": 2, "label": "if not new_comment:\n    raise ValueError(\"Failed to post comment.\")", "successors": []}, {"id": 4, "label": "return new_comment.id", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 173, "end_line": 174, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        yield \"comment_id\", self.reply_post(input_data.creds, input_data.data)", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\n    yield \"comment_id\", self.reply_post(input_data.creds, input_data.data)", "successors": []}]}], "classes": [{"name": "Input", "type": "class", "start_line": 143, "end_line": 147, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        creds: RedditCredentials = SchemaField(\n            description=\"Reddit credentials\", default=RedditCredentials()\n        )\n        data: RedditComment = SchemaField(description=\"Reddit comment\")", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    creds: RedditCredentials = SchemaField(description=\"Reddit credentials\", default=RedditCredentials())", "successors": []}, {"id": 3, "label": "    data: RedditComment = SchemaField(description=\"Reddit comment\")", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 149, "end_line": 150, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        comment_id: str = SchemaField(description=\"Posted comment ID\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    comment_id: str = SchemaField(description=\"Posted comment ID\")", "successors": []}]}], "simplified_code": "class PostRedditCommentBlock(Block):\n        data: RedditComment = SchemaField(description=\"Reddit comment\")\n\n        comment_id: str = SchemaField(description=\"Posted comment ID\")\n\n        )\n\n    @staticmethod\n        return new_comment.id\n\n        yield \"comment_id\", self.reply_post(input_data.creds, input_data.data)", "blocks": [{"id": 1, "label": "class PostRedditCommentBlock(Block):", "successors": [{"id": 2, "label": "data: RedditComment = SchemaField(description=\"Reddit comment\")", "successors": []}, {"id": 3, "label": "comment_id: str = SchemaField(description=\"Posted comment ID\")", "successors": []}]}]}], "simplified_code": "from datetime import datetime, timezone\nfrom typing import Iterator\n\nimport praw\nfrom pydantic import BaseModel, ConfigDict\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import BlockSecret, SchemaField, SecretField\nfrom backend.util.mock import MockObject\n\n\n    model_config = ConfigDict(title=\"Reddit Credentials\")\n\n\n    body: str\n\n\n    comment: str\n\n\n    return client\n\n\n            )\n\n\n        yield \"comment_id\", self.reply_post(input_data.creds, input_data.data)", "blocks": [{"id": 1, "label": "from datetime import datetime, timezone\nfrom typing import Iterator\n\nimport praw\nfrom pydantic import BaseModel, ConfigDict\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import BlockSecret, SchemaField, SecretField\nfrom backend.util.mock import MockObject", "successors": [{"id": 2, "label": "model_config = ConfigDict(title=\"Reddit Credentials\")\nbody: str", "successors": [{"id": 4, "label": "comment: str\nreturn client", "successors": []}]}, {"id": 6, "label": "yield \"comment_id\", self.reply_post(input_data.creds, input_data.data)", "successors": []}]}]}
{"file_name": "154.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 172, "functions": [], "classes": [{"name": "FakeResponse", "type": "class", "start_line": 12, "end_line": 16, "functions": [{"name": "__init__", "type": "function", "start_line": 13, "end_line": 16, "functions": [], "classes": [], "simplified_code": "    def __init__(self, code: int, headers: dict, text: str) -> None:\n        self.status_code = code\n        self.headers = headers\n        self.text = text", "blocks": [{"id": 1, "label": "def __init__(self, code: int, headers: dict, text: str) -> None:\n    self.status_code = code\n    self.headers = headers\n    self.text = text", "successors": []}]}], "classes": [], "simplified_code": "class FakeResponse():\n        self.text = text", "blocks": [{"id": 1, "label": "class FakeResponse():\n    self.text = text", "successors": []}]}, {"name": "TestValidateLinks", "type": "class", "start_line": 19, "end_line": 172, "functions": [{"name": "setUp", "type": "function", "start_line": 21, "end_line": 42, "functions": [], "classes": [], "simplified_code": "    def setUp(self):\n        self.duplicate_links = [\n            'https://www.example.com',\n            'https://www.example.com',\n            'https://www.example.com',\n            'https://www.anotherexample.com',\n        ]\n        self.no_duplicate_links = [\n            'https://www.firstexample.com',\n            'https://www.secondexample.com',\n            'https://www.anotherexample.com',\n        ]\n\n        self.code_200 = 200\n        self.code_403 = 403\n        self.code_503 = 503\n\n        self.cloudflare_headers = {'Server': 'cloudflare'}\n        self.no_cloudflare_headers = {'Server': 'google'}\n\n        self.text_with_cloudflare_flags = '403 Forbidden Cloudflare We are checking your browser...'\n        self.text_without_cloudflare_flags = 'Lorem Ipsum'", "blocks": [{"id": 1, "label": "def setUp(self):\nself.duplicate_links = [\n    'https://www.example.com',\n    'https://www.example.com',\n    'https://www.example.com',\n    'https://www.anotherexample.com',\n]", "successors": [{"id": 3, "label": "self.no_duplicate_links = [\n    'https://www.firstexample.com',\n    'https://www.secondexample.com',\n    'https://www.anotherexample.com',\n]\nself.code_200 = 200", "successors": [{"id": 5, "label": "self.code_403 = 403\nself.code_503 = 503", "successors": [{"id": 7, "label": "self.cloudflare_headers = {'Server': 'cloudflare'}\nself.no_cloudflare_headers = {'Server': 'google'}", "successors": [{"id": 9, "label": "self.text_with_cloudflare_flags = '403 Forbidden Cloudflare We are checking your browser...'\nself.text_without_cloudflare_flags = 'Lorem Ipsum'", "successors": []}]}]}]}]}]}, {"name": "test_find_link_in_text", "type": "function", "start_line": 44, "end_line": 73, "functions": [], "classes": [], "simplified_code": "    def test_find_link_in_text(self):\n        text = \"\"\"\n            # this is valid\n\n            http://example.com?param1=1&param2=2#anchor\n            https://www.example.com?param1=1&param2=2#anchor\n            https://www.example.com.br\n            https://www.example.com.gov.br\n            [Example](https://www.example.com?param1=1&param2=2#anchor)\n            lorem ipsum https://www.example.com?param1=1&param2=2#anchor\n            https://www.example.com?param1=1&param2=2#anchor lorem ipsum\n\n            # this not is valid\n\n            example.com\n            https:example.com\n            https:/example.com\n            https//example.com\n            https//.com\n        \"\"\"\n\n        links = find_links_in_text(text)\n\n        self.assertIsInstance(links, list)\n        self.assertEqual(len(links), 7)\n\n        for link in links:\n            with self.subTest():\n                self.assertIsInstance(link, str)\n", "blocks": [{"id": 1, "label": "def test_find_link_in_text(self):\ntext = \"\"\"\n            # this is valid\n\n            http://example.com?param1=1&param2=2#anchor\n            https://www.example.com?param1=1&param2=2#anchor\n            https://www.example.com.br\n            https://www.example.com.gov.br\n            [Example](https://www.example.com?param1=1&param2=2#anchor)\n            lorem ipsum https://www.example.com?param1=1&param2=2#anchor\n            https://www.example.com?param1=1&param2=2#anchor lorem ipsum\n\n            # this not is valid\n\n            example.com\n            https:example.com\n            https:/example.com\n            https//example.com\n            https//.com\n        \"\"\"\n\n        links = find_links_in_text(text)\n\n        self.assertIsInstance(links, list)\n        self.assertEqual(len(links), 7)", "successors": [{"id": 3, "label": "for link in links:", "successors": [{"id": 4, "label": "with self.subTest():\nself.assertIsInstance(link, str)", "successors": []}]}]}]}, {"name": "test_find_link_in_text_with_invalid_argument", "type": "function", "start_line": 74, "end_line": 78, "functions": [], "classes": [], "simplified_code": "    def test_find_link_in_text_with_invalid_argument(self):\n        with self.assertRaises(TypeError):\n            find_links_in_text()\n            find_links_in_text(1)\n            find_links_in_text(True)", "blocks": [{"id": 1, "label": "def test_find_link_in_text_with_invalid_argument(self):\nwith self.assertRaises(TypeError):", "successors": [{"id": 3, "label": "    find_links_in_text()", "successors": []}, {"id": 4, "label": "    find_links_in_text(1)", "successors": []}, {"id": 5, "label": "    find_links_in_text(True)", "successors": []}]}]}, {"name": "test_if_check_duplicate_links_has_the_correct_return", "type": "function", "start_line": 80, "end_line": 97, "functions": [], "classes": [], "simplified_code": "    def test_if_check_duplicate_links_has_the_correct_return(self):\n        result_1 = check_duplicate_links(self.duplicate_links)\n        result_2 = check_duplicate_links(self.no_duplicate_links)\n\n        self.assertIsInstance(result_1, tuple)\n        self.assertIsInstance(result_2, tuple)\n\n        has_duplicate_links, links = result_1\n        no_duplicate_links, no_links = result_2\n\n        self.assertTrue(has_duplicate_links)\n        self.assertFalse(no_duplicate_links)\n\n        self.assertIsInstance(links, list)\n        self.assertIsInstance(no_links, list)\n\n        self.assertEqual(len(links), 2)\n        self.assertEqual(len(no_links), 0)", "blocks": [{"id": 1, "label": "def test_if_check_duplicate_links_has_the_correct_return(self):\nresult_1 = check_duplicate_links(self.duplicate_links)\nresult_2 = check_duplicate_links(self.no_duplicate_links)\nself.assertIsInstance(result_1, tuple)\nself.assertIsInstance(result_2, tuple)\nhas_duplicate_links, links = result_1\nno_duplicate_links, no_links = result_2\nself.assertTrue(has_duplicate_links)\nself.assertFalse(no_duplicate_links)\nself.assertIsInstance(links, list)\nself.assertIsInstance(no_links, list)\nself.assertEqual(len(links), 2)\nself.assertEqual(len(no_links), 0)", "successors": []}]}, {"name": "test_if_fake_user_agent_has_a_str_as_return", "type": "function", "start_line": 99, "end_line": 101, "functions": [], "classes": [], "simplified_code": "    def test_if_fake_user_agent_has_a_str_as_return(self):\n        user_agent = fake_user_agent()\n        self.assertIsInstance(user_agent, str)", "blocks": [{"id": 1, "label": "def test_if_fake_user_agent_has_a_str_as_return(self):\nuser_agent = fake_user_agent()", "successors": [{"id": 3, "label": "self.assertIsInstance(user_agent, str)", "successors": []}]}]}, {"name": "test_get_host_from_link", "type": "function", "start_line": 103, "end_line": 126, "functions": [], "classes": [], "simplified_code": "    def test_get_host_from_link(self):\n        links = [\n            'example.com',\n            'https://example.com',\n            'https://www.example.com',\n            'https://www.example.com.br',\n            'https://www.example.com/route',\n            'https://www.example.com?p=1&q=2',\n            'https://www.example.com#anchor'\n        ]\n\n        for link in links:\n            host = get_host_from_link(link)\n\n            with self.subTest():\n                self.assertIsInstance(host, str)\n\n                self.assertNotIn('://', host)\n                self.assertNotIn('/', host)\n                self.assertNotIn('?', host)\n                self.assertNotIn('#', host)\n\n        with self.assertRaises(TypeError):\n            get_host_from_link()", "blocks": [{"id": 1, "label": "def test_get_host_from_link(self):\n    links = [\n        'example.com',\n        'https://example.com',\n        'https://www.example.com',\n        'https://www.example.com.br',\n        'https://www.example.com/route',\n        'https://www.example.com?p=1&q=2',\n        'https://www.example.com#anchor'\n    ]", "successors": [{"id": 2, "label": "for link in links:", "successors": [{"id": 3, "label": "    host = get_host_from_link(link)\n    with self.subTest():", "successors": [{"id": 5, "label": "        self.assertIsInstance(host, str)\n        self.assertNotIn('://', host)\n        self.assertNotIn('/', host)\n        self.assertNotIn('?', host)\n        self.assertNotIn('#', host)", "successors": [{"id": 8, "label": "with self.assertRaises(TypeError):\n    get_host_from_link()", "successors": []}]}]}]}]}]}, {"name": "test_has_cloudflare_protection_with_code_403_and_503_in_response", "type": "function", "start_line": 128, "end_line": 145, "functions": [], "classes": [], "simplified_code": "    def test_has_cloudflare_protection_with_code_403_and_503_in_response(self):\n        resp_with_cloudflare_protection_code_403 = FakeResponse(\n            code=self.code_403,\n            headers=self.cloudflare_headers,\n            text=self.text_with_cloudflare_flags\n        )\n\n        resp_with_cloudflare_protection_code_503 = FakeResponse(\n            code=self.code_503,\n            headers=self.cloudflare_headers,\n            text=self.text_with_cloudflare_flags\n        )\n\n        result1 = has_cloudflare_protection(resp_with_cloudflare_protection_code_403)\n        result2 = has_cloudflare_protection(resp_with_cloudflare_protection_code_503)\n\n        self.assertTrue(result1)\n        self.assertTrue(result2)", "blocks": [{"id": 1, "label": "def test_has_cloudflare_protection_with_code_403_and_503_in_response(self):\nresp_with_cloudflare_protection_code_403 = FakeResponse(code=self.code_403, headers=self.cloudflare_headers, text=self.text_with_cloudflare_flags)", "successors": [{"id": 3, "label": "resp_with_cloudflare_protection_code_503 = FakeResponse(code=self.code_503, headers=self.cloudflare_headers, text=self.text_with_cloudflare_flags)\nresult1 = has_cloudflare_protection(resp_with_cloudflare_protection_code_403)", "successors": [{"id": 5, "label": "result2 = has_cloudflare_protection(resp_with_cloudflare_protection_code_503)\nself.assertTrue(result1)", "successors": [{"id": 7, "label": "self.assertTrue(result2)", "successors": []}]}]}]}]}, {"name": "test_has_cloudflare_protection_when_there_is_no_protection", "type": "function", "start_line": 147, "end_line": 172, "functions": [], "classes": [], "simplified_code": "    def test_has_cloudflare_protection_when_there_is_no_protection(self):\n        resp_without_cloudflare_protection1 = FakeResponse(\n            code=self.code_200,\n            headers=self.no_cloudflare_headers,\n            text=self.text_without_cloudflare_flags\n        )\n\n        resp_without_cloudflare_protection2 = FakeResponse(\n            code=self.code_403,\n            headers=self.no_cloudflare_headers,\n            text=self.text_without_cloudflare_flags\n        )\n\n        resp_without_cloudflare_protection3 = FakeResponse(\n            code=self.code_503,\n            headers=self.no_cloudflare_headers,\n            text=self.text_without_cloudflare_flags\n        )\n\n        result1 = has_cloudflare_protection(resp_without_cloudflare_protection1)\n        result2 = has_cloudflare_protection(resp_without_cloudflare_protection2)\n        result3 = has_cloudflare_protection(resp_without_cloudflare_protection3)\n\n        self.assertFalse(result1)\n        self.assertFalse(result2)\n        self.assertFalse(result3)", "blocks": [{"id": 1, "label": "def test_has_cloudflare_protection_when_there_is_no_protection(self):\n    resp_without_cloudflare_protection1 = FakeResponse(\n        code=self.code_200,\n        headers=self.no_cloudflare_headers,\n        text=self.text_without_cloudflare_flags\n    )\n\n    resp_without_cloudflare_protection2 = FakeResponse(\n        code=self.code_403,\n        headers=self.no_cloudflare_headers,\n        text=self.text_without_cloudflare_flags\n    )\n\n    resp_without_cloudflare_protection3 = FakeResponse(\n        code=self.code_503,\n        headers=self.no_cloudflare_headers,\n        text=self.text_without_cloudflare_flags\n    )\n\n    result1 = has_cloudflare_protection(resp_without_cloudflare_protection1)\n    result2 = has_cloudflare_protection(resp_without_cloudflare_protection2)\n    result3 = has_cloudflare_protection(resp_without_cloudflare_protection3)\n\n    self.assertFalse(result1)\n    self.assertFalse(result2)\n    self.assertFalse(result3)", "successors": []}]}], "classes": [], "simplified_code": "class TestValidateLinks(unittest.TestCase):\n\n        self.text_without_cloudflare_flags = 'Lorem Ipsum'\n\n\n            find_links_in_text(True)\n\n        self.assertEqual(len(no_links), 0)\n\n        self.assertIsInstance(user_agent, str)\n\n            get_host_from_link()\n\n        self.assertTrue(result2)\n\n        self.assertFalse(result3)", "blocks": [{"id": 1, "label": "class TestValidateLinks(unittest.TestCase):\nself.text_without_cloudflare_flags = 'Lorem Ipsum'", "successors": [{"id": 3, "label": "find_links_in_text(True)\nself.assertEqual(len(no_links), 0)", "successors": [{"id": 5, "label": "self.assertIsInstance(user_agent, str)\nget_host_from_link()", "successors": [{"id": 7, "label": "self.assertTrue(result2)\nself.assertFalse(result3)", "successors": []}]}]}]}]}], "simplified_code": "# -*- coding: utf-8 -*-\n\nimport unittest\n\nfrom validate.links import find_links_in_text\nfrom validate.links import check_duplicate_links\nfrom validate.links import fake_user_agent\nfrom validate.links import get_host_from_link\nfrom validate.links import has_cloudflare_protection\n\n\n        self.text = text\n\n\n        self.assertFalse(result3)", "blocks": [{"id": 1, "label": "import unittest\nfrom validate.links import find_links_in_text", "successors": [{"id": 3, "label": "from validate.links import check_duplicate_links\nfrom validate.links import fake_user_agent", "successors": [{"id": 5, "label": "from validate.links import get_host_from_link\nfrom validate.links import has_cloudflare_protection", "successors": [{"id": 7, "label": "self.text = text\nself.assertFalse(result3)", "successors": []}]}]}]}]}
{"file_name": "155.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 125, "functions": [], "classes": [{"name": "VehicleSize", "type": "class", "start_line": 5, "end_line": 9, "functions": [], "simplified_code": "class VehicleSize(Enum):\n\n    MOTORCYCLE = 0\n    COMPACT = 1\n    LARGE = 2", "blocks": [{"id": 1, "label": "class VehicleSize(Enum):", "successors": [{"id": 2, "label": "    MOTORCYCLE = 0", "successors": []}, {"id": 3, "label": "    COMPACT = 1", "successors": []}, {"id": 4, "label": "    LARGE = 2", "successors": []}]}]}, {"name": "Vehicle", "type": "class", "start_line": 12, "end_line": 30, "functions": [{"name": "__init__", "type": "function", "start_line": 14, "end_line": 18, "functions": [], "classes": [], "simplified_code": "    def __init__(self, vehicle_size, license_plate, spot_size):\n        self.vehicle_size = vehicle_size\n        self.license_plate = license_plate\n        self.spot_size\n        self.spots_taken = []", "blocks": [{"id": 1, "label": "def __init__(self, vehicle_size, license_plate, spot_size):\n    self.vehicle_size = vehicle_size\n    self.license_plate = license_plate\n    self.spot_size", "successors": [{"id": 3, "label": "    self.spots_taken = []", "successors": []}]}]}, {"name": "clear_spots", "type": "function", "start_line": 20, "end_line": 23, "functions": [], "classes": [], "simplified_code": "    def clear_spots(self):\n        for spot in self.spots_taken:\n            spot.remove_vehicle(self)\n        self.spots_taken = []", "blocks": [{"id": 1, "label": "def clear_spots(self):", "successors": [{"id": 2, "label": "for spot in self.spots_taken:", "successors": [{"id": 3, "label": "spot.remove_vehicle(self)", "successors": [{"id": 2, "label": "for spot in self.spots_taken:", "successors": []}, {"id": 4, "label": "self.spots_taken = []", "successors": []}]}]}, {"id": 4, "label": "self.spots_taken = []", "successors": []}]}]}, {"name": "take_spot", "type": "function", "start_line": 25, "end_line": 26, "functions": [], "classes": [], "simplified_code": "    def take_spot(self, spot):\n        self.spots_taken.append(spot)", "blocks": [{"id": 1, "label": "def take_spot(self, spot):\n    self.spots_taken.append(spot)", "successors": []}]}, {"name": "can_fit_in_spot", "type": "function", "start_line": 29, "end_line": 30, "functions": [], "classes": [], "simplified_code": "    def can_fit_in_spot(self, spot):\n        pass", "blocks": [{"id": 1, "label": "def can_fit_in_spot(self, spot):\n    pass", "successors": []}]}], "simplified_code": "class Vehicle(metaclass=ABCMeta):\n\n        self.spots_taken = []\n\n        self.spots_taken = []\n\n        self.spots_taken.append(spot)\n\n    @abstractmethod\n        pass", "blocks": [{"id": 1, "label": "class Vehicle(metaclass=ABCMeta):", "successors": [{"id": 2, "label": "self.spots_taken = []", "successors": []}, {"id": 3, "label": "self.spots_taken = []", "successors": []}, {"id": 4, "label": "self.spots_taken.append(spot)", "successors": []}, {"id": 5, "label": "@abstractmethod", "successors": []}, {"id": 6, "label": "pass", "successors": []}]}]}, {"name": "Motorcycle", "type": "class", "start_line": 33, "end_line": 39, "functions": [{"name": "__init__", "type": "function", "start_line": 35, "end_line": 36, "functions": [], "classes": [], "simplified_code": "    def __init__(self, license_plate):\n        super(Motorcycle, self).__init__(VehicleSize.MOTORCYCLE, license_plate, spot_size=1)", "blocks": [{"id": 1, "label": "def __init__(self, license_plate):\n    super(Motorcycle, self).__init__(VehicleSize.MOTORCYCLE, license_plate, spot_size=1)", "successors": []}]}, {"name": "can_fit_in_spot", "type": "function", "start_line": 38, "end_line": 39, "functions": [], "classes": [], "simplified_code": "    def can_fit_in_spot(self, spot):\n        return True", "blocks": [{"id": 1, "label": "def can_fit_in_spot(self, spot):\n    return True", "successors": []}]}], "simplified_code": "class Motorcycle(Vehicle):\n\n        super(Motorcycle, self).__init__(VehicleSize.MOTORCYCLE, license_plate, spot_size=1)\n\n        return True", "blocks": [{"id": 1, "label": "class Motorcycle(Vehicle):\nsuper(Motorcycle, self).__init__(VehicleSize.MOTORCYCLE, license_plate, spot_size=1)", "successors": [{"id": 3, "label": "return True", "successors": []}]}]}, {"name": "Car", "type": "class", "start_line": 42, "end_line": 48, "functions": [{"name": "__init__", "type": "function", "start_line": 44, "end_line": 45, "functions": [], "classes": [], "simplified_code": "    def __init__(self, license_plate):\n        super(Car, self).__init__(VehicleSize.COMPACT, license_plate, spot_size=1)", "blocks": [{"id": 1, "label": "def __init__(self, license_plate):\n    super(Car, self).__init__(VehicleSize.COMPACT, license_plate, spot_size=1)", "successors": []}]}, {"name": "can_fit_in_spot", "type": "function", "start_line": 47, "end_line": 48, "functions": [], "classes": [], "simplified_code": "    def can_fit_in_spot(self, spot):\n        return spot.size in (VehicleSize.LARGE, VehicleSize.COMPACT)", "blocks": [{"id": 1, "label": "def can_fit_in_spot(self, spot):\n    return spot.size in (VehicleSize.LARGE, VehicleSize.COMPACT)", "successors": []}]}], "simplified_code": "class Car(Vehicle):\n\n        super(Car, self).__init__(VehicleSize.COMPACT, license_plate, spot_size=1)\n\n        return spot.size in (VehicleSize.LARGE, VehicleSize.COMPACT)", "blocks": [{"id": 1, "label": "super(Car, self).__init__(VehicleSize.COMPACT, license_plate, spot_size=1)\nreturn spot.size in (VehicleSize.LARGE, VehicleSize.COMPACT)", "successors": []}]}, {"name": "Bus", "type": "class", "start_line": 51, "end_line": 57, "functions": [{"name": "__init__", "type": "function", "start_line": 53, "end_line": 54, "functions": [], "classes": [], "simplified_code": "    def __init__(self, license_plate):\n        super(Bus, self).__init__(VehicleSize.LARGE, license_plate, spot_size=5)", "blocks": [{"id": 1, "label": "def __init__(self, license_plate):\n    super(Bus, self).__init__(VehicleSize.LARGE, license_plate, spot_size=5)", "successors": []}]}, {"name": "can_fit_in_spot", "type": "function", "start_line": 56, "end_line": 57, "functions": [], "classes": [], "simplified_code": "    def can_fit_in_spot(self, spot):\n        return spot.size == VehicleSize.LARGE", "blocks": [{"id": 1, "label": "def can_fit_in_spot(self, spot):\n    return spot.size == VehicleSize.LARGE", "successors": []}]}], "simplified_code": "class Bus(Vehicle):\n\n        super(Bus, self).__init__(VehicleSize.LARGE, license_plate, spot_size=5)\n\n        return spot.size == VehicleSize.LARGE", "blocks": [{"id": 1, "label": "class Bus(Vehicle):\nsuper(Bus, self).__init__(VehicleSize.LARGE, license_plate, spot_size=5)", "successors": [{"id": 3, "label": "return spot.size == VehicleSize.LARGE", "successors": []}]}]}, {"name": "ParkingLot", "type": "class", "start_line": 60, "end_line": 70, "functions": [{"name": "__init__", "type": "function", "start_line": 62, "end_line": 64, "functions": [], "classes": [], "simplified_code": "    def __init__(self, num_levels):\n        self.num_levels = num_levels\n        self.levels = []  # List of Levels", "blocks": [{"id": 1, "label": "def __init__(self, num_levels):\n    self.num_levels = num_levels\n    self.levels = []", "successors": []}]}, {"name": "park_vehicle", "type": "function", "start_line": 66, "end_line": 70, "functions": [], "classes": [], "simplified_code": "    def park_vehicle(self, vehicle):\n        for level in self.levels:\n            if level.park_vehicle(vehicle):\n                return True\n        return False", "blocks": [{"id": 1, "label": "def park_vehicle(self, vehicle):", "successors": [{"id": 2, "label": "for level in self.levels:", "successors": [{"id": 3, "label": "if level.park_vehicle(vehicle):\nreturn True", "successors": []}]}, {"id": 5, "label": "return False", "successors": []}]}]}], "simplified_code": "class ParkingLot(object):\n\n        self.levels = []  # List of Levels\n\n        return False", "blocks": [{"id": 1, "label": "class ParkingLot(object):\nself.levels = []  # List of Levels", "successors": [{"id": 3, "label": "return False", "successors": []}]}]}, {"name": "Level", "type": "class", "start_line": 73, "end_line": 100, "functions": [{"name": "__init__", "type": "function", "start_line": 77, "end_line": 81, "functions": [], "classes": [], "simplified_code": "    def __init__(self, floor, total_spots):\n        self.floor = floor\n        self.num_spots = total_spots\n        self.available_spots = 0\n        self.spots = []  # List of ParkingSpots", "blocks": [{"id": 1, "label": "def __init__(self, floor, total_spots):\nself.floor = floor\nself.num_spots = total_spots\nself.available_spots = 0\nself.spots = []  # List of ParkingSpots", "successors": []}]}, {"name": "spot_freed", "type": "function", "start_line": 83, "end_line": 84, "functions": [], "classes": [], "simplified_code": "    def spot_freed(self):\n        self.available_spots += 1", "blocks": [{"id": 1, "label": "def spot_freed(self):\n    self.available_spots += 1", "successors": []}]}, {"name": "park_vehicle", "type": "function", "start_line": 86, "end_line": 92, "functions": [], "classes": [], "simplified_code": "    def park_vehicle(self, vehicle):\n        spot = self._find_available_spot(vehicle)\n        if spot is None:\n            return None\n        else:\n            spot.park_vehicle(vehicle)\n            return spot", "blocks": [{"id": 1, "label": "spot = self._find_available_spot(vehicle)\nif spot is None:", "successors": [{"id": 3, "label": "    return None", "successors": []}, {"id": 4, "label": "    spot.park_vehicle(vehicle)\n    return spot", "successors": []}]}]}, {"name": "_find_available_spot", "type": "function", "start_line": 94, "end_line": 96, "functions": [], "classes": [], "simplified_code": "    def _find_available_spot(self, vehicle):\n        \"\"\"Find an available spot where vehicle can fit, or return None\"\"\"\n        pass", "blocks": [{"id": 1, "label": "def _find_available_spot(self, vehicle):\n\"\"\"Find an available spot where vehicle can fit, or return None\"\"\"", "successors": [{"id": 3, "label": "pass", "successors": []}]}]}, {"name": "_park_starting_at_spot", "type": "function", "start_line": 98, "end_line": 100, "functions": [], "classes": [], "simplified_code": "    def _park_starting_at_spot(self, spot, vehicle):\n        \"\"\"Occupy starting at spot.spot_number to vehicle.spot_size.\"\"\"\n        pass", "blocks": [{"id": 1, "label": "def _park_starting_at_spot(self, spot, vehicle):\n\"\"\"Occupy starting at spot.spot_number to vehicle.spot_size.\"\"\"", "successors": [{"id": 3, "label": "pass", "successors": []}]}]}], "simplified_code": "class Level(object):\n\n    SPOTS_PER_ROW = 10\n\n        self.spots = []  # List of ParkingSpots\n\n        self.available_spots += 1\n\n            return spot\n\n        pass\n\n        pass", "blocks": [{"id": 1, "label": "class Level(object):\nSPOTS_PER_ROW = 10", "successors": [{"id": 3, "label": "self.spots = []  # List of ParkingSpots\nself.available_spots += 1", "successors": [{"id": 5, "label": "return spot", "successors": []}, {"id": 6, "label": "pass", "successors": []}, {"id": 7, "label": "pass", "successors": []}]}]}]}, {"name": "ParkingSpot", "type": "class", "start_line": 103, "end_line": 125, "functions": [{"name": "__init__", "type": "function", "start_line": 105, "end_line": 111, "functions": [], "classes": [], "simplified_code": "    def __init__(self, level, row, spot_number, spot_size, vehicle_size):\n        self.level = level\n        self.row = row\n        self.spot_number = spot_number\n        self.spot_size = spot_size\n        self.vehicle_size = vehicle_size\n        self.vehicle = None", "blocks": [{"id": 1, "label": "def __init__(self, level, row, spot_number, spot_size, vehicle_size):\nself.level = level\nself.row = row\nself.spot_number = spot_number\nself.spot_size = spot_size\nself.vehicle_size = vehicle_size\nself.vehicle = None", "successors": []}]}, {"name": "is_available", "type": "function", "start_line": 113, "end_line": 114, "functions": [], "classes": [], "simplified_code": "    def is_available(self):\n        return True if self.vehicle is None else False", "blocks": [{"id": 1, "label": "def is_available(self):\nreturn True if self.vehicle is None else False", "successors": []}]}, {"name": "can_fit_vehicle", "type": "function", "start_line": 116, "end_line": 119, "functions": [], "classes": [], "simplified_code": "    def can_fit_vehicle(self, vehicle):\n        if self.vehicle is not None:\n            return False\n        return vehicle.can_fit_in_spot(self)", "blocks": [{"id": 1, "label": "def can_fit_vehicle(self, vehicle):\nif self.vehicle is not None:", "successors": [{"id": 3, "label": "return False", "successors": []}, {"id": 4, "label": "return vehicle.can_fit_in_spot(self)", "successors": []}]}]}, {"name": "park_vehicle", "type": "function", "start_line": 121, "end_line": 122, "functions": [], "classes": [], "simplified_code": "    def park_vehicle(self, vehicle):\n        pass", "blocks": [{"id": 1, "label": "def park_vehicle(self, vehicle):\npass", "successors": []}]}, {"name": "remove_vehicle", "type": "function", "start_line": 124, "end_line": 125, "functions": [], "classes": [], "simplified_code": "    def remove_vehicle(self):\n        pass", "blocks": [{"id": 1, "label": "def remove_vehicle(self):\npass", "successors": []}]}], "simplified_code": "class ParkingSpot(object):\n\n        self.vehicle = None\n\n        return True if self.vehicle is None else False\n\n        return vehicle.can_fit_in_spot(self)\n\n        pass\n\n        pass", "blocks": [{"id": 1, "label": "class ParkingSpot(object):\nself.vehicle = None", "successors": [{"id": 3, "label": "return True if self.vehicle is None else False", "successors": []}, {"id": 4, "label": "return vehicle.can_fit_in_spot(self)", "successors": []}, {"id": 5, "label": "pass", "successors": []}, {"id": 6, "label": "pass", "successors": []}]}]}], "simplified_code": "from abc import ABCMeta, abstractmethod\nfrom enum import Enum\n\n\n    LARGE = 2\n\n\n        pass\n\n\n        return True\n\n\n        return spot.size in (VehicleSize.LARGE, VehicleSize.COMPACT)\n\n\n        return spot.size == VehicleSize.LARGE\n\n\n        return False\n\n\n        pass\n\n\n        pass", "blocks": [{"id": 1, "label": "from abc import ABCMeta, abstractmethod\nfrom enum import Enum\n\n\n    LARGE = 2\n\n\n        pass\n\n\n        return True\n\n\n        return spot.size in (VehicleSize.LARGE, VehicleSize.COMPACT)\n\n\n        return spot.size == VehicleSize.LARGE\n\n\n        return False\n\n\n        pass\n\n\n        pass", "successors": []}]}
{"file_name": "156.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 32, "functions": [{"name": "rate_limit_middleware", "type": "function", "start_line": 7, "end_line": 32, "functions": [], "classes": [], "simplified_code": "async def rate_limit_middleware(request: Request, call_next: RequestResponseEndpoint):\n    \"\"\"FastAPI middleware for rate limiting API requests.\"\"\"\n    limiter = RateLimiter()\n\n    if not request.url.path.startswith(\"/api\"):\n        return await call_next(request)\n\n    api_key = request.headers.get(\"Authorization\")\n    if not api_key:\n        return await call_next(request)\n\n    api_key = api_key.replace(\"Bearer \", \"\")\n\n    is_allowed, remaining, reset_time = await limiter.check_rate_limit(api_key)\n\n    if not is_allowed:\n        raise HTTPException(\n            status_code=429, detail=\"Rate limit exceeded. Please try again later.\"\n        )\n\n    response = await call_next(request)\n    response.headers[\"X-RateLimit-Limit\"] = str(limiter.max_requests)\n    response.headers[\"X-RateLimit-Remaining\"] = str(remaining)\n    response.headers[\"X-RateLimit-Reset\"] = str(reset_time)\n\n    return response", "blocks": [{"id": 1, "label": "async def rate_limit_middleware(request: Request, call_next: RequestResponseEndpoint):\nlimiter = RateLimiter()", "successors": [{"id": 3, "label": "if not request.url.path.startswith(\"/api\"):", "successors": [{"id": 4, "label": "return await call_next(request)", "successors": []}, {"id": 5, "label": "api_key = request.headers.get(\"Authorization\")\nif not api_key:", "successors": [{"id": 7, "label": "return await call_next(request)", "successors": []}, {"id": 8, "label": "api_key = api_key.replace(\"Bearer \", \"\")\nis_allowed, remaining, reset_time = await limiter.check_rate_limit(api_key)", "successors": [{"id": 10, "label": "if not is_allowed:", "successors": [{"id": 11, "label": "raise HTTPException( status_code=429, detail=\"Rate limit exceeded. Please try again later.\")", "successors": []}, {"id": 12, "label": "response = await call_next(request)\nresponse.headers[\"X-RateLimit-Limit\"] = str(limiter.max_requests)", "successors": [{"id": 14, "label": "response.headers[\"X-RateLimit-Remaining\"] = str(remaining)\nresponse.headers[\"X-RateLimit-Reset\"] = str(reset_time)", "successors": [{"id": 16, "label": "return response", "successors": []}]}]}]}]}]}]}]}]}], "classes": [], "simplified_code": "from fastapi import HTTPException, Request\nfrom starlette.middleware.base import RequestResponseEndpoint\n\nfrom .limiter import RateLimiter\n\n\n    return response", "blocks": [{"id": 1, "label": "from fastapi import HTTPException, Request\nfrom starlette.middleware.base import RequestResponseEndpoint\n\nfrom .limiter import RateLimiter", "successors": []}]}
{"file_name": "157.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 84, "functions": [{"name": "connect", "type": "function", "start_line": 22, "end_line": 35, "functions": [], "classes": [], "simplified_code": "def connect() -> Redis:\n    global connection\n    if connection:\n        return connection\n\n    c = Redis(\n        host=HOST,\n        port=PORT,\n        password=PASSWORD,\n        decode_responses=True,\n    )\n    c.ping()\n    connection = c\n    return connection", "blocks": [{"id": 1, "label": "def connect() -> Redis:\n    global connection", "successors": [{"id": 2, "label": "if connection:\n    return connection", "successors": []}, {"id": 4, "label": "c = Redis(\n        host=HOST,\n        port=PORT,\n        password=PASSWORD,\n        decode_responses=True,\n    )\nc.ping()\nconnection = c\nreturn connection", "successors": []}]}]}, {"name": "disconnect", "type": "function", "start_line": 39, "end_line": 43, "functions": [], "classes": [], "simplified_code": "def disconnect():\n    global connection\n    if connection:\n        connection.close()\n    connection = None", "blocks": [{"id": 1, "label": "def disconnect():\nglobal connection", "successors": [{"id": 3, "label": "if connection:", "successors": [{"id": 4, "label": "connection.close()\nconnection = None", "successors": []}, {"id": 5, "label": "connection = None", "successors": []}]}]}]}, {"name": "get_redis", "type": "function", "start_line": 46, "end_line": 51, "functions": [], "classes": [], "simplified_code": "def get_redis(auto_connect: bool = True) -> Redis:\n    if connection:\n        return connection\n    if auto_connect:\n        return connect()\n    raise RuntimeError(\"Redis connection is not established\")", "blocks": [{"id": 1, "label": "def get_redis(auto_connect: bool = True) -> Redis:", "successors": [{"id": 2, "label": "if connection:\n    return connection", "successors": []}, {"id": 4, "label": "if auto_connect:\n    return connect()", "successors": []}, {"id": 6, "label": "raise RuntimeError(\"Redis connection is not established\")", "successors": []}]}]}, {"name": "connect_async", "type": "function", "start_line": 55, "end_line": 68, "functions": [], "classes": [], "simplified_code": "async def connect_async() -> AsyncRedis:\n    global connection_async\n    if connection_async:\n        return connection_async\n\n    c = AsyncRedis(\n        host=HOST,\n        port=PORT,\n        password=PASSWORD,\n        decode_responses=True,\n    )\n    await c.ping()\n    connection_async = c\n    return connection_async", "blocks": [{"id": 1, "label": "if connection_async:", "successors": [{"id": 2, "label": "return connection_async", "successors": []}, {"id": 3, "label": "c = AsyncRedis(\n    host=HOST,\n    port=PORT,\n    password=PASSWORD,\n    decode_responses=True,\n)\nawait c.ping()\nconnection_async = c\nreturn connection_async", "successors": []}]}]}, {"name": "disconnect_async", "type": "function", "start_line": 72, "end_line": 76, "functions": [], "classes": [], "simplified_code": "async def disconnect_async():\n    global connection_async\n    if connection_async:\n        await connection_async.close()\n    connection_async = None", "blocks": [{"id": 1, "label": "async def disconnect_async():\nglobal connection_async", "successors": [{"id": 3, "label": "if connection_async:", "successors": [{"id": 4, "label": "await connection_async.close()\nconnection_async = None", "successors": []}, {"id": 5, "label": "connection_async = None", "successors": []}]}]}]}, {"name": "get_redis_async", "type": "function", "start_line": 79, "end_line": 84, "functions": [], "classes": [], "simplified_code": "async def get_redis_async(auto_connect: bool = True) -> AsyncRedis:\n    if connection_async:\n        return connection_async\n    if auto_connect:\n        return await connect_async()\n    raise RuntimeError(\"AsyncRedis connection is not established\")", "blocks": [{"id": 1, "label": "async def get_redis_async(auto_connect: bool = True) -> AsyncRedis:\nif connection_async:", "successors": [{"id": 3, "label": "return connection_async", "successors": []}, {"id": 4, "label": "if auto_connect:", "successors": [{"id": 5, "label": "return await connect_async()", "successors": []}, {"id": 6, "label": "raise RuntimeError(\"AsyncRedis connection is not established\")", "successors": []}]}]}]}], "classes": [], "simplified_code": "import logging\nimport os\n\nfrom dotenv import load_dotenv\nfrom redis import Redis\nfrom redis.asyncio import Redis as AsyncRedis\n\nfrom backend.util.retry import conn_retry\n\nload_dotenv()\n\nHOST = os.getenv(\"REDIS_HOST\", \"localhost\")\nPORT = int(os.getenv(\"REDIS_PORT\", \"6379\"))\nPASSWORD = os.getenv(\"REDIS_PASSWORD\", \"password\")\n\nlogger = logging.getLogger(__name__)\nconnection: Redis | None = None\nconnection_async: AsyncRedis | None = None\n\n\n@conn_retry(\"Redis\", \"Acquiring connection\")\n    return connection\n\n\n@conn_retry(\"Redis\", \"Releasing connection\")\n    connection = None\n\n\n    raise RuntimeError(\"Redis connection is not established\")\n\n\n@conn_retry(\"AsyncRedis\", \"Acquiring connection\")\n    return connection_async\n\n\n@conn_retry(\"AsyncRedis\", \"Releasing connection\")\n    connection_async = None\n\n\n    raise RuntimeError(\"AsyncRedis connection is not established\")", "blocks": [{"id": 1, "label": "import logging\nimport os\n\nfrom dotenv import load_dotenv\nfrom redis import Redis\nfrom redis.asyncio import Redis as AsyncRedis\n\nfrom backend.util.retry import conn_retry\n\nload_dotenv()\n\nHOST = os.getenv(\"REDIS_HOST\", \"localhost\")\nPORT = int(os.getenv(\"REDIS_PORT\", \"6379\"))\nPASSWORD = os.getenv(\"REDIS_PASSWORD\", \"password\")\n\nlogger = logging.getLogger(__name__)\nconnection: Redis | None = None\nconnection_async: AsyncRedis | None = None\n\n\n@conn_retry(\"Redis\", \"Acquiring connection\")\nreturn connection\n\n\n@conn_retry(\"Redis\", \"Releasing connection\")\nconnection = None\n\n\nraise RuntimeError(\"Redis connection is not established\")\n\n\n@conn_retry(\"AsyncRedis\", \"Acquiring connection\")\nreturn connection_async\n\n\n@conn_retry(\"AsyncRedis\", \"Releasing connection\")\nconnection_async = None\n\n\nraise RuntimeError(\"AsyncRedis connection is not established\")", "successors": []}]}
{"file_name": "158.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 190, "functions": [{"name": "mock_settings", "type": "function", "start_line": 14, "end_line": 19, "functions": [], "classes": [], "simplified_code": "def mock_settings(monkeypatch):\n    settings = Settings()\n    settings.config.media_gcs_bucket_name = \"test-bucket\"\n    settings.config.google_application_credentials = \"test-credentials\"\n    monkeypatch.setattr(\"backend.server.v2.store.media.Settings\", lambda: settings)\n    return settings", "blocks": [{"id": 1, "label": "settings = Settings()\\nsettings.config.media_gcs_bucket_name = \"test-bucket\"\\nsettings.config.google_application_credentials = \"test-credentials\"\\nmonkeypatch.setattr(\"backend.server.v2.store.media.Settings\", lambda: settings)\nreturn settings", "successors": []}]}, {"name": "mock_storage_client", "type": "function", "start_line": 23, "end_line": 34, "functions": [], "classes": [], "simplified_code": "def mock_storage_client(mocker):\n    mock_client = unittest.mock.MagicMock()\n    mock_bucket = unittest.mock.MagicMock()\n    mock_blob = unittest.mock.MagicMock()\n\n    mock_client.bucket.return_value = mock_bucket\n    mock_bucket.blob.return_value = mock_blob\n    mock_blob.public_url = \"http://test-url/media/laptop.jpeg\"\n\n    mocker.patch(\"google.cloud.storage.Client\", return_value=mock_client)\n\n    return mock_client", "blocks": [{"id": 1, "label": "def mock_storage_client(mocker):\nmock_client = unittest.mock.MagicMock()\nmock_bucket = unittest.mock.MagicMock()\nmock_blob = unittest.mock.MagicMock()", "successors": [{"id": 3, "label": "mock_client.bucket.return_value = mock_bucket\nmock_bucket.blob.return_value = mock_blob\nmock_blob.public_url = \"http://test-url/media/laptop.jpeg\"\nmocker.patch(\"google.cloud.storage.Client\", return_value=mock_client)", "successors": [{"id": 5, "label": "return mock_client", "successors": []}]}]}]}, {"name": "test_upload_media_success", "type": "function", "start_line": 37, "end_line": 52, "functions": [], "classes": [], "simplified_code": "async def test_upload_media_success(mock_settings, mock_storage_client):\n    # Create test JPEG data with valid signature\n    test_data = b\"\\xFF\\xD8\\xFF\" + b\"test data\"\n\n    test_file = fastapi.UploadFile(\n        filename=\"laptop.jpeg\",\n        file=io.BytesIO(test_data),\n        headers=starlette.datastructures.Headers({\"content-type\": \"image/jpeg\"}),\n    )\n\n    result = await backend.server.v2.store.media.upload_media(\"test-user\", test_file)\n\n    assert result == \"http://test-url/media/laptop.jpeg\"\n    mock_bucket = mock_storage_client.bucket.return_value\n    mock_blob = mock_bucket.blob.return_value\n    mock_blob.upload_from_string.assert_called_once()", "blocks": [{"id": 1, "label": "async def test_upload_media_success(mock_settings, mock_storage_client):\n    test_data = b\"\\xFF\\xD8\\xFF\" + b\"test data\"", "successors": [{"id": 3, "label": "    test_file = fastapi.UploadFile(\n        filename=\"laptop.jpeg\",\n        file=io.BytesIO(test_data),\n        headers=starlette.datastructures.Headers({\"content-type\": \"image/jpeg\"}),\n    )\n    result = await backend.server.v2.store.media.upload_media(\"test-user\", test_file)", "successors": [{"id": 5, "label": "    assert result == \"http://test-url/media/laptop.jpeg\"\n    mock_bucket = mock_storage_client.bucket.return_value", "successors": [{"id": 7, "label": "    mock_blob = mock_bucket.blob.return_value\n    mock_blob.upload_from_string.assert_called_once()", "successors": []}]}]}]}]}, {"name": "test_upload_media_invalid_type", "type": "function", "start_line": 55, "end_line": 67, "functions": [], "classes": [], "simplified_code": "async def test_upload_media_invalid_type(mock_settings, mock_storage_client):\n    test_file = fastapi.UploadFile(\n        filename=\"test.txt\",\n        file=io.BytesIO(b\"test data\"),\n        headers=starlette.datastructures.Headers({\"content-type\": \"text/plain\"}),\n    )\n\n    with pytest.raises(backend.server.v2.store.exceptions.InvalidFileTypeError):\n        await backend.server.v2.store.media.upload_media(\"test-user\", test_file)\n\n    mock_bucket = mock_storage_client.bucket.return_value\n    mock_blob = mock_bucket.blob.return_value\n    mock_blob.upload_from_string.assert_not_called()", "blocks": [{"id": 1, "label": "async def test_upload_media_invalid_type(mock_settings, mock_storage_client):\ntest_file = fastapi.UploadFile(\n    filename=\"test.txt\",\n    file=io.BytesIO(b\"test data\"),\n    headers=starlette.datastructures.Headers({\"content-type\": \"text/plain\"}),\n)", "successors": [{"id": 3, "label": "with pytest.raises(backend.server.v2.store.exceptions.InvalidFileTypeError):\nawait backend.server.v2.store.media.upload_media(\"test-user\", test_file)", "successors": [{"id": 5, "label": "mock_bucket = mock_storage_client.bucket.return_value\nmock_blob = mock_bucket.blob.return_value\nmock_blob.upload_from_string.assert_not_called()", "successors": []}]}]}]}, {"name": "test_upload_media_missing_credentials", "type": "function", "start_line": 70, "end_line": 83, "functions": [], "classes": [], "simplified_code": "async def test_upload_media_missing_credentials(monkeypatch):\n    settings = Settings()\n    settings.config.media_gcs_bucket_name = \"\"\n    settings.config.google_application_credentials = \"\"\n    monkeypatch.setattr(\"backend.server.v2.store.media.Settings\", lambda: settings)\n\n    test_file = fastapi.UploadFile(\n        filename=\"laptop.jpeg\",\n        file=io.BytesIO(b\"\\xFF\\xD8\\xFF\" + b\"test data\"),  # Valid JPEG signature\n        headers=starlette.datastructures.Headers({\"content-type\": \"image/jpeg\"}),\n    )\n\n    with pytest.raises(backend.server.v2.store.exceptions.StorageConfigError):\n        await backend.server.v2.store.media.upload_media(\"test-user\", test_file)", "blocks": [{"id": 1, "label": "async def test_upload_media_missing_credentials(monkeypatch):\nsettings = Settings()\nsettings.config.media_gcs_bucket_name = \"\"\nsettings.config.google_application_credentials = \"\"\nmonkeypatch.setattr(\"backend.server.v2.store.media.Settings\", lambda: settings)\n\ntest_file = fastapi.UploadFile(\n    filename=\"laptop.jpeg\",\n    file=io.BytesIO(b\"\\xFF\\xD8\\xFF\" + b\"test data\"),  # Valid JPEG signature\n    headers=starlette.datastructures.Headers({\"content-type\": \"image/jpeg\"}),\n)", "successors": [{"id": 3, "label": "with pytest.raises(backend.server.v2.store.exceptions.StorageConfigError):\nawait backend.server.v2.store.media.upload_media(\"test-user\", test_file)", "successors": []}]}]}, {"name": "test_upload_media_video_type", "type": "function", "start_line": 86, "end_line": 98, "functions": [], "classes": [], "simplified_code": "async def test_upload_media_video_type(mock_settings, mock_storage_client):\n    test_file = fastapi.UploadFile(\n        filename=\"test.mp4\",\n        file=io.BytesIO(b\"\\x00\\x00\\x00\\x18ftypmp42\"),  # Valid MP4 signature\n        headers=starlette.datastructures.Headers({\"content-type\": \"video/mp4\"}),\n    )\n\n    result = await backend.server.v2.store.media.upload_media(\"test-user\", test_file)\n\n    assert result == \"http://test-url/media/laptop.jpeg\"\n    mock_bucket = mock_storage_client.bucket.return_value\n    mock_blob = mock_bucket.blob.return_value\n    mock_blob.upload_from_string.assert_called_once()", "blocks": [{"id": 1, "label": "async def test_upload_media_video_type(mock_settings, mock_storage_client):\ntest_file = fastapi.UploadFile(\n    filename=\"test.mp4\",\n    file=io.BytesIO(b\"\\x00\\x00\\x00\\x18ftypmp42\"),  # Valid MP4 signature\n    headers=starlette.datastructures.Headers({\"content-type\": \"video/mp4\"}),\n)", "successors": [{"id": 3, "label": "result = await backend.server.v2.store.media.upload_media(\"test-user\", test_file)\nassert result == \"http://test-url/media/laptop.jpeg\"", "successors": [{"id": 5, "label": "mock_bucket = mock_storage_client.bucket.return_value\nmock_blob = mock_bucket.blob.return_value", "successors": [{"id": 7, "label": "mock_blob.upload_from_string.assert_called_once()", "successors": []}]}]}]}]}, {"name": "test_upload_media_file_too_large", "type": "function", "start_line": 101, "end_line": 112, "functions": [], "classes": [], "simplified_code": "async def test_upload_media_file_too_large(mock_settings, mock_storage_client):\n    large_data = b\"\\xFF\\xD8\\xFF\" + b\"x\" * (\n        50 * 1024 * 1024 + 1\n    )  # 50MB + 1 byte with valid JPEG signature\n    test_file = fastapi.UploadFile(\n        filename=\"laptop.jpeg\",\n        file=io.BytesIO(large_data),\n        headers=starlette.datastructures.Headers({\"content-type\": \"image/jpeg\"}),\n    )\n\n    with pytest.raises(backend.server.v2.store.exceptions.FileSizeTooLargeError):\n        await backend.server.v2.store.media.upload_media(\"test-user\", test_file)", "blocks": [{"id": 1, "label": "async def test_upload_media_file_too_large(mock_settings, mock_storage_client):\nlarge_data = b\"\\xFF\\xD8\\xFF\" + b\"x\" * ( 50 * 1024 * 1024 + 1 )  # 50MB + 1 byte with valid JPEG signature\n    test_file = fastapi.UploadFile( filename=\"laptop.jpeg\", file=io.BytesIO(large_data), headers=starlette.datastructures.Headers({\"content-type\": \"image/jpeg\"}), )", "successors": [{"id": 3, "label": "with pytest.raises(backend.server.v2.store.exceptions.FileSizeTooLargeError):\nawait backend.server.v2.store.media.upload_media(\"test-user\", test_file)", "successors": []}]}]}, {"name": "test_upload_media_file_read_error", "type": "function", "start_line": 115, "end_line": 124, "functions": [], "classes": [], "simplified_code": "async def test_upload_media_file_read_error(mock_settings, mock_storage_client):\n    test_file = fastapi.UploadFile(\n        filename=\"laptop.jpeg\",\n        file=io.BytesIO(b\"\"),  # Empty file that will raise error on read\n        headers=starlette.datastructures.Headers({\"content-type\": \"image/jpeg\"}),\n    )\n    test_file.read = unittest.mock.AsyncMock(side_effect=Exception(\"Read error\"))\n\n    with pytest.raises(backend.server.v2.store.exceptions.FileReadError):\n        await backend.server.v2.store.media.upload_media(\"test-user\", test_file)", "blocks": [{"id": 1, "label": "async def test_upload_media_file_read_error(mock_settings, mock_storage_client):\ntest_file = fastapi.UploadFile(\n    filename=\"laptop.jpeg\",\n    file=io.BytesIO(b\"\"),  # Empty file that will raise error on read\n    headers=starlette.datastructures.Headers({\"content-type\": \"image/jpeg\"}),\n)", "successors": [{"id": 3, "label": "test_file.read = unittest.mock.AsyncMock(side_effect=Exception(\"Read error\"))\nwith pytest.raises(backend.server.v2.store.exceptions.FileReadError):", "successors": [{"id": 5, "label": "await backend.server.v2.store.media.upload_media(\"test-user\", test_file)", "successors": []}]}]}]}, {"name": "test_upload_media_png_success", "type": "function", "start_line": 127, "end_line": 135, "functions": [], "classes": [], "simplified_code": "async def test_upload_media_png_success(mock_settings, mock_storage_client):\n    test_file = fastapi.UploadFile(\n        filename=\"test.png\",\n        file=io.BytesIO(b\"\\x89PNG\\r\\n\\x1a\\n\"),  # Valid PNG signature\n        headers=starlette.datastructures.Headers({\"content-type\": \"image/png\"}),\n    )\n\n    result = await backend.server.v2.store.media.upload_media(\"test-user\", test_file)\n    assert result == \"http://test-url/media/laptop.jpeg\"", "blocks": [{"id": 1, "label": "async def test_upload_media_png_success(mock_settings, mock_storage_client):\n    test_file = fastapi.UploadFile(\n        filename=\"test.png\",\n        file=io.BytesIO(b\"\\x89PNG\\r\\n\\x1a\\n\"),  # Valid PNG signature\n        headers=starlette.datastructures.Headers({\"content-type\": \"image/png\"}),\n    )", "successors": [{"id": 3, "label": "    result = await backend.server.v2.store.media.upload_media(\"test-user\", test_file)\n    assert result == \"http://test-url/media/laptop.jpeg\"", "successors": []}]}]}, {"name": "test_upload_media_gif_success", "type": "function", "start_line": 138, "end_line": 146, "functions": [], "classes": [], "simplified_code": "async def test_upload_media_gif_success(mock_settings, mock_storage_client):\n    test_file = fastapi.UploadFile(\n        filename=\"test.gif\",\n        file=io.BytesIO(b\"GIF89a\"),  # Valid GIF signature\n        headers=starlette.datastructures.Headers({\"content-type\": \"image/gif\"}),\n    )\n\n    result = await backend.server.v2.store.media.upload_media(\"test-user\", test_file)\n    assert result == \"http://test-url/media/laptop.jpeg\"", "blocks": [{"id": 1, "label": "async def test_upload_media_gif_success(mock_settings, mock_storage_client):\ntest_file = fastapi.UploadFile(\n    filename=\"test.gif\",\n    file=io.BytesIO(b\"GIF89a\"),  # Valid GIF signature\n    headers=starlette.datastructures.Headers({\"content-type\": \"image/gif\"}),\n)", "successors": [{"id": 3, "label": "result = await backend.server.v2.store.media.upload_media(\"test-user\", test_file)\nassert result == \"http://test-url/media/laptop.jpeg\"", "successors": []}]}]}, {"name": "test_upload_media_webp_success", "type": "function", "start_line": 149, "end_line": 157, "functions": [], "classes": [], "simplified_code": "async def test_upload_media_webp_success(mock_settings, mock_storage_client):\n    test_file = fastapi.UploadFile(\n        filename=\"test.webp\",\n        file=io.BytesIO(b\"RIFF\\x00\\x00\\x00\\x00WEBP\"),  # Valid WebP signature\n        headers=starlette.datastructures.Headers({\"content-type\": \"image/webp\"}),\n    )\n\n    result = await backend.server.v2.store.media.upload_media(\"test-user\", test_file)\n    assert result == \"http://test-url/media/laptop.jpeg\"", "blocks": [{"id": 1, "label": "async def test_upload_media_webp_success(mock_settings, mock_storage_client):\ntest_file = fastapi.UploadFile(\n    filename=\"test.webp\",\n    file=io.BytesIO(b\"RIFF\\x00\\x00\\x00\\x00WEBP\"),  # Valid WebP signature\n    headers=starlette.datastructures.Headers({\"content-type\": \"image/webp\"}),\n)", "successors": [{"id": 3, "label": "result = await backend.server.v2.store.media.upload_media(\"test-user\", test_file)\nassert result == \"http://test-url/media/laptop.jpeg\"", "successors": []}]}]}, {"name": "test_upload_media_webm_success", "type": "function", "start_line": 160, "end_line": 168, "functions": [], "classes": [], "simplified_code": "async def test_upload_media_webm_success(mock_settings, mock_storage_client):\n    test_file = fastapi.UploadFile(\n        filename=\"test.webm\",\n        file=io.BytesIO(b\"\\x1a\\x45\\xdf\\xa3\"),  # Valid WebM signature\n        headers=starlette.datastructures.Headers({\"content-type\": \"video/webm\"}),\n    )\n\n    result = await backend.server.v2.store.media.upload_media(\"test-user\", test_file)\n    assert result == \"http://test-url/media/laptop.jpeg\"", "blocks": [{"id": 1, "label": "async def test_upload_media_webm_success(mock_settings, mock_storage_client):\n    test_file = fastapi.UploadFile(\n        filename=\"test.webm\",\n        file=io.BytesIO(b\"\\x1a\\x45\\xdf\\xa3\"),  # Valid WebM signature\n        headers=starlette.datastructures.Headers({\"content-type\": \"video/webm\"}),\n    )", "successors": [{"id": 3, "label": "    result = await backend.server.v2.store.media.upload_media(\"test-user\", test_file)\n    assert result == \"http://test-url/media/laptop.jpeg\"", "successors": []}]}]}, {"name": "test_upload_media_mismatched_signature", "type": "function", "start_line": 171, "end_line": 179, "functions": [], "classes": [], "simplified_code": "async def test_upload_media_mismatched_signature(mock_settings, mock_storage_client):\n    test_file = fastapi.UploadFile(\n        filename=\"test.jpeg\",\n        file=io.BytesIO(b\"\\x89PNG\\r\\n\\x1a\\n\"),  # PNG signature with JPEG content type\n        headers=starlette.datastructures.Headers({\"content-type\": \"image/jpeg\"}),\n    )\n\n    with pytest.raises(backend.server.v2.store.exceptions.InvalidFileTypeError):\n        await backend.server.v2.store.media.upload_media(\"test-user\", test_file)", "blocks": [{"id": 1, "label": "async def test_upload_media_mismatched_signature(mock_settings, mock_storage_client):\ntest_file = fastapi.UploadFile(\n    filename=\"test.jpeg\",\n    file=io.BytesIO(b\"\\x89PNG\\r\\n\\x1a\\n\"),  # PNG signature with JPEG content type\n    headers=starlette.datastructures.Headers({\"content-type\": \"image/jpeg\"}),\n)", "successors": [{"id": 3, "label": "with pytest.raises(backend.server.v2.store.exceptions.InvalidFileTypeError):\nawait backend.server.v2.store.media.upload_media(\"test-user\", test_file)", "successors": []}]}]}, {"name": "test_upload_media_invalid_signature", "type": "function", "start_line": 182, "end_line": 190, "functions": [], "classes": [], "simplified_code": "async def test_upload_media_invalid_signature(mock_settings, mock_storage_client):\n    test_file = fastapi.UploadFile(\n        filename=\"test.jpeg\",\n        file=io.BytesIO(b\"invalid signature\"),\n        headers=starlette.datastructures.Headers({\"content-type\": \"image/jpeg\"}),\n    )\n\n    with pytest.raises(backend.server.v2.store.exceptions.InvalidFileTypeError):\n        await backend.server.v2.store.media.upload_media(\"test-user\", test_file)", "blocks": [{"id": 1, "label": "async def test_upload_media_invalid_signature(mock_settings, mock_storage_client):\ntest_file = fastapi.UploadFile(\n    filename=\"test.jpeg\",\n    file=io.BytesIO(b\"invalid signature\"),\n    headers=starlette.datastructures.Headers({\"content-type\": \"image/jpeg\"}),\n)", "successors": [{"id": 3, "label": "with pytest.raises(backend.server.v2.store.exceptions.InvalidFileTypeError):\nawait backend.server.v2.store.media.upload_media(\"test-user\", test_file)", "successors": []}]}]}], "classes": [], "simplified_code": "import io\nimport unittest.mock\n\nimport fastapi\nimport pytest\nimport starlette.datastructures\n\nimport backend.server.v2.store.exceptions\nimport backend.server.v2.store.media\nfrom backend.util.settings import Settings\n\n\n@pytest.fixture\n    return settings\n\n\n@pytest.fixture\n    return mock_client\n\n\n    mock_blob.upload_from_string.assert_called_once()\n\n\n    mock_blob.upload_from_string.assert_not_called()\n\n\n        await backend.server.v2.store.media.upload_media(\"test-user\", test_file)\n\n\n    mock_blob.upload_from_string.assert_called_once()\n\n\n        await backend.server.v2.store.media.upload_media(\"test-user\", test_file)\n\n\n        await backend.server.v2.store.media.upload_media(\"test-user\", test_file)\n\n\n    assert result == \"http://test-url/media/laptop.jpeg\"\n\n\n    assert result == \"http://test-url/media/laptop.jpeg\"\n\n\n    assert result == \"http://test-url/media/laptop.jpeg\"\n\n\n    assert result == \"http://test-url/media/laptop.jpeg\"\n\n\n        await backend.server.v2.store.media.upload_media(\"test-user\", test_file)\n\n\n        await backend.server.v2.store.media.upload_media(\"test-user\", test_file)", "blocks": []}
{"file_name": "159.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 176, "functions": [{"name": "valid_connection", "type": "function", "start_line": 11, "end_line": 46, "functions": [], "classes": [], "simplified_code": "def valid_connection(\n    graph: list[list[int]], next_ver: int, curr_ind: int, path: list[int]\n) -> bool:\n    \"\"\"\n    Checks whether it is possible to add next into path by validating 2 statements\n    1. There should be path between current and next vertex\n    2. Next vertex should not be in path\n    If both validations succeed we return True, saying that it is possible to connect\n    this vertices, otherwise we return False\n\n    Case 1:Use exact graph as in main function, with initialized values\n    >>> graph = [[0, 1, 0, 1, 0],\n    ...          [1, 0, 1, 1, 1],\n    ...          [0, 1, 0, 0, 1],\n    ...          [1, 1, 0, 0, 1],\n    ...          [0, 1, 1, 1, 0]]\n    >>> path = [0, -1, -1, -1, -1, 0]\n    >>> curr_ind = 1\n    >>> next_ver = 1\n    >>> valid_connection(graph, next_ver, curr_ind, path)\n    True\n\n    Case 2: Same graph, but trying to connect to node that is already in path\n    >>> path = [0, 1, 2, 4, -1, 0]\n    >>> curr_ind = 4\n    >>> next_ver = 1\n    >>> valid_connection(graph, next_ver, curr_ind, path)\n    False\n    \"\"\"\n\n    # 1. Validate that path exists between current and next vertices\n    if graph[path[curr_ind - 1]][next_ver] == 0:\n        return False\n\n    # 2. Validate that next vertex is not already in path\n    return not any(vertex == next_ver for vertex in path)", "blocks": [{"id": 1, "label": "def valid_connection(graph: list[list[int]], next_ver: int, curr_ind: int, path: list[int]) -> bool:\n    if graph[path[curr_ind - 1]][next_ver] == 0:", "successors": [{"id": 3, "label": "        return False", "successors": []}, {"id": 4, "label": "    return not any(vertex == next_ver for vertex in path)", "successors": []}]}]}, {"name": "util_hamilton_cycle", "type": "function", "start_line": 49, "end_line": 107, "functions": [], "classes": [], "simplified_code": "def util_hamilton_cycle(graph: list[list[int]], path: list[int], curr_ind: int) -> bool:\n    \"\"\"\n    Pseudo-Code\n    Base Case:\n    1. Check if we visited all of vertices\n        1.1 If last visited vertex has path to starting vertex return True either\n            return False\n    Recursive Step:\n    2. Iterate over each vertex\n        Check if next vertex is valid for transiting from current vertex\n            2.1 Remember next vertex as next transition\n            2.2 Do recursive call and check if going to this vertex solves problem\n            2.3 If next vertex leads to solution return True\n            2.4 Else backtrack, delete remembered vertex\n\n    Case 1: Use exact graph as in main function, with initialized values\n    >>> graph = [[0, 1, 0, 1, 0],\n    ...          [1, 0, 1, 1, 1],\n    ...          [0, 1, 0, 0, 1],\n    ...          [1, 1, 0, 0, 1],\n    ...          [0, 1, 1, 1, 0]]\n    >>> path = [0, -1, -1, -1, -1, 0]\n    >>> curr_ind = 1\n    >>> util_hamilton_cycle(graph, path, curr_ind)\n    True\n    >>> path\n    [0, 1, 2, 4, 3, 0]\n\n    Case 2: Use exact graph as in previous case, but in the properties taken from\n        middle of calculation\n    >>> graph = [[0, 1, 0, 1, 0],\n    ...          [1, 0, 1, 1, 1],\n    ...          [0, 1, 0, 0, 1],\n    ...          [1, 1, 0, 0, 1],\n    ...          [0, 1, 1, 1, 0]]\n    >>> path = [0, 1, 2, -1, -1, 0]\n    >>> curr_ind = 3\n    >>> util_hamilton_cycle(graph, path, curr_ind)\n    True\n    >>> path\n    [0, 1, 2, 4, 3, 0]\n    \"\"\"\n\n    # Base Case\n    if curr_ind == len(graph):\n        # return whether path exists between current and starting vertices\n        return graph[path[curr_ind - 1]][path[0]] == 1\n\n    # Recursive Step\n    for next_ver in range(len(graph)):\n        if valid_connection(graph, next_ver, curr_ind, path):\n            # Insert current vertex  into path as next transition\n            path[curr_ind] = next_ver\n            # Validate created path\n            if util_hamilton_cycle(graph, path, curr_ind + 1):\n                return True\n            # Backtrack\n            path[curr_ind] = -1\n    return False", "blocks": [{"id": 1, "label": "def util_hamilton_cycle(graph: list[list[int]], path: list[int], curr_ind: int) -> bool:", "successors": [{"id": 2, "label": "if curr_ind == len(graph):\nreturn graph[path[curr_ind - 1]][path[0]] == 1", "successors": []}, {"id": 4, "label": "for next_ver in range(len(graph)):", "successors": [{"id": 5, "label": "if valid_connection(graph, next_ver, curr_ind, path):\npath[curr_ind] = next_ver", "successors": [{"id": 7, "label": "if util_hamilton_cycle(graph, path, curr_ind + 1):\nreturn True", "successors": []}, {"id": 9, "label": "path[curr_ind] = -1\nreturn False", "successors": []}]}]}, {"id": 11, "label": "return False", "successors": []}]}]}, {"name": "hamilton_cycle", "type": "function", "start_line": 110, "end_line": 176, "functions": [], "classes": [], "simplified_code": "def hamilton_cycle(graph: list[list[int]], start_index: int = 0) -> list[int]:\n    r\"\"\"\n    Wrapper function to call subroutine called util_hamilton_cycle,\n    which will either return array of vertices indicating hamiltonian cycle\n    or an empty list indicating that hamiltonian cycle was not found.\n    Case 1:\n    Following graph consists of 5 edges.\n    If we look closely, we can see that there are multiple Hamiltonian cycles.\n    For example one result is when we iterate like:\n    (0)->(1)->(2)->(4)->(3)->(0)\n\n    (0)---(1)---(2)\n     |   /   \\   |\n     |  /     \\  |\n     | /       \\ |\n     |/         \\|\n    (3)---------(4)\n    >>> graph = [[0, 1, 0, 1, 0],\n    ...          [1, 0, 1, 1, 1],\n    ...          [0, 1, 0, 0, 1],\n    ...          [1, 1, 0, 0, 1],\n    ...          [0, 1, 1, 1, 0]]\n    >>> hamilton_cycle(graph)\n    [0, 1, 2, 4, 3, 0]\n\n    Case 2:\n    Same Graph as it was in Case 1, changed starting index from default to 3\n\n    (0)---(1)---(2)\n     |   /   \\   |\n     |  /     \\  |\n     | /       \\ |\n     |/         \\|\n    (3)---------(4)\n    >>> graph = [[0, 1, 0, 1, 0],\n    ...          [1, 0, 1, 1, 1],\n    ...          [0, 1, 0, 0, 1],\n    ...          [1, 1, 0, 0, 1],\n    ...          [0, 1, 1, 1, 0]]\n    >>> hamilton_cycle(graph, 3)\n    [3, 0, 1, 2, 4, 3]\n\n    Case 3:\n    Following Graph is exactly what it was before, but edge 3-4 is removed.\n    Result is that there is no Hamiltonian Cycle anymore.\n\n    (0)---(1)---(2)\n     |   /   \\   |\n     |  /     \\  |\n     | /       \\ |\n     |/         \\|\n    (3)         (4)\n    >>> graph = [[0, 1, 0, 1, 0],\n    ...          [1, 0, 1, 1, 1],\n    ...          [0, 1, 0, 0, 1],\n    ...          [1, 1, 0, 0, 0],\n    ...          [0, 1, 1, 0, 0]]\n    >>> hamilton_cycle(graph,4)\n    []\n    \"\"\"\n\n    # Initialize path with -1, indicating that we have not visited them yet\n    path = [-1] * (len(graph) + 1)\n    # initialize start and end of path with starting index\n    path[0] = path[-1] = start_index\n    # evaluate and if we find answer return path either return empty array\n    return path if util_hamilton_cycle(graph, path, 1) else []", "blocks": [{"id": 1, "label": "def hamilton_cycle(graph: list[list[int]], start_index: int = 0) -> list[int]:\npath = [-1] * (len(graph) + 1)", "successors": [{"id": 3, "label": "path[0] = path[-1] = start_index\nreturn path if util_hamilton_cycle(graph, path, 1) else []", "successors": []}]}]}], "classes": [], "simplified_code": "\"\"\"\nA Hamiltonian cycle (Hamiltonian circuit) is a graph cycle\nthrough a graph that visits each node exactly once.\nDetermining whether such paths and cycles exist in graphs\nis the 'Hamiltonian path problem', which is NP-complete.\n\nWikipedia: https://en.wikipedia.org/wiki/Hamiltonian_path\n\"\"\"\n\n\n    return not any(vertex == next_ver for vertex in path)\n\n\n    return False\n\n\n    return path if util_hamilton_cycle(graph, path, 1) else []", "blocks": [{"id": 1, "label": "return not any(vertex == next_ver for vertex in path)", "successors": []}]}
{"file_name": "160.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 161, "functions": [], "classes": [{"name": "InstallationLocation", "type": "class", "start_line": 10, "end_line": 12, "functions": [], "simplified_code": "class InstallationLocation(str, Enum):\n    LOCAL = \"local\"\n    CLOUD = \"cloud\"", "blocks": [{"id": 1, "label": "class InstallationLocation(str, Enum):", "successors": [{"id": 2, "label": "    LOCAL = \"local\"", "successors": []}, {"id": 3, "label": "    CLOUD = \"cloud\"", "successors": []}]}]}, {"name": "AgentInstalledFromMarketplaceEventData", "type": "class", "start_line": 15, "end_line": 18, "functions": [], "simplified_code": "class AgentInstalledFromMarketplaceEventData(pydantic.BaseModel):\n    marketplace_agent_id: str\n    installed_agent_id: str\n    installation_location: InstallationLocation", "blocks": [{"id": 1, "label": "class AgentInstalledFromMarketplaceEventData(pydantic.BaseModel):\n    marketplace_agent_id: str\n    installed_agent_id: str\n    installation_location: InstallationLocation", "successors": []}]}, {"name": "AgentInstalledFromTemplateEventData", "type": "class", "start_line": 21, "end_line": 24, "functions": [], "simplified_code": "class AgentInstalledFromTemplateEventData(pydantic.BaseModel):\n    template_id: str\n    installed_agent_id: str\n    installation_location: InstallationLocation", "blocks": [{"id": 1, "label": "class AgentInstalledFromTemplateEventData(pydantic.BaseModel):\n    template_id: str\n    installed_agent_id: str\n    installation_location: InstallationLocation", "successors": []}]}, {"name": "AgentInstalledFromMarketplaceEvent", "type": "class", "start_line": 27, "end_line": 29, "functions": [], "simplified_code": "class AgentInstalledFromMarketplaceEvent(pydantic.BaseModel):\n    event_name: Literal[\"agent_installed_from_marketplace\"]\n    event_data: AgentInstalledFromMarketplaceEventData", "blocks": [{"id": 1, "label": "class AgentInstalledFromMarketplaceEvent(pydantic.BaseModel):", "successors": [{"id": 2, "label": " event_name: Literal[\"agent_installed_from_marketplace\"]", "successors": []}, {"id": 3, "label": " event_data: AgentInstalledFromMarketplaceEventData", "successors": []}]}]}, {"name": "AgentInstalledFromTemplateEvent", "type": "class", "start_line": 32, "end_line": 34, "functions": [], "simplified_code": "class AgentInstalledFromTemplateEvent(pydantic.BaseModel):\n    event_name: Literal[\"agent_installed_from_template\"]\n    event_data: AgentInstalledFromTemplateEventData", "blocks": [{"id": 1, "label": "class AgentInstalledFromTemplateEvent(pydantic.BaseModel):\n    event_name: Literal[\"agent_installed_from_template\"]", "successors": [{"id": 3, "label": "    event_data: AgentInstalledFromTemplateEventData", "successors": []}]}]}, {"name": "AnalyticsRequest", "type": "class", "start_line": 42, "end_line": 43, "functions": [], "simplified_code": "class AnalyticsRequest(pydantic.BaseModel):\n    event: AnalyticsEvent", "blocks": [{"id": 1, "label": "class AnalyticsRequest(pydantic.BaseModel):\n    event: AnalyticsEvent", "successors": []}]}, {"name": "AddAgentRequest", "type": "class", "start_line": 46, "end_line": 50, "functions": [], "simplified_code": "class AddAgentRequest(pydantic.BaseModel):\n    graph: dict[str, typing.Any]\n    author: str\n    keywords: list[str]\n    categories: list[str]", "blocks": [{"id": 1, "label": "class AddAgentRequest(pydantic.BaseModel):\n    graph: dict[str, typing.Any]\n    author: str\n    keywords: list[str]\n    categories: list[str]", "successors": []}]}, {"name": "SubmissionReviewRequest", "type": "class", "start_line": 53, "end_line": 57, "functions": [], "simplified_code": "class SubmissionReviewRequest(pydantic.BaseModel):\n    agent_id: str\n    version: int\n    status: prisma.enums.SubmissionStatus\n    comments: str | None", "blocks": [{"id": 1, "label": "class SubmissionReviewRequest(pydantic.BaseModel):\n    agent_id: str\n    version: int\n    status: prisma.enums.SubmissionStatus\n    comments: str | None", "successors": []}]}, {"name": "AgentResponse", "type": "class", "start_line": 60, "end_line": 87, "functions": [], "simplified_code": "class AgentResponse(pydantic.BaseModel):\n    \"\"\"\n    Represents a response from an agent.\n\n    Attributes:\n        id (str): The ID of the agent.\n        name (str, optional): The name of the agent.\n        description (str, optional): The description of the agent.\n        author (str, optional): The author of the agent.\n        keywords (list[str]): The keywords associated with the agent.\n        categories (list[str]): The categories the agent belongs to.\n        version (int): The version of the agent.\n        createdAt (str): The creation date of the agent.\n        updatedAt (str): The last update date of the agent.\n    \"\"\"\n\n    id: str\n    name: typing.Optional[str]\n    description: typing.Optional[str]\n    author: typing.Optional[str]\n    keywords: list[str]\n    categories: list[str]\n    version: int\n    createdAt: datetime.datetime\n    updatedAt: datetime.datetime\n    submissionStatus: str\n    views: int = 0\n    downloads: int = 0", "blocks": [{"id": 1, "label": "class AgentResponse(pydantic.BaseModel):\n\"\"\"\n    Represents a response from an agent.\n\n    Attributes:\n        id (str): The ID of the agent.\n        name (str, optional): The name of the agent.\n        description (str, optional): The description of the agent.\n        author (str, optional): The author of the agent.\n        keywords (list[str]): The keywords associated with the agent.\n        categories (list[str]): The categories the agent belongs to.\n        version (int): The version of the agent.\n        createdAt (str): The creation date of the agent.\n        updatedAt (str): The last update date of the agent.\n    \"\"\"", "successors": [{"id": 3, "label": "id: str\n    name: typing.Optional[str]\n    description: typing.Optional[str]\n    author: typing.Optional[str]\n    keywords: list[str]\n    categories: list[str]\n    version: int\n    createdAt: datetime.datetime\n    updatedAt: datetime.datetime\n    submissionStatus: str\n    views: int = 0\n    downloads: int = 0", "successors": []}]}]}, {"name": "AgentDetailResponse", "type": "class", "start_line": 90, "end_line": 116, "functions": [], "simplified_code": "class AgentDetailResponse(pydantic.BaseModel):\n    \"\"\"\n    Represents the response data for an agent detail.\n\n    Attributes:\n        id (str): The ID of the agent.\n        name (Optional[str]): The name of the agent.\n        description (Optional[str]): The description of the agent.\n        author (Optional[str]): The author of the agent.\n        keywords (List[str]): The keywords associated with the agent.\n        categories (List[str]): The categories the agent belongs to.\n        version (int): The version of the agent.\n        createdAt (str): The creation date of the agent.\n        updatedAt (str): The last update date of the agent.\n        graph (Dict[str, Any]): The graph data of the agent.\n    \"\"\"\n\n    id: str\n    name: typing.Optional[str]\n    description: typing.Optional[str]\n    author: typing.Optional[str]\n    keywords: list[str]\n    categories: list[str]\n    version: int\n    createdAt: datetime.datetime\n    updatedAt: datetime.datetime\n    graph: dict[str, typing.Any]", "blocks": [{"id": 1, "label": "class AgentDetailResponse(pydantic.BaseModel):\n\"\"\"\n Represents the response data for an agent detail.\n\n Attributes:\n id (str): The ID of the agent.\n name (Optional[str]): The name of the agent.\n description (Optional[str]): The description of the agent.\n author (Optional[str]): The author of the agent.\n keywords (List[str]): The keywords associated with the agent.\n categories (List[str]): The categories the agent belongs to.\n version (int): The version of the agent.\n createdAt (str): The creation date of the agent.\n updatedAt (str): The last update date of the agent.\n graph (Dict[str, Any]): The graph data of the agent.\n \"\"\"", "successors": [{"id": 3, "label": "id: str\nname: typing.Optional[str]", "successors": [{"id": 5, "label": "description: typing.Optional[str]\nauthor: typing.Optional[str]", "successors": [{"id": 7, "label": "keywords: list[str]\ncategories: list[str]", "successors": [{"id": 9, "label": "version: int\ncreatedAt: datetime.datetime", "successors": [{"id": 11, "label": "updatedAt: datetime.datetime\ngraph: dict[str, typing.Any]", "successors": []}]}]}]}]}]}]}, {"name": "FeaturedAgentResponse", "type": "class", "start_line": 119, "end_line": 128, "functions": [], "simplified_code": "class FeaturedAgentResponse(pydantic.BaseModel):\n    \"\"\"\n    Represents the response data for an agent detail.\n    \"\"\"\n\n    agentId: str\n    featuredCategories: list[str]\n    createdAt: datetime.datetime\n    updatedAt: datetime.datetime\n    isActive: bool", "blocks": [{"id": 1, "label": "class FeaturedAgentResponse(pydantic.BaseModel):\n\"\"\"\nRepresents the response data for an agent detail.\n\"\"\"", "successors": [{"id": 3, "label": "agentId: str\nfeaturedCategories: list[str]\ncreatedAt: datetime.datetime\nupdatedAt: datetime.datetime\nisActive: bool", "successors": []}]}]}, {"name": "CategoriesResponse", "type": "class", "start_line": 131, "end_line": 139, "functions": [], "simplified_code": "class CategoriesResponse(pydantic.BaseModel):\n    \"\"\"\n    Represents the response data for a list of categories.\n\n    Attributes:\n        unique_categories (list[str]): The list of unique categories.\n    \"\"\"\n\n    unique_categories: list[str]", "blocks": [{"id": 1, "label": "class CategoriesResponse(pydantic.BaseModel):\n \"\"\"\n Represents the response data for a list of categories.\n\n Attributes:\n unique_categories (list[str]): The list of unique categories.\n \"\"\"\n\n unique_categories: list[str]", "successors": []}]}, {"name": "ListResponse", "type": "class", "start_line": 145, "end_line": 161, "functions": [], "simplified_code": "class ListResponse(pydantic.BaseModel, Generic[T]):\n    \"\"\"\n    Represents a list response.\n\n    Attributes:\n        items (list[T]): The list of items.\n        total_count (int): The total count of items.\n        page (int): The current page number.\n        page_size (int): The number of items per page.\n        total_pages (int): The total number of pages.\n    \"\"\"\n\n    items: list[T]\n    total_count: int\n    page: int\n    page_size: int\n    total_pages: int", "blocks": [{"id": 1, "label": "class ListResponse(pydantic.BaseModel, Generic[T]):\n    \"\"\"\n    Represents a list response.\n\n    Attributes:\n        items (list[T]): The list of items.\n        total_count (int): The total count of items.\n        page (int): The current page number.\n        page_size (int): The number of items per page.\n        total_pages (int): The total number of pages.\n    \"\"\"", "successors": [{"id": 3, "label": "    items: list[T]\n    total_count: int", "successors": [{"id": 5, "label": "    page: int\n    page_size: int", "successors": [{"id": 7, "label": "    total_pages: int", "successors": []}]}]}]}]}], "simplified_code": "import datetime\nimport typing\nfrom enum import Enum\nfrom typing import Generic, Literal, TypeVar, Union\n\nimport prisma.enums\nimport pydantic\n\n\n    CLOUD = \"cloud\"\n\n\n    installation_location: InstallationLocation\n\n\n    installation_location: InstallationLocation\n\n\n    event_data: AgentInstalledFromMarketplaceEventData\n\n\n    event_data: AgentInstalledFromTemplateEventData\n\n\nAnalyticsEvent = Union[\n    AgentInstalledFromMarketplaceEvent, AgentInstalledFromTemplateEvent\n]\n\n\n    event: AnalyticsEvent\n\n\n    categories: list[str]\n\n\n    comments: str | None\n\n\n    downloads: int = 0\n\n\n    graph: dict[str, typing.Any]\n\n\n    isActive: bool\n\n\n    unique_categories: list[str]\n\n\nT = TypeVar(\"T\")\n\n\n    total_pages: int", "blocks": [{"id": 1, "label": "import datetime\nimport typing\nfrom enum import Enum\nfrom typing import Generic, Literal, TypeVar, Union\n\nimport prisma.enums\nimport pydantic", "successors": []}]}
{"file_name": "161.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 264, "functions": [], "classes": [{"name": "SamplingMethod", "type": "class", "start_line": 10, "end_line": 18, "functions": [], "classes": [], "simplified_code": "class SamplingMethod(str, Enum):\n    RANDOM = \"random\"\n    SYSTEMATIC = \"systematic\"\n    TOP = \"top\"\n    BOTTOM = \"bottom\"\n    STRATIFIED = \"stratified\"\n    WEIGHTED = \"weighted\"\n    RESERVOIR = \"reservoir\"\n    CLUSTER = \"cluster\"", "blocks": [{"id": 1, "label": "class SamplingMethod(str, Enum):\n    RANDOM = \"random\"\n    SYSTEMATIC = \"systematic\"\n    TOP = \"top\"\n    BOTTOM = \"bottom\"\n    STRATIFIED = \"stratified\"\n    WEIGHTED = \"weighted\"\n    RESERVOIR = \"reservoir\"\n    CLUSTER = \"cluster\"", "successors": []}]}, {"name": "DataSamplingBlock", "type": "class", "start_line": 21, "end_line": 264, "functions": [{"name": "__init__", "type": "function", "start_line": 65, "end_line": 94, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"4a448883-71fa-49cf-91cf-70d793bd7d87\",\n            description=\"This block samples data from a given dataset using various sampling methods.\",\n            categories={BlockCategory.LOGIC},\n            input_schema=DataSamplingBlock.Input,\n            output_schema=DataSamplingBlock.Output,\n            test_input={\n                \"data\": [\n                    {\"id\": i, \"value\": chr(97 + i), \"group\": i % 3} for i in range(10)\n                ],\n                \"sample_size\": 3,\n                \"sampling_method\": SamplingMethod.STRATIFIED,\n                \"accumulate\": False,\n                \"random_seed\": 42,\n                \"stratify_key\": \"group\",\n            },\n            test_output=[\n                (\n                    \"sampled_data\",\n                    [\n                        {\"id\": 0, \"value\": \"a\", \"group\": 0},\n                        {\"id\": 1, \"value\": \"b\", \"group\": 1},\n                        {\"id\": 8, \"value\": \"i\", \"group\": 2},\n                    ],\n                ),\n                (\"sample_indices\", [0, 1, 8]),\n            ],\n        )\n        self.accumulated_data = []", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"4a448883-71fa-49cf-91cf-70d793bd7d87\",\n    description=\"This block samples data from a given dataset using various sampling methods.\",\n    categories={BlockCategory.LOGIC},\n    input_schema=DataSamplingBlock.Input,\n    output_schema=DataSamplingBlock.Output,\n    test_input={\n        \"data\": [\n            {\"id\": i, \"value\": chr(97 + i), \"group\": i % 3} for i in range(10)\n        ],\n        \"sample_size\": 3,\n        \"sampling_method\": SamplingMethod.STRATIFIED,\n        \"accumulate\": False,\n        \"random_seed\": 42,\n        \"stratify_key\": \"group\",\n    },\n    test_output=[\n        (\n            \"sampled_data\",\n            [\n                {\"id\": 0, \"value\": \"a\", \"group\": 0},\n                {\"id\": 1, \"value\": \"b\", \"group\": 1},\n                {\"id\": 8, \"value\": \"i\", \"group\": 2},\n            ],\n        ),\n        (\"sample_indices\", [0, 1, 8]),\n    ],\n)", "successors": [{"id": 3, "label": "self.accumulated_data = []", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 96, "end_line": 264, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        if input_data.accumulate:\n            if isinstance(input_data.data, dict):\n                self.accumulated_data.append(input_data.data)\n            elif isinstance(input_data.data, list):\n                self.accumulated_data.extend(input_data.data)\n            else:\n                raise ValueError(f\"Unsupported data type: {type(input_data.data)}\")\n\n            # If we don't have enough data yet, return without sampling\n            if len(self.accumulated_data) < input_data.sample_size:\n                return\n\n            data_to_sample = self.accumulated_data\n        else:\n            # If not accumulating, use the input data directly\n            data_to_sample = (\n                input_data.data\n                if isinstance(input_data.data, list)\n                else [input_data.data]\n            )\n\n        if input_data.random_seed is not None:\n            random.seed(input_data.random_seed)\n\n        data_size = len(data_to_sample)\n\n        if input_data.sample_size > data_size:\n            raise ValueError(\n                f\"Sample size ({input_data.sample_size}) cannot be larger than the dataset size ({data_size}).\"\n            )\n\n        indices = []\n\n        if input_data.sampling_method == SamplingMethod.RANDOM:\n            indices = random.sample(range(data_size), input_data.sample_size)\n        elif input_data.sampling_method == SamplingMethod.SYSTEMATIC:\n            step = data_size // input_data.sample_size\n            start = random.randint(0, step - 1)\n            indices = list(range(start, data_size, step))[: input_data.sample_size]\n        elif input_data.sampling_method == SamplingMethod.TOP:\n            indices = list(range(input_data.sample_size))\n        elif input_data.sampling_method == SamplingMethod.BOTTOM:\n            indices = list(range(data_size - input_data.sample_size, data_size))\n        elif input_data.sampling_method == SamplingMethod.STRATIFIED:\n            if not input_data.stratify_key:\n                raise ValueError(\n                    \"Stratify key must be provided for stratified sampling.\"\n                )\n            strata = defaultdict(list)\n            for i, item in enumerate(data_to_sample):\n                if isinstance(item, dict):\n                    strata_value = item.get(input_data.stratify_key)\n                elif hasattr(item, input_data.stratify_key):\n                    strata_value = getattr(item, input_data.stratify_key)\n                else:\n                    raise ValueError(\n                        f\"Stratify key '{input_data.stratify_key}' not found in item {item}\"\n                    )\n\n                if strata_value is None:\n                    raise ValueError(\n                        f\"Stratify value for key '{input_data.stratify_key}' is None\"\n                    )\n\n                strata[str(strata_value)].append(i)\n\n            # Calculate the number of samples to take from each stratum\n            stratum_sizes = {\n                k: max(1, int(len(v) / data_size * input_data.sample_size))\n                for k, v in strata.items()\n            }\n\n            # Adjust sizes to ensure we get exactly sample_size samples\n            while sum(stratum_sizes.values()) != input_data.sample_size:\n                if sum(stratum_sizes.values()) < input_data.sample_size:\n                    stratum_sizes[\n                        max(stratum_sizes, key=lambda k: stratum_sizes[k])\n                    ] += 1\n                else:\n                    stratum_sizes[\n                        max(stratum_sizes, key=lambda k: stratum_sizes[k])\n                    ] -= 1\n\n            for stratum, size in stratum_sizes.items():\n                indices.extend(random.sample(strata[stratum], size))\n        elif input_data.sampling_method == SamplingMethod.WEIGHTED:\n            if not input_data.weight_key:\n                raise ValueError(\"Weight key must be provided for weighted sampling.\")\n            weights = []\n            for item in data_to_sample:\n                if isinstance(item, dict):\n                    weight = item.get(input_data.weight_key)\n                elif hasattr(item, input_data.weight_key):\n                    weight = getattr(item, input_data.weight_key)\n                else:\n                    raise ValueError(\n                        f\"Weight key '{input_data.weight_key}' not found in item {item}\"\n                    )\n\n                if weight is None:\n                    raise ValueError(\n                        f\"Weight value for key '{input_data.weight_key}' is None\"\n                    )\n                try:\n                    weights.append(float(weight))\n                except ValueError:\n                    raise ValueError(\n                        f\"Weight value '{weight}' cannot be converted to a number\"\n                    )\n\n            if not weights:\n                raise ValueError(\n                    f\"No valid weights found using key '{input_data.weight_key}'\"\n                )\n\n            indices = random.choices(\n                range(data_size), weights=weights, k=input_data.sample_size\n            )\n        elif input_data.sampling_method == SamplingMethod.RESERVOIR:\n            indices = list(range(input_data.sample_size))\n            for i in range(input_data.sample_size, data_size):\n                j = random.randint(0, i)\n                if j < input_data.sample_size:\n                    indices[j] = i\n        elif input_data.sampling_method == SamplingMethod.CLUSTER:\n            if not input_data.cluster_key:\n                raise ValueError(\"Cluster key must be provided for cluster sampling.\")\n            clusters = defaultdict(list)\n            for i, item in enumerate(data_to_sample):\n                if isinstance(item, dict):\n                    cluster_value = item.get(input_data.cluster_key)\n                elif hasattr(item, input_data.cluster_key):\n                    cluster_value = getattr(item, input_data.cluster_key)\n                else:\n                    raise TypeError(\n                        f\"Item {item} does not have the cluster key '{input_data.cluster_key}'\"\n                    )\n\n                clusters[str(cluster_value)].append(i)\n\n            # Randomly select clusters until we have enough samples\n            selected_clusters = []\n            while (\n                sum(len(clusters[c]) for c in selected_clusters)\n                < input_data.sample_size\n            ):\n                available_clusters = [c for c in clusters if c not in selected_clusters]\n                if not available_clusters:\n                    break\n                selected_clusters.append(random.choice(available_clusters))\n\n            for cluster in selected_clusters:\n                indices.extend(clusters[cluster])\n\n            # If we have more samples than needed, randomly remove some\n            if len(indices) > input_data.sample_size:\n                indices = random.sample(indices, input_data.sample_size)\n        else:\n            raise ValueError(f\"Unknown sampling method: {input_data.sampling_method}\")\n\n        sampled_data = [data_to_sample[i] for i in indices]\n\n        # Clear accumulated data after sampling if accumulation is enabled\n        if input_data.accumulate:\n            self.accumulated_data = []\n\n        yield \"sampled_data\", sampled_data\n        yield \"sample_indices\", indices", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:", "successors": [{"id": 2, "label": "if input_data.accumulate:", "successors": [{"id": 3, "label": "if isinstance(input_data.data, dict):\n    self.accumulated_data.append(input_data.data)", "successors": []}, {"id": 4, "label": "elif isinstance(input_data.data, list):\n    self.accumulated_data.extend(input_data.data)", "successors": []}, {"id": 5, "label": "else:\n    raise ValueError(f\"Unsupported data type: {type(input_data.data)}\")", "successors": []}, {"id": 6, "label": "if len(self.accumulated_data) < input_data.sample_size:\n    return", "successors": []}, {"id": 7, "label": "data_to_sample = self.accumulated_data", "successors": []}]}, {"id": 8, "label": "else:\n    data_to_sample = (input_data.data if isinstance(input_data.data, list) else [input_data.data])", "successors": []}, {"id": 9, "label": "if input_data.random_seed is not None:\n    random.seed(input_data.random_seed)", "successors": []}, {"id": 10, "label": "data_size = len(data_to_sample)", "successors": []}, {"id": 11, "label": "if input_data.sample_size > data_size:\n    raise ValueError(f\"Sample size ({input_data.sample_size}) cannot be larger than the dataset size ({data_size}).\")", "successors": []}, {"id": 12, "label": "indices = []", "successors": []}, {"id": 13, "label": "if input_data.sampling_method == SamplingMethod.RANDOM:\n    indices = random.sample(range(data_size), input_data.sample_size)", "successors": []}, {"id": 14, "label": "elif input_data.sampling_method == SamplingMethod.SYSTEMATIC:\n    step = data_size // input_data.sample_size\n    start = random.randint(0, step - 1)\n    indices = list(range(start, data_size, step))[: input_data.sample_size]", "successors": []}, {"id": 15, "label": "elif input_data.sampling_method == SamplingMethod.TOP:\n    indices = list(range(input_data.sample_size))", "successors": []}, {"id": 16, "label": "elif input_data.sampling_method == SamplingMethod.BOTTOM:\n    indices = list(range(data_size - input_data.sample_size, data_size))", "successors": []}, {"id": 17, "label": "elif input_data.sampling_method == SamplingMethod.STRATIFIED:", "successors": [{"id": 18, "label": "if not input_data.stratify_key:\n    raise ValueError(\"Stratify key must be provided for stratified sampling.\")", "successors": []}, {"id": 19, "label": "strata = defaultdict(list)", "successors": []}, {"id": 20, "label": "for i, item in enumerate(data_to_sample):", "successors": [{"id": 21, "label": "if isinstance(item, dict):\n    strata_value = item.get(input_data.stratify_key)", "successors": []}, {"id": 22, "label": "elif hasattr(item, input_data.stratify_key):\n    strata_value = getattr(item, input_data.stratify_key)", "successors": []}, {"id": 23, "label": "else:\n    raise ValueError(f\"Stratify key '{input_data.stratify_key}' not found in item {item}\")", "successors": []}]}, {"id": 24, "label": "if strata_value is None:\n    raise ValueError(f\"Stratify value for key '{input_data.stratify_key}' is None\")", "successors": []}, {"id": 25, "label": "strata[str(strata_value)].append(i)", "successors": []}, {"id": 26, "label": "stratum_sizes = {k: max(1, int(len(v) / data_size * input_data.sample_size)) for k, v in strata.items()}", "successors": []}, {"id": 27, "label": "while sum(stratum_sizes.values()) != input_data.sample_size:", "successors": [{"id": 28, "label": "if sum(stratum_sizes.values()) < input_data.sample_size:\n    stratum_sizes[max(stratum_sizes, key=lambda k: stratum_sizes[k])] += 1", "successors": []}, {"id": 29, "label": "else:\n    stratum_sizes[max(stratum_sizes, key=lambda k: stratum_sizes[k])] -= 1", "successors": []}]}, {"id": 30, "label": "for stratum, size in stratum_sizes.items():\n    indices.extend(random.sample(strata[stratum], size))", "successors": []}]}, {"id": 31, "label": "elif input_data.sampling_method == SamplingMethod.WEIGHTED:", "successors": [{"id": 32, "label": "if not input_data.weight_key:\n    raise ValueError(\"Weight key must be provided for weighted sampling.\")", "successors": []}, {"id": 33, "label": "weights = []", "successors": []}, {"id": 34, "label": "for item in data_to_sample:", "successors": [{"id": 35, "label": "if isinstance(item, dict):\n    weight = item.get(input_data.weight_key)", "successors": []}, {"id": 36, "label": "elif hasattr(item, input_data.weight_key):\n    weight = getattr(item, input_data.weight_key)", "successors": []}, {"id": 37, "label": "else:\n    raise ValueError(f\"Weight key '{input_data.weight_key}' not found in item {item}\")", "successors": []}]}, {"id": 38, "label": "if weight is None:\n    raise ValueError(f\"Weight value for key '{input_data.weight_key}' is None\")", "successors": []}, {"id": 39, "label": "try:\n    weights.append(float(weight))\nexcept ValueError:\n    raise ValueError(f\"Weight value '{weight}' cannot be converted to a number\")", "successors": []}, {"id": 41, "label": "if not weights:\n    raise ValueError(f\"No valid weights found using key '{input_data.weight_key}'\")", "successors": []}, {"id": 42, "label": "indices = random.choices(range(data_size), weights=weights, k=input_data.sample_size)", "successors": []}]}, {"id": 43, "label": "elif input_data.sampling_method == SamplingMethod.RESERVOIR:", "successors": [{"id": 44, "label": "indices = list(range(input_data.sample_size))", "successors": []}, {"id": 45, "label": "for i in range(input_data.sample_size, data_size):\n    j = random.randint(0, i)\n    if j < input_data.sample_size:\n        indices[j] = i", "successors": []}]}, {"id": 46, "label": "elif input_data.sampling_method == SamplingMethod.CLUSTER:", "successors": [{"id": 47, "label": "if not input_data.cluster_key:\n    raise ValueError(\"Cluster key must be provided for cluster sampling.\")", "successors": []}, {"id": 48, "label": "clusters = defaultdict(list)", "successors": []}, {"id": 49, "label": "for i, item in enumerate(data_to_sample):", "successors": [{"id": 50, "label": "if isinstance(item, dict):\n    cluster_value = item.get(input_data.cluster_key)", "successors": []}, {"id": 51, "label": "elif hasattr(item, input_data.cluster_key):\n    cluster_value = getattr(item, input_data.cluster_key)", "successors": []}, {"id": 52, "label": "else:\n    raise TypeError(f\"Item {item} does not have the cluster key '{input_data.cluster_key}'\")", "successors": []}]}, {"id": 53, "label": "clusters[str(cluster_value)].append(i)", "successors": []}, {"id": 54, "label": "selected_clusters = []", "successors": []}, {"id": 55, "label": "while (sum(len(clusters[c]) for c in selected_clusters) < input_data.sample_size):", "successors": [{"id": 56, "label": "available_clusters = [c for c in clusters if c not in selected_clusters]", "successors": []}, {"id": 57, "label": "if not available_clusters:\n    break", "successors": []}, {"id": 58, "label": "selected_clusters.append(random.choice(available_clusters))", "successors": []}]}, {"id": 59, "label": "for cluster in selected_clusters:\n    indices.extend(clusters[cluster])", "successors": []}, {"id": 60, "label": "if len(indices) > input_data.sample_size:\n    indices = random.sample(indices, input_data.sample_size)", "successors": []}]}, {"id": 61, "label": "else:\n    raise ValueError(f\"Unknown sampling method: {input_data.sampling_method}\")", "successors": []}, {"id": 62, "label": "sampled_data = [data_to_sample[i] for i in indices]", "successors": []}, {"id": 63, "label": "if input_data.accumulate:\n    self.accumulated_data = []", "successors": []}, {"id": 64, "label": "yield \"sampled_data\", sampled_data", "successors": []}, {"id": 65, "label": "yield \"sample_indices\", indices", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 22, "end_line": 55, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        data: Union[Dict[str, Any], List[Union[dict, List[Any]]]] = SchemaField(\n            description=\"The dataset to sample from. Can be a single dictionary, a list of dictionaries, or a list of lists.\",\n            placeholder=\"{'id': 1, 'value': 'a'} or [{'id': 1, 'value': 'a'}, {'id': 2, 'value': 'b'}, ...]\",\n        )\n        sample_size: int = SchemaField(\n            description=\"The number of samples to take from the dataset.\",\n            placeholder=\"10\",\n            default=10,\n        )\n        sampling_method: SamplingMethod = SchemaField(\n            description=\"The method to use for sampling.\",\n            default=SamplingMethod.RANDOM,\n        )\n        accumulate: bool = SchemaField(\n            description=\"Whether to accumulate data before sampling.\",\n            default=False,\n        )\n        random_seed: Optional[int] = SchemaField(\n            description=\"Seed for random number generator (optional).\",\n            default=None,\n        )\n        stratify_key: Optional[str] = SchemaField(\n            description=\"Key to use for stratified sampling (required for stratified sampling).\",\n            default=None,\n        )\n        weight_key: Optional[str] = SchemaField(\n            description=\"Key to use for weighted sampling (required for weighted sampling).\",\n            default=None,\n        )\n        cluster_key: Optional[str] = SchemaField(\n            description=\"Key to use for cluster sampling (required for cluster sampling).\",\n            default=None,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\ndata: Union[Dict[str, Any], List[Union[dict, List[Any]]]] = SchemaField(description=\"The dataset to sample from. Can be a single dictionary, a list of dictionaries, or a list of lists.\", placeholder=\"{'id': 1, 'value': 'a'} or [{'id': 1, 'value': 'a'}, {'id': 2, 'value': 'b'}, ...]\")", "successors": [{"id": 3, "label": "sample_size: int = SchemaField(description=\"The number of samples to take from the dataset.\", placeholder=\"10\", default=10)\nsampling_method: SamplingMethod = SchemaField(description=\"The method to use for sampling.\", default=SamplingMethod.RANDOM)", "successors": [{"id": 5, "label": "accumulate: bool = SchemaField(description=\"Whether to accumulate data before sampling.\", default=False)\nrandom_seed: Optional[int] = SchemaField(description=\"Seed for random number generator (optional).\", default=None)", "successors": [{"id": 7, "label": "stratify_key: Optional[str] = SchemaField(description=\"Key to use for stratified sampling (required for stratified sampling).\", default=None)\nweight_key: Optional[str] = SchemaField(description=\"Key to use for weighted sampling (required for weighted sampling).\", default=None)", "successors": [{"id": 9, "label": "cluster_key: Optional[str] = SchemaField(description=\"Key to use for cluster sampling (required for cluster sampling).\", default=None)", "successors": []}]}]}]}]}]}, {"name": "Output", "type": "class", "start_line": 57, "end_line": 63, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        sampled_data: List[Union[dict, List[Any]]] = SchemaField(\n            description=\"The sampled subset of the input data.\"\n        )\n        sample_indices: List[int] = SchemaField(\n            description=\"The indices of the sampled data in the original dataset.\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    sampled_data: List[Union[dict, List[Any]]] = SchemaField(\n        description=\"The sampled subset of the input data.\"\n    )", "successors": [{"id": 3, "label": "    sample_indices: List[int] = SchemaField(\n        description=\"The indices of the sampled data in the original dataset.\"\n    )", "successors": []}]}]}], "simplified_code": "class DataSamplingBlock(Block):\n        )\n\n        )\n\n        self.accumulated_data = []\n\n        yield \"sample_indices\", indices", "blocks": [{"id": 1, "label": "class DataSamplingBlock(Block):\n    pass", "successors": []}]}], "simplified_code": "import random\nfrom collections import defaultdict\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Union\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\n\n    CLUSTER = \"cluster\"\n\n\n        yield \"sample_indices\", indices", "blocks": [{"id": 1, "label": "import random\nfrom collections import defaultdict\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Union\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField", "successors": []}]}
{"file_name": "162.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 122, "functions": [], "classes": [{"name": "Rank", "type": "class", "start_line": 6, "end_line": 10, "functions": [], "simplified_code": "class Rank(Enum):\n\n    OPERATOR = 0\n    SUPERVISOR = 1\n    DIRECTOR = 2", "blocks": [{"id": 1, "label": "class Rank(Enum):", "successors": [{"id": 2, "label": "    OPERATOR = 0", "successors": []}, {"id": 3, "label": "    SUPERVISOR = 1", "successors": []}, {"id": 4, "label": "    DIRECTOR = 2", "successors": []}]}]}, {"name": "Employee", "type": "class", "start_line": 13, "end_line": 40, "functions": [{"name": "__init__", "type": "function", "start_line": 15, "end_line": 20, "functions": [], "classes": [], "simplified_code": "    def __init__(self, employee_id, name, rank, call_center):\n        self.employee_id = employee_id\n        self.name = name\n        self.rank = rank\n        self.call = None\n        self.call_center = call_center", "blocks": [{"id": 1, "label": "def __init__(self, employee_id, name, rank, call_center):\nself.employee_id = employee_id\nself.name = name\nself.rank = rank\nself.call = None\nself.call_center = call_center", "successors": []}]}, {"name": "take_call", "type": "function", "start_line": 22, "end_line": 26, "functions": [], "classes": [], "simplified_code": "    def take_call(self, call):\n        \"\"\"Assume the employee will always successfully take the call.\"\"\"\n        self.call = call\n        self.call.employee = self\n        self.call.state = CallState.IN_PROGRESS", "blocks": [{"id": 1, "label": "def take_call(self, call):\n\"\"\"Assume the employee will always successfully take the call.\"\"\"", "successors": [{"id": 3, "label": "self.call = call\nself.call.employee = self\nself.call.state = CallState.IN_PROGRESS", "successors": []}]}]}, {"name": "complete_call", "type": "function", "start_line": 28, "end_line": 30, "functions": [], "classes": [], "simplified_code": "    def complete_call(self):\n        self.call.state = CallState.COMPLETE\n        self.call_center.notify_call_completed(self.call)", "blocks": [{"id": 1, "label": "def complete_call(self):\nself.call.state = CallState.COMPLETE", "successors": [{"id": 3, "label": "self.call_center.notify_call_completed(self.call)", "successors": []}]}]}, {"name": "escalate_call", "type": "function", "start_line": 33, "end_line": 34, "functions": [], "classes": [], "simplified_code": "    def escalate_call(self):\n        pass", "blocks": [{"id": 1, "label": "def escalate_call(self):\npass", "successors": []}]}, {"name": "_escalate_call", "type": "function", "start_line": 36, "end_line": 40, "functions": [], "classes": [], "simplified_code": "    def _escalate_call(self):\n        self.call.state = CallState.READY\n        call = self.call\n        self.call = None\n        self.call_center.notify_call_escalated(call)", "blocks": [{"id": 1, "label": "def _escalate_call(self):\nself.call.state = CallState.READY\ncall = self.call\nself.call = None\nself.call_center.notify_call_escalated(call)", "successors": []}]}], "simplified_code": "class Employee(metaclass=ABCMeta):\n\n        self.call_center = call_center\n\n        self.call.state = CallState.IN_PROGRESS\n\n        self.call_center.notify_call_completed(self.call)\n\n    @abstractmethod\n        pass\n\n        self.call_center.notify_call_escalated(call)", "blocks": [{"id": 1, "label": "class Employee(metaclass=ABCMeta):", "successors": [{"id": 2, "label": "self.call_center = call_center\nself.call.state = CallState.IN_PROGRESS", "successors": [{"id": 4, "label": "self.call_center.notify_call_completed(self.call)", "successors": []}]}, {"id": 5, "label": "@abstractmethod\npass", "successors": [{"id": 7, "label": "self.call_center.notify_call_escalated(call)", "successors": []}]}]}]}, {"name": "Operator", "type": "class", "start_line": 43, "end_line": 50, "functions": [{"name": "__init__", "type": "function", "start_line": 45, "end_line": 46, "functions": [], "classes": [], "simplified_code": "    def __init__(self, employee_id, name):\n        super(Operator, self).__init__(employee_id, name, Rank.OPERATOR)", "blocks": [{"id": 1, "label": "def __init__(self, employee_id, name):\n    super(Operator, self).__init__(employee_id, name, Rank.OPERATOR)", "successors": []}]}, {"name": "escalate_call", "type": "function", "start_line": 48, "end_line": 50, "functions": [], "classes": [], "simplified_code": "    def escalate_call(self):\n        self.call.level = Rank.SUPERVISOR\n        self._escalate_call()", "blocks": [{"id": 1, "label": "def escalate_call(self):\nself.call.level = Rank.SUPERVISOR\nself._escalate_call()", "successors": []}]}], "simplified_code": "class Operator(Employee):\n\n        super(Operator, self).__init__(employee_id, name, Rank.OPERATOR)\n\n        self._escalate_call()", "blocks": [{"id": 1, "label": "class Operator(Employee):\nsuper(Operator, self).__init__(employee_id, name, Rank.OPERATOR)", "successors": [{"id": 3, "label": "self._escalate_call()", "successors": []}]}]}, {"name": "Supervisor", "type": "class", "start_line": 53, "end_line": 60, "functions": [{"name": "__init__", "type": "function", "start_line": 55, "end_line": 56, "functions": [], "classes": [], "simplified_code": "    def __init__(self, employee_id, name):\n        super(Operator, self).__init__(employee_id, name, Rank.SUPERVISOR)", "blocks": [{"id": 1, "label": "def __init__(self, employee_id, name):\n    super(Operator, self).__init__(employee_id, name, Rank.SUPERVISOR)", "successors": []}]}, {"name": "escalate_call", "type": "function", "start_line": 58, "end_line": 60, "functions": [], "classes": [], "simplified_code": "    def escalate_call(self):\n        self.call.level = Rank.DIRECTOR\n        self._escalate_call()", "blocks": [{"id": 1, "label": "def escalate_call(self):\nself.call.level = Rank.DIRECTOR", "successors": [{"id": 3, "label": "self._escalate_call()", "successors": []}]}]}], "simplified_code": "class Supervisor(Employee):\n\n        super(Operator, self).__init__(employee_id, name, Rank.SUPERVISOR)\n\n        self._escalate_call()", "blocks": [{"id": 1, "label": "class Supervisor(Employee):\nsuper(Operator, self).__init__(employee_id, name, Rank.SUPERVISOR)", "successors": [{"id": 3, "label": "self._escalate_call()", "successors": []}]}]}, {"name": "Director", "type": "class", "start_line": 63, "end_line": 69, "functions": [{"name": "__init__", "type": "function", "start_line": 65, "end_line": 66, "functions": [], "classes": [], "simplified_code": "    def __init__(self, employee_id, name):\n        super(Operator, self).__init__(employee_id, name, Rank.DIRECTOR)", "blocks": [{"id": 1, "label": "def __init__(self, employee_id, name):\nsuper(Operator, self).__init__(employee_id, name, Rank.DIRECTOR)", "successors": []}]}, {"name": "escalate_call", "type": "function", "start_line": 68, "end_line": 69, "functions": [], "classes": [], "simplified_code": "    def escalate_call(self):\n        raise NotImplementedError('Directors must be able to handle any call')", "blocks": [{"id": 1, "label": "def escalate_call(self):\nraise NotImplementedError('Directors must be able to handle any call')", "successors": []}]}], "simplified_code": "class Director(Employee):\n\n        super(Operator, self).__init__(employee_id, name, Rank.DIRECTOR)\n\n        raise NotImplementedError('Directors must be able to handle any call')", "blocks": [{"id": 1, "label": "class Director(Employee):\nsuper(Operator, self).__init__(employee_id, name, Rank.DIRECTOR)", "successors": [{"id": 3, "label": "raise NotImplementedError('Directors must be able to handle any call')", "successors": []}]}]}, {"name": "CallState", "type": "class", "start_line": 72, "end_line": 76, "functions": [], "simplified_code": "class CallState(Enum):\n\n    READY = 0\n    IN_PROGRESS = 1\n    COMPLETE = 2", "blocks": [{"id": 1, "label": "class CallState(Enum):\n    READY = 0\n    IN_PROGRESS = 1\n    COMPLETE = 2", "successors": []}]}, {"name": "Call", "type": "class", "start_line": 79, "end_line": 84, "functions": [{"name": "__init__", "type": "function", "start_line": 81, "end_line": 83, "functions": [], "classes": [], "simplified_code": "    def __init__(self, rank):\n        self.state = CallState.READY\n        self.rank = rank", "blocks": [{"id": 1, "label": "def __init__(self, rank):\n    self.state = CallState.READY\n    self.rank = rank", "successors": []}]}], "simplified_code": "class Call(object):\n\n        self.rank = rank\n        self.employee = None", "blocks": [{"id": 1, "label": "class Call(object):", "successors": [{"id": 2, "label": "self.rank = rank", "successors": []}, {"id": 3, "label": "self.employee = None", "successors": []}]}]}, {"name": "CallCenter", "type": "class", "start_line": 87, "end_line": 122, "functions": [{"name": "__init__", "type": "function", "start_line": 89, "end_line": 93, "functions": [], "classes": [], "simplified_code": "    def __init__(self, operators, supervisors, directors):\n        self.operators = operators\n        self.supervisors = supervisors\n        self.directors = directors\n        self.queued_calls = deque()", "blocks": [{"id": 1, "label": "def __init__(self, operators, supervisors, directors):\nself.operators = operators\nself.supervisors = supervisors\nself.directors = directors\nself.queued_calls = deque()", "successors": []}]}, {"name": "dispatch_call", "type": "function", "start_line": 95, "end_line": 106, "functions": [], "classes": [], "simplified_code": "    def dispatch_call(self, call):\n        if call.rank not in (Rank.OPERATOR, Rank.SUPERVISOR, Rank.DIRECTOR):\n            raise ValueError('Invalid call rank: {}'.format(call.rank))\n        employee = None\n        if call.rank == Rank.OPERATOR:\n            employee = self._dispatch_call(call, self.operators)\n        if call.rank == Rank.SUPERVISOR or employee is None:\n            employee = self._dispatch_call(call, self.supervisors)\n        if call.rank == Rank.DIRECTOR or employee is None:\n            employee = self._dispatch_call(call, self.directors)\n        if employee is None:\n            self.queued_calls.append(call)", "blocks": [{"id": 1, "label": "def dispatch_call(self, call):", "successors": [{"id": 2, "label": "if call.rank not in (Rank.OPERATOR, Rank.SUPERVISOR, Rank.DIRECTOR):\nraise ValueError('Invalid call rank: {}'.format(call.rank))", "successors": []}, {"id": 4, "label": "employee = None", "successors": [{"id": 5, "label": "if call.rank == Rank.OPERATOR:\nemployee = self._dispatch_call(call, self.operators)", "successors": []}, {"id": 7, "label": "if call.rank == Rank.SUPERVISOR or employee is None:\nemployee = self._dispatch_call(call, self.supervisors)", "successors": []}, {"id": 9, "label": "if call.rank == Rank.DIRECTOR or employee is None:\nemployee = self._dispatch_call(call, self.directors)", "successors": []}, {"id": 11, "label": "if employee is None:\nself.queued_calls.append(call)", "successors": []}]}]}]}, {"name": "_dispatch_call", "type": "function", "start_line": 108, "end_line": 113, "functions": [], "classes": [], "simplified_code": "    def _dispatch_call(self, call, employees):\n        for employee in employees:\n            if employee.call is None:\n                employee.take_call(call)\n                return employee\n        return None", "blocks": [{"id": 1, "label": "def _dispatch_call(self, call, employees):", "successors": [{"id": 2, "label": "for employee in employees:", "successors": [{"id": 3, "label": "if employee.call is None:\nemployee.take_call(call)", "successors": [{"id": 5, "label": "return employee", "successors": []}]}, {"id": 6, "label": "return None", "successors": []}]}]}]}, {"name": "notify_call_escalated", "type": "function", "start_line": 115, "end_line": 116, "functions": [], "classes": [], "simplified_code": "    def notify_call_escalated(self, call):\n        pass", "blocks": [{"id": 1, "label": "def notify_call_escalated(self, call):\n    pass", "successors": []}]}, {"name": "notify_call_completed", "type": "function", "start_line": 118, "end_line": 119, "functions": [], "classes": [], "simplified_code": "    def notify_call_completed(self, call):\n        pass", "blocks": [{"id": 1, "label": "def notify_call_completed(self, call):\n    pass", "successors": []}]}, {"name": "dispatch_queued_call_to_newly_freed_employee", "type": "function", "start_line": 121, "end_line": 122, "functions": [], "classes": [], "simplified_code": "    def dispatch_queued_call_to_newly_freed_employee(self, call, employee):\n        pass", "blocks": [{"id": 1, "label": "def dispatch_queued_call_to_newly_freed_employee(self, call, employee):\npass", "successors": []}]}], "simplified_code": "class CallCenter(object):\n\n        self.queued_calls = deque()\n\n            self.queued_calls.append(call)\n\n        return None\n\n        pass\n\n        pass\n\n        pass", "blocks": [{"id": 1, "label": "class CallCenter(object):\nself.queued_calls = deque()", "successors": [{"id": 3, "label": "self.queued_calls.append(call)", "successors": [{"id": 4, "label": "return None", "successors": []}, {"id": 5, "label": "pass", "successors": []}, {"id": 6, "label": "pass", "successors": []}, {"id": 7, "label": "pass", "successors": []}]}]}]}], "simplified_code": "from abc import ABCMeta, abstractmethod\nfrom collections import deque\nfrom enum import Enum\n\n\n    DIRECTOR = 2\n\n\n        self.call_center.notify_call_escalated(call)\n\n\n        self._escalate_call()\n\n\n        self._escalate_call()\n\n\n        raise NotImplementedError('Directors must be able to handle any call')\n\n\n    COMPLETE = 2\n\n\n        self.employee = None\n\n\n        pass", "blocks": [{"id": 1, "label": "from abc import ABCMeta, abstractmethod\nfrom collections import deque\nfrom enum import Enum", "successors": [{"id": 2, "label": "DIRECTOR = 2\nself.call_center.notify_call_escalated(call)", "successors": [{"id": 4, "label": "self._escalate_call()\nself._escalate_call()", "successors": [{"id": 6, "label": "raise NotImplementedError('Directors must be able to handle any call')", "successors": []}]}]}, {"id": 7, "label": "COMPLETE = 2\nself.employee = None", "successors": [{"id": 9, "label": "pass", "successors": []}]}]}]}
{"file_name": "163.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 73, "functions": [], "classes": [{"name": "PagesDataStore", "type": "class", "start_line": 4, "end_line": 32, "functions": [{"name": "__init__", "type": "function", "start_line": 6, "end_line": 8, "functions": [], "classes": [], "simplified_code": "    def __init__(self, db):\n        self.db = db\n        pass", "blocks": [{"id": 1, "label": "def __init__(self, db):\n    self.db = db\n    pass", "successors": []}]}, {"name": "add_link_to_crawl", "type": "function", "start_line": 10, "end_line": 12, "functions": [], "classes": [], "simplified_code": "    def add_link_to_crawl(self, url):\n        \"\"\"Add the given link to `links_to_crawl`.\"\"\"\n        pass", "blocks": [{"id": 1, "label": "def add_link_to_crawl(self, url):\n\"\"\"Add the given link to `links_to_crawl`.\"\"\"", "successors": [{"id": 3, "label": "pass", "successors": []}]}]}, {"name": "remove_link_to_crawl", "type": "function", "start_line": 14, "end_line": 16, "functions": [], "classes": [], "simplified_code": "    def remove_link_to_crawl(self, url):\n        \"\"\"Remove the given link from `links_to_crawl`.\"\"\"\n        pass", "blocks": [{"id": 1, "label": "def remove_link_to_crawl(self, url):\n\"\"\"Remove the given link from `links_to_crawl`.\"\"\"\npass", "successors": []}]}, {"name": "reduce_priority_link_to_crawl", "type": "function", "start_line": 18, "end_line": 20, "functions": [], "classes": [], "simplified_code": "    def reduce_priority_link_to_crawl(self, url):\n        \"\"\"Reduce the priority of a link in `links_to_crawl` to avoid cycles.\"\"\"\n        pass", "blocks": [{"id": 1, "label": "def reduce_priority_link_to_crawl(self, url):\n\"\"\"Reduce the priority of a link in `links_to_crawl` to avoid cycles.\"\"\"", "successors": [{"id": 3, "label": "pass", "successors": []}]}]}, {"name": "extract_max_priority_page", "type": "function", "start_line": 22, "end_line": 24, "functions": [], "classes": [], "simplified_code": "    def extract_max_priority_page(self):\n        \"\"\"Return the highest priority link in `links_to_crawl`.\"\"\"\n        pass", "blocks": [{"id": 1, "label": "def extract_max_priority_page(self):\n\"\"\"Return the highest priority link in `links_to_crawl`.\"\"\"", "successors": [{"id": 3, "label": "pass", "successors": []}]}]}, {"name": "insert_crawled_link", "type": "function", "start_line": 26, "end_line": 28, "functions": [], "classes": [], "simplified_code": "    def insert_crawled_link(self, url, signature):\n        \"\"\"Add the given link to `crawled_links`.\"\"\"\n        pass", "blocks": [{"id": 1, "label": "def insert_crawled_link(self, url, signature):\n\"\"\"Add the given link to `crawled_links`.\"\"\"", "successors": [{"id": 3, "label": "pass", "successors": []}]}]}, {"name": "crawled_similar", "type": "function", "start_line": 30, "end_line": 32, "functions": [], "classes": [], "simplified_code": "    def crawled_similar(self, signature):\n        \"\"\"Determine if we've already crawled a page matching the given signature\"\"\"\n        pass", "blocks": [{"id": 1, "label": "def crawled_similar(self, signature):\n\"\"\"Determine if we've already crawled a page matching the given signature\"\"\"", "successors": [{"id": 3, "label": "pass", "successors": []}]}]}], "simplified_code": "class PagesDataStore(object):\n\n        pass\n\n        pass\n\n        pass\n\n        pass\n\n        pass\n\n        pass\n\n        pass", "blocks": [{"id": 1, "label": "class PagesDataStore(object):\n    pass", "successors": [{"id": 3, "label": "    pass\n    pass", "successors": [{"id": 5, "label": "    pass\n    pass", "successors": [{"id": 7, "label": "    pass", "successors": []}]}]}]}]}, {"name": "Page", "type": "class", "start_line": 35, "end_line": 45, "functions": [{"name": "__init__", "type": "function", "start_line": 37, "end_line": 41, "functions": [], "classes": [], "simplified_code": "    def __init__(self, url, contents, child_urls):\n        self.url = url\n        self.contents = contents\n        self.child_urls = child_urls\n        self.signature = self.create_signature()", "blocks": [{"id": 1, "label": "def __init__(self, url, contents, child_urls):\n    self.url = url\n    self.contents = contents\n    self.child_urls = child_urls\n    self.signature = self.create_signature()", "successors": []}]}, {"name": "create_signature", "type": "function", "start_line": 43, "end_line": 45, "functions": [], "classes": [], "simplified_code": "    def create_signature(self):\n        # Create signature based on url and contents\n        pass", "blocks": [{"id": 1, "label": "def create_signature(self):\n# Create signature based on url and contents\npass", "successors": []}]}], "simplified_code": "class Page(object):\n\n        self.signature = self.create_signature()\n\n        pass", "blocks": [{"id": 1, "label": "class Page(object):\nself.signature = self.create_signature()", "successors": [{"id": 3, "label": "pass", "successors": []}]}]}, {"name": "Crawler", "type": "class", "start_line": 48, "end_line": 73, "functions": [{"name": "__init__", "type": "function", "start_line": 50, "end_line": 54, "functions": [], "classes": [], "simplified_code": "    def __init__(self, pages, data_store, reverse_index_queue, doc_index_queue):\n        self.pages = pages\n        self.data_store = data_store\n        self.reverse_index_queue = reverse_index_queue\n        self.doc_index_queue = doc_index_queue", "blocks": [{"id": 1, "label": "def __init__(self, pages, data_store, reverse_index_queue, doc_index_queue):\n    self.pages = pages\n    self.data_store = data_store\n    self.reverse_index_queue = reverse_index_queue\n    self.doc_index_queue = doc_index_queue", "successors": []}]}, {"name": "crawl_page", "type": "function", "start_line": 56, "end_line": 62, "functions": [], "classes": [], "simplified_code": "    def crawl_page(self, page):\n        for url in page.child_urls:\n            self.data_store.add_link_to_crawl(url)\n        self.reverse_index_queue.generate(page)\n        self.doc_index_queue.generate(page)\n        self.data_store.remove_link_to_crawl(page.url)\n        self.data_store.insert_crawled_link(page.url, page.signature)", "blocks": [{"id": 1, "label": "def crawl_page(self, page):", "successors": [{"id": 2, "label": "for url in page.child_urls:", "successors": [{"id": 3, "label": "    self.data_store.add_link_to_crawl(url)", "successors": [{"id": 2, "label": "for url in page.child_urls:", "successors": []}]}, {"id": 4, "label": "self.reverse_index_queue.generate(page)\nself.doc_index_queue.generate(page)", "successors": [{"id": 6, "label": "self.data_store.remove_link_to_crawl(page.url)\nself.data_store.insert_crawled_link(page.url, page.signature)", "successors": []}]}]}]}]}, {"name": "crawl", "type": "function", "start_line": 64, "end_line": 73, "functions": [], "classes": [], "simplified_code": "    def crawl(self):\n        while True:\n            page = self.data_store.extract_max_priority_page()\n            if page is None:\n                break\n            if self.data_store.crawled_similar(page.signature):\n                self.data_store.reduce_priority_link_to_crawl(page.url)\n            else:\n                self.crawl_page(page)\n            page = self.data_store.extract_max_priority_page()", "blocks": [{"id": 1, "label": "def crawl(self):", "successors": [{"id": 2, "label": "while True:", "successors": [{"id": 3, "label": "    page = self.data_store.extract_max_priority_page()\nif page is None:", "successors": [{"id": 5, "label": "    break", "successors": []}, {"id": 6, "label": "if self.data_store.crawled_similar(page.signature):", "successors": [{"id": 7, "label": "    self.data_store.reduce_priority_link_to_crawl(page.url)\npage = self.data_store.extract_max_priority_page()", "successors": [{"id": 3, "label": "    page = self.data_store.extract_max_priority_page()", "successors": []}]}, {"id": 8, "label": "    self.crawl_page(page)\npage = self.data_store.extract_max_priority_page()", "successors": [{"id": 3, "label": "    page = self.data_store.extract_max_priority_page()", "successors": []}]}]}]}]}]}]}], "simplified_code": "class Crawler(object):\n\n        self.doc_index_queue = doc_index_queue\n\n        self.data_store.insert_crawled_link(page.url, page.signature)\n\n            page = self.data_store.extract_max_priority_page()", "blocks": [{"id": 1, "label": "class Crawler(object):\n    self.doc_index_queue = doc_index_queue", "successors": [{"id": 3, "label": "    self.data_store.insert_crawled_link(page.url, page.signature)\n    page = self.data_store.extract_max_priority_page()", "successors": []}]}]}], "simplified_code": "# -*- coding: utf-8 -*-\n\n\n        pass\n\n\n        pass\n\n\n            page = self.data_store.extract_max_priority_page()", "blocks": [{"id": 1, "label": "pass\npass", "successors": [{"id": 3, "label": "page = self.data_store.extract_max_priority_page()", "successors": []}]}]}
{"file_name": "164.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 34, "functions": [{"name": "get_highest_set_bit_position", "type": "function", "start_line": 1, "end_line": 28, "functions": [], "classes": [], "simplified_code": "def get_highest_set_bit_position(number: int) -> int:\n    \"\"\"\n    Returns position of the highest set bit of a number.\n    Ref - https://graphics.stanford.edu/~seander/bithacks.html#IntegerLogObvious\n    >>> get_highest_set_bit_position(25)\n    5\n    >>> get_highest_set_bit_position(37)\n    6\n    >>> get_highest_set_bit_position(1)\n    1\n    >>> get_highest_set_bit_position(4)\n    3\n    >>> get_highest_set_bit_position(0)\n    0\n    >>> get_highest_set_bit_position(0.8)\n    Traceback (most recent call last):\n        ...\n    TypeError: Input value must be an 'int' type\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"Input value must be an 'int' type\")\n\n    position = 0\n    while number:\n        position += 1\n        number >>= 1\n\n    return position", "blocks": [{"id": 1, "label": "def get_highest_set_bit_position(number: int) -> int:\nif not isinstance(number, int):", "successors": [{"id": 3, "label": "raise TypeError(\"Input value must be an 'int' type\")", "successors": []}, {"id": 4, "label": "position = 0", "successors": [{"id": 5, "label": "while number:", "successors": [{"id": 6, "label": "position += 1\nnumber >>= 1", "successors": [{"id": 5, "label": "while number:", "successors": []}]}, {"id": 7, "label": "return position", "successors": []}]}]}]}]}], "classes": [], "simplified_code": "    return position\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()", "blocks": [{"id": 1, "label": "return position", "successors": []}]}
{"file_name": "165.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 45, "functions": [{"name": "ld_client", "type": "function", "start_line": 8, "end_line": 12, "functions": [], "classes": [], "simplified_code": "def ld_client(mocker):\n    client = mocker.Mock(spec=LDClient)\n    mocker.patch(\"ldclient.get\", return_value=client)\n    client.is_initialized.return_value = True\n    return client", "blocks": [{"id": 1, "label": "client = mocker.Mock(spec=LDClient)\nmocker.patch(\"ldclient.get\", return_value=client)", "successors": [{"id": 3, "label": "client.is_initialized.return_value = True\nreturn client", "successors": []}]}]}, {"name": "test_feature_flag_enabled", "type": "function", "start_line": 16, "end_line": 25, "functions": [{"name": "test_function", "type": "function", "start_line": 20, "end_line": 21, "functions": [], "classes": [], "simplified_code": "    async def test_function(user_id: str):\n        return \"success\"", "blocks": [{"id": 1, "label": "async def test_function(user_id: str):\n    return \"success\"", "successors": []}]}], "classes": [], "simplified_code": "async def test_feature_flag_enabled(ld_client):\n    ld_client.variation.return_value = True\n\n    @feature_flag(\"test-flag\")\n        return \"success\"\n\n    result = test_function(user_id=\"test-user\")\n    assert result == \"success\"\n    ld_client.variation.assert_called_once()", "blocks": [{"id": 1, "label": "async def test_feature_flag_enabled(ld_client):\n    ld_client.variation.return_value = True", "successors": [{"id": 3, "label": "    @feature_flag(\"test-flag\")\n    result = test_function(user_id=\"test-user\")", "successors": [{"id": 5, "label": "    assert result == \"success\"\n    ld_client.variation.assert_called_once()", "successors": []}]}]}]}, {"name": "test_feature_flag_unauthorized_response", "type": "function", "start_line": 29, "end_line": 37, "functions": [{"name": "test_function", "type": "function", "start_line": 33, "end_line": 34, "functions": [], "classes": [], "simplified_code": "    async def test_function(user_id: str):\n        return \"success\"", "blocks": [{"id": 1, "label": "async def test_function(user_id: str):\n    return \"success\"", "successors": []}]}], "classes": [], "simplified_code": "async def test_feature_flag_unauthorized_response(ld_client):\n    ld_client.variation.return_value = False\n\n    @feature_flag(\"test-flag\")\n        return \"success\"\n\n    result = test_function(user_id=\"test-user\")\n    assert result == {\"error\": \"disabled\"}", "blocks": [{"id": 1, "label": "async def test_feature_flag_unauthorized_response(ld_client):\n    ld_client.variation.return_value = False", "successors": [{"id": 3, "label": "@feature_flag(\"test-flag\")\nreturn \"success\"", "successors": []}, {"id": 5, "label": "result = test_function(user_id=\"test-user\")\nassert result == {\"error\": \"disabled\"}", "successors": []}]}]}, {"name": "test_mock_flag_variation", "type": "function", "start_line": 40, "end_line": 45, "functions": [], "classes": [], "simplified_code": "def test_mock_flag_variation(ld_client):\n    with mock_flag_variation(\"test-flag\", True):\n        assert ld_client.variation(\"test-flag\", None, False)\n\n    with mock_flag_variation(\"test-flag\", False):\n        assert ld_client.variation(\"test-flag\", None, False)", "blocks": [{"id": 1, "label": "def test_mock_flag_variation(ld_client):", "successors": [{"id": 2, "label": "with mock_flag_variation(\"test-flag\", True):\n    assert ld_client.variation(\"test-flag\", None, False)", "successors": []}, {"id": 4, "label": "with mock_flag_variation(\"test-flag\", False):\n    assert ld_client.variation(\"test-flag\", None, False)", "successors": []}]}]}], "classes": [], "simplified_code": "import pytest\nfrom ldclient import LDClient\n\nfrom autogpt_libs.feature_flag.client import feature_flag, mock_flag_variation\n\n\n@pytest.fixture\n    return client\n\n\n@pytest.mark.asyncio\n    ld_client.variation.assert_called_once()\n\n\n@pytest.mark.asyncio\n    assert result == {\"error\": \"disabled\"}\n\n\n        assert ld_client.variation(\"test-flag\", None, False)", "blocks": [{"id": 1, "label": "import pytest\nfrom ldclient import LDClient\n\nfrom autogpt_libs.feature_flag.client import feature_flag, mock_flag_variation\n@pytest.fixture\n    return client", "successors": [{"id": 3, "label": "@pytest.mark.asyncio\n    ld_client.variation.assert_called_once()\n@pytest.mark.asyncio\n    assert result == {\"error\": \"disabled\"}", "successors": [{"id": 5, "label": "assert ld_client.variation(\"test-flag\", None, False)", "successors": []}]}]}]}
{"file_name": "166.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 529, "functions": [], "classes": [{"name": "Attachment", "type": "class", "start_line": 22, "end_line": 26, "functions": [], "classes": [], "simplified_code": "class Attachment(BaseModel):\n    filename: str\n    content_type: str\n    size: int\n    attachment_id: str", "blocks": [{"id": 1, "label": "class Attachment(BaseModel):\n    filename: str\n    content_type: str\n    size: int\n    attachment_id: str", "successors": []}]}, {"name": "Email", "type": "class", "start_line": 29, "end_line": 38, "functions": [], "classes": [], "simplified_code": "class Email(BaseModel):\n    id: str\n    subject: str\n    snippet: str\n    from_: str\n    to: str\n    date: str\n    body: str = \"\"  # Default to an empty string\n    sizeEstimate: int\n    attachments: List[Attachment]", "blocks": [{"id": 1, "label": "class Email(BaseModel):\n    id: str\n    subject: str\n    snippet: str\n    from_: str\n    to: str\n    date: str\n    body: str = \"\"  # Default to an empty string\n    sizeEstimate: int\n    attachments: List[Attachment]", "successors": []}]}, {"name": "GmailReadBlock", "type": "class", "start_line": 41, "end_line": 240, "functions": [{"name": "__init__", "type": "function", "start_line": 66, "end_line": 128, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"25310c70-b89b-43ba-b25c-4dfa7e2a481c\",\n            description=\"This block reads emails from Gmail.\",\n            categories={BlockCategory.COMMUNICATION},\n            disabled=not GOOGLE_OAUTH_IS_CONFIGURED,\n            input_schema=GmailReadBlock.Input,\n            output_schema=GmailReadBlock.Output,\n            test_input={\n                \"query\": \"is:unread\",\n                \"max_results\": 5,\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\n                    \"email\",\n                    {\n                        \"id\": \"1\",\n                        \"subject\": \"Test Email\",\n                        \"snippet\": \"This is a test email\",\n                        \"from_\": \"test@example.com\",\n                        \"to\": \"recipient@example.com\",\n                        \"date\": \"2024-01-01\",\n                        \"body\": \"This is a test email\",\n                        \"sizeEstimate\": 100,\n                        \"attachments\": [],\n                    },\n                ),\n                (\n                    \"emails\",\n                    [\n                        {\n                            \"id\": \"1\",\n                            \"subject\": \"Test Email\",\n                            \"snippet\": \"This is a test email\",\n                            \"from_\": \"test@example.com\",\n                            \"to\": \"recipient@example.com\",\n                            \"date\": \"2024-01-01\",\n                            \"body\": \"This is a test email\",\n                            \"sizeEstimate\": 100,\n                            \"attachments\": [],\n                        }\n                    ],\n                ),\n            ],\n            test_mock={\n                \"_read_emails\": lambda *args, **kwargs: [\n                    {\n                        \"id\": \"1\",\n                        \"subject\": \"Test Email\",\n                        \"snippet\": \"This is a test email\",\n                        \"from_\": \"test@example.com\",\n                        \"to\": \"recipient@example.com\",\n                        \"date\": \"2024-01-01\",\n                        \"body\": \"This is a test email\",\n                        \"sizeEstimate\": 100,\n                        \"attachments\": [],\n                    }\n                ],\n                \"_send_email\": lambda *args, **kwargs: {\"id\": \"1\", \"status\": \"sent\"},\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\n    super().__init__(\n        id=\"25310c70-b89b-43ba-b25c-4dfa7e2a481c\",\n        description=\"This block reads emails from Gmail.\",\n        categories={BlockCategory.COMMUNICATION},\n        disabled=not GOOGLE_OAUTH_IS_CONFIGURED,\n        input_schema=GmailReadBlock.Input,\n        output_schema=GmailReadBlock.Output,\n        test_input={\n            \"query\": \"is:unread\",\n            \"max_results\": 5,\n            \"credentials\": TEST_CREDENTIALS_INPUT,\n        },\n        test_credentials=TEST_CREDENTIALS,\n        test_output=[\n            (\n                \"email\",\n                {\n                    \"id\": \"1\",\n                    \"subject\": \"Test Email\",\n                    \"snippet\": \"This is a test email\",\n                    \"from_\": \"test@example.com\",\n                    \"to\": \"recipient@example.com\",\n                    \"date\": \"2024-01-01\",\n                    \"body\": \"This is a test email\",\n                    \"sizeEstimate\": 100,\n                    \"attachments\": [],\n                },\n            ),\n            (\n                \"emails\",\n                [\n                    {\n                        \"id\": \"1\",\n                        \"subject\": \"Test Email\",\n                        \"snippet\": \"This is a test email\",\n                        \"from_\": \"test@example.com\",\n                        \"to\": \"recipient@example.com\",\n                        \"date\": \"2024-01-01\",\n                        \"body\": \"This is a test email\",\n                        \"sizeEstimate\": 100,\n                        \"attachments\": [],\n                    }\n                ],\n            ),\n        ],\n        test_mock={\n            \"_read_emails\": lambda *args, **kwargs: [\n                {\n                    \"id\": \"1\",\n                    \"subject\": \"Test Email\",\n                    \"snippet\": \"This is a test email\",\n                    \"from_\": \"test@example.com\",\n                    \"to\": \"recipient@example.com\",\n                    \"date\": \"2024-01-01\",\n                    \"body\": \"This is a test email\",\n                    \"sizeEstimate\": 100,\n                    \"attachments\": [],\n                }\n            ],\n            \"_send_email\": lambda *args, **kwargs: {\"id\": \"1\", \"status\": \"sent\"},\n        },\n    )", "successors": []}]}, {"name": "run", "type": "function", "start_line": 130, "end_line": 137, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: GoogleCredentials, **kwargs\n    ) -> BlockOutput:\n        service = self._build_service(credentials, **kwargs)\n        messages = self._read_emails(service, input_data.query, input_data.max_results)\n        for email in messages:\n            yield \"email\", email\n        yield \"emails\", messages", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: GoogleCredentials, **kwargs):\nservice = self._build_service(credentials, **kwargs)\nmessages = self._read_emails(service, input_data.query, input_data.max_results)", "successors": [{"id": 3, "label": "for email in messages:", "successors": [{"id": 4, "label": "yield \"email\", email\nyield \"emails\", messages", "successors": []}]}, {"id": 5, "label": "yield \"emails\", messages", "successors": []}]}]}, {"name": "_build_service", "type": "function", "start_line": 140, "end_line": 157, "functions": [], "classes": [], "simplified_code": "    def _build_service(credentials: GoogleCredentials, **kwargs):\n        creds = Credentials(\n            token=(\n                credentials.access_token.get_secret_value()\n                if credentials.access_token\n                else None\n            ),\n            refresh_token=(\n                credentials.refresh_token.get_secret_value()\n                if credentials.refresh_token\n                else None\n            ),\n            token_uri=\"https://oauth2.googleapis.com/token\",\n            client_id=kwargs.get(\"client_id\"),\n            client_secret=kwargs.get(\"client_secret\"),\n            scopes=credentials.scopes,\n        )\n        return build(\"gmail\", \"v1\", credentials=creds)", "blocks": [{"id": 1, "label": "def _build_service(credentials: GoogleCredentials, **kwargs):\ncreds = Credentials(token=(credentials.access_token.get_secret_value() if credentials.access_token else None), refresh_token=(credentials.refresh_token.get_secret_value() if credentials.refresh_token else None), token_uri=\"https://oauth2.googleapis.com/token\", client_id=kwargs.get(\"client_id\"), client_secret=kwargs.get(\"client_secret\"), scopes=credentials.scopes)", "successors": [{"id": 3, "label": "return build(\"gmail\", \"v1\", credentials=creds)", "successors": []}]}]}, {"name": "_read_emails", "type": "function", "start_line": 159, "end_line": 199, "functions": [], "classes": [], "simplified_code": "    def _read_emails(\n        self, service, query: str | None, max_results: int | None\n    ) -> list[Email]:\n        results = (\n            service.users()\n            .messages()\n            .list(userId=\"me\", q=query or \"\", maxResults=max_results or 10)\n            .execute()\n        )\n        messages = results.get(\"messages\", [])\n\n        email_data = []\n        for message in messages:\n            msg = (\n                service.users()\n                .messages()\n                .get(userId=\"me\", id=message[\"id\"], format=\"full\")\n                .execute()\n            )\n\n            headers = {\n                header[\"name\"].lower(): header[\"value\"]\n                for header in msg[\"payload\"][\"headers\"]\n            }\n\n            attachments = self._get_attachments(service, msg)\n\n            email = Email(\n                id=msg[\"id\"],\n                subject=headers.get(\"subject\", \"No Subject\"),\n                snippet=msg[\"snippet\"],\n                from_=parseaddr(headers.get(\"from\", \"\"))[1],\n                to=parseaddr(headers.get(\"to\", \"\"))[1],\n                date=headers.get(\"date\", \"\"),\n                body=self._get_email_body(msg),\n                sizeEstimate=msg[\"sizeEstimate\"],\n                attachments=attachments,\n            )\n            email_data.append(email)\n\n        return email_data", "blocks": [{"id": 1, "label": "def _read_emails(self, service, query: str | None, max_results: int | None) -> list[Email]:\nresults = (service.users().messages().list(userId=\"me\", q=query or \"\", maxResults=max_results or 10).execute())\nmessages = results.get(\"messages\", [])\n\nemail_data = []", "successors": [{"id": 3, "label": "for message in messages:", "successors": [{"id": 4, "label": "msg = (service.users().messages().get(userId=\"me\", id=message[\"id\"], format=\"full\").execute())\nheaders = {header[\"name\"].lower(): header[\"value\"] for header in msg[\"payload\"][\"headers\"]}\nattachments = self._get_attachments(service, msg)", "successors": [{"id": 6, "label": "email = Email(id=msg[\"id\"], subject=headers.get(\"subject\", \"No Subject\"), snippet=msg[\"snippet\"], from_=parseaddr(headers.get(\"from\", \"\"))[1], to=parseaddr(headers.get(\"to\", \"\"))[1], date=headers.get(\"date\", \"\"), body=self._get_email_body(msg), sizeEstimate=msg[\"sizeEstimate\"], attachments=attachments)\nemail_data.append(email)\nreturn email_data", "successors": []}]}]}]}]}, {"name": "_get_email_body", "type": "function", "start_line": 201, "end_line": 213, "functions": [], "classes": [], "simplified_code": "    def _get_email_body(self, msg):\n        if \"parts\" in msg[\"payload\"]:\n            for part in msg[\"payload\"][\"parts\"]:\n                if part[\"mimeType\"] == \"text/plain\":\n                    return base64.urlsafe_b64decode(part[\"body\"][\"data\"]).decode(\n                        \"utf-8\"\n                    )\n        elif msg[\"payload\"][\"mimeType\"] == \"text/plain\":\n            return base64.urlsafe_b64decode(msg[\"payload\"][\"body\"][\"data\"]).decode(\n                \"utf-8\"\n            )\n\n        return \"This email does not contain a text body.\"", "blocks": [{"id": 1, "label": "def _get_email_body(self, msg):", "successors": [{"id": 2, "label": "if \"parts\" in msg[\"payload\"]:", "successors": [{"id": 3, "label": "for part in msg[\"payload\"][\"parts\"]:", "successors": [{"id": 4, "label": "if part[\"mimeType\"] == \"text/plain\":\nreturn base64.urlsafe_b64decode(part[\"body\"][\"data\"]).decode(\"utf-8\")", "successors": []}]}]}, {"id": 6, "label": "elif msg[\"payload\"][\"mimeType\"] == \"text/plain\":\nreturn base64.urlsafe_b64decode(msg[\"payload\"][\"body\"][\"data\"]).decode(\"utf-8\")", "successors": []}, {"id": 8, "label": "return \"This email does not contain a text body.\"", "successors": []}]}]}, {"name": "_get_attachments", "type": "function", "start_line": 215, "end_line": 227, "functions": [], "classes": [], "simplified_code": "    def _get_attachments(self, service, message):\n        attachments = []\n        if \"parts\" in message[\"payload\"]:\n            for part in message[\"payload\"][\"parts\"]:\n                if part[\"filename\"]:\n                    attachment = Attachment(\n                        filename=part[\"filename\"],\n                        content_type=part[\"mimeType\"],\n                        size=int(part[\"body\"].get(\"size\", 0)),\n                        attachment_id=part[\"body\"][\"attachmentId\"],\n                    )\n                    attachments.append(attachment)\n        return attachments", "blocks": [{"id": 1, "label": "attachments = []", "successors": [{"id": 2, "label": "if \"parts\" in message[\"payload\"]:", "successors": [{"id": 3, "label": "for part in message[\"payload\"][\"parts\"]:", "successors": [{"id": 4, "label": "if part[\"filename\"]:\nattachment = Attachment(\n    filename=part[\"filename\"],\n    content_type=part[\"mimeType\"],\n    size=int(part[\"body\"].get(\"size\", 0)),\n    attachment_id=part[\"body\"][\"attachmentId\"]\n)", "successors": [{"id": 6, "label": "attachments.append(attachment)\nreturn attachments", "successors": []}]}, {"id": 7, "label": "return attachments", "successors": []}]}, {"id": 7, "label": "return attachments", "successors": []}]}, {"id": 7, "label": "return attachments", "successors": []}]}]}, {"name": "download_attachment", "type": "function", "start_line": 230, "end_line": 239, "functions": [], "classes": [], "simplified_code": "    def download_attachment(self, service, message_id: str, attachment_id: str):\n        attachment = (\n            service.users()\n            .messages()\n            .attachments()\n            .get(userId=\"me\", messageId=message_id, id=attachment_id)\n            .execute()\n        )\n        file_data = base64.urlsafe_b64decode(attachment[\"data\"].encode(\"UTF-8\"))\n        return file_data", "blocks": [{"id": 1, "label": "def download_attachment(self, service, message_id: str, attachment_id: str):\n    attachment = (service.users().messages().attachments().get(userId=\"me\", messageId=message_id, id=attachment_id).execute())", "successors": [{"id": 3, "label": "    file_data = base64.urlsafe_b64decode(attachment[\"data\"].encode(\"UTF-8\"))\n    return file_data", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 42, "end_line": 53, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GoogleCredentialsInput = GoogleCredentialsField(\n            [\"https://www.googleapis.com/auth/gmail.readonly\"]\n        )\n        query: str = SchemaField(\n            description=\"Search query for reading emails\",\n            default=\"is:unread\",\n        )\n        max_results: int = SchemaField(\n            description=\"Maximum number of emails to retrieve\",\n            default=10,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    credentials: GoogleCredentialsInput = GoogleCredentialsField([\n        \"https://www.googleapis.com/auth/gmail.readonly\"\n    ])", "successors": []}, {"id": 3, "label": "    query: str = SchemaField(\n        description=\"Search query for reading emails\",\n        default=\"is:unread\",\n    )", "successors": []}, {"id": 4, "label": "    max_results: int = SchemaField(\n        description=\"Maximum number of emails to retrieve\",\n        default=10,\n    )", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 55, "end_line": 64, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        email: Email = SchemaField(\n            description=\"Email data\",\n        )\n        emails: list[Email] = SchemaField(\n            description=\"List of email data\",\n        )\n        error: str = SchemaField(\n            description=\"Error message if any\",\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\nemail: Email = SchemaField(\n    description=\"Email data\",\n)", "successors": [{"id": 3, "label": "emails: list[Email] = SchemaField(\n    description=\"List of email data\",\n)\nerror: str = SchemaField(\n    description=\"Error message if any\",\n)", "successors": []}]}]}], "simplified_code": "class GmailReadBlock(Block):\n        )\n\n        )\n\n        )\n\n        yield \"emails\", messages\n\n    @staticmethod\n        return build(\"gmail\", \"v1\", credentials=creds)\n\n        return email_data\n\n        return \"This email does not contain a text body.\"\n\n        return attachments\n\n    # Add a new method to download attachment content\n        return file_data\n", "blocks": [{"id": 1, "label": "class GmailReadBlock(Block):\nyield \"emails\", messages", "successors": []}]}, {"name": "GmailSendBlock", "type": "class", "start_line": 242, "end_line": 314, "functions": [{"name": "__init__", "type": "function", "start_line": 265, "end_line": 286, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"6c27abc2-e51d-499e-a85f-5a0041ba94f0\",\n            description=\"This block sends an email using Gmail.\",\n            categories={BlockCategory.COMMUNICATION},\n            input_schema=GmailSendBlock.Input,\n            output_schema=GmailSendBlock.Output,\n            disabled=not GOOGLE_OAUTH_IS_CONFIGURED,\n            test_input={\n                \"to\": \"recipient@example.com\",\n                \"subject\": \"Test Email\",\n                \"body\": \"This is a test email sent from GmailSendBlock.\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\"result\", {\"id\": \"1\", \"status\": \"sent\"}),\n            ],\n            test_mock={\n                \"_send_email\": lambda *args, **kwargs: {\"id\": \"1\", \"status\": \"sent\"},\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"6c27abc2-e51d-499e-a85f-5a0041ba94f0\",\n    description=\"This block sends an email using Gmail.\",\n    categories={BlockCategory.COMMUNICATION},\n    input_schema=GmailSendBlock.Input,\n    output_schema=GmailSendBlock.Output,\n    disabled=not GOOGLE_OAUTH_IS_CONFIGURED,\n    test_input={\n        \"to\": \"recipient@example.com\",\n        \"subject\": \"Test Email\",\n        \"body\": \"This is a test email sent from GmailSendBlock.\",\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\"result\", {\"id\": \"1\", \"status\": \"sent\"}),\n    ],\n    test_mock={\n        \"_send_email\": lambda *args, **kwargs: {\"id\": \"1\", \"status\": \"sent\"},\n    },\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 288, "end_line": 295, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: GoogleCredentials, **kwargs\n    ) -> BlockOutput:\n        service = GmailReadBlock._build_service(credentials, **kwargs)\n        send_result = self._send_email(\n            service, input_data.to, input_data.subject, input_data.body\n        )\n        yield \"result\", send_result", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: GoogleCredentials, **kwargs) -> BlockOutput:\nservice = GmailReadBlock._build_service(credentials, **kwargs)", "successors": [{"id": 3, "label": "send_result = self._send_email(service, input_data.to, input_data.subject, input_data.body)\nyield \"result\", send_result", "successors": []}]}]}, {"name": "_send_email", "type": "function", "start_line": 297, "end_line": 304, "functions": [], "classes": [], "simplified_code": "    def _send_email(self, service, to: str, subject: str, body: str) -> dict:\n        if not to or not subject or not body:\n            raise ValueError(\"To, subject, and body are required for sending an email\")\n        message = self._create_message(to, subject, body)\n        sent_message = (\n            service.users().messages().send(userId=\"me\", body=message).execute()\n        )\n        return {\"id\": sent_message[\"id\"], \"status\": \"sent\"}", "blocks": [{"id": 1, "label": "def _send_email(self, service, to: str, subject: str, body: str) -> dict:", "successors": [{"id": 2, "label": "if not to or not subject or not body:\n    raise ValueError(\"To, subject, and body are required for sending an email\")", "successors": []}, {"id": 4, "label": "message = self._create_message(to, subject, body)\nsent_message = (\n    service.users().messages().send(userId=\"me\", body=message).execute()\n)", "successors": [{"id": 6, "label": "return {\"id\": sent_message[\"id\"], \"status\": \"sent\"}", "successors": []}]}]}]}, {"name": "_create_message", "type": "function", "start_line": 306, "end_line": 314, "functions": [], "classes": [], "simplified_code": "    def _create_message(self, to: str, subject: str, body: str) -> dict:\n        import base64\n        from email.mime.text import MIMEText\n\n        message = MIMEText(body)\n        message[\"to\"] = to\n        message[\"subject\"] = subject\n        raw_message = base64.urlsafe_b64encode(message.as_bytes()).decode(\"utf-8\")\n        return {\"raw\": raw_message}", "blocks": [{"id": 1, "label": "def _create_message(self, to: str, subject: str, body: str) -> dict:\nimport base64\nfrom email.mime.text import MIMEText\n\nmessage = MIMEText(body)\nmessage[\"to\"] = to\nmessage[\"subject\"] = subject\nraw_message = base64.urlsafe_b64encode(message.as_bytes()).decode(\"utf-8\")", "successors": [{"id": 3, "label": "return {\"raw\": raw_message}", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 243, "end_line": 255, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GoogleCredentialsInput = GoogleCredentialsField(\n            [\"https://www.googleapis.com/auth/gmail.send\"]\n        )\n        to: str = SchemaField(\n            description=\"Recipient email address\",\n        )\n        subject: str = SchemaField(\n            description=\"Email subject\",\n        )\n        body: str = SchemaField(\n            description=\"Email body\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\ncredentials: GoogleCredentialsInput = GoogleCredentialsField([\n    \"https://www.googleapis.com/auth/gmail.send\"\n])", "successors": [{"id": 3, "label": "to: str = SchemaField(\n    description=\"Recipient email address\",\n)\nsubject: str = SchemaField(\n    description=\"Email subject\",\n)", "successors": [{"id": 5, "label": "body: str = SchemaField(\n    description=\"Email body\",\n)", "successors": []}]}]}]}, {"name": "Output", "type": "class", "start_line": 257, "end_line": 263, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        result: dict = SchemaField(\n            description=\"Send confirmation\",\n        )\n        error: str = SchemaField(\n            description=\"Error message if any\",\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\nresult: dict = SchemaField(\n    description=\"Send confirmation\",\n)", "successors": [{"id": 3, "label": "error: str = SchemaField(\n    description=\"Error message if any\",\n)", "successors": []}]}]}], "simplified_code": "class GmailSendBlock(Block):\n        )\n\n        )\n\n        )\n\n        yield \"result\", send_result\n\n        return {\"id\": sent_message[\"id\"], \"status\": \"sent\"}\n\n        return {\"raw\": raw_message}", "blocks": [{"id": 1, "label": "class GmailSendBlock(Block):", "successors": [{"id": 2, "label": "yield \"result\", send_result\nreturn {\"id\": sent_message[\"id\"], \"status\": \"sent\"}", "successors": []}, {"id": 4, "label": "return {\"raw\": raw_message}", "successors": []}]}]}, {"name": "GmailListLabelsBlock", "type": "class", "start_line": 317, "end_line": 370, "functions": [{"name": "__init__", "type": "function", "start_line": 331, "end_line": 358, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"3e1c2c1c-c689-4520-b956-1f3bf4e02bb7\",\n            description=\"This block lists all labels in Gmail.\",\n            categories={BlockCategory.COMMUNICATION},\n            input_schema=GmailListLabelsBlock.Input,\n            output_schema=GmailListLabelsBlock.Output,\n            disabled=not GOOGLE_OAUTH_IS_CONFIGURED,\n            test_input={\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\n                    \"result\",\n                    [\n                        {\"id\": \"Label_1\", \"name\": \"Important\"},\n                        {\"id\": \"Label_2\", \"name\": \"Work\"},\n                    ],\n                ),\n            ],\n            test_mock={\n                \"_list_labels\": lambda *args, **kwargs: [\n                    {\"id\": \"Label_1\", \"name\": \"Important\"},\n                    {\"id\": \"Label_2\", \"name\": \"Work\"},\n                ],\n            },\n        )", "blocks": [{"id": 1, "label": "super().__init__(\n    id=\"3e1c2c1c-c689-4520-b956-1f3bf4e02bb7\",\n    description=\"This block lists all labels in Gmail.\",\n    categories={BlockCategory.COMMUNICATION},\n    input_schema=GmailListLabelsBlock.Input,\n    output_schema=GmailListLabelsBlock.Output,\n    disabled=not GOOGLE_OAUTH_IS_CONFIGURED,\n    test_input={\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\n            \"result\",\n            [\n                {\"id\": \"Label_1\", \"name\": \"Important\"},\n                {\"id\": \"Label_2\", \"name\": \"Work\"},\n            ],\n        ),\n    ],\n    test_mock={\n        \"_list_labels\": lambda *args, **kwargs: [\n            {\"id\": \"Label_1\", \"name\": \"Important\"},\n            {\"id\": \"Label_2\", \"name\": \"Work\"},\n        ],\n    },\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 360, "end_line": 365, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: GoogleCredentials, **kwargs\n    ) -> BlockOutput:\n        service = GmailReadBlock._build_service(credentials, **kwargs)\n        labels = self._list_labels(service)\n        yield \"result\", labels", "blocks": [{"id": 1, "label": "def run( self, input_data: Input, *, credentials: GoogleCredentials, **kwargs ) -> BlockOutput:\n    service = GmailReadBlock._build_service(credentials, **kwargs)\n    labels = self._list_labels(service)\n    yield \"result\", labels", "successors": []}]}, {"name": "_list_labels", "type": "function", "start_line": 367, "end_line": 370, "functions": [], "classes": [], "simplified_code": "    def _list_labels(self, service) -> list[dict]:\n        results = service.users().labels().list(userId=\"me\").execute()\n        labels = results.get(\"labels\", [])\n        return [{\"id\": label[\"id\"], \"name\": label[\"name\"]} for label in labels]", "blocks": [{"id": 1, "label": "def _list_labels(self, service) -> list[dict]:\nresults = service.users().labels().list(userId=\"me\").execute()\nlabels = results.get(\"labels\", [])", "successors": [{"id": 3, "label": "return [{\"id\": label[\"id\"], \"name\": label[\"name\"]} for label in labels]", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 318, "end_line": 321, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GoogleCredentialsInput = GoogleCredentialsField(\n            [\"https://www.googleapis.com/auth/gmail.labels\"]\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: GoogleCredentialsInput = GoogleCredentialsField(\n        [\"https://www.googleapis.com/auth/gmail.labels\"]\n    )", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 323, "end_line": 329, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        result: list[dict] = SchemaField(\n            description=\"List of labels\",\n        )\n        error: str = SchemaField(\n            description=\"Error message if any\",\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "    result: list[dict] = SchemaField(description=\"List of labels\",)", "successors": []}, {"id": 3, "label": "    error: str = SchemaField(description=\"Error message if any\",)", "successors": []}]}]}], "simplified_code": "class GmailListLabelsBlock(Block):\n        )\n\n        )\n\n        )\n\n        yield \"result\", labels\n\n        return [{\"id\": label[\"id\"], \"name\": label[\"name\"]} for label in labels]", "blocks": [{"id": 1, "label": "class GmailListLabelsBlock(Block):\nyield \"result\", labels", "successors": [{"id": 3, "label": "return [{\"id\": label[\"id\"], \"name\": label[\"name\"]} for label in labels]", "successors": []}]}]}, {"name": "GmailAddLabelBlock", "type": "class", "start_line": 373, "end_line": 453, "functions": [{"name": "__init__", "type": "function", "start_line": 393, "end_line": 419, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"f884b2fb-04f4-4265-9658-14f433926ac9\",\n            description=\"This block adds a label to a Gmail message.\",\n            categories={BlockCategory.COMMUNICATION},\n            input_schema=GmailAddLabelBlock.Input,\n            output_schema=GmailAddLabelBlock.Output,\n            disabled=not GOOGLE_OAUTH_IS_CONFIGURED,\n            test_input={\n                \"message_id\": \"12345\",\n                \"label_name\": \"Important\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\n                    \"result\",\n                    {\"status\": \"Label added successfully\", \"label_id\": \"Label_1\"},\n                ),\n            ],\n            test_mock={\n                \"_add_label\": lambda *args, **kwargs: {\n                    \"status\": \"Label added successfully\",\n                    \"label_id\": \"Label_1\",\n                },\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"f884b2fb-04f4-4265-9658-14f433926ac9\",\n    description=\"This block adds a label to a Gmail message.\",\n    categories={BlockCategory.COMMUNICATION},\n    input_schema=GmailAddLabelBlock.Input,\n    output_schema=GmailAddLabelBlock.Output,\n    disabled=not GOOGLE_OAUTH_IS_CONFIGURED,\n    test_input={\n        \"message_id\": \"12345\",\n        \"label_name\": \"Important\",\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\n            \"result\",\n            {\"status\": \"Label added successfully\", \"label_id\": \"Label_1\"},\n        ),\n    ],\n    test_mock={\n        \"_add_label\": lambda *args, **kwargs: {\n            \"status\": \"Label added successfully\",\n            \"label_id\": \"Label_1\",\n        },\n    },\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 421, "end_line": 426, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: GoogleCredentials, **kwargs\n    ) -> BlockOutput:\n        service = GmailReadBlock._build_service(credentials, **kwargs)\n        result = self._add_label(service, input_data.message_id, input_data.label_name)\n        yield \"result\", result", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: GoogleCredentials, **kwargs):\nservice = GmailReadBlock._build_service(credentials, **kwargs)", "successors": [{"id": 3, "label": "result = self._add_label(service, input_data.message_id, input_data.label_name)\nyield \"result\", result", "successors": []}]}]}, {"name": "_add_label", "type": "function", "start_line": 428, "end_line": 433, "functions": [], "classes": [], "simplified_code": "    def _add_label(self, service, message_id: str, label_name: str) -> dict:\n        label_id = self._get_or_create_label(service, label_name)\n        service.users().messages().modify(\n            userId=\"me\", id=message_id, body={\"addLabelIds\": [label_id]}\n        ).execute()\n        return {\"status\": \"Label added successfully\", \"label_id\": label_id}", "blocks": [{"id": 1, "label": "label_id = self._get_or_create_label(service, label_name)\nservice.users().messages().modify(userId=\"me\", id=message_id, body={\"addLabelIds\": [label_id]}).execute()", "successors": [{"id": 3, "label": "return {\"status\": \"Label added successfully\", \"label_id\": label_id}", "successors": []}]}]}, {"name": "_get_or_create_label", "type": "function", "start_line": 435, "end_line": 445, "functions": [], "classes": [], "simplified_code": "    def _get_or_create_label(self, service, label_name: str) -> str:\n        label_id = self._get_label_id(service, label_name)\n        if not label_id:\n            label = (\n                service.users()\n                .labels()\n                .create(userId=\"me\", body={\"name\": label_name})\n                .execute()\n            )\n            label_id = label[\"id\"]\n        return label_id", "blocks": [{"id": 1, "label": "label_id = self._get_label_id(service, label_name)\nif not label_id:", "successors": [{"id": 3, "label": "    label = (\n        service.users()\n        .labels()\n        .create(userId=\"me\", body={\"name\": label_name})\n        .execute()\n    )\n    label_id = label[\"id\"]\nreturn label_id", "successors": []}, {"id": 4, "label": "return label_id", "successors": []}]}]}, {"name": "_get_label_id", "type": "function", "start_line": 447, "end_line": 453, "functions": [], "classes": [], "simplified_code": "    def _get_label_id(self, service, label_name: str) -> str | None:\n        results = service.users().labels().list(userId=\"me\").execute()\n        labels = results.get(\"labels\", [])\n        for label in labels:\n            if label[\"name\"] == label_name:\n                return label[\"id\"]\n        return None", "blocks": [{"id": 1, "label": "def _get_label_id(self, service, label_name: str) -> str | None:\nresults = service.users().labels().list(userId=\"me\").execute()\nlabels = results.get(\"labels\", [])", "successors": [{"id": 3, "label": "for label in labels:", "successors": [{"id": 4, "label": "if label[\"name\"] == label_name:\nreturn label[\"id\"]", "successors": []}]}, {"id": 6, "label": "return None", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 374, "end_line": 383, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GoogleCredentialsInput = GoogleCredentialsField(\n            [\"https://www.googleapis.com/auth/gmail.modify\"]\n        )\n        message_id: str = SchemaField(\n            description=\"Message ID to add label to\",\n        )\n        label_name: str = SchemaField(\n            description=\"Label name to add\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: GoogleCredentialsInput = GoogleCredentialsField([\n        \"https://www.googleapis.com/auth/gmail.modify\"\n    ])", "successors": [{"id": 3, "label": "    message_id: str = SchemaField(\n        description=\"Message ID to add label to\",\n    )\n    label_name: str = SchemaField(\n        description=\"Label name to add\",\n    )", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 385, "end_line": 391, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        result: dict = SchemaField(\n            description=\"Label addition result\",\n        )\n        error: str = SchemaField(\n            description=\"Error message if any\",\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    result: dict = SchemaField(\n        description=\"Label addition result\",\n    )", "successors": [{"id": 3, "label": "    error: str = SchemaField(\n        description=\"Error message if any\",\n    )", "successors": []}]}]}], "simplified_code": "class GmailAddLabelBlock(Block):\n        )\n\n        )\n\n        )\n\n        yield \"result\", result\n\n        return {\"status\": \"Label added successfully\", \"label_id\": label_id}\n\n        return label_id\n\n        return None", "blocks": [{"id": 1, "label": "class GmailAddLabelBlock(Block):\n    def __init__(self, email, label_name):", "successors": [{"id": 3, "label": "        self.email = email\n        self.label_name = label_name\n    def add_label(self):", "successors": [{"id": 5, "label": "        service = self.authenticate_gmail()\n        labels = service.users().labels().list(userId='me').execute().get('labels', [])", "successors": [{"id": 7, "label": "        label_id = None", "successors": [{"id": 8, "label": "        for label in labels:", "successors": [{"id": 9, "label": "            if label['name'] == self.label_name:\n                label_id = label['id']", "successors": [{"id": 11, "label": "                break\n        if not label_id:", "successors": [{"id": 22, "label": "            label = {'name': self.label_name, 'labelListVisibility': 'labelShow', 'messageListVisibility': 'show'}\n            label = service.users().labels().create(userId='me', body=label).execute()", "successors": [{"id": 24, "label": "            label_id = label['id']\n        # Attach the label to the email", "successors": [{"id": 26, "label": "        msg_id = self.get_message_id()\n        if msg_id:", "successors": [{"id": 28, "label": "            service.users().messages().modify(userId='me', id=msg_id, body={'addLabelIds': [label_id]}).execute()\n            return {'status': 'Label added successfully', 'label_id': label_id}", "successors": []}, {"id": 30, "label": "        return {'status': 'Message ID not found'}", "successors": []}]}]}]}]}]}, {"id": 31, "label": "    def authenticate_gmail(self):\n        creds = None", "successors": [{"id": 33, "label": "        if os.path.exists('token.json'):\n            creds = Credentials.from_authorized_user_file('token.json', SCOPES)", "successors": [{"id": 35, "label": "        if not creds or not creds.valid:", "successors": [{"id": 36, "label": "            if creds and creds.expired and creds.refresh_token:\n                creds.refresh(Request())", "successors": []}, {"id": 38, "label": "            else:\n                flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)", "successors": [{"id": 40, "label": "                creds = flow.run_local_server(port=0)\n            with open('token.json', 'w') as token:", "successors": [{"id": 42, "label": "                token.write(creds.to_json())", "successors": []}]}]}]}, {"id": 43, "label": "        return build('gmail', 'v1', credentials=creds)", "successors": []}]}]}, {"id": 44, "label": "    def get_message_id(self):\n        # This could be implemented to fetch the message ID based on the email content", "successors": [{"id": 46, "label": "        return 'sample_message_id'", "successors": []}]}]}]}]}]}]}]}, {"name": "GmailRemoveLabelBlock", "type": "class", "start_line": 456, "end_line": 529, "functions": [{"name": "__init__", "type": "function", "start_line": 476, "end_line": 502, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"0afc0526-aba1-4b2b-888e-a22b7c3f359d\",\n            description=\"This block removes a label from a Gmail message.\",\n            categories={BlockCategory.COMMUNICATION},\n            input_schema=GmailRemoveLabelBlock.Input,\n            output_schema=GmailRemoveLabelBlock.Output,\n            disabled=not GOOGLE_OAUTH_IS_CONFIGURED,\n            test_input={\n                \"message_id\": \"12345\",\n                \"label_name\": \"Important\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\n                    \"result\",\n                    {\"status\": \"Label removed successfully\", \"label_id\": \"Label_1\"},\n                ),\n            ],\n            test_mock={\n                \"_remove_label\": lambda *args, **kwargs: {\n                    \"status\": \"Label removed successfully\",\n                    \"label_id\": \"Label_1\",\n                },\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"0afc0526-aba1-4b2b-888e-a22b7c3f359d\",\n    description=\"This block removes a label from a Gmail message.\",\n    categories={BlockCategory.COMMUNICATION},\n    input_schema=GmailRemoveLabelBlock.Input,\n    output_schema=GmailRemoveLabelBlock.Output,\n    disabled=not GOOGLE_OAUTH_IS_CONFIGURED,\n    test_input={\n        \"message_id\": \"12345\",\n        \"label_name\": \"Important\",\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\n            \"result\",\n            {\"status\": \"Label removed successfully\", \"label_id\": \"Label_1\"},\n        ),\n    ],\n    test_mock={\n        \"_remove_label\": lambda *args, **kwargs: {\n            \"status\": \"Label removed successfully\",\n            \"label_id\": \"Label_1\",\n        },\n    },\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 504, "end_line": 511, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: GoogleCredentials, **kwargs\n    ) -> BlockOutput:\n        service = GmailReadBlock._build_service(credentials, **kwargs)\n        result = self._remove_label(\n            service, input_data.message_id, input_data.label_name\n        )\n        yield \"result\", result", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: GoogleCredentials, **kwargs):\nservice = GmailReadBlock._build_service(credentials, **kwargs)", "successors": [{"id": 3, "label": "result = self._remove_label(service, input_data.message_id, input_data.label_name)\nyield \"result\", result", "successors": []}]}]}, {"name": "_remove_label", "type": "function", "start_line": 513, "end_line": 521, "functions": [], "classes": [], "simplified_code": "    def _remove_label(self, service, message_id: str, label_name: str) -> dict:\n        label_id = self._get_label_id(service, label_name)\n        if label_id:\n            service.users().messages().modify(\n                userId=\"me\", id=message_id, body={\"removeLabelIds\": [label_id]}\n            ).execute()\n            return {\"status\": \"Label removed successfully\", \"label_id\": label_id}\n        else:\n            return {\"status\": \"Label not found\", \"label_name\": label_name}", "blocks": [{"id": 1, "label": "def _remove_label(self, service, message_id: str, label_name: str) -> dict:\nlabel_id = self._get_label_id(service, label_name)", "successors": [{"id": 3, "label": "if label_id:", "successors": [{"id": 4, "label": "service.users().messages().modify(\n    userId=\"me\", id=message_id, body={\"removeLabelIds\": [label_id]}\n).execute()\nreturn {\"status\": \"Label removed successfully\", \"label_id\": label_id}", "successors": []}, {"id": 6, "label": "return {\"status\": \"Label not found\", \"label_name\": label_name}", "successors": []}]}]}]}, {"name": "_get_label_id", "type": "function", "start_line": 523, "end_line": 529, "functions": [], "classes": [], "simplified_code": "    def _get_label_id(self, service, label_name: str) -> str | None:\n        results = service.users().labels().list(userId=\"me\").execute()\n        labels = results.get(\"labels\", [])\n        for label in labels:\n            if label[\"name\"] == label_name:\n                return label[\"id\"]\n        return None", "blocks": [{"id": 1, "label": "results = service.users().labels().list(userId=\"me\").execute()\nlabels = results.get(\"labels\", [])", "successors": [{"id": 2, "label": "for label in labels:", "successors": [{"id": 3, "label": "    if label[\"name\"] == label_name:", "successors": [{"id": 4, "label": "        return label[\"id\"]", "successors": []}, {"id": 5, "label": "return None", "successors": []}]}, {"id": 5, "label": "return None", "successors": []}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 457, "end_line": 466, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: GoogleCredentialsInput = GoogleCredentialsField(\n            [\"https://www.googleapis.com/auth/gmail.modify\"]\n        )\n        message_id: str = SchemaField(\n            description=\"Message ID to remove label from\",\n        )\n        label_name: str = SchemaField(\n            description=\"Label name to remove\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: GoogleCredentialsInput = GoogleCredentialsField(\n        [\"https://www.googleapis.com/auth/gmail.modify\"]\n    )\n    message_id: str = SchemaField(\n        description=\"Message ID to remove label from\",\n    )\n    label_name: str = SchemaField(\n        description=\"Label name to remove\",\n    )", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 468, "end_line": 474, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        result: dict = SchemaField(\n            description=\"Label removal result\",\n        )\n        error: str = SchemaField(\n            description=\"Error message if any\",\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    result: dict = SchemaField(\n        description=\"Label removal result\",\n    )\n    error: str = SchemaField(\n        description=\"Error message if any\",\n    )", "successors": []}]}], "simplified_code": "class GmailRemoveLabelBlock(Block):\n        )\n\n        )\n\n        )\n\n        yield \"result\", result\n\n            return {\"status\": \"Label not found\", \"label_name\": label_name}\n\n        return None", "blocks": [{"id": 1, "label": "class GmailRemoveLabelBlock(Block):\nyield \"result\", result", "successors": [{"id": 3, "label": "return {\"status\": \"Label not found\", \"label_name\": label_name}\nreturn None", "successors": []}]}]}], "simplified_code": "import base64\nfrom email.utils import parseaddr\nfrom typing import List\n\nfrom google.oauth2.credentials import Credentials\nfrom googleapiclient.discovery import build\nfrom pydantic import BaseModel\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\nfrom ._auth import (\n    GOOGLE_OAUTH_IS_CONFIGURED,\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    GoogleCredentials,\n    GoogleCredentialsField,\n    GoogleCredentialsInput,\n)\n\n\n    attachment_id: str\n\n\n    attachments: List[Attachment]\n\n\n\n\n        return {\"raw\": raw_message}\n\n\n        return [{\"id\": label[\"id\"], \"name\": label[\"name\"]} for label in labels]\n\n\n        return None\n\n\n        return None", "blocks": [{"id": 1, "label": "import base64\nfrom email.utils import parseaddr\nfrom typing import List\n\nfrom google.oauth2.credentials import Credentials\nfrom googleapiclient.discovery import build\nfrom pydantic import BaseModel\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\nfrom ._auth import (\n    GOOGLE_OAUTH_IS_CONFIGURED,\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    GoogleCredentials,\n    GoogleCredentialsField,\n    GoogleCredentialsInput,\n)\n\n\n    attachment_id: str\n\n\n    attachments: List[Attachment]\n\n\n\n        return {\"raw\": raw_message}\n\n\n        return [{\"id\": label[\"id\"], \"name\": label[\"name\"]} for label in labels]\n\n\n        return None\n\n\n        return None", "successors": []}]}
{"file_name": "167.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 34, "functions": [], "classes": [{"name": "JSONCryptor", "type": "class", "start_line": 11, "end_line": 34, "functions": [{"name": "__init__", "type": "function", "start_line": 12, "end_line": 21, "functions": [], "classes": [], "simplified_code": "    def __init__(self, key: Optional[str] = None):\n        # Use provided key or get from environment\n        self.key = key or ENCRYPTION_KEY\n        if not self.key:\n            raise ValueError(\n                \"Encryption key must be provided or set in ENCRYPTION_KEY environment variable\"\n            )\n        self.fernet = Fernet(\n            self.key.encode() if isinstance(self.key, str) else self.key\n        )", "blocks": [{"id": 1, "label": "def __init__(self, key: Optional[str] = None):\n    self.key = key or ENCRYPTION_KEY\nif not self.key:", "successors": [{"id": 3, "label": "    raise ValueError(\n        \"Encryption key must be provided or set in ENCRYPTION_KEY environment variable\"\n    )\nself.fernet = Fernet(\n    self.key.encode() if isinstance(self.key, str) else self.key\n)", "successors": []}, {"id": 4, "label": "self.fernet = Fernet(\n    self.key.encode() if isinstance(self.key, str) else self.key\n)", "successors": []}]}]}, {"name": "encrypt", "type": "function", "start_line": 23, "end_line": 27, "functions": [], "classes": [], "simplified_code": "    def encrypt(self, data: dict) -> str:\n        \"\"\"Encrypt dictionary data to string\"\"\"\n        json_str = json.dumps(data)\n        encrypted = self.fernet.encrypt(json_str.encode())\n        return encrypted.decode()", "blocks": [{"id": 1, "label": "def encrypt(self, data: dict) -> str:\n\"\"\"Encrypt dictionary data to string\"\"\"", "successors": [{"id": 3, "label": "json_str = json.dumps(data)\nencrypted = self.fernet.encrypt(json_str.encode())", "successors": [{"id": 5, "label": "return encrypted.decode()", "successors": []}]}]}]}, {"name": "decrypt", "type": "function", "start_line": 29, "end_line": 34, "functions": [], "classes": [], "simplified_code": "    def decrypt(self, encrypted_str: str) -> dict:\n        \"\"\"Decrypt string to dictionary\"\"\"\n        if not encrypted_str:\n            return {}\n        decrypted = self.fernet.decrypt(encrypted_str.encode())\n        return json.loads(decrypted.decode())", "blocks": [{"id": 1, "label": "def decrypt(self, encrypted_str: str) -> dict:\n    \"\"\"Decrypt string to dictionary\"\"\"", "successors": [{"id": 3, "label": "if not encrypted_str:", "successors": [{"id": 4, "label": "    return {}", "successors": []}, {"id": 5, "label": "decrypted = self.fernet.decrypt(encrypted_str.encode())\nreturn json.loads(decrypted.decode())", "successors": []}]}]}]}], "simplified_code": "class JSONCryptor:\n        )\n\n        return encrypted.decode()\n\n        return json.loads(decrypted.decode())", "blocks": [{"id": 1, "label": "class JSONCryptor:", "successors": [{"id": 2, "label": "def encrypt(self, data):\njson_data = json.dumps(data)", "successors": [{"id": 4, "label": "encrypted = base64.b64encode(cipher.encrypt(json_data.encode()))\nreturn encrypted.decode()", "successors": []}]}, {"id": 6, "label": "def decrypt(self, encrypted_data):\ndecrypted = cipher.decrypt(base64.b64decode(encrypted_data.encode()))", "successors": [{"id": 8, "label": "return json.loads(decrypted.decode())", "successors": []}]}]}]}], "simplified_code": "import json\nfrom typing import Optional\n\nfrom cryptography.fernet import Fernet\n\nfrom backend.util.settings import Settings\n\nENCRYPTION_KEY = Settings().secrets.encryption_key\n\n\n        return json.loads(decrypted.decode())", "blocks": [{"id": 1, "label": "import json\nfrom typing import Optional\n\nfrom cryptography.fernet import Fernet\n\nfrom backend.util.settings import Settings\n\nENCRYPTION_KEY = Settings().secrets.encryption_key\nreturn json.loads(decrypted.decode())", "successors": []}]}
{"file_name": "168.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 51, "functions": [], "classes": [{"name": "RateLimiter", "type": "class", "start_line": 9, "end_line": 51, "functions": [{"name": "__init__", "type": "function", "start_line": 10, "end_line": 24, "functions": [], "classes": [], "simplified_code": "    def __init__(\n        self,\n        redis_host: str = RATE_LIMIT_SETTINGS.redis_host,\n        redis_port: str = RATE_LIMIT_SETTINGS.redis_port,\n        redis_password: str = RATE_LIMIT_SETTINGS.redis_password,\n        requests_per_minute: int = RATE_LIMIT_SETTINGS.requests_per_minute,\n    ):\n        self.redis = Redis(\n            host=redis_host,\n            port=int(redis_port),\n            password=redis_password,\n            decode_responses=True,\n        )\n        self.window = 60\n        self.max_requests = requests_per_minute", "blocks": [{"id": 1, "label": "def __init__(\n    self,\n    redis_host: str = RATE_LIMIT_SETTINGS.redis_host,\n    redis_port: str = RATE_LIMIT_SETTINGS.redis_port,\n    redis_password: str = RATE_LIMIT_SETTINGS.redis_password,\n    requests_per_minute: int = RATE_LIMIT_SETTINGS.requests_per_minute,\n):\n    self.redis = Redis(\n        host=redis_host,\n        port=int(redis_port),\n        password=redis_password,\n        decode_responses=True,\n    )", "successors": [{"id": 3, "label": "    self.window = 60\n    self.max_requests = requests_per_minute", "successors": []}]}]}, {"name": "check_rate_limit", "type": "function", "start_line": 26, "end_line": 51, "functions": [], "classes": [], "simplified_code": "    async def check_rate_limit(self, api_key_id: str) -> Tuple[bool, int, int]:\n        \"\"\"\n        Check if request is within rate limits.\n\n        Args:\n            api_key_id: The API key identifier to check\n\n        Returns:\n            Tuple of (is_allowed, remaining_requests, reset_time)\n        \"\"\"\n        now = time.time()\n        window_start = now - self.window\n        key = f\"ratelimit:{api_key_id}:1min\"\n\n        pipe = self.redis.pipeline()\n        pipe.zremrangebyscore(key, 0, window_start)\n        pipe.zadd(key, {str(now): now})\n        pipe.zcount(key, window_start, now)\n        pipe.expire(key, self.window)\n\n        _, _, request_count, _ = pipe.execute()\n\n        remaining = max(0, self.max_requests - request_count)\n        reset_time = int(now + self.window)\n\n        return request_count <= self.max_requests, remaining, reset_time", "blocks": [{"id": 1, "label": "async def check_rate_limit(self, api_key_id: str) -> Tuple[bool, int, int]:\n    \"\"\"\n    Check if request is within rate limits.\n\n    Args:\n        api_key_id: The API key identifier to check\n\n    Returns:\n        Tuple of (is_allowed, remaining_requests, reset_time)\n    \"\"\"\n    now = time.time()\n    window_start = now - self.window\n    key = f\"ratelimit:{api_key_id}:1min\"\n\n    pipe = self.redis.pipeline()\n    pipe.zremrangebyscore(key, 0, window_start)\n    pipe.zadd(key, {str(now): now})\n    pipe.zcount(key, window_start, now)\n    pipe.expire(key, self.window)\n\n    _, _, request_count, _ = pipe.execute()\n\n    remaining = max(0, self.max_requests - request_count)\n    reset_time = int(now + self.window)\n\n    return request_count <= self.max_requests, remaining, reset_time", "successors": []}]}], "simplified_code": "class RateLimiter:\n        self.max_requests = requests_per_minute\n\n        return request_count <= self.max_requests, remaining, reset_time", "blocks": [{"id": 1, "label": "class RateLimiter:\nself.max_requests = requests_per_minute", "successors": [{"id": 3, "label": "return request_count <= self.max_requests, remaining, reset_time", "successors": []}]}]}], "simplified_code": "import time\nfrom typing import Tuple\n\nfrom redis import Redis\n\nfrom .config import RATE_LIMIT_SETTINGS\n\n\n        return request_count <= self.max_requests, remaining, reset_time", "blocks": [{"id": 1, "label": "import time\nfrom typing import Tuple", "successors": [{"id": 3, "label": "from redis import Redis\nfrom .config import RATE_LIMIT_SETTINGS", "successors": [{"id": 5, "label": "return request_count <= self.max_requests, remaining, reset_time", "successors": []}]}]}]}
{"file_name": "169.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 110, "functions": [], "classes": [{"name": "CodeExtractionBlock", "type": "class", "start_line": 7, "end_line": 110, "functions": [{"name": "__init__", "type": "function", "start_line": 35, "end_line": 50, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"d3a7d896-3b78-4f44-8b4b-48fbf4f0bcd8\",\n            description=\"Extracts code blocks from text and identifies their programming languages\",\n            categories={BlockCategory.TEXT},\n            input_schema=CodeExtractionBlock.Input,\n            output_schema=CodeExtractionBlock.Output,\n            test_input={\n                \"text\": \"Here's a Python example:\\n```python\\nprint('Hello World')\\n```\\nAnd some HTML:\\n```html\\n<h1>Title</h1>\\n```\"\n            },\n            test_output=[\n                (\"html\", \"<h1>Title</h1>\"),\n                (\"python\", \"print('Hello World')\"),\n                (\"remaining_text\", \"Here's a Python example:\\nAnd some HTML:\"),\n            ],\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"d3a7d896-3b78-4f44-8b4b-48fbf4f0bcd8\",\n    description=\"Extracts code blocks from text and identifies their programming languages\",\n    categories={BlockCategory.TEXT},\n    input_schema=CodeExtractionBlock.Input,\n    output_schema=CodeExtractionBlock.Output,\n    test_input={\n        \"text\": \"Here's a Python example:\\n```python\\nprint('Hello World')\\n```\\nAnd some HTML:\\n```html\\n<h1>Title</h1>\\n```\"\n    },\n    test_output=[\n        (\"html\", \"<h1>Title</h1>\"),\n        (\"python\", \"print('Hello World')\"),\n        (\"remaining_text\", \"Here's a Python example:\\nAnd some HTML:\")\n    ],\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 52, "end_line": 100, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        # List of supported programming languages with mapped aliases\n        language_aliases = {\n            \"html\": [\"html\", \"htm\"],\n            \"css\": [\"css\"],\n            \"javascript\": [\"javascript\", \"js\"],\n            \"python\": [\"python\", \"py\"],\n            \"sql\": [\"sql\"],\n            \"java\": [\"java\"],\n            \"cpp\": [\"cpp\", \"c++\"],\n            \"csharp\": [\"csharp\", \"c#\", \"cs\"],\n            \"json_code\": [\"json\"],\n            \"bash\": [\"bash\", \"shell\", \"sh\"],\n            \"php\": [\"php\"],\n            \"ruby\": [\"ruby\", \"rb\"],\n            \"yaml\": [\"yaml\", \"yml\"],\n            \"markdown\": [\"markdown\", \"md\"],\n            \"typescript\": [\"typescript\", \"ts\"],\n            \"xml\": [\"xml\"],\n        }\n\n        # Extract code for each language\n        for canonical_name, aliases in language_aliases.items():\n            code = \"\"\n            # Try each alias for the language\n            for alias in aliases:\n                code_for_alias = self.extract_code(input_data.text, alias)\n                if code_for_alias:\n                    code = code + \"\\n\\n\" + code_for_alias if code else code_for_alias\n\n            if code:  # Only yield if there's actual code content\n                yield canonical_name, code\n\n        # Remove all code blocks from the text to get remaining text\n        pattern = (\n            r\"```(?:\"\n            + \"|\".join(\n                re.escape(alias)\n                for aliases in language_aliases.values()\n                for alias in aliases\n            )\n            + r\")\\s+[\\s\\S]*?```\"\n        )\n\n        remaining_text = re.sub(pattern, \"\", input_data.text).strip()\n        remaining_text = re.sub(r\"\\n\\s*\\n\", \"\\n\", remaining_text)\n\n        if remaining_text:  # Only yield if there's remaining text\n            yield \"remaining_text\", remaining_text", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\nlanguage_aliases = {\"html\": [\"html\", \"htm\"], \"css\": [\"css\"], \"javascript\": [\"javascript\", \"js\"], \"python\": [\"python\", \"py\"], \"sql\": [\"sql\"], \"java\": [\"java\"], \"cpp\": [\"cpp\", \"c++\"], \"csharp\": [\"csharp\", \"c#\", \"cs\"], \"json_code\": [\"json\"], \"bash\": [\"bash\", \"shell\", \"sh\"], \"php\": [\"php\"], \"ruby\": [\"ruby\", \"rb\"], \"yaml\": [\"yaml\", \"yml\"], \"markdown\": [\"markdown\", \"md\"], \"typescript\": [\"typescript\", \"ts\"], \"xml\": [\"xml\"]}", "successors": [{"id": 3, "label": "for canonical_name, aliases in language_aliases.items():", "successors": [{"id": 4, "label": "code = \"\"", "successors": [{"id": 5, "label": "for alias in aliases:", "successors": [{"id": 6, "label": "code_for_alias = self.extract_code(input_data.text, alias)\nif code_for_alias:", "successors": [{"id": 8, "label": "code = code + \"\\n\\n\" + code_for_alias if code else code_for_alias", "successors": []}]}]}, {"id": 9, "label": "if code:\nyield canonical_name, code", "successors": []}]}, {"id": 11, "label": "pattern = (r\"```(?:\" + \"|\".join(re.escape(alias) for aliases in language_aliases.values() for alias in aliases) + r\")\\s+[\\s\\S]*?```\")", "successors": [{"id": 12, "label": "remaining_text = re.sub(pattern, \"\", input_data.text).strip()\nremaining_text = re.sub(r\"\\n\\s*\\n\", \"\\n\", remaining_text)", "successors": []}, {"id": 14, "label": "if remaining_text:\nyield \"remaining_text\", remaining_text", "successors": []}]}]}]}]}, {"name": "extract_code", "type": "function", "start_line": 102, "end_line": 110, "functions": [], "classes": [], "simplified_code": "    def extract_code(self, text: str, language: str) -> str:\n        # Escape special regex characters in the language string\n        language = re.escape(language)\n        # Extract all code blocks enclosed in ```language``` blocks\n        pattern = re.compile(rf\"```{language}\\s+(.*?)```\", re.DOTALL | re.IGNORECASE)\n        matches = pattern.finditer(text)\n        # Combine all code blocks for this language with newlines between them\n        code_blocks = [match.group(1).strip() for match in matches]\n        return \"\\n\\n\".join(code_blocks) if code_blocks else \"\"", "blocks": [{"id": 1, "label": "def extract_code(self, text: str, language: str) -> str:\nlanguage = re.escape(language)", "successors": [{"id": 3, "label": "pattern = re.compile(rf\"```{language}\\s+(.*?)```\", re.DOTALL | re.IGNORECASE)\nmatches = pattern.finditer(text)", "successors": [{"id": 5, "label": "code_blocks = [match.group(1).strip() for match in matches]\nreturn \"\\n\\n\".join(code_blocks) if code_blocks else \"\"", "successors": []}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 8, "end_line": 12, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        text: str = SchemaField(\n            description=\"Text containing code blocks to extract (e.g., AI response)\",\n            placeholder=\"Enter text containing code blocks\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    text: str = SchemaField(description=\"Text containing code blocks to extract (e.g., AI response)\", placeholder=\"Enter text containing code blocks\")", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 14, "end_line": 33, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        html: str = SchemaField(description=\"Extracted HTML code\")\n        css: str = SchemaField(description=\"Extracted CSS code\")\n        javascript: str = SchemaField(description=\"Extracted JavaScript code\")\n        python: str = SchemaField(description=\"Extracted Python code\")\n        sql: str = SchemaField(description=\"Extracted SQL code\")\n        java: str = SchemaField(description=\"Extracted Java code\")\n        cpp: str = SchemaField(description=\"Extracted C++ code\")\n        csharp: str = SchemaField(description=\"Extracted C# code\")\n        json_code: str = SchemaField(description=\"Extracted JSON code\")\n        bash: str = SchemaField(description=\"Extracted Bash code\")\n        php: str = SchemaField(description=\"Extracted PHP code\")\n        ruby: str = SchemaField(description=\"Extracted Ruby code\")\n        yaml: str = SchemaField(description=\"Extracted YAML code\")\n        markdown: str = SchemaField(description=\"Extracted Markdown code\")\n        typescript: str = SchemaField(description=\"Extracted TypeScript code\")\n        xml: str = SchemaField(description=\"Extracted XML code\")\n        remaining_text: str = SchemaField(\n            description=\"Remaining text after code extraction\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    html: str = SchemaField(description=\"Extracted HTML code\")\n    css: str = SchemaField(description=\"Extracted CSS code\")\n    javascript: str = SchemaField(description=\"Extracted JavaScript code\")\n    python: str = SchemaField(description=\"Extracted Python code\")\n    sql: str = SchemaField(description=\"Extracted SQL code\")\n    java: str = SchemaField(description=\"Extracted Java code\")\n    cpp: str = SchemaField(description=\"Extracted C++ code\")\n    csharp: str = SchemaField(description=\"Extracted C# code\")\n    json_code: str = SchemaField(description=\"Extracted JSON code\")\n    bash: str = SchemaField(description=\"Extracted Bash code\")\n    php: str = SchemaField(description=\"Extracted PHP code\")\n    ruby: str = SchemaField(description=\"Extracted Ruby code\")\n    yaml: str = SchemaField(description=\"Extracted YAML code\")\n    markdown: str = SchemaField(description=\"Extracted Markdown code\")\n    typescript: str = SchemaField(description=\"Extracted TypeScript code\")\n    xml: str = SchemaField(description=\"Extracted XML code\")\n    remaining_text: str = SchemaField(\n        description=\"Remaining text after code extraction\"\n    )", "successors": []}]}], "simplified_code": "class CodeExtractionBlock(Block):\n        )\n\n        )\n\n        )\n\n            yield \"remaining_text\", remaining_text\n\n        return \"\\n\\n\".join(code_blocks) if code_blocks else \"\"", "blocks": [{"id": 1, "label": "class CodeExtractionBlock(Block):", "successors": [{"id": 2, "label": "yield \"remaining_text\", remaining_text", "successors": []}, {"id": 3, "label": "return \"\\n\\n\".join(code_blocks) if code_blocks else \"\"", "successors": []}]}]}], "simplified_code": "import re\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\n\n        return \"\\n\\n\".join(code_blocks) if code_blocks else \"\"", "blocks": [{"id": 1, "label": "import re\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\nreturn \"\\n\\n\".join(code_blocks) if code_blocks else \"\"", "successors": []}]}
{"file_name": "170.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 57, "functions": [], "classes": [{"name": "SpendingByCategory", "type": "class", "start_line": 6, "end_line": 53, "functions": [{"name": "__init__", "type": "function", "start_line": 8, "end_line": 10, "functions": [], "classes": [], "simplified_code": "    def __init__(self, categorizer):\n        self.categorizer = categorizer\n        ...", "blocks": [{"id": 1, "label": "def __init__(self, categorizer):\n    self.categorizer = categorizer\n    ...", "successors": []}]}, {"name": "current_year_month", "type": "function", "start_line": 12, "end_line": 14, "functions": [], "classes": [], "simplified_code": "    def current_year_month(self):\n        \"\"\"Return the current year and month.\"\"\"\n        ...", "blocks": [{"id": 1, "label": "def current_year_month(self):\n\"\"\"Return the current year and month.\"\"\"", "successors": [{"id": 3, "label": "...", "successors": []}]}]}, {"name": "extract_year_month", "type": "function", "start_line": 16, "end_line": 18, "functions": [], "classes": [], "simplified_code": "    def extract_year_month(self, timestamp):\n        \"\"\"Return the year and month portions of the timestamp.\"\"\"\n        ...", "blocks": [{"id": 1, "label": "def extract_year_month(self, timestamp):", "successors": [{"id": 2, "label": "\"\"\"Return the year and month portions of the timestamp.\"\"\"", "successors": []}, {"id": 3, "label": "...", "successors": []}]}]}, {"name": "handle_budget_notifications", "type": "function", "start_line": 20, "end_line": 22, "functions": [], "classes": [], "simplified_code": "    def handle_budget_notifications(self, key, total):\n        \"\"\"Call notification API if nearing or exceeded budget.\"\"\"\n        ...", "blocks": [{"id": 1, "label": "def handle_budget_notifications(self, key, total):\n\"\"\"Call notification API if nearing or exceeded budget.\"\"\"", "successors": [{"id": 3, "label": "...", "successors": []}]}]}, {"name": "mapper", "type": "function", "start_line": 24, "end_line": 36, "functions": [], "classes": [], "simplified_code": "    def mapper(self, _, line):\n        \"\"\"Parse each log line, extract and transform relevant lines.\n\n        Emit key value pairs of the form:\n\n        (2016-01, shopping), 25\n        (2016-01, shopping), 100\n        (2016-01, gas), 50\n        \"\"\"\n        timestamp, category, amount = line.split('\\t')\n        period = self. extract_year_month(timestamp)\n        if period == self.current_year_month():\n            yield (period, category), amount", "blocks": [{"id": 1, "label": "def mapper(self, _, line):\n\"\"\"Parse each log line, extract and transform relevant lines.\n\n        Emit key value pairs of the form:\n\n        (2016-01, shopping), 25\n        (2016-01, shopping), 100\n        (2016-01, gas), 50\n        \"\"\"\ntimestamp, category, amount = line.split('\\t')\nperiod = self. extract_year_month(timestamp)", "successors": [{"id": 3, "label": "if period == self.current_year_month():\nyield (period, category), amount", "successors": []}]}]}, {"name": "reducer", "type": "function", "start_line": 38, "end_line": 46, "functions": [], "classes": [], "simplified_code": "    def reducer(self, key, values):\n        \"\"\"Sum values for each key.\n\n        (2016-01, shopping), 125\n        (2016-01, gas), 50\n        \"\"\"\n        total = sum(values)\n        self.handle_budget_notifications(key, total)\n        yield key, sum(values)", "blocks": [{"id": 1, "label": "def reducer(self, key, values):\n\"\"\"Sum values for each key.\n\n(2016-01, shopping), 125\n(2016-01, gas), 50\n\"\"\"\ntotal = sum(values)\nself.handle_budget_notifications(key, total)\nyield key, sum(values)", "successors": []}]}, {"name": "steps", "type": "function", "start_line": 48, "end_line": 53, "functions": [], "classes": [], "simplified_code": "    def steps(self):\n        \"\"\"Run the map and reduce steps.\"\"\"\n        return [\n            self.mr(mapper=self.mapper,\n                    reducer=self.reducer)\n        ]", "blocks": [{"id": 1, "label": "def steps(self):\n    \"\"\"Run the map and reduce steps.\"\"\"", "successors": [{"id": 3, "label": "    return [\n        self.mr(mapper=self.mapper,", "successors": [{"id": 5, "label": "                reducer=self.reducer)\n    ]", "successors": []}]}]}]}], "classes": [], "simplified_code": "class SpendingByCategory(MRJob):\n\n        ...\n\n        ...\n\n        ...\n\n        ...\n\n            yield (period, category), amount\n\n        yield key, sum(values)\n\n        ]", "blocks": [{"id": 1, "label": "class SpendingByCategory(MRJob):\n...", "successors": []}]}], "simplified_code": "# -*- coding: utf-8 -*-\n\nfrom mrjob.job import MRJob\n\n\n        ]\n\n\nif __name__ == '__main__':\n    SpendingByCategory.run()", "blocks": [{"id": 1, "label": "from mrjob.job import MRJob\nif __name__ == '__main__':", "successors": [{"id": 3, "label": "    SpendingByCategory.run()", "successors": []}]}]}
{"file_name": "171.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 276, "functions": [{"name": "expose", "type": "function", "start_line": 51, "end_line": 70, "functions": [{"name": "wrapper", "type": "function", "start_line": 60, "end_line": 66, "functions": [], "classes": [], "simplified_code": "    def wrapper(*args, **kwargs):\n        try:\n            return func(*args, **kwargs)\n        except Exception as e:\n            msg = f\"Error in {func.__name__}: {e.__str__()}\"\n            logger.exception(msg)\n            raise", "blocks": [{"id": 1, "label": "def wrapper(*args, **kwargs):\ntry:", "successors": [{"id": 3, "label": "return func(*args, **kwargs)", "successors": []}, {"id": 4, "label": "except Exception as e:\nmsg = f\"Error in {func.__name__}: {e.__str__()}\"", "successors": [{"id": 6, "label": "logger.exception(msg)\nraise", "successors": []}]}]}]}], "classes": [], "simplified_code": "def expose(func: C) -> C:\n    \"\"\"\n    Decorator to mark a method or class to be exposed for remote calls.\n\n    ## \u26a0\ufe0f Gotcha\n    Aside from \"simple\" types, only Pydantic models are passed unscathed *if annotated*.\n    Any other passed or returned class objects are converted to dictionaries by Pyro.\n    \"\"\"\n\n            raise\n\n    register_pydantic_serializers(func)\n\n    return pyro.expose(wrapper)  # type: ignore", "blocks": [{"id": 1, "label": "def expose(func: C) -> C:\n\"\"\"\nDecorator to mark a method or class to be exposed for remote calls.\n\n## \u26a0\ufe0f Gotcha\nAside from \"simple\" types, only Pydantic models are passed unscathed *if annotated*.\nAny other passed or returned class objects are converted to dictionaries by Pyro.\n\"\"\"", "successors": [{"id": 3, "label": "raise", "successors": []}, {"id": 4, "label": "register_pydantic_serializers(func)\nreturn pyro.expose(wrapper)  # type: ignore", "successors": []}]}]}, {"name": "register_pydantic_serializers", "type": "function", "start_line": 73, "end_line": 89, "functions": [], "classes": [], "simplified_code": "def register_pydantic_serializers(func: Callable):\n    \"\"\"Register custom serializers and deserializers for annotated Pydantic models\"\"\"\n    for name, annotation in func.__annotations__.items():\n        try:\n            pydantic_types = _pydantic_models_from_type_annotation(annotation)\n        except Exception as e:\n            raise TypeError(f\"Error while exposing {func.__name__}: {e.__str__()}\")\n\n        for model in pydantic_types:\n            logger.debug(\n                f\"Registering Pyro (de)serializers for {func.__name__} annotation \"\n                f\"'{name}': {model.__qualname__}\"\n            )\n            pyro.register_class_to_dict(model, _make_custom_serializer(model))\n            pyro.register_dict_to_class(\n                model.__qualname__, _make_custom_deserializer(model)\n            )", "blocks": [{"id": 1, "label": "def register_pydantic_serializers(func: Callable):", "successors": [{"id": 2, "label": "for name, annotation in func.__annotations__.items():", "successors": [{"id": 3, "label": "try:", "successors": [{"id": 4, "label": "pydantic_types = _pydantic_models_from_type_annotation(annotation)", "successors": [{"id": 6, "label": "for model in pydantic_types:", "successors": [{"id": 7, "label": "logger.debug( f\"Registering Pyro (de)serializers for {func.__name__} annotation '{name}': {model.__qualname__}\" )\npyro.register_class_to_dict(model, _make_custom_serializer(model))", "successors": [{"id": 9, "label": "pyro.register_dict_to_class( model.__qualname__, _make_custom_deserializer(model) )", "successors": []}]}]}]}, {"id": 5, "label": "except Exception as e:\nraise TypeError(f\"Error while exposing {func.__name__}: {e.__str__()}\")", "successors": []}]}]}]}]}, {"name": "_make_custom_serializer", "type": "function", "start_line": 92, "end_line": 101, "functions": [{"name": "custom_class_to_dict", "type": "function", "start_line": 93, "end_line": 99, "functions": [], "classes": [], "simplified_code": "    def custom_class_to_dict(obj):\n        data = {\n            \"__class__\": obj.__class__.__qualname__,\n            **obj.model_dump(),\n        }\n        logger.debug(f\"Serializing {obj.__class__.__qualname__} with data: {data}\")\n        return data", "blocks": [{"id": 1, "label": "def custom_class_to_dict(obj):\n    data = {\n        \"__class__\": obj.__class__.__qualname__,\n        **obj.model_dump(),\n    }", "successors": [{"id": 3, "label": "    logger.debug(f\"Serializing {obj.__class__.__qualname__} with data: {data}\")\n    return data", "successors": []}]}]}], "classes": [], "simplified_code": "def _make_custom_serializer(model: Type[BaseModel]):\n        return data\n\n    return custom_class_to_dict", "blocks": [{"id": 1, "label": "def _make_custom_serializer(model: Type[BaseModel]):\n    return data", "successors": []}]}, {"name": "_make_custom_deserializer", "type": "function", "start_line": 104, "end_line": 109, "functions": [{"name": "custom_dict_to_class", "type": "function", "start_line": 105, "end_line": 107, "functions": [], "classes": [], "simplified_code": "    def custom_dict_to_class(qualname, data: dict):\n        logger.debug(f\"Deserializing {model.__qualname__} from data: {data}\")\n        return model(**data)", "blocks": [{"id": 1, "label": "def custom_dict_to_class(qualname, data: dict):\nlogger.debug(f\"Deserializing {model.__qualname__} from data: {data}\")", "successors": [{"id": 3, "label": "return model(**data)", "successors": []}]}]}], "classes": [], "simplified_code": "def _make_custom_deserializer(model: Type[BaseModel]):\n        return model(**data)\n\n    return custom_dict_to_class", "blocks": [{"id": 1, "label": "def _make_custom_deserializer(model: Type[BaseModel]):\n    return model(**data)", "successors": []}]}, {"name": "close_service_client", "type": "function", "start_line": 203, "end_line": 207, "functions": [], "classes": [], "simplified_code": "def close_service_client(client: AppService) -> None:\n    if isinstance(client, PyroClient):\n        client.proxy._pyroRelease()\n    else:\n        raise RuntimeError(f\"Client {client.__class__} is not a Pyro client.\")", "blocks": [{"id": 1, "label": "def close_service_client(client: AppService) -> None:\nif isinstance(client, PyroClient):", "successors": [{"id": 3, "label": "    client.proxy._pyroRelease()", "successors": []}, {"id": 4, "label": "else:\n    raise RuntimeError(f\"Client {client.__class__} is not a Pyro client.\")", "successors": []}]}]}, {"name": "get_service_client", "type": "function", "start_line": 210, "end_line": 228, "functions": [], "classes": [{"name": "DynamicClient", "type": "class", "start_line": 213, "end_line": 228, "functions": [{"name": "__init__", "type": "function", "start_line": 215, "end_line": 222, "functions": [], "classes": [], "simplified_code": "        def __init__(self):\n            host = os.environ.get(f\"{service_name.upper()}_HOST\", pyro_host)\n            uri = f\"PYRO:{service_type.service_name}@{host}:{service_type.get_port()}\"\n            logger.debug(f\"Connecting to service [{service_name}]. URI = {uri}\")\n            self.proxy = Pyro5.api.Proxy(uri)\n            # Attempt to bind to ensure the connection is established\n            self.proxy._pyroBind()\n            logger.debug(f\"Successfully connected to service [{service_name}]\")", "blocks": [{"id": 1, "label": "def __init__(self):\nhost = os.environ.get(f\"{service_name.upper()}_HOST\", pyro_host)\nuri = f\"PYRO:{service_type.service_name}@{host}:{service_type.get_port()}\"\nlogger.debug(f\"Connecting to service [{service_name}]. URI = {uri}\")\nself.proxy = Pyro5.api.Proxy(uri)", "successors": [{"id": 3, "label": "self.proxy._pyroBind()\nlogger.debug(f\"Successfully connected to service [{service_name}]\")", "successors": []}]}]}, {"name": "__getattr__", "type": "function", "start_line": 224, "end_line": 226, "functions": [], "classes": [], "simplified_code": "        def __getattr__(self, name: str) -> Callable[..., Any]:\n            res = getattr(self.proxy, name)\n            return res", "blocks": [{"id": 1, "label": "def __getattr__(self, name: str) -> Callable[..., Any]:\n    res = getattr(self.proxy, name)", "successors": [{"id": 3, "label": "    return res", "successors": []}]}]}], "classes": [], "simplified_code": "    class DynamicClient(PyroClient):\n        @conn_retry(\"Pyro\", f\"Connecting to [{service_name}]\")\n            logger.debug(f\"Successfully connected to service [{service_name}]\")\n\n            return res\n\n    return cast(AS, DynamicClient())", "blocks": [{"id": 1, "label": "class DynamicClient(PyroClient):\n@conn_retry(\"Pyro\", f\"Connecting to [{service_name}]\")", "successors": [{"id": 3, "label": "logger.debug(f\"Successfully connected to service [{service_name}]\")\nreturn res", "successors": []}]}]}], "simplified_code": "def get_service_client(service_type: Type[AS]) -> AS:\n    service_name = service_type.service_name\n\n    return cast(AS, DynamicClient())", "blocks": [{"id": 1, "label": "def get_service_client(service_type: Type[AS]) -> AS:\n service_name = service_type.service_name\nreturn cast(AS, DynamicClient())", "successors": []}]}, {"name": "_pydantic_models_from_type_annotation", "type": "function", "start_line": 234, "end_line": 276, "functions": [], "classes": [], "simplified_code": "def _pydantic_models_from_type_annotation(annotation) -> Iterator[type[BaseModel]]:\n    # Peel Annotated parameters\n    if (origin := get_origin(annotation)) and origin is Annotated:\n        annotation = get_args(annotation)[0]\n\n    origin = get_origin(annotation)\n    args = get_args(annotation)\n\n    if origin in (\n        Union,\n        UnionType,\n        list,\n        List,\n        tuple,\n        Tuple,\n        set,\n        Set,\n        frozenset,\n        FrozenSet,\n    ):\n        for arg in args:\n            yield from _pydantic_models_from_type_annotation(arg)\n    elif origin in (dict, Dict):\n        key_type, value_type = args\n        yield from _pydantic_models_from_type_annotation(key_type)\n        yield from _pydantic_models_from_type_annotation(value_type)\n    elif origin in (Awaitable, Coroutine):\n        # For coroutines and awaitables, check the return type\n        return_type = args[-1]\n        yield from _pydantic_models_from_type_annotation(return_type)\n    else:\n        annotype = annotation if origin is None else origin\n\n        # Exclude generic types and aliases\n        if (\n            annotype is not None\n            and not hasattr(typing, getattr(annotype, \"__name__\", \"\"))\n            and isinstance(annotype, type)\n        ):\n            if issubclass(annotype, BaseModel):\n                yield annotype\n            elif annotype not in builtin_types and not issubclass(annotype, Enum):\n                raise TypeError(f\"Unsupported type encountered: {annotype}\")", "blocks": [{"id": 1, "label": "def _pydantic_models_from_type_annotation(annotation) -> Iterator[type[BaseModel]]:\n    if (origin := get_origin(annotation)) and origin is Annotated:", "successors": [{"id": 3, "label": "        annotation = get_args(annotation)[0]\n    origin = get_origin(annotation)\n    args = get_args(annotation)", "successors": [{"id": 5, "label": "    if origin in (Union, UnionType, list, List, tuple, Tuple, set, Set, frozenset, FrozenSet):", "successors": [{"id": 6, "label": "        for arg in args:\n            yield from _pydantic_models_from_type_annotation(arg)", "successors": [{"id": 10, "label": "else:\n    annotype = annotation if origin is None else origin", "successors": [{"id": 12, "label": "    if (annotype is not None\n        and not hasattr(typing, getattr(annotype, \"__name__\", \"\"))\n        and isinstance(annotype, type)):\n        if issubclass(annotype, BaseModel):", "successors": [{"id": 14, "label": "            yield annotype", "successors": []}, {"id": 15, "label": "elif annotype not in builtin_types and not issubclass(annotype, Enum):\n                raise TypeError(f\"Unsupported type encountered: {annotype}\")", "successors": []}]}]}]}, {"id": 7, "label": "elif origin in (dict, Dict):\n        key_type, value_type = args\n        yield from _pydantic_models_from_type_annotation(key_type)\n        yield from _pydantic_models_from_type_annotation(value_type)", "successors": [{"id": 10, "label": "else:\n    annotype = annotation if origin is None else origin", "successors": [{"id": 12, "label": "    if (annotype is not None\n        and not hasattr(typing, getattr(annotype, \"__name__\", \"\"))\n        and isinstance(annotype, type)):\n        if issubclass(annotype, BaseModel):", "successors": [{"id": 14, "label": "            yield annotype", "successors": []}, {"id": 15, "label": "elif annotype not in builtin_types and not issubclass(annotype, Enum):\n                raise TypeError(f\"Unsupported type encountered: {annotype}\")", "successors": []}]}]}]}, {"id": 9, "label": "elif origin in (Awaitable, Coroutine):\n        return_type = args[-1]\n        yield from _pydantic_models_from_type_annotation(return_type)", "successors": [{"id": 10, "label": "else:\n    annotype = annotation if origin is None else origin", "successors": [{"id": 12, "label": "    if (annotype is not None\n        and not hasattr(typing, getattr(annotype, \"__name__\", \"\"))\n        and isinstance(annotype, type)):\n        if issubclass(annotype, BaseModel):", "successors": [{"id": 14, "label": "            yield annotype", "successors": []}, {"id": 15, "label": "elif annotype not in builtin_types and not issubclass(annotype, Enum):\n                raise TypeError(f\"Unsupported type encountered: {annotype}\")", "successors": []}]}]}]}]}]}]}]}], "classes": [{"name": "AppService", "type": "class", "start_line": 112, "end_line": 190, "functions": [{"name": "__init__", "type": "function", "start_line": 118, "end_line": 119, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        self.uri = None", "blocks": [{"id": 1, "label": "def __init__(self):\n    self.uri = None", "successors": []}]}, {"name": "get_port", "type": "function", "start_line": 123, "end_line": 124, "functions": [], "classes": [], "simplified_code": "    def get_port(cls) -> int:\n        pass", "blocks": [{"id": 1, "label": "def get_port(cls) -> int:\npass", "successors": []}]}, {"name": "get_host", "type": "function", "start_line": 127, "end_line": 128, "functions": [], "classes": [], "simplified_code": "    def get_host(cls) -> str:\n        return os.environ.get(f\"{cls.service_name.upper()}_HOST\", config.pyro_host)", "blocks": [{"id": 1, "label": "def get_host(cls) -> str:\n    return os.environ.get(f\"{cls.service_name.upper()}_HOST\", config.pyro_host)", "successors": []}]}, {"name": "run_service", "type": "function", "start_line": 130, "end_line": 132, "functions": [], "classes": [], "simplified_code": "    def run_service(self) -> None:\n        while True:\n            time.sleep(10)", "blocks": [{"id": 1, "label": "def run_service(self) -> None:", "successors": [{"id": 2, "label": "while True:", "successors": [{"id": 3, "label": "    time.sleep(10)", "successors": [{"id": 2, "label": "while True:", "successors": []}]}]}]}]}, {"name": "__run_async", "type": "function", "start_line": 134, "end_line": 135, "functions": [], "classes": [], "simplified_code": "    def __run_async(self, coro: Coroutine[Any, Any, T]):\n        return asyncio.run_coroutine_threadsafe(coro, self.shared_event_loop)", "blocks": [{"id": 1, "label": "def __run_async(self, coro: Coroutine[Any, Any, T]):\nreturn asyncio.run_coroutine_threadsafe(coro, self.shared_event_loop)", "successors": []}]}, {"name": "run_and_wait", "type": "function", "start_line": 137, "end_line": 139, "functions": [], "classes": [], "simplified_code": "    def run_and_wait(self, coro: Coroutine[Any, Any, T]) -> T:\n        future = self.__run_async(coro)\n        return future.result()", "blocks": [{"id": 1, "label": "def run_and_wait(self, coro: Coroutine[Any, Any, T]) -> T:\n    future = self.__run_async(coro)", "successors": [{"id": 3, "label": "    return future.result()", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 141, "end_line": 166, "functions": [], "classes": [], "simplified_code": "    def run(self):\n        self.shared_event_loop = asyncio.get_event_loop()\n        if self.use_db:\n            self.shared_event_loop.run_until_complete(db.connect())\n        if self.use_redis:\n            redis.connect()\n        if self.use_supabase:\n            from supabase import create_client\n\n            secrets = Secrets()\n            self.supabase = create_client(\n                secrets.supabase_url, secrets.supabase_service_role_key\n            )\n\n        # Initialize the async loop.\n        async_thread = threading.Thread(target=self.__start_async_loop)\n        async_thread.daemon = True\n        async_thread.start()\n\n        # Initialize pyro service\n        daemon_thread = threading.Thread(target=self.__start_pyro)\n        daemon_thread.daemon = True\n        daemon_thread.start()\n\n        # Run the main service (if it's not implemented, just sleep).\n        self.run_service()", "blocks": [{"id": 1, "label": "def run(self):\nself.shared_event_loop = asyncio.get_event_loop()", "successors": [{"id": 3, "label": "if self.use_db:", "successors": [{"id": 4, "label": "self.shared_event_loop.run_until_complete(db.connect())\nif self.use_redis:", "successors": [{"id": 8, "label": "redis.connect()", "successors": [{"id": 13, "label": "if self.use_supabase:\nfrom supabase import create_client\n\n            secrets = Secrets()\n            self.supabase = create_client(\n                secrets.supabase_url, secrets.supabase_service_role_key\n            )", "successors": [{"id": 21, "label": "async_thread = threading.Thread(target=self.__start_async_loop)\n        async_thread.daemon = True\n        async_thread.start()\ndaemon_thread = threading.Thread(target=self.__start_pyro)\n        daemon_thread.daemon = True\n        daemon_thread.start()", "successors": [{"id": 23, "label": "self.run_service()", "successors": []}]}]}, {"id": 21, "label": "async_thread = threading.Thread(target=self.__start_async_loop)\n        async_thread.daemon = True\n        async_thread.start()\ndaemon_thread = threading.Thread(target=self.__start_pyro)\n        daemon_thread.daemon = True\n        daemon_thread.start()", "successors": [{"id": 23, "label": "self.run_service()", "successors": []}]}]}]}, {"id": 13, "label": "if self.use_supabase:\nfrom supabase import create_client\n\n            secrets = Secrets()\n            self.supabase = create_client(\n                secrets.supabase_url, secrets.supabase_service_role_key\n            )", "successors": [{"id": 21, "label": "async_thread = threading.Thread(target=self.__start_async_loop)\n        async_thread.daemon = True\n        async_thread.start()\ndaemon_thread = threading.Thread(target=self.__start_pyro)\n        daemon_thread.daemon = True\n        daemon_thread.start()", "successors": [{"id": 23, "label": "self.run_service()", "successors": []}]}]}, {"id": 21, "label": "async_thread = threading.Thread(target=self.__start_async_loop)\n        async_thread.daemon = True\n        async_thread.start()\ndaemon_thread = threading.Thread(target=self.__start_pyro)\n        daemon_thread.daemon = True\n        daemon_thread.start()", "successors": [{"id": 23, "label": "self.run_service()", "successors": []}]}]}]}]}, {"name": "cleanup", "type": "function", "start_line": 168, "end_line": 174, "functions": [], "classes": [], "simplified_code": "    def cleanup(self):\n        if self.use_db:\n            logger.info(f\"[{self.__class__.__name__}] \u23f3 Disconnecting DB...\")\n            self.run_and_wait(db.disconnect())\n        if self.use_redis:\n            logger.info(f\"[{self.__class__.__name__}] \u23f3 Disconnecting Redis...\")\n            redis.disconnect()", "blocks": [{"id": 1, "label": "def cleanup(self):\nif self.use_db:", "successors": [{"id": 3, "label": "    logger.info(f\"[{self.__class__.__name__}] \u23f3 Disconnecting DB...\")\n    self.run_and_wait(db.disconnect())\nif self.use_redis:", "successors": [{"id": 6, "label": "    logger.info(f\"[{self.__class__.__name__}] \u23f3 Disconnecting Redis...\")\n    redis.disconnect()", "successors": []}]}, {"id": 4, "label": "if self.use_redis:\n    logger.info(f\"[{self.__class__.__name__}] \u23f3 Disconnecting Redis...\")\n    redis.disconnect()", "successors": []}]}]}, {"name": "__start_pyro", "type": "function", "start_line": 177, "end_line": 187, "functions": [], "classes": [], "simplified_code": "    def __start_pyro(self):\n        maximum_connection_thread_count = max(\n            Pyro5.config.THREADPOOL_SIZE,\n            config.num_node_workers * config.num_graph_workers,\n        )\n\n        Pyro5.config.THREADPOOL_SIZE = maximum_connection_thread_count  # type: ignore\n        daemon = Pyro5.api.Daemon(host=config.pyro_host, port=self.get_port())\n        self.uri = daemon.register(self, objectId=self.service_name)\n        logger.info(f\"[{self.service_name}] Connected to Pyro; URI = {self.uri}\")\n        daemon.requestLoop()", "blocks": [{"id": 1, "label": "def __start_pyro(self):\nmaximum_connection_thread_count = max(\n    Pyro5.config.THREADPOOL_SIZE,\n    config.num_node_workers * config.num_graph_workers,\n)", "successors": [{"id": 3, "label": "Pyro5.config.THREADPOOL_SIZE = maximum_connection_thread_count  # type: ignore\ndaemon = Pyro5.api.Daemon(host=config.pyro_host, port=self.get_port())", "successors": [{"id": 5, "label": "self.uri = daemon.register(self, objectId=self.service_name)\nlogger.info(f\"[{self.service_name}] Connected to Pyro; URI = {self.uri}\")", "successors": [{"id": 7, "label": "daemon.requestLoop()", "successors": []}]}]}]}]}, {"name": "__start_async_loop", "type": "function", "start_line": 189, "end_line": 190, "functions": [], "classes": [], "simplified_code": "    def __start_async_loop(self):\n        self.shared_event_loop.run_forever()", "blocks": [{"id": 1, "label": "def __start_async_loop(self):\n    self.shared_event_loop.run_forever()", "successors": []}]}], "classes": [], "simplified_code": "class AppService(AppProcess, ABC):\n    shared_event_loop: asyncio.AbstractEventLoop\n    use_db: bool = False\n    use_redis: bool = False\n    use_supabase: bool = False\n\n        self.uri = None\n\n    @classmethod\n    @abstractmethod\n        pass\n\n    @classmethod\n        return os.environ.get(f\"{cls.service_name.upper()}_HOST\", config.pyro_host)\n\n            time.sleep(10)\n\n        return asyncio.run_coroutine_threadsafe(coro, self.shared_event_loop)\n\n        return future.result()\n\n        self.run_service()\n\n            redis.disconnect()\n\n    @conn_retry(\"Pyro\", \"Starting Pyro Service\")\n        daemon.requestLoop()\n\n        self.shared_event_loop.run_forever()", "blocks": [{"id": 1, "label": "class AppService(AppProcess, ABC):", "successors": [{"id": 2, "label": "shared_event_loop: asyncio.AbstractEventLoop\nuse_db: bool = False\nuse_redis: bool = False\nuse_supabase: bool = False\n\nself.uri = None", "successors": []}, {"id": 3, "label": "@classmethod\n@abstractmethod\npass", "successors": []}, {"id": 4, "label": "@classmethod\nreturn os.environ.get(f\"{cls.service_name.upper()}_HOST\", config.pyro_host)", "successors": []}, {"id": 5, "label": "time.sleep(10)", "successors": []}, {"id": 6, "label": "return asyncio.run_coroutine_threadsafe(coro, self.shared_event_loop)", "successors": []}, {"id": 7, "label": "return future.result()", "successors": []}, {"id": 8, "label": "self.run_service()", "successors": []}, {"id": 9, "label": "redis.disconnect()", "successors": []}, {"id": 10, "label": "@conn_retry(\"Pyro\", \"Starting Pyro Service\")\ndaemon.requestLoop()", "successors": []}, {"id": 11, "label": "self.shared_event_loop.run_forever()", "successors": []}]}]}, {"name": "PyroClient", "type": "class", "start_line": 199, "end_line": 202, "functions": [], "classes": [], "simplified_code": "class PyroClient:\n    proxy: Pyro5.api.Proxy\n\n", "blocks": []}], "simplified_code": "import asyncio\nimport builtins\nimport logging\nimport os\nimport threading\nimport time\nimport typing\nfrom abc import ABC, abstractmethod\nfrom enum import Enum\nfrom types import NoneType, UnionType\nfrom typing import (\n    Annotated,\n    Any,\n    Awaitable,\n    Callable,\n    Coroutine,\n    Dict,\n    FrozenSet,\n    Iterator,\n    List,\n    Set,\n    Tuple,\n    Type,\n    TypeVar,\n    Union,\n    cast,\n    get_args,\n    get_origin,\n)\n\nimport Pyro5.api\nfrom pydantic import BaseModel\nfrom Pyro5 import api as pyro\nfrom Pyro5 import config as pyro_config\n\nfrom backend.data import db, redis\nfrom backend.util.process import AppProcess\nfrom backend.util.retry import conn_retry\nfrom backend.util.settings import Config, Secrets\n\nlogger = logging.getLogger(__name__)\nT = TypeVar(\"T\")\nC = TypeVar(\"C\", bound=Callable)\n\nconfig = Config()\npyro_host = config.pyro_host\npyro_config.MAX_RETRIES = config.pyro_client_comm_retry  # type: ignore\npyro_config.COMMTIMEOUT = config.pyro_client_comm_timeout  # type: ignore\n\n\n    return pyro.expose(wrapper)  # type: ignore\n\n\n            )\n\n\n    return custom_class_to_dict\n\n\n    return custom_dict_to_class\n\n\n        self.shared_event_loop.run_forever()\n\n\n# --------- UTILITIES --------- #\n\n\nAS = TypeVar(\"AS\", bound=AppService)\n\n\n\n        raise RuntimeError(f\"Client {client.__class__} is not a Pyro client.\")\n\n\n    return cast(AS, DynamicClient())\n\n\nbuiltin_types = [*vars(builtins).values(), NoneType, Enum]\n\n\n                raise TypeError(f\"Unsupported type encountered: {annotype}\")", "blocks": [{"id": 1, "label": "import asyncio\nimport builtins\nimport logging\nimport os\nimport threading\nimport time\nimport typing\nfrom abc import ABC, abstractmethod\nfrom enum import Enum\nfrom types import NoneType, UnionType\nfrom typing import (\n    Annotated,\n    Any,\n    Awaitable,\n    Callable,\n    Coroutine,\n    Dict,\n    FrozenSet,\n    Iterator,\n    List,\n    Set,\n    Tuple,\n    Type,\n    TypeVar,\n    Union,\n    cast,\n    get_args,\n    get_origin,\n)\n\nimport Pyro5.api\nfrom pydantic import BaseModel\nfrom Pyro5 import api as pyro\nfrom Pyro5 import config as pyro_config\n\nfrom backend.data import db, redis\nfrom backend.util.process import AppProcess\nfrom backend.util.retry import conn_retry\nfrom backend.util.settings import Config, Secrets\n\nlogger = logging.getLogger(__name__)\nT = TypeVar(\"T\")\nC = TypeVar(\"C\", bound=Callable)", "successors": [{"id": 2, "label": "config = Config()\npyro_host = config.pyro_host\npyro_config.MAX_RETRIES = config.pyro_client_comm_retry  # type: ignore\npyro_config.COMMTIMEOUT = config.pyro_client_comm_timeout  # type: ignore", "successors": [{"id": 3, "label": "return pyro.expose(wrapper)  # type: ignore", "successors": []}, {"id": 4, "label": "return custom_class_to_dict", "successors": []}, {"id": 5, "label": "return custom_dict_to_class", "successors": []}, {"id": 6, "label": "self.shared_event_loop.run_forever()", "successors": []}]}, {"id": 7, "label": "raise RuntimeError(f\"Client {client.__class__} is not a Pyro client.\")\nreturn cast(AS, DynamicClient())", "successors": []}, {"id": 9, "label": "builtin_types = [*vars(builtins).values(), NoneType, Enum]\nraise TypeError(f\"Unsupported type encountered: {annotype}\")", "successors": []}]}]}
{"file_name": "172.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 257, "functions": [{"name": "get_pid_path", "type": "function", "start_line": 15, "end_line": 19, "functions": [], "classes": [], "simplified_code": "def get_pid_path() -> pathlib.Path:\n    home_dir = pathlib.Path.home()\n    new_dir = home_dir / \".config\" / \"agpt\"\n    file_path = new_dir / \"running.tmp\"\n    return file_path", "blocks": [{"id": 1, "label": "def get_pid_path() -> pathlib.Path:\nhome_dir = pathlib.Path.home()\nnew_dir = home_dir / \".config\" / \"agpt\"\nfile_path = new_dir / \"running.tmp\"", "successors": [{"id": 3, "label": "return file_path", "successors": []}]}]}, {"name": "get_pid", "type": "function", "start_line": 22, "end_line": 33, "functions": [], "classes": [], "simplified_code": "def get_pid() -> int | None:\n    file_path = get_pid_path()\n    if not file_path.exists():\n        return None\n\n    os.makedirs(file_path.parent, exist_ok=True)\n    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n        pid = file.read()\n    try:\n        return int(pid)\n    except ValueError:\n        return None", "blocks": [{"id": 1, "label": "def get_pid() -> int | None:\n    file_path = get_pid_path()\n    if not file_path.exists():", "successors": [{"id": 2, "label": "    return None", "successors": []}, {"id": 3, "label": "    os.makedirs(file_path.parent, exist_ok=True)\n    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n        pid = file.read()\ntry:\n        return int(pid)", "successors": [{"id": 5, "label": "except ValueError:\n        return None", "successors": []}]}]}]}, {"name": "write_pid", "type": "function", "start_line": 36, "end_line": 40, "functions": [], "classes": [], "simplified_code": "def write_pid(pid: int):\n    file_path = get_pid_path()\n    os.makedirs(file_path.parent, exist_ok=True)\n    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n        file.write(str(pid))", "blocks": [{"id": 1, "label": "def write_pid(pid: int):\n    file_path = get_pid_path()\n    os.makedirs(file_path.parent, exist_ok=True)", "successors": [{"id": 3, "label": "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n        file.write(str(pid))", "successors": []}]}]}, {"name": "main", "type": "function", "start_line": 49, "end_line": 51, "functions": [], "classes": [], "simplified_code": "def main():\n    \"\"\"AutoGPT Server CLI Tool\"\"\"\n    pass", "blocks": [{"id": 1, "label": "def main():\n\"\"\"AutoGPT Server CLI Tool\"\"\"\npass", "successors": []}]}, {"name": "start", "type": "function", "start_line": 55, "end_line": 74, "functions": [], "classes": [], "simplified_code": "def start():\n    \"\"\"\n    Starts the server in the background and saves the PID\n    \"\"\"\n    # Define the path for the new directory and file\n    pid = get_pid()\n    if pid and psutil.pid_exists(pid):\n        print(\"Server is already running\")\n        exit(1)\n    elif pid:\n        print(\"PID does not exist deleting file\")\n        os.remove(get_pid_path())\n\n    print(\"Starting server\")\n    pid = MainApp().start(background=True, silent=True)\n    print(f\"Server running in process: {pid}\")\n\n    write_pid(pid)\n    print(\"done\")\n    os._exit(status=0)", "blocks": [{"id": 1, "label": "def start():\npid = get_pid()", "successors": [{"id": 3, "label": "if pid and psutil.pid_exists(pid):", "successors": [{"id": 4, "label": "    print(\"Server is already running\")\n    exit(1)", "successors": []}, {"id": 5, "label": "elif pid:\n    print(\"PID does not exist deleting file\")\n    os.remove(get_pid_path())", "successors": [{"id": 7, "label": "print(\"Starting server\")\npid = MainApp().start(background=True, silent=True)\nprint(f\"Server running in process: {pid}\")\n\nwrite_pid(pid)\nprint(\"done\")\nos._exit(status=0)", "successors": []}]}]}]}]}, {"name": "stop", "type": "function", "start_line": 78, "end_line": 93, "functions": [], "classes": [], "simplified_code": "def stop():\n    \"\"\"\n    Stops the server\n    \"\"\"\n    pid = get_pid()\n    if not pid:\n        print(\"Server is not running\")\n        return\n\n    os.remove(get_pid_path())\n    process = psutil.Process(int(pid))\n    for child in process.children(recursive=True):\n        child.terminate()\n    process.terminate()\n\n    print(\"Server Stopped\")", "blocks": [{"id": 1, "label": "pid = get_pid()\nif not pid:", "successors": [{"id": 3, "label": "    print(\"Server is not running\")\n    return", "successors": []}, {"id": 4, "label": "os.remove(get_pid_path())\nprocess = psutil.Process(int(pid))", "successors": [{"id": 5, "label": "for child in process.children(recursive=True):", "successors": [{"id": 6, "label": "    child.terminate()\nprocess.terminate()\nprint(\"Server Stopped\")", "successors": []}]}]}]}]}, {"name": "gen_encrypt_key", "type": "function", "start_line": 97, "end_line": 103, "functions": [], "classes": [], "simplified_code": "def gen_encrypt_key():\n    \"\"\"\n    Generate a new encryption key\n    \"\"\"\n    from cryptography.fernet import Fernet\n\n    print(Fernet.generate_key().decode())", "blocks": [{"id": 1, "label": "def gen_encrypt_key():\n\"\"\"\n    Generate a new encryption key\n    \"\"\"", "successors": [{"id": 3, "label": "from cryptography.fernet import Fernet\nprint(Fernet.generate_key().decode())", "successors": []}]}]}, {"name": "test", "type": "function", "start_line": 107, "end_line": 111, "functions": [], "classes": [], "simplified_code": "def test():\n    \"\"\"\n    Group for test commands\n    \"\"\"\n    pass", "blocks": [{"id": 1, "label": "def test():\n\"\"\"\n    Group for test commands\n    \"\"\"", "successors": [{"id": 3, "label": "pass", "successors": []}]}]}, {"name": "reddit", "type": "function", "start_line": 116, "end_line": 132, "functions": [], "classes": [], "simplified_code": "def reddit(server_address: str):\n    \"\"\"\n    Create an event graph\n    \"\"\"\n    import requests\n\n    from backend.usecases.reddit_marketing import create_test_graph\n\n    test_graph = create_test_graph()\n    url = f\"{server_address}/graphs\"\n    headers = {\"Content-Type\": \"application/json\"}\n    data = test_graph.model_dump_json()\n\n    response = requests.post(url, headers=headers, data=data)\n\n    graph_id = response.json()[\"id\"]\n    print(f\"Graph created with ID: {graph_id}\")", "blocks": [{"id": 1, "label": "def reddit(server_address: str):\nimport requests\n\nfrom backend.usecases.reddit_marketing import create_test_graph", "successors": [{"id": 3, "label": "test_graph = create_test_graph()\nurl = f\"{server_address}/graphs\"\nheaders = {\"Content-Type\": \"application/json\"}\ndata = test_graph.model_dump_json()\n\nresponse = requests.post(url, headers=headers, data=data)\ngraph_id = response.json()[\"id\"]\nprint(f\"Graph created with ID: {graph_id}\")", "successors": []}]}]}, {"name": "populate_db", "type": "function", "start_line": 137, "end_line": 168, "functions": [], "classes": [], "simplified_code": "def populate_db(server_address: str):\n    \"\"\"\n    Create an event graph\n    \"\"\"\n    import requests\n\n    from backend.usecases.sample import create_test_graph\n\n    test_graph = create_test_graph()\n    url = f\"{server_address}/graphs\"\n    headers = {\"Content-Type\": \"application/json\"}\n    data = test_graph.model_dump_json()\n\n    response = requests.post(url, headers=headers, data=data)\n\n    graph_id = response.json()[\"id\"]\n\n    if response.status_code == 200:\n        execute_url = f\"{server_address}/graphs/{response.json()['id']}/execute\"\n        text = \"Hello, World!\"\n        input_data = {\"input\": text}\n        response = requests.post(execute_url, headers=headers, json=input_data)\n\n        schedule_url = f\"{server_address}/graphs/{graph_id}/schedules\"\n        data = {\n            \"graph_id\": graph_id,\n            \"cron\": \"*/5 * * * *\",\n            \"input_data\": {\"input\": \"Hello, World!\"},\n        }\n        response = requests.post(schedule_url, headers=headers, json=data)\n\n    print(\"Database populated with: \\n- graph\\n- execution\\n- schedule\")", "blocks": [{"id": 1, "label": "def populate_db(server_address: str):\n    \"\"\"\n    Create an event graph\n    \"\"\"\nimport requests\n\n    from backend.usecases.sample import create_test_graph\n\n    test_graph = create_test_graph()\n    url = f\"{server_address}/graphs\"\n    headers = {\"Content-Type\": \"application/json\"}\n    data = test_graph.model_dump_json()\n\n    response = requests.post(url, headers=headers, data=data)\n\n    graph_id = response.json()[\"id\"]", "successors": [{"id": 3, "label": "if response.status_code == 200:\nexecute_url = f\"{server_address}/graphs/{response.json()['id']}/execute\"\n        text = \"Hello, World!\"\n        input_data = {\"input\": text}\n        response = requests.post(execute_url, headers=headers, json=input_data)\n\n        schedule_url = f\"{server_address}/graphs/{graph_id}/schedules\"\n        data = {\n            \"graph_id\": graph_id,\n            \"cron\": \"*/5 * * * *\",\n            \"input_data\": {\"input\": \"Hello, World!\"},\n        }\n        response = requests.post(schedule_url, headers=headers, json=data)", "successors": [{"id": 5, "label": "print(\"Database populated with: \\n- graph\\n- execution\\n- schedule\")", "successors": []}]}]}]}, {"name": "graph", "type": "function", "start_line": 173, "end_line": 195, "functions": [], "classes": [], "simplified_code": "def graph(server_address: str):\n    \"\"\"\n    Create an event graph\n    \"\"\"\n    import requests\n\n    from backend.usecases.sample import create_test_graph\n\n    url = f\"{server_address}/graphs\"\n    headers = {\"Content-Type\": \"application/json\"}\n    data = create_test_graph().model_dump_json()\n    response = requests.post(url, headers=headers, data=data)\n\n    if response.status_code == 200:\n        print(response.json()[\"id\"])\n        execute_url = f\"{server_address}/graphs/{response.json()['id']}/execute\"\n        text = \"Hello, World!\"\n        input_data = {\"input\": text}\n        response = requests.post(execute_url, headers=headers, json=input_data)\n\n    else:\n        print(\"Failed to send graph\")\n        print(f\"Response: {response.text}\")", "blocks": [{"id": 1, "label": "def graph(server_address: str):\n    import requests\n\n    from backend.usecases.sample import create_test_graph\n\n    url = f\"{server_address}/graphs\"\n    headers = {\"Content-Type\": \"application/json\"}\n    data = create_test_graph().model_dump_json()\n    response = requests.post(url, headers=headers, data=data)", "successors": [{"id": 3, "label": "if response.status_code == 200:", "successors": [{"id": 4, "label": "    print(response.json()[\"id\"])\n    execute_url = f\"{server_address}/graphs/{response.json()['id']}/execute\"\n    text = \"Hello, World!\"\n    input_data = {\"input\": text}\n    response = requests.post(execute_url, headers=headers, json=input_data)", "successors": []}, {"id": 5, "label": "else:\n    print(\"Failed to send graph\")\n    print(f\"Response: {response.text}\")", "successors": []}]}]}]}, {"name": "execute", "type": "function", "start_line": 201, "end_line": 210, "functions": [], "classes": [], "simplified_code": "def execute(graph_id: str, content: dict):\n    \"\"\"\n    Create an event graph\n    \"\"\"\n    import requests\n\n    headers = {\"Content-Type\": \"application/json\"}\n\n    execute_url = f\"http://0.0.0.0:8000/graphs/{graph_id}/execute\"\n    requests.post(execute_url, headers=headers, json=content)", "blocks": [{"id": 1, "label": "def execute(graph_id: str, content: dict):\nimport requests", "successors": [{"id": 3, "label": "headers = {\"Content-Type\": \"application/json\"}\nexecute_url = f\"http://0.0.0.0:8000/graphs/{graph_id}/execute\"", "successors": [{"id": 5, "label": "requests.post(execute_url, headers=headers, json=content)", "successors": []}]}]}]}, {"name": "event", "type": "function", "start_line": 214, "end_line": 218, "functions": [], "classes": [], "simplified_code": "def event():\n    \"\"\"\n    Send an event to the running server\n    \"\"\"\n    print(\"Event sent\")", "blocks": [{"id": 1, "label": "def event():\nprint(\"Event sent\")", "successors": []}]}, {"name": "websocket", "type": "function", "start_line": 224, "end_line": 250, "functions": [{"name": "send_message", "type": "function", "start_line": 234, "end_line": 250, "functions": [], "classes": [], "simplified_code": "    async def send_message(server_address: str):\n        uri = f\"ws://{server_address}\"\n        async with websockets.asyncio.client.connect(uri) as websocket:\n            try:\n                msg = WsMessage(\n                    method=Methods.SUBSCRIBE,\n                    data=ExecutionSubscription(graph_id=graph_id).model_dump(),\n                ).model_dump_json()\n                await websocket.send(msg)\n                print(f\"Sending: {msg}\")\n                while True:\n                    response = await websocket.recv()\n                    print(f\"Response from server: {response}\")\n            except InterruptedError:\n                exit(0)\n\n    asyncio.run(send_message(server_address))", "blocks": [{"id": 1, "label": "async def send_message(server_address: str):\nuri = f\"ws://{server_address}\"", "successors": [{"id": 3, "label": "async with websockets.asyncio.client.connect(uri) as websocket:\ntry:", "successors": [{"id": 5, "label": "msg = WsMessage(\n    method=Methods.SUBSCRIBE,\n    data=ExecutionSubscription(graph_id=graph_id).model_dump(),\n).model_dump_json()\nawait websocket.send(msg)\nprint(f\"Sending: {msg}\")", "successors": [{"id": 7, "label": "while True:", "successors": [{"id": 8, "label": "response = await websocket.recv()\nprint(f\"Response from server: {response}\")", "successors": [{"id": 7, "label": "while True:", "successors": [{"id": 8, "label": "response = await websocket.recv()\nprint(f\"Response from server: {response}\")", "successors": []}]}]}]}]}, {"id": 9, "label": "except InterruptedError:\nexit(0)", "successors": []}]}]}]}], "classes": [], "simplified_code": "def websocket(server_address: str, graph_id: str):\n    \"\"\"\n    Tests the websocket connection.\n    \"\"\"\n    import asyncio\n\n    import websockets.asyncio.client\n\n    from backend.server.ws_api import ExecutionSubscription, Methods, WsMessage\n\n    asyncio.run(send_message(server_address))", "blocks": [{"id": 1, "label": "def websocket(server_address: str, graph_id: str):\n    \"\"\"\n    Tests the websocket connection.\n    \"\"\"", "successors": [{"id": 3, "label": "    import asyncio\n    import websockets.asyncio.client", "successors": [{"id": 5, "label": "    from backend.server.ws_api import ExecutionSubscription, Methods, WsMessage\n    asyncio.run(send_message(server_address))", "successors": []}]}]}]}], "classes": [{"name": "MainApp", "type": "class", "start_line": 43, "end_line": 45, "functions": [{"name": "run", "type": "function", "start_line": 44, "end_line": 45, "functions": [], "classes": [], "simplified_code": "    def run(self):\n        app.main(silent=True)", "blocks": [{"id": 1, "label": "def run(self):\napp.main(silent=True)", "successors": []}]}], "classes": [], "simplified_code": "class MainApp(AppProcess):\n        app.main(silent=True)", "blocks": [{"id": 1, "label": "class MainApp(AppProcess):\n    app.main(silent=True)", "successors": []}]}], "simplified_code": "\"\"\"\nThe command line interface for the agent server\n\"\"\"\n\nimport os\nimport pathlib\n\nimport click\nimport psutil\n\nfrom backend import app\nfrom backend.util.process import AppProcess\n\n\n    return file_path\n\n\n        return None\n\n\n        file.write(str(pid))\n\n\n        app.main(silent=True)\n\n\n@click.group()\n    pass\n\n\n@main.command()\n    os._exit(status=0)\n\n\n@main.command()\n    print(\"Server Stopped\")\n\n\n@main.command()\n    print(Fernet.generate_key().decode())\n\n\n@click.group()\n    pass\n\n\n@test.command()\n@click.argument(\"server_address\")\n    print(f\"Graph created with ID: {graph_id}\")\n\n\n@test.command()\n@click.argument(\"server_address\")\n    print(\"Database populated with: \\n- graph\\n- execution\\n- schedule\")\n\n\n@test.command()\n@click.argument(\"server_address\")\n        print(f\"Response: {response.text}\")\n\n\n@test.command()\n@click.argument(\"graph_id\")\n@click.argument(\"content\")\n    requests.post(execute_url, headers=headers, json=content)\n\n\n@test.command()\n    print(\"Event sent\")\n\n\n@test.command()\n@click.argument(\"server_address\")\n@click.argument(\"graph_id\")\n    asyncio.run(send_message(server_address))\n    print(\"Testing WS\")\n\n\nmain.add_command(test)\n\nif __name__ == \"__main__\":\n    main()", "blocks": [{"id": 1, "label": "import os\nimport pathlib\n\nimport click\nimport psutil\n\nfrom backend import app\nfrom backend.util.process import AppProcess\n@click.group()\ndef main():\n    pass", "successors": [{"id": 3, "label": "@main.command()\ndef stop():\n    os._exit(status=0)\n@main.command()\ndef stopped_notification():\n    print(\"Server Stopped\")", "successors": [{"id": 5, "label": "@main.command()\ndef generate_key():\n    print(Fernet.generate_key().decode())\n@click.group()\ndef test():\n    pass", "successors": [{"id": 7, "label": "@test.command()\n@click.argument(\"server_address\")\ndef create_graph(server_address):\n    print(f\"Graph created with ID: {graph_id}\")\n@test.command()\n@click.argument(\"server_address\")\ndef populate_database(server_address):\n    print(\"Database populated with: \\n- graph\\n- execution\\n- schedule\")", "successors": [{"id": 9, "label": "@test.command()\n@click.argument(\"server_address\")\ndef get_response(server_address):\n    print(f\"Response: {response.text}\")\n@test.command()\n@click.argument(\"graph_id\")\n@click.argument(\"content\")\ndef send_content(graph_id, content):\n    requests.post(execute_url, headers=headers, json=content)", "successors": [{"id": 11, "label": "@test.command()\ndef send_event():\n    print(\"Event sent\")\n@test.command()\n@click.argument(\"server_address\")\n@click.argument(\"graph_id\")\ndef test_ws(server_address, graph_id):\n    asyncio.run(send_message(server_address))\n    print(\"Testing WS\")", "successors": [{"id": 13, "label": "main.add_command(test)\nif __name__ == \"__main__\":\n    main()", "successors": []}]}]}]}]}]}]}]}
{"file_name": "173.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 77, "functions": [], "classes": [{"name": "SalesRanker", "type": "class", "start_line": 6, "end_line": 73, "functions": [{"name": "within_past_week", "type": "function", "start_line": 8, "end_line": 10, "functions": [], "classes": [], "simplified_code": "    def within_past_week(self, timestamp):\n        \"\"\"Return True if timestamp is within past week, False otherwise.\"\"\"\n        ...", "blocks": [{"id": 1, "label": "def within_past_week(self, timestamp):\n\"\"\"Return True if timestamp is within past week, False otherwise.\"\"\"", "successors": [{"id": 3, "label": "...", "successors": []}]}]}, {"name": "mapper", "type": "function", "start_line": 12, "end_line": 26, "functions": [], "classes": [], "simplified_code": "    def mapper(self, _, line):\n        \"\"\"Parse each log line, extract and transform relevant lines.\n\n        Emit key value pairs of the form:\n\n        (foo, p1), 2\n        (bar, p1), 2\n        (bar, p1), 1\n        (foo, p2), 3\n        (bar, p3), 10\n        (foo, p4), 1\n        \"\"\"\n        timestamp, product_id, category, quantity = line.split('\\t')\n        if self.within_past_week(timestamp):\n            yield (category, product_id), quantity", "blocks": [{"id": 1, "label": "    timestamp, product_id, category, quantity = line.split('\\t')\nif self.within_past_week(timestamp):", "successors": [{"id": 3, "label": "    yield (category, product_id), quantity", "successors": []}]}]}, {"name": "reducer", "type": "function", "start_line": 28, "end_line": 37, "functions": [], "classes": [], "simplified_code": "    def reducer(self, key, values):\n        \"\"\"Sum values for each key.\n\n        (foo, p1), 2\n        (bar, p1), 3\n        (foo, p2), 3\n        (bar, p3), 10\n        (foo, p4), 1\n        \"\"\"\n        yield key, sum(values)", "blocks": [{"id": 1, "label": "def reducer(self, key, values):\n\"\"\"Sum values for each key.\n\n        (foo, p1), 2\n        (bar, p1), 3\n        (foo, p2), 3\n        (bar, p3), 10\n        (foo, p4), 1\n        \"\"\"", "successors": [{"id": 3, "label": "yield key, sum(values)", "successors": []}]}]}, {"name": "mapper_sort", "type": "function", "start_line": 39, "end_line": 61, "functions": [], "classes": [], "simplified_code": "    def mapper_sort(self, key, value):\n        \"\"\"Construct key to ensure proper sorting.\n\n        Transform key and value to the form:\n\n        (foo, 2), p1\n        (bar, 3), p1\n        (foo, 3), p2\n        (bar, 10), p3\n        (foo, 1), p4\n\n        The shuffle/sort step of MapReduce will then do a\n        distributed sort on the keys, resulting in:\n\n        (category1, 1), product4\n        (category1, 2), product1\n        (category1, 3), product2\n        (category2, 3), product1\n        (category2, 7), product3\n        \"\"\"\n        category, product_id = key\n        quantity = value\n        yield (category, quantity), product_id", "blocks": [{"id": 1, "label": "def mapper_sort(self, key, value):\ncategory, product_id = key", "successors": [{"id": 3, "label": "quantity = value\nyield (category, quantity), product_id", "successors": []}]}]}, {"name": "reducer_identity", "type": "function", "start_line": 63, "end_line": 64, "functions": [], "classes": [], "simplified_code": "    def reducer_identity(self, key, value):\n        yield key, value", "blocks": [{"id": 1, "label": "def reducer_identity(self, key, value):\n    yield key, value", "successors": []}]}, {"name": "steps", "type": "function", "start_line": 66, "end_line": 73, "functions": [], "classes": [], "simplified_code": "    def steps(self):\n        \"\"\"Run the map and reduce steps.\"\"\"\n        return [\n            self.mr(mapper=self.mapper,\n                    reducer=self.reducer),\n            self.mr(mapper=self.mapper_sort,\n                    reducer=self.reducer_identity),\n        ]", "blocks": [{"id": 1, "label": "def steps(self):\n    \"\"\"Run the map and reduce steps.\"\"\"\n    return [\n        self.mr(mapper=self.mapper,\n                reducer=self.reducer),\n        self.mr(mapper=self.mapper_sort,\n                reducer=self.reducer_identity),\n    ]", "successors": []}]}], "classes": [], "simplified_code": "class SalesRanker(MRJob):\n\n        ...\n\n            yield (category, product_id), quantity\n\n        yield key, sum(values)\n\n        yield (category, quantity), product_id\n\n        yield key, value\n\n        ]", "blocks": [{"id": 1, "label": "class SalesRanker(MRJob):\n...", "successors": [{"id": 3, "label": "yield (category, product_id), quantity\nyield key, sum(values)", "successors": [{"id": 5, "label": "yield (category, quantity), product_id\nyield key, value", "successors": [{"id": 7, "label": "]", "successors": []}]}]}]}]}], "simplified_code": "# -*- coding: utf-8 -*-\n\nfrom mrjob.job import MRJob\n\n\n        ]\n\n\nif __name__ == '__main__':\n    SalesRanker.run()", "blocks": [{"id": 1, "label": "from mrjob.job import MRJob\nif __name__ == '__main__':", "successors": [{"id": 3, "label": "    SalesRanker.run()", "successors": []}]}]}
{"file_name": "174.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 72, "functions": [], "classes": [{"name": "State", "type": "class", "start_line": 6, "end_line": 8, "functions": [], "simplified_code": "class State(Enum):\n    unvisited = 0\n    visited = 1", "blocks": [{"id": 1, "label": "class State(Enum):\n    unvisited = 0\n    visited = 1", "successors": []}]}, {"name": "Graph", "type": "class", "start_line": 11, "end_line": 28, "functions": [{"name": "bfs", "type": "function", "start_line": 13, "end_line": 28, "functions": [], "classes": [], "simplified_code": "    def bfs(self, source, dest):\n        if source is None:\n            return False\n        queue = deque()\n        queue.append(source)\n        source.visit_state = State.visited\n        while queue:\n            node = queue.popleft()\n            print(node)\n            if dest is node:\n                return True\n            for adjacent_node in node.adj_nodes.values():\n                if adjacent_node.visit_state == State.unvisited:\n                    queue.append(adjacent_node)\n                    adjacent_node.visit_state = State.visited\n        return False", "blocks": [{"id": 1, "label": "def bfs(self, source, dest):", "successors": [{"id": 2, "label": "if source is None:\nreturn False", "successors": []}, {"id": 4, "label": "queue = deque()\nqueue.append(source)\nsource.visit_state = State.visited", "successors": [{"id": 5, "label": "while queue:", "successors": [{"id": 6, "label": "node = queue.popleft()\nprint(node)", "successors": [{"id": 7, "label": "if dest is node:\nreturn True", "successors": []}, {"id": 9, "label": "for adjacent_node in node.adj_nodes.values():", "successors": [{"id": 10, "label": "if adjacent_node.visit_state == State.unvisited:\nqueue.append(adjacent_node)\nadjacent_node.visit_state = State.visited", "successors": [{"id": 5, "label": "while queue:", "successors": []}]}, {"id": 5, "label": "while queue:", "successors": []}]}]}]}, {"id": 12, "label": "return False", "successors": []}]}]}]}], "simplified_code": "class Graph(object):\n\n        return False", "blocks": [{"id": 1, "label": "class Graph(object):\nreturn False", "successors": []}]}, {"name": "Person", "type": "class", "start_line": 31, "end_line": 36, "functions": [{"name": "__init__", "type": "function", "start_line": 33, "end_line": 36, "functions": [], "classes": [], "simplified_code": "    def __init__(self, id, name):\n        self.id = id\n        self.name = name\n        self.friend_ids = []", "blocks": [{"id": 1, "label": "def __init__(self, id, name):\n    self.id = id\n    self.name = name\n    self.friend_ids = []", "successors": []}]}], "simplified_code": "class Person(object):\n\n        self.friend_ids = []", "blocks": [{"id": 1, "label": "class Person(object):\n    self.friend_ids = []", "successors": []}]}, {"name": "LookupService", "type": "class", "start_line": 39, "end_line": 46, "functions": [{"name": "__init__", "type": "function", "start_line": 41, "end_line": 42, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        self.lookup = {}  # key: person_id, value: person_server", "blocks": [{"id": 1, "label": "def __init__(self):\n    self.lookup = {}", "successors": []}]}, {"name": "get_person", "type": "function", "start_line": 44, "end_line": 46, "functions": [], "classes": [], "simplified_code": "    def get_person(self, person_id):\n        person_server = self.lookup[person_id]\n        return person_server.people[person_id]", "blocks": [{"id": 1, "label": "def get_person(self, person_id):\nperson_server = self.lookup[person_id]", "successors": [{"id": 3, "label": "return person_server.people[person_id]", "successors": []}]}]}], "simplified_code": "class LookupService(object):\n\n        self.lookup = {}  # key: person_id, value: person_server\n\n        return person_server.people[person_id]", "blocks": [{"id": 1, "label": "class LookupService(object):\nself.lookup = {}  # key: person_id, value: person_server", "successors": [{"id": 3, "label": "return person_server.people[person_id]", "successors": []}]}]}, {"name": "PersonServer", "type": "class", "start_line": 49, "end_line": 59, "functions": [{"name": "__init__", "type": "function", "start_line": 51, "end_line": 52, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        self.people = {}  # key: person_id, value: person", "blocks": [{"id": 1, "label": "def __init__(self):\n    self.people = {}  # key: person_id, value: person", "successors": []}]}, {"name": "get_people", "type": "function", "start_line": 54, "end_line": 59, "functions": [], "classes": [], "simplified_code": "    def get_people(self, ids):\n        results = []\n        for id in ids:\n            if id in self.people:\n                results.append(self.people[id])\n        return results", "blocks": [{"id": 1, "label": "results = []", "successors": [{"id": 2, "label": "for id in ids:", "successors": [{"id": 3, "label": "    if id in self.people:", "successors": [{"id": 4, "label": "        results.append(self.people[id])", "successors": [{"id": 2, "label": "for id in ids:", "successors": []}]}, {"id": 5, "label": "        pass", "successors": [{"id": 2, "label": "for id in ids:", "successors": []}]}]}]}, {"id": 6, "label": "return results", "successors": []}]}]}], "simplified_code": "class PersonServer(object):\n\n        self.people = {}  # key: person_id, value: person\n\n        return results", "blocks": [{"id": 1, "label": "class PersonServer(object):", "successors": [{"id": 2, "label": "    self.people = {}  # key: person_id, value: person", "successors": []}, {"id": 3, "label": "    return results", "successors": []}]}]}, {"name": "UserGraphService", "type": "class", "start_line": 62, "end_line": 72, "functions": [{"name": "__init__", "type": "function", "start_line": 64, "end_line": 67, "functions": [], "classes": [], "simplified_code": "    def __init__(self, person_ids, lookup):\n        self.lookup = lookup\n        self.person_ids = person_ids\n        self.visited_ids = set()", "blocks": [{"id": 1, "label": "def __init__(self, person_ids, lookup):\n    self.lookup = lookup\n    self.person_ids = person_ids\n    self.visited_ids = set()", "successors": []}]}, {"name": "bfs", "type": "function", "start_line": 69, "end_line": 72, "functions": [], "classes": [], "simplified_code": "    def bfs(self, source, dest):\n        # Use self.visited_ids to track visited nodes\n        # Use self.lookup to translate a person_id to a Person\n        pass", "blocks": [{"id": 1, "label": "def bfs(self, source, dest):\n# Use self.visited_ids to track visited nodes\n# Use self.lookup to translate a person_id to a Person\npass", "successors": []}]}], "simplified_code": "class UserGraphService(object):\n\n        self.visited_ids = set()\n\n        pass", "blocks": [{"id": 1, "label": "class UserGraphService(object):\n    self.visited_ids = set()", "successors": [{"id": 3, "label": "    pass", "successors": []}]}]}], "simplified_code": "# -*- coding: utf-8 -*-\nfrom collections import deque\nfrom enum import Enum\n\n\n    visited = 1\n\n\n        return False\n\n\n        self.friend_ids = []\n\n\n        return person_server.people[person_id]\n\n\n        return results\n\n\n        pass", "blocks": [{"id": 1, "label": "visited = 1", "successors": [{"id": 2, "label": "return False", "successors": []}, {"id": 3, "label": "self.friend_ids = []\nreturn person_server.people[person_id]", "successors": []}, {"id": 5, "label": "return results", "successors": []}, {"id": 6, "label": "pass", "successors": []}]}]}
{"file_name": "175.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 175, "functions": [{"name": "_extract_schema_from_url", "type": "function", "start_line": 21, "end_line": 37, "functions": [], "classes": [], "simplified_code": "def _extract_schema_from_url(database_url) -> tuple[str, str]:\n    \"\"\"\n    Extracts the schema from the DATABASE_URL and returns the schema and cleaned URL.\n    \"\"\"\n    parsed_url = urlparse(database_url)\n    query_params = parse_qs(parsed_url.query)\n\n    # Extract the 'schema' parameter\n    schema_list = query_params.pop(\"schema\", None)\n    schema = schema_list[0] if schema_list else \"public\"\n\n    # Reconstruct the query string without the 'schema' parameter\n    new_query = urlencode(query_params, doseq=True)\n    new_parsed_url = parsed_url._replace(query=new_query)\n    database_url_clean = str(urlunparse(new_parsed_url))\n\n    return schema, database_url_clean", "blocks": [{"id": 1, "label": "def _extract_schema_from_url(database_url) -> tuple[str, str]:\nparsed_url = urlparse(database_url)\nquery_params = parse_qs(parsed_url.query)", "successors": [{"id": 3, "label": "schema_list = query_params.pop(\"schema\", None)\nschema = schema_list[0] if schema_list else \"public\"\nnew_query = urlencode(query_params, doseq=True)\nnew_parsed_url = parsed_url._replace(query=new_query)\ndatabase_url_clean = str(urlunparse(new_parsed_url))", "successors": [{"id": 5, "label": "return schema, database_url_clean", "successors": []}]}]}]}, {"name": "log", "type": "function", "start_line": 44, "end_line": 45, "functions": [], "classes": [], "simplified_code": "def log(msg, **kwargs):\n    logger.info(\"[ExecutionScheduler] \" + msg, **kwargs)", "blocks": [{"id": 1, "label": "def log(msg, **kwargs):\nlogger.info(\"[ExecutionScheduler] \" + msg, **kwargs)", "successors": []}]}, {"name": "job_listener", "type": "function", "start_line": 48, "end_line": 53, "functions": [], "classes": [], "simplified_code": "def job_listener(event):\n    \"\"\"Logs job execution outcomes for better monitoring.\"\"\"\n    if event.exception:\n        log(f\"Job {event.job_id} failed.\")\n    else:\n        log(f\"Job {event.job_id} completed successfully.\")", "blocks": [{"id": 1, "label": "def job_listener(event):\nif event.exception:", "successors": [{"id": 3, "label": "    log(f\"Job {event.job_id} failed.\")", "successors": []}, {"id": 4, "label": "    log(f\"Job {event.job_id} completed successfully.\")", "successors": []}]}]}, {"name": "get_execution_client", "type": "function", "start_line": 57, "end_line": 58, "functions": [], "classes": [], "simplified_code": "def get_execution_client() -> ExecutionManager:\n    return get_service_client(ExecutionManager)", "blocks": [{"id": 1, "label": "def get_execution_client() -> ExecutionManager:\nreturn get_service_client(ExecutionManager)", "successors": []}]}, {"name": "execute_graph", "type": "function", "start_line": 61, "end_line": 69, "functions": [], "classes": [], "simplified_code": "def execute_graph(**kwargs):\n    args = JobArgs(**kwargs)\n    try:\n        log(f\"Executing recurring job for graph #{args.graph_id}\")\n        get_execution_client().add_execution(\n            args.graph_id, args.input_data, args.user_id\n        )\n    except Exception as e:\n        logger.exception(f\"Error executing graph {args.graph_id}: {e}\")", "blocks": [{"id": 1, "label": "def execute_graph(**kwargs):\nargs = JobArgs(**kwargs)", "successors": [{"id": 3, "label": "try:", "successors": [{"id": 4, "label": "log(f\"Executing recurring job for graph #{args.graph_id}\")\nget_execution_client().add_execution(\n    args.graph_id, args.input_data, args.user_id\n)", "successors": []}, {"id": 5, "label": "except Exception as e:\nlogger.exception(f\"Error executing graph {args.graph_id}: {e}\")", "successors": []}]}]}]}], "classes": [{"name": "JobArgs", "type": "class", "start_line": 72, "end_line": 77, "functions": [], "classes": [], "simplified_code": "class JobArgs(BaseModel):\n    graph_id: str\n    input_data: BlockInput\n    user_id: str\n    graph_version: int\n    cron: str", "blocks": [{"id": 1, "label": "class JobArgs(BaseModel):\n    graph_id: str\n    input_data: BlockInput\n    user_id: str\n    graph_version: int\n    cron: str", "successors": []}]}, {"name": "JobInfo", "type": "class", "start_line": 80, "end_line": 92, "functions": [{"name": "from_db", "type": "function", "start_line": 86, "end_line": 92, "functions": [], "classes": [], "simplified_code": "    def from_db(job_args: JobArgs, job_obj: JobObj) -> \"JobInfo\":\n        return JobInfo(\n            id=job_obj.id,\n            name=job_obj.name,\n            next_run_time=job_obj.next_run_time.isoformat(),\n            **job_args.model_dump(),\n        )", "blocks": [{"id": 1, "label": "def from_db(job_args: JobArgs, job_obj: JobObj) -> \"JobInfo\":\nreturn JobInfo(id=job_obj.id, name=job_obj.name, next_run_time=job_obj.next_run_time.isoformat(), **job_args.model_dump(), )", "successors": []}]}], "classes": [], "simplified_code": "class JobInfo(JobArgs):\n    id: str\n    name: str\n    next_run_time: str\n\n    @staticmethod\n        )", "blocks": [{"id": 1, "label": "class JobInfo(JobArgs):\nid: str\nname: str\nnext_run_time: str", "successors": [{"id": 3, "label": "@staticmethod", "successors": []}]}]}, {"name": "ExecutionScheduler", "type": "class", "start_line": 95, "end_line": 175, "functions": [{"name": "get_port", "type": "function", "start_line": 99, "end_line": 100, "functions": [], "classes": [], "simplified_code": "    def get_port(cls) -> int:\n        return config.execution_scheduler_port", "blocks": [{"id": 1, "label": "def get_port(cls) -> int:\n    return config.execution_scheduler_port", "successors": []}]}, {"name": "execution_client", "type": "function", "start_line": 104, "end_line": 105, "functions": [], "classes": [], "simplified_code": "    def execution_client(self) -> ExecutionManager:\n        return get_service_client(ExecutionManager)", "blocks": [{"id": 1, "label": "def execution_client(self) -> ExecutionManager:\n    return get_service_client(ExecutionManager)", "successors": []}]}, {"name": "run_service", "type": "function", "start_line": 107, "end_line": 119, "functions": [], "classes": [], "simplified_code": "    def run_service(self):\n        load_dotenv()\n        db_schema, db_url = _extract_schema_from_url(os.getenv(\"DATABASE_URL\"))\n        self.scheduler = BlockingScheduler(\n            jobstores={\n                \"default\": SQLAlchemyJobStore(\n                    engine=create_engine(db_url),\n                    metadata=MetaData(schema=db_schema),\n                )\n            }\n        )\n        self.scheduler.add_listener(job_listener, EVENT_JOB_EXECUTED | EVENT_JOB_ERROR)\n        self.scheduler.start()", "blocks": [{"id": 1, "label": "def run_service(self):\nload_dotenv()", "successors": [{"id": 3, "label": "db_schema, db_url = _extract_schema_from_url(os.getenv(\"DATABASE_URL\"))\nself.scheduler = BlockingScheduler(jobstores={\"default\": SQLAlchemyJobStore(engine=create_engine(db_url), metadata=MetaData(schema=db_schema),)})", "successors": [{"id": 5, "label": "self.scheduler.add_listener(job_listener, EVENT_JOB_EXECUTED | EVENT_JOB_ERROR)\nself.scheduler.start()", "successors": []}]}]}]}, {"name": "add_execution_schedule", "type": "function", "start_line": 122, "end_line": 144, "functions": [], "classes": [], "simplified_code": "    def add_execution_schedule(\n        self,\n        graph_id: str,\n        graph_version: int,\n        cron: str,\n        input_data: BlockInput,\n        user_id: str,\n    ) -> JobInfo:\n        job_args = JobArgs(\n            graph_id=graph_id,\n            input_data=input_data,\n            user_id=user_id,\n            graph_version=graph_version,\n            cron=cron,\n        )\n        job = self.scheduler.add_job(\n            execute_graph,\n            CronTrigger.from_crontab(cron),\n            kwargs=job_args.model_dump(),\n            replace_existing=True,\n        )\n        log(f\"Added job {job.id} with cron schedule '{cron}' input data: {input_data}\")\n        return JobInfo.from_db(job_args, job)", "blocks": [{"id": 1, "label": "def add_execution_schedule(\n    self,\n    graph_id: str,\n    graph_version: int,\n    cron: str,\n    input_data: BlockInput,\n    user_id: str,\n) -> JobInfo:\n    job_args = JobArgs(\n        graph_id=graph_id,\n        input_data=input_data,\n        user_id=user_id,\n        graph_version=graph_version,\n        cron=cron,\n    )", "successors": [{"id": 3, "label": "    job = self.scheduler.add_job(\n        execute_graph,\n        CronTrigger.from_crontab(cron),\n        kwargs=job_args.model_dump(),\n        replace_existing=True,\n    )\n    log(f\"Added job {job.id} with cron schedule '{cron}' input data: {input_data}\")", "successors": [{"id": 5, "label": "    return JobInfo.from_db(job_args, job)", "successors": []}]}]}]}, {"name": "delete_schedule", "type": "function", "start_line": 147, "end_line": 160, "functions": [], "classes": [], "simplified_code": "    def delete_schedule(self, schedule_id: str, user_id: str) -> JobInfo:\n        job = self.scheduler.get_job(schedule_id)\n        if not job:\n            log(f\"Job {schedule_id} not found.\")\n            raise ValueError(f\"Job #{schedule_id} not found.\")\n\n        job_args = JobArgs(**job.kwargs)\n        if job_args.user_id != user_id:\n            raise ValueError(\"User ID does not match the job's user ID.\")\n\n        log(f\"Deleting job {schedule_id}\")\n        job.remove()\n\n        return JobInfo.from_db(job_args, job)", "blocks": [{"id": 1, "label": "def delete_schedule(self, schedule_id: str, user_id: str) -> JobInfo:\njob = self.scheduler.get_job(schedule_id)", "successors": [{"id": 3, "label": "if not job:\nlog(f\"Job {schedule_id} not found.\")", "successors": [{"id": 5, "label": "raise ValueError(f\"Job #{schedule_id} not found.\")", "successors": []}]}, {"id": 6, "label": "job_args = JobArgs(**job.kwargs)", "successors": [{"id": 7, "label": "if job_args.user_id != user_id:\nraise ValueError(\"User ID does not match the job's user ID.\")", "successors": []}, {"id": 9, "label": "log(f\"Deleting job {schedule_id}\")\njob.remove()", "successors": [{"id": 11, "label": "return JobInfo.from_db(job_args, job)", "successors": []}]}]}]}]}, {"name": "get_execution_schedules", "type": "function", "start_line": 163, "end_line": 175, "functions": [], "classes": [], "simplified_code": "    def get_execution_schedules(\n        self, graph_id: str | None = None, user_id: str | None = None\n    ) -> list[JobInfo]:\n        schedules = []\n        for job in self.scheduler.get_jobs():\n            job_args = JobArgs(**job.kwargs)\n            if (\n                job.next_run_time is not None\n                and (graph_id is None or job_args.graph_id == graph_id)\n                and (user_id is None or job_args.user_id == user_id)\n            ):\n                schedules.append(JobInfo.from_db(job_args, job))\n        return schedules", "blocks": [{"id": 1, "label": "def get_execution_schedules(\n    self, graph_id: str | None = None, user_id: str | None = None\n) -> list[JobInfo]:\nschedules = []", "successors": [{"id": 3, "label": "for job in self.scheduler.get_jobs():", "successors": [{"id": 4, "label": "job_args = JobArgs(**job.kwargs)", "successors": [{"id": 5, "label": "if (\n    job.next_run_time is not None\n    and (graph_id is None or job_args.graph_id == graph_id)\n    and (user_id is None or job_args.user_id == user_id)\n):", "successors": [{"id": 6, "label": "schedules.append(JobInfo.from_db(job_args, job))\nreturn schedules", "successors": []}, {"id": 7, "label": "return schedules", "successors": []}]}, {"id": 7, "label": "return schedules", "successors": []}]}, {"id": 7, "label": "return schedules", "successors": []}]}, {"id": 7, "label": "return schedules", "successors": []}]}]}], "classes": [], "simplified_code": "class ExecutionScheduler(AppService):\n    scheduler: BlockingScheduler\n\n    @classmethod\n        return config.execution_scheduler_port\n\n    @property\n    @thread_cached\n        return get_service_client(ExecutionManager)\n\n        self.scheduler.start()\n\n    @expose\n        return JobInfo.from_db(job_args, job)\n\n    @expose\n        return JobInfo.from_db(job_args, job)\n\n    @expose\n        return schedules", "blocks": [{"id": 1, "label": "class ExecutionScheduler(AppService):\n    scheduler: BlockingScheduler", "successors": []}]}], "simplified_code": "import logging\nimport os\nfrom urllib.parse import parse_qs, urlencode, urlparse, urlunparse\n\nfrom apscheduler.events import EVENT_JOB_ERROR, EVENT_JOB_EXECUTED\nfrom apscheduler.job import Job as JobObj\nfrom apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore\nfrom apscheduler.schedulers.blocking import BlockingScheduler\nfrom apscheduler.triggers.cron import CronTrigger\nfrom autogpt_libs.utils.cache import thread_cached\nfrom dotenv import load_dotenv\nfrom pydantic import BaseModel\nfrom sqlalchemy import MetaData, create_engine\n\nfrom backend.data.block import BlockInput\nfrom backend.executor.manager import ExecutionManager\nfrom backend.util.service import AppService, expose, get_service_client\nfrom backend.util.settings import Config\n\n\n    return schema, database_url_clean\n\n\nlogger = logging.getLogger(__name__)\nconfig = Config()\n\n\n    logger.info(\"[ExecutionScheduler] \" + msg, **kwargs)\n\n\n        log(f\"Job {event.job_id} completed successfully.\")\n\n\n@thread_cached\n    return get_service_client(ExecutionManager)\n\n\n        logger.exception(f\"Error executing graph {args.graph_id}: {e}\")\n\n\n    cron: str\n\n\n        )\n\n\n        return schedules", "blocks": [{"id": 1, "label": "import logging\nimport os\nfrom urllib.parse import parse_qs, urlencode, urlparse, urlunparse\n\nfrom apscheduler.events import EVENT_JOB_ERROR, EVENT_JOB_EXECUTED\nfrom apscheduler.job import Job as JobObj\nfrom apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore\nfrom apscheduler.schedulers.blocking import BlockingScheduler\nfrom apscheduler.triggers.cron import CronTrigger\nfrom autogpt_libs.utils.cache import thread_cached\nfrom dotenv import load_dotenv\nfrom pydantic import BaseModel\nfrom sqlalchemy import MetaData, create_engine\n\nfrom backend.data.block import BlockInput\nfrom backend.executor.manager import ExecutionManager\nfrom backend.util.service import AppService, expose, get_service_client\nfrom backend.util.settings import Config\n\n\n    return schema, database_url_clean\n\n\nlogger = logging.getLogger(__name__)\nconfig = Config()\n\n\n    logger.info(\"[ExecutionScheduler] \" + msg, **kwargs)\n\n\n        log(f\"Job {event.job_id} completed successfully.\")\n\n\n@thread_cached\n    return get_service_client(ExecutionManager)\n\n\n        logger.exception(f\"Error executing graph {args.graph_id}: {e}\")\n\n\n    cron: str\n\n\n        )\n\n\n        return schedules", "successors": []}]}
{"file_name": "176.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 189, "functions": [{"name": "lifespan", "type": "function", "start_line": 23, "end_line": 27, "functions": [], "classes": [], "simplified_code": "async def lifespan(app: FastAPI):\n    manager = get_connection_manager()\n    fut = asyncio.create_task(event_broadcaster(manager))\n    fut.add_done_callback(lambda _: logger.info(\"Event broadcaster stopped\"))\n    yield", "blocks": [{"id": 1, "label": "async def lifespan(app: FastAPI):\nmanager = get_connection_manager()\nfut = asyncio.create_task(event_broadcaster(manager))\nfut.add_done_callback(lambda _: logger.info(\"Event broadcaster stopped\"))", "successors": [{"id": 3, "label": "yield", "successors": []}]}]}, {"name": "get_connection_manager", "type": "function", "start_line": 35, "end_line": 39, "functions": [], "classes": [], "simplified_code": "def get_connection_manager():\n    global _connection_manager\n    if _connection_manager is None:\n        _connection_manager = ConnectionManager()\n    return _connection_manager", "blocks": [{"id": 1, "label": "def get_connection_manager():\nglobal _connection_manager", "successors": [{"id": 3, "label": "if _connection_manager is None:", "successors": [{"id": 4, "label": "_connection_manager = ConnectionManager()\nreturn _connection_manager", "successors": []}, {"id": 5, "label": "return _connection_manager", "successors": []}]}]}]}, {"name": "event_broadcaster", "type": "function", "start_line": 42, "end_line": 52, "functions": [], "classes": [], "simplified_code": "async def event_broadcaster(manager: ConnectionManager):\n    try:\n        redis.connect()\n        event_queue = AsyncRedisExecutionEventBus()\n        async for event in event_queue.listen():\n            await manager.send_execution_result(event)\n    except Exception as e:\n        logger.exception(f\"Event broadcaster error: {e}\")\n        raise\n    finally:\n        redis.disconnect()", "blocks": [{"id": 1, "label": "try:\n    redis.connect()", "successors": [{"id": 3, "label": "    event_queue = AsyncRedisExecutionEventBus()\n    async for event in event_queue.listen():", "successors": [{"id": 5, "label": "        await manager.send_execution_result(event)\nredis.disconnect()", "successors": []}]}, {"id": 6, "label": "except Exception as e:\n    logger.exception(f\"Event broadcaster error: {e}\")\n    raise", "successors": [{"id": 8, "label": "redis.disconnect()", "successors": []}]}, {"id": 8, "label": "finally:", "successors": []}]}]}, {"name": "authenticate_websocket", "type": "function", "start_line": 55, "end_line": 73, "functions": [], "classes": [], "simplified_code": "async def authenticate_websocket(websocket: WebSocket) -> str:\n    if not settings.config.enable_auth:\n        return DEFAULT_USER_ID\n\n    token = websocket.query_params.get(\"token\")\n    if not token:\n        await websocket.close(code=4001, reason=\"Missing authentication token\")\n        return \"\"\n\n    try:\n        payload = parse_jwt_token(token)\n        user_id = payload.get(\"sub\")\n        if not user_id:\n            await websocket.close(code=4002, reason=\"Invalid token\")\n            return \"\"\n        return user_id\n    except ValueError:\n        await websocket.close(code=4003, reason=\"Invalid token\")\n        return \"\"", "blocks": [{"id": 1, "label": "async def authenticate_websocket(websocket: WebSocket) -> str:\nif not settings.config.enable_auth:", "successors": [{"id": 3, "label": "return DEFAULT_USER_ID", "successors": []}, {"id": 4, "label": "token = websocket.query_params.get(\"token\")\nif not token:", "successors": [{"id": 5, "label": "await websocket.close(code=4001, reason=\"Missing authentication token\")\nreturn \"\"", "successors": []}, {"id": 6, "label": "try:", "successors": [{"id": 7, "label": "payload = parse_jwt_token(token)\nuser_id = payload.get(\"sub\")\nif not user_id:", "successors": [{"id": 8, "label": "await websocket.close(code=4002, reason=\"Invalid token\")\nreturn \"\"", "successors": []}, {"id": 9, "label": "return user_id", "successors": []}]}, {"id": 10, "label": "except ValueError:\nawait websocket.close(code=4003, reason=\"Invalid token\")\nreturn \"\"", "successors": []}]}]}]}]}, {"name": "handle_subscribe", "type": "function", "start_line": 76, "end_line": 97, "functions": [], "classes": [], "simplified_code": "async def handle_subscribe(\n    websocket: WebSocket, manager: ConnectionManager, message: WsMessage\n):\n    if not message.data:\n        await websocket.send_text(\n            WsMessage(\n                method=Methods.ERROR,\n                success=False,\n                error=\"Subscription data missing\",\n            ).model_dump_json()\n        )\n    else:\n        ex_sub = ExecutionSubscription.model_validate(message.data)\n        await manager.subscribe(ex_sub.graph_id, websocket)\n        logger.debug(f\"New execution subscription for graph {ex_sub.graph_id}\")\n        await websocket.send_text(\n            WsMessage(\n                method=Methods.SUBSCRIBE,\n                success=True,\n                channel=ex_sub.graph_id,\n            ).model_dump_json()\n        )", "blocks": [{"id": 1, "label": "async def handle_subscribe(\n    websocket: WebSocket, manager: ConnectionManager, message: WsMessage\n):\nif not message.data:", "successors": [{"id": 3, "label": "await websocket.send_text(\n    WsMessage(\n        method=Methods.ERROR,\n        success=False,\n        error=\"Subscription data missing\",\n    ).model_dump_json()\n)", "successors": []}, {"id": 4, "label": "ex_sub = ExecutionSubscription.model_validate(message.data)\nawait manager.subscribe(ex_sub.graph_id, websocket)\nlogger.debug(f\"New execution subscription for graph {ex_sub.graph_id}\")\nawait websocket.send_text(\n    WsMessage(\n        method=Methods.SUBSCRIBE,\n        success=True,\n        channel=ex_sub.graph_id,\n    ).model_dump_json()\n)", "successors": []}]}]}, {"name": "handle_unsubscribe", "type": "function", "start_line": 100, "end_line": 121, "functions": [], "classes": [], "simplified_code": "async def handle_unsubscribe(\n    websocket: WebSocket, manager: ConnectionManager, message: WsMessage\n):\n    if not message.data:\n        await websocket.send_text(\n            WsMessage(\n                method=Methods.ERROR,\n                success=False,\n                error=\"Subscription data missing\",\n            ).model_dump_json()\n        )\n    else:\n        ex_sub = ExecutionSubscription.model_validate(message.data)\n        await manager.unsubscribe(ex_sub.graph_id, websocket)\n        logger.debug(f\"Removed execution subscription for graph {ex_sub.graph_id}\")\n        await websocket.send_text(\n            WsMessage(\n                method=Methods.UNSUBSCRIBE,\n                success=True,\n                channel=ex_sub.graph_id,\n            ).model_dump_json()\n        )", "blocks": [{"id": 1, "label": "if not message.data:", "successors": [{"id": 2, "label": "    await websocket.send_text(\n        WsMessage(\n            method=Methods.ERROR,\n            success=False,\n            error=\"Subscription data missing\",\n        ).model_dump_json()\n    )", "successors": []}, {"id": 3, "label": "    ex_sub = ExecutionSubscription.model_validate(message.data)\n    await manager.unsubscribe(ex_sub.graph_id, websocket)\n    logger.debug(f\"Removed execution subscription for graph {ex_sub.graph_id}\")\n    await websocket.send_text(\n        WsMessage(\n            method=Methods.UNSUBSCRIBE,\n            success=True,\n            channel=ex_sub.graph_id,\n        ).model_dump_json()\n    )", "successors": []}]}]}, {"name": "health", "type": "function", "start_line": 125, "end_line": 126, "functions": [], "classes": [], "simplified_code": "async def health():\n    return {\"status\": \"healthy\"}", "blocks": [{"id": 1, "label": "async def health():\nreturn {\"status\": \"healthy\"}", "successors": []}]}, {"name": "websocket_router", "type": "function", "start_line": 130, "end_line": 172, "functions": [], "classes": [], "simplified_code": "async def websocket_router(\n    websocket: WebSocket, manager: ConnectionManager = Depends(get_connection_manager)\n):\n    user_id = await authenticate_websocket(websocket)\n    if not user_id:\n        return\n    await manager.connect(websocket)\n    try:\n        while True:\n            data = await websocket.receive_text()\n            message = WsMessage.model_validate_json(data)\n\n            if message.method == Methods.HEARTBEAT:\n                await websocket.send_json(\n                    {\"method\": Methods.HEARTBEAT.value, \"data\": \"pong\", \"success\": True}\n                )\n                continue\n\n            if message.method == Methods.SUBSCRIBE:\n                await handle_subscribe(websocket, manager, message)\n\n            elif message.method == Methods.UNSUBSCRIBE:\n                await handle_unsubscribe(websocket, manager, message)\n\n            elif message.method == Methods.ERROR:\n                logger.error(f\"WebSocket Error message received: {message.data}\")\n\n            else:\n                logger.warning(\n                    f\"Unknown WebSocket message type {message.method} received: \"\n                    f\"{message.data}\"\n                )\n                await websocket.send_text(\n                    WsMessage(\n                        method=Methods.ERROR,\n                        success=False,\n                        error=\"Message type is not processed by the server\",\n                    ).model_dump_json()\n                )\n\n    except WebSocketDisconnect:\n        manager.disconnect(websocket)\n        logger.debug(\"WebSocket client disconnected\")", "blocks": [{"id": 1, "label": "async def websocket_router(\n    websocket: WebSocket, manager: ConnectionManager = Depends(get_connection_manager)\n):\n    user_id = await authenticate_websocket(websocket)\n    if not user_id:", "successors": [{"id": 2, "label": "return", "successors": []}, {"id": 3, "label": "await manager.connect(websocket)\n    try:", "successors": [{"id": 4, "label": "while True:", "successors": [{"id": 5, "label": "data = await websocket.receive_text()\n            message = WsMessage.model_validate_json(data)\n\n            if message.method == Methods.HEARTBEAT:\nawait websocket.send_json(\n                    {\"method\": Methods.HEARTBEAT.value, \"data\": \"pong\", \"success\": True}\n                )\n                continue", "successors": [{"id": 4, "label": "while True:", "successors": []}]}, {"id": 7, "label": "if message.method == Methods.SUBSCRIBE:\nawait handle_subscribe(websocket, manager, message)", "successors": [{"id": 4, "label": "while True:", "successors": []}]}, {"id": 9, "label": "elif message.method == Methods.UNSUBSCRIBE:\nawait handle_unsubscribe(websocket, manager, message)", "successors": [{"id": 4, "label": "while True:", "successors": []}]}, {"id": 11, "label": "elif message.method == Methods.ERROR:\nlogger.error(f\"WebSocket Error message received: {message.data}\")", "successors": [{"id": 4, "label": "while True:", "successors": []}]}, {"id": 13, "label": "else:\nlogger.warning(\n                    f\"Unknown WebSocket message type {message.method} received: \"\n                    f\"{message.data}\"\n                )\n                await websocket.send_text(\n                    WsMessage(\n                        method=Methods.ERROR,\n                        success=False,\n                        error=\"Message type is not processed by the server\",\n                    ).model_dump_json()\n                )", "successors": [{"id": 4, "label": "while True:", "successors": []}]}]}, {"id": 15, "label": "except WebSocketDisconnect:\nmanager.disconnect(websocket)\n        logger.debug(\"WebSocket client disconnected\")", "successors": []}]}]}]}], "classes": [{"name": "WebsocketServer", "type": "class", "start_line": 175, "end_line": 189, "functions": [{"name": "run", "type": "function", "start_line": 176, "end_line": 189, "functions": [], "classes": [], "simplified_code": "    def run(self):\n        logger.info(f\"CORS allow origins: {settings.config.backend_cors_allow_origins}\")\n        server_app = CORSMiddleware(\n            app=app,\n            allow_origins=settings.config.backend_cors_allow_origins,\n            allow_credentials=True,\n            allow_methods=[\"*\"],\n            allow_headers=[\"*\"],\n        )\n        uvicorn.run(\n            server_app,\n            host=Config().websocket_server_host,\n            port=Config().websocket_server_port,\n        )", "blocks": [{"id": 1, "label": "logger.info(f\"CORS allow origins: {settings.config.backend_cors_allow_origins}\")\nserver_app = CORSMiddleware(\n    app=app,\n    allow_origins=settings.config.backend_cors_allow_origins,\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"]\n)", "successors": [{"id": 3, "label": "uvicorn.run(\n    server_app,\n    host=Config().websocket_server_host,\n    port=Config().websocket_server_port\n)", "successors": []}]}]}], "classes": [], "simplified_code": "class WebsocketServer(AppProcess):\n        )", "blocks": []}], "simplified_code": "import asyncio\nimport logging\nfrom contextlib import asynccontextmanager\n\nimport uvicorn\nfrom autogpt_libs.auth import parse_jwt_token\nfrom fastapi import Depends, FastAPI, WebSocket, WebSocketDisconnect\nfrom starlette.middleware.cors import CORSMiddleware\n\nfrom backend.data import redis\nfrom backend.data.execution import AsyncRedisExecutionEventBus\nfrom backend.data.user import DEFAULT_USER_ID\nfrom backend.server.conn_manager import ConnectionManager\nfrom backend.server.model import ExecutionSubscription, Methods, WsMessage\nfrom backend.util.service import AppProcess\nfrom backend.util.settings import AppEnvironment, Config, Settings\n\nlogger = logging.getLogger(__name__)\nsettings = Settings()\n\n\n@asynccontextmanager\n    yield\n\n\ndocs_url = \"/docs\" if settings.config.app_env == AppEnvironment.LOCAL else None\napp = FastAPI(lifespan=lifespan, docs_url=docs_url)\n_connection_manager = None\n\n\n    return _connection_manager\n\n\n        redis.disconnect()\n\n\n        return \"\"\n\n\n        )\n\n\n        )\n\n\n@app.get(\"/\")\n    return {\"status\": \"healthy\"}\n\n\n@app.websocket(\"/ws\")\n        logger.debug(\"WebSocket client disconnected\")\n\n\n        )", "blocks": [{"id": 1, "label": "import asyncio\nimport logging\nfrom contextlib import asynccontextmanager\n\nimport uvicorn\nfrom autogpt_libs.auth import parse_jwt_token\nfrom fastapi import Depends, FastAPI, WebSocket, WebSocketDisconnect\nfrom starlette.middleware.cors import CORSMiddleware\n\nfrom backend.data import redis\nfrom backend.data.execution import AsyncRedisExecutionEventBus\nfrom backend.data.user import DEFAULT_USER_ID\nfrom backend.server.conn_manager import ConnectionManager\nfrom backend.server.model import ExecutionSubscription, Methods, WsMessage\nfrom backend.util.service import AppProcess\nfrom backend.util.settings import AppEnvironment, Config, Settings\n\nlogger = logging.getLogger(__name__)\nsettings = Settings()", "successors": [{"id": 2, "label": "@asynccontextmanager\nyield", "successors": []}, {"id": 3, "label": "docs_url = \"/docs\" if settings.config.app_env == AppEnvironment.LOCAL else None\napp = FastAPI(lifespan=lifespan, docs_url=docs_url)\n_connection_manager = None", "successors": []}, {"id": 4, "label": "return _connection_manager", "successors": []}, {"id": 5, "label": "redis.disconnect()", "successors": []}, {"id": 6, "label": "return \"\"", "successors": []}, {"id": 7, "label": "@app.get(\"/\")\nreturn {\"status\": \"healthy\"}", "successors": []}, {"id": 8, "label": "@app.websocket(\"/ws\")\nlogger.debug(\"WebSocket client disconnected\")", "successors": []}]}]}
{"file_name": "177.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 57, "functions": [], "classes": [{"name": "RedisKeyedMutex", "type": "class", "start_line": 12, "end_line": 57, "functions": [{"name": "__init__", "type": "function", "start_line": 20, "end_line": 26, "functions": [], "classes": [], "simplified_code": "    def __init__(self, redis: \"Redis\", timeout: int | None = 60):\n        self.redis = redis\n        self.timeout = timeout\n        self.locks: dict[Any, \"RedisLock\"] = ExpiringDict(\n            max_len=6000, max_age_seconds=self.timeout\n        )\n        self.locks_lock = Lock()", "blocks": [{"id": 1, "label": "def __init__(self, redis: \"Redis\", timeout: int | None = 60):\n    self.redis = redis\n    self.timeout = timeout\n    self.locks: dict[Any, \"RedisLock\"] = ExpiringDict(\n        max_len=6000, max_age_seconds=self.timeout\n    )\n    self.locks_lock = Lock()", "successors": []}]}, {"name": "locked", "type": "function", "start_line": 29, "end_line": 35, "functions": [], "classes": [], "simplified_code": "    def locked(self, key: Any):\n        lock = self.acquire(key)\n        try:\n            yield\n        finally:\n            if lock.locked():\n                lock.release()", "blocks": [{"id": 1, "label": "def locked(self, key: Any):\nlock = self.acquire(key)", "successors": [{"id": 3, "label": "try:\nyield", "successors": [{"id": 5, "label": "finally:\nif lock.locked():", "successors": [{"id": 7, "label": "lock.release()", "successors": []}]}]}]}]}, {"name": "acquire", "type": "function", "start_line": 37, "end_line": 46, "functions": [], "classes": [], "simplified_code": "    def acquire(self, key: Any) -> \"RedisLock\":\n        \"\"\"Acquires and returns a lock with the given key\"\"\"\n        with self.locks_lock:\n            if key not in self.locks:\n                self.locks[key] = self.redis.lock(\n                    str(key), self.timeout, thread_local=False\n                )\n            lock = self.locks[key]\n        lock.acquire()\n        return lock", "blocks": [{"id": 1, "label": "def acquire(self, key: Any) -> \"RedisLock\":\n    with self.locks_lock:", "successors": [{"id": 3, "label": "        if key not in self.locks:", "successors": [{"id": 4, "label": "            self.locks[key] = self.redis.lock(\n                str(key), self.timeout, thread_local=False\n            )\n        lock = self.locks[key]", "successors": [{"id": 6, "label": "lock.acquire()\nreturn lock", "successors": []}]}, {"id": 5, "label": "        lock = self.locks[key]\nlock.acquire()", "successors": [{"id": 7, "label": "return lock", "successors": []}]}]}]}]}, {"name": "release", "type": "function", "start_line": 48, "end_line": 50, "functions": [], "classes": [], "simplified_code": "    def release(self, key: Any):\n        if (lock := self.locks.get(key)) and lock.locked() and lock.owned():\n            lock.release()", "blocks": [{"id": 1, "label": "def release(self, key: Any):\nif (lock := self.locks.get(key)) and lock.locked() and lock.owned():", "successors": [{"id": 3, "label": "lock.release()", "successors": []}]}]}, {"name": "release_all_locks", "type": "function", "start_line": 52, "end_line": 57, "functions": [], "classes": [], "simplified_code": "    def release_all_locks(self):\n        \"\"\"Call this on process termination to ensure all locks are released\"\"\"\n        self.locks_lock.acquire(blocking=False)\n        for lock in self.locks.values():\n            if lock.locked() and lock.owned():\n                lock.release()", "blocks": [{"id": 1, "label": "def release_all_locks(self):\n\"\"\"Call this on process termination to ensure all locks are released\"\"\"\nself.locks_lock.acquire(blocking=False)", "successors": [{"id": 3, "label": "for lock in self.locks.values():", "successors": [{"id": 4, "label": "if lock.locked() and lock.owned():\nlock.release()", "successors": []}]}]}]}], "classes": [], "simplified_code": "class RedisKeyedMutex:\n    \"\"\"\n    This class provides a mutex that can be locked and unlocked by a specific key,\n    using Redis as a distributed locking provider.\n    It uses an ExpiringDict to automatically clear the mutex after a specified timeout,\n    in case the key is not unlocked for a specified duration, to prevent memory leaks.\n    \"\"\"\n\n        self.locks_lock = Lock()\n\n    @contextmanager\n                lock.release()\n\n        return lock\n\n            lock.release()\n\n                lock.release()", "blocks": [{"id": 1, "label": "class RedisKeyedMutex:\n\"\"\"\nThis class provides a mutex that can be locked and unlocked by a specific key,\nusing Redis as a distributed locking provider.\nIt uses an ExpiringDict to automatically clear the mutex after a specified timeout,\nin case the key is not unlocked for a specified duration, to prevent memory leaks.\n\"\"\"", "successors": [{"id": 3, "label": "self.locks_lock = Lock()\n@contextmanager", "successors": [{"id": 5, "label": "lock.release()\nreturn lock", "successors": [{"id": 7, "label": "lock.release()\nlock.release()", "successors": []}]}]}]}]}], "simplified_code": "from contextlib import contextmanager\nfrom threading import Lock\nfrom typing import TYPE_CHECKING, Any\n\nfrom expiringdict import ExpiringDict\n\nif TYPE_CHECKING:\n    from redis import Redis\n    from redis.lock import Lock as RedisLock\n\n\n                lock.release()", "blocks": [{"id": 1, "label": "from contextlib import contextmanager\nfrom threading import Lock\nfrom typing import TYPE_CHECKING, Any\n\nfrom expiringdict import ExpiringDict\n\nif TYPE_CHECKING:\n    from redis import Redis\n    from redis.lock import Lock as RedisLock\n\n\nlock.release()", "successors": []}]}
{"file_name": "178.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 237, "functions": [], "classes": [{"name": "ReplicateFluxModelName", "type": "class", "start_line": 34, "end_line": 46, "functions": [{"name": "api_name", "type": "function", "start_line": 40, "end_line": 46, "functions": [], "classes": [], "simplified_code": "    def api_name(self):\n        api_names = {\n            ReplicateFluxModelName.FLUX_SCHNELL: \"black-forest-labs/flux-schnell\",\n            ReplicateFluxModelName.FLUX_PRO: \"black-forest-labs/flux-pro\",\n            ReplicateFluxModelName.FLUX_PRO1_1: \"black-forest-labs/flux-1.1-pro\",\n        }\n        return api_names[self]", "blocks": [{"id": 1, "label": "def api_name(self):\napi_names = {\n    ReplicateFluxModelName.FLUX_SCHNELL: \"black-forest-labs/flux-schnell\",\n    ReplicateFluxModelName.FLUX_PRO: \"black-forest-labs/flux-pro\",\n    ReplicateFluxModelName.FLUX_PRO1_1: \"black-forest-labs/flux-1.1-pro\",\n}", "successors": [{"id": 3, "label": "return api_names[self]", "successors": []}]}]}], "simplified_code": "class ReplicateFluxModelName(str, Enum):\n    FLUX_SCHNELL = (\"Flux Schnell\",)\n    FLUX_PRO = (\"Flux Pro\",)\n    FLUX_PRO1_1 = (\"Flux Pro 1.1\",)\n\n    @property\n        return api_names[self]", "blocks": [{"id": 1, "label": "class ReplicateFluxModelName(str, Enum):", "successors": [{"id": 2, "label": "    FLUX_SCHNELL = (\"Flux Schnell\",)", "successors": []}, {"id": 3, "label": "    FLUX_PRO = (\"Flux Pro\",)", "successors": []}, {"id": 4, "label": "    FLUX_PRO1_1 = (\"Flux Pro 1.1\",)", "successors": []}, {"id": 5, "label": "    @property\n        return api_names[self]", "successors": []}]}]}, {"name": "ImageType", "type": "class", "start_line": 50, "end_line": 53, "functions": [], "classes": [], "simplified_code": "class ImageType(str, Enum):\n    WEBP = \"webp\"\n    JPG = \"jpg\"\n    PNG = \"png\"", "blocks": [{"id": 1, "label": "class ImageType(str, Enum):\n    WEBP = \"webp\"\n    JPG = \"jpg\"\n    PNG = \"png\"", "successors": []}]}, {"name": "ReplicateFluxAdvancedModelBlock", "type": "class", "start_line": 56, "end_line": 237, "functions": [{"name": "__init__", "type": "function", "start_line": 130, "end_line": 160, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"90f8c45e-e983-4644-aa0b-b4ebe2f531bc\",\n            description=\"This block runs Flux models on Replicate with advanced settings.\",\n            categories={BlockCategory.AI},\n            input_schema=ReplicateFluxAdvancedModelBlock.Input,\n            output_schema=ReplicateFluxAdvancedModelBlock.Output,\n            test_input={\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n                \"replicate_model_name\": ReplicateFluxModelName.FLUX_SCHNELL,\n                \"prompt\": \"A beautiful landscape painting of a serene lake at sunrise\",\n                \"seed\": None,\n                \"steps\": 25,\n                \"guidance\": 3.0,\n                \"interval\": 2.0,\n                \"aspect_ratio\": \"1:1\",\n                \"output_format\": ImageType.PNG,\n                \"output_quality\": 80,\n                \"safety_tolerance\": 2,\n            },\n            test_output=[\n                (\n                    \"result\",\n                    \"https://replicate.com/output/generated-image-url.jpg\",\n                ),\n            ],\n            test_mock={\n                \"run_model\": lambda api_key, model_name, prompt, seed, steps, guidance, interval, aspect_ratio, output_format, output_quality, safety_tolerance: \"https://replicate.com/output/generated-image-url.jpg\",\n            },\n            test_credentials=TEST_CREDENTIALS,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"90f8c45e-e983-4644-aa0b-b4ebe2f531bc\",\n    description=\"This block runs Flux models on Replicate with advanced settings.\",\n    categories={BlockCategory.AI},\n    input_schema=ReplicateFluxAdvancedModelBlock.Input,\n    output_schema=ReplicateFluxAdvancedModelBlock.Output,\n    test_input={\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n        \"replicate_model_name\": ReplicateFluxModelName.FLUX_SCHNELL,\n        \"prompt\": \"A beautiful landscape painting of a serene lake at sunrise\",\n        \"seed\": None,\n        \"steps\": 25,\n        \"guidance\": 3.0,\n        \"interval\": 2.0,\n        \"aspect_ratio\": \"1:1\",\n        \"output_format\": ImageType.PNG,\n        \"output_quality\": 80,\n        \"safety_tolerance\": 2,\n    },\n    test_output=[\n        (\n            \"result\",\n            \"https://replicate.com/output/generated-image-url.jpg\",\n        ),\n    ],\n    test_mock={\n        \"run_model\": lambda api_key, model_name, prompt, seed, steps, guidance, interval, aspect_ratio, output_format, output_quality, safety_tolerance: \"https://replicate.com/output/generated-image-url.jpg\",\n    },\n    test_credentials=TEST_CREDENTIALS,\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 162, "end_line": 184, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        # If the seed is not provided, generate a random seed\n        seed = input_data.seed\n        if seed is None:\n            seed = int.from_bytes(os.urandom(4), \"big\")\n\n        # Run the model using the provided inputs\n        result = self.run_model(\n            api_key=credentials.api_key,\n            model_name=input_data.replicate_model_name.api_name,\n            prompt=input_data.prompt,\n            seed=seed,\n            steps=input_data.steps,\n            guidance=input_data.guidance,\n            interval=input_data.interval,\n            aspect_ratio=input_data.aspect_ratio,\n            output_format=input_data.output_format,\n            output_quality=input_data.output_quality,\n            safety_tolerance=input_data.safety_tolerance,\n        )\n        yield \"result\", result", "blocks": [{"id": 1, "label": "def run(\n    self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n) -> BlockOutput:\n# If the seed is not provided, generate a random seed\nseed = input_data.seed", "successors": [{"id": 3, "label": "if seed is None:\n    seed = int.from_bytes(os.urandom(4), \"big\")", "successors": [{"id": 5, "label": "# Run the model using the provided inputs\nresult = self.run_model(\n    api_key=credentials.api_key,\n    model_name=input_data.replicate_model_name.api_name,\n    prompt=input_data.prompt,\n    seed=seed,\n    steps=input_data.steps,\n    guidance=input_data.guidance,\n    interval=input_data.interval,\n    aspect_ratio=input_data.aspect_ratio,\n    output_format=input_data.output_format,\n    output_quality=input_data.output_quality,\n    safety_tolerance=input_data.safety_tolerance,\n)\nyield \"result\", result", "successors": []}]}, {"id": 5, "label": "# Run the model using the provided inputs\nresult = self.run_model(\n    api_key=credentials.api_key,\n    model_name=input_data.replicate_model_name.api_name,\n    prompt=input_data.prompt,\n    seed=seed,\n    steps=input_data.steps,\n    guidance=input_data.guidance,\n    interval=input_data.interval,\n    aspect_ratio=input_data.aspect_ratio,\n    output_format=input_data.output_format,\n    output_quality=input_data.output_quality,\n    safety_tolerance=input_data.safety_tolerance,\n)\nyield \"result\", result", "successors": []}]}]}, {"name": "run_model", "type": "function", "start_line": 186, "end_line": 237, "functions": [], "classes": [], "simplified_code": "    def run_model(\n        self,\n        api_key: SecretStr,\n        model_name,\n        prompt,\n        seed,\n        steps,\n        guidance,\n        interval,\n        aspect_ratio,\n        output_format,\n        output_quality,\n        safety_tolerance,\n    ):\n        # Initialize Replicate client with the API key\n        client = replicate.Client(api_token=api_key.get_secret_value())\n\n        # Run the model with additional parameters\n        output: FileOutput | list[FileOutput] = client.run(  # type: ignore This is because they changed the return type, and didn't update the type hint! It should be overloaded depending on the value of `use_file_output` to `FileOutput | list[FileOutput]` but it's `Any | Iterator[Any]`\n            f\"{model_name}\",\n            input={\n                \"prompt\": prompt,\n                \"seed\": seed,\n                \"steps\": steps,\n                \"guidance\": guidance,\n                \"interval\": interval,\n                \"aspect_ratio\": aspect_ratio,\n                \"output_format\": output_format,\n                \"output_quality\": output_quality,\n                \"safety_tolerance\": safety_tolerance,\n            },\n            wait=False,  # don't arbitrarily return data:octect/stream or sometimes url depending on the model???? what is this api\n        )\n\n        # Check if output is a list or a string and extract accordingly; otherwise, assign a default message\n        if isinstance(output, list) and len(output) > 0:\n            if isinstance(output[0], FileOutput):\n                result_url = output[0].url  # If output is a list, get the first element\n            else:\n                result_url = output[\n                    0\n                ]  # If output is a list and not a FileOutput, get the first element. Should never happen, but just in case.\n        elif isinstance(output, FileOutput):\n            result_url = output.url  # If output is a FileOutput, use the url\n        elif isinstance(output, str):\n            result_url = output  # If output is a string (for some reason due to their janky type hinting), use it directly\n        else:\n            result_url = (\n                \"No output received\"  # Fallback message if output is not as expected\n            )\n\n        return result_url", "blocks": [{"id": 1, "label": "client = replicate.Client(api_token=api_key.get_secret_value())\n\noutput: FileOutput | list[FileOutput] = client.run(\n    f\"{model_name}\",\n    input={\n        \"prompt\": prompt,\n        \"seed\": seed,\n        \"steps\": steps,\n        \"guidance\": guidance,\n        \"interval\": interval,\n        \"aspect_ratio\": aspect_ratio,\n        \"output_format\": output_format,\n        \"output_quality\": output_quality,\n        \"safety_tolerance\": safety_tolerance,\n    },\n    wait=False,\n)", "successors": [{"id": 2, "label": "if isinstance(output, list) and len(output) > 0:", "successors": [{"id": 3, "label": "    if isinstance(output[0], FileOutput):\n        result_url = output[0].url\n    else:\n        result_url = output[0]\nreturn result_url", "successors": []}, {"id": 4, "label": "\nreturn result_url", "successors": []}]}, {"id": 5, "label": "elif isinstance(output, FileOutput):\n    result_url = output.url\nreturn result_url", "successors": []}, {"id": 6, "label": "elif isinstance(output, str):\n    result_url = output\nelse:\n    result_url = \"No output received\"\nreturn result_url", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 57, "end_line": 124, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: CredentialsMetaInput[\n            Literal[ProviderName.REPLICATE], Literal[\"api_key\"]\n        ] = CredentialsField(\n            description=\"The Replicate integration can be used with \"\n            \"any API key with sufficient permissions for the blocks it is used on.\",\n        )\n        prompt: str = SchemaField(\n            description=\"Text prompt for image generation\",\n            placeholder=\"e.g., 'A futuristic cityscape at sunset'\",\n            title=\"Prompt\",\n        )\n        replicate_model_name: ReplicateFluxModelName = SchemaField(\n            description=\"The name of the Image Generation Model, i.e Flux Schnell\",\n            default=ReplicateFluxModelName.FLUX_SCHNELL,\n            title=\"Image Generation Model\",\n            advanced=False,\n        )\n        seed: int | None = SchemaField(\n            description=\"Random seed. Set for reproducible generation\",\n            default=None,\n            title=\"Seed\",\n        )\n        steps: int = SchemaField(\n            description=\"Number of diffusion steps\",\n            default=25,\n            title=\"Steps\",\n        )\n        guidance: float = SchemaField(\n            description=(\n                \"Controls the balance between adherence to the text prompt and image quality/diversity. \"\n                \"Higher values make the output more closely match the prompt but may reduce overall image quality.\"\n            ),\n            default=3,\n            title=\"Guidance\",\n        )\n        interval: float = SchemaField(\n            description=(\n                \"Interval is a setting that increases the variance in possible outputs. \"\n                \"Setting this value low will ensure strong prompt following with more consistent outputs.\"\n            ),\n            default=2,\n            title=\"Interval\",\n        )\n        aspect_ratio: str = SchemaField(\n            description=\"Aspect ratio for the generated image\",\n            default=\"1:1\",\n            title=\"Aspect Ratio\",\n            placeholder=\"Choose from: 1:1, 16:9, 2:3, 3:2, 4:5, 5:4, 9:16\",\n        )\n        output_format: ImageType = SchemaField(\n            description=\"File format of the output image\",\n            default=ImageType.WEBP,\n            title=\"Output Format\",\n        )\n        output_quality: int = SchemaField(\n            description=(\n                \"Quality when saving the output images, from 0 to 100. \"\n                \"Not relevant for .png outputs\"\n            ),\n            default=80,\n            title=\"Output Quality\",\n        )\n        safety_tolerance: int = SchemaField(\n            description=\"Safety tolerance, 1 is most strict and 5 is most permissive\",\n            default=2,\n            title=\"Safety Tolerance\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\ncredentials: CredentialsMetaInput[\n    Literal[ProviderName.REPLICATE], Literal[\"api_key\"]\n] = CredentialsField(\n    description=\"The Replicate integration can be used with any API key with sufficient permissions for the blocks it is used on.\",\n)\n", "successors": [{"id": 3, "label": "prompt: str = SchemaField(\n    description=\"Text prompt for image generation\",\n    placeholder=\"e.g., 'A futuristic cityscape at sunset'\",\n    title=\"Prompt\",\n)\n\nreplicate_model_name: ReplicateFluxModelName = SchemaField(\n    description=\"The name of the Image Generation Model, i.e Flux Schnell\",\n    default=ReplicateFluxModelName.FLUX_SCHNELL,\n    title=\"Image Generation Model\",\n    advanced=False,\n)\n", "successors": [{"id": 5, "label": "seed: int | None = SchemaField(\n    description=\"Random seed. Set for reproducible generation\",\n    default=None,\n    title=\"Seed\",\n)\n\nsteps: int = SchemaField(\n    description=\"Number of diffusion steps\",\n    default=25,\n    title=\"Steps\",\n)\n", "successors": [{"id": 7, "label": "guidance: float = SchemaField(\n    description=(\n        \"Controls the balance between adherence to the text prompt and image quality/diversity. \"\n        \"Higher values make the output more closely match the prompt but may reduce overall image quality.\"\n    ),\n    default=3,\n    title=\"Guidance\",\n)\n\ninterval: float = SchemaField(\n    description=(\n        \"Interval is a setting that increases the variance in possible outputs. \"\n        \"Setting this value low will ensure strong prompt following with more consistent outputs.\"\n    ),\n    default=2,\n    title=\"Interval\",\n)\n", "successors": [{"id": 9, "label": "aspect_ratio: str = SchemaField(\n    description=\"Aspect ratio for the generated image\",\n    default=\"1:1\",\n    title=\"Aspect Ratio\",\n    placeholder=\"Choose from: 1:1, 16:9, 2:3, 3:2, 4:5, 5:4, 9:16\",\n)\n\noutput_format: ImageType = SchemaField(\n    description=\"File format of the output image\",\n    default=ImageType.WEBP,\n    title=\"Output Format\",\n)\n", "successors": [{"id": 11, "label": "output_quality: int = SchemaField(\n    description=(\n        \"Quality when saving the output images, from 0 to 100. \"\n        \"Not relevant for .png outputs\"\n    ),\n    default=80,\n    title=\"Output Quality\",\n)\n\nsafety_tolerance: int = SchemaField(\n    description=\"Safety tolerance, 1 is most strict and 5 is most permissive\",\n    default=2,\n    title=\"Safety Tolerance\",\n)\n", "successors": []}]}]}]}]}]}]}, {"name": "Output", "type": "class", "start_line": 126, "end_line": 128, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        result: str = SchemaField(description=\"Generated output\")\n        error: str = SchemaField(description=\"Error message if the model run failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    result: str = SchemaField(description=\"Generated output\")", "successors": [{"id": 3, "label": "    error: str = SchemaField(description=\"Error message if the model run failed\")", "successors": []}]}]}], "simplified_code": "class ReplicateFluxAdvancedModelBlock(Block):\n        )\n\n        error: str = SchemaField(description=\"Error message if the model run failed\")\n\n        )\n\n        yield \"result\", result\n\n        return result_url", "blocks": [{"id": 1, "label": "class ReplicateFluxAdvancedModelBlock(Block):", "successors": [{"id": 2, "label": "error: str = SchemaField(description=\"Error message if the model run failed\")", "successors": []}, {"id": 3, "label": "yield \"result\", result", "successors": []}, {"id": 4, "label": "return result_url", "successors": []}]}]}], "simplified_code": "import os\nfrom enum import Enum\nfrom typing import Literal\n\nimport replicate\nfrom pydantic import SecretStr\nfrom replicate.helpers import FileOutput\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"replicate\",\n    api_key=SecretStr(\"mock-replicate-api-key\"),\n    title=\"Mock Replicate API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.type,\n}\n\n\n# Model name enum\n        return api_names[self]\n\n\n# Image type Enum\n    PNG = \"png\"\n\n\n        return result_url", "blocks": [{"id": 1, "label": "import os\nfrom enum import Enum\nfrom typing import Literal\n\nimport replicate\nfrom pydantic import SecretStr\nfrom replicate.helpers import FileOutput\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"01234567-89ab-cdef-0123-456789abcdef\",\n    provider=\"replicate\",\n    api_key=SecretStr(\"mock-replicate-api-key\"),\n    title=\"Mock Replicate API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.type,\n}\n\n\n# Model name enum\n        return api_names[self]\n\n\n# Image type Enum\n    PNG = \"png\"\n\n\n        return result_url", "successors": []}]}
{"file_name": "179.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 85, "functions": [], "classes": [{"name": "Slant3DFilamentBlock", "type": "class", "start_line": 16, "end_line": 85, "functions": [{"name": "__init__", "type": "function", "start_line": 28, "end_line": 73, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"7cc416f4-f305-4606-9b3b-452b8a81031c\",\n            description=\"Get list of available filaments\",\n            input_schema=self.Input,\n            output_schema=self.Output,\n            test_input={\"credentials\": TEST_CREDENTIALS_INPUT},\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\n                    \"filaments\",\n                    [\n                        {\n                            \"filament\": \"PLA BLACK\",\n                            \"hexColor\": \"000000\",\n                            \"colorTag\": \"black\",\n                            \"profile\": \"PLA\",\n                        },\n                        {\n                            \"filament\": \"PLA WHITE\",\n                            \"hexColor\": \"ffffff\",\n                            \"colorTag\": \"white\",\n                            \"profile\": \"PLA\",\n                        },\n                    ],\n                )\n            ],\n            test_mock={\n                \"_make_request\": lambda *args, **kwargs: {\n                    \"filaments\": [\n                        {\n                            \"filament\": \"PLA BLACK\",\n                            \"hexColor\": \"000000\",\n                            \"colorTag\": \"black\",\n                            \"profile\": \"PLA\",\n                        },\n                        {\n                            \"filament\": \"PLA WHITE\",\n                            \"hexColor\": \"ffffff\",\n                            \"colorTag\": \"white\",\n                            \"profile\": \"PLA\",\n                        },\n                    ]\n                }\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"7cc416f4-f305-4606-9b3b-452b8a81031c\",\n    description=\"Get list of available filaments\",\n    input_schema=self.Input,\n    output_schema=self.Output,\n    test_input={\"credentials\": TEST_CREDENTIALS_INPUT},\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\n            \"filaments\",\n            [\n                {\n                    \"filament\": \"PLA BLACK\",\n                    \"hexColor\": \"000000\",\n                    \"colorTag\": \"black\",\n                    \"profile\": \"PLA\",\n                },\n                {\n                    \"filament\": \"PLA WHITE\",\n                    \"hexColor\": \"ffffff\",\n                    \"colorTag\": \"white\",\n                    \"profile\": \"PLA\",\n                },\n            ],\n        )\n    ],\n    test_mock={\n        \"_make_request\": lambda *args, **kwargs: {\n            \"filaments\": [\n                {\n                    \"filament\": \"PLA BLACK\",\n                    \"hexColor\": \"000000\",\n                    \"colorTag\": \"black\",\n                    \"profile\": \"PLA\",\n                },\n                {\n                    \"filament\": \"PLA WHITE\",\n                    \"hexColor\": \"ffffff\",\n                    \"colorTag\": \"white\",\n                    \"profile\": \"PLA\",\n                },\n            ]\n        }\n    },\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 75, "end_line": 85, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        try:\n            result = self._make_request(\n                \"GET\", \"filament\", credentials.api_key.get_secret_value()\n            )\n            yield \"filaments\", result[\"filaments\"]\n        except Exception as e:\n            yield \"error\", str(e)\n            raise", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs) -> BlockOutput:\ntry:", "successors": [{"id": 3, "label": "result = self._make_request(\n    \"GET\", \"filament\", credentials.api_key.get_secret_value()\n)\nyield \"filaments\", result[\"filaments\"]", "successors": []}, {"id": 5, "label": "except Exception as e:\nyield \"error\", str(e)", "successors": [{"id": 7, "label": "raise", "successors": []}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 19, "end_line": 20, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: Slant3DCredentialsInput = Slant3DCredentialsField()", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: Slant3DCredentialsInput = Slant3DCredentialsField()", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 22, "end_line": 26, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        filaments: List[Filament] = SchemaField(\n            description=\"List of available filaments\"\n        )\n        error: str = SchemaField(description=\"Error message if request failed\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "    filaments: List[Filament] = SchemaField(description=\"List of available filaments\")", "successors": []}, {"id": 3, "label": "    error: str = SchemaField(description=\"Error message if request failed\")", "successors": []}]}]}], "simplified_code": "class Slant3DFilamentBlock(Slant3DBlockBase):\n    \"\"\"Block for retrieving available filaments\"\"\"\n\n        credentials: Slant3DCredentialsInput = Slant3DCredentialsField()\n\n        error: str = SchemaField(description=\"Error message if request failed\")\n\n        )\n\n            raise", "blocks": [{"id": 1, "label": "class Slant3DFilamentBlock(Slant3DBlockBase):\n\"\"\"Block for retrieving available filaments\"\"\"\n\n    credentials: Slant3DCredentialsInput = Slant3DCredentialsField()\n\n    error: str = SchemaField(description=\"Error message if request failed\")", "successors": [{"id": 3, "label": "pass", "successors": []}]}]}], "simplified_code": "from typing import List\n\nfrom backend.data.block import BlockOutput, BlockSchema\nfrom backend.data.model import APIKeyCredentials, SchemaField\n\nfrom ._api import (\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    Filament,\n    Slant3DCredentialsField,\n    Slant3DCredentialsInput,\n)\nfrom .base import Slant3DBlockBase\n\n\n            raise", "blocks": [{"id": 1, "label": "from typing import List\n\nfrom backend.data.block import BlockOutput, BlockSchema\nfrom backend.data.model import APIKeyCredentials, SchemaField\n\nfrom ._api import (\n    TEST_CREDENTIALS,\n    TEST_CREDENTIALS_INPUT,\n    Filament,\n    Slant3DCredentialsField,\n    Slant3DCredentialsInput,\n)\nfrom .base import Slant3DBlockBase\n\n\nraise", "successors": []}]}
{"file_name": "180.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 130, "functions": [{"name": "get_or_create_user", "type": "function", "start_line": 16, "end_line": 34, "functions": [], "classes": [], "simplified_code": "async def get_or_create_user(user_data: dict) -> User:\n    user_id = user_data.get(\"sub\")\n    if not user_id:\n        raise HTTPException(status_code=401, detail=\"User ID not found in token\")\n\n    user_email = user_data.get(\"email\")\n    if not user_email:\n        raise HTTPException(status_code=401, detail=\"Email not found in token\")\n\n    user = await prisma.user.find_unique(where={\"id\": user_id})\n    if not user:\n        user = await prisma.user.create(\n            data={\n                \"id\": user_id,\n                \"email\": user_email,\n                \"name\": user_data.get(\"user_metadata\", {}).get(\"name\"),\n            }\n        )\n    return User.model_validate(user)", "blocks": [{"id": 1, "label": "async def get_or_create_user(user_data: dict) -> User:", "successors": [{"id": 2, "label": "user_id = user_data.get(\"sub\")\nif not user_id:", "successors": [{"id": 4, "label": "raise HTTPException(status_code=401, detail=\"User ID not found in token\")", "successors": []}]}, {"id": 5, "label": "user_email = user_data.get(\"email\")\nif not user_email:", "successors": [{"id": 7, "label": "raise HTTPException(status_code=401, detail=\"Email not found in token\")", "successors": []}]}, {"id": 8, "label": "user = await prisma.user.find_unique(where={\"id\": user_id})\nif not user:", "successors": [{"id": 10, "label": "user = await prisma.user.create(\n    data={\n        \"id\": user_id,\n        \"email\": user_email,\n        \"name\": user_data.get(\"user_metadata\", {}).get(\"name\"),\n    }\n)", "successors": []}]}, {"id": 11, "label": "return User.model_validate(user)", "successors": []}]}]}, {"name": "get_user_by_id", "type": "function", "start_line": 37, "end_line": 39, "functions": [], "classes": [], "simplified_code": "async def get_user_by_id(user_id: str) -> Optional[User]:\n    user = await prisma.user.find_unique(where={\"id\": user_id})\n    return User.model_validate(user) if user else None", "blocks": [{"id": 1, "label": "async def get_user_by_id(user_id: str) -> Optional[User]:\nuser = await prisma.user.find_unique(where={\"id\": user_id})", "successors": [{"id": 3, "label": "return User.model_validate(user) if user else None", "successors": []}]}]}, {"name": "create_default_user", "type": "function", "start_line": 42, "end_line": 52, "functions": [], "classes": [], "simplified_code": "async def create_default_user() -> Optional[User]:\n    user = await prisma.user.find_unique(where={\"id\": DEFAULT_USER_ID})\n    if not user:\n        user = await prisma.user.create(\n            data={\n                \"id\": DEFAULT_USER_ID,\n                \"email\": \"default@example.com\",\n                \"name\": \"Default User\",\n            }\n        )\n    return User.model_validate(user)", "blocks": [{"id": 1, "label": "async def create_default_user() -> Optional[User]:\nuser = await prisma.user.find_unique(where={\"id\": DEFAULT_USER_ID})", "successors": [{"id": 3, "label": "if not user:", "successors": [{"id": 4, "label": "user = await prisma.user.create(\n    data={\n        \"id\": DEFAULT_USER_ID,\n        \"email\": \"default@example.com\",\n        \"name\": \"Default User\",\n    }\n)\nreturn User.model_validate(user)", "successors": []}, {"id": 5, "label": "return User.model_validate(user)", "successors": []}]}]}]}, {"name": "get_user_metadata", "type": "function", "start_line": 55, "end_line": 61, "functions": [], "classes": [], "simplified_code": "async def get_user_metadata(user_id: str) -> UserMetadata:\n    user = await User.prisma().find_unique_or_raise(\n        where={\"id\": user_id},\n    )\n\n    metadata = cast(UserMetadataRaw, user.metadata)\n    return UserMetadata.model_validate(metadata)", "blocks": [{"id": 1, "label": "async def get_user_metadata(user_id: str) -> UserMetadata:\n    user = await User.prisma().find_unique_or_raise(\n        where={\"id\": user_id},\n    )", "successors": [{"id": 3, "label": "    metadata = cast(UserMetadataRaw, user.metadata)\n    return UserMetadata.model_validate(metadata)", "successors": []}]}]}, {"name": "update_user_metadata", "type": "function", "start_line": 64, "end_line": 68, "functions": [], "classes": [], "simplified_code": "async def update_user_metadata(user_id: str, metadata: UserMetadata):\n    await User.prisma().update(\n        where={\"id\": user_id},\n        data={\"metadata\": Json(metadata.model_dump())},\n    )", "blocks": [{"id": 1, "label": "async def update_user_metadata(user_id: str, metadata: UserMetadata):\n    await User.prisma().update(\n        where={\"id\": user_id},\n        data={\"metadata\": Json(metadata.model_dump())},\n    )", "successors": []}]}, {"name": "get_user_integrations", "type": "function", "start_line": 71, "end_line": 82, "functions": [], "classes": [], "simplified_code": "async def get_user_integrations(user_id: str) -> UserIntegrations:\n    user = await User.prisma().find_unique_or_raise(\n        where={\"id\": user_id},\n    )\n\n    encrypted_integrations = user.integrations\n    if not encrypted_integrations:\n        return UserIntegrations()\n    else:\n        return UserIntegrations.model_validate(\n            JSONCryptor().decrypt(encrypted_integrations)\n        )", "blocks": [{"id": 1, "label": "async def get_user_integrations(user_id: str) -> UserIntegrations:\n    user = await User.prisma().find_unique_or_raise(\n        where={\"id\": user_id},\n    )\n\n    encrypted_integrations = user.integrations\n    if not encrypted_integrations:", "successors": [{"id": 2, "label": "return UserIntegrations()", "successors": []}, {"id": 3, "label": "return UserIntegrations.model_validate(\n    JSONCryptor().decrypt(encrypted_integrations)\n)", "successors": []}]}]}, {"name": "update_user_integrations", "type": "function", "start_line": 85, "end_line": 90, "functions": [], "classes": [], "simplified_code": "async def update_user_integrations(user_id: str, data: UserIntegrations):\n    encrypted_data = JSONCryptor().encrypt(data.model_dump())\n    await User.prisma().update(\n        where={\"id\": user_id},\n        data={\"integrations\": encrypted_data},\n    )", "blocks": [{"id": 1, "label": "async def update_user_integrations(user_id: str, data: UserIntegrations):\nencrypted_data = JSONCryptor().encrypt(data.model_dump())", "successors": [{"id": 3, "label": "await User.prisma().update(where={\"id\": user_id}, data={\"integrations\": encrypted_data})", "successors": []}]}]}, {"name": "migrate_and_encrypt_user_integrations", "type": "function", "start_line": 93, "end_line": 130, "functions": [], "classes": [], "simplified_code": "async def migrate_and_encrypt_user_integrations():\n    \"\"\"Migrate integration credentials and OAuth states from metadata to integrations column.\"\"\"\n    users = await User.prisma().find_many(\n        where={\n            \"metadata\": {\n                \"path\": [\"integration_credentials\"],\n                \"not\": Json({\"a\": \"yolo\"}),  # bogus value works to check if key exists\n            }  # type: ignore\n        }\n    )\n    logger.info(f\"Migrating integration credentials for {len(users)} users\")\n\n    for user in users:\n        raw_metadata = cast(UserMetadataRaw, user.metadata)\n        metadata = UserMetadata.model_validate(raw_metadata)\n\n        # Get existing integrations data\n        integrations = await get_user_integrations(user_id=user.id)\n\n        # Copy credentials and oauth states from metadata if they exist\n        if metadata.integration_credentials and not integrations.credentials:\n            integrations.credentials = metadata.integration_credentials\n        if metadata.integration_oauth_states:\n            integrations.oauth_states = metadata.integration_oauth_states\n\n        # Save to integrations column\n        await update_user_integrations(user_id=user.id, data=integrations)\n\n        # Remove from metadata\n        raw_metadata = dict(raw_metadata)\n        raw_metadata.pop(\"integration_credentials\", None)\n        raw_metadata.pop(\"integration_oauth_states\", None)\n\n        # Update metadata without integration data\n        await User.prisma().update(\n            where={\"id\": user.id},\n            data={\"metadata\": Json(raw_metadata)},\n        )", "blocks": [{"id": 1, "label": "users = await User.prisma().find_many(...)\nlogger.info(f\"Migrating integration credentials for {len(users)} users\")", "successors": [{"id": 2, "label": "for user in users:", "successors": [{"id": 3, "label": "raw_metadata = cast(UserMetadataRaw, user.metadata)\nmetadata = UserMetadata.model_validate(raw_metadata)\nintegrations = await get_user_integrations(user_id=user.id)\nif metadata.integration_credentials and not integrations.credentials:", "successors": [{"id": 5, "label": "integrations.credentials = metadata.integration_credentials\nawait update_user_integrations(user_id=user.id, data=integrations)\nraw_metadata = dict(raw_metadata)\nraw_metadata.pop(\"integration_credentials\", None)\nraw_metadata.pop(\"integration_oauth_states\", None)\nawait User.prisma().update(where={\"id\": user.id}, data={\"metadata\": Json(raw_metadata)})", "successors": []}, {"id": 6, "label": "if metadata.integration_oauth_states:\nintegrations.oauth_states = metadata.integration_oauth_states", "successors": [{"id": 7, "label": "await update_user_integrations(user_id=user.id, data=integrations)\nraw_metadata = dict(raw_metadata)\nraw_metadata.pop(\"integration_credentials\", None)\nraw_metadata.pop(\"integration_oauth_states\", None)\nawait User.prisma().update(where={\"id\": user.id}, data={\"metadata\": Json(raw_metadata)})", "successors": []}]}]}]}]}]}], "classes": [], "simplified_code": "import logging\nfrom typing import Optional, cast\n\nfrom autogpt_libs.auth.models import DEFAULT_USER_ID\nfrom fastapi import HTTPException\nfrom prisma import Json\nfrom prisma.models import User\n\nfrom backend.data.db import prisma\nfrom backend.data.model import UserIntegrations, UserMetadata, UserMetadataRaw\nfrom backend.util.encryption import JSONCryptor\n\nlogger = logging.getLogger(__name__)\n\n\n    return User.model_validate(user)\n\n\n    return User.model_validate(user) if user else None\n\n\n    return User.model_validate(user)\n\n\n    return UserMetadata.model_validate(metadata)\n\n\n    )\n\n\n        )\n\n\n    )\n\n\n        )", "blocks": [{"id": 1, "label": "import logging\nfrom typing import Optional, cast\n\nfrom autogpt_libs.auth.models import DEFAULT_USER_ID\nfrom fastapi import HTTPException\nfrom prisma import Json\nfrom prisma.models import User\n\nfrom backend.data.db import prisma\nfrom backend.data.model import UserIntegrations, UserMetadata, UserMetadataRaw\nfrom backend.util.encryption import JSONCryptor\n\nlogger = logging.getLogger(__name__)\nreturn User.model_validate(user)", "successors": []}]}
{"file_name": "181.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 195, "functions": [], "classes": [{"name": "BaseWebhooksManager", "type": "class", "start_line": 23, "end_line": 195, "functions": [{"name": "get_suitable_auto_webhook", "type": "function", "start_line": 30, "end_line": 49, "functions": [], "classes": [], "simplified_code": "    async def get_suitable_auto_webhook(\n        self,\n        user_id: str,\n        credentials: Credentials,\n        webhook_type: WT,\n        resource: str,\n        events: list[str],\n    ) -> integrations.Webhook:\n        if not app_config.platform_base_url:\n            raise MissingConfigError(\n                \"PLATFORM_BASE_URL must be set to use Webhook functionality\"\n            )\n\n        if webhook := await integrations.find_webhook_by_credentials_and_props(\n            credentials.id, webhook_type, resource, events\n        ):\n            return webhook\n        return await self._create_webhook(\n            user_id, webhook_type, events, resource, credentials\n        )", "blocks": [{"id": 1, "label": "async def get_suitable_auto_webhook(self, user_id: str, credentials: Credentials, webhook_type: WT, resource: str, events: list[str]) -> integrations.Webhook:", "successors": [{"id": 2, "label": "if not app_config.platform_base_url:\nraise MissingConfigError(\"PLATFORM_BASE_URL must be set to use Webhook functionality\")", "successors": []}, {"id": 4, "label": "if webhook := await integrations.find_webhook_by_credentials_and_props(credentials.id, webhook_type, resource, events):", "successors": [{"id": 5, "label": "return webhook", "successors": []}, {"id": 6, "label": "return await self._create_webhook(user_id, webhook_type, events, resource, credentials)", "successors": []}]}]}]}, {"name": "get_manual_webhook", "type": "function", "start_line": 51, "end_line": 67, "functions": [], "classes": [], "simplified_code": "    async def get_manual_webhook(\n        self,\n        user_id: str,\n        graph_id: str,\n        webhook_type: WT,\n        events: list[str],\n    ):\n        if current_webhook := await integrations.find_webhook_by_graph_and_props(\n            graph_id, self.PROVIDER_NAME, webhook_type, events\n        ):\n            return current_webhook\n        return await self._create_webhook(\n            user_id,\n            webhook_type,\n            events,\n            register=False,\n        )", "blocks": [{"id": 1, "label": "async def get_manual_webhook(\n    self,\n    user_id: str,\n    graph_id: str,\n    webhook_type: WT,\n    events: list[str],\n):\nif current_webhook := await integrations.find_webhook_by_graph_and_props(\n    graph_id, self.PROVIDER_NAME, webhook_type, events\n):", "successors": [{"id": 3, "label": "    return current_webhook", "successors": []}, {"id": 4, "label": "return await self._create_webhook(\n    user_id,\n    webhook_type,\n    events,\n    register=False,\n)", "successors": []}]}]}, {"name": "prune_webhook_if_dangling", "type": "function", "start_line": 69, "end_line": 82, "functions": [], "classes": [], "simplified_code": "    async def prune_webhook_if_dangling(\n        self, webhook_id: str, credentials: Optional[Credentials]\n    ) -> bool:\n        webhook = await integrations.get_webhook(webhook_id)\n        if webhook.attached_nodes is None:\n            raise ValueError(\"Error retrieving webhook including attached nodes\")\n        if webhook.attached_nodes:\n            # Don't prune webhook if in use\n            return False\n\n        if credentials:\n            await self._deregister_webhook(webhook, credentials)\n        await integrations.delete_webhook(webhook.id)\n        return True", "blocks": [{"id": 1, "label": "async def prune_webhook_if_dangling(\n    self, webhook_id: str, credentials: Optional[Credentials]\n) -> bool:\n    webhook = await integrations.get_webhook(webhook_id)", "successors": [{"id": 2, "label": "if webhook.attached_nodes is None:\nraise ValueError(\"Error retrieving webhook including attached nodes\")", "successors": []}, {"id": 4, "label": "if webhook.attached_nodes:\nreturn False", "successors": []}, {"id": 6, "label": "if credentials:\nawait self._deregister_webhook(webhook, credentials)", "successors": []}, {"id": 8, "label": "await integrations.delete_webhook(webhook.id)\nreturn True", "successors": []}]}]}, {"name": "validate_payload", "type": "function", "start_line": 87, "end_line": 100, "functions": [], "classes": [], "simplified_code": "    async def validate_payload(\n        cls, webhook: integrations.Webhook, request: Request\n    ) -> tuple[dict, str]:\n        \"\"\"\n        Validates an incoming webhook request and returns its payload and type.\n\n        Params:\n            webhook: Object representing the configured webhook and its properties in our system.\n            request: Incoming FastAPI `Request`\n\n        Returns:\n            dict: The validated payload\n            str: The event type associated with the payload\n        \"\"\"", "blocks": [{"id": 1, "label": "async def validate_payload( cls, webhook: integrations.Webhook, request: Request ) -> tuple[dict, str]:\n\"\"\"\nValidates an incoming webhook request and returns its payload and type.\n\nParams:\n webhook: Object representing the configured webhook and its properties in our system.\n request: Incoming FastAPI `Request`\n\nReturns:\n dict: The validated payload\n str: The event type associated with the payload\n\"\"\"", "successors": []}]}, {"name": "trigger_ping", "type": "function", "start_line": 105, "end_line": 115, "functions": [], "classes": [], "simplified_code": "    async def trigger_ping(\n        self, webhook: integrations.Webhook, credentials: Credentials | None\n    ) -> None:\n        \"\"\"\n        Triggers a ping to the given webhook.\n\n        Raises:\n            NotImplementedError: if the provider doesn't support pinging\n        \"\"\"\n        # --8<-- [end:BaseWebhooksManager5]\n        raise NotImplementedError(f\"{self.__class__.__name__} doesn't support pinging\")", "blocks": [{"id": 1, "label": "async def trigger_ping(\n        self, webhook: integrations.Webhook, credentials: Credentials | None\n    ) -> None:\n\"\"\"\n        Triggers a ping to the given webhook.\n\n        Raises:\n            NotImplementedError: if the provider doesn't support pinging\n        \"\"\"", "successors": [{"id": 3, "label": "raise NotImplementedError(f\"{self.__class__.__name__} doesn't support pinging\")", "successors": []}]}]}, {"name": "_register_webhook", "type": "function", "start_line": 119, "end_line": 143, "functions": [], "classes": [], "simplified_code": "    async def _register_webhook(\n        self,\n        credentials: Credentials,\n        webhook_type: WT,\n        resource: str,\n        events: list[str],\n        ingress_url: str,\n        secret: str,\n    ) -> tuple[str, dict]:\n        \"\"\"\n        Registers a new webhook with the provider.\n\n        Params:\n            credentials: The credentials with which to create the webhook\n            webhook_type: The provider-specific webhook type to create\n            resource: The resource to receive events for\n            events: The events to subscribe to\n            ingress_url: The ingress URL for webhook payloads\n            secret: Secret used to verify webhook payloads\n\n        Returns:\n            str: Webhook ID assigned by the provider\n            config: Provider-specific configuration for the webhook\n        \"\"\"\n        ...", "blocks": []}, {"name": "_deregister_webhook", "type": "function", "start_line": 149, "end_line": 151, "functions": [], "classes": [], "simplified_code": "    async def _deregister_webhook(\n        self, webhook: integrations.Webhook, credentials: Credentials\n    ) -> None: ...", "blocks": [{"id": 1, "label": "async def _deregister_webhook(self, webhook: integrations.Webhook, credentials: Credentials) -> None: ...", "successors": []}]}, {"name": "_create_webhook", "type": "function", "start_line": 155, "end_line": 195, "functions": [], "classes": [], "simplified_code": "    async def _create_webhook(\n        self,\n        user_id: str,\n        webhook_type: WT,\n        events: list[str],\n        resource: str = \"\",\n        credentials: Optional[Credentials] = None,\n        register: bool = True,\n    ) -> integrations.Webhook:\n        if not app_config.platform_base_url:\n            raise MissingConfigError(\n                \"PLATFORM_BASE_URL must be set to use Webhook functionality\"\n            )\n\n        id = str(uuid4())\n        secret = secrets.token_hex(32)\n        provider_name = self.PROVIDER_NAME\n        ingress_url = webhook_ingress_url(provider_name=provider_name, webhook_id=id)\n        if register:\n            if not credentials:\n                raise TypeError(\"credentials are required if register = True\")\n            provider_webhook_id, config = await self._register_webhook(\n                credentials, webhook_type, resource, events, ingress_url, secret\n            )\n        else:\n            provider_webhook_id, config = \"\", {}\n\n        return await integrations.create_webhook(\n            integrations.Webhook(\n                id=id,\n                user_id=user_id,\n                provider=provider_name,\n                credentials_id=credentials.id if credentials else \"\",\n                webhook_type=webhook_type,\n                resource=resource,\n                events=events,\n                provider_webhook_id=provider_webhook_id,\n                config=config,\n                secret=secret,\n            )\n        )", "blocks": [{"id": 1, "label": "async def _create_webhook(self, user_id: str, webhook_type: WT, events: list[str], resource: str = \"\", credentials: Optional[Credentials] = None, register: bool = True) -> integrations.Webhook:", "successors": [{"id": 2, "label": "if not app_config.platform_base_url:\nraise MissingConfigError(\"PLATFORM_BASE_URL must be set to use Webhook functionality\")", "successors": []}, {"id": 4, "label": "id = str(uuid4())\nsecret = secrets.token_hex(32)\nprovider_name = self.PROVIDER_NAME\ningress_url = webhook_ingress_url(provider_name=provider_name, webhook_id=id)", "successors": [{"id": 5, "label": "if register:", "successors": [{"id": 6, "label": "if not credentials:\nraise TypeError(\"credentials are required if register = True\")", "successors": []}, {"id": 8, "label": "provider_webhook_id, config = await self._register_webhook(credentials, webhook_type, resource, events, ingress_url, secret)\nreturn await integrations.create_webhook(integrations.Webhook(id=id, user_id=user_id, provider=provider_name, credentials_id=credentials.id if credentials else \"\", webhook_type=webhook_type, resource=resource, events=events, provider_webhook_id=provider_webhook_id, config=config, secret=secret))", "successors": []}]}, {"id": 9, "label": "provider_webhook_id, config = \"\", {}\nreturn await integrations.create_webhook(integrations.Webhook(id=id, user_id=user_id, provider=provider_name, credentials_id=credentials.id if credentials else \"\", webhook_type=webhook_type, resource=resource, events=events, provider_webhook_id=provider_webhook_id, config=config, secret=secret))", "successors": []}]}]}]}], "classes": [], "simplified_code": "class BaseWebhooksManager(ABC, Generic[WT]):\n    # --8<-- [start:BaseWebhooksManager1]\n    PROVIDER_NAME: ClassVar[ProviderName]\n    # --8<-- [end:BaseWebhooksManager1]\n\n    WebhookType: WT\n\n        )\n\n        )\n\n        return True\n\n    # --8<-- [start:BaseWebhooksManager3]\n    @classmethod\n    @abstractmethod\n        \"\"\"\n\n    # --8<-- [end:BaseWebhooksManager3]\n\n    # --8<-- [start:BaseWebhooksManager5]\n        raise NotImplementedError(f\"{self.__class__.__name__} doesn't support pinging\")\n\n    # --8<-- [start:BaseWebhooksManager2]\n    @abstractmethod\n        ...\n\n    # --8<-- [end:BaseWebhooksManager2]\n\n    # --8<-- [start:BaseWebhooksManager4]\n    @abstractmethod\n    ) -> None: ...\n\n    # --8<-- [end:BaseWebhooksManager4]\n\n        )", "blocks": [{"id": 1, "label": "class BaseWebhooksManager(ABC, Generic[WT]):\nPROVIDER_NAME: ClassVar[ProviderName]", "successors": [{"id": 3, "label": "WebhookType: WT\nreturn True", "successors": [{"id": 5, "label": "@classmethod\n    @abstractmethod\nraise NotImplementedError(f\"{self.__class__.__name__} doesn't support pinging\")", "successors": [{"id": 7, "label": "@abstractmethod", "successors": []}]}]}]}]}], "simplified_code": "import logging\nimport secrets\nfrom abc import ABC, abstractmethod\nfrom typing import ClassVar, Generic, Optional, TypeVar\nfrom uuid import uuid4\n\nfrom fastapi import Request\nfrom strenum import StrEnum\n\nfrom backend.data import integrations\nfrom backend.data.model import Credentials\nfrom backend.integrations.providers import ProviderName\nfrom backend.integrations.webhooks.utils import webhook_ingress_url\nfrom backend.util.exceptions import MissingConfigError\nfrom backend.util.settings import Config\n\nlogger = logging.getLogger(__name__)\napp_config = Config()\n\nWT = TypeVar(\"WT\", bound=StrEnum)\n\n\n        )", "blocks": [{"id": 1, "label": "import logging\nimport secrets\nfrom abc import ABC, abstractmethod\nfrom typing import ClassVar, Generic, Optional, TypeVar\nfrom uuid import uuid4\n\nfrom fastapi import Request\nfrom strenum import StrEnum\n\nfrom backend.data import integrations\nfrom backend.data.model import Credentials\nfrom backend.integrations.providers import ProviderName\nfrom backend.integrations.webhooks.utils import webhook_ingress_url\nfrom backend.util.exceptions import MissingConfigError\nfrom backend.util.settings import Config\nlogger = logging.getLogger(__name__)\napp_config = Config()", "successors": []}]}
{"file_name": "182.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 50, "functions": [], "classes": [{"name": "DefaultCategories", "type": "class", "start_line": 6, "end_line": 12, "functions": [], "simplified_code": "class DefaultCategories(Enum):\n\n    HOUSING = 0\n    FOOD = 1\n    GAS = 2\n    SHOPPING = 3\n    # ...", "blocks": [{"id": 1, "label": "class DefaultCategories(Enum):\n    HOUSING = 0\n    FOOD = 1\n    GAS = 2\n    SHOPPING = 3", "successors": []}]}, {"name": "Categorizer", "type": "class", "start_line": 20, "end_line": 33, "functions": [{"name": "__init__", "type": "function", "start_line": 22, "end_line": 24, "functions": [], "classes": [], "simplified_code": "    def __init__(self, seller_category_map, seller_category_overrides_map):\n        self.seller_category_map = seller_category_map\n        self.seller_category_overrides_map = seller_category_overrides_map", "blocks": [{"id": 1, "label": "def __init__(self, seller_category_map, seller_category_overrides_map):\nself.seller_category_map = seller_category_map\nself.seller_category_overrides_map = seller_category_overrides_map", "successors": []}]}, {"name": "categorize", "type": "function", "start_line": 26, "end_line": 33, "functions": [], "classes": [], "simplified_code": "    def categorize(self, transaction):\n        if transaction.seller in self.seller_category_map:\n            return self.seller_category_map[transaction.seller]\n        if transaction.seller in self.seller_category_overrides_map:\n            seller_category_map[transaction.seller] = \\\n                self.manual_overrides[transaction.seller].peek_min()\n            return self.seller_category_map[transaction.seller]\n        return None", "blocks": [{"id": 1, "label": "def categorize(self, transaction):\nif transaction.seller in self.seller_category_map:", "successors": [{"id": 3, "label": "return self.seller_category_map[transaction.seller]", "successors": []}, {"id": 4, "label": "if transaction.seller in self.seller_category_overrides_map:", "successors": [{"id": 5, "label": "seller_category_map[transaction.seller] = \\\n    self.manual_overrides[transaction.seller].peek_min()\nreturn self.seller_category_map[transaction.seller]", "successors": []}, {"id": 7, "label": "return None", "successors": []}]}]}]}], "simplified_code": "class Categorizer(object):\n\n        self.seller_category_overrides_map = seller_category_overrides_map\n\n        return None", "blocks": [{"id": 1, "label": "class Categorizer(object):\nself.seller_category_overrides_map = seller_category_overrides_map", "successors": [{"id": 3, "label": "return None", "successors": []}]}]}, {"name": "Transaction", "type": "class", "start_line": 36, "end_line": 41, "functions": [{"name": "__init__", "type": "function", "start_line": 38, "end_line": 41, "functions": [], "classes": [], "simplified_code": "    def __init__(self, timestamp, seller, amount):\n        self.timestamp = timestamp\n        self.seller = seller\n        self.amount = amount", "blocks": [{"id": 1, "label": "def __init__(self, timestamp, seller, amount):\n    self.timestamp = timestamp\n    self.seller = seller\n    self.amount = amount", "successors": []}]}], "simplified_code": "class Transaction(object):\n\n        self.amount = amount", "blocks": [{"id": 1, "label": "class Transaction(object):\nself.amount = amount", "successors": []}]}, {"name": "Budget", "type": "class", "start_line": 44, "end_line": 50, "functions": [{"name": "__init__", "type": "function", "start_line": 46, "end_line": 47, "functions": [], "classes": [], "simplified_code": "    def __init__(self, template_categories_to_budget_map):\n        self.categories_to_budget_map = template_categories_to_budget_map", "blocks": [{"id": 1, "label": "def __init__(self, template_categories_to_budget_map):\n    self.categories_to_budget_map = template_categories_to_budget_map", "successors": []}]}, {"name": "override_category_budget", "type": "function", "start_line": 49, "end_line": 50, "functions": [], "classes": [], "simplified_code": "    def override_category_budget(self, category, amount):\n        self.categories_to_budget_map[category] = amount", "blocks": [{"id": 1, "label": "def override_category_budget(self, category, amount):\n    self.categories_to_budget_map[category] = amount", "successors": []}]}], "simplified_code": "class Budget(object):\n\n        self.categories_to_budget_map = template_categories_to_budget_map\n\n        self.categories_to_budget_map[category] = amount", "blocks": [{"id": 1, "label": "class Budget(object):\nself.categories_to_budget_map = template_categories_to_budget_map", "successors": [{"id": 3, "label": "self.categories_to_budget_map[category] = amount", "successors": []}]}]}], "simplified_code": "# -*- coding: utf-8 -*-\n\nfrom enum import Enum\n\n\n    # ...\n\n\nseller_category_map = {}\nseller_category_map['Exxon'] = DefaultCategories.GAS\nseller_category_map['Target'] = DefaultCategories.SHOPPING\n\n\n        return None\n\n\n        self.amount = amount\n\n\n        self.categories_to_budget_map[category] = amount", "blocks": [{"id": 1, "label": "seller_category_map = {}\nseller_category_map['Exxon'] = DefaultCategories.GAS", "successors": [{"id": 3, "label": "seller_category_map['Target'] = DefaultCategories.SHOPPING\nreturn None", "successors": []}]}]}
{"file_name": "185.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 82, "functions": [{"name": "combination_lists", "type": "function", "start_line": 13, "end_line": 18, "functions": [], "classes": [], "simplified_code": "def combination_lists(n: int, k: int) -> list[list[int]]:\n    \"\"\"\n    >>> combination_lists(n=4, k=2)\n    [[1, 2], [1, 3], [1, 4], [2, 3], [2, 4], [3, 4]]\n    \"\"\"\n    return [list(x) for x in combinations(range(1, n + 1), k)]", "blocks": [{"id": 1, "label": "def combination_lists(n: int, k: int) -> list[list[int]]:\n\"\"\"\n>>> combination_lists(n=4, k=2)\n[[1, 2], [1, 3], [1, 4], [2, 3], [2, 4], [3, 4]]\n\"\"\"", "successors": [{"id": 3, "label": "return [list(x) for x in combinations(range(1, n + 1), k)]", "successors": []}]}]}, {"name": "generate_all_combinations", "type": "function", "start_line": 21, "end_line": 49, "functions": [], "classes": [], "simplified_code": "def generate_all_combinations(n: int, k: int) -> list[list[int]]:\n    \"\"\"\n    >>> generate_all_combinations(n=4, k=2)\n    [[1, 2], [1, 3], [1, 4], [2, 3], [2, 4], [3, 4]]\n    >>> generate_all_combinations(n=0, k=0)\n    [[]]\n    >>> generate_all_combinations(n=10, k=-1)\n    Traceback (most recent call last):\n        ...\n    ValueError: k must not be negative\n    >>> generate_all_combinations(n=-1, k=10)\n    Traceback (most recent call last):\n        ...\n    ValueError: n must not be negative\n    >>> generate_all_combinations(n=5, k=4)\n    [[1, 2, 3, 4], [1, 2, 3, 5], [1, 2, 4, 5], [1, 3, 4, 5], [2, 3, 4, 5]]\n    >>> from itertools import combinations\n    >>> all(generate_all_combinations(n, k) == combination_lists(n, k)\n    ...     for n in range(1, 6) for k in range(1, 6))\n    True\n    \"\"\"\n    if k < 0:\n        raise ValueError(\"k must not be negative\")\n    if n < 0:\n        raise ValueError(\"n must not be negative\")\n\n    result: list[list[int]] = []\n    create_all_state(1, n, k, [], result)\n    return result", "blocks": [{"id": 1, "label": "if k < 0:\n    raise ValueError(\"k must not be negative\")", "successors": []}]}, {"name": "create_all_state", "type": "function", "start_line": 52, "end_line": 66, "functions": [], "classes": [], "simplified_code": "def create_all_state(\n    increment: int,\n    total_number: int,\n    level: int,\n    current_list: list[int],\n    total_list: list[list[int]],\n) -> None:\n    if level == 0:\n        total_list.append(current_list[:])\n        return\n\n    for i in range(increment, total_number - level + 2):\n        current_list.append(i)\n        create_all_state(i + 1, total_number, level - 1, current_list, total_list)\n        current_list.pop()", "blocks": [{"id": 1, "label": "if level == 0:\n    total_list.append(current_list[:])", "successors": [{"id": 3, "label": "return", "successors": []}]}]}], "classes": [], "simplified_code": "\"\"\"\nIn this problem, we want to determine all possible combinations of k\nnumbers out of 1 ... n. We use backtracking to solve this problem.\n\nTime complexity: O(C(n,k)) which is O(n choose k) = O((n!/(k! * (n - k)!))),\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom itertools import combinations\n\n\n    return [list(x) for x in combinations(range(1, n + 1), k)]\n\n\n    return result\n\n\n        current_list.pop()\n\n\nif __name__ == \"__main__\":\n    from doctest import testmod\n\n    testmod()\n    print(generate_all_combinations(n=4, k=2))\n    tests = ((n, k) for n in range(1, 5) for k in range(1, 5))\n    for n, k in tests:\n        print(n, k, generate_all_combinations(n, k) == combination_lists(n, k))\n\n    print(\"Benchmark:\")\n    from timeit import timeit\n\n    for func in (\"combination_lists\", \"generate_all_combinations\"):\n        print(f\"{func:>25}(): {timeit(f'{func}(n=4, k = 2)', globals=globals())}\")", "blocks": [{"id": 1, "label": "if __name__ == \"__main__\":\nfrom doctest import testmod", "successors": [{"id": 3, "label": "testmod()\nprint(generate_all_combinations(n=4, k=2))", "successors": [{"id": 5, "label": "tests = ((n, k) for n in range(1, 5) for k in range(1, 5))", "successors": [{"id": 6, "label": "for n, k in tests:", "successors": [{"id": 7, "label": "print(n, k, generate_all_combinations(n, k) == combination_lists(n, k))\nprint(\"Benchmark:\")", "successors": [{"id": 10, "label": "from timeit import timeit", "successors": [{"id": 11, "label": "for func in (\"combination_lists\", \"generate_all_combinations\"):", "successors": [{"id": 12, "label": "print(f\"{func:>25}(): {timeit(f'{func}(n=4, k = 2)', globals=globals())}\")", "successors": []}]}]}]}]}, {"id": 9, "label": "print(\"Benchmark:\")\nfrom timeit import timeit", "successors": [{"id": 11, "label": "for func in (\"combination_lists\", \"generate_all_combinations\"):", "successors": [{"id": 12, "label": "print(f\"{func:>25}(): {timeit(f'{func}(n=4, k = 2)', globals=globals())}\")", "successors": []}]}]}]}]}]}]}
{"file_name": "186.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 1125, "functions": [{"name": "AICredentialsField", "type": "function", "start_line": 56, "end_line": 63, "functions": [], "classes": [], "simplified_code": "def AICredentialsField() -> AICredentials:\n    return CredentialsField(\n        description=\"API key for the LLM provider.\",\n        discriminator=\"model\",\n        discriminator_mapping={\n            model.value: model.metadata.provider for model in LlmModel\n        },\n    )", "blocks": [{"id": 1, "label": "def AICredentialsField() -> AICredentials:\n    return CredentialsField(\n        description=\"API key for the LLM provider.\",\n        discriminator=\"model\",\n        discriminator_mapping={\n            model.value: model.metadata.provider for model in LlmModel\n        },\n    )", "successors": []}]}], "classes": [{"name": "ModelMetadata", "type": "class", "start_line": 66, "end_line": 68, "functions": [], "classes": [], "simplified_code": "class ModelMetadata(NamedTuple):\n    provider: str\n    context_window: int", "blocks": [{"id": 1, "label": "class ModelMetadata(NamedTuple):", "successors": [{"id": 2, "label": "    provider: str", "successors": []}, {"id": 3, "label": "    context_window: int", "successors": []}]}]}, {"name": "LlmModelMeta", "type": "class", "start_line": 71, "end_line": 87, "functions": [{"name": "__members__", "type": "function", "start_line": 73, "end_line": 87, "functions": [], "classes": [], "simplified_code": "    def __members__(\n        self: type[\"_EnumMemberT\"],\n    ) -> MappingProxyType[str, \"_EnumMemberT\"]:\n        if Settings().config.behave_as == BehaveAs.LOCAL:\n            members = super().__members__\n            return members\n        else:\n            removed_providers = [\"ollama\"]\n            existing_members = super().__members__\n            members = {\n                name: member\n                for name, member in existing_members.items()\n                if LlmModel[name].provider not in removed_providers\n            }\n            return MappingProxyType(members)", "blocks": [{"id": 1, "label": "def __members__(self: type[\"_EnumMemberT\"]) -> MappingProxyType[str, \"_EnumMemberT\"]:\nif Settings().config.behave_as == BehaveAs.LOCAL:", "successors": [{"id": 3, "label": "members = super().__members__\nreturn members", "successors": []}, {"id": 4, "label": "removed_providers = [\"ollama\"]\nexisting_members = super().__members__\nmembers = {\n    name: member\n    for name, member in existing_members.items()\n    if LlmModel[name].provider not in removed_providers\n}\nreturn MappingProxyType(members)", "successors": []}]}]}], "classes": [], "simplified_code": "class LlmModelMeta(EnumMeta):\n    @property\n            return MappingProxyType(members)", "blocks": [{"id": 1, "label": "class LlmModelMeta(EnumMeta):\n@property", "successors": [{"id": 3, "label": "return MappingProxyType(members)", "successors": []}]}]}, {"name": "LlmModel", "type": "class", "start_line": 90, "end_line": 191, "functions": [{"name": "metadata", "type": "function", "start_line": 136, "end_line": 137, "functions": [], "classes": [], "simplified_code": "    def metadata(self) -> ModelMetadata:\n        return MODEL_METADATA[self]", "blocks": [{"id": 1, "label": "def metadata(self) -> ModelMetadata:\n    return MODEL_METADATA[self]", "successors": []}]}, {"name": "provider", "type": "function", "start_line": 140, "end_line": 141, "functions": [], "classes": [], "simplified_code": "    def provider(self) -> str:\n        return self.metadata.provider", "blocks": [{"id": 1, "label": "def provider(self) -> str:\nreturn self.metadata.provider", "successors": []}]}, {"name": "context_window", "type": "function", "start_line": 144, "end_line": 145, "functions": [], "classes": [], "simplified_code": "    def context_window(self) -> int:\n        return self.metadata.context_window", "blocks": [{"id": 1, "label": "def context_window(self) -> int:\nreturn self.metadata.context_window", "successors": []}]}], "classes": [], "simplified_code": "class LlmModel(str, Enum, metaclass=LlmModelMeta):\n    # OpenAI models\n    O1_PREVIEW = \"o1-preview\"\n    O1_MINI = \"o1-mini\"\n    GPT4O_MINI = \"gpt-4o-mini\"\n    GPT4O = \"gpt-4o\"\n    GPT4_TURBO = \"gpt-4-turbo\"\n    GPT3_5_TURBO = \"gpt-3.5-turbo\"\n    # Anthropic models\n    CLAUDE_3_5_SONNET = \"claude-3-5-sonnet-latest\"\n    CLAUDE_3_HAIKU = \"claude-3-haiku-20240307\"\n    # Groq models\n    LLAMA3_8B = \"llama3-8b-8192\"\n    LLAMA3_70B = \"llama3-70b-8192\"\n    MIXTRAL_8X7B = \"mixtral-8x7b-32768\"\n    GEMMA_7B = \"gemma-7b-it\"\n    GEMMA2_9B = \"gemma2-9b-it\"\n    # New Groq models (Preview)\n    LLAMA3_1_405B = \"llama-3.1-405b-reasoning\"\n    LLAMA3_1_70B = \"llama-3.1-70b-versatile\"\n    LLAMA3_1_8B = \"llama-3.1-8b-instant\"\n    # Ollama models\n    OLLAMA_LLAMA3_8B = \"llama3\"\n    OLLAMA_LLAMA3_405B = \"llama3.1:405b\"\n    OLLAMA_DOLPHIN = \"dolphin-mistral:latest\"\n    # OpenRouter models\n    GEMINI_FLASH_1_5_8B = \"google/gemini-flash-1.5\"\n    GROK_BETA = \"x-ai/grok-beta\"\n    MISTRAL_NEMO = \"mistralai/mistral-nemo\"\n    COHERE_COMMAND_R_08_2024 = \"cohere/command-r-08-2024\"\n    COHERE_COMMAND_R_PLUS_08_2024 = \"cohere/command-r-plus-08-2024\"\n    EVA_QWEN_2_5_32B = \"eva-unit-01/eva-qwen-2.5-32b\"\n    DEEPSEEK_CHAT = \"deepseek/deepseek-chat\"\n    PERPLEXITY_LLAMA_3_1_SONAR_LARGE_128K_ONLINE = (\n        \"perplexity/llama-3.1-sonar-large-128k-online\"\n    )\n    QWEN_QWQ_32B_PREVIEW = \"qwen/qwq-32b-preview\"\n    NOUSRESEARCH_HERMES_3_LLAMA_3_1_405B = \"nousresearch/hermes-3-llama-3.1-405b\"\n    NOUSRESEARCH_HERMES_3_LLAMA_3_1_70B = \"nousresearch/hermes-3-llama-3.1-70b\"\n    AMAZON_NOVA_LITE_V1 = \"amazon/nova-lite-v1\"\n    AMAZON_NOVA_MICRO_V1 = \"amazon/nova-micro-v1\"\n    AMAZON_NOVA_PRO_V1 = \"amazon/nova-pro-v1\"\n    MICROSOFT_WIZARDLM_2_8X22B = \"microsoft/wizardlm-2-8x22b\"\n    GRYPHE_MYTHOMAX_L2_13B = \"gryphe/mythomax-l2-13b\"\n\n    @property\n        return MODEL_METADATA[self]\n\n    @property\n        return self.metadata.provider\n\n    @property\n        return self.metadata.context_window\n\n\nMODEL_METADATA = {\n    LlmModel.O1_PREVIEW: ModelMetadata(\"openai\", 32000),\n    LlmModel.O1_MINI: ModelMetadata(\"openai\", 62000),\n    LlmModel.GPT4O_MINI: ModelMetadata(\"openai\", 128000),\n    LlmModel.GPT4O: ModelMetadata(\"openai\", 128000),\n    LlmModel.GPT4_TURBO: ModelMetadata(\"openai\", 128000),\n    LlmModel.GPT3_5_TURBO: ModelMetadata(\"openai\", 16385),\n    LlmModel.CLAUDE_3_5_SONNET: ModelMetadata(\"anthropic\", 200000),\n    LlmModel.CLAUDE_3_HAIKU: ModelMetadata(\"anthropic\", 200000),\n    LlmModel.LLAMA3_8B: ModelMetadata(\"groq\", 8192),\n    LlmModel.LLAMA3_70B: ModelMetadata(\"groq\", 8192),\n    LlmModel.MIXTRAL_8X7B: ModelMetadata(\"groq\", 32768),\n    LlmModel.GEMMA_7B: ModelMetadata(\"groq\", 8192),\n    LlmModel.GEMMA2_9B: ModelMetadata(\"groq\", 8192),\n    LlmModel.LLAMA3_1_405B: ModelMetadata(\"groq\", 8192),\n    # Limited to 16k during preview\n    LlmModel.LLAMA3_1_70B: ModelMetadata(\"groq\", 131072),\n    LlmModel.LLAMA3_1_8B: ModelMetadata(\"groq\", 131072),\n    LlmModel.OLLAMA_LLAMA3_8B: ModelMetadata(\"ollama\", 8192),\n    LlmModel.OLLAMA_LLAMA3_405B: ModelMetadata(\"ollama\", 8192),\n    LlmModel.OLLAMA_DOLPHIN: ModelMetadata(\"ollama\", 32768),\n    LlmModel.GEMINI_FLASH_1_5_8B: ModelMetadata(\"open_router\", 8192),\n    LlmModel.GROK_BETA: ModelMetadata(\"open_router\", 8192),\n    LlmModel.MISTRAL_NEMO: ModelMetadata(\"open_router\", 4000),\n    LlmModel.COHERE_COMMAND_R_08_2024: ModelMetadata(\"open_router\", 4000),\n    LlmModel.COHERE_COMMAND_R_PLUS_08_2024: ModelMetadata(\"open_router\", 4000),\n    LlmModel.EVA_QWEN_2_5_32B: ModelMetadata(\"open_router\", 4000),\n    LlmModel.DEEPSEEK_CHAT: ModelMetadata(\"open_router\", 8192),\n    LlmModel.PERPLEXITY_LLAMA_3_1_SONAR_LARGE_128K_ONLINE: ModelMetadata(\n        \"open_router\", 8192\n    ),\n    LlmModel.QWEN_QWQ_32B_PREVIEW: ModelMetadata(\"open_router\", 4000),\n    LlmModel.NOUSRESEARCH_HERMES_3_LLAMA_3_1_405B: ModelMetadata(\"open_router\", 4000),\n    LlmModel.NOUSRESEARCH_HERMES_3_LLAMA_3_1_70B: ModelMetadata(\"open_router\", 4000),\n    LlmModel.AMAZON_NOVA_LITE_V1: ModelMetadata(\"open_router\", 4000),\n    LlmModel.AMAZON_NOVA_MICRO_V1: ModelMetadata(\"open_router\", 4000),\n    LlmModel.AMAZON_NOVA_PRO_V1: ModelMetadata(\"open_router\", 4000),\n    LlmModel.MICROSOFT_WIZARDLM_2_8X22B: ModelMetadata(\"open_router\", 4000),\n    LlmModel.GRYPHE_MYTHOMAX_L2_13B: ModelMetadata(\"open_router\", 4000),\n}\n\nfor model in LlmModel:\n    if model not in MODEL_METADATA:\n        raise ValueError(f\"Missing MODEL_METADATA metadata for model: {model}\")", "blocks": [{"id": 1, "label": "class LlmModel(str, Enum, metaclass=LlmModelMeta):\n    # OpenAI models\n    O1_PREVIEW = \"o1-preview\"\n    O1_MINI = \"o1-mini\"\n    GPT4O_MINI = \"gpt-4o-mini\"\n    GPT4O = \"gpt-4o\"\n    GPT4_TURBO = \"gpt-4-turbo\"\n    GPT3_5_TURBO = \"gpt-3.5-turbo\"\n    # Anthropic models\n    CLAUDE_3_5_SONNET = \"claude-3-5-sonnet-latest\"\n    CLAUDE_3_HAIKU = \"claude-3-haiku-20240307\"\n    # Groq models\n    LLAMA3_8B = \"llama3-8b-8192\"\n    LLAMA3_70B = \"llama3-70b-8192\"\n    MIXTRAL_8X7B = \"mixtral-8x7b-32768\"\n    GEMMA_7B = \"gemma-7b-it\"\n    GEMMA2_9B = \"gemma2-9b-it\"\n    # New Groq models (Preview)\n    LLAMA3_1_405B = \"llama-3.1-405b-reasoning\"\n    LLAMA3_1_70B = \"llama-3.1-70b-versatile\"\n    LLAMA3_1_8B = \"llama-3.1-8b-instant\"\n    # Ollama models\n    OLLAMA_LLAMA3_8B = \"llama3\"\n    OLLAMA_LLAMA3_405B = \"llama3.1:405b\"\n    OLLAMA_DOLPHIN = \"dolphin-mistral:latest\"\n    # OpenRouter models\n    GEMINI_FLASH_1_5_8B = \"google/gemini-flash-1.5\"\n    GROK_BETA = \"x-ai/grok-beta\"\n    MISTRAL_NEMO = \"mistralai/mistral-nemo\"\n    COHERE_COMMAND_R_08_2024 = \"cohere/command-r-08-2024\"\n    COHERE_COMMAND_R_PLUS_08_2024 = \"cohere/command-r-plus-08-2024\"\n    EVA_QWEN_2_5_32B = \"eva-unit-01/eva-qwen-2.5-32b\"\n    DEEPSEEK_CHAT = \"deepseek/deepseek-chat\"\n    PERPLEXITY_LLAMA_3_1_SONAR_LARGE_128K_ONLINE = (\n        \"perplexity/llama-3.1-sonar-large-128k-online\"\n    )\n    QWEN_QWQ_32B_PREVIEW = \"qwen/qwq-32b-preview\"\n    NOUSRESEARCH_HERMES_3_LLAMA_3_1_405B = \"nousresearch/hermes-3-llama-3.1-405b\"\n    NOUSRESEARCH_HERMES_3_LLAMA_3_1_70B = \"nousresearch/hermes-3-llama-3.1-70b\"\n    AMAZON_NOVA_LITE_V1 = \"amazon/nova-lite-v1\"\n    AMAZON_NOVA_MICRO_V1 = \"amazon/nova-micro-v1\"\n    AMAZON_NOVA_PRO_V1 = \"amazon/nova-pro-v1\"\n    MICROSOFT_WIZARDLM_2_8X22B = \"microsoft/wizardlm-2-8x22b\"\n    GRYPHE_MYTHOMAX_L2_13B = \"gryphe/mythomax-l2-13b\"\n\n    @property\n    def metadata(self):\n        return MODEL_METADATA[self]\n\n    @property\n    def provider(self):\n        return self.metadata.provider\n\n    @property\n    def context_window(self):\n        return self.metadata.context_window\n\n", "successors": []}]}, {"name": "MessageRole", "type": "class", "start_line": 194, "end_line": 197, "functions": [], "classes": [], "simplified_code": "class MessageRole(str, Enum):\n    SYSTEM = \"system\"\n    USER = \"user\"\n    ASSISTANT = \"assistant\"", "blocks": [{"id": 1, "label": "class MessageRole(str, Enum):", "successors": [{"id": 2, "label": "    SYSTEM = \"system\"", "successors": []}, {"id": 3, "label": "    USER = \"user\"", "successors": []}, {"id": 4, "label": "    ASSISTANT = \"assistant\"", "successors": []}]}]}, {"name": "Message", "type": "class", "start_line": 200, "end_line": 202, "functions": [], "classes": [], "simplified_code": "class Message(BlockSchema):\n    role: MessageRole\n    content: str", "blocks": [{"id": 1, "label": "class Message(BlockSchema):\n    role: MessageRole", "successors": [{"id": 3, "label": "    content: str", "successors": []}]}]}, {"name": "AIStructuredResponseGeneratorBlock", "type": "class", "start_line": 205, "end_line": 552, "functions": [{"name": "__init__", "type": "function", "start_line": 257, "end_line": 287, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"ed55ac19-356e-4243-a6cb-bc599e9b716f\",\n            description=\"Call a Large Language Model (LLM) to generate formatted object based on the given prompt.\",\n            categories={BlockCategory.AI},\n            input_schema=AIStructuredResponseGeneratorBlock.Input,\n            output_schema=AIStructuredResponseGeneratorBlock.Output,\n            test_input={\n                \"model\": LlmModel.GPT4_TURBO,\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n                \"expected_format\": {\n                    \"key1\": \"value1\",\n                    \"key2\": \"value2\",\n                },\n                \"prompt\": \"User prompt\",\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=(\"response\", {\"key1\": \"key1Value\", \"key2\": \"key2Value\"}),\n            test_mock={\n                \"llm_call\": lambda *args, **kwargs: (\n                    json.dumps(\n                        {\n                            \"key1\": \"key1Value\",\n                            \"key2\": \"key2Value\",\n                        }\n                    ),\n                    0,\n                    0,\n                )\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\n    super().__init__(\n        id=\"ed55ac19-356e-4243-a6cb-bc599e9b716f\",\n        description=\"Call a Large Language Model (LLM) to generate formatted object based on the given prompt.\",\n        categories={BlockCategory.AI},\n        input_schema=AIStructuredResponseGeneratorBlock.Input,\n        output_schema=AIStructuredResponseGeneratorBlock.Output,\n        test_input={\n            \"model\": LlmModel.GPT4_TURBO,\n            \"credentials\": TEST_CREDENTIALS_INPUT,\n            \"expected_format\": {\n                \"key1\": \"value1\",\n                \"key2\": \"value2\",\n            },\n            \"prompt\": \"User prompt\",\n        },\n        test_credentials=TEST_CREDENTIALS,\n        test_output=(\"response\", {\"key1\": \"key1Value\", \"key2\": \"key2Value\"}),\n        test_mock={\n            \"llm_call\": lambda *args, **kwargs: (\n                json.dumps(\n                    {\n                        \"key1\": \"key1Value\",\n                        \"key2\": \"key2Value\",\n                    }\n                ),\n                0,\n                0,\n            )\n        },\n    )\n", "successors": []}]}, {"name": "llm_call", "type": "function", "start_line": 290, "end_line": 437, "functions": [], "classes": [], "simplified_code": "    def llm_call(\n        credentials: APIKeyCredentials,\n        llm_model: LlmModel,\n        prompt: list[dict],\n        json_format: bool,\n        max_tokens: int | None = None,\n        ollama_host: str = \"localhost:11434\",\n    ) -> tuple[str, int, int]:\n        \"\"\"\n        Args:\n            api_key: API key for the LLM provider.\n            llm_model: The LLM model to use.\n            prompt: The prompt to send to the LLM.\n            json_format: Whether the response should be in JSON format.\n            max_tokens: The maximum number of tokens to generate in the chat completion.\n            ollama_host: The host for ollama to use\n\n        Returns:\n            The response from the LLM.\n            The number of tokens used in the prompt.\n            The number of tokens used in the completion.\n        \"\"\"\n        provider = llm_model.metadata.provider\n\n        if provider == \"openai\":\n            oai_client = openai.OpenAI(api_key=credentials.api_key.get_secret_value())\n            response_format = None\n\n            if llm_model in [LlmModel.O1_MINI, LlmModel.O1_PREVIEW]:\n                sys_messages = [p[\"content\"] for p in prompt if p[\"role\"] == \"system\"]\n                usr_messages = [p[\"content\"] for p in prompt if p[\"role\"] != \"system\"]\n                prompt = [\n                    {\"role\": \"user\", \"content\": \"\\n\".join(sys_messages)},\n                    {\"role\": \"user\", \"content\": \"\\n\".join(usr_messages)},\n                ]\n            elif json_format:\n                response_format = {\"type\": \"json_object\"}\n\n            response = oai_client.chat.completions.create(\n                model=llm_model.value,\n                messages=prompt,  # type: ignore\n                response_format=response_format,  # type: ignore\n                max_completion_tokens=max_tokens,\n            )\n\n            return (\n                response.choices[0].message.content or \"\",\n                response.usage.prompt_tokens if response.usage else 0,\n                response.usage.completion_tokens if response.usage else 0,\n            )\n        elif provider == \"anthropic\":\n            system_messages = [p[\"content\"] for p in prompt if p[\"role\"] == \"system\"]\n            sysprompt = \" \".join(system_messages)\n\n            messages = []\n            last_role = None\n            for p in prompt:\n                if p[\"role\"] in [\"user\", \"assistant\"]:\n                    if p[\"role\"] != last_role:\n                        messages.append({\"role\": p[\"role\"], \"content\": p[\"content\"]})\n                        last_role = p[\"role\"]\n                    else:\n                        # If the role is the same as the last one, combine the content\n                        messages[-1][\"content\"] += \"\\n\" + p[\"content\"]\n\n            client = anthropic.Anthropic(api_key=credentials.api_key.get_secret_value())\n            try:\n                resp = client.messages.create(\n                    model=llm_model.value,\n                    system=sysprompt,\n                    messages=messages,\n                    max_tokens=max_tokens or 8192,\n                )\n\n                if not resp.content:\n                    raise ValueError(\"No content returned from Anthropic.\")\n\n                return (\n                    (\n                        resp.content[0].name\n                        if isinstance(resp.content[0], anthropic.types.ToolUseBlock)\n                        else resp.content[0].text\n                    ),\n                    resp.usage.input_tokens,\n                    resp.usage.output_tokens,\n                )\n            except anthropic.APIError as e:\n                error_message = f\"Anthropic API error: {str(e)}\"\n                logger.error(error_message)\n                raise ValueError(error_message)\n        elif provider == \"groq\":\n            client = Groq(api_key=credentials.api_key.get_secret_value())\n            response_format = {\"type\": \"json_object\"} if json_format else None\n            response = client.chat.completions.create(\n                model=llm_model.value,\n                messages=prompt,  # type: ignore\n                response_format=response_format,  # type: ignore\n                max_tokens=max_tokens,\n            )\n            return (\n                response.choices[0].message.content or \"\",\n                response.usage.prompt_tokens if response.usage else 0,\n                response.usage.completion_tokens if response.usage else 0,\n            )\n        elif provider == \"ollama\":\n            client = ollama.Client(host=ollama_host)\n            sys_messages = [p[\"content\"] for p in prompt if p[\"role\"] == \"system\"]\n            usr_messages = [p[\"content\"] for p in prompt if p[\"role\"] != \"system\"]\n            response = client.generate(\n                model=llm_model.value,\n                prompt=f\"{sys_messages}\\n\\n{usr_messages}\",\n                stream=False,\n            )\n            return (\n                response.get(\"response\") or \"\",\n                response.get(\"prompt_eval_count\") or 0,\n                response.get(\"eval_count\") or 0,\n            )\n        elif provider == \"open_router\":\n            client = openai.OpenAI(\n                base_url=\"https://openrouter.ai/api/v1\",\n                api_key=credentials.api_key.get_secret_value(),\n            )\n\n            response = client.chat.completions.create(\n                extra_headers={\n                    \"HTTP-Referer\": \"https://agpt.co\",\n                    \"X-Title\": \"AutoGPT\",\n                },\n                model=llm_model.value,\n                messages=prompt,  # type: ignore\n                max_tokens=max_tokens,\n            )\n\n            # If there's no response, raise an error\n            if not response.choices:\n                if response:\n                    raise ValueError(f\"OpenRouter error: {response}\")\n                else:\n                    raise ValueError(\"No response from OpenRouter.\")\n\n            return (\n                response.choices[0].message.content or \"\",\n                response.usage.prompt_tokens if response.usage else 0,\n                response.usage.completion_tokens if response.usage else 0,\n            )\n        else:\n            raise ValueError(f\"Unsupported LLM provider: {provider}\")", "blocks": [{"id": 1, "label": "def llm_call( credentials: APIKeyCredentials, llm_model: LlmModel, prompt: list[dict], json_format: bool, max_tokens: int | None = None, ollama_host: str = \"localhost:11434\") -> tuple[str, int, int]:", "successors": [{"id": 2, "label": "provider = llm_model.metadata.provider", "successors": [{"id": 3, "label": "if provider == \"openai\":\noai_client = openai.OpenAI(api_key=credentials.api_key.get_secret_value())\nresponse_format = None", "successors": [{"id": 5, "label": "if llm_model in [LlmModel.O1_MINI, LlmModel.O1_PREVIEW]:\nsys_messages = [p[\"content\"] for p in prompt if p[\"role\"] == \"system\"]\nusr_messages = [p[\"content\"] for p in prompt if p[\"role\"] != \"system\"]\nprompt = [ {\"role\": \"user\", \"content\": \"\\n\".join(sys_messages)}, {\"role\": \"user\", \"content\": \"\\n\".join(usr_messages)}, ]", "successors": [{"id": 9, "label": "response = oai_client.chat.completions.create( model=llm_model.value, messages=prompt,  # type: ignore response_format=response_format,  # type: ignore max_completion_tokens=max_tokens, )\nreturn ( response.choices[0].message.content or \"\", response.usage.prompt_tokens if response.usage else 0, response.usage.completion_tokens if response.usage else 0, )", "successors": []}]}, {"id": 7, "label": "elif json_format:\nresponse_format = {\"type\": \"json_object\"}", "successors": [{"id": 9, "label": "response = oai_client.chat.completions.create( model=llm_model.value, messages=prompt,  # type: ignore response_format=response_format,  # type: ignore max_completion_tokens=max_tokens, )\nreturn ( response.choices[0].message.content or \"\", response.usage.prompt_tokens if response.usage else 0, response.usage.completion_tokens if response.usage else 0, )", "successors": []}]}]}, {"id": 11, "label": "elif provider == \"anthropic\":\nsystem_messages = [p[\"content\"] for p in prompt if p[\"role\"] == \"system\"]\nsysprompt = \" \".join(system_messages)\n\nmessages = []\nlast_role = None\nfor p in prompt:\n    if p[\"role\"] in [\"user\", \"assistant\"]:\n        if p[\"role\"] != last_role:\n            messages.append({\"role\": p[\"role\"], \"content\": p[\"content\"]})\n            last_role = p[\"role\"]\n        else:\n            messages[-1][\"content\"] += \"\\n\" + p[\"content\"]", "successors": [{"id": 13, "label": "client = anthropic.Anthropic(api_key=credentials.api_key.get_secret_value())", "successors": [{"id": 14, "label": "try:\nresp = client.messages.create( model=llm_model.value, system=sysprompt, messages=messages, max_tokens=max_tokens or 8192, )", "successors": [{"id": 16, "label": "if not resp.content:\nraise ValueError(\"No content returned from Anthropic.\")", "successors": [{"id": 18, "label": "return ( ( resp.content[0].name if isinstance(resp.content[0], anthropic.types.ToolUseBlock) else resp.content[0].text ), resp.usage.input_tokens, resp.usage.output_tokens, )", "successors": []}]}]}, {"id": 19, "label": "except anthropic.APIError as e:\nerror_message = f\"Anthropic API error: {str(e)}\"\nlogger.error(error_message)\nraise ValueError(error_message)", "successors": []}]}]}, {"id": 21, "label": "elif provider == \"groq\":\nclient = Groq(api_key=credentials.api_key.get_secret_value())\nresponse_format = {\"type\": \"json_object\"} if json_format else None\nresponse = client.chat.completions.create( model=llm_model.value, messages=prompt,  # type: ignore response_format=response_format,  # type: ignore max_tokens=max_tokens, )", "successors": [{"id": 23, "label": "return ( response.choices[0].message.content or \"\", response.usage.prompt_tokens if response.usage else 0, response.usage.completion_tokens if response.usage else 0, )", "successors": []}]}, {"id": 24, "label": "elif provider == \"ollama\":\nclient = ollama.Client(host=ollama_host)\nsys_messages = [p[\"content\"] for p in prompt if p[\"role\"] == \"system\"]\nusr_messages = [p[\"content\"] for p in prompt if p[\"role\"] != \"system\"]\nresponse = client.generate( model=llm_model.value, prompt=f\"{sys_messages}\\n\\n{usr_messages}\", stream=False, )", "successors": [{"id": 26, "label": "return ( response.get(\"response\") or \"\", response.get(\"prompt_eval_count\") or 0, response.get(\"eval_count\") or 0, )", "successors": []}]}, {"id": 27, "label": "elif provider == \"open_router\":", "successors": [{"id": 28, "label": "client = openai.OpenAI( base_url=\"https://openrouter.ai/api/v1\", api_key=credentials.api_key.get_secret_value(), )\n\nresponse = client.chat.completions.create( extra_headers={ \"HTTP-Referer\": \"https://agpt.co\", \"X-Title\": \"AutoGPT\", }, model=llm_model.value, messages=prompt,  # type: ignore max_tokens=max_tokens, )", "successors": [{"id": 29, "label": "if not response.choices:\nif response:", "successors": [{"id": 31, "label": "raise ValueError(f\"OpenRouter error: {response}\")", "successors": []}]}, {"id": 32, "label": "else:\nraise ValueError(\"No response from OpenRouter.\")", "successors": []}]}, {"id": 34, "label": "return ( response.choices[0].message.content or \"\", response.usage.prompt_tokens if response.usage else 0, response.usage.completion_tokens if response.usage else 0, )", "successors": []}]}]}, {"id": 35, "label": "else:\nraise ValueError(f\"Unsupported LLM provider: {provider}\")", "successors": []}]}]}, {"name": "run", "type": "function", "start_line": 439, "end_line": 552, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        logger.debug(f\"Calling LLM with input data: {input_data}\")\n        prompt = [p.model_dump() for p in input_data.conversation_history]\n\n        def trim_prompt(s: str) -> str:\n            lines = s.strip().split(\"\\n\")\n            return \"\\n\".join([line.strip().lstrip(\"|\") for line in lines])\n\n        values = input_data.prompt_values\n        if values:\n            input_data.prompt = input_data.prompt.format(**values)\n            input_data.sys_prompt = input_data.sys_prompt.format(**values)\n\n        if input_data.sys_prompt:\n            prompt.append({\"role\": \"system\", \"content\": input_data.sys_prompt})\n\n        if input_data.expected_format:\n            expected_format = [\n                f'\"{k}\": \"{v}\"' for k, v in input_data.expected_format.items()\n            ]\n            format_prompt = \",\\n  \".join(expected_format)\n            sys_prompt = trim_prompt(\n                f\"\"\"\n                  |Reply strictly only in the following JSON format:\n                  |{{\n                  |  {format_prompt}\n                  |}}\n                \"\"\"\n            )\n            prompt.append({\"role\": \"system\", \"content\": sys_prompt})\n\n        if input_data.prompt:\n            prompt.append({\"role\": \"user\", \"content\": input_data.prompt})\n\n        def parse_response(resp: str) -> tuple[dict[str, Any], str | None]:\n            try:\n                parsed = json.loads(resp)\n                if not isinstance(parsed, dict):\n                    return {}, f\"Expected a dictionary, but got {type(parsed)}\"\n                miss_keys = set(input_data.expected_format.keys()) - set(parsed.keys())\n                if miss_keys:\n                    return parsed, f\"Missing keys: {miss_keys}\"\n                return parsed, None\n            except JSONDecodeError as e:\n                return {}, f\"JSON decode error: {e}\"\n\n        logger.info(f\"LLM request: {prompt}\")\n        retry_prompt = \"\"\n        llm_model = input_data.model\n\n        for retry_count in range(input_data.retry):\n            try:\n                response_text, input_token, output_token = self.llm_call(\n                    credentials=credentials,\n                    llm_model=llm_model,\n                    prompt=prompt,\n                    json_format=bool(input_data.expected_format),\n                    ollama_host=input_data.ollama_host,\n                    max_tokens=input_data.max_tokens,\n                )\n                self.merge_stats(\n                    {\n                        \"input_token_count\": input_token,\n                        \"output_token_count\": output_token,\n                    }\n                )\n                logger.info(f\"LLM attempt-{retry_count} response: {response_text}\")\n\n                if input_data.expected_format:\n                    parsed_dict, parsed_error = parse_response(response_text)\n                    if not parsed_error:\n                        yield \"response\", {\n                            k: (\n                                json.loads(v)\n                                if isinstance(v, str)\n                                and v.startswith(\"[\")\n                                and v.endswith(\"]\")\n                                else (\", \".join(v) if isinstance(v, list) else v)\n                            )\n                            for k, v in parsed_dict.items()\n                        }\n                        return\n                else:\n                    yield \"response\", {\"response\": response_text}\n                    return\n\n                retry_prompt = trim_prompt(\n                    f\"\"\"\n                  |This is your previous error response:\n                  |--\n                  |{response_text}\n                  |--\n                  |\n                  |And this is the error:\n                  |--\n                  |{parsed_error}\n                  |--\n                \"\"\"\n                )\n                prompt.append({\"role\": \"user\", \"content\": retry_prompt})\n            except Exception as e:\n                logger.exception(f\"Error calling LLM: {e}\")\n                retry_prompt = f\"Error calling LLM: {e}\"\n            finally:\n                self.merge_stats(\n                    {\n                        \"llm_call_count\": retry_count + 1,\n                        \"llm_retry_count\": retry_count,\n                    }\n                )\n\n        raise RuntimeError(retry_prompt)", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs) -> BlockOutput:\n    logger.debug(f\"Calling LLM with input data: {input_data}\")\n    prompt = [p.model_dump() for p in input_data.conversation_history]\n\ndef trim_prompt(s: str) -> str:\n    lines = s.strip().split(\"\\n\")\n    return \"\\n\".join([line.strip().lstrip(\"|\") for line in lines])\n\nvalues = input_data.prompt_values\nif values:\n    input_data.prompt = input_data.prompt.format(**values)\n    input_data.sys_prompt = input_data.sys_prompt.format(**values)", "successors": [{"id": 3, "label": "if input_data.sys_prompt:\n    prompt.append({\"role\": \"system\", \"content\": input_data.sys_prompt})\nif input_data.expected_format:\n    expected_format = [\n        f'\"{k}\": \"{v}\"' for k, v in input_data.expected_format.items()\n    ]\n    format_prompt = \",\\n  \".join(expected_format)\n    sys_prompt = trim_prompt(\n        f\"\"\"\n          |Reply strictly only in the following JSON format:\n          |{{\n          |  {format_prompt}\n          |}}\n        \"\"\"\n    )\n    prompt.append({\"role\": \"system\", \"content\": sys_prompt})", "successors": [{"id": 5, "label": "if input_data.prompt:\n    prompt.append({\"role\": \"user\", \"content\": input_data.prompt})\ndef parse_response(resp: str) -> tuple[dict[str, Any], str | None]:\n    try:\n        parsed = json.loads(resp)\n        if not isinstance(parsed, dict):\n            return {}, f\"Expected a dictionary, but got {type(parsed)}\"\n        miss_keys = set(input_data.expected_format.keys()) - set(parsed.keys())\n        if miss_keys:\n            return parsed, f\"Missing keys: {miss_keys}\"\n        return parsed, None\n    except JSONDecodeError as e:\n        return {}, f\"JSON decode error: {e}\"", "successors": [{"id": 7, "label": "logger.info(f\"LLM request: {prompt}\")\nretry_prompt = \"\"\nllm_model = input_data.model\n\nfor retry_count in range(input_data.retry):", "successors": [{"id": 8, "label": "try:\n    response_text, input_token, output_token = self.llm_call(\n        credentials=credentials,\n        llm_model=llm_model,\n        prompt=prompt,\n        json_format=bool(input_data.expected_format),\n        ollama_host=input_data.ollama_host,\n        max_tokens=input_data.max_tokens,\n    )\n    self.merge_stats(\n        {\n            \"input_token_count\": input_token,\n            \"output_token_count\": output_token,\n        }\n    )\n    logger.info(f\"LLM attempt-{retry_count} response: {response_text}\")", "successors": [{"id": 9, "label": "if input_data.expected_format:\n    parsed_dict, parsed_error = parse_response(response_text)\n    if not parsed_error:\n        yield \"response\", {\n            k: (\n                json.loads(v)\n                if isinstance(v, str)\n                and v.startswith(\"[\")\n                and v.endswith(\"]\")\n                else (\", \".join(v) if isinstance(v, list) else v)\n            )\n            for k, v in parsed_dict.items()\n        }\n        return", "successors": []}, {"id": 10, "label": "else:\n    yield \"response\", {\"response\": response_text}\n    return", "successors": []}]}, {"id": 11, "label": "retry_prompt = trim_prompt(\n    f\"\"\"\n  |This is your previous error response:\n  |--\n  |{response_text}\n  |--\n  |\n  |And this is the error:\n  |--\n  |{parsed_error}\n  |--\n\"\"\"\n)\nprompt.append({\"role\": \"user\", \"content\": retry_prompt})", "successors": []}, {"id": 12, "label": "except Exception as e:\n    logger.exception(f\"Error calling LLM: {e}\")\n    retry_prompt = f\"Error calling LLM: {e}\"", "successors": []}, {"id": 13, "label": "finally:\n    self.merge_stats(\n        {\n            \"llm_call_count\": retry_count + 1,\n            \"llm_retry_count\": retry_count,\n        }\n    )", "successors": []}]}, {"id": 14, "label": "raise RuntimeError(retry_prompt)", "successors": []}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 206, "end_line": 250, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        prompt: str = SchemaField(\n            description=\"The prompt to send to the language model.\",\n            placeholder=\"Enter your prompt here...\",\n        )\n        expected_format: dict[str, str] = SchemaField(\n            description=\"Expected format of the response. If provided, the response will be validated against this format. \"\n            \"The keys should be the expected fields in the response, and the values should be the description of the field.\",\n        )\n        model: LlmModel = SchemaField(\n            title=\"LLM Model\",\n            default=LlmModel.GPT4_TURBO,\n            description=\"The language model to use for answering the prompt.\",\n            advanced=False,\n        )\n        credentials: AICredentials = AICredentialsField()\n        sys_prompt: str = SchemaField(\n            title=\"System Prompt\",\n            default=\"\",\n            description=\"The system prompt to provide additional context to the model.\",\n        )\n        conversation_history: list[Message] = SchemaField(\n            default=[],\n            description=\"The conversation history to provide context for the prompt.\",\n        )\n        retry: int = SchemaField(\n            title=\"Retry Count\",\n            default=3,\n            description=\"Number of times to retry the LLM call if the response does not match the expected format.\",\n        )\n        prompt_values: dict[str, str] = SchemaField(\n            advanced=False, default={}, description=\"Values used to fill in the prompt.\"\n        )\n        max_tokens: int | None = SchemaField(\n            advanced=True,\n            default=None,\n            description=\"The maximum number of tokens to generate in the chat completion.\",\n        )\n\n        ollama_host: str = SchemaField(\n            advanced=True,\n            default=\"localhost:11434\",\n            description=\"Ollama host for local  models\",\n        )\n", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\nprompt: str = SchemaField(description=\"The prompt to send to the language model.\", placeholder=\"Enter your prompt here...\")", "successors": [{"id": 3, "label": "expected_format: dict[str, str] = SchemaField(description=\"Expected format of the response. If provided, the response will be validated against this format. The keys should be the expected fields in the response, and the values should be the description of the field.\")\nmodel: LlmModel = SchemaField(title=\"LLM Model\", default=LlmModel.GPT4_TURBO, description=\"The language model to use for answering the prompt.\", advanced=False)", "successors": [{"id": 5, "label": "credentials: AICredentials = AICredentialsField()\nsys_prompt: str = SchemaField(title=\"System Prompt\", default=\"\", description=\"The system prompt to provide additional context to the model.\")", "successors": [{"id": 7, "label": "conversation_history: list[Message] = SchemaField(default=[], description=\"The conversation history to provide context for the prompt.\")\nretry: int = SchemaField(title=\"Retry Count\", default=3, description=\"Number of times to retry the LLM call if the response does not match the expected format.\")", "successors": [{"id": 9, "label": "prompt_values: dict[str, str] = SchemaField(advanced=False, default={}, description=\"Values used to fill in the prompt.\")\nmax_tokens: int | None = SchemaField(advanced=True, default=None, description=\"The maximum number of tokens to generate in the chat completion.\")", "successors": [{"id": 11, "label": "ollama_host: str = SchemaField(advanced=True, default=\"localhost:11434\", description=\"Ollama host for local  models\")", "successors": []}]}]}]}]}]}]}, {"name": "Output", "type": "class", "start_line": 251, "end_line": 255, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        response: dict[str, Any] = SchemaField(\n            description=\"The response object generated by the language model.\"\n        )\n        error: str = SchemaField(description=\"Error message if the API call failed.\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    response: dict[str, Any] = SchemaField(\n        description=\"The response object generated by the language model.\"\n    )", "successors": [{"id": 3, "label": "    error: str = SchemaField(description=\"Error message if the API call failed.\")", "successors": []}]}]}], "simplified_code": "class AIStructuredResponseGeneratorBlock(Block):\n\n        error: str = SchemaField(description=\"Error message if the API call failed.\")\n\n        )\n\n    @staticmethod\n            raise ValueError(f\"Unsupported LLM provider: {provider}\")\n\n        raise RuntimeError(retry_prompt)", "blocks": [{"id": 1, "label": "class AIStructuredResponseGeneratorBlock(Block):\nerror: str = SchemaField(description=\"Error message if the API call failed.\")", "successors": [{"id": 3, "label": "@staticmethod", "successors": [{"id": 4, "label": "raise ValueError(f\"Unsupported LLM provider: {provider}\")", "successors": []}, {"id": 5, "label": "raise RuntimeError(retry_prompt)", "successors": []}]}]}]}, {"name": "AITextGeneratorBlock", "type": "class", "start_line": 555, "end_line": 632, "functions": [{"name": "__init__", "type": "function", "start_line": 598, "end_line": 612, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"1f292d4a-41a4-4977-9684-7c8d560b9f91\",\n            description=\"Call a Large Language Model (LLM) to generate a string based on the given prompt.\",\n            categories={BlockCategory.AI},\n            input_schema=AITextGeneratorBlock.Input,\n            output_schema=AITextGeneratorBlock.Output,\n            test_input={\n                \"prompt\": \"User prompt\",\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=(\"response\", \"Response text\"),\n            test_mock={\"llm_call\": lambda *args, **kwargs: \"Response text\"},\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\n    super().__init__(\n        id=\"1f292d4a-41a4-4977-9684-7c8d560b9f91\",\n        description=\"Call a Large Language Model (LLM) to generate a string based on the given prompt.\",\n        categories={BlockCategory.AI},\n        input_schema=AITextGeneratorBlock.Input,\n        output_schema=AITextGeneratorBlock.Output,\n        test_input={\n            \"prompt\": \"User prompt\",\n            \"credentials\": TEST_CREDENTIALS_INPUT,\n        },\n        test_credentials=TEST_CREDENTIALS,\n        test_output=(\"response\", \"Response text\"),\n        test_mock={\"llm_call\": lambda *args, **kwargs: \"Response text\"},\n    )", "successors": []}]}, {"name": "llm_call", "type": "function", "start_line": 614, "end_line": 622, "functions": [], "classes": [], "simplified_code": "    def llm_call(\n        self,\n        input_data: AIStructuredResponseGeneratorBlock.Input,\n        credentials: APIKeyCredentials,\n    ) -> str:\n        block = AIStructuredResponseGeneratorBlock()\n        response = block.run_once(input_data, \"response\", credentials=credentials)\n        self.merge_stats(block.execution_stats)\n        return response[\"response\"]", "blocks": [{"id": 1, "label": "def llm_call(self, input_data: AIStructuredResponseGeneratorBlock.Input, credentials: APIKeyCredentials) -> str:\nblock = AIStructuredResponseGeneratorBlock()\nresponse = block.run_once(input_data, \"response\", credentials=credentials)\nself.merge_stats(block.execution_stats)\nreturn response[\"response\"]", "successors": []}]}, {"name": "run", "type": "function", "start_line": 624, "end_line": 632, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        object_input_data = AIStructuredResponseGeneratorBlock.Input(\n            **{attr: getattr(input_data, attr) for attr in input_data.model_fields},\n            expected_format={},\n        )\n        yield \"response\", self.llm_call(object_input_data, credentials)\n", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs) -> BlockOutput:\nobject_input_data = AIStructuredResponseGeneratorBlock.Input(**{attr: getattr(input_data, attr) for attr in input_data.model_fields}, expected_format={})", "successors": [{"id": 3, "label": "yield \"response\", self.llm_call(object_input_data, credentials)", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 556, "end_line": 590, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        prompt: str = SchemaField(\n            description=\"The prompt to send to the language model. You can use any of the {keys} from Prompt Values to fill in the prompt with values from the prompt values dictionary by putting them in curly braces.\",\n            placeholder=\"Enter your prompt here...\",\n        )\n        model: LlmModel = SchemaField(\n            title=\"LLM Model\",\n            default=LlmModel.GPT4_TURBO,\n            description=\"The language model to use for answering the prompt.\",\n            advanced=False,\n        )\n        credentials: AICredentials = AICredentialsField()\n        sys_prompt: str = SchemaField(\n            title=\"System Prompt\",\n            default=\"\",\n            description=\"The system prompt to provide additional context to the model.\",\n        )\n        retry: int = SchemaField(\n            title=\"Retry Count\",\n            default=3,\n            description=\"Number of times to retry the LLM call if the response does not match the expected format.\",\n        )\n        prompt_values: dict[str, str] = SchemaField(\n            advanced=False, default={}, description=\"Values used to fill in the prompt.\"\n        )\n        ollama_host: str = SchemaField(\n            advanced=True,\n            default=\"localhost:11434\",\n            description=\"Ollama host for local  models\",\n        )\n        max_tokens: int | None = SchemaField(\n            advanced=True,\n            default=None,\n            description=\"The maximum number of tokens to generate in the chat completion.\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "prompt: str = SchemaField(description=\"The prompt to send to the language model. You can use any of the {keys} from Prompt Values to fill in the prompt with values from the prompt values dictionary by putting them in curly braces.\", placeholder=\"Enter your prompt here...\")", "successors": []}, {"id": 3, "label": "model: LlmModel = SchemaField(title=\"LLM Model\", default=LlmModel.GPT4_TURBO, description=\"The language model to use for answering the prompt.\", advanced=False)", "successors": []}, {"id": 4, "label": "credentials: AICredentials = AICredentialsField()", "successors": []}, {"id": 5, "label": "sys_prompt: str = SchemaField(title=\"System Prompt\", default=\"\", description=\"The system prompt to provide additional context to the model.\")", "successors": []}, {"id": 6, "label": "retry: int = SchemaField(title=\"Retry Count\", default=3, description=\"Number of times to retry the LLM call if the response does not match the expected format.\")", "successors": []}, {"id": 7, "label": "prompt_values: dict[str, str] = SchemaField(advanced=False, default={}, description=\"Values used to fill in the prompt.\")", "successors": []}, {"id": 8, "label": "ollama_host: str = SchemaField(advanced=True, default=\"localhost:11434\", description=\"Ollama host for local  models\")", "successors": []}, {"id": 9, "label": "max_tokens: int | None = SchemaField(advanced=True, default=None, description=\"The maximum number of tokens to generate in the chat completion.\")", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 592, "end_line": 596, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        response: str = SchemaField(\n            description=\"The response generated by the language model.\"\n        )\n        error: str = SchemaField(description=\"Error message if the API call failed.\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "response: str = SchemaField(description=\"The response generated by the language model.\")", "successors": []}, {"id": 3, "label": "error: str = SchemaField(description=\"Error message if the API call failed.\")", "successors": []}]}]}], "simplified_code": "class AITextGeneratorBlock(Block):\n        )\n\n        error: str = SchemaField(description=\"Error message if the API call failed.\")\n\n        )\n\n        return response[\"response\"]\n\n", "blocks": [{"id": 1, "label": "class AITextGeneratorBlock(Block):\npass", "successors": []}]}, {"name": "SummaryStyle", "type": "class", "start_line": 634, "end_line": 638, "functions": [], "classes": [], "simplified_code": "class SummaryStyle(Enum):\n    CONCISE = \"concise\"\n    DETAILED = \"detailed\"\n    BULLET_POINTS = \"bullet points\"\n    NUMBERED_LIST = \"numbered list\"", "blocks": [{"id": 1, "label": "class SummaryStyle(Enum):\n    CONCISE = \"concise\"\n    DETAILED = \"detailed\"\n    BULLET_POINTS = \"bullet points\"\n    NUMBERED_LIST = \"numbered list\"", "successors": []}]}, {"name": "AITextSummarizerBlock", "type": "class", "start_line": 641, "end_line": 800, "functions": [{"name": "__init__", "type": "function", "start_line": 686, "end_line": 706, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"a0a69be1-4528-491c-a85a-a4ab6873e3f0\",\n            description=\"Utilize a Large Language Model (LLM) to summarize a long text.\",\n            categories={BlockCategory.AI, BlockCategory.TEXT},\n            input_schema=AITextSummarizerBlock.Input,\n            output_schema=AITextSummarizerBlock.Output,\n            test_input={\n                \"text\": \"Lorem ipsum...\" * 100,\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=(\"summary\", \"Final summary of a long text\"),\n            test_mock={\n                \"llm_call\": lambda input_data, credentials: (\n                    {\"final_summary\": \"Final summary of a long text\"}\n                    if \"final_summary\" in input_data.expected_format\n                    else {\"summary\": \"Summary of a chunk of text\"}\n                )\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"a0a69be1-4528-491c-a85a-a4ab6873e3f0\",\n    description=\"Utilize a Large Language Model (LLM) to summarize a long text.\",\n    categories={BlockCategory.AI, BlockCategory.TEXT},\n    input_schema=AITextSummarizerBlock.Input,\n    output_schema=AITextSummarizerBlock.Output,\n    test_input={\n        \"text\": \"Lorem ipsum...\" * 100,\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=(\"summary\", \"Final summary of a long text\"),\n    test_mock={\n        \"llm_call\": lambda input_data, credentials: (\n            {\"final_summary\": \"Final summary of a long text\"}\n            if \"final_summary\" in input_data.expected_format\n            else {\"summary\": \"Summary of a chunk of text\"}\n        )\n    },\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 708, "end_line": 712, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        for output in self._run(input_data, credentials):\n            yield output", "blocks": [{"id": 1, "label": "def run( self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs ) -> BlockOutput:", "successors": [{"id": 2, "label": "for output in self._run(input_data, credentials):", "successors": [{"id": 3, "label": "yield output", "successors": []}]}]}]}, {"name": "_run", "type": "function", "start_line": 714, "end_line": 725, "functions": [], "classes": [], "simplified_code": "    def _run(self, input_data: Input, credentials: APIKeyCredentials) -> BlockOutput:\n        chunks = self._split_text(\n            input_data.text, input_data.max_tokens, input_data.chunk_overlap\n        )\n        summaries = []\n\n        for chunk in chunks:\n            chunk_summary = self._summarize_chunk(chunk, input_data, credentials)\n            summaries.append(chunk_summary)\n\n        final_summary = self._combine_summaries(summaries, input_data, credentials)\n        yield \"summary\", final_summary", "blocks": [{"id": 1, "label": "def _run(self, input_data: Input, credentials: APIKeyCredentials) -> BlockOutput:\nchunks = self._split_text(input_data.text, input_data.max_tokens, input_data.chunk_overlap)", "successors": [{"id": 3, "label": "summaries = []", "successors": [{"id": 4, "label": "for chunk in chunks:", "successors": [{"id": 5, "label": "chunk_summary = self._summarize_chunk(chunk, input_data, credentials)\nsummaries.append(chunk_summary)", "successors": [{"id": 4, "label": "for chunk in chunks:", "successors": [{"id": 5, "label": "chunk_summary = self._summarize_chunk(chunk, input_data, credentials)\nsummaries.append(chunk_summary)", "successors": [{"id": 4, "label": "for chunk in chunks:", "successors": [{"id": 5, "label": "chunk_summary = self._summarize_chunk(chunk, input_data, credentials)\nsummaries.append(chunk_summary)", "successors": [{"id": 4, "label": "for chunk in chunks:", "successors": [{"id": 5, "label": "chunk_summary = self._summarize_chunk(chunk, input_data, credentials)\nsummaries.append(chunk_summary)", "successors": [{"id": 4, "label": "for chunk in chunks:", "successors": [{"id": 5, "label": "chunk_summary = self._summarize_chunk(chunk, input_data, credentials)\nsummaries.append(chunk_summary)", "successors": [{"id": 4, "label": "for chunk in chunks:", "successors": []}]}]}]}]}]}]}]}]}]}, {"id": 7, "label": "final_summary = self._combine_summaries(summaries, input_data, credentials)\nyield \"summary\", final_summary", "successors": []}]}]}]}]}, {"name": "llm_call", "type": "function", "start_line": 739, "end_line": 747, "functions": [], "classes": [], "simplified_code": "    def llm_call(\n        self,\n        input_data: AIStructuredResponseGeneratorBlock.Input,\n        credentials: APIKeyCredentials,\n    ) -> dict:\n        block = AIStructuredResponseGeneratorBlock()\n        response = block.run_once(input_data, \"response\", credentials=credentials)\n        self.merge_stats(block.execution_stats)\n        return response", "blocks": [{"id": 1, "label": "def llm_call(self, input_data: AIStructuredResponseGeneratorBlock.Input, credentials: APIKeyCredentials) -> dict:\nblock = AIStructuredResponseGeneratorBlock()", "successors": [{"id": 3, "label": "response = block.run_once(input_data, \"response\", credentials=credentials)\nself.merge_stats(block.execution_stats)", "successors": [{"id": 5, "label": "return response", "successors": []}]}]}]}, {"name": "_summarize_chunk", "type": "function", "start_line": 749, "end_line": 764, "functions": [], "classes": [], "simplified_code": "    def _summarize_chunk(\n        self, chunk: str, input_data: Input, credentials: APIKeyCredentials\n    ) -> str:\n        prompt = f\"Summarize the following text in a {input_data.style} form. Focus your summary on the topic of `{input_data.focus}` if present, otherwise just provide a general summary:\\n\\n```{chunk}```\"\n\n        llm_response = self.llm_call(\n            AIStructuredResponseGeneratorBlock.Input(\n                prompt=prompt,\n                credentials=input_data.credentials,\n                model=input_data.model,\n                expected_format={\"summary\": \"The summary of the given text.\"},\n            ),\n            credentials=credentials,\n        )\n\n        return llm_response[\"summary\"]", "blocks": [{"id": 1, "label": "def _summarize_chunk(\n    self, chunk: str, input_data: Input, credentials: APIKeyCredentials\n) -> str:\n    prompt = f\"Summarize the following text in a {input_data.style} form. Focus your summary on the topic of `{input_data.focus}` if present, otherwise just provide a general summary:\\n\\n```{chunk}```\"", "successors": [{"id": 3, "label": "    llm_response = self.llm_call(\n        AIStructuredResponseGeneratorBlock.Input(\n            prompt=prompt,\n            credentials=input_data.credentials,\n            model=input_data.model,\n            expected_format={\"summary\": \"The summary of the given text.\"},\n        ),\n        credentials=credentials,\n    )\n    return llm_response[\"summary\"]", "successors": []}]}]}, {"name": "_combine_summaries", "type": "function", "start_line": 766, "end_line": 800, "functions": [], "classes": [], "simplified_code": "    def _combine_summaries(\n        self, summaries: list[str], input_data: Input, credentials: APIKeyCredentials\n    ) -> str:\n        combined_text = \"\\n\\n\".join(summaries)\n\n        if len(combined_text.split()) <= input_data.max_tokens:\n            prompt = f\"Provide a final summary of the following section summaries in a {input_data.style} form, focus your summary on the topic of `{input_data.focus}` if present:\\n\\n ```{combined_text}```\\n\\n Just respond with the final_summary in the format specified.\"\n\n            llm_response = self.llm_call(\n                AIStructuredResponseGeneratorBlock.Input(\n                    prompt=prompt,\n                    credentials=input_data.credentials,\n                    model=input_data.model,\n                    expected_format={\n                        \"final_summary\": \"The final summary of all provided summaries.\"\n                    },\n                ),\n                credentials=credentials,\n            )\n\n            return llm_response[\"final_summary\"]\n        else:\n            # If combined summaries are still too long, recursively summarize\n            return self._run(\n                AITextSummarizerBlock.Input(\n                    text=combined_text,\n                    credentials=input_data.credentials,\n                    model=input_data.model,\n                    max_tokens=input_data.max_tokens,\n                    chunk_overlap=input_data.chunk_overlap,\n                ),\n                credentials=credentials,\n            ).send(None)[\n                1\n            ]  # Get the first yielded value", "blocks": [{"id": 1, "label": "combined_text = \"\\n\\n\".join(summaries)\nif len(combined_text.split()) <= input_data.max_tokens:", "successors": [{"id": 3, "label": "    prompt = f\"Provide a final summary of the following section summaries in a {input_data.style} form, focus your summary on the topic of `{input_data.focus}` if present:\\n\\n ```{combined_text}```\\n\\n Just respond with the final_summary in the format specified.\"\n    llm_response = self.llm_call(AIStructuredResponseGeneratorBlock.Input(prompt=prompt, credentials=input_data.credentials, model=input_data.model, expected_format={\"final_summary\": \"The final summary of all provided summaries.\"}), credentials=credentials)", "successors": [{"id": 5, "label": "    return llm_response[\"final_summary\"]", "successors": []}]}, {"id": 6, "label": "    return self._run(AITextSummarizerBlock.Input(text=combined_text, credentials=input_data.credentials, model=input_data.model, max_tokens=input_data.max_tokens, chunk_overlap=input_data.chunk_overlap), credentials=credentials).send(None)[1]", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 642, "end_line": 680, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        text: str = SchemaField(\n            description=\"The text to summarize.\",\n            placeholder=\"Enter the text to summarize here...\",\n        )\n        model: LlmModel = SchemaField(\n            title=\"LLM Model\",\n            default=LlmModel.GPT4_TURBO,\n            description=\"The language model to use for summarizing the text.\",\n        )\n        focus: str = SchemaField(\n            title=\"Focus\",\n            default=\"general information\",\n            description=\"The topic to focus on in the summary\",\n        )\n        style: SummaryStyle = SchemaField(\n            title=\"Summary Style\",\n            default=SummaryStyle.CONCISE,\n            description=\"The style of the summary to generate.\",\n        )\n        credentials: AICredentials = AICredentialsField()\n        # TODO: Make this dynamic\n        max_tokens: int = SchemaField(\n            title=\"Max Tokens\",\n            default=4096,\n            description=\"The maximum number of tokens to generate in the chat completion.\",\n            ge=1,\n        )\n        chunk_overlap: int = SchemaField(\n            title=\"Chunk Overlap\",\n            default=100,\n            description=\"The number of overlapping tokens between chunks to maintain context.\",\n            ge=0,\n        )\n        ollama_host: str = SchemaField(\n            advanced=True,\n            default=\"localhost:11434\",\n            description=\"Ollama host for local  models\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    text: str = SchemaField(\n        description=\"The text to summarize.\",\n        placeholder=\"Enter the text to summarize here...\",\n    )", "successors": [{"id": 3, "label": "    model: LlmModel = SchemaField(\n        title=\"LLM Model\",\n        default=LlmModel.GPT4_TURBO,\n        description=\"The language model to use for summarizing the text.\",\n    )\n    focus: str = SchemaField(\n        title=\"Focus\",\n        default=\"general information\",\n        description=\"The topic to focus on in the summary\",\n    )", "successors": [{"id": 5, "label": "    style: SummaryStyle = SchemaField(\n        title=\"Summary Style\",\n        default=SummaryStyle.CONCISE,\n        description=\"The style of the summary to generate.\",\n    )\n    credentials: AICredentials = AICredentialsField()", "successors": [{"id": 7, "label": "    # TODO: Make this dynamic\n    max_tokens: int = SchemaField(\n        title=\"Max Tokens\",\n        default=4096,\n        description=\"The maximum number of tokens to generate in the chat completion.\",\n        ge=1,\n    )\n    chunk_overlap: int = SchemaField(\n        title=\"Chunk Overlap\",\n        default=100,\n        description=\"The number of overlapping tokens between chunks to maintain context.\",\n        ge=0,\n    )", "successors": [{"id": 9, "label": "    ollama_host: str = SchemaField(\n        advanced=True,\n        default=\"localhost:11434\",\n        description=\"Ollama host for local  models\",\n    )", "successors": []}]}]}]}]}]}, {"name": "Output", "type": "class", "start_line": 682, "end_line": 684, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        summary: str = SchemaField(description=\"The final summary of the text.\")\n        error: str = SchemaField(description=\"Error message if the API call failed.\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "summary: str = SchemaField(description=\"The final summary of the text.\")", "successors": []}, {"id": 3, "label": "error: str = SchemaField(description=\"Error message if the API call failed.\")", "successors": []}]}]}], "simplified_code": "class AITextSummarizerBlock(Block):\n        )\n\n        error: str = SchemaField(description=\"Error message if the API call failed.\")\n\n        )\n\n            yield output\n\n        yield \"summary\", final_summary\n\n    @staticmethod\n    def _split_text(text: str, max_tokens: int, overlap: int) -> list[str]:\n        words = text.split()\n        chunks = []\n        chunk_size = max_tokens - overlap\n\n        for i in range(0, len(words), chunk_size):\n            chunk = \" \".join(words[i : i + max_tokens])\n            chunks.append(chunk)\n\n        return chunks\n\n        return response\n\n        return llm_response[\"summary\"]\n\n            ]  # Get the first yielded value", "blocks": [{"id": 1, "label": "class AITextSummarizerBlock(Block):\nerror: str = SchemaField(description=\"Error message if the API call failed.\")", "successors": [{"id": 3, "label": "yield output\nyield \"summary\", final_summary", "successors": []}]}]}, {"name": "AIConversationBlock", "type": "class", "start_line": 803, "end_line": 886, "functions": [{"name": "__init__", "type": "function", "start_line": 831, "end_line": 859, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"32a87eab-381e-4dd4-bdb8-4c47151be35a\",\n            description=\"Advanced LLM call that takes a list of messages and sends them to the language model.\",\n            categories={BlockCategory.AI},\n            input_schema=AIConversationBlock.Input,\n            output_schema=AIConversationBlock.Output,\n            test_input={\n                \"messages\": [\n                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n                    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n                    {\n                        \"role\": \"assistant\",\n                        \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\",\n                    },\n                    {\"role\": \"user\", \"content\": \"Where was it played?\"},\n                ],\n                \"model\": LlmModel.GPT4_TURBO,\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=(\n                \"response\",\n                \"The 2020 World Series was played at Globe Life Field in Arlington, Texas.\",\n            ),\n            test_mock={\n                \"llm_call\": lambda *args, **kwargs: \"The 2020 World Series was played at Globe Life Field in Arlington, Texas.\"\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(id=\"32a87eab-381e-4dd4-bdb8-4c47151be35a\",\n        description=\"Advanced LLM call that takes a list of messages and sends them to the language model.\",\n        categories={BlockCategory.AI},\n        input_schema=AIConversationBlock.Input,\n        output_schema=AIConversationBlock.Output,\n        test_input={\n            \"messages\": [\n                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n                {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n                {\n                    \"role\": \"assistant\",\n                    \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"\n                },\n                {\"role\": \"user\", \"content\": \"Where was it played?\"}\n            ],\n            \"model\": LlmModel.GPT4_TURBO,\n            \"credentials\": TEST_CREDENTIALS_INPUT\n        },\n        test_credentials=TEST_CREDENTIALS,\n        test_output=(\n            \"response\",\n            \"The 2020 World Series was played at Globe Life Field in Arlington, Texas.\"\n        ),\n        test_mock={\n            \"llm_call\": lambda *args, **kwargs: \"The 2020 World Series was played at Globe Life Field in Arlington, Texas.\"\n        }\n    )", "successors": []}]}, {"name": "llm_call", "type": "function", "start_line": 861, "end_line": 869, "functions": [], "classes": [], "simplified_code": "    def llm_call(\n        self,\n        input_data: AIStructuredResponseGeneratorBlock.Input,\n        credentials: APIKeyCredentials,\n    ) -> str:\n        block = AIStructuredResponseGeneratorBlock()\n        response = block.run_once(input_data, \"response\", credentials=credentials)\n        self.merge_stats(block.execution_stats)\n        return response[\"response\"]", "blocks": [{"id": 1, "label": "def llm_call(self, input_data: AIStructuredResponseGeneratorBlock.Input, credentials: APIKeyCredentials) -> str:\n    block = AIStructuredResponseGeneratorBlock()", "successors": [{"id": 3, "label": "    response = block.run_once(input_data, \"response\", credentials=credentials)\n    self.merge_stats(block.execution_stats)", "successors": [{"id": 5, "label": "    return response[\"response\"]", "successors": []}]}]}]}, {"name": "run", "type": "function", "start_line": 871, "end_line": 886, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        response = self.llm_call(\n            AIStructuredResponseGeneratorBlock.Input(\n                prompt=\"\",\n                credentials=input_data.credentials,\n                model=input_data.model,\n                conversation_history=input_data.messages,\n                max_tokens=input_data.max_tokens,\n                expected_format={},\n            ),\n            credentials=credentials,\n        )\n\n        yield \"response\", response", "blocks": [{"id": 1, "label": "def run(\n    self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n) -> BlockOutput:\n    response = self.llm_call(\n        AIStructuredResponseGeneratorBlock.Input(\n            prompt=\"\",\n            credentials=input_data.credentials,\n            model=input_data.model,\n            conversation_history=input_data.messages,\n            max_tokens=input_data.max_tokens,\n            expected_format={},\n        ),\n        credentials=credentials,\n    )", "successors": [{"id": 3, "label": "    yield \"response\", response", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 804, "end_line": 823, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        messages: List[Message] = SchemaField(\n            description=\"List of messages in the conversation.\", min_length=1\n        )\n        model: LlmModel = SchemaField(\n            title=\"LLM Model\",\n            default=LlmModel.GPT4_TURBO,\n            description=\"The language model to use for the conversation.\",\n        )\n        credentials: AICredentials = AICredentialsField()\n        max_tokens: int | None = SchemaField(\n            advanced=True,\n            default=None,\n            description=\"The maximum number of tokens to generate in the chat completion.\",\n        )\n        ollama_host: str = SchemaField(\n            advanced=True,\n            default=\"localhost:11434\",\n            description=\"Ollama host for local  models\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    messages: List[Message] = SchemaField(description=\"List of messages in the conversation.\", min_length=1)", "successors": [{"id": 3, "label": "    model: LlmModel = SchemaField(title=\"LLM Model\", default=LlmModel.GPT4_TURBO, description=\"The language model to use for the conversation.\")\n    credentials: AICredentials = AICredentialsField()", "successors": [{"id": 5, "label": "    max_tokens: int | None = SchemaField(advanced=True, default=None, description=\"The maximum number of tokens to generate in the chat completion.\")\n    ollama_host: str = SchemaField(advanced=True, default=\"localhost:11434\", description=\"Ollama host for local  models\")", "successors": []}]}]}]}, {"name": "Output", "type": "class", "start_line": 825, "end_line": 829, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        response: str = SchemaField(\n            description=\"The model's response to the conversation.\"\n        )\n        error: str = SchemaField(description=\"Error message if the API call failed.\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\nresponse: str = SchemaField(description=\"The model's response to the conversation.\")", "successors": [{"id": 3, "label": "error: str = SchemaField(description=\"Error message if the API call failed.\")", "successors": []}]}]}], "simplified_code": "class AIConversationBlock(Block):\n        )\n\n        error: str = SchemaField(description=\"Error message if the API call failed.\")\n\n        )\n\n        return response[\"response\"]\n\n        yield \"response\", response", "blocks": [{"id": 1, "label": "class AIConversationBlock(Block):", "successors": [{"id": 2, "label": "    error: str = SchemaField(description=\"Error message if the API call failed.\")", "successors": []}, {"id": 3, "label": "    return response[\"response\"]", "successors": []}, {"id": 4, "label": "    yield \"response\", response", "successors": []}]}]}, {"name": "AIListGeneratorBlock", "type": "class", "start_line": 889, "end_line": 1125, "functions": [{"name": "__init__", "type": "function", "start_line": 936, "end_line": 974, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"9c0b0450-d199-458b-a731-072189dd6593\",\n            description=\"Generate a Python list based on the given prompt using a Large Language Model (LLM).\",\n            categories={BlockCategory.AI, BlockCategory.TEXT},\n            input_schema=AIListGeneratorBlock.Input,\n            output_schema=AIListGeneratorBlock.Output,\n            test_input={\n                \"focus\": \"planets\",\n                \"source_data\": (\n                    \"Zylora Prime is a glowing jungle world with bioluminescent plants, \"\n                    \"while Kharon-9 is a harsh desert planet with underground cities. \"\n                    \"Vortexia's constant storms power floating cities, and Oceara is a water-covered world home to \"\n                    \"intelligent marine life. On icy Draknos, ancient ruins lie buried beneath its frozen landscape, \"\n                    \"drawing explorers to uncover its mysteries. Each planet showcases the limitless possibilities of \"\n                    \"fictional worlds.\"\n                ),\n                \"model\": LlmModel.GPT4_TURBO,\n                \"credentials\": TEST_CREDENTIALS_INPUT,\n                \"max_retries\": 3,\n            },\n            test_credentials=TEST_CREDENTIALS,\n            test_output=[\n                (\n                    \"generated_list\",\n                    [\"Zylora Prime\", \"Kharon-9\", \"Vortexia\", \"Oceara\", \"Draknos\"],\n                ),\n                (\"list_item\", \"Zylora Prime\"),\n                (\"list_item\", \"Kharon-9\"),\n                (\"list_item\", \"Vortexia\"),\n                (\"list_item\", \"Oceara\"),\n                (\"list_item\", \"Draknos\"),\n            ],\n            test_mock={\n                \"llm_call\": lambda input_data, credentials: {\n                    \"response\": \"['Zylora Prime', 'Kharon-9', 'Vortexia', 'Oceara', 'Draknos']\"\n                },\n            },\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"9c0b0450-d199-458b-a731-072189dd6593\",\n    description=\"Generate a Python list based on the given prompt using a Large Language Model (LLM).\",\n    categories={BlockCategory.AI, BlockCategory.TEXT},\n    input_schema=AIListGeneratorBlock.Input,\n    output_schema=AIListGeneratorBlock.Output,\n    test_input={\n        \"focus\": \"planets\",\n        \"source_data\": (\n            \"Zylora Prime is a glowing jungle world with bioluminescent plants, \"\n            \"while Kharon-9 is a harsh desert planet with underground cities. \"\n            \"Vortexia's constant storms power floating cities, and Oceara is a water-covered world home to \"\n            \"intelligent marine life. On icy Draknos, ancient ruins lie buried beneath its frozen landscape, \"\n            \"drawing explorers to uncover its mysteries. Each planet showcases the limitless possibilities of \"\n            \"fictional worlds.\"\n        ),\n        \"model\": LlmModel.GPT4_TURBO,\n        \"credentials\": TEST_CREDENTIALS_INPUT,\n        \"max_retries\": 3,\n    },\n    test_credentials=TEST_CREDENTIALS,\n    test_output=[\n        (\n            \"generated_list\",\n            [\"Zylora Prime\", \"Kharon-9\", \"Vortexia\", \"Oceara\", \"Draknos\"],\n        ),\n        (\"list_item\", \"Zylora Prime\"),\n        (\"list_item\", \"Kharon-9\"),\n        (\"list_item\", \"Vortexia\"),\n        (\"list_item\", \"Oceara\"),\n        (\"list_item\", \"Draknos\"),\n    ],\n    test_mock={\n        \"llm_call\": lambda input_data, credentials: {\n            \"response\": \"['Zylora Prime', 'Kharon-9', 'Vortexia', 'Oceara', 'Draknos']\"\n        },\n    },\n)", "successors": []}]}, {"name": "llm_call", "type": "function", "start_line": 977, "end_line": 983, "functions": [], "classes": [], "simplified_code": "    def llm_call(\n        input_data: AIStructuredResponseGeneratorBlock.Input,\n        credentials: APIKeyCredentials,\n    ) -> dict[str, str]:\n        llm_block = AIStructuredResponseGeneratorBlock()\n        response = llm_block.run_once(input_data, \"response\", credentials=credentials)\n        return response", "blocks": [{"id": 1, "label": "def llm_call( input_data: AIStructuredResponseGeneratorBlock.Input, credentials: APIKeyCredentials, ) -> dict[str, str]:\nllm_block = AIStructuredResponseGeneratorBlock()", "successors": [{"id": 3, "label": "response = llm_block.run_once(input_data, \"response\", credentials=credentials)\nreturn response", "successors": []}]}]}, {"name": "string_to_list", "type": "function", "start_line": 986, "end_line": 1002, "functions": [], "classes": [], "simplified_code": "    def string_to_list(string):\n        \"\"\"\n        Converts a string representation of a list into an actual Python list object.\n        \"\"\"\n        logger.debug(f\"Converting string to list. Input string: {string}\")\n        try:\n            # Use ast.literal_eval to safely evaluate the string\n            python_list = ast.literal_eval(string)\n            if isinstance(python_list, list):\n                logger.debug(f\"Successfully converted string to list: {python_list}\")\n                return python_list\n            else:\n                logger.error(f\"The provided string '{string}' is not a valid list\")\n                raise ValueError(f\"The provided string '{string}' is not a valid list.\")\n        except (SyntaxError, ValueError) as e:\n            logger.error(f\"Failed to convert string to list: {e}\")\n            raise ValueError(\"Invalid list format. Could not convert to list.\")", "blocks": [{"id": 1, "label": "def string_to_list(string):\nlogger.debug(f\"Converting string to list. Input string: {string}\")", "successors": [{"id": 3, "label": "try:", "successors": [{"id": 4, "label": "python_list = ast.literal_eval(string)\nif isinstance(python_list, list):", "successors": [{"id": 6, "label": "logger.debug(f\"Successfully converted string to list: {python_list}\")\nreturn python_list", "successors": []}, {"id": 8, "label": "logger.error(f\"The provided string '{string}' is not a valid list\")\nraise ValueError(f\"The provided string '{string}' is not a valid list.\")", "successors": []}]}, {"id": 10, "label": "except (SyntaxError, ValueError) as e:\nlogger.error(f\"Failed to convert string to list: {e}\")", "successors": [{"id": 12, "label": "raise ValueError(\"Invalid list format. Could not convert to list.\")", "successors": []}]}]}]}]}, {"name": "run", "type": "function", "start_line": 1004, "end_line": 1125, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        logger.debug(f\"Starting AIListGeneratorBlock.run with input data: {input_data}\")\n\n        # Check for API key\n        api_key_check = credentials.api_key.get_secret_value()\n        if not api_key_check:\n            raise ValueError(\"No LLM API key provided.\")\n\n        # Prepare the system prompt\n        sys_prompt = \"\"\"You are a Python list generator. Your task is to generate a Python list based on the user's prompt. \n            |Respond ONLY with a valid python list. \n            |The list can contain strings, numbers, or nested lists as appropriate. \n            |Do not include any explanations or additional text.\n\n            |Valid Example string formats:\n\n            |Example 1:\n            |```\n            |['1', '2', '3', '4']\n            |```\n\n            |Example 2:\n            |```\n            |[['1', '2'], ['3', '4'], ['5', '6']]\n            |```\n\n            |Example 3:\n            |```\n            |['1', ['2', '3'], ['4', ['5', '6']]]\n            |```\n\n            |Example 4:\n            |```\n            |['a', 'b', 'c']\n            |```\n\n            |Example 5:\n            |```\n            |['1', '2.5', 'string', 'True', ['False', 'None']]\n            |```\n\n            |Do not include any explanations or additional text, just respond with the list in the format specified above.\n            \"\"\"\n        # If a focus is provided, add it to the prompt\n        if input_data.focus:\n            prompt = f\"Generate a list with the following focus:\\n<focus>\\n\\n{input_data.focus}</focus>\"\n        else:\n            # If there's source data\n            if input_data.source_data:\n                prompt = \"Extract the main focus of the source data to a list.\\ni.e if the source data is a news website, the focus would be the news stories rather than the social links in the footer.\"\n            else:\n                # No focus or source data provided, generat a random list\n                prompt = \"Generate a random list.\"\n\n        # If the source data is provided, add it to the prompt\n        if input_data.source_data:\n            prompt += f\"\\n\\nUse the following source data to generate the list from:\\n\\n<source_data>\\n\\n{input_data.source_data}</source_data>\\n\\nDo not invent fictional data that is not present in the source data.\"\n        # Else, tell the LLM to synthesize the data\n        else:\n            prompt += \"\\n\\nInvent the data to generate the list from.\"\n\n        for attempt in range(input_data.max_retries):\n            try:\n                logger.debug(\"Calling LLM\")\n                llm_response = self.llm_call(\n                    AIStructuredResponseGeneratorBlock.Input(\n                        sys_prompt=sys_prompt,\n                        prompt=prompt,\n                        credentials=input_data.credentials,\n                        model=input_data.model,\n                        expected_format={},  # Do not use structured response\n                        ollama_host=input_data.ollama_host,\n                    ),\n                    credentials=credentials,\n                )\n\n                logger.debug(f\"LLM response: {llm_response}\")\n\n                # Extract Response string\n                response_string = llm_response[\"response\"]\n                logger.debug(f\"Response string: {response_string}\")\n\n                # Convert the string to a Python list\n                logger.debug(\"Converting string to Python list\")\n                parsed_list = self.string_to_list(response_string)\n                logger.debug(f\"Parsed list: {parsed_list}\")\n\n                # If we reach here, we have a valid Python list\n                logger.debug(\"Successfully generated a valid Python list\")\n                yield \"generated_list\", parsed_list\n\n                # Yield each item in the list\n                for item in parsed_list:\n                    yield \"list_item\", item\n                return\n\n            except Exception as e:\n                logger.error(f\"Error in attempt {attempt + 1}: {str(e)}\")\n                if attempt == input_data.max_retries - 1:\n                    logger.error(\n                        f\"Failed to generate a valid Python list after {input_data.max_retries} attempts\"\n                    )\n                    raise RuntimeError(\n                        f\"Failed to generate a valid Python list after {input_data.max_retries} attempts. Last error: {str(e)}\"\n                    )\n                else:\n                    # Add a retry prompt\n                    logger.debug(\"Preparing retry prompt\")\n                    prompt = f\"\"\"\n                    The previous attempt failed due to `{e}`\n                    Generate a valid Python list based on the original prompt.\n                    Remember to respond ONLY with a valid Python list as per the format specified earlier.\n                    Original prompt: \n                    ```{prompt}```\n                    \n                    Respond only with the list in the format specified with no commentary or apologies.\n                    \"\"\"\n                    logger.debug(f\"Retry prompt: {prompt}\")\n\n        logger.debug(\"AIListGeneratorBlock.run completed\")", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs) -> BlockOutput:\nlogger.debug(f\"Starting AIListGeneratorBlock.run with input data: {input_data}\")", "successors": [{"id": 3, "label": "api_key_check = credentials.api_key.get_secret_value()", "successors": [{"id": 4, "label": "if not api_key_check:\nraise ValueError(\"No LLM API key provided.\")", "successors": []}, {"id": 6, "label": "sys_prompt = \"\"\"You are a Python list generator. Your task is to generate a Python list based on the user's prompt. \n            |Respond ONLY with a valid python list. \n            |The list can contain strings, numbers, or nested lists as appropriate. \n            |Do not include any explanations or additional text.\n\n            |Valid Example string formats:\n\n            |Example 1:\n            |```\n            |['1', '2', '3', '4']\n            |```\n\n            |Example 2:\n            |```\n            |[['1', '2'], ['3', '4'], ['5', '6']]\n            |```\n\n            |Example 3:\n            |```\n            |['1', ['2', '3'], ['4', ['5', '6']]]\n            |```\n\n            |Example 4:\n            |```\n            |['a', 'b', 'c']\n            |```\n\n            |Example 5:\n            |```\n            |['1', '2.5', 'string', 'True', ['False', 'None']]\n            |```\n\n            |Do not include any explanations or additional text, just respond with the list in the format specified above.\n            \"\"\"\nif input_data.focus:", "successors": [{"id": 8, "label": "prompt = f\"Generate a list with the following focus:\\n<focus>\\n\\n{input_data.focus}</focus>\"\nif input_data.source_data:", "successors": [{"id": 15, "label": "prompt += f\"\\n\\nUse the following source data to generate the list from:\\n\\n<source_data>\\n\\n{input_data.source_data}</source_data>\\n\\nDo not invent fictional data that is not present in the source data.\"", "successors": [{"id": 22, "label": "for attempt in range(input_data.max_retries):", "successors": [{"id": 23, "label": "try:", "successors": [{"id": 24, "label": "logger.debug(\"Calling LLM\")\nllm_response = self.llm_call(AIStructuredResponseGeneratorBlock.Input(sys_prompt=sys_prompt, prompt=prompt, credentials=input_data.credentials, model=input_data.model, expected_format={},  # Do not use structured response ollama_host=input_data.ollama_host,), credentials=credentials,)", "successors": [{"id": 26, "label": "logger.debug(f\"LLM response: {llm_response}\")\nresponse_string = llm_response[\"response\"]", "successors": [{"id": 28, "label": "logger.debug(f\"Response string: {response_string}\")\nlogger.debug(\"Converting string to Python list\")", "successors": [{"id": 30, "label": "parsed_list = self.string_to_list(response_string)\nlogger.debug(f\"Parsed list: {parsed_list}\")", "successors": [{"id": 32, "label": "logger.debug(\"Successfully generated a valid Python list\")\nyield \"generated_list\", parsed_list", "successors": [{"id": 34, "label": "for item in parsed_list:", "successors": [{"id": 35, "label": "yield \"list_item\", item", "successors": []}]}, {"id": 36, "label": "return", "successors": []}]}]}]}]}]}, {"id": 37, "label": "except Exception as e:\nlogger.error(f\"Error in attempt {attempt + 1}: {str(e)}\")", "successors": [{"id": 39, "label": "if attempt == input_data.max_retries - 1:\nlogger.error(\"Failed to generate a valid Python list after {input_data.max_retries} attempts\")", "successors": [{"id": 41, "label": "raise RuntimeError(f\"Failed to generate a valid Python list after {input_data.max_retries} attempts. Last error: {str(e)}\")", "successors": []}]}, {"id": 42, "label": "logger.debug(\"Preparing retry prompt\")\nprompt = f\"\"\n                    The previous attempt failed due to `{e}`\n                    Generate a valid Python list based on the original prompt.\n                    Remember to respond ONLY with a valid Python list as per the format specified earlier.\n                    Original prompt: \n                    ```{prompt}```\n                    \n                    Respond only with the list in the format specified with no commentary or apologies.\n                    \"\"\"", "successors": [{"id": 44, "label": "logger.debug(f\"Retry prompt: {prompt}\")", "successors": []}]}]}]}]}]}, {"id": 16, "label": "prompt += \"\\n\\nInvent the data to generate the list from.\"", "successors": [{"id": 22, "label": "for attempt in range(input_data.max_retries):", "successors": [{"id": 23, "label": "try:", "successors": [{"id": 24, "label": "logger.debug(\"Calling LLM\")\nllm_response = self.llm_call(AIStructuredResponseGeneratorBlock.Input(sys_prompt=sys_prompt, prompt=prompt, credentials=input_data.credentials, model=input_data.model, expected_format={},  # Do not use structured response ollama_host=input_data.ollama_host,), credentials=credentials,)", "successors": [{"id": 26, "label": "logger.debug(f\"LLM response: {llm_response}\")\nresponse_string = llm_response[\"response\"]", "successors": [{"id": 28, "label": "logger.debug(f\"Response string: {response_string}\")\nlogger.debug(\"Converting string to Python list\")", "successors": [{"id": 30, "label": "parsed_list = self.string_to_list(response_string)\nlogger.debug(f\"Parsed list: {parsed_list}\")", "successors": [{"id": 32, "label": "logger.debug(\"Successfully generated a valid Python list\")\nyield \"generated_list\", parsed_list", "successors": [{"id": 34, "label": "for item in parsed_list:", "successors": [{"id": 35, "label": "yield \"list_item\", item", "successors": []}]}, {"id": 36, "label": "return", "successors": []}]}]}]}]}]}, {"id": 37, "label": "except Exception as e:\nlogger.error(f\"Error in attempt {attempt + 1}: {str(e)}\")", "successors": [{"id": 39, "label": "if attempt == input_data.max_retries - 1:\nlogger.error(\"Failed to generate a valid Python list after {input_data.max_retries} attempts\")", "successors": [{"id": 41, "label": "raise RuntimeError(f\"Failed to generate a valid Python list after {input_data.max_retries} attempts. Last error: {str(e)}\")", "successors": []}]}, {"id": 42, "label": "logger.debug(\"Preparing retry prompt\")\nprompt = f\"\"\n                    The previous attempt failed due to `{e}`\n                    Generate a valid Python list based on the original prompt.\n                    Remember to respond ONLY with a valid Python list as per the format specified earlier.\n                    Original prompt: \n                    ```{prompt}```\n                    \n                    Respond only with the list in the format specified with no commentary or apologies.\n                    \"\"\"", "successors": [{"id": 44, "label": "logger.debug(f\"Retry prompt: {prompt}\")", "successors": []}]}]}]}]}]}]}, {"id": 9, "label": "if input_data.source_data:", "successors": [{"id": 10, "label": "prompt = \"Extract the main focus of the source data to a list.\\ni.e if the source data is a news website, the focus would be the news stories rather than the social links in the footer.\"", "successors": [{"id": 14, "label": "if input_data.source_data:\nprompt += f\"\\n\\nUse the following source data to generate the list from:\\n\\n<source_data>\\n\\n{input_data.source_data}</source_data>\\n\\nDo not invent fictional data that is not present in the source data.\"", "successors": [{"id": 22, "label": "for attempt in range(input_data.max_retries):", "successors": [{"id": 23, "label": "try:", "successors": [{"id": 24, "label": "logger.debug(\"Calling LLM\")\nllm_response = self.llm_call(AIStructuredResponseGeneratorBlock.Input(sys_prompt=sys_prompt, prompt=prompt, credentials=input_data.credentials, model=input_data.model, expected_format={},  # Do not use structured response ollama_host=input_data.ollama_host,), credentials=credentials,)", "successors": [{"id": 26, "label": "logger.debug(f\"LLM response: {llm_response}\")\nresponse_string = llm_response[\"response\"]", "successors": [{"id": 28, "label": "logger.debug(f\"Response string: {response_string}\")\nlogger.debug(\"Converting string to Python list\")", "successors": [{"id": 30, "label": "parsed_list = self.string_to_list(response_string)\nlogger.debug(f\"Parsed list: {parsed_list}\")", "successors": [{"id": 32, "label": "logger.debug(\"Successfully generated a valid Python list\")\nyield \"generated_list\", parsed_list", "successors": [{"id": 34, "label": "for item in parsed_list:", "successors": [{"id": 35, "label": "yield \"list_item\", item", "successors": []}]}, {"id": 36, "label": "return", "successors": []}]}]}]}]}]}, {"id": 37, "label": "except Exception as e:\nlogger.error(f\"Error in attempt {attempt + 1}: {str(e)}\")", "successors": [{"id": 39, "label": "if attempt == input_data.max_retries - 1:\nlogger.error(\"Failed to generate a valid Python list after {input_data.max_retries} attempts\")", "successors": [{"id": 41, "label": "raise RuntimeError(f\"Failed to generate a valid Python list after {input_data.max_retries} attempts. Last error: {str(e)}\")", "successors": []}]}, {"id": 42, "label": "logger.debug(\"Preparing retry prompt\")\nprompt = f\"\"\n                    The previous attempt failed due to `{e}`\n                    Generate a valid Python list based on the original prompt.\n                    Remember to respond ONLY with a valid Python list as per the format specified earlier.\n                    Original prompt: \n                    ```{prompt}```\n                    \n                    Respond only with the list in the format specified with no commentary or apologies.\n                    \"\"\"", "successors": [{"id": 44, "label": "logger.debug(f\"Retry prompt: {prompt}\")", "successors": []}]}]}]}]}]}, {"id": 16, "label": "prompt += \"\\n\\nInvent the data to generate the list from.\"", "successors": [{"id": 22, "label": "for attempt in range(input_data.max_retries):", "successors": [{"id": 23, "label": "try:", "successors": [{"id": 24, "label": "logger.debug(\"Calling LLM\")\nllm_response = self.llm_call(AIStructuredResponseGeneratorBlock.Input(sys_prompt=sys_prompt, prompt=prompt, credentials=input_data.credentials, model=input_data.model, expected_format={},  # Do not use structured response ollama_host=input_data.ollama_host,), credentials=credentials,)", "successors": [{"id": 26, "label": "logger.debug(f\"LLM response: {llm_response}\")\nresponse_string = llm_response[\"response\"]", "successors": [{"id": 28, "label": "logger.debug(f\"Response string: {response_string}\")\nlogger.debug(\"Converting string to Python list\")", "successors": [{"id": 30, "label": "parsed_list = self.string_to_list(response_string)\nlogger.debug(f\"Parsed list: {parsed_list}\")", "successors": [{"id": 32, "label": "logger.debug(\"Successfully generated a valid Python list\")\nyield \"generated_list\", parsed_list", "successors": [{"id": 34, "label": "for item in parsed_list:", "successors": [{"id": 35, "label": "yield \"list_item\", item", "successors": []}]}, {"id": 36, "label": "return", "successors": []}]}]}]}]}]}, {"id": 37, "label": "except Exception as e:\nlogger.error(f\"Error in attempt {attempt + 1}: {str(e)}\")", "successors": [{"id": 39, "label": "if attempt == input_data.max_retries - 1:\nlogger.error(\"Failed to generate a valid Python list after {input_data.max_retries} attempts\")", "successors": [{"id": 41, "label": "raise RuntimeError(f\"Failed to generate a valid Python list after {input_data.max_retries} attempts. Last error: {str(e)}\")", "successors": []}]}, {"id": 42, "label": "logger.debug(\"Preparing retry prompt\")\nprompt = f\"\"\n                    The previous attempt failed due to `{e}`\n                    Generate a valid Python list based on the original prompt.\n                    Remember to respond ONLY with a valid Python list as per the format specified earlier.\n                    Original prompt: \n                    ```{prompt}```\n                    \n                    Respond only with the list in the format specified with no commentary or apologies.\n                    \"\"\"", "successors": [{"id": 44, "label": "logger.debug(f\"Retry prompt: {prompt}\")", "successors": []}]}]}]}]}]}]}, {"id": 11, "label": "prompt = \"Generate a random list.\"", "successors": [{"id": 14, "label": "if input_data.source_data:\nprompt += f\"\\n\\nUse the following source data to generate the list from:\\n\\n<source_data>\\n\\n{input_data.source_data}</source_data>\\n\\nDo not invent fictional data that is not present in the source data.\"", "successors": [{"id": 22, "label": "for attempt in range(input_data.max_retries):", "successors": [{"id": 23, "label": "try:", "successors": [{"id": 24, "label": "logger.debug(\"Calling LLM\")\nllm_response = self.llm_call(AIStructuredResponseGeneratorBlock.Input(sys_prompt=sys_prompt, prompt=prompt, credentials=input_data.credentials, model=input_data.model, expected_format={},  # Do not use structured response ollama_host=input_data.ollama_host,), credentials=credentials,)", "successors": [{"id": 26, "label": "logger.debug(f\"LLM response: {llm_response}\")\nresponse_string = llm_response[\"response\"]", "successors": [{"id": 28, "label": "logger.debug(f\"Response string: {response_string}\")\nlogger.debug(\"Converting string to Python list\")", "successors": [{"id": 30, "label": "parsed_list = self.string_to_list(response_string)\nlogger.debug(f\"Parsed list: {parsed_list}\")", "successors": [{"id": 32, "label": "logger.debug(\"Successfully generated a valid Python list\")\nyield \"generated_list\", parsed_list", "successors": [{"id": 34, "label": "for item in parsed_list:", "successors": [{"id": 35, "label": "yield \"list_item\", item", "successors": []}]}, {"id": 36, "label": "return", "successors": []}]}]}]}]}]}, {"id": 37, "label": "except Exception as e:\nlogger.error(f\"Error in attempt {attempt + 1}: {str(e)}\")", "successors": [{"id": 39, "label": "if attempt == input_data.max_retries - 1:\nlogger.error(\"Failed to generate a valid Python list after {input_data.max_retries} attempts\")", "successors": [{"id": 41, "label": "raise RuntimeError(f\"Failed to generate a valid Python list after {input_data.max_retries} attempts. Last error: {str(e)}\")", "successors": []}]}, {"id": 42, "label": "logger.debug(\"Preparing retry prompt\")\nprompt = f\"\"\n                    The previous attempt failed due to `{e}`\n                    Generate a valid Python list based on the original prompt.\n                    Remember to respond ONLY with a valid Python list as per the format specified earlier.\n                    Original prompt: \n                    ```{prompt}```\n                    \n                    Respond only with the list in the format specified with no commentary or apologies.\n                    \"\"\"", "successors": [{"id": 44, "label": "logger.debug(f\"Retry prompt: {prompt}\")", "successors": []}]}]}]}]}]}, {"id": 16, "label": "prompt += \"\\n\\nInvent the data to generate the list from.\"", "successors": [{"id": 22, "label": "for attempt in range(input_data.max_retries):", "successors": [{"id": 23, "label": "try:", "successors": [{"id": 24, "label": "logger.debug(\"Calling LLM\")\nllm_response = self.llm_call(AIStructuredResponseGeneratorBlock.Input(sys_prompt=sys_prompt, prompt=prompt, credentials=input_data.credentials, model=input_data.model, expected_format={},  # Do not use structured response ollama_host=input_data.ollama_host,), credentials=credentials,)", "successors": [{"id": 26, "label": "logger.debug(f\"LLM response: {llm_response}\")\nresponse_string = llm_response[\"response\"]", "successors": [{"id": 28, "label": "logger.debug(f\"Response string: {response_string}\")\nlogger.debug(\"Converting string to Python list\")", "successors": [{"id": 30, "label": "parsed_list = self.string_to_list(response_string)\nlogger.debug(f\"Parsed list: {parsed_list}\")", "successors": [{"id": 32, "label": "logger.debug(\"Successfully generated a valid Python list\")\nyield \"generated_list\", parsed_list", "successors": [{"id": 34, "label": "for item in parsed_list:", "successors": [{"id": 35, "label": "yield \"list_item\", item", "successors": []}]}, {"id": 36, "label": "return", "successors": []}]}]}]}]}]}, {"id": 37, "label": "except Exception as e:\nlogger.error(f\"Error in attempt {attempt + 1}: {str(e)}\")", "successors": [{"id": 39, "label": "if attempt == input_data.max_retries - 1:\nlogger.error(\"Failed to generate a valid Python list after {input_data.max_retries} attempts\")", "successors": [{"id": 41, "label": "raise RuntimeError(f\"Failed to generate a valid Python list after {input_data.max_retries} attempts. Last error: {str(e)}\")", "successors": []}]}, {"id": 42, "label": "logger.debug(\"Preparing retry prompt\")\nprompt = f\"\"\n                    The previous attempt failed due to `{e}`\n                    Generate a valid Python list based on the original prompt.\n                    Remember to respond ONLY with a valid Python list as per the format specified earlier.\n                    Original prompt: \n                    ```{prompt}```\n                    \n                    Respond only with the list in the format specified with no commentary or apologies.\n                    \"\"\"", "successors": [{"id": 44, "label": "logger.debug(f\"Retry prompt: {prompt}\")", "successors": []}]}]}]}]}]}]}]}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 890, "end_line": 925, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        focus: str | None = SchemaField(\n            description=\"The focus of the list to generate.\",\n            placeholder=\"The top 5 most interesting news stories in the data.\",\n            default=None,\n            advanced=False,\n        )\n        source_data: str | None = SchemaField(\n            description=\"The data to generate the list from.\",\n            placeholder=\"News Today: Humans land on Mars: Today humans landed on mars. -- AI wins Nobel Prize: AI wins Nobel Prize for solving world hunger. -- New AI Model: A new AI model has been released.\",\n            default=None,\n            advanced=False,\n        )\n        model: LlmModel = SchemaField(\n            title=\"LLM Model\",\n            default=LlmModel.GPT4_TURBO,\n            description=\"The language model to use for generating the list.\",\n            advanced=True,\n        )\n        credentials: AICredentials = AICredentialsField()\n        max_retries: int = SchemaField(\n            default=3,\n            description=\"Maximum number of retries for generating a valid list.\",\n            ge=1,\n            le=5,\n        )\n        max_tokens: int | None = SchemaField(\n            advanced=True,\n            default=None,\n            description=\"The maximum number of tokens to generate in the chat completion.\",\n        )\n        ollama_host: str = SchemaField(\n            advanced=True,\n            default=\"localhost:11434\",\n            description=\"Ollama host for local  models\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\nfocus: str | None = SchemaField(description=\"The focus of the list to generate.\", placeholder=\"The top 5 most interesting news stories in the data.\", default=None, advanced=False,)", "successors": [{"id": 3, "label": "source_data: str | None = SchemaField(description=\"The data to generate the list from.\", placeholder=\"News Today: Humans land on Mars: Today humans landed on mars. -- AI wins Nobel Prize: AI wins Nobel Prize for solving world hunger. -- New AI Model: A new AI model has been released.\", default=None, advanced=False,)\nmodel: LlmModel = SchemaField(title=\"LLM Model\", default=LlmModel.GPT4_TURBO, description=\"The language model to use for generating the list.\", advanced=True,)", "successors": [{"id": 5, "label": "credentials: AICredentials = AICredentialsField()\nmax_retries: int = SchemaField(default=3, description=\"Maximum number of retries for generating a valid list.\", ge=1, le=5,)", "successors": [{"id": 7, "label": "max_tokens: int | None = SchemaField(advanced=True, default=None, description=\"The maximum number of tokens to generate in the chat completion.\",)\nollama_host: str = SchemaField(advanced=True, default=\"localhost:11434\", description=\"Ollama host for local  models\",)", "successors": []}]}]}]}]}, {"name": "Output", "type": "class", "start_line": 927, "end_line": 934, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        generated_list: List[str] = SchemaField(description=\"The generated list.\")\n        list_item: str = SchemaField(\n            description=\"Each individual item in the list.\",\n        )\n        error: str = SchemaField(\n            description=\"Error message if the list generation failed.\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "    generated_list: List[str] = SchemaField(description=\"The generated list.\")", "successors": []}, {"id": 3, "label": "    list_item: str = SchemaField(description=\"Each individual item in the list.\")", "successors": []}, {"id": 4, "label": "    error: str = SchemaField(description=\"Error message if the list generation failed.\")", "successors": []}]}]}], "simplified_code": "class AIListGeneratorBlock(Block):\n        )\n\n        )\n\n        )\n\n    @staticmethod\n        return response\n\n    @staticmethod\n            raise ValueError(\"Invalid list format. Could not convert to list.\")\n\n        logger.debug(\"AIListGeneratorBlock.run completed\")", "blocks": [{"id": 1, "label": "class AIListGeneratorBlock(Block):", "successors": [{"id": 2, "label": "@staticmethod\nreturn response", "successors": []}, {"id": 4, "label": "@staticmethod\nraise ValueError(\"Invalid list format. Could not convert to list.\")", "successors": []}, {"id": 6, "label": "logger.debug(\"AIListGeneratorBlock.run completed\")", "successors": []}]}]}], "simplified_code": "import ast\nimport logging\nfrom enum import Enum, EnumMeta\nfrom json import JSONDecodeError\nfrom types import MappingProxyType\nfrom typing import TYPE_CHECKING, Any, List, Literal, NamedTuple\n\nfrom pydantic import SecretStr\n\nfrom backend.integrations.providers import ProviderName\n\nif TYPE_CHECKING:\n    from enum import _EnumMemberT\n\nimport anthropic\nimport ollama\nimport openai\nfrom groq import Groq\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.util import json\nfrom backend.util.settings import BehaveAs, Settings\n\nlogger = logging.getLogger(__name__)\n\nLLMProviderName = Literal[\n    ProviderName.ANTHROPIC,\n    ProviderName.GROQ,\n    ProviderName.OLLAMA,\n    ProviderName.OPENAI,\n    ProviderName.OPEN_ROUTER,\n]\nAICredentials = CredentialsMetaInput[LLMProviderName, Literal[\"api_key\"]]\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"ed55ac19-356e-4243-a6cb-bc599e9b716f\",\n    provider=\"openai\",\n    api_key=SecretStr(\"mock-openai-api-key\"),\n    title=\"Mock OpenAI API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.title,\n}\n\n\n    )\n\n\n    context_window: int\n\n\n            return MappingProxyType(members)\n\n\n        raise ValueError(f\"Missing MODEL_METADATA metadata for model: {model}\")\n\n\n    ASSISTANT = \"assistant\"\n\n\n    content: str\n\n\n        raise RuntimeError(retry_prompt)\n\n\n\n\n    NUMBERED_LIST = \"numbered list\"\n\n\n            ]  # Get the first yielded value\n\n\n        yield \"response\", response\n\n\n        logger.debug(\"AIListGeneratorBlock.run completed\")", "blocks": [{"id": 1, "label": "import ast\nimport logging\nfrom enum import Enum, EnumMeta\nfrom json import JSONDecodeError\nfrom types import MappingProxyType\nfrom typing import TYPE_CHECKING, Any, List, Literal, NamedTuple\n\nfrom pydantic import SecretStr\n\nfrom backend.integrations.providers import ProviderName\n\nif TYPE_CHECKING:\n    from enum import _EnumMemberT\n\nimport anthropic\nimport ollama\nimport openai\nfrom groq import Groq\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.util import json\nfrom backend.util.settings import BehaveAs, Settings\n\nlogger = logging.getLogger(__name__)\n\nLLMProviderName = Literal[\n    ProviderName.ANTHROPIC,\n    ProviderName.GROQ,\n    ProviderName.OLLAMA,\n    ProviderName.OPENAI,\n    ProviderName.OPEN_ROUTER,\n]\nAICredentials = CredentialsMetaInput[LLMProviderName, Literal[\"api_key\"]]\n\nTEST_CREDENTIALS = APIKeyCredentials(\n    id=\"ed55ac19-356e-4243-a6cb-bc599e9b716f\",\n    provider=\"openai\",\n    api_key=SecretStr(\"mock-openai-api-key\"),\n    title=\"Mock OpenAI API key\",\n    expires_at=None,\n)\nTEST_CREDENTIALS_INPUT = {\n    \"provider\": TEST_CREDENTIALS.provider,\n    \"id\": TEST_CREDENTIALS.id,\n    \"type\": TEST_CREDENTIALS.type,\n    \"title\": TEST_CREDENTIALS.title\n}\n\n\n    )\n\n\n    context_window: int\n\n\n            return MappingProxyType(members)\n\n\n        raise ValueError(f\"Missing MODEL_METADATA metadata for model: {model}\")\n\n\n    ASSISTANT = \"assistant\"\n\n\n    content: str\n\n\n        raise RuntimeError(retry_prompt)\n\n\n\n\n    NUMBERED_LIST = \"numbered list\"\n\n\n            ]  # Get the first yielded value\n\n\n        yield \"response\", response\n\n\n        logger.debug(\"AIListGeneratorBlock.run completed\")", "successors": []}]}
{"file_name": "187.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 16, "functions": [{"name": "main", "type": "function", "start_line": 5, "end_line": 12, "functions": [], "classes": [], "simplified_code": "def main():\n    \"\"\"\n    Run all the processes required for the AutoGPT-server REST API.\n    \"\"\"\n    run_processes(\n        DatabaseManager(),\n        ExecutionManager(),\n    )", "blocks": [{"id": 1, "label": "def main():\n\"\"\"\nRun all the processes required for the AutoGPT-server REST API.\n\"\"\"", "successors": [{"id": 3, "label": "run_processes(\n    DatabaseManager(),\n    ExecutionManager(),\n)", "successors": []}]}]}], "classes": [], "simplified_code": "from backend.app import run_processes\nfrom backend.executor import DatabaseManager, ExecutionManager\n\n\n    )\n\n\nif __name__ == \"__main__\":\n    main()", "blocks": [{"id": 1, "label": "from backend.app import run_processes\nfrom backend.executor import DatabaseManager, ExecutionManager\n\nif __name__ == \"__main__\":", "successors": [{"id": 3, "label": "    main()", "successors": []}]}]}
{"file_name": "188.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 264, "functions": [{"name": "setup_prisma", "type": "function", "start_line": 13, "end_line": 19, "functions": [], "classes": [], "simplified_code": "async def setup_prisma():\n    # Don't register client if already registered\n    try:\n        Prisma()\n    except prisma.errors.ClientAlreadyRegisteredError:\n        pass\n    yield", "blocks": [{"id": 1, "label": "async def setup_prisma():\ntry:", "successors": [{"id": 3, "label": "Prisma()\nyield", "successors": []}, {"id": 4, "label": "except prisma.errors.ClientAlreadyRegisteredError:\n    pass\nyield", "successors": []}]}]}, {"name": "test_get_store_agents", "type": "function", "start_line": 23, "end_line": 61, "functions": [], "classes": [], "simplified_code": "async def test_get_store_agents(mocker):\n    # Mock data\n    mock_agents = [\n        prisma.models.StoreAgent(\n            listing_id=\"test-id\",\n            storeListingVersionId=\"version123\",\n            slug=\"test-agent\",\n            agent_name=\"Test Agent\",\n            agent_video=None,\n            agent_image=[\"image.jpg\"],\n            featured=False,\n            creator_username=\"creator\",\n            creator_avatar=\"avatar.jpg\",\n            sub_heading=\"Test heading\",\n            description=\"Test description\",\n            categories=[],\n            runs=10,\n            rating=4.5,\n            versions=[\"1.0\"],\n            updated_at=datetime.now(),\n        )\n    ]\n\n    # Mock prisma calls\n    mock_store_agent = mocker.patch(\"prisma.models.StoreAgent.prisma\")\n    mock_store_agent.return_value.find_many = mocker.AsyncMock(return_value=mock_agents)\n    mock_store_agent.return_value.count = mocker.AsyncMock(return_value=1)\n\n    # Call function\n    result = await db.get_store_agents()\n\n    # Verify results\n    assert len(result.agents) == 1\n    assert result.agents[0].slug == \"test-agent\"\n    assert result.pagination.total_items == 1\n\n    # Verify mocks called correctly\n    mock_store_agent.return_value.find_many.assert_called_once()\n    mock_store_agent.return_value.count.assert_called_once()", "blocks": [{"id": 1, "label": "async def test_get_store_agents(mocker):\n    mock_agents = [\n        prisma.models.StoreAgent(\n            listing_id=\"test-id\",\n            storeListingVersionId=\"version123\",\n            slug=\"test-agent\",\n            agent_name=\"Test Agent\",\n            agent_video=None,\n            agent_image=[\"image.jpg\"],\n            featured=False,\n            creator_username=\"creator\",\n            creator_avatar=\"avatar.jpg\",\n            sub_heading=\"Test heading\",\n            description=\"Test description\",\n            categories=[],\n            runs=10,\n            rating=4.5,\n            versions=[\"1.0\"],\n            updated_at=datetime.now(),\n        )\n    ]", "successors": [{"id": 3, "label": "    mock_store_agent = mocker.patch(\"prisma.models.StoreAgent.prisma\")\n    mock_store_agent.return_value.find_many = mocker.AsyncMock(return_value=mock_agents)\n    mock_store_agent.return_value.count = mocker.AsyncMock(return_value=1)\n    result = await db.get_store_agents()", "successors": [{"id": 5, "label": "    assert len(result.agents) == 1\n    assert result.agents[0].slug == \"test-agent\"\n    assert result.pagination.total_items == 1\n    mock_store_agent.return_value.find_many.assert_called_once()\n    mock_store_agent.return_value.count.assert_called_once()", "successors": []}]}]}]}, {"name": "test_get_store_agent_details", "type": "function", "start_line": 65, "end_line": 100, "functions": [], "classes": [], "simplified_code": "async def test_get_store_agent_details(mocker):\n    # Mock data\n    mock_agent = prisma.models.StoreAgent(\n        listing_id=\"test-id\",\n        storeListingVersionId=\"version123\",\n        slug=\"test-agent\",\n        agent_name=\"Test Agent\",\n        agent_video=\"video.mp4\",\n        agent_image=[\"image.jpg\"],\n        featured=False,\n        creator_username=\"creator\",\n        creator_avatar=\"avatar.jpg\",\n        sub_heading=\"Test heading\",\n        description=\"Test description\",\n        categories=[\"test\"],\n        runs=10,\n        rating=4.5,\n        versions=[\"1.0\"],\n        updated_at=datetime.now(),\n    )\n\n    # Mock prisma call\n    mock_store_agent = mocker.patch(\"prisma.models.StoreAgent.prisma\")\n    mock_store_agent.return_value.find_first = mocker.AsyncMock(return_value=mock_agent)\n\n    # Call function\n    result = await db.get_store_agent_details(\"creator\", \"test-agent\")\n\n    # Verify results\n    assert result.slug == \"test-agent\"\n    assert result.agent_name == \"Test Agent\"\n\n    # Verify mock called correctly\n    mock_store_agent.return_value.find_first.assert_called_once_with(\n        where={\"creator_username\": \"creator\", \"slug\": \"test-agent\"}\n    )", "blocks": [{"id": 1, "label": "async def test_get_store_agent_details(mocker):\n    mock_agent = prisma.models.StoreAgent(\n        listing_id=\"test-id\",\n        storeListingVersionId=\"version123\",\n        slug=\"test-agent\",\n        agent_name=\"Test Agent\",\n        agent_video=\"video.mp4\",\n        agent_image=[\"image.jpg\"],\n        featured=False,\n        creator_username=\"creator\",\n        creator_avatar=\"avatar.jpg\",\n        sub_heading=\"Test heading\",\n        description=\"Test description\",\n        categories=[\"test\"],\n        runs=10,\n        rating=4.5,\n        versions=[\"1.0\"],\n        updated_at=datetime.now(),\n    )", "successors": [{"id": 3, "label": "    mock_store_agent = mocker.patch(\"prisma.models.StoreAgent.prisma\")\n    mock_store_agent.return_value.find_first = mocker.AsyncMock(return_value=mock_agent)\n    result = await db.get_store_agent_details(\"creator\", \"test-agent\")", "successors": [{"id": 5, "label": "    assert result.slug == \"test-agent\"\n    assert result.agent_name == \"Test Agent\"\n    mock_store_agent.return_value.find_first.assert_called_once_with(\n        where={\"creator_username\": \"creator\", \"slug\": \"test-agent\"}\n    )", "successors": []}]}]}]}, {"name": "test_get_store_creator_details", "type": "function", "start_line": 104, "end_line": 137, "functions": [], "classes": [], "simplified_code": "async def test_get_store_creator_details(mocker):\n    # Mock data\n    mock_creator_data = prisma.models.Creator(\n        name=\"Test Creator\",\n        username=\"creator\",\n        description=\"Test description\",\n        links=[\"link1\"],\n        avatar_url=\"avatar.jpg\",\n        num_agents=1,\n        agent_rating=4.5,\n        agent_runs=10,\n        top_categories=[\"test\"],\n        is_featured=False,\n    )\n\n    # Mock prisma call\n    mock_creator = mocker.patch(\"prisma.models.Creator.prisma\")\n    mock_creator.return_value.find_unique = mocker.AsyncMock()\n    # Configure the mock to return values that will pass validation\n    mock_creator.return_value.find_unique.return_value = mock_creator_data\n\n    # Call function\n    result = await db.get_store_creator_details(\"creator\")\n\n    # Verify results\n    assert result.username == \"creator\"\n    assert result.name == \"Test Creator\"\n    assert result.description == \"Test description\"\n    assert result.avatar_url == \"avatar.jpg\"\n\n    # Verify mock called correctly\n    mock_creator.return_value.find_unique.assert_called_once_with(\n        where={\"username\": \"creator\"}\n    )", "blocks": [{"id": 1, "label": "async def test_get_store_creator_details(mocker):\n    mock_creator_data = prisma.models.Creator(name=\"Test Creator\", username=\"creator\", description=\"Test description\", links=[\"link1\"], avatar_url=\"avatar.jpg\", num_agents=1, agent_rating=4.5, agent_runs=10, top_categories=[\"test\"], is_featured=False)", "successors": [{"id": 3, "label": "    mock_creator = mocker.patch(\"prisma.models.Creator.prisma\")\n    mock_creator.return_value.find_unique = mocker.AsyncMock()\n    mock_creator.return_value.find_unique.return_value = mock_creator_data\n    result = await db.get_store_creator_details(\"creator\")", "successors": [{"id": 5, "label": "    assert result.username == \"creator\"\n    assert result.name == \"Test Creator\"\n    assert result.description == \"Test description\"\n    assert result.avatar_url == \"avatar.jpg\"\n    mock_creator.return_value.find_unique.assert_called_once_with(where={\"username\": \"creator\"})", "successors": []}]}]}]}, {"name": "test_create_store_submission", "type": "function", "start_line": 141, "end_line": 188, "functions": [], "classes": [], "simplified_code": "async def test_create_store_submission(mocker):\n    # Mock data\n    mock_agent = prisma.models.AgentGraph(\n        id=\"agent-id\",\n        version=1,\n        userId=\"user-id\",\n        createdAt=datetime.now(),\n        isActive=True,\n        isTemplate=False,\n    )\n\n    mock_listing = prisma.models.StoreListing(\n        id=\"listing-id\",\n        createdAt=datetime.now(),\n        updatedAt=datetime.now(),\n        isDeleted=False,\n        isApproved=False,\n        agentId=\"agent-id\",\n        agentVersion=1,\n        owningUserId=\"user-id\",\n    )\n\n    # Mock prisma calls\n    mock_agent_graph = mocker.patch(\"prisma.models.AgentGraph.prisma\")\n    mock_agent_graph.return_value.find_first = mocker.AsyncMock(return_value=mock_agent)\n\n    mock_store_listing = mocker.patch(\"prisma.models.StoreListing.prisma\")\n    mock_store_listing.return_value.find_first = mocker.AsyncMock(return_value=None)\n    mock_store_listing.return_value.create = mocker.AsyncMock(return_value=mock_listing)\n\n    # Call function\n    result = await db.create_store_submission(\n        user_id=\"user-id\",\n        agent_id=\"agent-id\",\n        agent_version=1,\n        slug=\"test-agent\",\n        name=\"Test Agent\",\n        description=\"Test description\",\n    )\n\n    # Verify results\n    assert result.name == \"Test Agent\"\n    assert result.description == \"Test description\"\n\n    # Verify mocks called correctly\n    mock_agent_graph.return_value.find_first.assert_called_once()\n    mock_store_listing.return_value.find_first.assert_called_once()\n    mock_store_listing.return_value.create.assert_called_once()", "blocks": [{"id": 1, "label": "async def test_create_store_submission(mocker):\n    mock_agent = prisma.models.AgentGraph(\n        id=\"agent-id\",\n        version=1,\n        userId=\"user-id\",\n        createdAt=datetime.now(),\n        isActive=True,\n        isTemplate=False,\n    )", "successors": [{"id": 3, "label": "    mock_listing = prisma.models.StoreListing(\n        id=\"listing-id\",\n        createdAt=datetime.now(),\n        updatedAt=datetime.now(),\n        isDeleted=False,\n        isApproved=False,\n        agentId=\"agent-id\",\n        agentVersion=1,\n        owningUserId=\"user-id\",\n    )\n    mock_agent_graph = mocker.patch(\"prisma.models.AgentGraph.prisma\")\n    mock_agent_graph.return_value.find_first = mocker.AsyncMock(return_value=mock_agent)", "successors": [{"id": 5, "label": "    mock_store_listing = mocker.patch(\"prisma.models.StoreListing.prisma\")\n    mock_store_listing.return_value.find_first = mocker.AsyncMock(return_value=None)\n    mock_store_listing.return_value.create = mocker.AsyncMock(return_value=mock_listing)\n    result = await db.create_store_submission(\n        user_id=\"user-id\",\n        agent_id=\"agent-id\",\n        agent_version=1,\n        slug=\"test-agent\",\n        name=\"Test Agent\",\n        description=\"Test description\",\n    )", "successors": [{"id": 7, "label": "    assert result.name == \"Test Agent\"\n    assert result.description == \"Test description\"\n    mock_agent_graph.return_value.find_first.assert_called_once()\n    mock_store_listing.return_value.find_first.assert_called_once()\n    mock_store_listing.return_value.create.assert_called_once()", "successors": []}]}]}]}]}, {"name": "test_update_profile", "type": "function", "start_line": 192, "end_line": 232, "functions": [], "classes": [], "simplified_code": "async def test_update_profile(mocker):\n    # Mock data\n    mock_profile = prisma.models.Profile(\n        id=\"profile-id\",\n        name=\"Test Creator\",\n        username=\"creator\",\n        description=\"Test description\",\n        links=[\"link1\"],\n        avatarUrl=\"avatar.jpg\",\n        isFeatured=False,\n        createdAt=datetime.now(),\n        updatedAt=datetime.now(),\n    )\n\n    # Mock prisma calls\n    mock_profile_db = mocker.patch(\"prisma.models.Profile.prisma\")\n    mock_profile_db.return_value.find_first = mocker.AsyncMock(\n        return_value=mock_profile\n    )\n    mock_profile_db.return_value.update = mocker.AsyncMock(return_value=mock_profile)\n\n    # Test data\n    profile = Profile(\n        name=\"Test Creator\",\n        username=\"creator\",\n        description=\"Test description\",\n        links=[\"link1\"],\n        avatar_url=\"avatar.jpg\",\n        is_featured=False,\n    )\n\n    # Call function\n    result = await db.update_or_create_profile(\"user-id\", profile)\n\n    # Verify results\n    assert result.username == \"creator\"\n    assert result.name == \"Test Creator\"\n\n    # Verify mocks called correctly\n    mock_profile_db.return_value.find_first.assert_called_once()\n    mock_profile_db.return_value.update.assert_called_once()", "blocks": [{"id": 1, "label": "async def test_update_profile(mocker):\n    mock_profile = prisma.models.Profile(\n        id=\"profile-id\",\n        name=\"Test Creator\",\n        username=\"creator\",\n        description=\"Test description\",\n        links=[\"link1\"],\n        avatarUrl=\"avatar.jpg\",\n        isFeatured=False,\n        createdAt=datetime.now(),\n        updatedAt=datetime.now(),\n    )", "successors": [{"id": 3, "label": "    mock_profile_db = mocker.patch(\"prisma.models.Profile.prisma\")\n    mock_profile_db.return_value.find_first = mocker.AsyncMock(\n        return_value=mock_profile\n    )\n    mock_profile_db.return_value.update = mocker.AsyncMock(return_value=mock_profile)\n    profile = Profile(\n        name=\"Test Creator\",\n        username=\"creator\",\n        description=\"Test description\",\n        links=[\"link1\"],\n        avatar_url=\"avatar.jpg\",\n        is_featured=False,\n    )", "successors": [{"id": 5, "label": "    result = await db.update_or_create_profile(\"user-id\", profile)\n    assert result.username == \"creator\"\n    assert result.name == \"Test Creator\"", "successors": [{"id": 7, "label": "    mock_profile_db.return_value.find_first.assert_called_once()\n    mock_profile_db.return_value.update.assert_called_once()", "successors": []}]}]}]}]}, {"name": "test_get_user_profile", "type": "function", "start_line": 236, "end_line": 264, "functions": [], "classes": [], "simplified_code": "async def test_get_user_profile(mocker):\n    # Mock data\n    mock_profile = prisma.models.Profile(\n        id=\"profile-id\",\n        name=\"No Profile Data\",\n        username=\"testuser\",\n        description=\"Test description\",\n        links=[\"link1\", \"link2\"],\n        avatarUrl=\"avatar.jpg\",\n        isFeatured=False,\n        createdAt=datetime.now(),\n        updatedAt=datetime.now(),\n    )\n\n    # Mock prisma calls\n    mock_profile_db = mocker.patch(\"prisma.models.Profile.prisma\")\n    mock_profile_db.return_value.find_unique = mocker.AsyncMock(\n        return_value=mock_profile\n    )\n\n    # Call function\n    result = await db.get_user_profile(\"user-id\")\n\n    # Verify results\n    assert result.name == \"No Profile Data\"\n    assert result.username == \"No Profile Data\"\n    assert result.description == \"No Profile Data\"\n    assert result.links == []\n    assert result.avatar_url == \"\"", "blocks": [{"id": 1, "label": "async def test_get_user_profile(mocker):\n    mock_profile = prisma.models.Profile(id=\"profile-id\", name=\"No Profile Data\", username=\"testuser\", description=\"Test description\", links=[\"link1\", \"link2\"], avatarUrl=\"avatar.jpg\", isFeatured=False, createdAt=datetime.now(), updatedAt=datetime.now())", "successors": [{"id": 3, "label": "    mock_profile_db = mocker.patch(\"prisma.models.Profile.prisma\")\n    mock_profile_db.return_value.find_unique = mocker.AsyncMock(return_value=mock_profile)", "successors": [{"id": 5, "label": "    result = await db.get_user_profile(\"user-id\")\n    assert result.name == \"No Profile Data\"", "successors": [{"id": 7, "label": "    assert result.username == \"No Profile Data\"\n    assert result.description == \"No Profile Data\"", "successors": [{"id": 9, "label": "    assert result.links == []\n    assert result.avatar_url == \"\"", "successors": []}]}]}]}]}]}], "classes": [], "simplified_code": "from datetime import datetime\n\nimport prisma.errors\nimport prisma.models\nimport pytest\nfrom prisma import Prisma\n\nimport backend.server.v2.store.db as db\nfrom backend.server.v2.store.model import Profile\n\n\n@pytest.fixture(autouse=True)\n    yield\n\n\n@pytest.mark.asyncio\n    mock_store_agent.return_value.count.assert_called_once()\n\n\n@pytest.mark.asyncio\n    )\n\n\n@pytest.mark.asyncio\n    )\n\n\n@pytest.mark.asyncio\n    mock_store_listing.return_value.create.assert_called_once()\n\n\n@pytest.mark.asyncio\n    mock_profile_db.return_value.update.assert_called_once()\n\n\n@pytest.mark.asyncio\n    assert result.avatar_url == \"\"", "blocks": [{"id": 1, "label": "from datetime import datetime\n\nimport prisma.errors\nimport prisma.models\nimport pytest\nfrom prisma import Prisma\n\nimport backend.server.v2.store.db as db\nfrom backend.server.v2.store.model import Profile\n\n\n@pytest.fixture(autouse=True)\nyield\n\n\n@pytest.mark.asyncio\nmock_store_agent.return_value.count.assert_called_once()\n\n\n@pytest.mark.asyncio\n\n\n@pytest.mark.asyncio\n\n\n@pytest.mark.asyncio\nmock_store_listing.return_value.create.assert_called_once()\n\n\n@pytest.mark.asyncio\nmock_profile_db.return_value.update.assert_called_once()\n\n\n@pytest.mark.asyncio\nassert result.avatar_url == \"\"", "successors": []}]}
{"file_name": "189.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 30, "functions": [], "classes": [{"name": "LogConfig", "type": "class", "start_line": 4, "end_line": 30, "functions": [], "classes": [], "simplified_code": "class LogConfig(BaseModel):\n    \"\"\"Logging configuration to be set for the server\"\"\"\n\n    LOGGER_NAME: str = \"marketplace\"\n    LOG_FORMAT: str = \"%(levelprefix)s | %(asctime)s | %(message)s\"\n    LOG_LEVEL: str = \"DEBUG\"\n\n    # Logging config\n    version: int = 1\n    disable_existing_loggers: bool = False\n    formatters: dict = {\n        \"default\": {\n            \"()\": \"uvicorn.logging.DefaultFormatter\",\n            \"fmt\": LOG_FORMAT,\n            \"datefmt\": \"%Y-%m-%d %H:%M:%S\",\n        },\n    }\n    handlers: dict = {\n        \"default\": {\n            \"formatter\": \"default\",\n            \"class\": \"logging.StreamHandler\",\n            \"stream\": \"ext://sys.stderr\",\n        },\n    }\n    loggers: dict = {\n        LOGGER_NAME: {\"handlers\": [\"default\"], \"level\": LOG_LEVEL},\n    }", "blocks": [{"id": 1, "label": "class LogConfig(BaseModel):\n    \"\"\"Logging configuration to be set for the server\"\"\"\n\n    LOGGER_NAME: str = \"marketplace\"\n    LOG_FORMAT: str = \"%(levelprefix)s | %(asctime)s | %(message)s\"\n    LOG_LEVEL: str = \"DEBUG\"\n\n    # Logging config\n    version: int = 1\n    disable_existing_loggers: bool = False\n    formatters: dict = {\n        \"default\": {\n            \"()\": \"uvicorn.logging.DefaultFormatter\",\n            \"fmt\": LOG_FORMAT,\n            \"datefmt\": \"%Y-%m-%d %H:%M:%S\",\n        },\n    }\n    handlers: dict = {\n        \"default\": {\n            \"formatter\": \"default\",\n            \"class\": \"logging.StreamHandler\",\n            \"stream\": \"ext://sys.stderr\",\n        },\n    }\n    loggers: dict = {\n        LOGGER_NAME: {\"handlers\": [\"default\"], \"level\": LOG_LEVEL},\n    }", "successors": []}]}], "simplified_code": "from pydantic import BaseModel\n\n\n    }", "blocks": [{"id": 1, "label": "from pydantic import BaseModel", "successors": []}]}
{"file_name": "190.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 6, "functions": [], "classes": [{"name": "MissingConfigError", "type": "class", "start_line": 1, "end_line": 2, "functions": [], "simplified_code": "class MissingConfigError(Exception):\n    \"\"\"The attempted operation requires configuration which is not available\"\"\"", "blocks": [{"id": 1, "label": "class MissingConfigError(Exception):\n\"\"\"The attempted operation requires configuration which is not available\"\"\"", "successors": []}]}, {"name": "NeedConfirmation", "type": "class", "start_line": 5, "end_line": 6, "functions": [], "simplified_code": "class NeedConfirmation(Exception):\n    \"\"\"The user must explicitly confirm that they want to proceed\"\"\"", "blocks": [{"id": 1, "label": "class NeedConfirmation(Exception):\n    \"\"\"The user must explicitly confirm that they want to proceed\"\"\"", "successors": []}]}], "simplified_code": "    \"\"\"The attempted operation requires configuration which is not available\"\"\"\n\n\n    \"\"\"The user must explicitly confirm that they want to proceed\"\"\"", "blocks": []}
{"file_name": "191.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 101, "functions": [{"name": "get_valid_pos", "type": "function", "start_line": 6, "end_line": 32, "functions": [], "classes": [], "simplified_code": "def get_valid_pos(position: tuple[int, int], n: int) -> list[tuple[int, int]]:\n    \"\"\"\n    Find all the valid positions a knight can move to from the current position.\n\n    >>> get_valid_pos((1, 3), 4)\n    [(2, 1), (0, 1), (3, 2)]\n    \"\"\"\n\n    y, x = position\n    positions = [\n        (y + 1, x + 2),\n        (y - 1, x + 2),\n        (y + 1, x - 2),\n        (y - 1, x - 2),\n        (y + 2, x + 1),\n        (y + 2, x - 1),\n        (y - 2, x + 1),\n        (y - 2, x - 1),\n    ]\n    permissible_positions = []\n\n    for inner_position in positions:\n        y_test, x_test = inner_position\n        if 0 <= y_test < n and 0 <= x_test < n:\n            permissible_positions.append(inner_position)\n\n    return permissible_positions", "blocks": [{"id": 1, "label": "def get_valid_pos(position: tuple[int, int], n: int) -> list[tuple[int, int]]:\n    \"\"\"\n    Find all the valid positions a knight can move to from the current position.\n\n    >>> get_valid_pos((1, 3), 4)\n    [(2, 1), (0, 1), (3, 2)]\n    \"\"\"\n\n    y, x = position\n    positions = [\n        (y + 1, x + 2),\n        (y - 1, x + 2),\n        (y + 1, x - 2),\n        (y - 1, x - 2),\n        (y + 2, x + 1),\n        (y + 2, x - 1),\n        (y - 2, x + 1),\n        (y - 2, x - 1),\n    ]\n    permissible_positions = []", "successors": [{"id": 2, "label": "for inner_position in positions:\n    y_test, x_test = inner_position", "successors": [{"id": 3, "label": "if 0 <= y_test < n and 0 <= x_test < n:", "successors": [{"id": 4, "label": "    permissible_positions.append(inner_position)\nreturn permissible_positions", "successors": []}, {"id": 5, "label": "return permissible_positions", "successors": []}]}]}]}]}, {"name": "is_complete", "type": "function", "start_line": 35, "end_line": 46, "functions": [], "classes": [], "simplified_code": "def is_complete(board: list[list[int]]) -> bool:\n    \"\"\"\n    Check if the board (matrix) has been completely filled with non-zero values.\n\n    >>> is_complete([[1]])\n    True\n\n    >>> is_complete([[1, 2], [3, 0]])\n    False\n    \"\"\"\n\n    return not any(elem == 0 for row in board for elem in row)", "blocks": [{"id": 1, "label": "def is_complete(board: list[list[int]]) -> bool:\nreturn not any(elem == 0 for row in board for elem in row)", "successors": []}]}, {"name": "open_knight_tour_helper", "type": "function", "start_line": 49, "end_line": 68, "functions": [], "classes": [], "simplified_code": "def open_knight_tour_helper(\n    board: list[list[int]], pos: tuple[int, int], curr: int\n) -> bool:\n    \"\"\"\n    Helper function to solve knight tour problem.\n    \"\"\"\n\n    if is_complete(board):\n        return True\n\n    for position in get_valid_pos(pos, len(board)):\n        y, x = position\n\n        if board[y][x] == 0:\n            board[y][x] = curr + 1\n            if open_knight_tour_helper(board, position, curr + 1):\n                return True\n            board[y][x] = 0\n\n    return False", "blocks": [{"id": 1, "label": "def open_knight_tour_helper(\n    board: list[list[int]], pos: tuple[int, int], curr: int\n) -> bool:", "successors": [{"id": 2, "label": "if is_complete(board):\n    return True", "successors": []}, {"id": 4, "label": "for position in get_valid_pos(pos, len(board)):\n    y, x = position", "successors": [{"id": 5, "label": "if board[y][x] == 0:\n    board[y][x] = curr + 1", "successors": [{"id": 7, "label": "if open_knight_tour_helper(board, position, curr + 1):\n    return True", "successors": []}, {"id": 9, "label": "board[y][x] = 0", "successors": []}]}]}, {"id": 10, "label": "return False", "successors": []}]}]}, {"name": "open_knight_tour", "type": "function", "start_line": 71, "end_line": 95, "functions": [], "classes": [], "simplified_code": "def open_knight_tour(n: int) -> list[list[int]]:\n    \"\"\"\n    Find the solution for the knight tour problem for a board of size n. Raises\n    ValueError if the tour cannot be performed for the given size.\n\n    >>> open_knight_tour(1)\n    [[1]]\n\n    >>> open_knight_tour(2)\n    Traceback (most recent call last):\n        ...\n    ValueError: Open Knight Tour cannot be performed on a board of size 2\n    \"\"\"\n\n    board = [[0 for i in range(n)] for j in range(n)]\n\n    for i in range(n):\n        for j in range(n):\n            board[i][j] = 1\n            if open_knight_tour_helper(board, (i, j), 1):\n                return board\n            board[i][j] = 0\n\n    msg = f\"Open Knight Tour cannot be performed on a board of size {n}\"\n    raise ValueError(msg)", "blocks": [{"id": 1, "label": "def open_knight_tour(n: int) -> list[list[int]]:\n    board = [[0 for i in range(n)] for j in range(n)]", "successors": [{"id": 3, "label": "for i in range(n):", "successors": [{"id": 4, "label": "for j in range(n):", "successors": [{"id": 5, "label": "board[i][j] = 1\nif open_knight_tour_helper(board, (i, j), 1):", "successors": [{"id": 7, "label": "return board", "successors": []}, {"id": 8, "label": "board[i][j] = 0\nmsg = f\"Open Knight Tour cannot be performed on a board of size {n}\"", "successors": [{"id": 10, "label": "raise ValueError(msg)", "successors": []}]}]}]}]}]}]}], "classes": [], "simplified_code": "# Knight Tour Intro: https://www.youtube.com/watch?v=ab_dY3dZFHM\n\nfrom __future__ import annotations\n\n\n    return permissible_positions\n\n\n    return not any(elem == 0 for row in board for elem in row)\n\n\n    return False\n\n\n    raise ValueError(msg)\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()", "blocks": [{"id": 1, "label": "if __name__ == \"__main__\":\n    import doctest", "successors": [{"id": 3, "label": "    doctest.testmod()", "successors": []}]}]}
{"file_name": "192.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 124, "functions": [], "classes": [{"name": "Operation", "type": "class", "start_line": 9, "end_line": 14, "functions": [], "classes": [], "simplified_code": "class Operation(Enum):\n    ADD = \"Add\"\n    SUBTRACT = \"Subtract\"\n    MULTIPLY = \"Multiply\"\n    DIVIDE = \"Divide\"\n    POWER = \"Power\"", "blocks": [{"id": 1, "label": "class Operation(Enum):\n    ADD = \"Add\"", "successors": [{"id": 3, "label": "    SUBTRACT = \"Subtract\"\n    MULTIPLY = \"Multiply\"", "successors": [{"id": 5, "label": "    DIVIDE = \"Divide\"\n    POWER = \"Power\"", "successors": []}]}]}]}, {"name": "CalculatorBlock", "type": "class", "start_line": 17, "end_line": 84, "functions": [{"name": "__init__", "type": "function", "start_line": 37, "end_line": 53, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"b1ab9b19-67a6-406d-abf5-2dba76d00c79\",\n            input_schema=CalculatorBlock.Input,\n            output_schema=CalculatorBlock.Output,\n            description=\"Performs a mathematical operation on two numbers.\",\n            categories={BlockCategory.LOGIC},\n            test_input={\n                \"operation\": Operation.ADD.value,\n                \"a\": 10.0,\n                \"b\": 5.0,\n                \"round_result\": False,\n            },\n            test_output=[\n                (\"result\", 15.0),\n            ],\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"b1ab9b19-67a6-406d-abf5-2dba76d00c79\",\n    input_schema=CalculatorBlock.Input,\n    output_schema=CalculatorBlock.Output,\n    description=\"Performs a mathematical operation on two numbers.\",\n    categories={BlockCategory.LOGIC},\n    test_input={\n        \"operation\": Operation.ADD.value,\n        \"a\": 10.0,\n        \"b\": 5.0,\n        \"round_result\": False,\n    },\n    test_output=[\n        (\"result\", 15.0),\n    ],\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 55, "end_line": 84, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        operation = input_data.operation\n        a = input_data.a\n        b = input_data.b\n\n        operations = {\n            Operation.ADD: operator.add,\n            Operation.SUBTRACT: operator.sub,\n            Operation.MULTIPLY: operator.mul,\n            Operation.DIVIDE: operator.truediv,\n            Operation.POWER: operator.pow,\n        }\n\n        op_func = operations[operation]\n\n        try:\n            if operation == Operation.DIVIDE and b == 0:\n                raise ZeroDivisionError(\"Cannot divide by zero\")\n\n            result = op_func(a, b)\n\n            if input_data.round_result:\n                result = round(result)\n\n            yield \"result\", result\n\n        except ZeroDivisionError:\n            yield \"result\", float(\"inf\")  # Return infinity for division by zero\n        except Exception:\n            yield \"result\", float(\"nan\")  # Return NaN for other errors", "blocks": [{"id": 1, "label": "operation = input_data.operation\na = input_data.a\nb = input_data.b\n\noperations = {\n    Operation.ADD: operator.add,\n    Operation.SUBTRACT: operator.sub,\n    Operation.MULTIPLY: operator.mul,\n    Operation.DIVIDE: operator.truediv,\n    Operation.POWER: operator.pow,\n}\n\nop_func = operations[operation]\ntry:", "successors": [{"id": 3, "label": "if operation == Operation.DIVIDE and b == 0:", "successors": [{"id": 4, "label": "raise ZeroDivisionError(\"Cannot divide by zero\")", "successors": []}, {"id": 5, "label": "result = op_func(a, b)", "successors": [{"id": 6, "label": "if input_data.round_result:", "successors": [{"id": 7, "label": "result = round(result)", "successors": []}, {"id": 8, "label": "yield \"result\", result", "successors": []}]}, {"id": 8, "label": "yield \"result\", result", "successors": []}]}]}, {"id": 9, "label": "except ZeroDivisionError:\nyield \"result\", float(\"inf\")  # Return infinity for division by zero", "successors": []}, {"id": 11, "label": "except Exception:\nyield \"result\", float(\"nan\")  # Return NaN for other errors", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 18, "end_line": 32, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        operation: Operation = SchemaField(\n            description=\"Choose the math operation you want to perform\",\n            placeholder=\"Select an operation\",\n        )\n        a: float = SchemaField(\n            description=\"Enter the first number (A)\", placeholder=\"For example: 10\"\n        )\n        b: float = SchemaField(\n            description=\"Enter the second number (B)\", placeholder=\"For example: 5\"\n        )\n        round_result: bool = SchemaField(\n            description=\"Do you want to round the result to a whole number?\",\n            default=False,\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\noperation: Operation = SchemaField(description=\"Choose the math operation you want to perform\", placeholder=\"Select an operation\")", "successors": [{"id": 3, "label": "a: float = SchemaField(description=\"Enter the first number (A)\", placeholder=\"For example: 10\")\nb: float = SchemaField(description=\"Enter the second number (B)\", placeholder=\"For example: 5\")", "successors": [{"id": 5, "label": "round_result: bool = SchemaField(description=\"Do you want to round the result to a whole number?\", default=False)", "successors": []}]}]}]}, {"name": "Output", "type": "class", "start_line": 34, "end_line": 35, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        result: float = SchemaField(description=\"The result of your calculation\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    result: float = SchemaField(description=\"The result of your calculation\")", "successors": []}]}], "simplified_code": "class CalculatorBlock(Block):\n        )\n\n        result: float = SchemaField(description=\"The result of your calculation\")\n\n        )\n\n            yield \"result\", float(\"nan\")  # Return NaN for other errors", "blocks": [{"id": 1, "label": "class CalculatorBlock(Block):\n    def calculate(self, a, b, operation):", "successors": [{"id": 3, "label": "        try:", "successors": [{"id": 4, "label": "            if operation == 'add':\n                return a + b", "successors": []}, {"id": 6, "label": "            elif operation == 'subtract':\n                return a - b", "successors": []}, {"id": 8, "label": "            elif operation == 'multiply':\n                return a * b", "successors": []}, {"id": 10, "label": "            elif operation == 'divide':\n                return a / b", "successors": []}]}, {"id": 12, "label": "        except ZeroDivisionError:\n            return float('inf')  # Return infinity for division by zero", "successors": []}, {"id": 14, "label": "        except Exception:\n            return float('nan')  # Return NaN for other errors", "successors": []}]}]}, {"name": "CountItemsBlock", "type": "class", "start_line": 87, "end_line": 124, "functions": [{"name": "__init__", "type": "function", "start_line": 97, "end_line": 108, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"3c9c2f42-b0c3-435f-ba35-05f7a25c772a\",\n            input_schema=CountItemsBlock.Input,\n            output_schema=CountItemsBlock.Output,\n            description=\"Counts the number of items in a collection.\",\n            categories={BlockCategory.LOGIC},\n            test_input={\"collection\": [1, 2, 3, 4, 5]},\n            test_output=[\n                (\"count\", 5),\n            ],\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"3c9c2f42-b0c3-435f-ba35-05f7a25c772a\",\n    input_schema=CountItemsBlock.Input,\n    output_schema=CountItemsBlock.Output,\n    description=\"Counts the number of items in a collection.\",\n    categories={BlockCategory.LOGIC},\n    test_input={\"collection\": [1, 2, 3, 4, 5]},\n    test_output=[\n        (\"count\", 5),\n    ],\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 110, "end_line": 124, "functions": [], "classes": [], "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        collection = input_data.collection\n\n        try:\n            if isinstance(collection, (str, list, tuple, set, dict)):\n                count = len(collection)\n            elif hasattr(collection, \"__iter__\"):\n                count = sum(1 for _ in collection)\n            else:\n                raise ValueError(\"Input is not a countable collection\")\n\n            yield \"count\", count\n\n        except Exception:\n            yield \"count\", -1  # Return -1 to indicate an error", "blocks": [{"id": 1, "label": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\ncollection = input_data.collection", "successors": [{"id": 3, "label": "try:", "successors": [{"id": 4, "label": "if isinstance(collection, (str, list, tuple, set, dict)):", "successors": [{"id": 5, "label": "count = len(collection)\nyield \"count\", count", "successors": []}, {"id": 6, "label": "elif hasattr(collection, \"__iter__\"):\ncount = sum(1 for _ in collection)", "successors": [{"id": 8, "label": "yield \"count\", count", "successors": []}]}, {"id": 9, "label": "else:\nraise ValueError(\"Input is not a countable collection\")", "successors": []}]}, {"id": 11, "label": "except Exception:\nyield \"count\", -1", "successors": []}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 88, "end_line": 92, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        collection: Any = SchemaField(\n            description=\"Enter the collection you want to count. This can be a list, dictionary, string, or any other iterable.\",\n            placeholder=\"For example: [1, 2, 3] or {'a': 1, 'b': 2} or 'hello'\",\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\ncollection: Any = SchemaField(description=\"Enter the collection you want to count. This can be a list, dictionary, string, or any other iterable.\", placeholder=\"For example: [1, 2, 3] or {'a': 1, 'b': 2} or 'hello'\")", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 94, "end_line": 95, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        count: int = SchemaField(description=\"The number of items in the collection\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    count: int = SchemaField(description=\"The number of items in the collection\")", "successors": []}]}], "simplified_code": "class CountItemsBlock(Block):\n        )\n\n        count: int = SchemaField(description=\"The number of items in the collection\")\n\n        )\n\n            yield \"count\", -1  # Return -1 to indicate an error", "blocks": [{"id": 1, "label": "class CountItemsBlock(Block):\ncount: int = SchemaField(description=\"The number of items in the collection\")", "successors": [{"id": 3, "label": "yield \"count\", -1  # Return -1 to indicate an error", "successors": []}]}]}], "simplified_code": "import operator\nfrom enum import Enum\nfrom typing import Any\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\n\n    POWER = \"Power\"\n\n\n            yield \"result\", float(\"nan\")  # Return NaN for other errors\n\n\n            yield \"count\", -1  # Return -1 to indicate an error", "blocks": [{"id": 1, "label": "import operator\nfrom enum import Enum\nfrom typing import Any\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\nPOWER = \"Power\"", "successors": [{"id": 3, "label": "yield \"result\", float(\"nan\")  # Return NaN for other errors\nyield \"count\", -1  # Return -1 to indicate an error", "successors": []}]}]}
{"file_name": "193.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 68, "functions": [{"name": "test_verify_user_no_payload", "type": "function", "start_line": 6, "end_line": 9, "functions": [], "classes": [], "simplified_code": "def test_verify_user_no_payload():\n    user = verify_user(None, admin_only=False)\n    assert user.user_id == \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\"\n    assert user.role == \"admin\"", "blocks": [{"id": 1, "label": "user = verify_user(None, admin_only=False)\nassert user.user_id == \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\"", "successors": [{"id": 3, "label": "assert user.role == \"admin\"", "successors": []}]}]}, {"name": "test_verify_user_no_user_id", "type": "function", "start_line": 12, "end_line": 14, "functions": [], "classes": [], "simplified_code": "def test_verify_user_no_user_id():\n    with pytest.raises(Exception):\n        verify_user({\"role\": \"admin\"}, admin_only=False)", "blocks": [{"id": 1, "label": "def test_verify_user_no_user_id():\nwith pytest.raises(Exception):", "successors": [{"id": 3, "label": "verify_user({\"role\": \"admin\"}, admin_only=False)", "successors": []}]}]}, {"name": "test_verify_user_not_admin", "type": "function", "start_line": 17, "end_line": 22, "functions": [], "classes": [], "simplified_code": "def test_verify_user_not_admin():\n    with pytest.raises(Exception):\n        verify_user(\n            {\"sub\": \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\", \"role\": \"user\"},\n            admin_only=True,\n        )", "blocks": [{"id": 1, "label": "def test_verify_user_not_admin():\nwith pytest.raises(Exception):", "successors": [{"id": 3, "label": "verify_user(\n    {\"sub\": \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\", \"role\": \"user\"},\n    admin_only=True,\n)", "successors": []}]}]}, {"name": "test_verify_user_with_admin_role", "type": "function", "start_line": 25, "end_line": 31, "functions": [], "classes": [], "simplified_code": "def test_verify_user_with_admin_role():\n    user = verify_user(\n        {\"sub\": \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\", \"role\": \"admin\"},\n        admin_only=True,\n    )\n    assert user.user_id == \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\"\n    assert user.role == \"admin\"", "blocks": [{"id": 1, "label": "def test_verify_user_with_admin_role():\nuser = verify_user(\n    {\"sub\": \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\", \"role\": \"admin\"},\n    admin_only=True,\n)", "successors": [{"id": 3, "label": "assert user.user_id == \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\"\nassert user.role == \"admin\"", "successors": []}]}]}, {"name": "test_verify_user_with_user_role", "type": "function", "start_line": 34, "end_line": 40, "functions": [], "classes": [], "simplified_code": "def test_verify_user_with_user_role():\n    user = verify_user(\n        {\"sub\": \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\", \"role\": \"user\"},\n        admin_only=False,\n    )\n    assert user.user_id == \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\"\n    assert user.role == \"user\"", "blocks": [{"id": 1, "label": "user = verify_user(\n    {\"sub\": \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\", \"role\": \"user\"},\n    admin_only=False,\n)\nassert user.user_id == \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\"", "successors": [{"id": 3, "label": "assert user.role == \"user\"", "successors": []}]}]}, {"name": "test_requires_user", "type": "function", "start_line": 43, "end_line": 48, "functions": [], "classes": [], "simplified_code": "def test_requires_user():\n    user = requires_user(\n        {\"sub\": \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\", \"role\": \"user\"}\n    )\n    assert user.user_id == \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\"\n    assert user.role == \"user\"", "blocks": [{"id": 1, "label": "def test_requires_user():\nuser = requires_user(\n    {\"sub\": \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\", \"role\": \"user\"}\n)", "successors": [{"id": 3, "label": "assert user.user_id == \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\"\nassert user.role == \"user\"", "successors": []}]}]}, {"name": "test_requires_user_no_user_id", "type": "function", "start_line": 51, "end_line": 53, "functions": [], "classes": [], "simplified_code": "def test_requires_user_no_user_id():\n    with pytest.raises(Exception):\n        requires_user({\"role\": \"user\"})", "blocks": [{"id": 1, "label": "def test_requires_user_no_user_id():\nwith pytest.raises(Exception):", "successors": [{"id": 3, "label": "    requires_user({\"role\": \"user\"})", "successors": []}]}]}, {"name": "test_requires_admin_user", "type": "function", "start_line": 56, "end_line": 61, "functions": [], "classes": [], "simplified_code": "def test_requires_admin_user():\n    user = requires_admin_user(\n        {\"sub\": \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\", \"role\": \"admin\"}\n    )\n    assert user.user_id == \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\"\n    assert user.role == \"admin\"", "blocks": [{"id": 1, "label": "def test_requires_admin_user():\n    user = requires_admin_user(\n        {\"sub\": \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\", \"role\": \"admin\"}\n    )", "successors": [{"id": 3, "label": "    assert user.user_id == \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\"\n    assert user.role == \"admin\"", "successors": []}]}]}, {"name": "test_requires_admin_user_not_admin", "type": "function", "start_line": 64, "end_line": 68, "functions": [], "classes": [], "simplified_code": "def test_requires_admin_user_not_admin():\n    with pytest.raises(Exception):\n        requires_admin_user(\n            {\"sub\": \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\", \"role\": \"user\"}\n        )", "blocks": [{"id": 1, "label": "def test_requires_admin_user_not_admin():\nwith pytest.raises(Exception):", "successors": [{"id": 3, "label": "requires_admin_user(\n    {\"sub\": \"3e53486c-cf57-477e-ba2a-cb02dc828e1a\", \"role\": \"user\"}\n)", "successors": []}]}]}], "classes": [], "simplified_code": "import pytest\n\nfrom .depends import requires_admin_user, requires_user, verify_user\n\n\n    assert user.role == \"admin\"\n\n\n        verify_user({\"role\": \"admin\"}, admin_only=False)\n\n\n        )\n\n\n    assert user.role == \"admin\"\n\n\n    assert user.role == \"user\"\n\n\n    assert user.role == \"user\"\n\n\n        requires_user({\"role\": \"user\"})\n\n\n    assert user.role == \"admin\"\n\n\n        )", "blocks": [{"id": 1, "label": "import pytest\n\nfrom .depends import requires_admin_user, requires_user, verify_user\nassert user.role == \"admin\"", "successors": [{"id": 3, "label": "verify_user({\"role\": \"admin\"}, admin_only=False)\nassert user.role == \"admin\"", "successors": [{"id": 5, "label": "assert user.role == \"user\"\nrequires_user({\"role\": \"user\"})", "successors": [{"id": 7, "label": "assert user.role == \"admin\"", "successors": []}]}]}]}]}
{"file_name": "194.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 88, "functions": [{"name": "generate_all_permutations", "type": "function", "start_line": 12, "end_line": 14, "functions": [], "classes": [], "simplified_code": "def generate_all_permutations(sequence: list[int | str]) -> None:\n    create_state_space_tree(sequence, [], 0, [0 for i in range(len(sequence))])\n", "blocks": [{"id": 1, "label": "create_state_space_tree(sequence, [], 0, [0 for i in range(len(sequence))])", "successors": []}]}, {"name": "create_state_space_tree", "type": "function", "start_line": 16, "end_line": 74, "functions": [], "classes": [], "simplified_code": "def create_state_space_tree(\n    sequence: list[int | str],\n    current_sequence: list[int | str],\n    index: int,\n    index_used: list[int],\n) -> None:\n    \"\"\"\n    Creates a state space tree to iterate through each branch using DFS.\n    We know that each state has exactly len(sequence) - index children.\n    It terminates when it reaches the end of the given sequence.\n\n    :param sequence: The input sequence for which permutations are generated.\n    :param current_sequence: The current permutation being built.\n    :param index: The current index in the sequence.\n    :param index_used: list to track which elements are used in permutation.\n\n    Example 1:\n    >>> sequence = [1, 2, 3]\n    >>> current_sequence = []\n    >>> index_used = [False, False, False]\n    >>> create_state_space_tree(sequence, current_sequence, 0, index_used)\n    [1, 2, 3]\n    [1, 3, 2]\n    [2, 1, 3]\n    [2, 3, 1]\n    [3, 1, 2]\n    [3, 2, 1]\n\n    Example 2:\n    >>> sequence = [\"A\", \"B\", \"C\"]\n    >>> current_sequence = []\n    >>> index_used = [False, False, False]\n    >>> create_state_space_tree(sequence, current_sequence, 0, index_used)\n    ['A', 'B', 'C']\n    ['A', 'C', 'B']\n    ['B', 'A', 'C']\n    ['B', 'C', 'A']\n    ['C', 'A', 'B']\n    ['C', 'B', 'A']\n\n    Example 3:\n    >>> sequence = [1]\n    >>> current_sequence = []\n    >>> index_used = [False]\n    >>> create_state_space_tree(sequence, current_sequence, 0, index_used)\n    [1]\n    \"\"\"\n\n    if index == len(sequence):\n        print(current_sequence)\n        return\n\n    for i in range(len(sequence)):\n        if not index_used[i]:\n            current_sequence.append(sequence[i])\n            index_used[i] = True\n            create_state_space_tree(sequence, current_sequence, index + 1, index_used)\n            current_sequence.pop()\n            index_used[i] = False", "blocks": [{"id": 1, "label": "def create_state_space_tree(\n    sequence: list[int | str],\n    current_sequence: list[int | str],\n    index: int,\n    index_used: list[int],\n) -> None:", "successors": [{"id": 2, "label": "if index == len(sequence):\n    print(current_sequence)\n    return", "successors": []}, {"id": 4, "label": "for i in range(len(sequence)):", "successors": [{"id": 5, "label": "    if not index_used[i]:\n        current_sequence.append(sequence[i])\n        index_used[i] = True\n        create_state_space_tree(sequence, current_sequence, index + 1, index_used)\n        current_sequence.pop()\n        index_used[i] = False", "successors": []}]}]}]}], "classes": [], "simplified_code": "\"\"\"\nIn this problem, we want to determine all possible permutations\nof the given sequence. We use backtracking to solve this problem.\n\nTime complexity: O(n! * n),\nwhere n denotes the length of the given sequence.\n\"\"\"\n\nfrom __future__ import annotations\n\n\n\n\n            index_used[i] = False\n\n\n\"\"\"\nremove the comment to take an input from the user\n\nprint(\"Enter the elements\")\nsequence = list(map(int, input().split()))\n\"\"\"\n\nsequence: list[int | str] = [3, 1, 2, 4]\ngenerate_all_permutations(sequence)\n\nsequence_2: list[int | str] = [\"A\", \"B\", \"C\"]\ngenerate_all_permutations(sequence_2)", "blocks": [{"id": 1, "label": "from __future__ import annotations\nsequence: list[int | str] = [3, 1, 2, 4]\ngenerate_all_permutations(sequence)", "successors": [{"id": 3, "label": "sequence_2: list[int | str] = [\"A\", \"B\", \"C\"]\ngenerate_all_permutations(sequence_2)", "successors": []}]}]}
{"file_name": "195.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 228, "functions": [{"name": "PineconeCredentialsField", "type": "function", "start_line": 22, "end_line": 26, "functions": [], "classes": [], "simplified_code": "def PineconeCredentialsField() -> PineconeCredentialsInput:\n    \"\"\"Creates a Pinecone credentials input on a block.\"\"\"\n    return CredentialsField(\n        description=\"The Pinecone integration can be used with an API Key.\",\n    )", "blocks": [{"id": 1, "label": "def PineconeCredentialsField() -> PineconeCredentialsInput:\n    \"\"\"Creates a Pinecone credentials input on a block.\"\"\"", "successors": [{"id": 3, "label": "    return CredentialsField(\n        description=\"The Pinecone integration can be used with an API Key.\"\n    )", "successors": []}]}]}], "classes": [{"name": "PineconeInitBlock", "type": "class", "start_line": 29, "end_line": 82, "functions": [{"name": "__init__", "type": "function", "start_line": 50, "end_line": 57, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"48d8fdab-8f03-41f3-8407-8107ba11ec9b\",\n            description=\"Initializes a Pinecone index\",\n            categories={BlockCategory.LOGIC},\n            input_schema=PineconeInitBlock.Input,\n            output_schema=PineconeInitBlock.Output,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\n    super().__init__(\n        id=\"48d8fdab-8f03-41f3-8407-8107ba11ec9b\",\n        description=\"Initializes a Pinecone index\",\n        categories={BlockCategory.LOGIC},\n        input_schema=PineconeInitBlock.Input,\n        output_schema=PineconeInitBlock.Output,\n    )", "successors": []}]}, {"name": "run", "type": "function", "start_line": 59, "end_line": 82, "functions": [], "classes": [], "simplified_code": "    def run(\n        self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs\n    ) -> BlockOutput:\n        pc = Pinecone(api_key=credentials.api_key.get_secret_value())\n\n        try:\n            existing_indexes = pc.list_indexes()\n            if input_data.index_name not in [index.name for index in existing_indexes]:\n                pc.create_index(\n                    name=input_data.index_name,\n                    dimension=input_data.dimension,\n                    metric=input_data.metric,\n                    spec=ServerlessSpec(\n                        cloud=input_data.cloud, region=input_data.region\n                    ),\n                )\n                message = f\"Created new index: {input_data.index_name}\"\n            else:\n                message = f\"Using existing index: {input_data.index_name}\"\n\n            yield \"index\", input_data.index_name\n            yield \"message\", message\n        except Exception as e:\n            yield \"message\", f\"Error initializing Pinecone index: {str(e)}\"", "blocks": [{"id": 1, "label": "pc = Pinecone(api_key=credentials.api_key.get_secret_value())\ntry:", "successors": [{"id": 3, "label": "existing_indexes = pc.list_indexes()\nif input_data.index_name not in [index.name for index in existing_indexes]:", "successors": [{"id": 5, "label": "pc.create_index(name=input_data.index_name, dimension=input_data.dimension, metric=input_data.metric, spec=ServerlessSpec(cloud=input_data.cloud, region=input_data.region))\nmessage = f\"Created new index: {input_data.index_name}\"", "successors": [{"id": 8, "label": "yield \"index\", input_data.index_name\nyield \"message\", message", "successors": []}]}, {"id": 7, "label": "message = f\"Using existing index: {input_data.index_name}\"\nyield \"index\", input_data.index_name\nyield \"message\", message", "successors": []}]}, {"id": 9, "label": "except Exception as e:\nyield \"message\", f\"Error initializing Pinecone index: {str(e)}\"", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 30, "end_line": 44, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: PineconeCredentialsInput = PineconeCredentialsField()\n        index_name: str = SchemaField(description=\"Name of the Pinecone index\")\n        dimension: int = SchemaField(\n            description=\"Dimension of the vectors\", default=768\n        )\n        metric: str = SchemaField(\n            description=\"Distance metric for the index\", default=\"cosine\"\n        )\n        cloud: str = SchemaField(\n            description=\"Cloud provider for serverless\", default=\"aws\"\n        )\n        region: str = SchemaField(\n            description=\"Region for serverless\", default=\"us-east-1\"\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\n    credentials: PineconeCredentialsInput = PineconeCredentialsField()\n    index_name: str = SchemaField(description=\"Name of the Pinecone index\")\n    dimension: int = SchemaField(\n        description=\"Dimension of the vectors\", default=768\n    )\n    metric: str = SchemaField(\n        description=\"Distance metric for the index\", default=\"cosine\"\n    )\n    cloud: str = SchemaField(\n        description=\"Cloud provider for serverless\", default=\"aws\"\n    )\n    region: str = SchemaField(\n        description=\"Region for serverless\", default=\"us-east-1\"\n    )", "successors": []}]}, {"name": "Output", "type": "class", "start_line": 46, "end_line": 48, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        index: str = SchemaField(description=\"Name of the initialized Pinecone index\")\n        message: str = SchemaField(description=\"Status message\")", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    index: str = SchemaField(description=\"Name of the initialized Pinecone index\")", "successors": [{"id": 3, "label": "    message: str = SchemaField(description=\"Status message\")", "successors": []}]}]}], "simplified_code": "class PineconeInitBlock(Block):\n        )\n\n        message: str = SchemaField(description=\"Status message\")\n\n        )\n\n            yield \"message\", f\"Error initializing Pinecone index: {str(e)}\"", "blocks": [{"id": 1, "label": "class PineconeInitBlock(Block):\nmessage: str = SchemaField(description=\"Status message\")", "successors": []}]}, {"name": "PineconeQueryBlock", "type": "class", "start_line": 85, "end_line": 165, "functions": [{"name": "__init__", "type": "function", "start_line": 111, "end_line": 118, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"9ad93d0f-91b4-4c9c-8eb1-82e26b4a01c5\",\n            description=\"Queries a Pinecone index\",\n            categories={BlockCategory.LOGIC},\n            input_schema=PineconeQueryBlock.Input,\n            output_schema=PineconeQueryBlock.Output,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\n    super().__init__(\n        id=\"9ad93d0f-91b4-4c9c-8eb1-82e26b4a01c5\",\n        description=\"Queries a Pinecone index\",\n        categories={BlockCategory.LOGIC},\n        input_schema=PineconeQueryBlock.Input,\n        output_schema=PineconeQueryBlock.Output,\n    )", "successors": []}]}, {"name": "run", "type": "function", "start_line": 120, "end_line": 165, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: APIKeyCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        try:\n            # Create a new client instance\n            pc = Pinecone(api_key=credentials.api_key.get_secret_value())\n\n            # Get the index\n            idx = pc.Index(input_data.idx_name)\n\n            # Ensure query_vector is in correct format\n            query_vector = input_data.query_vector\n            if isinstance(query_vector, list) and len(query_vector) > 0:\n                if isinstance(query_vector[0], list):\n                    query_vector = query_vector[0]\n\n            results = idx.query(\n                namespace=input_data.namespace,\n                vector=query_vector,\n                top_k=input_data.top_k,\n                include_values=input_data.include_values,\n                include_metadata=input_data.include_metadata,\n            ).to_dict()  # type: ignore\n            combined_text = \"\"\n            if results[\"matches\"]:\n                texts = [\n                    match[\"metadata\"][\"text\"]\n                    for match in results[\"matches\"]\n                    if match.get(\"metadata\", {}).get(\"text\")\n                ]\n                combined_text = \"\\n\\n\".join(texts)\n\n            # Return both the raw matches and combined text\n            yield \"results\", {\n                \"matches\": results[\"matches\"],\n                \"combined_text\": combined_text,\n            }\n            yield \"combined_results\", combined_text\n\n        except Exception as e:\n            error_msg = f\"Error querying Pinecone: {str(e)}\"\n            raise RuntimeError(error_msg) from e", "blocks": [{"id": 1, "label": "try:\n    pc = Pinecone(api_key=credentials.api_key.get_secret_value())", "successors": [{"id": 3, "label": "    idx = pc.Index(input_data.idx_name)\n    query_vector = input_data.query_vector", "successors": [{"id": 5, "label": "    if isinstance(query_vector, list) and len(query_vector) > 0:\n        if isinstance(query_vector[0], list):", "successors": [{"id": 7, "label": "            query_vector = query_vector[0]", "successors": []}]}, {"id": 8, "label": "    results = idx.query(namespace=input_data.namespace, vector=query_vector, top_k=input_data.top_k, include_values=input_data.include_values, include_metadata=input_data.include_metadata, ).to_dict()\n    combined_text = \"\"", "successors": [{"id": 10, "label": "    if results[\"matches\"]:\n        texts = [ match[\"metadata\"][\"text\"] for match in results[\"matches\"] if match.get(\"metadata\", {}).get(\"text\") ]", "successors": [{"id": 12, "label": "        combined_text = \"\\n\\n\".join(texts)", "successors": []}]}, {"id": 13, "label": "    yield \"results\", { \"matches\": results[\"matches\"], \"combined_text\": combined_text, }\n    yield \"combined_results\", combined_text", "successors": []}]}]}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 86, "end_line": 103, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: PineconeCredentialsInput = PineconeCredentialsField()\n        query_vector: list = SchemaField(description=\"Query vector\")\n        namespace: str = SchemaField(\n            description=\"Namespace to query in Pinecone\", default=\"\"\n        )\n        top_k: int = SchemaField(\n            description=\"Number of top results to return\", default=3\n        )\n        include_values: bool = SchemaField(\n            description=\"Whether to include vector values in the response\",\n            default=False,\n        )\n        include_metadata: bool = SchemaField(\n            description=\"Whether to include metadata in the response\", default=True\n        )\n        host: str = SchemaField(description=\"Host for pinecone\", default=\"\")\n        idx_name: str = SchemaField(description=\"Index name for pinecone\")", "blocks": [{"id": 1, "label": "class Input(BlockSchema):", "successors": [{"id": 2, "label": "    credentials: PineconeCredentialsInput = PineconeCredentialsField()", "successors": []}, {"id": 3, "label": "    query_vector: list = SchemaField(description=\"Query vector\")", "successors": []}, {"id": 4, "label": "    namespace: str = SchemaField(description=\"Namespace to query in Pinecone\", default=\"\")", "successors": []}, {"id": 5, "label": "    top_k: int = SchemaField(description=\"Number of top results to return\", default=3)", "successors": []}, {"id": 6, "label": "    include_values: bool = SchemaField(description=\"Whether to include vector values in the response\", default=False)", "successors": []}, {"id": 7, "label": "    include_metadata: bool = SchemaField(description=\"Whether to include metadata in the response\", default=True)", "successors": []}, {"id": 8, "label": "    host: str = SchemaField(description=\"Host for pinecone\", default=\"\")", "successors": []}, {"id": 9, "label": "    idx_name: str = SchemaField(description=\"Index name for pinecone\")", "successors": []}]}]}, {"name": "Output", "type": "class", "start_line": 105, "end_line": 109, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        results: Any = SchemaField(description=\"Query results from Pinecone\")\n        combined_results: Any = SchemaField(\n            description=\"Combined results from Pinecone\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):", "successors": [{"id": 2, "label": "    results: Any = SchemaField(description=\"Query results from Pinecone\")", "successors": []}, {"id": 3, "label": "    combined_results: Any = SchemaField(\n        description=\"Combined results from Pinecone\"\n    )", "successors": []}]}]}], "simplified_code": "class PineconeQueryBlock(Block):\n        idx_name: str = SchemaField(description=\"Index name for pinecone\")\n\n        )\n\n        )\n\n            raise RuntimeError(error_msg) from e", "blocks": [{"id": 1, "label": "class PineconeQueryBlock(Block):", "successors": [{"id": 2, "label": "idx_name: str = SchemaField(description=\"Index name for pinecone\")", "successors": []}, {"id": 3, "label": "def query(self, params):", "successors": [{"id": 4, "label": "query_str = self.build_query(params)", "successors": []}, {"id": 5, "label": "try:\nwith self.client.conn() as conn:", "successors": [{"id": 7, "label": "results = conn.query(query_str, self.idx_name)\nreturn results", "successors": []}]}, {"id": 9, "label": "except Exception as e:", "successors": [{"id": 10, "label": "error_msg = f\"Query failed: {str(e)}\"", "successors": []}, {"id": 11, "label": "raise RuntimeError(error_msg) from e", "successors": []}]}]}]}]}, {"name": "PineconeInsertBlock", "type": "class", "start_line": 168, "end_line": 228, "functions": [{"name": "__init__", "type": "function", "start_line": 188, "end_line": 195, "functions": [], "classes": [], "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"477f2168-cd91-475a-8146-9499a5982434\",\n            description=\"Upload data to a Pinecone index\",\n            categories={BlockCategory.LOGIC},\n            input_schema=PineconeInsertBlock.Input,\n            output_schema=PineconeInsertBlock.Output,\n        )", "blocks": [{"id": 1, "label": "def __init__(self):\nsuper().__init__(\n    id=\"477f2168-cd91-475a-8146-9499a5982434\",\n    description=\"Upload data to a Pinecone index\",\n    categories={BlockCategory.LOGIC},\n    input_schema=PineconeInsertBlock.Input,\n    output_schema=PineconeInsertBlock.Output,\n)", "successors": []}]}, {"name": "run", "type": "function", "start_line": 197, "end_line": 228, "functions": [], "classes": [], "simplified_code": "    def run(\n        self,\n        input_data: Input,\n        *,\n        credentials: APIKeyCredentials,\n        **kwargs,\n    ) -> BlockOutput:\n        try:\n            # Create a new client instance\n            pc = Pinecone(api_key=credentials.api_key.get_secret_value())\n\n            # Get the index\n            idx = pc.Index(input_data.index)\n\n            vectors = []\n            for chunk, embedding in zip(input_data.chunks, input_data.embeddings):\n                vector_metadata = input_data.metadata.copy()\n                vector_metadata[\"text\"] = chunk\n                vectors.append(\n                    {\n                        \"id\": str(uuid.uuid4()),\n                        \"values\": embedding,\n                        \"metadata\": vector_metadata,\n                    }\n                )\n            idx.upsert(vectors=vectors, namespace=input_data.namespace)\n\n            yield \"upsert_response\", \"successfully upserted\"\n\n        except Exception as e:\n            error_msg = f\"Error uploading to Pinecone: {str(e)}\"\n            raise RuntimeError(error_msg) from e", "blocks": [{"id": 1, "label": "def run(\n    self,\n    input_data: Input,\n    *,\n    credentials: APIKeyCredentials,\n    **kwargs,\n) -> BlockOutput:", "successors": [{"id": 2, "label": "try:\n    pc = Pinecone(api_key=credentials.api_key.get_secret_value())\n\n    # Get the index\n    idx = pc.Index(input_data.index)\n\n    vectors = []", "successors": [{"id": 4, "label": "for chunk, embedding in zip(input_data.chunks, input_data.embeddings):", "successors": [{"id": 5, "label": "    vector_metadata = input_data.metadata.copy()\n    vector_metadata[\"text\"] = chunk\n    vectors.append(\n        {\n            \"id\": str(uuid.uuid4()),\n            \"values\": embedding,\n            \"metadata\": vector_metadata,\n        }\n    )\nidx.upsert(vectors=vectors, namespace=input_data.namespace)\n\nyield \"upsert_response\", \"successfully upserted\"", "successors": []}]}]}, {"id": 7, "label": "except Exception as e:\nerror_msg = f\"Error uploading to Pinecone: {str(e)}\"\nraise RuntimeError(error_msg) from e", "successors": []}]}]}], "classes": [{"name": "Input", "type": "class", "start_line": 169, "end_line": 181, "functions": [], "classes": [], "simplified_code": "    class Input(BlockSchema):\n        credentials: PineconeCredentialsInput = PineconeCredentialsField()\n        index: str = SchemaField(description=\"Initialized Pinecone index\")\n        chunks: list = SchemaField(description=\"List of text chunks to ingest\")\n        embeddings: list = SchemaField(\n            description=\"List of embeddings corresponding to the chunks\"\n        )\n        namespace: str = SchemaField(\n            description=\"Namespace to use in Pinecone\", default=\"\"\n        )\n        metadata: dict = SchemaField(\n            description=\"Additional metadata to store with each vector\", default={}\n        )", "blocks": [{"id": 1, "label": "class Input(BlockSchema):\ncredentials: PineconeCredentialsInput = PineconeCredentialsField()", "successors": [{"id": 3, "label": "index: str = SchemaField(description=\"Initialized Pinecone index\")\nchunks: list = SchemaField(description=\"List of text chunks to ingest\")", "successors": [{"id": 5, "label": "embeddings: list = SchemaField(\n    description=\"List of embeddings corresponding to the chunks\"\n)\nnamespace: str = SchemaField(\n    description=\"Namespace to use in Pinecone\", default=\"\"\n)", "successors": [{"id": 7, "label": "metadata: dict = SchemaField(\n    description=\"Additional metadata to store with each vector\", default={}\n)", "successors": []}]}]}]}]}, {"name": "Output", "type": "class", "start_line": 183, "end_line": 186, "functions": [], "classes": [], "simplified_code": "    class Output(BlockSchema):\n        upsert_response: str = SchemaField(\n            description=\"Response from Pinecone upsert operation\"\n        )", "blocks": [{"id": 1, "label": "class Output(BlockSchema):\n    upsert_response: str = SchemaField(description=\"Response from Pinecone upsert operation\")", "successors": []}]}], "simplified_code": "class PineconeInsertBlock(Block):\n        )\n\n        )\n\n        )\n\n            raise RuntimeError(error_msg) from e", "blocks": [{"id": 1, "label": "class PineconeInsertBlock(Block):", "successors": [{"id": 2, "label": "def __init__(self, index):\nself.index = index", "successors": []}, {"id": 4, "label": "def insert(self, data):\ntry:", "successors": [{"id": 6, "label": "self.index.upsert(data)\nexcept Exception as e:", "successors": [{"id": 10, "label": "error_msg = f\"Failed to insert data: {str(e)}\"\nraise RuntimeError(error_msg) from e", "successors": []}]}]}]}]}], "simplified_code": "import uuid\nfrom typing import Any, Literal\n\nfrom pinecone import Pinecone, ServerlessSpec\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\n\nPineconeCredentials = APIKeyCredentials\nPineconeCredentialsInput = CredentialsMetaInput[\n    Literal[ProviderName.PINECONE],\n    Literal[\"api_key\"],\n]\n\n\n    )\n\n\n            yield \"message\", f\"Error initializing Pinecone index: {str(e)}\"\n\n\n            raise RuntimeError(error_msg) from e\n\n\n            raise RuntimeError(error_msg) from e", "blocks": [{"id": 1, "label": "import uuid\nfrom typing import Any, Literal\n\nfrom pinecone import Pinecone, ServerlessSpec\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import (\n    APIKeyCredentials,\n    CredentialsField,\n    CredentialsMetaInput,\n    SchemaField,\n)\nfrom backend.integrations.providers import ProviderName\n\nPineconeCredentials = APIKeyCredentials\nPineconeCredentialsInput = CredentialsMetaInput[\n    Literal[ProviderName.PINECONE],\n    Literal[\"api_key\"],\n]", "successors": []}]}
{"file_name": "196.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 48, "functions": [{"name": "server", "type": "function", "start_line": 20, "end_line": 22, "functions": [], "classes": [], "simplified_code": "async def server():\n    async with SpinTestServer() as server:\n        yield server", "blocks": [{"id": 1, "label": "async def server():\nasync with SpinTestServer() as server:", "successors": [{"id": 3, "label": "    yield server", "successors": []}]}]}, {"name": "graph_cleanup", "type": "function", "start_line": 26, "end_line": 48, "functions": [{"name": "create_graph_wrapper", "type": "function", "start_line": 30, "end_line": 35, "functions": [], "classes": [], "simplified_code": "    async def create_graph_wrapper(*args, **kwargs):\n        created_graph = await original_create_graph(*args, **kwargs)\n        # Extract user_id correctly\n        user_id = kwargs.get(\"user_id\", args[2] if len(args) > 2 else None)\n        created_graph_ids.append((created_graph.id, user_id))\n        return created_graph", "blocks": [{"id": 1, "label": "async def create_graph_wrapper(*args, **kwargs):\ncreated_graph = await original_create_graph(*args, **kwargs)", "successors": [{"id": 3, "label": "user_id = kwargs.get(\"user_id\", args[2] if len(args) > 2 else None)\ncreated_graph_ids.append((created_graph.id, user_id))", "successors": [{"id": 5, "label": "return created_graph", "successors": []}]}]}]}], "classes": [], "simplified_code": "async def graph_cleanup(server):\n    created_graph_ids = []\n    original_create_graph = server.agent_server.test_create_graph\n\n        return created_graph\n\n    try:\n        server.agent_server.test_create_graph = create_graph_wrapper\n        yield  # This runs the test function\n    finally:\n        server.agent_server.test_create_graph = original_create_graph\n\n        # Delete the created graphs and assert they were deleted\n        for graph_id, user_id in created_graph_ids:\n            if user_id:\n                resp = await server.agent_server.test_delete_graph(graph_id, user_id)\n                num_deleted = resp[\"version_counts\"]\n                assert num_deleted > 0, f\"Graph {graph_id} was not deleted.\"", "blocks": [{"id": 1, "label": "async def graph_cleanup(server):\ncreated_graph_ids = []", "successors": [{"id": 3, "label": "original_create_graph = server.agent_server.test_create_graph\n    return created_graph", "successors": [{"id": 5, "label": "try:\nserver.agent_server.test_create_graph = create_graph_wrapper", "successors": [{"id": 7, "label": "yield  # This runs the test function\nfinally:", "successors": [{"id": 9, "label": "server.agent_server.test_create_graph = original_create_graph", "successors": [{"id": 10, "label": "for graph_id, user_id in created_graph_ids:", "successors": [{"id": 11, "label": "if user_id:\nresp = await server.agent_server.test_delete_graph(graph_id, user_id)", "successors": [{"id": 13, "label": "num_deleted = resp[\"version_counts\"]\nassert num_deleted > 0, f\"Graph {graph_id} was not deleted.\"", "successors": []}]}]}]}]}]}]}]}]}], "classes": [], "simplified_code": "import logging\n\nimport pytest\n\nfrom backend.util.test import SpinTestServer\n\n#  NOTE: You can run tests like with the --log-cli-level=INFO to see the logs\n# Set up logging\nlogger = logging.getLogger(__name__)\n\n# Create console handler with formatting\nch = logging.StreamHandler()\nch.setLevel(logging.INFO)\nformatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\nch.setFormatter(formatter)\nlogger.addHandler(ch)\n\n\n@pytest.fixture(scope=\"session\")\n        yield server\n\n\n@pytest.fixture(scope=\"session\", autouse=True)\n                assert num_deleted > 0, f\"Graph {graph_id} was not deleted.\"", "blocks": [{"id": 1, "label": "import logging\n\nimport pytest\n\nfrom backend.util.test import SpinTestServer\n\n#  NOTE: You can run tests like with the --log-cli-level=INFO to see the logs\n# Set up logging\nlogger = logging.getLogger(__name__)\n\n# Create console handler with formatting\nch = logging.StreamHandler()\nch.setLevel(logging.INFO)\nformatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\nch.setFormatter(formatter)\nlogger.addHandler(ch)", "successors": []}]}
{"file_name": "197.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 48, "functions": [{"name": "binary_or", "type": "function", "start_line": 4, "end_line": 42, "functions": [], "classes": [], "simplified_code": "def binary_or(a: int, b: int) -> str:\n    \"\"\"\n    Take in 2 integers, convert them to binary, and return a binary number that is the\n    result of a binary or operation on the integers provided.\n\n    >>> binary_or(25, 32)\n    '0b111001'\n    >>> binary_or(37, 50)\n    '0b110111'\n    >>> binary_or(21, 30)\n    '0b11111'\n    >>> binary_or(58, 73)\n    '0b1111011'\n    >>> binary_or(0, 255)\n    '0b11111111'\n    >>> binary_or(0, 256)\n    '0b100000000'\n    >>> binary_or(0, -1)\n    Traceback (most recent call last):\n        ...\n    ValueError: the value of both inputs must be positive\n    >>> binary_or(0, 1.1)\n    Traceback (most recent call last):\n        ...\n    TypeError: 'float' object cannot be interpreted as an integer\n    >>> binary_or(\"0\", \"1\")\n    Traceback (most recent call last):\n        ...\n    TypeError: '<' not supported between instances of 'str' and 'int'\n    \"\"\"\n    if a < 0 or b < 0:\n        raise ValueError(\"the value of both inputs must be positive\")\n    a_binary = str(bin(a))[2:]  # remove the leading \"0b\"\n    b_binary = str(bin(b))[2:]\n    max_len = max(len(a_binary), len(b_binary))\n    return \"0b\" + \"\".join(\n        str(int(\"1\" in (char_a, char_b)))\n        for char_a, char_b in zip(a_binary.zfill(max_len), b_binary.zfill(max_len))\n    )", "blocks": [{"id": 1, "label": "def binary_or(a: int, b: int) -> str:\n    if a < 0 or b < 0:", "successors": [{"id": 3, "label": "        raise ValueError(\"the value of both inputs must be positive\")", "successors": []}, {"id": 4, "label": "    a_binary = str(bin(a))[2:]\n    b_binary = str(bin(b))[2:]\n    max_len = max(len(a_binary), len(b_binary))\n    return \"0b\" + \"\".join(\n        str(int(\"1\" in (char_a, char_b)))\n        for char_a, char_b in zip(a_binary.zfill(max_len), b_binary.zfill(max_len))\n    )", "successors": []}]}]}], "classes": [], "simplified_code": "# https://www.tutorialspoint.com/python3/bitwise_operators_example.htm\n\n\n    )\n\n\nif __name__ == \"__main__\":\n    import doctest\n\n    doctest.testmod()", "blocks": [{"id": 1, "label": "if __name__ == \"__main__\":\n    import doctest", "successors": [{"id": 3, "label": "    doctest.testmod()", "successors": []}]}]}
{"file_name": "198.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 20, "functions": [{"name": "configure_logging", "type": "function", "start_line": 6, "end_line": 20, "functions": [], "classes": [], "simplified_code": "def configure_logging():\n    import logging\n\n    import autogpt_libs.logging.config\n\n    if (\n        settings.config.behave_as == BehaveAs.LOCAL\n        or settings.config.app_env == AppEnvironment.LOCAL\n    ):\n        autogpt_libs.logging.config.configure_logging(force_cloud_logging=False)\n    else:\n        autogpt_libs.logging.config.configure_logging(force_cloud_logging=True)\n\n    # Silence httpx logger\n    logging.getLogger(\"httpx\").setLevel(logging.WARNING)", "blocks": [{"id": 1, "label": "def configure_logging():\nimport logging\n\nimport autogpt_libs.logging.config", "successors": [{"id": 3, "label": "if (\n    settings.config.behave_as == BehaveAs.LOCAL\n    or settings.config.app_env == AppEnvironment.LOCAL\n):", "successors": [{"id": 4, "label": "    autogpt_libs.logging.config.configure_logging(force_cloud_logging=False)\nlogging.getLogger(\"httpx\").setLevel(logging.WARNING)", "successors": []}, {"id": 5, "label": "    autogpt_libs.logging.config.configure_logging(force_cloud_logging=True)\nlogging.getLogger(\"httpx\").setLevel(logging.WARNING)", "successors": []}]}]}]}], "classes": [], "simplified_code": "from backend.util.settings import AppEnvironment, BehaveAs, Settings\n\nsettings = Settings()\n\n\n    logging.getLogger(\"httpx\").setLevel(logging.WARNING)", "blocks": [{"id": 1, "label": "from backend.util.settings import AppEnvironment, BehaveAs, Settings\n\nsettings = Settings()\nlogging.getLogger(\"httpx\").setLevel(logging.WARNING)", "successors": []}]}
{"file_name": "199.json", "name": "example_script", "type": "CFG", "start_line": 1, "end_line": 51, "functions": [{"name": "get_index_of_rightmost_set_bit", "type": "function", "start_line": 4, "end_line": 40, "functions": [], "classes": [], "simplified_code": "def get_index_of_rightmost_set_bit(number: int) -> int:\n    \"\"\"\n    Take in a positive integer 'number'.\n    Returns the zero-based index of first set bit in that 'number' from right.\n    Returns -1, If no set bit found.\n\n    >>> get_index_of_rightmost_set_bit(0)\n    -1\n    >>> get_index_of_rightmost_set_bit(5)\n    0\n    >>> get_index_of_rightmost_set_bit(36)\n    2\n    >>> get_index_of_rightmost_set_bit(8)\n    3\n    >>> get_index_of_rightmost_set_bit(-18)\n    Traceback (most recent call last):\n        ...\n    ValueError: Input must be a non-negative integer\n    >>> get_index_of_rightmost_set_bit('test')\n    Traceback (most recent call last):\n        ...\n    ValueError: Input must be a non-negative integer\n    >>> get_index_of_rightmost_set_bit(1.25)\n    Traceback (most recent call last):\n        ...\n    ValueError: Input must be a non-negative integer\n    \"\"\"\n\n    if not isinstance(number, int) or number < 0:\n        raise ValueError(\"Input must be a non-negative integer\")\n\n    intermediate = number & ~(number - 1)\n    index = 0\n    while intermediate:\n        intermediate >>= 1\n        index += 1\n    return index - 1", "blocks": [{"id": 1, "label": "def get_index_of_rightmost_set_bit(number: int) -> int:\nif not isinstance(number, int) or number < 0:", "successors": [{"id": 3, "label": "raise ValueError(\"Input must be a non-negative integer\")", "successors": []}, {"id": 4, "label": "intermediate = number & ~(number - 1)\nindex = 0", "successors": [{"id": 6, "label": "while intermediate:", "successors": [{"id": 7, "label": "intermediate >>= 1\nindex += 1", "successors": [{"id": 6, "label": "while intermediate:", "successors": []}]}, {"id": 9, "label": "return index - 1", "successors": []}]}]}]}]}], "classes": [], "simplified_code": "# Reference: https://www.geeksforgeeks.org/position-of-rightmost-set-bit/\n\n\n    return index - 1\n\n\nif __name__ == \"__main__\":\n    \"\"\"\n    Finding the index of rightmost set bit has some very peculiar use-cases,\n    especially in finding missing or/and repeating numbers in a list of\n    positive integers.\n    \"\"\"\n    import doctest\n\n    doctest.testmod(verbose=True)", "blocks": [{"id": 1, "label": "return index - 1", "successors": []}]}
