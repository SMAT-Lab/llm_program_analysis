{
  "name": "example_script",
  "type": "CFG",
  "start_line": 1,
  "end_line": 264,
  "functions": [],
  "classes": [
    {
      "name": "SamplingMethod",
      "type": "class",
      "start_line": 10,
      "end_line": 18,
      "functions": [],
      "classes": [],
      "simplified_code": "class SamplingMethod(str, Enum):\n    RANDOM = \"random\"\n    SYSTEMATIC = \"systematic\"\n    TOP = \"top\"\n    BOTTOM = \"bottom\"\n    STRATIFIED = \"stratified\"\n    WEIGHTED = \"weighted\"\n    RESERVOIR = \"reservoir\"\n    CLUSTER = \"cluster\"",
      "blocks": [
        {
          "id": 1,
          "label": "class SamplingMethod(str, Enum):",
          "successors": [
            2
          ]
        },
        {
          "id": 2,
          "label": "RANDOM = \"random\"\nSYSTEMATIC = \"systematic\"\nTOP = \"top\"\nBOTTOM = \"bottom\"\nSTRATIFIED = \"stratified\"\nWEIGHTED = \"weighted\"\nRESERVOIR = \"reservoir\"\nCLUSTER = \"cluster\"",
          "successors": []
        }
      ]
    },
    {
      "name": "DataSamplingBlock",
      "type": "class",
      "start_line": 21,
      "end_line": 264,
      "functions": [
        {
          "name": "__init__",
          "type": "function",
          "start_line": 65,
          "end_line": 94,
          "functions": [],
          "classes": [],
          "simplified_code": "    def __init__(self):\n        super().__init__(\n            id=\"4a448883-71fa-49cf-91cf-70d793bd7d87\",\n            description=\"This block samples data from a given dataset using various sampling methods.\",\n            categories={BlockCategory.LOGIC},\n            input_schema=DataSamplingBlock.Input,\n            output_schema=DataSamplingBlock.Output,\n            test_input={\n                \"data\": [\n                    {\"id\": i, \"value\": chr(97 + i), \"group\": i % 3} for i in range(10)\n                ],\n                \"sample_size\": 3,\n                \"sampling_method\": SamplingMethod.STRATIFIED,\n                \"accumulate\": False,\n                \"random_seed\": 42,\n                \"stratify_key\": \"group\",\n            },\n            test_output=[\n                (\n                    \"sampled_data\",\n                    [\n                        {\"id\": 0, \"value\": \"a\", \"group\": 0},\n                        {\"id\": 1, \"value\": \"b\", \"group\": 1},\n                        {\"id\": 8, \"value\": \"i\", \"group\": 2},\n                    ],\n                ),\n                (\"sample_indices\", [0, 1, 8]),\n            ],\n        )\n        self.accumulated_data = []",
          "blocks": [
            {
              "id": 1,
              "label": "def __init__(self):",
              "successors": [
                2
              ]
            },
            {
              "id": 2,
              "label": "super().__init__(...)",
              "successors": [
                3
              ]
            },
            {
              "id": 3,
              "label": "self.accumulated_data = []",
              "successors": []
            }
          ]
        },
        {
          "name": "run",
          "type": "function",
          "start_line": 96,
          "end_line": 264,
          "functions": [],
          "classes": [],
          "simplified_code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        if input_data.accumulate:\n            if isinstance(input_data.data, dict):\n                self.accumulated_data.append(input_data.data)\n            elif isinstance(input_data.data, list):\n                self.accumulated_data.extend(input_data.data)\n            else:\n                raise ValueError(f\"Unsupported data type: {type(input_data.data)}\")\n\n            # If we don't have enough data yet, return without sampling\n            if len(self.accumulated_data) < input_data.sample_size:\n                return\n\n            data_to_sample = self.accumulated_data\n        else:\n            # If not accumulating, use the input data directly\n            data_to_sample = (\n                input_data.data\n                if isinstance(input_data.data, list)\n                else [input_data.data]\n            )\n\n        if input_data.random_seed is not None:\n            random.seed(input_data.random_seed)\n\n        data_size = len(data_to_sample)\n\n        if input_data.sample_size > data_size:\n            raise ValueError(\n                f\"Sample size ({input_data.sample_size}) cannot be larger than the dataset size ({data_size}).\"\n            )\n\n        indices = []\n\n        if input_data.sampling_method == SamplingMethod.RANDOM:\n            indices = random.sample(range(data_size), input_data.sample_size)\n        elif input_data.sampling_method == SamplingMethod.SYSTEMATIC:\n            step = data_size // input_data.sample_size\n            start = random.randint(0, step - 1)\n            indices = list(range(start, data_size, step))[: input_data.sample_size]\n        elif input_data.sampling_method == SamplingMethod.TOP:\n            indices = list(range(input_data.sample_size))\n        elif input_data.sampling_method == SamplingMethod.BOTTOM:\n            indices = list(range(data_size - input_data.sample_size, data_size))\n        elif input_data.sampling_method == SamplingMethod.STRATIFIED:\n            if not input_data.stratify_key:\n                raise ValueError(\n                    \"Stratify key must be provided for stratified sampling.\"\n                )\n            strata = defaultdict(list)\n            for i, item in enumerate(data_to_sample):\n                if isinstance(item, dict):\n                    strata_value = item.get(input_data.stratify_key)\n                elif hasattr(item, input_data.stratify_key):\n                    strata_value = getattr(item, input_data.stratify_key)\n                else:\n                    raise ValueError(\n                        f\"Stratify key '{input_data.stratify_key}' not found in item {item}\"\n                    )\n\n                if strata_value is None:\n                    raise ValueError(\n                        f\"Stratify value for key '{input_data.stratify_key}' is None\"\n                    )\n\n                strata[str(strata_value)].append(i)\n\n            # Calculate the number of samples to take from each stratum\n            stratum_sizes = {\n                k: max(1, int(len(v) / data_size * input_data.sample_size))\n                for k, v in strata.items()\n            }\n\n            # Adjust sizes to ensure we get exactly sample_size samples\n            while sum(stratum_sizes.values()) != input_data.sample_size:\n                if sum(stratum_sizes.values()) < input_data.sample_size:\n                    stratum_sizes[\n                        max(stratum_sizes, key=lambda k: stratum_sizes[k])\n                    ] += 1\n                else:\n                    stratum_sizes[\n                        max(stratum_sizes, key=lambda k: stratum_sizes[k])\n                    ] -= 1\n\n            for stratum, size in stratum_sizes.items():\n                indices.extend(random.sample(strata[stratum], size))\n        elif input_data.sampling_method == SamplingMethod.WEIGHTED:\n            if not input_data.weight_key:\n                raise ValueError(\"Weight key must be provided for weighted sampling.\")\n            weights = []\n            for item in data_to_sample:\n                if isinstance(item, dict):\n                    weight = item.get(input_data.weight_key)\n                elif hasattr(item, input_data.weight_key):\n                    weight = getattr(item, input_data.weight_key)\n                else:\n                    raise ValueError(\n                        f\"Weight key '{input_data.weight_key}' not found in item {item}\"\n                    )\n\n                if weight is None:\n                    raise ValueError(\n                        f\"Weight value for key '{input_data.weight_key}' is None\"\n                    )\n                try:\n                    weights.append(float(weight))\n                except ValueError:\n                    raise ValueError(\n                        f\"Weight value '{weight}' cannot be converted to a number\"\n                    )\n\n            if not weights:\n                raise ValueError(\n                    f\"No valid weights found using key '{input_data.weight_key}'\"\n                )\n\n            indices = random.choices(\n                range(data_size), weights=weights, k=input_data.sample_size\n            )\n        elif input_data.sampling_method == SamplingMethod.RESERVOIR:\n            indices = list(range(input_data.sample_size))\n            for i in range(input_data.sample_size, data_size):\n                j = random.randint(0, i)\n                if j < input_data.sample_size:\n                    indices[j] = i\n        elif input_data.sampling_method == SamplingMethod.CLUSTER:\n            if not input_data.cluster_key:\n                raise ValueError(\"Cluster key must be provided for cluster sampling.\")\n            clusters = defaultdict(list)\n            for i, item in enumerate(data_to_sample):\n                if isinstance(item, dict):\n                    cluster_value = item.get(input_data.cluster_key)\n                elif hasattr(item, input_data.cluster_key):\n                    cluster_value = getattr(item, input_data.cluster_key)\n                else:\n                    raise TypeError(\n                        f\"Item {item} does not have the cluster key '{input_data.cluster_key}'\"\n                    )\n\n                clusters[str(cluster_value)].append(i)\n\n            # Randomly select clusters until we have enough samples\n            selected_clusters = []\n            while (\n                sum(len(clusters[c]) for c in selected_clusters)\n                < input_data.sample_size\n            ):\n                available_clusters = [c for c in clusters if c not in selected_clusters]\n                if not available_clusters:\n                    break\n                selected_clusters.append(random.choice(available_clusters))\n\n            for cluster in selected_clusters:\n                indices.extend(clusters[cluster])\n\n            # If we have more samples than needed, randomly remove some\n            if len(indices) > input_data.sample_size:\n                indices = random.sample(indices, input_data.sample_size)\n        else:\n            raise ValueError(f\"Unknown sampling method: {input_data.sampling_method}\")\n\n        sampled_data = [data_to_sample[i] for i in indices]\n\n        # Clear accumulated data after sampling if accumulation is enabled\n        if input_data.accumulate:\n            self.accumulated_data = []\n\n        yield \"sampled_data\", sampled_data\n        yield \"sample_indices\", indices",
          "blocks": [
            {
              "id": 1,
              "label": "if input_data.accumulate:",
              "successors": [
                2,
                14
              ]
            },
            {
              "id": 2,
              "label": "if isinstance(input_data.data, dict):",
              "successors": [
                3,
                4
              ]
            },
            {
              "id": 3,
              "label": "self.accumulated_data.append(input_data.data)",
              "successors": [
                7
              ]
            },
            {
              "id": 4,
              "label": "elif isinstance(input_data.data, list):",
              "successors": [
                5,
                6
              ]
            },
            {
              "id": 5,
              "label": "self.accumulated_data.extend(input_data.data)",
              "successors": [
                7
              ]
            },
            {
              "id": 6,
              "label": "raise ValueError(f\"Unsupported data type: {type(input_data.data)}\")",
              "successors": [
                7
              ]
            },
            {
              "id": 7,
              "label": "if len(self.accumulated_data) < input_data.sample_size:",
              "successors": [
                8,
                9
              ]
            },
            {
              "id": 8,
              "label": "return",
              "successors": []
            },
            {
              "id": 9,
              "label": "data_to_sample = self.accumulated_data",
              "successors": [
                15
              ]
            },
            {
              "id": 14,
              "label": "data_to_sample = (input_data.data if isinstance(input_data.data, list) else [input_data.data])",
              "successors": [
                15
              ]
            },
            {
              "id": 15,
              "label": "if input_data.random_seed is not None:",
              "successors": [
                16,
                17
              ]
            },
            {
              "id": 16,
              "label": "random.seed(input_data.random_seed)",
              "successors": [
                17
              ]
            },
            {
              "id": 17,
              "label": "data_size = len(data_to_sample)",
              "successors": [
                18
              ]
            },
            {
              "id": 18,
              "label": "if input_data.sample_size > data_size:",
              "successors": [
                19,
                20
              ]
            },
            {
              "id": 19,
              "label": "raise ValueError(f\"Sample size ({input_data.sample_size}) cannot be larger than the dataset size ({data_size}).\")",
              "successors": [
                20
              ]
            },
            {
              "id": 20,
              "label": "indices = []",
              "successors": [
                21
              ]
            },
            {
              "id": 21,
              "label": "if input_data.sampling_method == SamplingMethod.RANDOM:",
              "successors": [
                22,
                23
              ]
            },
            {
              "id": 22,
              "label": "indices = random.sample(range(data_size), input_data.sample_size)",
              "successors": [
                66
              ]
            },
            {
              "id": 23,
              "label": "elif input_data.sampling_method == SamplingMethod.SYSTEMATIC:",
              "successors": [
                24,
                25
              ]
            },
            {
              "id": 24,
              "label": "step = data_size // input_data.sample_size",
              "successors": [
                25
              ]
            },
            {
              "id": 25,
              "label": "start = random.randint(0, step - 1)",
              "successors": [
                26
              ]
            },
            {
              "id": 26,
              "label": "indices = list(range(start, data_size, step))[: input_data.sample_size]",
              "successors": [
                66
              ]
            },
            {
              "id": 27,
              "label": "elif input_data.sampling_method == SamplingMethod.TOP:",
              "successors": [
                28,
                29
              ]
            },
            {
              "id": 28,
              "label": "indices = list(range(input_data.sample_size))",
              "successors": [
                66
              ]
            },
            {
              "id": 29,
              "label": "elif input_data.sampling_method == SamplingMethod.BOTTOM:",
              "successors": [
                30,
                31
              ]
            },
            {
              "id": 30,
              "label": "indices = list(range(data_size - input_data.sample_size, data_size))",
              "successors": [
                66
              ]
            },
            {
              "id": 31,
              "label": "elif input_data.sampling_method == SamplingMethod.STRATIFIED:",
              "successors": [
                32,
                39
              ]
            },
            {
              "id": 32,
              "label": "if not input_data.stratify_key:",
              "successors": [
                33,
                34
              ]
            },
            {
              "id": 33,
              "label": "raise ValueError(\"Stratify key must be provided for stratified sampling.\")",
              "successors": [
                34
              ]
            },
            {
              "id": 34,
              "label": "strata = defaultdict(list)",
              "successors": [
                35
              ]
            },
            {
              "id": 35,
              "label": "for i, item in enumerate(data_to_sample):",
              "successors": [
                36,
                37
              ]
            },
            {
              "id": 36,
              "label": "if isinstance(item, dict):",
              "successors": [
                38
              ]
            },
            {
              "id": 37,
              "label": "elif hasattr(item, input_data.stratify_key):",
              "successors": [
                38
              ]
            },
            {
              "id": 38,
              "label": "else: raise ValueError(f\"Stratify key '{input_data.stratify_key}' not found in item {item}\")",
              "successors": [
                39
              ]
            },
            {
              "id": 39,
              "label": "if strata_value is None: raise ValueError(f\"Stratify value for key '{input_data.stratify_key}' is None\")",
              "successors": [
                41
              ]
            },
            {
              "id": 41,
              "label": "strata[str(strata_value)].append(i)",
              "successors": [
                42
              ]
            },
            {
              "id": 42,
              "label": "stratum_sizes = {k: max(1, int(len(v) / data_size * input_data.sample_size)) for k, v in strata.items()}",
              "successors": [
                43
              ]
            },
            {
              "id": 43,
              "label": "while sum(stratum_sizes.values()) != input_data.sample_size:",
              "successors": [
                44,
                45
              ]
            },
            {
              "id": 44,
              "label": "if sum(stratum_sizes.values()) < input_data.sample_size: stratum_sizes[max(stratum_sizes, key=lambda k: stratum_sizes[k])] += 1",
              "successors": [
                45
              ]
            },
            {
              "id": 45,
              "label": "else: stratum_sizes[max(stratum_sizes, key=lambda k: stratum_sizes[k])] -= 1",
              "successors": [
                46
              ]
            },
            {
              "id": 46,
              "label": "for stratum, size in stratum_sizes.items(): indices.extend(random.sample(strata[stratum], size))",
              "successors": [
                66
              ]
            },
            {
              "id": 47,
              "label": "elif input_data.sampling_method == SamplingMethod.WEIGHTED:",
              "successors": [
                48,
                55
              ]
            },
            {
              "id": 48,
              "label": "if not input_data.weight_key: raise ValueError(\"Weight key must be provided for weighted sampling.\")",
              "successors": [
                49
              ]
            },
            {
              "id": 49,
              "label": "weights = []",
              "successors": [
                50
              ]
            },
            {
              "id": 50,
              "label": "for item in data_to_sample:",
              "successors": [
                51,
                52
              ]
            },
            {
              "id": 51,
              "label": "if isinstance(item, dict): weight = item.get(input_data.weight_key)",
              "successors": [
                51
              ]
            },
            {
              "id": 52,
              "label": "elif hasattr(item, input_data.weight_key): weight = getattr(item, input_data.weight_key)",
              "successors": [
                53
              ]
            },
            {
              "id": 53,
              "label": "else: raise ValueError(f\"Weight key '{input_data.weight_key}' not found in item {item}\")",
              "successors": [
                55
              ]
            },
            {
              "id": 55,
              "label": "if weight is None: raise ValueError(f\"Weight value for key '{input_data.weight_key}' is None\")",
              "successors": [
                56
              ]
            },
            {
              "id": 56,
              "label": "try: weights.append(float(weight))",
              "successors": [
                57
              ]
            },
            {
              "id": 57,
              "label": "except ValueError: raise ValueError(f\"Weight value '{weight}' cannot be converted to a number\")",
              "successors": [
                58
              ]
            },
            {
              "id": 58,
              "label": "if not weights: raise ValueError(f\"No valid weights found using key '{input_data.weight_key}'\")",
              "successors": [
                59
              ]
            },
            {
              "id": 59,
              "label": "indices = random.choices(range(data_size), weights=weights, k=input_data.sample_size)",
              "successors": [
                66
              ]
            },
            {
              "id": 61,
              "label": "elif input_data.sampling_method == SamplingMethod.RESERVOIR:",
              "successors": [
                62,
                63
              ]
            },
            {
              "id": 62,
              "label": "indices = list(range(input_data.sample_size))",
              "successors": [
                63
              ]
            },
            {
              "id": 63,
              "label": "for i in range(input_data.sample_size, data_size):",
              "successors": [
                64,
                65
              ]
            },
            {
              "id": 64,
              "label": "j = random.randint(0, i)",
              "successors": [
                66
              ]
            },
            {
              "id": 65,
              "label": "if j < input_data.sample_size: indices[j] = i",
              "successors": [
                66
              ]
            },
            {
              "id": 66,
              "label": "elif input_data.sampling_method == SamplingMethod.CLUSTER:",
              "successors": [
                67,
                73
              ]
            },
            {
              "id": 67,
              "label": "if not input_data.cluster_key: raise ValueError(\"Cluster key must be provided for cluster sampling.\")",
              "successors": [
                68
              ]
            },
            {
              "id": 68,
              "label": "clusters = defaultdict(list)",
              "successors": [
                69
              ]
            },
            {
              "id": 69,
              "label": "for i, item in enumerate(data_to_sample):",
              "successors": [
                70,
                71
              ]
            },
            {
              "id": 70,
              "label": "if isinstance(item, dict): cluster_value = item.get(input_data.cluster_key)",
              "successors": [
                71
              ]
            },
            {
              "id": 71,
              "label": "elif hasattr(item, input_data.cluster_key): cluster_value = getattr(item, input_data.cluster_key)",
              "successors": [
                72
              ]
            },
            {
              "id": 72,
              "label": "else: raise TypeError(f\"Item {item} does not have the cluster key '{input_data.cluster_key}')",
              "successors": [
                75
              ]
            },
            {
              "id": 73,
              "label": "clusters[str(cluster_value)].append(i)",
              "successors": [
                74
              ]
            },
            {
              "id": 74,
              "label": "selected_clusters = []",
              "successors": [
                75
              ]
            },
            {
              "id": 75,
              "label": "while (sum(len(clusters[c]) for c in selected_clusters) < input_data.sample_size):",
              "successors": [
                76,
                77
              ]
            },
            {
              "id": 76,
              "label": "available_clusters = [c for c in clusters if c not in selected_clusters]",
              "successors": [
                78
              ]
            },
            {
              "id": 77,
              "label": "if not available_clusters: break",
              "successors": [
                78
              ]
            },
            {
              "id": 78,
              "label": "selected_clusters.append(random.choice(available_clusters))",
              "successors": [
                79
              ]
            },
            {
              "id": 79,
              "label": "for cluster in selected_clusters: indices.extend(clusters[cluster])",
              "successors": [
                80
              ]
            },
            {
              "id": 80,
              "label": "if len(indices) > input_data.sample_size: indices = random.sample(indices, input_data.sample_size)",
              "successors": [
                81
              ]
            },
            {
              "id": 81,
              "label": "else: raise ValueError(f\"Unknown sampling method: {input_data.sampling_method}\")",
              "successors": [
                82
              ]
            },
            {
              "id": 82,
              "label": "sampled_data = [data_to_sample[i] for i in indices]",
              "successors": [
                83
              ]
            },
            {
              "id": 83,
              "label": "if input_data.accumulate: self.accumulated_data = []",
              "successors": [
                84
              ]
            },
            {
              "id": 84,
              "label": "yield \"sampled_data\", sampled_data",
              "successors": [
                85
              ]
            },
            {
              "id": 85,
              "label": "yield \"sample_indices\", indices",
              "successors": []
            }
          ]
        }
      ],
      "classes": [
        {
          "name": "Input",
          "type": "class",
          "start_line": 22,
          "end_line": 55,
          "functions": [],
          "classes": [],
          "simplified_code": "    class Input(BlockSchema):\n        data: Union[Dict[str, Any], List[Union[dict, List[Any]]]] = SchemaField(\n            description=\"The dataset to sample from. Can be a single dictionary, a list of dictionaries, or a list of lists.\",\n            placeholder=\"{'id': 1, 'value': 'a'} or [{'id': 1, 'value': 'a'}, {'id': 2, 'value': 'b'}, ...]\",\n        )\n        sample_size: int = SchemaField(\n            description=\"The number of samples to take from the dataset.\",\n            placeholder=\"10\",\n            default=10,\n        )\n        sampling_method: SamplingMethod = SchemaField(\n            description=\"The method to use for sampling.\",\n            default=SamplingMethod.RANDOM,\n        )\n        accumulate: bool = SchemaField(\n            description=\"Whether to accumulate data before sampling.\",\n            default=False,\n        )\n        random_seed: Optional[int] = SchemaField(\n            description=\"Seed for random number generator (optional).\",\n            default=None,\n        )\n        stratify_key: Optional[str] = SchemaField(\n            description=\"Key to use for stratified sampling (required for stratified sampling).\",\n            default=None,\n        )\n        weight_key: Optional[str] = SchemaField(\n            description=\"Key to use for weighted sampling (required for weighted sampling).\",\n            default=None,\n        )\n        cluster_key: Optional[str] = SchemaField(\n            description=\"Key to use for cluster sampling (required for cluster sampling).\",\n            default=None,\n        )",
          "blocks": [
            {
              "id": 1,
              "label": "class Input(BlockSchema):",
              "successors": [
                2
              ]
            },
            {
              "id": 2,
              "label": "data = SchemaField(...)",
              "successors": [
                3
              ]
            },
            {
              "id": 3,
              "label": "sample_size = SchemaField(...)",
              "successors": [
                4
              ]
            },
            {
              "id": 4,
              "label": "sampling_method = SchemaField(...)",
              "successors": [
                5
              ]
            },
            {
              "id": 5,
              "label": "accumulate = SchemaField(...)",
              "successors": [
                6
              ]
            },
            {
              "id": 6,
              "label": "random_seed = SchemaField(...)",
              "successors": [
                7
              ]
            },
            {
              "id": 7,
              "label": "stratify_key = SchemaField(...)",
              "successors": [
                8
              ]
            },
            {
              "id": 8,
              "label": "weight_key = SchemaField(...)",
              "successors": [
                9
              ]
            },
            {
              "id": 9,
              "label": "cluster_key = SchemaField(...)",
              "successors": []
            }
          ]
        },
        {
          "name": "Output",
          "type": "class",
          "start_line": 57,
          "end_line": 63,
          "functions": [],
          "classes": [],
          "simplified_code": "    class Output(BlockSchema):\n        sampled_data: List[Union[dict, List[Any]]] = SchemaField(\n            description=\"The sampled subset of the input data.\"\n        )\n        sample_indices: List[int] = SchemaField(\n            description=\"The indices of the sampled data in the original dataset.\"\n        )",
          "blocks": [
            {
              "id": 1,
              "label": "class Output(BlockSchema):",
              "successors": [
                2,
                3
              ]
            },
            {
              "id": 2,
              "label": "sampled_data: List[Union[dict, List[Any]]] = SchemaField(description=\"The sampled subset of the input data.\")",
              "successors": [
                3
              ]
            },
            {
              "id": 3,
              "label": "sample_indices: List[int] = SchemaField(description=\"The indices of the sampled data in the original dataset.\")",
              "successors": []
            }
          ]
        }
      ],
      "simplified_code": "class DataSamplingBlock(Block):\n        )\n\n        )\n\n        self.accumulated_data = []\n\n        yield \"sample_indices\", indices",
      "blocks": [
        {
          "id": 1,
          "label": "class DataSamplingBlock(Block):",
          "successors": [
            2
          ]
        },
        {
          "id": 2,
          "label": "def accumulate_data(self, data):",
          "successors": [
            3
          ]
        },
        {
          "id": 3,
          "label": "for datum in data:",
          "successors": [
            4,
            5
          ]
        },
        {
          "id": 4,
          "label": "self.accumulated_data.append(datum)",
          "successors": [
            3
          ]
        },
        {
          "id": 5,
          "label": "return self.accumulated_data",
          "successors": []
        },
        {
          "id": 6,
          "label": "def data_ticket(self, num_samples):",
          "successors": [
            7
          ]
        },
        {
          "id": 7,
          "label": "complete_data = range(100)",
          "successors": [
            8
          ]
        },
        {
          "id": 8,
          "label": "indices = random.sample(complete_data, num_samples)",
          "successors": [
            9
          ]
        },
        {
          "id": 9,
          "label": "yield \"sample_indices\", indices",
          "successors": []
        }
      ]
    }
  ],
  "simplified_code": "import random\nfrom collections import defaultdict\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Union\n\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\n\n\n    CLUSTER = \"cluster\"\n\n\n        yield \"sample_indices\", indices",
  "blocks": [
    {
      "id": 1,
      "label": "import random",
      "successors": [
        2
      ]
    },
    {
      "id": 2,
      "label": "from collections import defaultdict",
      "successors": [
        3
      ]
    },
    {
      "id": 3,
      "label": "from enum import Enum",
      "successors": [
        4
      ]
    },
    {
      "id": 4,
      "label": "from typing import Any, Dict, List, Optional, Union",
      "successors": [
        5
      ]
    },
    {
      "id": 5,
      "label": "from backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema",
      "successors": [
        6
      ]
    },
    {
      "id": 6,
      "label": "from backend.data.model import SchemaField",
      "successors": [
        7
      ]
    },
    {
      "id": 7,
      "label": "CLUSTER = \"cluster\"",
      "successors": [
        8
      ]
    },
    {
      "id": 8,
      "label": "yield \"sample_indices\", indices",
      "successors": []
    }
  ]
}