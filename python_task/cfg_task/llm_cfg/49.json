[
  {
    "decl_name": "GlobalBlock",
    "start_line": 0,
    "end_line": 3,
    "children": [],
    "code": "from backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import ContributorDetails, SchemaField\n\n\n",
    "cfg": {
      "nodes": [
        {
          "id": "GlobalBlock_1",
          "code": "from backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\n"
        },
        {
          "id": "GlobalBlock_2",
          "code": "from backend.data.model import ContributorDetails, SchemaField\n"
        }
      ],
      "edges": [
        {
          "from": "GlobalBlock_1",
          "to": "GlobalBlock_2"
        }
      ]
    }
  },
  {
    "decl_name": "ReadCsvBlock",
    "start_line": 4,
    "end_line": 108,
    "children": [
      {
        "decl_name": "ReadCsvBlock.Input",
        "start_line": 5,
        "end_line": 37,
        "children": [],
        "code": "    class Input(BlockSchema):\n        contents: str = SchemaField(\n            description=\"The contents of the CSV file to read\",\n            placeholder=\"a, b, c\\n1,2,3\\n4,5,6\",\n        )\n        delimiter: str = SchemaField(\n            description=\"The delimiter used in the CSV file\",\n            default=\",\",\n        )\n        quotechar: str = SchemaField(\n            description=\"The character used to quote fields\",\n            default='\"',\n        )\n        escapechar: str = SchemaField(\n            description=\"The character used to escape the delimiter\",\n            default=\"\\\\\",\n        )\n        has_header: bool = SchemaField(\n            description=\"Whether the CSV file has a header row\",\n            default=True,\n        )\n        skip_rows: int = SchemaField(\n            description=\"The number of rows to skip from the start of the file\",\n            default=0,\n        )\n        strip: bool = SchemaField(\n            description=\"Whether to strip whitespace from the values\",\n            default=True,\n        )\n        skip_columns: list[str] = SchemaField(\n            description=\"The columns to skip from the start of the row\",\n            default=[],\n        )\n",
        "cfg": {
          "nodes": [
            {
              "id": "ReadCsvBlock.Input_1",
              "code": "class Input(BlockSchema):\n"
            },
            {
              "id": "ReadCsvBlock.Input_2",
              "code": "        contents: str = SchemaField(\n            description=\"The contents of the CSV file to read\",\n            placeholder=\"a, b, c\\n1,2,3\\n4,5,6\",\n        )\n"
            },
            {
              "id": "ReadCsvBlock.Input_3",
              "code": "        delimiter: str = SchemaField(\n            description=\"The delimiter used in the CSV file\",\n            default=\",\",\n        )\n"
            },
            {
              "id": "ReadCsvBlock.Input_4",
              "code": "        quotechar: str = SchemaField(\n            description=\"The character used to quote fields\",\n            default='\"',\n        )\n"
            },
            {
              "id": "ReadCsvBlock.Input_5",
              "code": "        escapechar: str = SchemaField(\n            description=\"The character used to escape the delimiter\",\n            default=\"\\\\\",\n        )\n"
            },
            {
              "id": "ReadCsvBlock.Input_6",
              "code": "        has_header: bool = SchemaField(\n            description=\"Whether the CSV file has a header row\",\n            default=True,\n        )\n"
            },
            {
              "id": "ReadCsvBlock.Input_7",
              "code": "        skip_rows: int = SchemaField(\n            description=\"The number of rows to skip from the start of the file\",\n            default=0,\n        )\n"
            },
            {
              "id": "ReadCsvBlock.Input_8",
              "code": "        strip: bool = SchemaField(\n            description=\"Whether to strip whitespace from the values\",\n            default=True,\n        )\n"
            },
            {
              "id": "ReadCsvBlock.Input_9",
              "code": "        skip_columns: list[str] = SchemaField(\n            description=\"The columns to skip from the start of the row\",\n            default=[],\n        )\n"
            }
          ],
          "edges": [
            {
              "from": "ReadCsvBlock.Input_1",
              "to": "ReadCsvBlock.Input_2"
            },
            {
              "from": "ReadCsvBlock.Input_2",
              "to": "ReadCsvBlock.Input_3"
            },
            {
              "from": "ReadCsvBlock.Input_3",
              "to": "ReadCsvBlock.Input_4"
            },
            {
              "from": "ReadCsvBlock.Input_4",
              "to": "ReadCsvBlock.Input_5"
            },
            {
              "from": "ReadCsvBlock.Input_5",
              "to": "ReadCsvBlock.Input_6"
            },
            {
              "from": "ReadCsvBlock.Input_6",
              "to": "ReadCsvBlock.Input_7"
            },
            {
              "from": "ReadCsvBlock.Input_7",
              "to": "ReadCsvBlock.Input_8"
            },
            {
              "from": "ReadCsvBlock.Input_8",
              "to": "ReadCsvBlock.Input_9"
            }
          ]
        }
      },
      {
        "decl_name": "ReadCsvBlock.Output",
        "start_line": 39,
        "end_line": 45,
        "children": [],
        "code": "    class Output(BlockSchema):\n        row: dict[str, str] = SchemaField(\n            description=\"The data produced from each row in the CSV file\"\n        )\n        all_data: list[dict[str, str]] = SchemaField(\n            description=\"All the data in the CSV file as a list of rows\"\n        )\n",
        "cfg": {
          "nodes": [
            {
              "id": "ReadCsvBlock.Output_1",
              "code": "class Output(BlockSchema):\n"
            },
            {
              "id": "ReadCsvBlock.Output_2",
              "code": "        row: dict[str, str] = SchemaField(\n            description=\"The data produced from each row in the CSV file\"\n        )\n"
            },
            {
              "id": "ReadCsvBlock.Output_3",
              "code": "        all_data: list[dict[str, str]] = SchemaField(\n            description=\"All the data in the CSV file as a list of rows\"\n        )\n"
            }
          ],
          "edges": [
            {
              "from": "ReadCsvBlock.Output_1",
              "to": "ReadCsvBlock.Output_2"
            },
            {
              "from": "ReadCsvBlock.Output_1",
              "to": "ReadCsvBlock.Output_3"
            }
          ]
        }
      },
      {
        "decl_name": "ReadCsvBlock.__init__",
        "start_line": 47,
        "end_line": 69,
        "children": [],
        "code": "    def __init__(self):\n        super().__init__(\n            id=\"acf7625e-d2cb-4941-bfeb-2819fc6fc015\",\n            input_schema=ReadCsvBlock.Input,\n            output_schema=ReadCsvBlock.Output,\n            description=\"Reads a CSV file and outputs the data as a list of dictionaries and individual rows via rows.\",\n            contributors=[ContributorDetails(name=\"Nicholas Tindle\")],\n            categories={BlockCategory.TEXT, BlockCategory.DATA},\n            test_input={\n                \"contents\": \"a, b, c\\n1,2,3\\n4,5,6\",\n            },\n            test_output=[\n                (\"row\", {\"a\": \"1\", \"b\": \"2\", \"c\": \"3\"}),\n                (\"row\", {\"a\": \"4\", \"b\": \"5\", \"c\": \"6\"}),\n                (\n                    \"all_data\",\n                    [\n                        {\"a\": \"1\", \"b\": \"2\", \"c\": \"3\"},\n                        {\"a\": \"4\", \"b\": \"5\", \"c\": \"6\"},\n                    ],\n                ),\n            ],\n        )\n",
        "cfg": {
          "nodes": [
            {
              "id": "ReadCsvBlock.__init___1",
              "code": "def __init__(self):\n        super().__init__(\n            id=\"acf7625e-d2cb-4941-bfeb-2819fc6fc015\",\n            input_schema=ReadCsvBlock.Input,\n            output_schema=ReadCsvBlock.Output,\n            description=\"Reads a CSV file and outputs the data as a list of dictionaries and individual rows via rows.\",\n            contributors=[ContributorDetails(name=\"Nicholas Tindle\")],\n            categories={BlockCategory.TEXT, BlockCategory.DATA},\n            test_input={\n                \"contents\": \"a, b, c\\n1,2,3\\n4,5,6\",\n            },\n            test_output=[\n                (\"row\", {\"a\": \"1\", \"b\": \"2\", \"c\": \"3\"}),\n                (\"row\", {\"a\": \"4\", \"b\": \"5\", \"c\": \"6\"}),\n                (\n                    \"all_data\",\n                    [\n                        {\"a\": \"1\", \"b\": \"2\", \"c\": \"3\"},\n                        {\"a\": \"4\", \"b\": \"5\", \"c\": \"6\"},\n                    ],\n                ),\n            ],\n        )\n"
            }
          ],
          "edges": []
        }
      },
      {
        "decl_name": "ReadCsvBlock.run",
        "start_line": 71,
        "end_line": 108,
        "children": [
          {
            "decl_name": "ReadCsvBlock.run.process_row",
            "start_line": 92,
            "end_line": 100,
            "children": [],
            "code": "        def process_row(row):\n            data = {}\n            for i, value in enumerate(row):\n                if i not in input_data.skip_columns:\n                    if input_data.has_header and header:\n                        data[header[i]] = value.strip() if input_data.strip else value\n                    else:\n                        data[str(i)] = value.strip() if input_data.strip else value\n            return data\n",
            "cfg": {
              "nodes": [
                {
                  "id": "ReadCsvBlock.run.process_row_1",
                  "code": "def process_row(row):\n            data = {}\n"
                },
                {
                  "id": "ReadCsvBlock.run.process_row_2",
                  "code": "            for i, value in enumerate(row):\n                if i not in input_data.skip_columns:\n"
                },
                {
                  "id": "ReadCsvBlock.run.process_row_3",
                  "code": "                    if input_data.has_header and header:\n                        data[header[i]] = value.strip() if input_data.strip else value\n"
                },
                {
                  "id": "ReadCsvBlock.run.process_row_4",
                  "code": "                    else:\n                        data[str(i)] = value.strip() if input_data.strip else value\n"
                },
                {
                  "id": "ReadCsvBlock.run.process_row_5",
                  "code": "            return data\n"
                }
              ],
              "edges": [
                {
                  "from": "ReadCsvBlock.run.process_row_1",
                  "to": "ReadCsvBlock.run.process_row_2"
                },
                {
                  "from": "ReadCsvBlock.run.process_row_2",
                  "to": "ReadCsvBlock.run.process_row_3"
                },
                {
                  "from": "ReadCsvBlock.run.process_row_2",
                  "to": "ReadCsvBlock.run.process_row_4"
                },
                {
                  "from": "ReadCsvBlock.run.process_row_3",
                  "to": "ReadCsvBlock.run.process_row_2"
                },
                {
                  "from": "ReadCsvBlock.run.process_row_4",
                  "to": "ReadCsvBlock.run.process_row_2"
                }
              ]
            }
          }
        ],
        "code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        import csv\n        from io import StringIO\n\n        csv_file = StringIO(input_data.contents)\n        reader = csv.reader(\n            csv_file,\n            delimiter=input_data.delimiter,\n            quotechar=input_data.quotechar,\n            escapechar=input_data.escapechar,\n        )\n\n        header = None\n        if input_data.has_header:\n            header = next(reader)\n            if input_data.strip:\n                header = [h.strip() for h in header]\n\n        for _ in range(input_data.skip_rows):\n            next(reader)\n\n\n        all_data = []\n        for row in reader:\n            processed_row = process_row(row)\n            all_data.append(processed_row)\n            yield \"row\", processed_row\n\n        yield \"all_data\", all_data\n",
        "cfg": {
          "nodes": [
            {
              "id": "ReadCsvBlock.run_1",
              "code": "def run(self, input_data: Input, **kwargs) -> BlockOutput:\n"
            },
            {
              "id": "ReadCsvBlock.run_2",
              "code": "        import csv\n        from io import StringIO\n"
            },
            {
              "id": "ReadCsvBlock.run_3",
              "code": "        csv_file = StringIO(input_data.contents)\n        reader = csv.reader(\n            csv_file,\n            delimiter=input_data.delimiter,\n            quotechar=input_data.quotechar,\n            escapechar=input_data.escapechar,\n        )\n"
            },
            {
              "id": "ReadCsvBlock.run_4",
              "code": "        header = None\n"
            },
            {
              "id": "ReadCsvBlock.run_5",
              "code": "        if input_data.has_header:\n            header = next(reader)\n            if input_data.strip:\n                header = [h.strip() for h in header]\n\n"
            },
            {
              "id": "ReadCsvBlock.run_6",
              "code": "        for _ in range(input_data.skip_rows):\n            next(reader)\n"
            },
            {
              "id": "ReadCsvBlock.run_7",
              "code": "        all_data = []\n"
            },
            {
              "id": "ReadCsvBlock.run_8",
              "code": "        for row in reader:\n            processed_row = process_row(row)\n            all_data.append(processed_row)\n            yield \"row\", processed_row\n"
            },
            {
              "id": "ReadCsvBlock.run_9",
              "code": "        yield \"all_data\", all_data\n"
            }
          ],
          "edges": [
            {
              "from": "ReadCsvBlock.run_1",
              "to": "ReadCsvBlock.run_2"
            },
            {
              "from": "ReadCsvBlock.run_2",
              "to": "ReadCsvBlock.run_3"
            },
            {
              "from": "ReadCsvBlock.run_3",
              "to": "ReadCsvBlock.run_4"
            },
            {
              "from": "ReadCsvBlock.run_4",
              "to": "ReadCsvBlock.run_5"
            },
            {
              "from": "ReadCsvBlock.run_5",
              "to": "ReadCsvBlock.run_6"
            },
            {
              "from": "ReadCsvBlock.run_6",
              "to": "ReadCsvBlock.run_7"
            },
            {
              "from": "ReadCsvBlock.run_7",
              "to": "ReadCsvBlock.run_8"
            },
            {
              "from": "ReadCsvBlock.run_8",
              "to": "ReadCsvBlock.run_9"
            }
          ]
        }
      }
    ],
    "code": "class ReadCsvBlock(Block):\n\n\n\n",
    "cfg": {
      "nodes": [
        {
          "id": "ReadCsvBlock_1",
          "code": "class ReadCsvBlock(Block):\n"
        }
      ],
      "edges": []
    }
  }
]