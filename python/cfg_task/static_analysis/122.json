{
  "nodes": [
    {
      "id": "n0",
      "type": "block",
      "statements": [
        "from collections import defaultdict",
        "from datetime import datetime, timezone",
        "from multiprocessing import Manager",
        "from typing import Any, AsyncGenerator, Generator, Generic, TypeVar",
        "from prisma.enums import AgentExecutionStatus",
        "from prisma.models import AgentGraphExecution, AgentNodeExecution, AgentNodeExecutionInputOutput",
        "from pydantic import BaseModel",
        "from backend.data.block import BlockData, BlockInput, CompletedBlockOutput",
        "from backend.data.includes import EXECUTION_RESULT_INCLUDE, GRAPH_EXECUTION_INCLUDE",
        "from backend.data.queue import AsyncRedisEventBus, RedisEventBus",
        "from backend.util import json, mock",
        "from backend.util.settings import Config",
        "class GraphExecutionEntry(BaseModel):\n    user_id: str\n    graph_exec_id: str\n    graph_id: str\n    start_node_execs: list['NodeExecutionEntry']",
        "user_id: str",
        "graph_exec_id: str",
        "graph_id: str",
        "start_node_execs: list['NodeExecutionEntry']",
        "class NodeExecutionEntry(BaseModel):\n    user_id: str\n    graph_exec_id: str\n    graph_id: str\n    node_exec_id: str\n    node_id: str\n    data: BlockInput",
        "user_id: str",
        "graph_exec_id: str",
        "graph_id: str",
        "node_exec_id: str",
        "node_id: str",
        "data: BlockInput",
        "ExecutionStatus = AgentExecutionStatus",
        "T = TypeVar('T')",
        "class ExecutionQueue(Generic[T]):\n    \"\"\"\n    Queue for managing the execution of agents.\n    This will be shared between different processes\n    \"\"\"\n\n    def __init__(self):\n        self.queue = Manager().Queue()\n\n    def add(self, execution: T) -> T:\n        self.queue.put(execution)\n        return execution\n\n    def get(self) -> T:\n        return self.queue.get()\n\n    def empty(self) -> bool:\n        return self.queue.empty()",
        "'\\n    Queue for managing the execution of agents.\\n    This will be shared between different processes\\n    '",
        "def __init__(self):\n    self.queue = Manager().Queue()",
        "self.queue = Manager().Queue()",
        "def add(self, execution: T) -> T:\n    self.queue.put(execution)\n    return execution",
        "self.queue.put(execution)",
        "return execution"
      ],
      "code": "from collections import defaultdict\nfrom datetime import datetime, timezone\nfrom multiprocessing import Manager\nfrom typing import Any, AsyncGenerator, Generator, Generic, TypeVar\nfrom prisma.enums import AgentExecutionStatus\nfrom prisma.models import AgentGraphExecution, AgentNodeExecution, AgentNodeExecutionInputOutput\nfrom pydantic import BaseModel\nfrom backend.data.block import BlockData, BlockInput, CompletedBlockOutput\nfrom backend.data.includes import EXECUTION_RESULT_INCLUDE, GRAPH_EXECUTION_INCLUDE\nfrom backend.data.queue import AsyncRedisEventBus, RedisEventBus\nfrom backend.util import json, mock\nfrom backend.util.settings import Config\nclass GraphExecutionEntry(BaseModel):\n    user_id: str\n    graph_exec_id: str\n    graph_id: str\n    start_node_execs: list['NodeExecutionEntry']\nuser_id: str\ngraph_exec_id: str\ngraph_id: str\nstart_node_execs: list['NodeExecutionEntry']\nclass NodeExecutionEntry(BaseModel):\n    user_id: str\n    graph_exec_id: str\n    graph_id: str\n    node_exec_id: str\n    node_id: str\n    data: BlockInput\nuser_id: str\ngraph_exec_id: str\ngraph_id: str\nnode_exec_id: str\nnode_id: str\ndata: BlockInput\nExecutionStatus = AgentExecutionStatus\nT = TypeVar('T')\nclass ExecutionQueue(Generic[T]):\n    \"\"\"\n    Queue for managing the execution of agents.\n    This will be shared between different processes\n    \"\"\"\n\n    def __init__(self):\n        self.queue = Manager().Queue()\n\n    def add(self, execution: T) -> T:\n        self.queue.put(execution)\n        return execution\n\n    def get(self) -> T:\n        return self.queue.get()\n\n    def empty(self) -> bool:\n        return self.queue.empty()\n'\\n    Queue for managing the execution of agents.\\n    This will be shared between different processes\\n    '\ndef __init__(self):\n    self.queue = Manager().Queue()\nself.queue = Manager().Queue()\ndef add(self, execution: T) -> T:\n    self.queue.put(execution)\n    return execution\nself.queue.put(execution)\nreturn execution"
    },
    {
      "id": "n1",
      "type": "block",
      "statements": [
        "def get(self) -> T:\n    return self.queue.get()",
        "return self.queue.get()"
      ],
      "code": "def get(self) -> T:\n    return self.queue.get()\nreturn self.queue.get()"
    },
    {
      "id": "n2",
      "type": "block",
      "statements": [
        "def empty(self) -> bool:\n    return self.queue.empty()",
        "return self.queue.empty()"
      ],
      "code": "def empty(self) -> bool:\n    return self.queue.empty()\nreturn self.queue.empty()"
    },
    {
      "id": "n3",
      "type": "block",
      "statements": [
        "class ExecutionResult(BaseModel):\n    graph_id: str\n    graph_version: int\n    graph_exec_id: str\n    node_exec_id: str\n    node_id: str\n    block_id: str\n    status: ExecutionStatus\n    input_data: BlockInput\n    output_data: CompletedBlockOutput\n    add_time: datetime\n    queue_time: datetime | None\n    start_time: datetime | None\n    end_time: datetime | None\n\n    @staticmethod\n    def from_graph(graph: AgentGraphExecution):\n        return ExecutionResult(graph_id=graph.agentGraphId, graph_version=graph.agentGraphVersion, graph_exec_id=graph.id, node_exec_id='', node_id='', block_id='', status=graph.executionStatus, input_data={}, output_data={}, add_time=graph.createdAt, queue_time=graph.createdAt, start_time=graph.startedAt, end_time=graph.updatedAt)\n\n    @staticmethod\n    def from_db(execution: AgentNodeExecution):\n        if execution.executionData:\n            input_data = json.loads(execution.executionData, target_type=dict[str, Any])\n        else:\n            input_data: BlockInput = defaultdict()\n            for data in execution.Input or []:\n                input_data[data.name] = json.loads(data.data)\n        output_data: CompletedBlockOutput = defaultdict(list)\n        for data in execution.Output or []:\n            output_data[data.name].append(json.loads(data.data))\n        graph_execution: AgentGraphExecution | None = execution.AgentGraphExecution\n        return ExecutionResult(graph_id=graph_execution.agentGraphId if graph_execution else '', graph_version=graph_execution.agentGraphVersion if graph_execution else 0, graph_exec_id=execution.agentGraphExecutionId, block_id=execution.AgentNode.agentBlockId if execution.AgentNode else '', node_exec_id=execution.id, node_id=execution.agentNodeId, status=execution.executionStatus, input_data=input_data, output_data=output_data, add_time=execution.addedTime, queue_time=execution.queuedTime, start_time=execution.startedTime, end_time=execution.endedTime)",
        "graph_id: str",
        "graph_version: int",
        "graph_exec_id: str",
        "node_exec_id: str",
        "node_id: str",
        "block_id: str",
        "status: ExecutionStatus",
        "input_data: BlockInput",
        "output_data: CompletedBlockOutput",
        "add_time: datetime",
        "queue_time: datetime | None",
        "start_time: datetime | None",
        "end_time: datetime | None",
        "@staticmethod\ndef from_graph(graph: AgentGraphExecution):\n    return ExecutionResult(graph_id=graph.agentGraphId, graph_version=graph.agentGraphVersion, graph_exec_id=graph.id, node_exec_id='', node_id='', block_id='', status=graph.executionStatus, input_data={}, output_data={}, add_time=graph.createdAt, queue_time=graph.createdAt, start_time=graph.startedAt, end_time=graph.updatedAt)",
        "return ExecutionResult(graph_id=graph.agentGraphId, graph_version=graph.agentGraphVersion, graph_exec_id=graph.id, node_exec_id='', node_id='', block_id='', status=graph.executionStatus, input_data={}, output_data={}, add_time=graph.createdAt, queue_time=graph.createdAt, start_time=graph.startedAt, end_time=graph.updatedAt)"
      ],
      "code": "class ExecutionResult(BaseModel):\n    graph_id: str\n    graph_version: int\n    graph_exec_id: str\n    node_exec_id: str\n    node_id: str\n    block_id: str\n    status: ExecutionStatus\n    input_data: BlockInput\n    output_data: CompletedBlockOutput\n    add_time: datetime\n    queue_time: datetime | None\n    start_time: datetime | None\n    end_time: datetime | None\n\n    @staticmethod\n    def from_graph(graph: AgentGraphExecution):\n        return ExecutionResult(graph_id=graph.agentGraphId, graph_version=graph.agentGraphVersion, graph_exec_id=graph.id, node_exec_id='', node_id='', block_id='', status=graph.executionStatus, input_data={}, output_data={}, add_time=graph.createdAt, queue_time=graph.createdAt, start_time=graph.startedAt, end_time=graph.updatedAt)\n\n    @staticmethod\n    def from_db(execution: AgentNodeExecution):\n        if execution.executionData:\n            input_data = json.loads(execution.executionData, target_type=dict[str, Any])\n        else:\n            input_data: BlockInput = defaultdict()\n            for data in execution.Input or []:\n                input_data[data.name] = json.loads(data.data)\n        output_data: CompletedBlockOutput = defaultdict(list)\n        for data in execution.Output or []:\n            output_data[data.name].append(json.loads(data.data))\n        graph_execution: AgentGraphExecution | None = execution.AgentGraphExecution\n        return ExecutionResult(graph_id=graph_execution.agentGraphId if graph_execution else '', graph_version=graph_execution.agentGraphVersion if graph_execution else 0, graph_exec_id=execution.agentGraphExecutionId, block_id=execution.AgentNode.agentBlockId if execution.AgentNode else '', node_exec_id=execution.id, node_id=execution.agentNodeId, status=execution.executionStatus, input_data=input_data, output_data=output_data, add_time=execution.addedTime, queue_time=execution.queuedTime, start_time=execution.startedTime, end_time=execution.endedTime)\ngraph_id: str\ngraph_version: int\ngraph_exec_id: str\nnode_exec_id: str\nnode_id: str\nblock_id: str\nstatus: ExecutionStatus\ninput_data: BlockInput\noutput_data: CompletedBlockOutput\nadd_time: datetime\nqueue_time: datetime | None\nstart_time: datetime | None\nend_time: datetime | None\n@staticmethod\ndef from_graph(graph: AgentGraphExecution):\n    return ExecutionResult(graph_id=graph.agentGraphId, graph_version=graph.agentGraphVersion, graph_exec_id=graph.id, node_exec_id='', node_id='', block_id='', status=graph.executionStatus, input_data={}, output_data={}, add_time=graph.createdAt, queue_time=graph.createdAt, start_time=graph.startedAt, end_time=graph.updatedAt)\nreturn ExecutionResult(graph_id=graph.agentGraphId, graph_version=graph.agentGraphVersion, graph_exec_id=graph.id, node_exec_id='', node_id='', block_id='', status=graph.executionStatus, input_data={}, output_data={}, add_time=graph.createdAt, queue_time=graph.createdAt, start_time=graph.startedAt, end_time=graph.updatedAt)"
    },
    {
      "id": "n4",
      "type": "block",
      "statements": [
        "@staticmethod\ndef from_db(execution: AgentNodeExecution):\n    if execution.executionData:\n        input_data = json.loads(execution.executionData, target_type=dict[str, Any])\n    else:\n        input_data: BlockInput = defaultdict()\n        for data in execution.Input or []:\n            input_data[data.name] = json.loads(data.data)\n    output_data: CompletedBlockOutput = defaultdict(list)\n    for data in execution.Output or []:\n        output_data[data.name].append(json.loads(data.data))\n    graph_execution: AgentGraphExecution | None = execution.AgentGraphExecution\n    return ExecutionResult(graph_id=graph_execution.agentGraphId if graph_execution else '', graph_version=graph_execution.agentGraphVersion if graph_execution else 0, graph_exec_id=execution.agentGraphExecutionId, block_id=execution.AgentNode.agentBlockId if execution.AgentNode else '', node_exec_id=execution.id, node_id=execution.agentNodeId, status=execution.executionStatus, input_data=input_data, output_data=output_data, add_time=execution.addedTime, queue_time=execution.queuedTime, start_time=execution.startedTime, end_time=execution.endedTime)",
        "execution.executionData"
      ],
      "code": "@staticmethod\ndef from_db(execution: AgentNodeExecution):\n    if execution.executionData:\n        input_data = json.loads(execution.executionData, target_type=dict[str, Any])\n    else:\n        input_data: BlockInput = defaultdict()\n        for data in execution.Input or []:\n            input_data[data.name] = json.loads(data.data)\n    output_data: CompletedBlockOutput = defaultdict(list)\n    for data in execution.Output or []:\n        output_data[data.name].append(json.loads(data.data))\n    graph_execution: AgentGraphExecution | None = execution.AgentGraphExecution\n    return ExecutionResult(graph_id=graph_execution.agentGraphId if graph_execution else '', graph_version=graph_execution.agentGraphVersion if graph_execution else 0, graph_exec_id=execution.agentGraphExecutionId, block_id=execution.AgentNode.agentBlockId if execution.AgentNode else '', node_exec_id=execution.id, node_id=execution.agentNodeId, status=execution.executionStatus, input_data=input_data, output_data=output_data, add_time=execution.addedTime, queue_time=execution.queuedTime, start_time=execution.startedTime, end_time=execution.endedTime)\nexecution.executionData"
    },
    {
      "id": "n5",
      "type": "block",
      "statements": [
        "input_data = json.loads(execution.executionData, target_type=dict[str, Any])"
      ],
      "code": "input_data = json.loads(execution.executionData, target_type=dict[str, Any])"
    },
    {
      "id": "n6",
      "type": "block",
      "statements": [
        "input_data: BlockInput = defaultdict()"
      ],
      "code": "input_data: BlockInput = defaultdict()"
    },
    {
      "id": "n7",
      "type": "block",
      "statements": [
        "output_data: CompletedBlockOutput = defaultdict(list)"
      ],
      "code": "output_data: CompletedBlockOutput = defaultdict(list)"
    },
    {
      "id": "n8",
      "type": "block",
      "statements": [
        "data",
        "execution.Input or []"
      ],
      "code": "data\nexecution.Input or []"
    },
    {
      "id": "n9",
      "type": "block",
      "statements": [
        "input_data[data.name] = json.loads(data.data)"
      ],
      "code": "input_data[data.name] = json.loads(data.data)"
    },
    {
      "id": "n10",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n11",
      "type": "block",
      "statements": [
        "data",
        "execution.Output or []"
      ],
      "code": "data\nexecution.Output or []"
    },
    {
      "id": "n12",
      "type": "block",
      "statements": [
        "output_data[data.name].append(json.loads(data.data))"
      ],
      "code": "output_data[data.name].append(json.loads(data.data))"
    },
    {
      "id": "n13",
      "type": "block",
      "statements": [
        "graph_execution: AgentGraphExecution | None = execution.AgentGraphExecution",
        "return ExecutionResult(graph_id=graph_execution.agentGraphId if graph_execution else '', graph_version=graph_execution.agentGraphVersion if graph_execution else 0, graph_exec_id=execution.agentGraphExecutionId, block_id=execution.AgentNode.agentBlockId if execution.AgentNode else '', node_exec_id=execution.id, node_id=execution.agentNodeId, status=execution.executionStatus, input_data=input_data, output_data=output_data, add_time=execution.addedTime, queue_time=execution.queuedTime, start_time=execution.startedTime, end_time=execution.endedTime)"
      ],
      "code": "graph_execution: AgentGraphExecution | None = execution.AgentGraphExecution\nreturn ExecutionResult(graph_id=graph_execution.agentGraphId if graph_execution else '', graph_version=graph_execution.agentGraphVersion if graph_execution else 0, graph_exec_id=execution.agentGraphExecutionId, block_id=execution.AgentNode.agentBlockId if execution.AgentNode else '', node_exec_id=execution.id, node_id=execution.agentNodeId, status=execution.executionStatus, input_data=input_data, output_data=output_data, add_time=execution.addedTime, queue_time=execution.queuedTime, start_time=execution.startedTime, end_time=execution.endedTime)"
    },
    {
      "id": "n14",
      "type": "block",
      "statements": [
        "async def create_graph_execution(graph_id: str, graph_version: int, nodes_input: list[tuple[str, BlockInput]], user_id: str) -> tuple[str, list[ExecutionResult]]:\n    \"\"\"\n    Create a new AgentGraphExecution record.\n    Returns:\n        The id of the AgentGraphExecution and the list of ExecutionResult for each node.\n    \"\"\"\n    result = await AgentGraphExecution.prisma().create(data={'agentGraphId': graph_id, 'agentGraphVersion': graph_version, 'executionStatus': ExecutionStatus.QUEUED, 'AgentNodeExecutions': {'create': [{'agentNodeId': node_id, 'executionStatus': ExecutionStatus.INCOMPLETE, 'Input': {'create': [{'name': name, 'data': json.dumps(data)} for (name, data) in node_input.items()]}} for (node_id, node_input) in nodes_input]}, 'userId': user_id}, include=GRAPH_EXECUTION_INCLUDE)\n    return (result.id, [ExecutionResult.from_db(execution) for execution in result.AgentNodeExecutions or []])",
        "'\\n    Create a new AgentGraphExecution record.\\n    Returns:\\n        The id of the AgentGraphExecution and the list of ExecutionResult for each node.\\n    '",
        "result = await AgentGraphExecution.prisma().create(data={'agentGraphId': graph_id, 'agentGraphVersion': graph_version, 'executionStatus': ExecutionStatus.QUEUED, 'AgentNodeExecutions': {'create': [{'agentNodeId': node_id, 'executionStatus': ExecutionStatus.INCOMPLETE, 'Input': {'create': [{'name': name, 'data': json.dumps(data)} for (name, data) in node_input.items()]}} for (node_id, node_input) in nodes_input]}, 'userId': user_id}, include=GRAPH_EXECUTION_INCLUDE)",
        "return (result.id, [ExecutionResult.from_db(execution) for execution in result.AgentNodeExecutions or []])"
      ],
      "code": "async def create_graph_execution(graph_id: str, graph_version: int, nodes_input: list[tuple[str, BlockInput]], user_id: str) -> tuple[str, list[ExecutionResult]]:\n    \"\"\"\n    Create a new AgentGraphExecution record.\n    Returns:\n        The id of the AgentGraphExecution and the list of ExecutionResult for each node.\n    \"\"\"\n    result = await AgentGraphExecution.prisma().create(data={'agentGraphId': graph_id, 'agentGraphVersion': graph_version, 'executionStatus': ExecutionStatus.QUEUED, 'AgentNodeExecutions': {'create': [{'agentNodeId': node_id, 'executionStatus': ExecutionStatus.INCOMPLETE, 'Input': {'create': [{'name': name, 'data': json.dumps(data)} for (name, data) in node_input.items()]}} for (node_id, node_input) in nodes_input]}, 'userId': user_id}, include=GRAPH_EXECUTION_INCLUDE)\n    return (result.id, [ExecutionResult.from_db(execution) for execution in result.AgentNodeExecutions or []])\n'\\n    Create a new AgentGraphExecution record.\\n    Returns:\\n        The id of the AgentGraphExecution and the list of ExecutionResult for each node.\\n    '\nresult = await AgentGraphExecution.prisma().create(data={'agentGraphId': graph_id, 'agentGraphVersion': graph_version, 'executionStatus': ExecutionStatus.QUEUED, 'AgentNodeExecutions': {'create': [{'agentNodeId': node_id, 'executionStatus': ExecutionStatus.INCOMPLETE, 'Input': {'create': [{'name': name, 'data': json.dumps(data)} for (name, data) in node_input.items()]}} for (node_id, node_input) in nodes_input]}, 'userId': user_id}, include=GRAPH_EXECUTION_INCLUDE)\nreturn (result.id, [ExecutionResult.from_db(execution) for execution in result.AgentNodeExecutions or []])"
    },
    {
      "id": "n15",
      "type": "block",
      "statements": [
        "async def upsert_execution_input(node_id: str, graph_exec_id: str, input_name: str, input_data: Any, node_exec_id: str | None=None) -> tuple[str, BlockInput]:\n    \"\"\"\n    Insert AgentNodeExecutionInputOutput record for as one of AgentNodeExecution.Input.\n    If there is no AgentNodeExecution that has no `input_name` as input, create new one.\n\n    Args:\n        node_id: The id of the AgentNode.\n        graph_exec_id: The id of the AgentGraphExecution.\n        input_name: The name of the input data.\n        input_data: The input data to be inserted.\n        node_exec_id: [Optional] The id of the AgentNodeExecution that has no `input_name` as input. If not provided, it will find the eligible incomplete AgentNodeExecution or create a new one.\n\n    Returns:\n        * The id of the created or existing AgentNodeExecution.\n        * Dict of node input data, key is the input name, value is the input data.\n    \"\"\"\n    existing_execution = await AgentNodeExecution.prisma().find_first(where={**({'id': node_exec_id} if node_exec_id else {}), 'agentNodeId': node_id, 'agentGraphExecutionId': graph_exec_id, 'executionStatus': ExecutionStatus.INCOMPLETE, 'Input': {'every': {'name': {'not': input_name}}}}, order={'addedTime': 'asc'}, include={'Input': True})\n    json_input_data = json.dumps(input_data)\n    if existing_execution:\n        await AgentNodeExecutionInputOutput.prisma().create(data={'name': input_name, 'data': json_input_data, 'referencedByInputExecId': existing_execution.id})\n        return (existing_execution.id, {**{input_data.name: json.loads(input_data.data) for input_data in existing_execution.Input or []}, input_name: input_data})\n    elif not node_exec_id:\n        result = await AgentNodeExecution.prisma().create(data={'agentNodeId': node_id, 'agentGraphExecutionId': graph_exec_id, 'executionStatus': ExecutionStatus.INCOMPLETE, 'Input': {'create': {'name': input_name, 'data': json_input_data}}})\n        return (result.id, {input_name: input_data})\n    else:\n        raise ValueError(f'NodeExecution {node_exec_id} not found or already has input {input_name}.')",
        "'\\n    Insert AgentNodeExecutionInputOutput record for as one of AgentNodeExecution.Input.\\n    If there is no AgentNodeExecution that has no `input_name` as input, create new one.\\n\\n    Args:\\n        node_id: The id of the AgentNode.\\n        graph_exec_id: The id of the AgentGraphExecution.\\n        input_name: The name of the input data.\\n        input_data: The input data to be inserted.\\n        node_exec_id: [Optional] The id of the AgentNodeExecution that has no `input_name` as input. If not provided, it will find the eligible incomplete AgentNodeExecution or create a new one.\\n\\n    Returns:\\n        * The id of the created or existing AgentNodeExecution.\\n        * Dict of node input data, key is the input name, value is the input data.\\n    '",
        "existing_execution = await AgentNodeExecution.prisma().find_first(where={**({'id': node_exec_id} if node_exec_id else {}), 'agentNodeId': node_id, 'agentGraphExecutionId': graph_exec_id, 'executionStatus': ExecutionStatus.INCOMPLETE, 'Input': {'every': {'name': {'not': input_name}}}}, order={'addedTime': 'asc'}, include={'Input': True})",
        "json_input_data = json.dumps(input_data)",
        "existing_execution"
      ],
      "code": "async def upsert_execution_input(node_id: str, graph_exec_id: str, input_name: str, input_data: Any, node_exec_id: str | None=None) -> tuple[str, BlockInput]:\n    \"\"\"\n    Insert AgentNodeExecutionInputOutput record for as one of AgentNodeExecution.Input.\n    If there is no AgentNodeExecution that has no `input_name` as input, create new one.\n\n    Args:\n        node_id: The id of the AgentNode.\n        graph_exec_id: The id of the AgentGraphExecution.\n        input_name: The name of the input data.\n        input_data: The input data to be inserted.\n        node_exec_id: [Optional] The id of the AgentNodeExecution that has no `input_name` as input. If not provided, it will find the eligible incomplete AgentNodeExecution or create a new one.\n\n    Returns:\n        * The id of the created or existing AgentNodeExecution.\n        * Dict of node input data, key is the input name, value is the input data.\n    \"\"\"\n    existing_execution = await AgentNodeExecution.prisma().find_first(where={**({'id': node_exec_id} if node_exec_id else {}), 'agentNodeId': node_id, 'agentGraphExecutionId': graph_exec_id, 'executionStatus': ExecutionStatus.INCOMPLETE, 'Input': {'every': {'name': {'not': input_name}}}}, order={'addedTime': 'asc'}, include={'Input': True})\n    json_input_data = json.dumps(input_data)\n    if existing_execution:\n        await AgentNodeExecutionInputOutput.prisma().create(data={'name': input_name, 'data': json_input_data, 'referencedByInputExecId': existing_execution.id})\n        return (existing_execution.id, {**{input_data.name: json.loads(input_data.data) for input_data in existing_execution.Input or []}, input_name: input_data})\n    elif not node_exec_id:\n        result = await AgentNodeExecution.prisma().create(data={'agentNodeId': node_id, 'agentGraphExecutionId': graph_exec_id, 'executionStatus': ExecutionStatus.INCOMPLETE, 'Input': {'create': {'name': input_name, 'data': json_input_data}}})\n        return (result.id, {input_name: input_data})\n    else:\n        raise ValueError(f'NodeExecution {node_exec_id} not found or already has input {input_name}.')\n'\\n    Insert AgentNodeExecutionInputOutput record for as one of AgentNodeExecution.Input.\\n    If there is no AgentNodeExecution that has no `input_name` as input, create new one.\\n\\n    Args:\\n        node_id: The id of the AgentNode.\\n        graph_exec_id: The id of the AgentGraphExecution.\\n        input_name: The name of the input data.\\n        input_data: The input data to be inserted.\\n        node_exec_id: [Optional] The id of the AgentNodeExecution that has no `input_name` as input. If not provided, it will find the eligible incomplete AgentNodeExecution or create a new one.\\n\\n    Returns:\\n        * The id of the created or existing AgentNodeExecution.\\n        * Dict of node input data, key is the input name, value is the input data.\\n    '\nexisting_execution = await AgentNodeExecution.prisma().find_first(where={**({'id': node_exec_id} if node_exec_id else {}), 'agentNodeId': node_id, 'agentGraphExecutionId': graph_exec_id, 'executionStatus': ExecutionStatus.INCOMPLETE, 'Input': {'every': {'name': {'not': input_name}}}}, order={'addedTime': 'asc'}, include={'Input': True})\njson_input_data = json.dumps(input_data)\nexisting_execution"
    },
    {
      "id": "n16",
      "type": "block",
      "statements": [
        "await AgentNodeExecutionInputOutput.prisma().create(data={'name': input_name, 'data': json_input_data, 'referencedByInputExecId': existing_execution.id})",
        "return (existing_execution.id, {**{input_data.name: json.loads(input_data.data) for input_data in existing_execution.Input or []}, input_name: input_data})"
      ],
      "code": "await AgentNodeExecutionInputOutput.prisma().create(data={'name': input_name, 'data': json_input_data, 'referencedByInputExecId': existing_execution.id})\nreturn (existing_execution.id, {**{input_data.name: json.loads(input_data.data) for input_data in existing_execution.Input or []}, input_name: input_data})"
    },
    {
      "id": "n17",
      "type": "block",
      "statements": [
        "not node_exec_id"
      ],
      "code": "not node_exec_id"
    },
    {
      "id": "n18",
      "type": "block",
      "statements": [
        "async def upsert_execution_output(node_exec_id: str, output_name: str, output_data: Any) -> None:\n    \"\"\"\n    Insert AgentNodeExecutionInputOutput record for as one of AgentNodeExecution.Output.\n    \"\"\"\n    await AgentNodeExecutionInputOutput.prisma().create(data={'name': output_name, 'data': json.dumps(output_data), 'referencedByOutputExecId': node_exec_id})",
        "'\\n    Insert AgentNodeExecutionInputOutput record for as one of AgentNodeExecution.Output.\\n    '",
        "await AgentNodeExecutionInputOutput.prisma().create(data={'name': output_name, 'data': json.dumps(output_data), 'referencedByOutputExecId': node_exec_id})",
        "async def update_graph_execution_start_time(graph_exec_id: str):\n    await AgentGraphExecution.prisma().update(where={'id': graph_exec_id}, data={'executionStatus': ExecutionStatus.RUNNING, 'startedAt': datetime.now(tz=timezone.utc)})",
        "await AgentGraphExecution.prisma().update(where={'id': graph_exec_id}, data={'executionStatus': ExecutionStatus.RUNNING, 'startedAt': datetime.now(tz=timezone.utc)})",
        "async def update_graph_execution_stats(graph_exec_id: str, stats: dict[str, Any]) -> ExecutionResult:\n    status = ExecutionStatus.FAILED if stats.get('error') else ExecutionStatus.COMPLETED\n    res = await AgentGraphExecution.prisma().update(where={'id': graph_exec_id}, data={'executionStatus': status, 'stats': json.dumps(stats)})\n    if not res:\n        raise ValueError(f'Execution {graph_exec_id} not found.')\n    return ExecutionResult.from_graph(res)",
        "status = ExecutionStatus.FAILED if stats.get('error') else ExecutionStatus.COMPLETED",
        "res = await AgentGraphExecution.prisma().update(where={'id': graph_exec_id}, data={'executionStatus': status, 'stats': json.dumps(stats)})",
        "not res"
      ],
      "code": "async def upsert_execution_output(node_exec_id: str, output_name: str, output_data: Any) -> None:\n    \"\"\"\n    Insert AgentNodeExecutionInputOutput record for as one of AgentNodeExecution.Output.\n    \"\"\"\n    await AgentNodeExecutionInputOutput.prisma().create(data={'name': output_name, 'data': json.dumps(output_data), 'referencedByOutputExecId': node_exec_id})\n'\\n    Insert AgentNodeExecutionInputOutput record for as one of AgentNodeExecution.Output.\\n    '\nawait AgentNodeExecutionInputOutput.prisma().create(data={'name': output_name, 'data': json.dumps(output_data), 'referencedByOutputExecId': node_exec_id})\nasync def update_graph_execution_start_time(graph_exec_id: str):\n    await AgentGraphExecution.prisma().update(where={'id': graph_exec_id}, data={'executionStatus': ExecutionStatus.RUNNING, 'startedAt': datetime.now(tz=timezone.utc)})\nawait AgentGraphExecution.prisma().update(where={'id': graph_exec_id}, data={'executionStatus': ExecutionStatus.RUNNING, 'startedAt': datetime.now(tz=timezone.utc)})\nasync def update_graph_execution_stats(graph_exec_id: str, stats: dict[str, Any]) -> ExecutionResult:\n    status = ExecutionStatus.FAILED if stats.get('error') else ExecutionStatus.COMPLETED\n    res = await AgentGraphExecution.prisma().update(where={'id': graph_exec_id}, data={'executionStatus': status, 'stats': json.dumps(stats)})\n    if not res:\n        raise ValueError(f'Execution {graph_exec_id} not found.')\n    return ExecutionResult.from_graph(res)\nstatus = ExecutionStatus.FAILED if stats.get('error') else ExecutionStatus.COMPLETED\nres = await AgentGraphExecution.prisma().update(where={'id': graph_exec_id}, data={'executionStatus': status, 'stats': json.dumps(stats)})\nnot res"
    },
    {
      "id": "n19",
      "type": "block",
      "statements": [
        "result = await AgentNodeExecution.prisma().create(data={'agentNodeId': node_id, 'agentGraphExecutionId': graph_exec_id, 'executionStatus': ExecutionStatus.INCOMPLETE, 'Input': {'create': {'name': input_name, 'data': json_input_data}}})",
        "return (result.id, {input_name: input_data})"
      ],
      "code": "result = await AgentNodeExecution.prisma().create(data={'agentNodeId': node_id, 'agentGraphExecutionId': graph_exec_id, 'executionStatus': ExecutionStatus.INCOMPLETE, 'Input': {'create': {'name': input_name, 'data': json_input_data}}})\nreturn (result.id, {input_name: input_data})"
    },
    {
      "id": "n20",
      "type": "block",
      "statements": [
        "raise ValueError(f'NodeExecution {node_exec_id} not found or already has input {input_name}.')"
      ],
      "code": "raise ValueError(f'NodeExecution {node_exec_id} not found or already has input {input_name}.')\n"
    },
    {
      "id": "n21",
      "type": "block",
      "statements": [
        "raise ValueError(f'Execution {graph_exec_id} not found.')"
      ],
      "code": "raise ValueError(f'Execution {graph_exec_id} not found.')"
    },
    {
      "id": "n22",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n23",
      "type": "block",
      "statements": [
        "return ExecutionResult.from_graph(res)"
      ],
      "code": "return ExecutionResult.from_graph(res)"
    },
    {
      "id": "n24",
      "type": "block",
      "statements": [
        "async def update_node_execution_stats(node_exec_id: str, stats: dict[str, Any]):\n    await AgentNodeExecution.prisma().update(where={'id': node_exec_id}, data={'stats': json.dumps(stats)})",
        "await AgentNodeExecution.prisma().update(where={'id': node_exec_id}, data={'stats': json.dumps(stats)})",
        "async def update_execution_status(node_exec_id: str, status: ExecutionStatus, execution_data: BlockInput | None=None, stats: dict[str, Any] | None=None) -> ExecutionResult:\n    if status == ExecutionStatus.QUEUED and execution_data is None:\n        raise ValueError('Execution data must be provided when queuing an execution.')\n    now = datetime.now(tz=timezone.utc)\n    data = {**{'executionStatus': status}, **({'queuedTime': now} if status == ExecutionStatus.QUEUED else {}), **({'startedTime': now} if status == ExecutionStatus.RUNNING else {}), **({'endedTime': now} if status == ExecutionStatus.FAILED else {}), **({'endedTime': now} if status == ExecutionStatus.COMPLETED else {}), **({'executionData': json.dumps(execution_data)} if execution_data else {}), **({'stats': json.dumps(stats)} if stats else {})}\n    res = await AgentNodeExecution.prisma().update(where={'id': node_exec_id}, data=data, include=EXECUTION_RESULT_INCLUDE)\n    if not res:\n        raise ValueError(f'Execution {node_exec_id} not found.')\n    return ExecutionResult.from_db(res)",
        "status == ExecutionStatus.QUEUED and execution_data is None"
      ],
      "code": "async def update_node_execution_stats(node_exec_id: str, stats: dict[str, Any]):\n    await AgentNodeExecution.prisma().update(where={'id': node_exec_id}, data={'stats': json.dumps(stats)})\nawait AgentNodeExecution.prisma().update(where={'id': node_exec_id}, data={'stats': json.dumps(stats)})\nasync def update_execution_status(node_exec_id: str, status: ExecutionStatus, execution_data: BlockInput | None=None, stats: dict[str, Any] | None=None) -> ExecutionResult:\n    if status == ExecutionStatus.QUEUED and execution_data is None:\n        raise ValueError('Execution data must be provided when queuing an execution.')\n    now = datetime.now(tz=timezone.utc)\n    data = {**{'executionStatus': status}, **({'queuedTime': now} if status == ExecutionStatus.QUEUED else {}), **({'startedTime': now} if status == ExecutionStatus.RUNNING else {}), **({'endedTime': now} if status == ExecutionStatus.FAILED else {}), **({'endedTime': now} if status == ExecutionStatus.COMPLETED else {}), **({'executionData': json.dumps(execution_data)} if execution_data else {}), **({'stats': json.dumps(stats)} if stats else {})}\n    res = await AgentNodeExecution.prisma().update(where={'id': node_exec_id}, data=data, include=EXECUTION_RESULT_INCLUDE)\n    if not res:\n        raise ValueError(f'Execution {node_exec_id} not found.')\n    return ExecutionResult.from_db(res)\nstatus == ExecutionStatus.QUEUED and execution_data is None"
    },
    {
      "id": "n25",
      "type": "block",
      "statements": [
        "raise ValueError('Execution data must be provided when queuing an execution.')"
      ],
      "code": "raise ValueError('Execution data must be provided when queuing an execution.')"
    },
    {
      "id": "n26",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n27",
      "type": "block",
      "statements": [
        "now = datetime.now(tz=timezone.utc)",
        "data = {**{'executionStatus': status}, **({'queuedTime': now} if status == ExecutionStatus.QUEUED else {}), **({'startedTime': now} if status == ExecutionStatus.RUNNING else {}), **({'endedTime': now} if status == ExecutionStatus.FAILED else {}), **({'endedTime': now} if status == ExecutionStatus.COMPLETED else {}), **({'executionData': json.dumps(execution_data)} if execution_data else {}), **({'stats': json.dumps(stats)} if stats else {})}",
        "res = await AgentNodeExecution.prisma().update(where={'id': node_exec_id}, data=data, include=EXECUTION_RESULT_INCLUDE)",
        "not res"
      ],
      "code": "now = datetime.now(tz=timezone.utc)\ndata = {**{'executionStatus': status}, **({'queuedTime': now} if status == ExecutionStatus.QUEUED else {}), **({'startedTime': now} if status == ExecutionStatus.RUNNING else {}), **({'endedTime': now} if status == ExecutionStatus.FAILED else {}), **({'endedTime': now} if status == ExecutionStatus.COMPLETED else {}), **({'executionData': json.dumps(execution_data)} if execution_data else {}), **({'stats': json.dumps(stats)} if stats else {})}\nres = await AgentNodeExecution.prisma().update(where={'id': node_exec_id}, data=data, include=EXECUTION_RESULT_INCLUDE)\nnot res"
    },
    {
      "id": "n28",
      "type": "block",
      "statements": [
        "raise ValueError(f'Execution {node_exec_id} not found.')"
      ],
      "code": "raise ValueError(f'Execution {node_exec_id} not found.')"
    },
    {
      "id": "n29",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n30",
      "type": "block",
      "statements": [
        "return ExecutionResult.from_db(res)"
      ],
      "code": "return ExecutionResult.from_db(res)"
    },
    {
      "id": "n31",
      "type": "block",
      "statements": [
        "async def get_execution_results(graph_exec_id: str) -> list[ExecutionResult]:\n    executions = await AgentNodeExecution.prisma().find_many(where={'agentGraphExecutionId': graph_exec_id}, include=EXECUTION_RESULT_INCLUDE, order=[{'queuedTime': 'asc'}, {'addedTime': 'asc'}])\n    res = [ExecutionResult.from_db(execution) for execution in executions]\n    return res",
        "executions = await AgentNodeExecution.prisma().find_many(where={'agentGraphExecutionId': graph_exec_id}, include=EXECUTION_RESULT_INCLUDE, order=[{'queuedTime': 'asc'}, {'addedTime': 'asc'}])",
        "res = [ExecutionResult.from_db(execution) for execution in executions]",
        "return res"
      ],
      "code": "async def get_execution_results(graph_exec_id: str) -> list[ExecutionResult]:\n    executions = await AgentNodeExecution.prisma().find_many(where={'agentGraphExecutionId': graph_exec_id}, include=EXECUTION_RESULT_INCLUDE, order=[{'queuedTime': 'asc'}, {'addedTime': 'asc'}])\n    res = [ExecutionResult.from_db(execution) for execution in executions]\n    return res\nexecutions = await AgentNodeExecution.prisma().find_many(where={'agentGraphExecutionId': graph_exec_id}, include=EXECUTION_RESULT_INCLUDE, order=[{'queuedTime': 'asc'}, {'addedTime': 'asc'}])\nres = [ExecutionResult.from_db(execution) for execution in executions]\nreturn res"
    },
    {
      "id": "n32",
      "type": "block",
      "statements": [
        "LIST_SPLIT = '_$_'",
        "DICT_SPLIT = '_#_'",
        "OBJC_SPLIT = '_@_'",
        "def parse_execution_output(output: BlockData, name: str) -> Any | None:\n    (output_name, output_data) = output\n    if name == output_name:\n        return output_data\n    if name.startswith(f'{output_name}{LIST_SPLIT}'):\n        index = int(name.split(LIST_SPLIT)[1])\n        if not isinstance(output_data, list) or len(output_data) <= index:\n            return None\n        return output_data[int(name.split(LIST_SPLIT)[1])]\n    if name.startswith(f'{output_name}{DICT_SPLIT}'):\n        index = name.split(DICT_SPLIT)[1]\n        if not isinstance(output_data, dict) or index not in output_data:\n            return None\n        return output_data[index]\n    if name.startswith(f'{output_name}{OBJC_SPLIT}'):\n        index = name.split(OBJC_SPLIT)[1]\n        if isinstance(output_data, object) and hasattr(output_data, index):\n            return getattr(output_data, index)\n        return None\n    return None",
        "(output_name, output_data) = output",
        "name Eq output_name"
      ],
      "code": "LIST_SPLIT = '_$_'\nDICT_SPLIT = '_#_'\nOBJC_SPLIT = '_@_'\ndef parse_execution_output(output: BlockData, name: str) -> Any | None:\n    (output_name, output_data) = output\n    if name == output_name:\n        return output_data\n    if name.startswith(f'{output_name}{LIST_SPLIT}'):\n        index = int(name.split(LIST_SPLIT)[1])\n        if not isinstance(output_data, list) or len(output_data) <= index:\n            return None\n        return output_data[int(name.split(LIST_SPLIT)[1])]\n    if name.startswith(f'{output_name}{DICT_SPLIT}'):\n        index = name.split(DICT_SPLIT)[1]\n        if not isinstance(output_data, dict) or index not in output_data:\n            return None\n        return output_data[index]\n    if name.startswith(f'{output_name}{OBJC_SPLIT}'):\n        index = name.split(OBJC_SPLIT)[1]\n        if isinstance(output_data, object) and hasattr(output_data, index):\n            return getattr(output_data, index)\n        return None\n    return None\n(output_name, output_data) = output\nname Eq output_name"
    },
    {
      "id": "n33",
      "type": "block",
      "statements": [
        "return output_data"
      ],
      "code": "return output_data"
    },
    {
      "id": "n34",
      "type": "block",
      "statements": [],
      "code": "\nname.startswith(f'{output_name}{LIST_SPLIT}')"
    },
    {
      "id": "n35",
      "type": "block",
      "statements": [
        "index = int(name.split(LIST_SPLIT)[1])",
        "not isinstance(output_data, list) or len(output_data) <= index"
      ],
      "code": "index = int(name.split(LIST_SPLIT)[1])\nnot isinstance(output_data, list) or len(output_data) <= index"
    },
    {
      "id": "n36",
      "type": "block",
      "statements": [],
      "code": "\nname.startswith(f'{output_name}{DICT_SPLIT}')"
    },
    {
      "id": "n37",
      "type": "block",
      "statements": [
        "return None"
      ],
      "code": "return None"
    },
    {
      "id": "n38",
      "type": "block",
      "statements": [],
      "code": "\nreturn output_data[int(name.split(LIST_SPLIT)[1])]"
    },
    {
      "id": "n39",
      "type": "block",
      "statements": [
        "index = name.split(DICT_SPLIT)[1]",
        "not isinstance(output_data, dict) or index not in output_data"
      ],
      "code": "index = name.split(DICT_SPLIT)[1]\nnot isinstance(output_data, dict) or index not in output_data"
    },
    {
      "id": "n40",
      "type": "block",
      "statements": [],
      "code": "\nname.startswith(f'{output_name}{OBJC_SPLIT}')"
    },
    {
      "id": "n41",
      "type": "block",
      "statements": [
        "return None"
      ],
      "code": "return None"
    },
    {
      "id": "n42",
      "type": "block",
      "statements": [],
      "code": "\nreturn output_data[index]"
    },
    {
      "id": "n43",
      "type": "block",
      "statements": [
        "index = name.split(OBJC_SPLIT)[1]",
        "isinstance(output_data, object) and hasattr(output_data, index)"
      ],
      "code": "index = name.split(OBJC_SPLIT)[1]\nisinstance(output_data, object) and hasattr(output_data, index)"
    },
    {
      "id": "n44",
      "type": "block",
      "statements": [],
      "code": "\nreturn None"
    },
    {
      "id": "n45",
      "type": "block",
      "statements": [
        "return getattr(output_data, index)"
      ],
      "code": "return getattr(output_data, index)"
    },
    {
      "id": "n46",
      "type": "block",
      "statements": [],
      "code": "\nreturn None"
    },
    {
      "id": "n47",
      "type": "block",
      "statements": [
        "def merge_execution_input(data: BlockInput) -> BlockInput:\n    \"\"\"\n    Merge all dynamic input pins which described by the following pattern:\n    - <input_name>_$_<index> for list input.\n    - <input_name>_#_<index> for dict input.\n    - <input_name>_@_<index> for object input.\n    This function will construct pins with the same name into a single list/dict/object.\n    \"\"\"\n    items = list(data.items())\n    for (key, value) in items:\n        if LIST_SPLIT not in key:\n            continue\n        (name, index) = key.split(LIST_SPLIT)\n        if not index.isdigit():\n            raise ValueError(f'Invalid key: {key}, #{index} index must be an integer.')\n        data[name] = data.get(name, [])\n        if int(index) >= len(data[name]):\n            data[name].extend([''] * (int(index) - len(data[name]) + 1))\n        data[name][int(index)] = value\n    for (key, value) in items:\n        if DICT_SPLIT not in key:\n            continue\n        (name, index) = key.split(DICT_SPLIT)\n        data[name] = data.get(name, {})\n        data[name][index] = value\n    for (key, value) in items:\n        if OBJC_SPLIT not in key:\n            continue\n        (name, index) = key.split(OBJC_SPLIT)\n        if name not in data or not isinstance(data[name], object):\n            data[name] = mock.MockObject()\n        setattr(data[name], index, value)\n    return data",
        "'\\n    Merge all dynamic input pins which described by the following pattern:\\n    - <input_name>_$_<index> for list input.\\n    - <input_name>_#_<index> for dict input.\\n    - <input_name>_@_<index> for object input.\\n    This function will construct pins with the same name into a single list/dict/object.\\n    '",
        "items = list(data.items())"
      ],
      "code": "def merge_execution_input(data: BlockInput) -> BlockInput:\n    \"\"\"\n    Merge all dynamic input pins which described by the following pattern:\n    - <input_name>_$_<index> for list input.\n    - <input_name>_#_<index> for dict input.\n    - <input_name>_@_<index> for object input.\n    This function will construct pins with the same name into a single list/dict/object.\n    \"\"\"\n    items = list(data.items())\n    for (key, value) in items:\n        if LIST_SPLIT not in key:\n            continue\n        (name, index) = key.split(LIST_SPLIT)\n        if not index.isdigit():\n            raise ValueError(f'Invalid key: {key}, #{index} index must be an integer.')\n        data[name] = data.get(name, [])\n        if int(index) >= len(data[name]):\n            data[name].extend([''] * (int(index) - len(data[name]) + 1))\n        data[name][int(index)] = value\n    for (key, value) in items:\n        if DICT_SPLIT not in key:\n            continue\n        (name, index) = key.split(DICT_SPLIT)\n        data[name] = data.get(name, {})\n        data[name][index] = value\n    for (key, value) in items:\n        if OBJC_SPLIT not in key:\n            continue\n        (name, index) = key.split(OBJC_SPLIT)\n        if name not in data or not isinstance(data[name], object):\n            data[name] = mock.MockObject()\n        setattr(data[name], index, value)\n    return data\n'\\n    Merge all dynamic input pins which described by the following pattern:\\n    - <input_name>_$_<index> for list input.\\n    - <input_name>_#_<index> for dict input.\\n    - <input_name>_@_<index> for object input.\\n    This function will construct pins with the same name into a single list/dict/object.\\n    '\nitems = list(data.items())"
    },
    {
      "id": "n48",
      "type": "block",
      "statements": [
        "(key, value)",
        "items"
      ],
      "code": "(key, value)\nitems"
    },
    {
      "id": "n49",
      "type": "block",
      "statements": [
        "LIST_SPLIT NotIn key"
      ],
      "code": "LIST_SPLIT NotIn key"
    },
    {
      "id": "n50",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n51",
      "type": "block",
      "statements": [
        "continue"
      ],
      "code": "continue"
    },
    {
      "id": "n52",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n53",
      "type": "block",
      "statements": [
        "(name, index) = key.split(LIST_SPLIT)",
        "not index.isdigit()"
      ],
      "code": "(name, index) = key.split(LIST_SPLIT)\nnot index.isdigit()"
    },
    {
      "id": "n54",
      "type": "block",
      "statements": [
        "raise ValueError(f'Invalid key: {key}, #{index} index must be an integer.')"
      ],
      "code": "raise ValueError(f'Invalid key: {key}, #{index} index must be an integer.')"
    },
    {
      "id": "n55",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n56",
      "type": "block",
      "statements": [
        "data[name] = data.get(name, [])",
        "int(index) GtE len(data[name])"
      ],
      "code": "data[name] = data.get(name, [])\nint(index) GtE len(data[name])"
    },
    {
      "id": "n57",
      "type": "block",
      "statements": [
        "data[name].extend([''] Mult int(index) Sub len(data[name]) Add 1)"
      ],
      "code": "data[name].extend([''] Mult int(index) Sub len(data[name]) Add 1)"
    },
    {
      "id": "n58",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n59",
      "type": "block",
      "statements": [
        "data[name][int(index)] = value"
      ],
      "code": "data[name][int(index)] = value"
    },
    {
      "id": "n60",
      "type": "block",
      "statements": [
        "(key, value)",
        "items"
      ],
      "code": "(key, value)\nitems"
    },
    {
      "id": "n61",
      "type": "block",
      "statements": [
        "DICT_SPLIT NotIn key"
      ],
      "code": "DICT_SPLIT NotIn key"
    },
    {
      "id": "n62",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n63",
      "type": "block",
      "statements": [
        "continue"
      ],
      "code": "continue"
    },
    {
      "id": "n64",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n65",
      "type": "block",
      "statements": [
        "(name, index) = key.split(DICT_SPLIT)",
        "data[name] = data.get(name, {})",
        "data[name][index] = value"
      ],
      "code": "(name, index) = key.split(DICT_SPLIT)\ndata[name] = data.get(name, {})\ndata[name][index] = value"
    },
    {
      "id": "n66",
      "type": "block",
      "statements": [
        "(key, value)",
        "items"
      ],
      "code": "(key, value)\nitems"
    },
    {
      "id": "n67",
      "type": "block",
      "statements": [
        "OBJC_SPLIT NotIn key"
      ],
      "code": "OBJC_SPLIT NotIn key"
    },
    {
      "id": "n68",
      "type": "block",
      "statements": [
        "return data"
      ],
      "code": "return data"
    },
    {
      "id": "n69",
      "type": "block",
      "statements": [
        "continue"
      ],
      "code": "continue"
    },
    {
      "id": "n70",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n71",
      "type": "block",
      "statements": [
        "(name, index) = key.split(OBJC_SPLIT)",
        "name not in data or not isinstance(data[name], object)"
      ],
      "code": "(name, index) = key.split(OBJC_SPLIT)\nname not in data or not isinstance(data[name], object)"
    },
    {
      "id": "n72",
      "type": "block",
      "statements": [
        "data[name] = mock.MockObject()"
      ],
      "code": "data[name] = mock.MockObject()"
    },
    {
      "id": "n73",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n74",
      "type": "block",
      "statements": [
        "setattr(data[name], index, value)"
      ],
      "code": "setattr(data[name], index, value)"
    },
    {
      "id": "n75",
      "type": "block",
      "statements": [
        "async def get_latest_execution(node_id: str, graph_eid: str) -> ExecutionResult | None:\n    execution = await AgentNodeExecution.prisma().find_first(where={'agentNodeId': node_id, 'agentGraphExecutionId': graph_eid, 'executionStatus': {'not': ExecutionStatus.INCOMPLETE}, 'executionData': {'not': None}}, order={'queuedTime': 'desc'}, include=EXECUTION_RESULT_INCLUDE)\n    if not execution:\n        return None\n    return ExecutionResult.from_db(execution)",
        "execution = await AgentNodeExecution.prisma().find_first(where={'agentNodeId': node_id, 'agentGraphExecutionId': graph_eid, 'executionStatus': {'not': ExecutionStatus.INCOMPLETE}, 'executionData': {'not': None}}, order={'queuedTime': 'desc'}, include=EXECUTION_RESULT_INCLUDE)",
        "not execution"
      ],
      "code": "async def get_latest_execution(node_id: str, graph_eid: str) -> ExecutionResult | None:\n    execution = await AgentNodeExecution.prisma().find_first(where={'agentNodeId': node_id, 'agentGraphExecutionId': graph_eid, 'executionStatus': {'not': ExecutionStatus.INCOMPLETE}, 'executionData': {'not': None}}, order={'queuedTime': 'desc'}, include=EXECUTION_RESULT_INCLUDE)\n    if not execution:\n        return None\n    return ExecutionResult.from_db(execution)\nexecution = await AgentNodeExecution.prisma().find_first(where={'agentNodeId': node_id, 'agentGraphExecutionId': graph_eid, 'executionStatus': {'not': ExecutionStatus.INCOMPLETE}, 'executionData': {'not': None}}, order={'queuedTime': 'desc'}, include=EXECUTION_RESULT_INCLUDE)\nnot execution"
    },
    {
      "id": "n76",
      "type": "block",
      "statements": [
        "return None"
      ],
      "code": "return None"
    },
    {
      "id": "n77",
      "type": "block",
      "statements": [],
      "code": "\nreturn ExecutionResult.from_db(execution)"
    },
    {
      "id": "n78",
      "type": "block",
      "statements": [
        "async def get_incomplete_executions(node_id: str, graph_eid: str) -> list[ExecutionResult]:\n    executions = await AgentNodeExecution.prisma().find_many(where={'agentNodeId': node_id, 'agentGraphExecutionId': graph_eid, 'executionStatus': ExecutionStatus.INCOMPLETE}, include=EXECUTION_RESULT_INCLUDE)\n    return [ExecutionResult.from_db(execution) for execution in executions]",
        "executions = await AgentNodeExecution.prisma().find_many(where={'agentNodeId': node_id, 'agentGraphExecutionId': graph_eid, 'executionStatus': ExecutionStatus.INCOMPLETE}, include=EXECUTION_RESULT_INCLUDE)",
        "return [ExecutionResult.from_db(execution) for execution in executions]"
      ],
      "code": "async def get_incomplete_executions(node_id: str, graph_eid: str) -> list[ExecutionResult]:\n    executions = await AgentNodeExecution.prisma().find_many(where={'agentNodeId': node_id, 'agentGraphExecutionId': graph_eid, 'executionStatus': ExecutionStatus.INCOMPLETE}, include=EXECUTION_RESULT_INCLUDE)\n    return [ExecutionResult.from_db(execution) for execution in executions]\nexecutions = await AgentNodeExecution.prisma().find_many(where={'agentNodeId': node_id, 'agentGraphExecutionId': graph_eid, 'executionStatus': ExecutionStatus.INCOMPLETE}, include=EXECUTION_RESULT_INCLUDE)\nreturn [ExecutionResult.from_db(execution) for execution in executions]"
    },
    {
      "id": "n79",
      "type": "block",
      "statements": [
        "config = Config()",
        "class RedisExecutionEventBus(RedisEventBus[ExecutionResult]):\n    Model = ExecutionResult\n\n    @property\n    def event_bus_name(self) -> str:\n        return config.execution_event_bus_name\n\n    def publish(self, res: ExecutionResult):\n        self.publish_event(res, f'{res.graph_id}/{res.graph_exec_id}')\n\n    def listen(self, graph_id: str='*', graph_exec_id: str='*') -> Generator[ExecutionResult, None, None]:\n        for execution_result in self.listen_events(f'{graph_id}/{graph_exec_id}'):\n            yield execution_result",
        "Model = ExecutionResult",
        "@property\ndef event_bus_name(self) -> str:\n    return config.execution_event_bus_name",
        "return config.execution_event_bus_name"
      ],
      "code": "config = Config()\nclass RedisExecutionEventBus(RedisEventBus[ExecutionResult]):\n    Model = ExecutionResult\n\n    @property\n    def event_bus_name(self) -> str:\n        return config.execution_event_bus_name\n\n    def publish(self, res: ExecutionResult):\n        self.publish_event(res, f'{res.graph_id}/{res.graph_exec_id}')\n\n    def listen(self, graph_id: str='*', graph_exec_id: str='*') -> Generator[ExecutionResult, None, None]:\n        for execution_result in self.listen_events(f'{graph_id}/{graph_exec_id}'):\n            yield execution_result\nModel = ExecutionResult\n@property\ndef event_bus_name(self) -> str:\n    return config.execution_event_bus_name\nreturn config.execution_event_bus_name"
    },
    {
      "id": "n80",
      "type": "block",
      "statements": [
        "def publish(self, res: ExecutionResult):\n    self.publish_event(res, f'{res.graph_id}/{res.graph_exec_id}')",
        "self.publish_event(res, f'{res.graph_id}/{res.graph_exec_id}')",
        "def listen(self, graph_id: str='*', graph_exec_id: str='*') -> Generator[ExecutionResult, None, None]:\n    for execution_result in self.listen_events(f'{graph_id}/{graph_exec_id}'):\n        yield execution_result"
      ],
      "code": "def publish(self, res: ExecutionResult):\n    self.publish_event(res, f'{res.graph_id}/{res.graph_exec_id}')\nself.publish_event(res, f'{res.graph_id}/{res.graph_exec_id}')\ndef listen(self, graph_id: str='*', graph_exec_id: str='*') -> Generator[ExecutionResult, None, None]:\n    for execution_result in self.listen_events(f'{graph_id}/{graph_exec_id}'):\n        yield execution_result"
    },
    {
      "id": "n81",
      "type": "block",
      "statements": [
        "execution_result",
        "self.listen_events(f'{graph_id}/{graph_exec_id}')"
      ],
      "code": "execution_result\nself.listen_events(f'{graph_id}/{graph_exec_id}')"
    },
    {
      "id": "n82",
      "type": "block",
      "statements": [
        "(yield execution_result)"
      ],
      "code": "(yield execution_result)"
    },
    {
      "id": "n83",
      "type": "block",
      "statements": [
        "class AsyncRedisExecutionEventBus(AsyncRedisEventBus[ExecutionResult]):\n    Model = ExecutionResult\n\n    @property\n    def event_bus_name(self) -> str:\n        return config.execution_event_bus_name\n\n    async def publish(self, res: ExecutionResult):\n        await self.publish_event(res, f'{res.graph_id}/{res.graph_exec_id}')\n\n    async def listen(self, graph_id: str='*', graph_exec_id: str='*') -> AsyncGenerator[ExecutionResult, None]:\n        async for execution_result in self.listen_events(f'{graph_id}/{graph_exec_id}'):\n            yield execution_result",
        "Model = ExecutionResult",
        "@property\ndef event_bus_name(self) -> str:\n    return config.execution_event_bus_name",
        "return config.execution_event_bus_name"
      ],
      "code": "class AsyncRedisExecutionEventBus(AsyncRedisEventBus[ExecutionResult]):\n    Model = ExecutionResult\n\n    @property\n    def event_bus_name(self) -> str:\n        return config.execution_event_bus_name\n\n    async def publish(self, res: ExecutionResult):\n        await self.publish_event(res, f'{res.graph_id}/{res.graph_exec_id}')\n\n    async def listen(self, graph_id: str='*', graph_exec_id: str='*') -> AsyncGenerator[ExecutionResult, None]:\n        async for execution_result in self.listen_events(f'{graph_id}/{graph_exec_id}'):\n            yield execution_result\nModel = ExecutionResult\n@property\ndef event_bus_name(self) -> str:\n    return config.execution_event_bus_name\nreturn config.execution_event_bus_name"
    },
    {
      "id": "n84",
      "type": "block",
      "statements": [
        "async def publish(self, res: ExecutionResult):\n    await self.publish_event(res, f'{res.graph_id}/{res.graph_exec_id}')",
        "await self.publish_event(res, f'{res.graph_id}/{res.graph_exec_id}')",
        "async def listen(self, graph_id: str='*', graph_exec_id: str='*') -> AsyncGenerator[ExecutionResult, None]:\n    async for execution_result in self.listen_events(f'{graph_id}/{graph_exec_id}'):\n        yield execution_result",
        "async for execution_result in self.listen_events(f'{graph_id}/{graph_exec_id}'):\n    yield execution_result",
        "(yield execution_result)"
      ],
      "code": "async def publish(self, res: ExecutionResult):\n    await self.publish_event(res, f'{res.graph_id}/{res.graph_exec_id}')\nawait self.publish_event(res, f'{res.graph_id}/{res.graph_exec_id}')\nasync def listen(self, graph_id: str='*', graph_exec_id: str='*') -> AsyncGenerator[ExecutionResult, None]:\n    async for execution_result in self.listen_events(f'{graph_id}/{graph_exec_id}'):\n        yield execution_result\nasync for execution_result in self.listen_events(f'{graph_id}/{graph_exec_id}'):\n    yield execution_result\n(yield execution_result)"
    }
  ],
  "edges": [
    {
      "source": "n61",
      "target": "n64"
    },
    {
      "source": "n70",
      "target": "n71"
    },
    {
      "source": "n67",
      "target": "n69"
    },
    {
      "source": "n17",
      "target": "n19"
    },
    {
      "source": "n26",
      "target": "n27"
    },
    {
      "source": "n82",
      "target": "n81"
    },
    {
      "source": "n80",
      "target": "n81"
    },
    {
      "source": "n8",
      "target": "n9"
    },
    {
      "source": "n53",
      "target": "n55"
    },
    {
      "source": "n34",
      "target": "n36"
    },
    {
      "source": "n21",
      "target": "n23"
    },
    {
      "source": "n71",
      "target": "n72"
    },
    {
      "source": "n81",
      "target": "n82"
    },
    {
      "source": "n12",
      "target": "n11"
    },
    {
      "source": "n75",
      "target": "n77"
    },
    {
      "source": "n75",
      "target": "n76"
    },
    {
      "source": "n6",
      "target": "n8"
    },
    {
      "source": "n15",
      "target": "n17"
    },
    {
      "source": "n35",
      "target": "n37"
    },
    {
      "source": "n59",
      "target": "n48"
    },
    {
      "source": "n34",
      "target": "n35"
    },
    {
      "source": "n43",
      "target": "n46"
    },
    {
      "source": "n69",
      "target": "n71"
    },
    {
      "source": "n17",
      "target": "n20"
    },
    {
      "source": "n62",
      "target": "n66"
    },
    {
      "source": "n81",
      "target": "n83"
    },
    {
      "source": "n24",
      "target": "n25"
    },
    {
      "source": "n15",
      "target": "n16"
    },
    {
      "source": "n29",
      "target": "n30"
    },
    {
      "source": "n48",
      "target": "n50"
    },
    {
      "source": "n28",
      "target": "n30"
    },
    {
      "source": "n58",
      "target": "n59"
    },
    {
      "source": "n11",
      "target": "n12"
    },
    {
      "source": "n60",
      "target": "n62"
    },
    {
      "source": "n73",
      "target": "n74"
    },
    {
      "source": "n66",
      "target": "n68"
    },
    {
      "source": "n18",
      "target": "n22"
    },
    {
      "source": "n57",
      "target": "n59"
    },
    {
      "source": "n56",
      "target": "n58"
    },
    {
      "source": "n55",
      "target": "n56"
    },
    {
      "source": "n72",
      "target": "n74"
    },
    {
      "source": "n65",
      "target": "n60"
    },
    {
      "source": "n22",
      "target": "n23"
    },
    {
      "source": "n53",
      "target": "n54"
    },
    {
      "source": "n36",
      "target": "n40"
    },
    {
      "source": "n4",
      "target": "n6"
    },
    {
      "source": "n47",
      "target": "n48"
    },
    {
      "source": "n36",
      "target": "n39"
    },
    {
      "source": "n51",
      "target": "n53"
    },
    {
      "source": "n39",
      "target": "n42"
    },
    {
      "source": "n60",
      "target": "n61"
    },
    {
      "source": "n18",
      "target": "n21"
    },
    {
      "source": "n54",
      "target": "n56"
    },
    {
      "source": "n64",
      "target": "n65"
    },
    {
      "source": "n27",
      "target": "n29"
    },
    {
      "source": "n24",
      "target": "n26"
    },
    {
      "source": "n27",
      "target": "n28"
    },
    {
      "source": "n49",
      "target": "n52"
    },
    {
      "source": "n9",
      "target": "n8"
    },
    {
      "source": "n32",
      "target": "n34"
    },
    {
      "source": "n63",
      "target": "n65"
    },
    {
      "source": "n11",
      "target": "n13"
    },
    {
      "source": "n39",
      "target": "n41"
    },
    {
      "source": "n48",
      "target": "n49"
    },
    {
      "source": "n52",
      "target": "n53"
    },
    {
      "source": "n7",
      "target": "n11"
    },
    {
      "source": "n67",
      "target": "n70"
    },
    {
      "source": "n61",
      "target": "n63"
    },
    {
      "source": "n71",
      "target": "n73"
    },
    {
      "source": "n4",
      "target": "n5"
    },
    {
      "source": "n40",
      "target": "n43"
    },
    {
      "source": "n32",
      "target": "n33"
    },
    {
      "source": "n20",
      "target": "n18"
    },
    {
      "source": "n49",
      "target": "n51"
    },
    {
      "source": "n66",
      "target": "n67"
    },
    {
      "source": "n50",
      "target": "n60"
    },
    {
      "source": "n10",
      "target": "n7"
    },
    {
      "source": "n40",
      "target": "n44"
    },
    {
      "source": "n43",
      "target": "n45"
    },
    {
      "source": "n8",
      "target": "n10"
    },
    {
      "source": "n25",
      "target": "n27"
    },
    {
      "source": "n74",
      "target": "n66"
    },
    {
      "source": "n35",
      "target": "n38"
    },
    {
      "source": "n5",
      "target": "n7"
    },
    {
      "source": "n56",
      "target": "n57"
    }
  ]
}