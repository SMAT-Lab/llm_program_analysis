{
  "nodes": [
    {
      "id": "n0",
      "type": "block",
      "statements": [
        "from backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema",
        "from backend.data.model import ContributorDetails, SchemaField",
        "class ReadCsvBlock(Block):\n\n    class Input(BlockSchema):\n        contents: str = SchemaField(description='The contents of the CSV file to read', placeholder='a, b, c\\n1,2,3\\n4,5,6')\n        delimiter: str = SchemaField(description='The delimiter used in the CSV file', default=',')\n        quotechar: str = SchemaField(description='The character used to quote fields', default='\"')\n        escapechar: str = SchemaField(description='The character used to escape the delimiter', default='\\\\')\n        has_header: bool = SchemaField(description='Whether the CSV file has a header row', default=True)\n        skip_rows: int = SchemaField(description='The number of rows to skip from the start of the file', default=0)\n        strip: bool = SchemaField(description='Whether to strip whitespace from the values', default=True)\n        skip_columns: list[str] = SchemaField(description='The columns to skip from the start of the row', default=[])\n\n    class Output(BlockSchema):\n        row: dict[str, str] = SchemaField(description='The data produced from each row in the CSV file')\n        all_data: list[dict[str, str]] = SchemaField(description='All the data in the CSV file as a list of rows')\n\n    def __init__(self):\n        super().__init__(id='acf7625e-d2cb-4941-bfeb-2819fc6fc015', input_schema=ReadCsvBlock.Input, output_schema=ReadCsvBlock.Output, description='Reads a CSV file and outputs the data as a list of dictionaries and individual rows via rows.', contributors=[ContributorDetails(name='Nicholas Tindle')], categories={BlockCategory.TEXT, BlockCategory.DATA}, test_input={'contents': 'a, b, c\\n1,2,3\\n4,5,6'}, test_output=[('row', {'a': '1', 'b': '2', 'c': '3'}), ('row', {'a': '4', 'b': '5', 'c': '6'}), ('all_data', [{'a': '1', 'b': '2', 'c': '3'}, {'a': '4', 'b': '5', 'c': '6'}])])\n\n    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        import csv\n        from io import StringIO\n        csv_file = StringIO(input_data.contents)\n        reader = csv.reader(csv_file, delimiter=input_data.delimiter, quotechar=input_data.quotechar, escapechar=input_data.escapechar)\n        header = None\n        if input_data.has_header:\n            header = next(reader)\n            if input_data.strip:\n                header = [h.strip() for h in header]\n        for _ in range(input_data.skip_rows):\n            next(reader)\n\n        def process_row(row):\n            data = {}\n            for (i, value) in enumerate(row):\n                if i not in input_data.skip_columns:\n                    if input_data.has_header and header:\n                        data[header[i]] = value.strip() if input_data.strip else value\n                    else:\n                        data[str(i)] = value.strip() if input_data.strip else value\n            return data\n        all_data = []\n        for row in reader:\n            processed_row = process_row(row)\n            all_data.append(processed_row)\n            yield ('row', processed_row)\n        yield ('all_data', all_data)",
        "class Input(BlockSchema):\n    contents: str = SchemaField(description='The contents of the CSV file to read', placeholder='a, b, c\\n1,2,3\\n4,5,6')\n    delimiter: str = SchemaField(description='The delimiter used in the CSV file', default=',')\n    quotechar: str = SchemaField(description='The character used to quote fields', default='\"')\n    escapechar: str = SchemaField(description='The character used to escape the delimiter', default='\\\\')\n    has_header: bool = SchemaField(description='Whether the CSV file has a header row', default=True)\n    skip_rows: int = SchemaField(description='The number of rows to skip from the start of the file', default=0)\n    strip: bool = SchemaField(description='Whether to strip whitespace from the values', default=True)\n    skip_columns: list[str] = SchemaField(description='The columns to skip from the start of the row', default=[])",
        "contents: str = SchemaField(description='The contents of the CSV file to read', placeholder='a, b, c\\n1,2,3\\n4,5,6')",
        "delimiter: str = SchemaField(description='The delimiter used in the CSV file', default=',')",
        "quotechar: str = SchemaField(description='The character used to quote fields', default='\"')",
        "escapechar: str = SchemaField(description='The character used to escape the delimiter', default='\\\\')",
        "has_header: bool = SchemaField(description='Whether the CSV file has a header row', default=True)",
        "skip_rows: int = SchemaField(description='The number of rows to skip from the start of the file', default=0)",
        "strip: bool = SchemaField(description='Whether to strip whitespace from the values', default=True)",
        "skip_columns: list[str] = SchemaField(description='The columns to skip from the start of the row', default=[])",
        "class Output(BlockSchema):\n    row: dict[str, str] = SchemaField(description='The data produced from each row in the CSV file')\n    all_data: list[dict[str, str]] = SchemaField(description='All the data in the CSV file as a list of rows')",
        "row: dict[str, str] = SchemaField(description='The data produced from each row in the CSV file')",
        "all_data: list[dict[str, str]] = SchemaField(description='All the data in the CSV file as a list of rows')",
        "def __init__(self):\n    super().__init__(id='acf7625e-d2cb-4941-bfeb-2819fc6fc015', input_schema=ReadCsvBlock.Input, output_schema=ReadCsvBlock.Output, description='Reads a CSV file and outputs the data as a list of dictionaries and individual rows via rows.', contributors=[ContributorDetails(name='Nicholas Tindle')], categories={BlockCategory.TEXT, BlockCategory.DATA}, test_input={'contents': 'a, b, c\\n1,2,3\\n4,5,6'}, test_output=[('row', {'a': '1', 'b': '2', 'c': '3'}), ('row', {'a': '4', 'b': '5', 'c': '6'}), ('all_data', [{'a': '1', 'b': '2', 'c': '3'}, {'a': '4', 'b': '5', 'c': '6'}])])",
        "super().__init__()",
        "def run(self, input_data: Input, **kwargs) -> BlockOutput:\n    import csv\n    from io import StringIO\n    csv_file = StringIO(input_data.contents)\n    reader = csv.reader(csv_file, delimiter=input_data.delimiter, quotechar=input_data.quotechar, escapechar=input_data.escapechar)\n    header = None\n    if input_data.has_header:\n        header = next(reader)\n        if input_data.strip:\n            header = [h.strip() for h in header]\n    for _ in range(input_data.skip_rows):\n        next(reader)\n\n    def process_row(row):\n        data = {}\n        for (i, value) in enumerate(row):\n            if i not in input_data.skip_columns:\n                if input_data.has_header and header:\n                    data[header[i]] = value.strip() if input_data.strip else value\n                else:\n                    data[str(i)] = value.strip() if input_data.strip else value\n        return data\n    all_data = []\n    for row in reader:\n        processed_row = process_row(row)\n        all_data.append(processed_row)\n        yield ('row', processed_row)\n    yield ('all_data', all_data)",
        "import csv",
        "from io import StringIO",
        "csv_file = StringIO(input_data.contents)",
        "reader = csv.reader(csv_file, delimiter=input_data.delimiter, quotechar=input_data.quotechar, escapechar=input_data.escapechar)",
        "header = None",
        "input_data.has_header"
      ],
      "code": "from backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import ContributorDetails, SchemaField\nclass ReadCsvBlock(Block):\n\n    class Input(BlockSchema):\n        contents: str = SchemaField(description='The contents of the CSV file to read', placeholder='a, b, c\\n1,2,3\\n4,5,6')\n        delimiter: str = SchemaField(description='The delimiter used in the CSV file', default=',')\n        quotechar: str = SchemaField(description='The character used to quote fields', default='\"')\n        escapechar: str = SchemaField(description='The character used to escape the delimiter', default='\\\\')\n        has_header: bool = SchemaField(description='Whether the CSV file has a header row', default=True)\n        skip_rows: int = SchemaField(description='The number of rows to skip from the start of the file', default=0)\n        strip: bool = SchemaField(description='Whether to strip whitespace from the values', default=True)\n        skip_columns: list[str] = SchemaField(description='The columns to skip from the start of the row', default=[])\n\n    class Output(BlockSchema):\n        row: dict[str, str] = SchemaField(description='The data produced from each row in the CSV file')\n        all_data: list[dict[str, str]] = SchemaField(description='All the data in the CSV file as a list of rows')\n\n    def __init__(self):\n        super().__init__(id='acf7625e-d2cb-4941-bfeb-2819fc6fc015', input_schema=ReadCsvBlock.Input, output_schema=ReadCsvBlock.Output, description='Reads a CSV file and outputs the data as a list of dictionaries and individual rows via rows.', contributors=[ContributorDetails(name='Nicholas Tindle')], categories={BlockCategory.TEXT, BlockCategory.DATA}, test_input={'contents': 'a, b, c\\n1,2,3\\n4,5,6'}, test_output=[('row', {'a': '1', 'b': '2', 'c': '3'}), ('row', {'a': '4', 'b': '5', 'c': '6'}), ('all_data', [{'a': '1', 'b': '2', 'c': '3'}, {'a': '4', 'b': '5', 'c': '6'}])])\n\n    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        import csv\n        from io import StringIO\n        csv_file = StringIO(input_data.contents)\n        reader = csv.reader(csv_file, delimiter=input_data.delimiter, quotechar=input_data.quotechar, escapechar=input_data.escapechar)\n        header = None\n        if input_data.has_header:\n            header = next(reader)\n            if input_data.strip:\n                header = [h.strip() for h in header]\n        for _ in range(input_data.skip_rows):\n            next(reader)\n\n        def process_row(row):\n            data = {}\n            for (i, value) in enumerate(row):\n                if i not in input_data.skip_columns:\n                    if input_data.has_header and header:\n                        data[header[i]] = value.strip() if input_data.strip else value\n                    else:\n                        data[str(i)] = value.strip() if input_data.strip else value\n            return data\n        all_data = []\n        for row in reader:\n            processed_row = process_row(row)\n            all_data.append(processed_row)\n            yield ('row', processed_row)\n        yield ('all_data', all_data)\nclass Input(BlockSchema):\n    contents: str = SchemaField(description='The contents of the CSV file to read', placeholder='a, b, c\\n1,2,3\\n4,5,6')\n    delimiter: str = SchemaField(description='The delimiter used in the CSV file', default=',')\n    quotechar: str = SchemaField(description='The character used to quote fields', default='\"')\n    escapechar: str = SchemaField(description='The character used to escape the delimiter', default='\\\\')\n    has_header: bool = SchemaField(description='Whether the CSV file has a header row', default=True)\n    skip_rows: int = SchemaField(description='The number of rows to skip from the start of the file', default=0)\n    strip: bool = SchemaField(description='Whether to strip whitespace from the values', default=True)\n    skip_columns: list[str] = SchemaField(description='The columns to skip from the start of the row', default=[])\ncontents: str = SchemaField(description='The contents of the CSV file to read', placeholder='a, b, c\\n1,2,3\\n4,5,6')\ndelimiter: str = SchemaField(description='The delimiter used in the CSV file', default=',')\nquotechar: str = SchemaField(description='The character used to quote fields', default='\"')\nescapechar: str = SchemaField(description='The character used to escape the delimiter', default='\\\\')\nhas_header: bool = SchemaField(description='Whether the CSV file has a header row', default=True)\nskip_rows: int = SchemaField(description='The number of rows to skip from the start of the file', default=0)\nstrip: bool = SchemaField(description='Whether to strip whitespace from the values', default=True)\nskip_columns: list[str] = SchemaField(description='The columns to skip from the start of the row', default=[])\nclass Output(BlockSchema):\n    row: dict[str, str] = SchemaField(description='The data produced from each row in the CSV file')\n    all_data: list[dict[str, str]] = SchemaField(description='All the data in the CSV file as a list of rows')\nrow: dict[str, str] = SchemaField(description='The data produced from each row in the CSV file')\nall_data: list[dict[str, str]] = SchemaField(description='All the data in the CSV file as a list of rows')\ndef __init__(self):\n    super().__init__(id='acf7625e-d2cb-4941-bfeb-2819fc6fc015', input_schema=ReadCsvBlock.Input, output_schema=ReadCsvBlock.Output, description='Reads a CSV file and outputs the data as a list of dictionaries and individual rows via rows.', contributors=[ContributorDetails(name='Nicholas Tindle')], categories={BlockCategory.TEXT, BlockCategory.DATA}, test_input={'contents': 'a, b, c\\n1,2,3\\n4,5,6'}, test_output=[('row', {'a': '1', 'b': '2', 'c': '3'}), ('row', {'a': '4', 'b': '5', 'c': '6'}), ('all_data', [{'a': '1', 'b': '2', 'c': '3'}, {'a': '4', 'b': '5', 'c': '6'}])])\nsuper().__init__()\ndef run(self, input_data: Input, **kwargs) -> BlockOutput:\n    import csv\n    from io import StringIO\n    csv_file = StringIO(input_data.contents)\n    reader = csv.reader(csv_file, delimiter=input_data.delimiter, quotechar=input_data.quotechar, escapechar=input_data.escapechar)\n    header = None\n    if input_data.has_header:\n        header = next(reader)\n        if input_data.strip:\n            header = [h.strip() for h in header]\n    for _ in range(input_data.skip_rows):\n        next(reader)\n\n    def process_row(row):\n        data = {}\n        for (i, value) in enumerate(row):\n            if i not in input_data.skip_columns:\n                if input_data.has_header and header:\n                    data[header[i]] = value.strip() if input_data.strip else value\n                else:\n                    data[str(i)] = value.strip() if input_data.strip else value\n        return data\n    all_data = []\n    for row in reader:\n        processed_row = process_row(row)\n        all_data.append(processed_row)\n        yield ('row', processed_row)\n    yield ('all_data', all_data)\nimport csv\nfrom io import StringIO\ncsv_file = StringIO(input_data.contents)\nreader = csv.reader(csv_file, delimiter=input_data.delimiter, quotechar=input_data.quotechar, escapechar=input_data.escapechar)\nheader = None\ninput_data.has_header"
    },
    {
      "id": "n1",
      "type": "block",
      "statements": [
        "header = next(reader)",
        "input_data.strip"
      ],
      "code": "header = next(reader)\ninput_data.strip"
    },
    {
      "id": "n2",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n3",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n4",
      "type": "block",
      "statements": [
        "header = [h.strip() for h in header]"
      ],
      "code": "header = [h.strip() for h in header]"
    },
    {
      "id": "n5",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n6",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n7",
      "type": "block",
      "statements": [
        "_",
        "range(input_data.skip_rows)"
      ],
      "code": "_\nrange(input_data.skip_rows)"
    },
    {
      "id": "n8",
      "type": "block",
      "statements": [
        "next(reader)"
      ],
      "code": "next(reader)"
    },
    {
      "id": "n9",
      "type": "block",
      "statements": [
        "def process_row(row):\n    data = {}\n    for (i, value) in enumerate(row):\n        if i not in input_data.skip_columns:\n            if input_data.has_header and header:\n                data[header[i]] = value.strip() if input_data.strip else value\n            else:\n                data[str(i)] = value.strip() if input_data.strip else value\n    return data",
        "data = {}"
      ],
      "code": "def process_row(row):\n    data = {}\n    for (i, value) in enumerate(row):\n        if i not in input_data.skip_columns:\n            if input_data.has_header and header:\n                data[header[i]] = value.strip() if input_data.strip else value\n            else:\n                data[str(i)] = value.strip() if input_data.strip else value\n    return data\ndata = {}"
    },
    {
      "id": "n10",
      "type": "block",
      "statements": [
        "(i, value)",
        "enumerate(row)"
      ],
      "code": "(i, value)\nenumerate(row)"
    },
    {
      "id": "n11",
      "type": "block",
      "statements": [
        "i NotIn input_data.skip_columns"
      ],
      "code": "i NotIn input_data.skip_columns"
    },
    {
      "id": "n12",
      "type": "block",
      "statements": [
        "return data"
      ],
      "code": "return data"
    },
    {
      "id": "n13",
      "type": "block",
      "statements": [
        "input_data.has_header and header"
      ],
      "code": "input_data.has_header and header"
    },
    {
      "id": "n14",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n15",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n16",
      "type": "block",
      "statements": [
        "data[header[i]] = value.strip() if input_data.strip else value"
      ],
      "code": "data[header[i]] = value.strip() if input_data.strip else value"
    },
    {
      "id": "n17",
      "type": "block",
      "statements": [
        "data[str(i)] = value.strip() if input_data.strip else value"
      ],
      "code": "data[str(i)] = value.strip() if input_data.strip else value"
    },
    {
      "id": "n18",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n19",
      "type": "block",
      "statements": [
        "all_data = []"
      ],
      "code": "all_data = []"
    },
    {
      "id": "n20",
      "type": "block",
      "statements": [
        "row",
        "reader"
      ],
      "code": "row\nreader"
    },
    {
      "id": "n21",
      "type": "block",
      "statements": [
        "processed_row = process_row(row)",
        "all_data.append(processed_row)",
        "(yield ('row', processed_row))"
      ],
      "code": "processed_row = process_row(row)\nall_data.append(processed_row)\n(yield ('row', processed_row))"
    },
    {
      "id": "n22",
      "type": "block",
      "statements": [
        "(yield ('all_data', all_data))"
      ],
      "code": "(yield ('all_data', all_data))"
    }
  ],
  "edges": [
    {
      "source": "n21",
      "target": "n20"
    },
    {
      "source": "n14",
      "target": "n15"
    },
    {
      "source": "n0",
      "target": "n1"
    },
    {
      "source": "n17",
      "target": "n18"
    },
    {
      "source": "n11",
      "target": "n14"
    },
    {
      "source": "n15",
      "target": "n10"
    },
    {
      "source": "n10",
      "target": "n11"
    },
    {
      "source": "n8",
      "target": "n7"
    },
    {
      "source": "n2",
      "target": "n3"
    },
    {
      "source": "n6",
      "target": "n3"
    },
    {
      "source": "n16",
      "target": "n18"
    },
    {
      "source": "n1",
      "target": "n5"
    },
    {
      "source": "n4",
      "target": "n6"
    },
    {
      "source": "n19",
      "target": "n20"
    },
    {
      "source": "n13",
      "target": "n17"
    },
    {
      "source": "n7",
      "target": "n8"
    },
    {
      "source": "n18",
      "target": "n15"
    },
    {
      "source": "n20",
      "target": "n21"
    },
    {
      "source": "n9",
      "target": "n10"
    },
    {
      "source": "n10",
      "target": "n12"
    },
    {
      "source": "n7",
      "target": "n9"
    },
    {
      "source": "n5",
      "target": "n6"
    },
    {
      "source": "n13",
      "target": "n16"
    },
    {
      "source": "n1",
      "target": "n4"
    },
    {
      "source": "n20",
      "target": "n22"
    },
    {
      "source": "n11",
      "target": "n13"
    },
    {
      "source": "n0",
      "target": "n2"
    },
    {
      "source": "n3",
      "target": "n7"
    }
  ]
}