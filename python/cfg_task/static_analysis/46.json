{
  "nodes": [
    {
      "id": "n0",
      "type": "block",
      "statements": [
        "from datetime import datetime",
        "from typing import Any, List",
        "from backend.blocks.exa._auth import ExaCredentials, ExaCredentialsField, ExaCredentialsInput",
        "from backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema",
        "from backend.data.model import SchemaField",
        "from backend.util.request import requests",
        "from .helpers import ContentSettings",
        "class ExaFindSimilarBlock(Block):\n\n    class Input(BlockSchema):\n        credentials: ExaCredentialsInput = ExaCredentialsField()\n        url: str = SchemaField(description='The url for which you would like to find similar links')\n        number_of_results: int = SchemaField(description='Number of results to return', default=10, advanced=True)\n        include_domains: List[str] = SchemaField(description='Domains to include in search', default=[], advanced=True)\n        exclude_domains: List[str] = SchemaField(description='Domains to exclude from search', default=[], advanced=True)\n        start_crawl_date: datetime = SchemaField(description='Start date for crawled content')\n        end_crawl_date: datetime = SchemaField(description='End date for crawled content')\n        start_published_date: datetime = SchemaField(description='Start date for published content')\n        end_published_date: datetime = SchemaField(description='End date for published content')\n        include_text: List[str] = SchemaField(description='Text patterns to include (max 1 string, up to 5 words)', default=[], advanced=True)\n        exclude_text: List[str] = SchemaField(description='Text patterns to exclude (max 1 string, up to 5 words)', default=[], advanced=True)\n        contents: ContentSettings = SchemaField(description='Content retrieval settings', default=ContentSettings(), advanced=True)\n\n    class Output(BlockSchema):\n        results: List[Any] = SchemaField(description='List of similar documents with title, URL, published date, author, and score', default=[])\n\n    def __init__(self):\n        super().__init__(id='5e7315d1-af61-4a0c-9350-7c868fa7438a', description=\"Finds similar links using Exa's findSimilar API\", categories={BlockCategory.SEARCH}, input_schema=ExaFindSimilarBlock.Input, output_schema=ExaFindSimilarBlock.Output)\n\n    def run(self, input_data: Input, *, credentials: ExaCredentials, **kwargs) -> BlockOutput:\n        url = 'https://api.exa.ai/findSimilar'\n        headers = {'Content-Type': 'application/json', 'x-api-key': credentials.api_key.get_secret_value()}\n        payload = {'url': input_data.url, 'numResults': input_data.number_of_results, 'contents': input_data.contents.dict()}\n        optional_field_mapping = {'include_domains': 'includeDomains', 'exclude_domains': 'excludeDomains', 'include_text': 'includeText', 'exclude_text': 'excludeText'}\n        for (input_field, api_field) in optional_field_mapping.items():\n            value = getattr(input_data, input_field)\n            if value:\n                payload[api_field] = value\n        date_field_mapping = {'start_crawl_date': 'startCrawlDate', 'end_crawl_date': 'endCrawlDate', 'start_published_date': 'startPublishedDate', 'end_published_date': 'endPublishedDate'}\n        for (input_field, api_field) in date_field_mapping.items():\n            value = getattr(input_data, input_field, None)\n            if value:\n                payload[api_field] = value.strftime('%Y-%m-%dT%H:%M:%S.000Z')\n        try:\n            response = requests.post(url, headers=headers, json=payload)\n            response.raise_for_status()\n            data = response.json()\n            yield ('results', data.get('results', []))\n        except Exception as e:\n            yield ('error', str(e))\n            yield ('results', [])",
        "class Input(BlockSchema):\n    credentials: ExaCredentialsInput = ExaCredentialsField()\n    url: str = SchemaField(description='The url for which you would like to find similar links')\n    number_of_results: int = SchemaField(description='Number of results to return', default=10, advanced=True)\n    include_domains: List[str] = SchemaField(description='Domains to include in search', default=[], advanced=True)\n    exclude_domains: List[str] = SchemaField(description='Domains to exclude from search', default=[], advanced=True)\n    start_crawl_date: datetime = SchemaField(description='Start date for crawled content')\n    end_crawl_date: datetime = SchemaField(description='End date for crawled content')\n    start_published_date: datetime = SchemaField(description='Start date for published content')\n    end_published_date: datetime = SchemaField(description='End date for published content')\n    include_text: List[str] = SchemaField(description='Text patterns to include (max 1 string, up to 5 words)', default=[], advanced=True)\n    exclude_text: List[str] = SchemaField(description='Text patterns to exclude (max 1 string, up to 5 words)', default=[], advanced=True)\n    contents: ContentSettings = SchemaField(description='Content retrieval settings', default=ContentSettings(), advanced=True)",
        "credentials: ExaCredentialsInput = ExaCredentialsField()",
        "url: str = SchemaField(description='The url for which you would like to find similar links')",
        "number_of_results: int = SchemaField(description='Number of results to return', default=10, advanced=True)",
        "include_domains: List[str] = SchemaField(description='Domains to include in search', default=[], advanced=True)",
        "exclude_domains: List[str] = SchemaField(description='Domains to exclude from search', default=[], advanced=True)",
        "start_crawl_date: datetime = SchemaField(description='Start date for crawled content')",
        "end_crawl_date: datetime = SchemaField(description='End date for crawled content')",
        "start_published_date: datetime = SchemaField(description='Start date for published content')",
        "end_published_date: datetime = SchemaField(description='End date for published content')",
        "include_text: List[str] = SchemaField(description='Text patterns to include (max 1 string, up to 5 words)', default=[], advanced=True)",
        "exclude_text: List[str] = SchemaField(description='Text patterns to exclude (max 1 string, up to 5 words)', default=[], advanced=True)",
        "contents: ContentSettings = SchemaField(description='Content retrieval settings', default=ContentSettings(), advanced=True)",
        "class Output(BlockSchema):\n    results: List[Any] = SchemaField(description='List of similar documents with title, URL, published date, author, and score', default=[])",
        "results: List[Any] = SchemaField(description='List of similar documents with title, URL, published date, author, and score', default=[])",
        "def __init__(self):\n    super().__init__(id='5e7315d1-af61-4a0c-9350-7c868fa7438a', description=\"Finds similar links using Exa's findSimilar API\", categories={BlockCategory.SEARCH}, input_schema=ExaFindSimilarBlock.Input, output_schema=ExaFindSimilarBlock.Output)",
        "super().__init__()",
        "def run(self, input_data: Input, *, credentials: ExaCredentials, **kwargs) -> BlockOutput:\n    url = 'https://api.exa.ai/findSimilar'\n    headers = {'Content-Type': 'application/json', 'x-api-key': credentials.api_key.get_secret_value()}\n    payload = {'url': input_data.url, 'numResults': input_data.number_of_results, 'contents': input_data.contents.dict()}\n    optional_field_mapping = {'include_domains': 'includeDomains', 'exclude_domains': 'excludeDomains', 'include_text': 'includeText', 'exclude_text': 'excludeText'}\n    for (input_field, api_field) in optional_field_mapping.items():\n        value = getattr(input_data, input_field)\n        if value:\n            payload[api_field] = value\n    date_field_mapping = {'start_crawl_date': 'startCrawlDate', 'end_crawl_date': 'endCrawlDate', 'start_published_date': 'startPublishedDate', 'end_published_date': 'endPublishedDate'}\n    for (input_field, api_field) in date_field_mapping.items():\n        value = getattr(input_data, input_field, None)\n        if value:\n            payload[api_field] = value.strftime('%Y-%m-%dT%H:%M:%S.000Z')\n    try:\n        response = requests.post(url, headers=headers, json=payload)\n        response.raise_for_status()\n        data = response.json()\n        yield ('results', data.get('results', []))\n    except Exception as e:\n        yield ('error', str(e))\n        yield ('results', [])",
        "url = 'https://api.exa.ai/findSimilar'",
        "headers = {'Content-Type': 'application/json', 'x-api-key': credentials.api_key.get_secret_value()}",
        "payload = {'url': input_data.url, 'numResults': input_data.number_of_results, 'contents': input_data.contents.dict()}",
        "optional_field_mapping = {'include_domains': 'includeDomains', 'exclude_domains': 'excludeDomains', 'include_text': 'includeText', 'exclude_text': 'excludeText'}"
      ],
      "code": "from datetime import datetime\nfrom typing import Any, List\nfrom backend.blocks.exa._auth import ExaCredentials, ExaCredentialsField, ExaCredentialsInput\nfrom backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import SchemaField\nfrom backend.util.request import requests\nfrom .helpers import ContentSettings\nclass ExaFindSimilarBlock(Block):\n\n    class Input(BlockSchema):\n        credentials: ExaCredentialsInput = ExaCredentialsField()\n        url: str = SchemaField(description='The url for which you would like to find similar links')\n        number_of_results: int = SchemaField(description='Number of results to return', default=10, advanced=True)\n        include_domains: List[str] = SchemaField(description='Domains to include in search', default=[], advanced=True)\n        exclude_domains: List[str] = SchemaField(description='Domains to exclude from search', default=[], advanced=True)\n        start_crawl_date: datetime = SchemaField(description='Start date for crawled content')\n        end_crawl_date: datetime = SchemaField(description='End date for crawled content')\n        start_published_date: datetime = SchemaField(description='Start date for published content')\n        end_published_date: datetime = SchemaField(description='End date for published content')\n        include_text: List[str] = SchemaField(description='Text patterns to include (max 1 string, up to 5 words)', default=[], advanced=True)\n        exclude_text: List[str] = SchemaField(description='Text patterns to exclude (max 1 string, up to 5 words)', default=[], advanced=True)\n        contents: ContentSettings = SchemaField(description='Content retrieval settings', default=ContentSettings(), advanced=True)\n\n    class Output(BlockSchema):\n        results: List[Any] = SchemaField(description='List of similar documents with title, URL, published date, author, and score', default=[])\n\n    def __init__(self):\n        super().__init__(id='5e7315d1-af61-4a0c-9350-7c868fa7438a', description=\"Finds similar links using Exa's findSimilar API\", categories={BlockCategory.SEARCH}, input_schema=ExaFindSimilarBlock.Input, output_schema=ExaFindSimilarBlock.Output)\n\n    def run(self, input_data: Input, *, credentials: ExaCredentials, **kwargs) -> BlockOutput:\n        url = 'https://api.exa.ai/findSimilar'\n        headers = {'Content-Type': 'application/json', 'x-api-key': credentials.api_key.get_secret_value()}\n        payload = {'url': input_data.url, 'numResults': input_data.number_of_results, 'contents': input_data.contents.dict()}\n        optional_field_mapping = {'include_domains': 'includeDomains', 'exclude_domains': 'excludeDomains', 'include_text': 'includeText', 'exclude_text': 'excludeText'}\n        for (input_field, api_field) in optional_field_mapping.items():\n            value = getattr(input_data, input_field)\n            if value:\n                payload[api_field] = value\n        date_field_mapping = {'start_crawl_date': 'startCrawlDate', 'end_crawl_date': 'endCrawlDate', 'start_published_date': 'startPublishedDate', 'end_published_date': 'endPublishedDate'}\n        for (input_field, api_field) in date_field_mapping.items():\n            value = getattr(input_data, input_field, None)\n            if value:\n                payload[api_field] = value.strftime('%Y-%m-%dT%H:%M:%S.000Z')\n        try:\n            response = requests.post(url, headers=headers, json=payload)\n            response.raise_for_status()\n            data = response.json()\n            yield ('results', data.get('results', []))\n        except Exception as e:\n            yield ('error', str(e))\n            yield ('results', [])\nclass Input(BlockSchema):\n    credentials: ExaCredentialsInput = ExaCredentialsField()\n    url: str = SchemaField(description='The url for which you would like to find similar links')\n    number_of_results: int = SchemaField(description='Number of results to return', default=10, advanced=True)\n    include_domains: List[str] = SchemaField(description='Domains to include in search', default=[], advanced=True)\n    exclude_domains: List[str] = SchemaField(description='Domains to exclude from search', default=[], advanced=True)\n    start_crawl_date: datetime = SchemaField(description='Start date for crawled content')\n    end_crawl_date: datetime = SchemaField(description='End date for crawled content')\n    start_published_date: datetime = SchemaField(description='Start date for published content')\n    end_published_date: datetime = SchemaField(description='End date for published content')\n    include_text: List[str] = SchemaField(description='Text patterns to include (max 1 string, up to 5 words)', default=[], advanced=True)\n    exclude_text: List[str] = SchemaField(description='Text patterns to exclude (max 1 string, up to 5 words)', default=[], advanced=True)\n    contents: ContentSettings = SchemaField(description='Content retrieval settings', default=ContentSettings(), advanced=True)\ncredentials: ExaCredentialsInput = ExaCredentialsField()\nurl: str = SchemaField(description='The url for which you would like to find similar links')\nnumber_of_results: int = SchemaField(description='Number of results to return', default=10, advanced=True)\ninclude_domains: List[str] = SchemaField(description='Domains to include in search', default=[], advanced=True)\nexclude_domains: List[str] = SchemaField(description='Domains to exclude from search', default=[], advanced=True)\nstart_crawl_date: datetime = SchemaField(description='Start date for crawled content')\nend_crawl_date: datetime = SchemaField(description='End date for crawled content')\nstart_published_date: datetime = SchemaField(description='Start date for published content')\nend_published_date: datetime = SchemaField(description='End date for published content')\ninclude_text: List[str] = SchemaField(description='Text patterns to include (max 1 string, up to 5 words)', default=[], advanced=True)\nexclude_text: List[str] = SchemaField(description='Text patterns to exclude (max 1 string, up to 5 words)', default=[], advanced=True)\ncontents: ContentSettings = SchemaField(description='Content retrieval settings', default=ContentSettings(), advanced=True)\nclass Output(BlockSchema):\n    results: List[Any] = SchemaField(description='List of similar documents with title, URL, published date, author, and score', default=[])\nresults: List[Any] = SchemaField(description='List of similar documents with title, URL, published date, author, and score', default=[])\ndef __init__(self):\n    super().__init__(id='5e7315d1-af61-4a0c-9350-7c868fa7438a', description=\"Finds similar links using Exa's findSimilar API\", categories={BlockCategory.SEARCH}, input_schema=ExaFindSimilarBlock.Input, output_schema=ExaFindSimilarBlock.Output)\nsuper().__init__()\ndef run(self, input_data: Input, *, credentials: ExaCredentials, **kwargs) -> BlockOutput:\n    url = 'https://api.exa.ai/findSimilar'\n    headers = {'Content-Type': 'application/json', 'x-api-key': credentials.api_key.get_secret_value()}\n    payload = {'url': input_data.url, 'numResults': input_data.number_of_results, 'contents': input_data.contents.dict()}\n    optional_field_mapping = {'include_domains': 'includeDomains', 'exclude_domains': 'excludeDomains', 'include_text': 'includeText', 'exclude_text': 'excludeText'}\n    for (input_field, api_field) in optional_field_mapping.items():\n        value = getattr(input_data, input_field)\n        if value:\n            payload[api_field] = value\n    date_field_mapping = {'start_crawl_date': 'startCrawlDate', 'end_crawl_date': 'endCrawlDate', 'start_published_date': 'startPublishedDate', 'end_published_date': 'endPublishedDate'}\n    for (input_field, api_field) in date_field_mapping.items():\n        value = getattr(input_data, input_field, None)\n        if value:\n            payload[api_field] = value.strftime('%Y-%m-%dT%H:%M:%S.000Z')\n    try:\n        response = requests.post(url, headers=headers, json=payload)\n        response.raise_for_status()\n        data = response.json()\n        yield ('results', data.get('results', []))\n    except Exception as e:\n        yield ('error', str(e))\n        yield ('results', [])\nurl = 'https://api.exa.ai/findSimilar'\nheaders = {'Content-Type': 'application/json', 'x-api-key': credentials.api_key.get_secret_value()}\npayload = {'url': input_data.url, 'numResults': input_data.number_of_results, 'contents': input_data.contents.dict()}\noptional_field_mapping = {'include_domains': 'includeDomains', 'exclude_domains': 'excludeDomains', 'include_text': 'includeText', 'exclude_text': 'excludeText'}"
    },
    {
      "id": "n1",
      "type": "block",
      "statements": [
        "(input_field, api_field)",
        "optional_field_mapping.items()"
      ],
      "code": "(input_field, api_field)\noptional_field_mapping.items()"
    },
    {
      "id": "n2",
      "type": "block",
      "statements": [
        "value = getattr(input_data, input_field)",
        "value"
      ],
      "code": "value = getattr(input_data, input_field)\nvalue"
    },
    {
      "id": "n3",
      "type": "block",
      "statements": [
        "date_field_mapping = {'start_crawl_date': 'startCrawlDate', 'end_crawl_date': 'endCrawlDate', 'start_published_date': 'startPublishedDate', 'end_published_date': 'endPublishedDate'}"
      ],
      "code": "date_field_mapping = {'start_crawl_date': 'startCrawlDate', 'end_crawl_date': 'endCrawlDate', 'start_published_date': 'startPublishedDate', 'end_published_date': 'endPublishedDate'}"
    },
    {
      "id": "n4",
      "type": "block",
      "statements": [
        "payload[api_field] = value"
      ],
      "code": "payload[api_field] = value"
    },
    {
      "id": "n5",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n6",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n7",
      "type": "block",
      "statements": [
        "(input_field, api_field)",
        "date_field_mapping.items()"
      ],
      "code": "(input_field, api_field)\ndate_field_mapping.items()"
    },
    {
      "id": "n8",
      "type": "block",
      "statements": [
        "value = getattr(input_data, input_field, None)",
        "value"
      ],
      "code": "value = getattr(input_data, input_field, None)\nvalue"
    },
    {
      "id": "n9",
      "type": "block",
      "statements": [
        "try:\n    response = requests.post(url, headers=headers, json=payload)\n    response.raise_for_status()\n    data = response.json()\n    yield ('results', data.get('results', []))\nexcept Exception as e:\n    yield ('error', str(e))\n    yield ('results', [])",
        "response = requests.post(url, headers=headers, json=payload)",
        "response.raise_for_status()",
        "data = response.json()",
        "(yield ('results', data.get('results', [])))",
        "(yield ('error', str(e)))",
        "(yield ('results', []))"
      ],
      "code": "try:\n    response = requests.post(url, headers=headers, json=payload)\n    response.raise_for_status()\n    data = response.json()\n    yield ('results', data.get('results', []))\nexcept Exception as e:\n    yield ('error', str(e))\n    yield ('results', [])\nresponse = requests.post(url, headers=headers, json=payload)\nresponse.raise_for_status()\ndata = response.json()\n(yield ('results', data.get('results', [])))\n(yield ('error', str(e)))\n(yield ('results', []))"
    },
    {
      "id": "n10",
      "type": "block",
      "statements": [
        "payload[api_field] = value.strftime('%Y-%m-%dT%H:%M:%S.000Z')"
      ],
      "code": "payload[api_field] = value.strftime('%Y-%m-%dT%H:%M:%S.000Z')"
    },
    {
      "id": "n11",
      "type": "block",
      "statements": [],
      "code": ""
    },
    {
      "id": "n12",
      "type": "block",
      "statements": [],
      "code": ""
    }
  ],
  "edges": [
    {
      "source": "n12",
      "target": "n7"
    },
    {
      "source": "n5",
      "target": "n6"
    },
    {
      "source": "n1",
      "target": "n3"
    },
    {
      "source": "n8",
      "target": "n10"
    },
    {
      "source": "n0",
      "target": "n1"
    },
    {
      "source": "n6",
      "target": "n1"
    },
    {
      "source": "n2",
      "target": "n5"
    },
    {
      "source": "n2",
      "target": "n4"
    },
    {
      "source": "n1",
      "target": "n2"
    },
    {
      "source": "n4",
      "target": "n6"
    },
    {
      "source": "n10",
      "target": "n12"
    },
    {
      "source": "n11",
      "target": "n12"
    },
    {
      "source": "n7",
      "target": "n8"
    },
    {
      "source": "n8",
      "target": "n11"
    },
    {
      "source": "n3",
      "target": "n7"
    },
    {
      "source": "n7",
      "target": "n9"
    }
  ]
}