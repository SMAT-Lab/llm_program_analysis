{
    "nodes": [
        {
            "id": "1",
            "type": "block",
            "statements": [
                "from backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema",
                "from backend.data.model import ContributorDetails, SchemaField",
                "class ReadCsvBlock(Block):\n\n    class Input(BlockSchema):\n        contents: str = SchemaField(description='The contents of the CSV file to read', placeholder='a, b, c\\n1,2,3\\n4,5,6')\n        delimiter: str = SchemaField(description='The delimiter used in the CSV file', default=',')\n        quotechar: str = SchemaField(description='The character used to quote fields', default='\"')\n        escapechar: str = SchemaField(description='The character used to escape the delimiter', default='\\\\')\n        has_header: bool = SchemaField(description='Whether the CSV file has a header row', default=True)\n        skip_rows: int = SchemaField(description='The number of rows to skip from the start of the file', default=0)\n        strip: bool = SchemaField(description='Whether to strip whitespace from the values', default=True)\n        skip_columns: list[str] = SchemaField(description='The columns to skip from the start of the row', default=[])\n\n    class Output(BlockSchema):\n        row: dict[str, str] = SchemaField(description='The data produced from each row in the CSV file')\n        all_data: list[dict[str, str]] = SchemaField(description='All the data in the CSV file as a list of rows')\n\n    def __init__(self):\n        super().__init__(id='acf7625e-d2cb-4941-bfeb-2819fc6fc015', input_schema=ReadCsvBlock.Input, output_schema=ReadCsvBlock.Output, description='Reads a CSV file and outputs the data as a list of dictionaries and individual rows via rows.', contributors=[ContributorDetails(name='Nicholas Tindle')], categories={BlockCategory.TEXT, BlockCategory.DATA}, test_input={'contents': 'a, b, c\\n1,2,3\\n4,5,6'}, test_output=[('row', {'a': '1', 'b': '2', 'c': '3'}), ('row', {'a': '4', 'b': '5', 'c': '6'}), ('all_data', [{'a': '1', 'b': '2', 'c': '3'}, {'a': '4', 'b': '5', 'c': '6'}])])\n\n    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        import csv\n        from io import StringIO\n        csv_file = StringIO(input_data.contents)\n        reader = csv.reader(csv_file, delimiter=input_data.delimiter, quotechar=input_data.quotechar, escapechar=input_data.escapechar)\n        header = None\n        if input_data.has_header:\n            header = next(reader)\n            if input_data.strip:\n                header = [h.strip() for h in header]\n        for _ in range(input_data.skip_rows):\n            next(reader)\n\n        def process_row(row):\n            data = {}\n            for (i, value) in enumerate(row):\n                if i not in input_data.skip_columns:\n                    if input_data.has_header and header:\n                        data[header[i]] = value.strip() if input_data.strip else value\n                    else:\n                        data[str(i)] = value.strip() if input_data.strip else value\n            return data\n        all_data = []\n        for row in reader:\n            processed_row = process_row(row)\n            all_data.append(processed_row)\n            yield ('row', processed_row)\n        yield ('all_data', all_data)",
                "class Input(BlockSchema):\n    contents: str = SchemaField(description='The contents of the CSV file to read', placeholder='a, b, c\\n1,2,3\\n4,5,6')\n    delimiter: str = SchemaField(description='The delimiter used in the CSV file', default=',')\n    quotechar: str = SchemaField(description='The character used to quote fields', default='\"')\n    escapechar: str = SchemaField(description='The character used to escape the delimiter', default='\\\\')\n    has_header: bool = SchemaField(description='Whether the CSV file has a header row', default=True)\n    skip_rows: int = SchemaField(description='The number of rows to skip from the start of the file', default=0)\n    strip: bool = SchemaField(description='Whether to strip whitespace from the values', default=True)\n    skip_columns: list[str] = SchemaField(description='The columns to skip from the start of the row', default=[])",
                "contents: str = SchemaField(description='The contents of the CSV file to read', placeholder='a, b, c\\n1,2,3\\n4,5,6')",
                "delimiter: str = SchemaField(description='The delimiter used in the CSV file', default=',')",
                "quotechar: str = SchemaField(description='The character used to quote fields', default='\"')",
                "escapechar: str = SchemaField(description='The character used to escape the delimiter', default='\\\\')",
                "has_header: bool = SchemaField(description='Whether the CSV file has a header row', default=True)",
                "skip_rows: int = SchemaField(description='The number of rows to skip from the start of the file', default=0)",
                "strip: bool = SchemaField(description='Whether to strip whitespace from the values', default=True)",
                "skip_columns: list[str] = SchemaField(description='The columns to skip from the start of the row', default=[])",
                "class Output(BlockSchema):\n    row: dict[str, str] = SchemaField(description='The data produced from each row in the CSV file')\n    all_data: list[dict[str, str]] = SchemaField(description='All the data in the CSV file as a list of rows')",
                "row: dict[str, str] = SchemaField(description='The data produced from each row in the CSV file')",
                "all_data: list[dict[str, str]] = SchemaField(description='All the data in the CSV file as a list of rows')",
                "def __init__(self):\n    super().__init__(id='acf7625e-d2cb-4941-bfeb-2819fc6fc015', input_schema=ReadCsvBlock.Input, output_schema=ReadCsvBlock.Output, description='Reads a CSV file and outputs the data as a list of dictionaries and individual rows via rows.', contributors=[ContributorDetails(name='Nicholas Tindle')], categories={BlockCategory.TEXT, BlockCategory.DATA}, test_input={'contents': 'a, b, c\\n1,2,3\\n4,5,6'}, test_output=[('row', {'a': '1', 'b': '2', 'c': '3'}), ('row', {'a': '4', 'b': '5', 'c': '6'}), ('all_data', [{'a': '1', 'b': '2', 'c': '3'}, {'a': '4', 'b': '5', 'c': '6'}])])",
                "super().__init__()",
                "def run(self, input_data: Input, **kwargs) -> BlockOutput:\n    import csv\n    from io import StringIO\n    csv_file = StringIO(input_data.contents)\n    reader = csv.reader(csv_file, delimiter=input_data.delimiter, quotechar=input_data.quotechar, escapechar=input_data.escapechar)\n    header = None\n    if input_data.has_header:\n        header = next(reader)\n        if input_data.strip:\n            header = [h.strip() for h in header]\n    for _ in range(input_data.skip_rows):\n        next(reader)\n\n    def process_row(row):\n        data = {}\n        for (i, value) in enumerate(row):\n            if i not in input_data.skip_columns:\n                if input_data.has_header and header:\n                    data[header[i]] = value.strip() if input_data.strip else value\n                else:\n                    data[str(i)] = value.strip() if input_data.strip else value\n        return data\n    all_data = []\n    for row in reader:\n        processed_row = process_row(row)\n        all_data.append(processed_row)\n        yield ('row', processed_row)\n    yield ('all_data', all_data)",
                "import csv",
                "from io import StringIO",
                "csv_file = StringIO(input_data.contents)",
                "reader = csv.reader(csv_file, delimiter=input_data.delimiter, quotechar=input_data.quotechar, escapechar=input_data.escapechar)",
                "header = None",
                "input_data.has_header"
            ]
        },
        {
            "id": "2",
            "type": "block",
            "statements": [
                "header = next(reader)",
                "input_data.strip"
            ]
        },
        {
            "id": "3",
            "type": "block",
            "statements": []
        },
        {
            "id": "4",
            "type": "block",
            "statements": []
        },
        {
            "id": "5",
            "type": "block",
            "statements": [
                "header = [h.strip() for h in header]"
            ]
        },
        {
            "id": "6",
            "type": "block",
            "statements": []
        },
        {
            "id": "7",
            "type": "block",
            "statements": []
        },
        {
            "id": "8",
            "type": "block",
            "statements": [
                "_",
                "range(input_data.skip_rows)"
            ]
        },
        {
            "id": "9",
            "type": "block",
            "statements": [
                "next(reader)"
            ]
        },
        {
            "id": "10",
            "type": "block",
            "statements": [
                "def process_row(row):\n    data = {}\n    for (i, value) in enumerate(row):\n        if i not in input_data.skip_columns:\n            if input_data.has_header and header:\n                data[header[i]] = value.strip() if input_data.strip else value\n            else:\n                data[str(i)] = value.strip() if input_data.strip else value\n    return data",
                "data = {}"
            ]
        },
        {
            "id": "11",
            "type": "block",
            "statements": [
                "(i, value)",
                "enumerate(row)"
            ]
        },
        {
            "id": "12",
            "type": "block",
            "statements": [
                "i NotIn input_data.skip_columns"
            ]
        },
        {
            "id": "13",
            "type": "block",
            "statements": [
                "return data"
            ]
        },
        {
            "id": "14",
            "type": "block",
            "statements": [
                "input_data.has_header and header"
            ]
        },
        {
            "id": "15",
            "type": "block",
            "statements": []
        },
        {
            "id": "16",
            "type": "block",
            "statements": []
        },
        {
            "id": "17",
            "type": "block",
            "statements": [
                "data[header[i]] = value.strip() if input_data.strip else value"
            ]
        },
        {
            "id": "18",
            "type": "block",
            "statements": [
                "data[str(i)] = value.strip() if input_data.strip else value"
            ]
        },
        {
            "id": "19",
            "type": "block",
            "statements": []
        },
        {
            "id": "20",
            "type": "block",
            "statements": [
                "all_data = []"
            ]
        },
        {
            "id": "21",
            "type": "block",
            "statements": [
                "row",
                "reader"
            ]
        },
        {
            "id": "22",
            "type": "block",
            "statements": [
                "processed_row = process_row(row)",
                "all_data.append(processed_row)",
                "(yield ('row', processed_row))"
            ]
        },
        {
            "id": "23",
            "type": "block",
            "statements": [
                "(yield ('all_data', all_data))"
            ]
        }
    ],
    "edges": [
        {
            "source": "1",
            "target": "2",
            "type": "true"
        },
        {
            "source": "1",
            "target": "3",
            "type": "false"
        },
        {
            "source": "2",
            "target": "5",
            "type": "true"
        },
        {
            "source": "2",
            "target": "6",
            "type": "false"
        },
        {
            "source": "3",
            "target": "4",
            "type": "next"
        },
        {
            "source": "4",
            "target": "8",
            "type": "next"
        },
        {
            "source": "5",
            "target": "7",
            "type": "next"
        },
        {
            "source": "6",
            "target": "7",
            "type": "next"
        },
        {
            "source": "7",
            "target": "4",
            "type": "next"
        },
        {
            "source": "8",
            "target": "9",
            "type": "true"
        },
        {
            "source": "8",
            "target": "10",
            "type": "false"
        },
        {
            "source": "9",
            "target": "8",
            "type": "next"
        },
        {
            "source": "10",
            "target": "11",
            "type": "next"
        },
        {
            "source": "11",
            "target": "12",
            "type": "true"
        },
        {
            "source": "11",
            "target": "13",
            "type": "false"
        },
        {
            "source": "12",
            "target": "14",
            "type": "true"
        },
        {
            "source": "12",
            "target": "15",
            "type": "false"
        },
        {
            "source": "14",
            "target": "17",
            "type": "true"
        },
        {
            "source": "14",
            "target": "18",
            "type": "false"
        },
        {
            "source": "15",
            "target": "16",
            "type": "next"
        },
        {
            "source": "16",
            "target": "11",
            "type": "next"
        },
        {
            "source": "17",
            "target": "19",
            "type": "next"
        },
        {
            "source": "18",
            "target": "19",
            "type": "next"
        },
        {
            "source": "19",
            "target": "16",
            "type": "next"
        },
        {
            "source": "20",
            "target": "21",
            "type": "next"
        },
        {
            "source": "21",
            "target": "22",
            "type": "true"
        },
        {
            "source": "21",
            "target": "23",
            "type": "false"
        },
        {
            "source": "22",
            "target": "21",
            "type": "next"
        }
    ]
}