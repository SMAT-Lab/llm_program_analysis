{
  "nodes": [
    {
      "id": "n0",
      "code": "from backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import ContributorDetails, SchemaField\n\n\n\n\n"
    },
    {
      "id": "n1",
      "code": "class ReadCsvBlock(Block):\n\n    class Input(BlockSchema):\n        contents: str = SchemaField(\n            description=\"The contents of the CSV file to read\",\n            placeholder=\"a, b, c\\n1,2,3\\n4,5,6\",\n        )\n        delimiter: str = SchemaField(\n            description=\"The delimiter used in the CSV file\",\n            default=\",\",\n        )\n        quotechar: str = SchemaField(\n            description=\"The character used to quote fields\",\n            default='\"',\n        )\n        escapechar: str = SchemaField(\n            description=\"The character used to escape the delimiter\",\n            default=\"\\\\\",\n        )\n        has_header: bool = SchemaField(\n            description=\"Whether the CSV file has a header row\",\n            default=True,\n        )\n        skip_rows: int = SchemaField(\n            description=\"The number of rows to skip from the start of the file\",\n            default=0,\n        )\n        strip: bool = SchemaField(\n            description=\"Whether to strip whitespace from the values\",\n            default=True,\n        )\n        skip_columns: list[str] = SchemaField(\n            description=\"The columns to skip from the start of the row\",\n            default=[],\n        )\n\n    class Output(BlockSchema):\n        row: dict[str, str] = SchemaField(\n            description=\"The data produced from each row in the CSV file\"\n        )\n        all_data: list[dict[str, str]] = SchemaField(\n            description=\"All the data in the CSV file as a list of rows\"\n        )\n\n    def __init__(self):\n        super().__init__(\n            id=\"acf7625e-d2cb-4941-bfeb-2819fc6fc015\",\n            input_schema=ReadCsvBlock.Input,\n            output_schema=ReadCsvBlock.Output,\n            description=\"Reads a CSV file and outputs the data as a list of dictionaries and individual rows via rows.\",\n            contributors=[ContributorDetails(name=\"Nicholas Tindle\")],\n            categories={BlockCategory.TEXT, BlockCategory.DATA},\n            test_input={\n                \"contents\": \"a, b, c\\n1,2,3\\n4,5,6\",\n            },\n            test_output=[\n                (\"row\", {\"a\": \"1\", \"b\": \"2\", \"c\": \"3\"}),\n                (\"row\", {\"a\": \"4\", \"b\": \"5\", \"c\": \"6\"}),\n                (\n                    \"all_data\",\n                    [\n                        {\"a\": \"1\", \"b\": \"2\", \"c\": \"3\"},\n                        {\"a\": \"4\", \"b\": \"5\", \"c\": \"6\"},\n                    ],\n                ),\n            ],\n        )\n\n    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n        import csv\n        from io import StringIO\n\n\n        csv_file = StringIO(input_data.contents)\n        reader = csv.reader(\n            csv_file,\n            delimiter=input_data.delimiter,\n            quotechar=input_data.quotechar,\n            escapechar=input_data.escapechar,\n        )\n\n        header = None\n        if input_data.has_header:\n            header = next(reader)\n            if input_data.strip:\n                header = [h.strip() for h in header]\n\n\n        for _ in range(input_data.skip_rows):\n            next(reader)\n\n        def process_row(row):\n            data = {}\n            for i, value in enumerate(row):\n                if i not in input_data.skip_columns:\n                    if input_data.has_header and header:\n                        data[header[i]] = value.strip() if input_data.strip else value\n                    else:\n                        data[str(i)] = value.strip() if input_data.strip else value\n            return data\n"
    },
    {
      "id": "n2",
      "code": "        all_data = []\n        for row in reader:\n            processed_row = process_row(row)\n            all_data.append(processed_row)\n            yield \"row\", processed_row\n"
    },
    {
      "id": "n3",
      "code": "        yield \"all_data\", all_data\n"
    },
    {
      "id": "n4",
      "code": "    class Input(BlockSchema):\n\n        contents: str = SchemaField(\n            description=\"The contents of the CSV file to read\",\n            placeholder=\"a, b, c\\n1,2,3\\n4,5,6\",\n        )\n\n        delimiter: str = SchemaField(\n            description=\"The delimiter used in the CSV file\",\n            default=\",\",\n        )\n\n        quotechar: str = SchemaField(\n            description=\"The character used to quote fields\",\n            default='\"',\n        )\n\n        escapechar: str = SchemaField(\n            description=\"The character used to escape the delimiter\",\n            default=\"\\\\\",\n        )\n\n        has_header: bool = SchemaField(\n            description=\"Whether the CSV file has a header row\",\n            default=True,\n        )\n\n        skip_rows: int = SchemaField(\n            description=\"The number of rows to skip from the start of the file\",\n            default=0,\n        )\n\n        strip: bool = SchemaField(\n            description=\"Whether to strip whitespace from the values\",\n            default=True,\n        )\n\n        skip_columns: list[str] = SchemaField(\n            description=\"The columns to skip from the start of the row\",\n            default=[],\n        )\n"
    },
    {
      "id": "n5",
      "code": "    class Output(BlockSchema):\n\n        row: dict[str, str] = SchemaField(\n            description=\"The data produced from each row in the CSV file\"\n        )\n\n        all_data: list[dict[str, str]] = SchemaField(\n            description=\"All the data in the CSV file as a list of rows\"\n        )\n"
    },
    {
      "id": "n6",
      "code": "    def __init__(self):\n        super().__init__(\n            id=\"acf7625e-d2cb-4941-bfeb-2819fc6fc015\",\n            input_schema=ReadCsvBlock.Input,\n            output_schema=ReadCsvBlock.Output,\n            description=\"Reads a CSV file and outputs the data as a list of dictionaries and individual rows via rows.\",\n            contributors=[ContributorDetails(name=\"Nicholas Tindle\")],\n            categories={BlockCategory.TEXT, BlockCategory.DATA},\n            test_input={\n                \"contents\": \"a, b, c\\n1,2,3\\n4,5,6\",\n            },\n            test_output=[\n                (\"row\", {\"a\": \"1\", \"b\": \"2\", \"c\": \"3\"}),\n                (\"row\", {\"a\": \"4\", \"b\": \"5\", \"c\": \"6\"}),\n                (\n                    \"all_data\",\n                    [\n                        {\"a\": \"1\", \"b\": \"2\", \"c\": \"3\"},\n                        {\"a\": \"4\", \"b\": \"5\", \"c\": \"6\"},\n                    ],\n                ),\n            ],\n        )\n"
    },
    {
      "id": "n7",
      "code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n\n        import csv\n        from io import StringIO\n\n        csv_file = StringIO(input_data.contents)\n        reader = csv.reader(\n            csv_file,\n            delimiter=input_data.delimiter,\n            quotechar=input_data.quotechar,\n            escapechar=input_data.escapechar,\n        )\n\n        header = None\n\n        if input_data.has_header:\n            header = next(reader)\n            if input_data.strip:\n                header = [h.strip() for h in header]\n\n\n        for _ in range(input_data.skip_rows):\n            next(reader)\n\n        def process_row(row):\n            data = {}\n            for i, value in enumerate(row):\n                if i not in input_data.skip_columns:\n                    if input_data.has_header and header:\n                        data[header[i]] = value.strip() if input_data.strip else value\n                    else:\n                        data[str(i)] = value.strip() if input_data.strip else value\n            return data\n"
    },
    {
      "id": "n8",
      "code": "        all_data = []\n        for row in reader:\n            processed_row = process_row(row)\n            all_data.append(processed_row)\n            yield \"row\", processed_row\n"
    },
    {
      "id": "n9",
      "code": "        yield \"all_data\", all_data\n"
    }
  ],
  "edges": [
    {
      "source": "n8",
      "target": "n9"
    },
    {
      "source": "n8",
      "target": "n8"
    },
    {
      "source": "n2",
      "target": "n2"
    },
    {
      "source": "n1",
      "target": "n2"
    },
    {
      "source": "n7",
      "target": "n8"
    },
    {
      "source": "n2",
      "target": "n3"
    }
  ]
}