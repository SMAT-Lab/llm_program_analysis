{
  "nodes": [
    {
      "id": "1",
      "type": "block",
      "statements": [
        "import uuid",
        "from typing import Any, Literal",
        "from pinecone import Pinecone, ServerlessSpec",
        "from backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema",
        "from backend.data.model import APIKeyCredentials, CredentialsField, CredentialsMetaInput, SchemaField",
        "from backend.integrations.providers import ProviderName",
        "PineconeCredentials = APIKeyCredentials",
        "PineconeCredentialsInput = CredentialsMetaInput[Literal[ProviderName.PINECONE], Literal['api_key']]",
        "def PineconeCredentialsField() -> PineconeCredentialsInput:\n    \"\"\"Creates a Pinecone credentials input on a block.\"\"\"\n    return CredentialsField(description='The Pinecone integration can be used with an API Key.')",
        "'Creates a Pinecone credentials input on a block.'",
        "return CredentialsField(description='The Pinecone integration can be used with an API Key.')"
      ]
    },
    {
      "id": "2",
      "type": "block",
      "statements": [
        "class PineconeInitBlock(Block):\n\n    class Input(BlockSchema):\n        credentials: PineconeCredentialsInput = PineconeCredentialsField()\n        index_name: str = SchemaField(description='Name of the Pinecone index')\n        dimension: int = SchemaField(description='Dimension of the vectors', default=768)\n        metric: str = SchemaField(description='Distance metric for the index', default='cosine')\n        cloud: str = SchemaField(description='Cloud provider for serverless', default='aws')\n        region: str = SchemaField(description='Region for serverless', default='us-east-1')\n\n    class Output(BlockSchema):\n        index: str = SchemaField(description='Name of the initialized Pinecone index')\n        message: str = SchemaField(description='Status message')\n\n    def __init__(self):\n        super().__init__(id='48d8fdab-8f03-41f3-8407-8107ba11ec9b', description='Initializes a Pinecone index', categories={BlockCategory.LOGIC}, input_schema=PineconeInitBlock.Input, output_schema=PineconeInitBlock.Output)\n\n    def run(self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs) -> BlockOutput:\n        pc = Pinecone(api_key=credentials.api_key.get_secret_value())\n        try:\n            existing_indexes = pc.list_indexes()\n            if input_data.index_name not in [index.name for index in existing_indexes]:\n                pc.create_index(name=input_data.index_name, dimension=input_data.dimension, metric=input_data.metric, spec=ServerlessSpec(cloud=input_data.cloud, region=input_data.region))\n                message = f'Created new index: {input_data.index_name}'\n            else:\n                message = f'Using existing index: {input_data.index_name}'\n            yield ('index', input_data.index_name)\n            yield ('message', message)\n        except Exception as e:\n            yield ('message', f'Error initializing Pinecone index: {str(e)}')",
        "class Input(BlockSchema):\n    credentials: PineconeCredentialsInput = PineconeCredentialsField()\n    index_name: str = SchemaField(description='Name of the Pinecone index')\n    dimension: int = SchemaField(description='Dimension of the vectors', default=768)\n    metric: str = SchemaField(description='Distance metric for the index', default='cosine')\n    cloud: str = SchemaField(description='Cloud provider for serverless', default='aws')\n    region: str = SchemaField(description='Region for serverless', default='us-east-1')",
        "credentials: PineconeCredentialsInput = PineconeCredentialsField()",
        "index_name: str = SchemaField(description='Name of the Pinecone index')",
        "dimension: int = SchemaField(description='Dimension of the vectors', default=768)",
        "metric: str = SchemaField(description='Distance metric for the index', default='cosine')",
        "cloud: str = SchemaField(description='Cloud provider for serverless', default='aws')",
        "region: str = SchemaField(description='Region for serverless', default='us-east-1')",
        "class Output(BlockSchema):\n    index: str = SchemaField(description='Name of the initialized Pinecone index')\n    message: str = SchemaField(description='Status message')",
        "index: str = SchemaField(description='Name of the initialized Pinecone index')",
        "message: str = SchemaField(description='Status message')",
        "def __init__(self):\n    super().__init__(id='48d8fdab-8f03-41f3-8407-8107ba11ec9b', description='Initializes a Pinecone index', categories={BlockCategory.LOGIC}, input_schema=PineconeInitBlock.Input, output_schema=PineconeInitBlock.Output)",
        "super().__init__()",
        "def run(self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs) -> BlockOutput:\n    pc = Pinecone(api_key=credentials.api_key.get_secret_value())\n    try:\n        existing_indexes = pc.list_indexes()\n        if input_data.index_name not in [index.name for index in existing_indexes]:\n            pc.create_index(name=input_data.index_name, dimension=input_data.dimension, metric=input_data.metric, spec=ServerlessSpec(cloud=input_data.cloud, region=input_data.region))\n            message = f'Created new index: {input_data.index_name}'\n        else:\n            message = f'Using existing index: {input_data.index_name}'\n        yield ('index', input_data.index_name)\n        yield ('message', message)\n    except Exception as e:\n        yield ('message', f'Error initializing Pinecone index: {str(e)}')",
        "pc = Pinecone(api_key=credentials.api_key.get_secret_value())",
        "try:\n    existing_indexes = pc.list_indexes()\n    if input_data.index_name not in [index.name for index in existing_indexes]:\n        pc.create_index(name=input_data.index_name, dimension=input_data.dimension, metric=input_data.metric, spec=ServerlessSpec(cloud=input_data.cloud, region=input_data.region))\n        message = f'Created new index: {input_data.index_name}'\n    else:\n        message = f'Using existing index: {input_data.index_name}'\n    yield ('index', input_data.index_name)\n    yield ('message', message)\nexcept Exception as e:\n    yield ('message', f'Error initializing Pinecone index: {str(e)}')",
        "existing_indexes = pc.list_indexes()",
        "input_data.index_name NotIn [index.name for index in existing_indexes]"
      ]
    },
    {
      "id": "3",
      "type": "block",
      "statements": [
        "pc.create_index()",
        "message = f'Created new index: {input_data.index_name}'"
      ]
    },
    {
      "id": "4",
      "type": "block",
      "statements": [
        "message = f'Using existing index: {input_data.index_name}'"
      ]
    },
    {
      "id": "5",
      "type": "block",
      "statements": [
        "(yield ('index', input_data.index_name))",
        "(yield ('message', message))",
        "(yield ('message', f'Error initializing Pinecone index: {str(e)}'))",
        "class PineconeQueryBlock(Block):\n\n    class Input(BlockSchema):\n        credentials: PineconeCredentialsInput = PineconeCredentialsField()\n        query_vector: list = SchemaField(description='Query vector')\n        namespace: str = SchemaField(description='Namespace to query in Pinecone', default='')\n        top_k: int = SchemaField(description='Number of top results to return', default=3)\n        include_values: bool = SchemaField(description='Whether to include vector values in the response', default=False)\n        include_metadata: bool = SchemaField(description='Whether to include metadata in the response', default=True)\n        host: str = SchemaField(description='Host for pinecone', default='')\n        idx_name: str = SchemaField(description='Index name for pinecone')\n\n    class Output(BlockSchema):\n        results: Any = SchemaField(description='Query results from Pinecone')\n        combined_results: Any = SchemaField(description='Combined results from Pinecone')\n\n    def __init__(self):\n        super().__init__(id='9ad93d0f-91b4-4c9c-8eb1-82e26b4a01c5', description='Queries a Pinecone index', categories={BlockCategory.LOGIC}, input_schema=PineconeQueryBlock.Input, output_schema=PineconeQueryBlock.Output)\n\n    def run(self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs) -> BlockOutput:\n        try:\n            pc = Pinecone(api_key=credentials.api_key.get_secret_value())\n            idx = pc.Index(input_data.idx_name)\n            query_vector = input_data.query_vector\n            if isinstance(query_vector, list) and len(query_vector) > 0:\n                if isinstance(query_vector[0], list):\n                    query_vector = query_vector[0]\n            results = idx.query(namespace=input_data.namespace, vector=query_vector, top_k=input_data.top_k, include_values=input_data.include_values, include_metadata=input_data.include_metadata).to_dict()\n            combined_text = ''\n            if results['matches']:\n                texts = [match['metadata']['text'] for match in results['matches'] if match.get('metadata', {}).get('text')]\n                combined_text = '\\n\\n'.join(texts)\n            yield ('results', {'matches': results['matches'], 'combined_text': combined_text})\n            yield ('combined_results', combined_text)\n        except Exception as e:\n            error_msg = f'Error querying Pinecone: {str(e)}'\n            raise RuntimeError(error_msg) from e",
        "class Input(BlockSchema):\n    credentials: PineconeCredentialsInput = PineconeCredentialsField()\n    query_vector: list = SchemaField(description='Query vector')\n    namespace: str = SchemaField(description='Namespace to query in Pinecone', default='')\n    top_k: int = SchemaField(description='Number of top results to return', default=3)\n    include_values: bool = SchemaField(description='Whether to include vector values in the response', default=False)\n    include_metadata: bool = SchemaField(description='Whether to include metadata in the response', default=True)\n    host: str = SchemaField(description='Host for pinecone', default='')\n    idx_name: str = SchemaField(description='Index name for pinecone')",
        "credentials: PineconeCredentialsInput = PineconeCredentialsField()",
        "query_vector: list = SchemaField(description='Query vector')",
        "namespace: str = SchemaField(description='Namespace to query in Pinecone', default='')",
        "top_k: int = SchemaField(description='Number of top results to return', default=3)",
        "include_values: bool = SchemaField(description='Whether to include vector values in the response', default=False)",
        "include_metadata: bool = SchemaField(description='Whether to include metadata in the response', default=True)",
        "host: str = SchemaField(description='Host for pinecone', default='')",
        "idx_name: str = SchemaField(description='Index name for pinecone')",
        "class Output(BlockSchema):\n    results: Any = SchemaField(description='Query results from Pinecone')\n    combined_results: Any = SchemaField(description='Combined results from Pinecone')",
        "results: Any = SchemaField(description='Query results from Pinecone')",
        "combined_results: Any = SchemaField(description='Combined results from Pinecone')",
        "def __init__(self):\n    super().__init__(id='9ad93d0f-91b4-4c9c-8eb1-82e26b4a01c5', description='Queries a Pinecone index', categories={BlockCategory.LOGIC}, input_schema=PineconeQueryBlock.Input, output_schema=PineconeQueryBlock.Output)",
        "super().__init__()",
        "def run(self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs) -> BlockOutput:\n    try:\n        pc = Pinecone(api_key=credentials.api_key.get_secret_value())\n        idx = pc.Index(input_data.idx_name)\n        query_vector = input_data.query_vector\n        if isinstance(query_vector, list) and len(query_vector) > 0:\n            if isinstance(query_vector[0], list):\n                query_vector = query_vector[0]\n        results = idx.query(namespace=input_data.namespace, vector=query_vector, top_k=input_data.top_k, include_values=input_data.include_values, include_metadata=input_data.include_metadata).to_dict()\n        combined_text = ''\n        if results['matches']:\n            texts = [match['metadata']['text'] for match in results['matches'] if match.get('metadata', {}).get('text')]\n            combined_text = '\\n\\n'.join(texts)\n        yield ('results', {'matches': results['matches'], 'combined_text': combined_text})\n        yield ('combined_results', combined_text)\n    except Exception as e:\n        error_msg = f'Error querying Pinecone: {str(e)}'\n        raise RuntimeError(error_msg) from e",
        "try:\n    pc = Pinecone(api_key=credentials.api_key.get_secret_value())\n    idx = pc.Index(input_data.idx_name)\n    query_vector = input_data.query_vector\n    if isinstance(query_vector, list) and len(query_vector) > 0:\n        if isinstance(query_vector[0], list):\n            query_vector = query_vector[0]\n    results = idx.query(namespace=input_data.namespace, vector=query_vector, top_k=input_data.top_k, include_values=input_data.include_values, include_metadata=input_data.include_metadata).to_dict()\n    combined_text = ''\n    if results['matches']:\n        texts = [match['metadata']['text'] for match in results['matches'] if match.get('metadata', {}).get('text')]\n        combined_text = '\\n\\n'.join(texts)\n    yield ('results', {'matches': results['matches'], 'combined_text': combined_text})\n    yield ('combined_results', combined_text)\nexcept Exception as e:\n    error_msg = f'Error querying Pinecone: {str(e)}'\n    raise RuntimeError(error_msg) from e",
        "pc = Pinecone(api_key=credentials.api_key.get_secret_value())",
        "idx = pc.Index(input_data.idx_name)",
        "query_vector = input_data.query_vector",
        "isinstance(query_vector, list) and len(query_vector) > 0"
      ]
    },
    {
      "id": "6",
      "type": "block",
      "statements": [
        "isinstance(query_vector[0], list)"
      ]
    },
    {
      "id": "7",
      "type": "block",
      "statements": []
    },
    {
      "id": "8",
      "type": "block",
      "statements": [
        "results = idx.query(namespace=input_data.namespace, vector=query_vector, top_k=input_data.top_k, include_values=input_data.include_values, include_metadata=input_data.include_metadata).to_dict()",
        "combined_text = ''",
        "results['matches']"
      ]
    },
    {
      "id": "9",
      "type": "block",
      "statements": [
        "query_vector = query_vector[0]"
      ]
    },
    {
      "id": "10",
      "type": "block",
      "statements": []
    },
    {
      "id": "11",
      "type": "block",
      "statements": []
    },
    {
      "id": "12",
      "type": "block",
      "statements": [
        "texts = [match['metadata']['text'] for match in results['matches'] if match.get('metadata', {}).get('text')]",
        "combined_text = '\\n\\n'.join(texts)"
      ]
    },
    {
      "id": "13",
      "type": "block",
      "statements": []
    },
    {
      "id": "14",
      "type": "block",
      "statements": [
        "(yield ('results', {'matches': results['matches'], 'combined_text': combined_text}))",
        "(yield ('combined_results', combined_text))",
        "error_msg = f'Error querying Pinecone: {str(e)}'",
        "raise RuntimeError(error_msg) from e",
        "class PineconeInsertBlock(Block):\n\n    class Input(BlockSchema):\n        credentials: PineconeCredentialsInput = PineconeCredentialsField()\n        index: str = SchemaField(description='Initialized Pinecone index')\n        chunks: list = SchemaField(description='List of text chunks to ingest')\n        embeddings: list = SchemaField(description='List of embeddings corresponding to the chunks')\n        namespace: str = SchemaField(description='Namespace to use in Pinecone', default='')\n        metadata: dict = SchemaField(description='Additional metadata to store with each vector', default={})\n\n    class Output(BlockSchema):\n        upsert_response: str = SchemaField(description='Response from Pinecone upsert operation')\n\n    def __init__(self):\n        super().__init__(id='477f2168-cd91-475a-8146-9499a5982434', description='Upload data to a Pinecone index', categories={BlockCategory.LOGIC}, input_schema=PineconeInsertBlock.Input, output_schema=PineconeInsertBlock.Output)\n\n    def run(self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs) -> BlockOutput:\n        try:\n            pc = Pinecone(api_key=credentials.api_key.get_secret_value())\n            idx = pc.Index(input_data.index)\n            vectors = []\n            for (chunk, embedding) in zip(input_data.chunks, input_data.embeddings):\n                vector_metadata = input_data.metadata.copy()\n                vector_metadata['text'] = chunk\n                vectors.append({'id': str(uuid.uuid4()), 'values': embedding, 'metadata': vector_metadata})\n            idx.upsert(vectors=vectors, namespace=input_data.namespace)\n            yield ('upsert_response', 'successfully upserted')\n        except Exception as e:\n            error_msg = f'Error uploading to Pinecone: {str(e)}'\n            raise RuntimeError(error_msg) from e",
        "class Input(BlockSchema):\n    credentials: PineconeCredentialsInput = PineconeCredentialsField()\n    index: str = SchemaField(description='Initialized Pinecone index')\n    chunks: list = SchemaField(description='List of text chunks to ingest')\n    embeddings: list = SchemaField(description='List of embeddings corresponding to the chunks')\n    namespace: str = SchemaField(description='Namespace to use in Pinecone', default='')\n    metadata: dict = SchemaField(description='Additional metadata to store with each vector', default={})",
        "credentials: PineconeCredentialsInput = PineconeCredentialsField()",
        "index: str = SchemaField(description='Initialized Pinecone index')",
        "chunks: list = SchemaField(description='List of text chunks to ingest')",
        "embeddings: list = SchemaField(description='List of embeddings corresponding to the chunks')",
        "namespace: str = SchemaField(description='Namespace to use in Pinecone', default='')",
        "metadata: dict = SchemaField(description='Additional metadata to store with each vector', default={})",
        "class Output(BlockSchema):\n    upsert_response: str = SchemaField(description='Response from Pinecone upsert operation')",
        "upsert_response: str = SchemaField(description='Response from Pinecone upsert operation')",
        "def __init__(self):\n    super().__init__(id='477f2168-cd91-475a-8146-9499a5982434', description='Upload data to a Pinecone index', categories={BlockCategory.LOGIC}, input_schema=PineconeInsertBlock.Input, output_schema=PineconeInsertBlock.Output)",
        "super().__init__()",
        "def run(self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs) -> BlockOutput:\n    try:\n        pc = Pinecone(api_key=credentials.api_key.get_secret_value())\n        idx = pc.Index(input_data.index)\n        vectors = []\n        for (chunk, embedding) in zip(input_data.chunks, input_data.embeddings):\n            vector_metadata = input_data.metadata.copy()\n            vector_metadata['text'] = chunk\n            vectors.append({'id': str(uuid.uuid4()), 'values': embedding, 'metadata': vector_metadata})\n        idx.upsert(vectors=vectors, namespace=input_data.namespace)\n        yield ('upsert_response', 'successfully upserted')\n    except Exception as e:\n        error_msg = f'Error uploading to Pinecone: {str(e)}'\n        raise RuntimeError(error_msg) from e",
        "try:\n    pc = Pinecone(api_key=credentials.api_key.get_secret_value())\n    idx = pc.Index(input_data.index)\n    vectors = []\n    for (chunk, embedding) in zip(input_data.chunks, input_data.embeddings):\n        vector_metadata = input_data.metadata.copy()\n        vector_metadata['text'] = chunk\n        vectors.append({'id': str(uuid.uuid4()), 'values': embedding, 'metadata': vector_metadata})\n    idx.upsert(vectors=vectors, namespace=input_data.namespace)\n    yield ('upsert_response', 'successfully upserted')\nexcept Exception as e:\n    error_msg = f'Error uploading to Pinecone: {str(e)}'\n    raise RuntimeError(error_msg) from e",
        "pc = Pinecone(api_key=credentials.api_key.get_secret_value())",
        "idx = pc.Index(input_data.index)",
        "vectors = []"
      ]
    },
    {
      "id": "15",
      "type": "block",
      "statements": [
        "(chunk, embedding)",
        "zip(input_data.chunks, input_data.embeddings)"
      ]
    },
    {
      "id": "16",
      "type": "block",
      "statements": [
        "vector_metadata = input_data.metadata.copy()",
        "vector_metadata['text'] = chunk",
        "vectors.append({'id': str(uuid.uuid4()), 'values': embedding, 'metadata': vector_metadata})"
      ]
    },
    {
      "id": "17",
      "type": "block",
      "statements": [
        "idx.upsert()",
        "(yield ('upsert_response', 'successfully upserted'))",
        "error_msg = f'Error uploading to Pinecone: {str(e)}'",
        "raise RuntimeError(error_msg) from e"
      ]
    }
  ],
  "edges": [
    {
      "source": "2",
      "target": "3",
      "type": "true"
    },
    {
      "source": "2",
      "target": "4",
      "type": "false"
    },
    {
      "source": "3",
      "target": "5",
      "type": "next"
    },
    {
      "source": "4",
      "target": "5",
      "type": "next"
    },
    {
      "source": "5",
      "target": "6",
      "type": "true"
    },
    {
      "source": "5",
      "target": "7",
      "type": "false"
    },
    {
      "source": "6",
      "target": "9",
      "type": "true"
    },
    {
      "source": "6",
      "target": "10",
      "type": "false"
    },
    {
      "source": "7",
      "target": "8",
      "type": "next"
    },
    {
      "source": "8",
      "target": "12",
      "type": "true"
    },
    {
      "source": "8",
      "target": "13",
      "type": "false"
    },
    {
      "source": "9",
      "target": "11",
      "type": "next"
    },
    {
      "source": "10",
      "target": "11",
      "type": "next"
    },
    {
      "source": "11",
      "target": "8",
      "type": "next"
    },
    {
      "source": "12",
      "target": "14",
      "type": "next"
    },
    {
      "source": "13",
      "target": "14",
      "type": "next"
    },
    {
      "source": "14",
      "target": "15",
      "type": "next"
    },
    {
      "source": "15",
      "target": "16",
      "type": "true"
    },
    {
      "source": "15",
      "target": "17",
      "type": "false"
    },
    {
      "source": "16",
      "target": "15",
      "type": "next"
    }
  ]
}