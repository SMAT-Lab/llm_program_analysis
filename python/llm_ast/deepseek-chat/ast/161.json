{
    "type": "Program",
    "name": "Global",
    "range": [
        52,
        694
    ],
    "children": [
        {
            "type": "EnumDeclaration",
            "name": "SamplingMethod",
            "range": [
                52,
                92
            ],
            "children": [
                {
                    "type": "EnumMember",
                    "name": "RANDOM",
                    "range": [
                        61,
                        63
                    ],
                    "children": [
                        {
                            "type": "Literal",
                            "value": "\"random\"",
                            "range": [
                                63,
                                63
                            ],
                            "content": "="
                        }
                    ],
                    "content": "\nRANDOM="
                },
                {
                    "type": "EnumMember",
                    "name": "SYSTEMATIC",
                    "range": [
                        65,
                        67
                    ],
                    "children": [
                        {
                            "type": "Literal",
                            "value": "\"systematic\"",
                            "range": [
                                67,
                                67
                            ],
                            "content": "="
                        }
                    ],
                    "content": "\nSYSTEMATIC="
                },
                {
                    "type": "EnumMember",
                    "name": "TOP",
                    "range": [
                        69,
                        71
                    ],
                    "children": [
                        {
                            "type": "Literal",
                            "value": "\"top\"",
                            "range": [
                                71,
                                71
                            ],
                            "content": "="
                        }
                    ],
                    "content": "\nTOP="
                },
                {
                    "type": "EnumMember",
                    "name": "BOTTOM",
                    "range": [
                        73,
                        75
                    ],
                    "children": [
                        {
                            "type": "Literal",
                            "value": "\"bottom\"",
                            "range": [
                                75,
                                75
                            ],
                            "content": "="
                        }
                    ],
                    "content": "\nBOTTOM="
                },
                {
                    "type": "EnumMember",
                    "name": "STRATIFIED",
                    "range": [
                        77,
                        79
                    ],
                    "children": [
                        {
                            "type": "Literal",
                            "value": "\"stratified\"",
                            "range": [
                                79,
                                79
                            ],
                            "content": "="
                        }
                    ],
                    "content": "\nSTRATIFIED="
                },
                {
                    "type": "EnumMember",
                    "name": "WEIGHTED",
                    "range": [
                        81,
                        83
                    ],
                    "children": [
                        {
                            "type": "Literal",
                            "value": "\"weighted\"",
                            "range": [
                                83,
                                83
                            ],
                            "content": "="
                        }
                    ],
                    "content": "\nWEIGHTED="
                },
                {
                    "type": "EnumMember",
                    "name": "RESERVOIR",
                    "range": [
                        85,
                        87
                    ],
                    "children": [
                        {
                            "type": "Literal",
                            "value": "\"reservoir\"",
                            "range": [
                                87,
                                87
                            ],
                            "content": "="
                        }
                    ],
                    "content": "\nRESERVOIR="
                },
                {
                    "type": "EnumMember",
                    "name": "CLUSTER",
                    "range": [
                        89,
                        91
                    ],
                    "children": [
                        {
                            "type": "Literal",
                            "value": "\"cluster\"",
                            "range": [
                                91,
                                91
                            ],
                            "content": "="
                        }
                    ],
                    "content": "\nCLUSTER="
                }
            ],
            "content": "\nclass SamplingMethod(str,Enum):\nRANDOM=\"random\"\nSYSTEMATIC=\"systematic\"\nTOP=\"top\"\nBOTTOM=\"bottom\"\nSTRATIFIED=\"stratified\"\nWEIGHTED=\"weighted\"\nRESERVOIR=\"reservoir\"\nCLUSTER=\"cluster\""
        },
        {
            "type": "ClassDecl",
            "name": "DataSamplingBlock",
            "range": [
                93,
                298
            ],
            "children": [
                {
                    "type": "ClassDecl",
                    "name": "Input",
                    "range": [
                        100,
                        298
                    ],
                    "children": [
                        {
                            "type": "VariableDecl",
                            "name": "data",
                            "range": [
                                107,
                                145
                            ],
                            "children": [],
                            "content": "):\ndata:Union[Dict[str,Any],List[Union[dict,List[Any]]]]=SchemaField(\ndescription=\"The dataset to sample from. Can be a single dictionary, a list of dictionaries, or a list of lists.\",\nplaceholder=\"{'id': 1, 'value': 'a'} or [{'id': 1, 'value': 'a'}, {'id': 2, 'value': 'b'}, ...]\""
                        },
                        {
                            "type": "VariableDecl",
                            "name": "sample_size",
                            "range": [
                                147,
                                169
                            ],
                            "children": [],
                            "content": "\n)\nsample_size:int=SchemaField(\ndescription=\"The number of samples to take from the dataset.\",\nplaceholder=\"10\",\ndefault=10"
                        },
                        {
                            "type": "VariableDecl",
                            "name": "sampling_method",
                            "range": [
                                171,
                                190
                            ],
                            "children": [],
                            "content": "\n)\nsampling_method:SamplingMethod=SchemaField(\ndescription=\"The method to use for sampling.\",\ndefault=SamplingMethod.RANDOM"
                        },
                        {
                            "type": "VariableDecl",
                            "name": "accumulate",
                            "range": [
                                192,
                                209
                            ],
                            "children": [],
                            "content": "\n)\naccumulate:bool=SchemaField(\ndescription=\"Whether to accumulate data before sampling.\",\ndefault=False"
                        },
                        {
                            "type": "VariableDecl",
                            "name": "random_seed",
                            "range": [
                                211,
                                231
                            ],
                            "children": [],
                            "content": "\n)\nrandom_seed:Optional[int]=SchemaField(\ndescription=\"Seed for random number generator (optional).\",\ndefault=None"
                        },
                        {
                            "type": "VariableDecl",
                            "name": "stratify_key",
                            "range": [
                                233,
                                253
                            ],
                            "children": [],
                            "content": "\n)\nstratify_key:Optional[str]=SchemaField(\ndescription=\"Key to use for stratified sampling (required for stratified sampling).\",\ndefault=None"
                        },
                        {
                            "type": "VariableDecl",
                            "name": "weight_key",
                            "range": [
                                255,
                                275
                            ],
                            "children": [],
                            "content": "\n)\nweight_key:Optional[str]=SchemaField(\ndescription=\"Key to use for weighted sampling (required for weighted sampling).\",\ndefault=None"
                        },
                        {
                            "type": "VariableDecl",
                            "name": "cluster_key",
                            "range": [
                                277,
                                297
                            ],
                            "children": [],
                            "content": "\n)\ncluster_key:Optional[str]=SchemaField(\ndescription=\"Key to use for cluster sampling (required for cluster sampling).\",\ndefault=None"
                        }
                    ],
                    "content": "):\nclass Input(BlockSchema):\ndata:Union[Dict[str,Any],List[Union[dict,List[Any]]]]=SchemaField(\ndescription=\"The dataset to sample from. Can be a single dictionary, a list of dictionaries, or a list of lists.\",\nplaceholder=\"{'id': 1, 'value': 'a'} or [{'id': 1, 'value': 'a'}, {'id': 2, 'value': 'b'}, ...]\",\n)\nsample_size:int=SchemaField(\ndescription=\"The number of samples to take from the dataset.\",\nplaceholder=\"10\",\ndefault=10,\n)\nsampling_method:SamplingMethod=SchemaField(\ndescription=\"The method to use for sampling.\",\ndefault=SamplingMethod.RANDOM,\n)\naccumulate:bool=SchemaField(\ndescription=\"Whether to accumulate data before sampling.\",\ndefault=False,\n)\nrandom_seed:Optional[int]=SchemaField(\ndescription=\"Seed for random number generator (optional).\",\ndefault=None,\n)\nstratify_key:Optional[str]=SchemaField(\ndescription=\"Key to use for stratified sampling (required for stratified sampling).\",\ndefault=None,\n)\nweight_key:Optional[str]=SchemaField(\ndescription=\"Key to use for weighted sampling (required for weighted sampling).\",\ndefault=None,\n)\ncluster_key:Optional[str]=SchemaField(\ndescription=\"Key to use for cluster sampling (required for cluster sampling).\",\ndefault=None,"
                }
            ],
            "content": "\n\n\nclass DataSamplingBlock(Block):\nclass Input(BlockSchema):\ndata:Union[Dict[str,Any],List[Union[dict,List[Any]]]]=SchemaField(\ndescription=\"The dataset to sample from. Can be a single dictionary, a list of dictionaries, or a list of lists.\",\nplaceholder=\"{'id': 1, 'value': 'a'} or [{'id': 1, 'value': 'a'}, {'id': 2, 'value': 'b'}, ...]\",\n)\nsample_size:int=SchemaField(\ndescription=\"The number of samples to take from the dataset.\",\nplaceholder=\"10\",\ndefault=10,\n)\nsampling_method:SamplingMethod=SchemaField(\ndescription=\"The method to use for sampling.\",\ndefault=SamplingMethod.RANDOM,\n)\naccumulate:bool=SchemaField(\ndescription=\"Whether to accumulate data before sampling.\",\ndefault=False,\n)\nrandom_seed:Optional[int]=SchemaField(\ndescription=\"Seed for random number generator (optional).\",\ndefault=None,\n)\nstratify_key:Optional[str]=SchemaField(\ndescription=\"Key to use for stratified sampling (required for stratified sampling).\",\ndefault=None,\n)\nweight_key:Optional[str]=SchemaField(\ndescription=\"Key to use for weighted sampling (required for weighted sampling).\",\ndefault=None,\n)\ncluster_key:Optional[str]=SchemaField(\ndescription=\"Key to use for cluster sampling (required for cluster sampling).\",\ndefault=None,"
        },
        {
            "type": "ClassDecl",
            "name": "Output",
            "range": [
                300,
                346
            ],
            "children": [
                {
                    "type": "VariableDecl",
                    "name": "sampled_data",
                    "range": [
                        307,
                        329
                    ],
                    "children": [],
                    "content": "):\nsampled_data:List[Union[dict,List[Any]]]=SchemaField(\ndescription="
                },
                {
                    "type": "VariableDecl",
                    "name": "sample_indices",
                    "range": [
                        331,
                        345
                    ],
                    "children": [],
                    "content": "\n)\nsample_indices:List[int]=SchemaField(\ndescription="
                }
            ],
            "content": ")\n\nclass Output(BlockSchema):\nsampled_data:List[Union[dict,List[Any]]]=SchemaField(\ndescription=\"The sampled subset of the input data.\"\n)\nsample_indices:List[int]=SchemaField(\ndescription=\"The indices of the sampled data in the original dataset.\""
        },
        {
            "type": "FunctionDecl",
            "name": "__init__",
            "range": [
                348,
                543
            ],
            "children": [
                {
                    "type": "SuperCall",
                    "name": "",
                    "range": [
                        355,
                        393
                    ],
                    "children": [],
                    "content": "):\nsuper().__init__(\nid=\"4a448883-71fa-49cf-91cf-70d793bd7d87\",\ndescription=\"This block samples data from a given dataset using various sampling methods.\",\ncategories={BlockCategory.LOGIC},\ninput_schema=DataSamplingBlock.Input,\noutput_schema=DataSamplingBlock"
                },
                {
                    "type": "VariableDecl",
                    "name": "accumulated_data",
                    "range": [
                        544,
                        550
                    ],
                    "children": [],
                    "content": "\n)\nself.accumulated_data="
                }
            ],
            "content": ")\n\ndef __init__(self):\nsuper().__init__(\nid=\"4a448883-71fa-49cf-91cf-70d793bd7d87\",\ndescription=\"This block samples data from a given dataset using various sampling methods.\",\ncategories={BlockCategory.LOGIC},\ninput_schema=DataSamplingBlock.Input,\noutput_schema=DataSamplingBlock.Output,\ntest_input={\n\"data\":[\n{\"id\":i,\"value\":chr(97+i),\"group\":i%3}for i in range(10)\n],\n\"sample_size\":3,\n\"sampling_method\":SamplingMethod.STRATIFIED,\n\"accumulate\":False,\n\"random_seed\":42,\n\"stratify_key\":\"group\",\n},\ntest_output=[\n(\n\"sampled_data\",\n[\n{\"id\":0,\"value\":\"a\",\"group\":0},\n{\"id\":1,\"value\":\"b\",\"group\":1},\n{\"id\":8,\"value\":\"i\",\"group\":2},\n],\n),\n(\"sample_indices\",[0,1,8]),\n],"
        },
        {
            "type": "FunctionDecl",
            "name": "run",
            "range": [
                552,
                693
            ],
            "children": [
                {
                    "type": "IfStatement",
                    "name": "",
                    "range": [
                        570,
                        629
                    ],
                    "children": [],
                    "content": "BlockOutput:\nif input_data.accumulate:\nif isinstance(input_data.data,dict):\nself.accumulated_data.append(input_data.data)\nelif isinstance(input_data.data,list):\nself.accumulated_data.extend(input_data.data)\nelse:\nraise ValueError(f"
                },
                {
                    "type": "Comment",
                    "name": "",
                    "range": [
                        631,
                        635
                    ],
                    "children": [],
                    "content": ")\n\n#If"
                },
                {
                    "type": "IfStatement",
                    "name": "",
                    "range": [
                        636,
                        641
                    ],
                    "children": [],
                    "content": "we don 't have enough data yet, return without sampling \\n             if len(self.accumulated_data) < input_data.sample_size: \\n                 return \\n  \\n             data_to_sample = self.accumulated_data \\n         else: \\n             # If not accumulating, use the input data directly \\n             data_to_sample = ( \\n                 input_data.data \\n                 if isinstance(input_data.data, list) \\n                 else [input_data.data] \\n             ) \\n  \\n         if input_data.random_seed is not None: \\n             random.seed(input_data.random_seed) \\n  \\n         data_size = len(data_to_sample) \\n  \\n         if input_data.sample_size > data_size: \\n             raise ValueError( \\n                 f\"Sample size ({input_data.sample_size}) cannot be larger than the dataset size ({data_size}).\" \\n             ) \\n  \\n         indices = [] \\n  \\n         if input_data.sampling_method == SamplingMethod.RANDOM: \\n             indices = random.sample(range(data_size), input_data.sample_size) \\n         elif input_data.sampling_method == SamplingMethod.SYSTEMATIC: \\n             step = data_size // input_data.sample_size \\n             start = random.randint(0, step - 1) \\n             indices = list(range(start, data_size, step))[: input_data.sample_size] \\n         elif input_data.sampling_method == SamplingMethod.TOP: \\n             indices = list(range(input_data.sample_size)) \\n         elif input_data.sampling_method == SamplingMethod.BOTTOM: \\n             indices = list(range(data_size - input_data.sample_size, data_size)) \\n         elif input_data.sampling_method == SamplingMethod.STRATIFIED: \\n             if not input_data.stratify_key: \\n                 raise ValueError( \\n                     \"Stratify key must be provided for stratified sampling.\" \\n                 ) \\n             strata = defaultdict(list) \\n             for i, item in enumerate(data_to_sample): \\n                 if isinstance(item, dict): \\n                     strata_value = item.get(input_data.stratify_key) \\n                 elif hasattr(item, input_data.stratify_key): \\n                     strata_value = getattr(item, input_data.stratify_key) \\n                 else: \\n                     raise ValueError( \\n                         f\"Stratify key '{input_data."
                },
                {
                    "type": "IfStatement",
                    "name": "",
                    "range": [
                        642,
                        647
                    ],
                    "children": [],
                    "content": "stratify_key}' not found in item {item}\" \\n                     ) \\n  \\n                 if strata_value is None: \\n                     raise ValueError( \\n                         f\"Stratify value for key '{input_data."
                },
                {
                    "type": "IfStatement",
                    "name": "",
                    "range": [
                        648,
                        653
                    ],
                    "children": [],
                    "content": "stratify_key}' is None\" \\n                     ) \\n  \\n                 strata[str(strata_value)].append(i) \\n  \\n             # Calculate the number of samples to take from each stratum \\n             stratum_sizes = { \\n                 k: max(1, int(len(v) / data_size * input_data.sample_size)) \\n                 for k, v in strata.items() \\n             } \\n  \\n             # Adjust sizes to ensure we get exactly sample_size samples \\n             while sum(stratum_sizes.values()) != input_data.sample_size: \\n                 if sum(stratum_sizes.values()) < input_data.sample_size: \\n                     stratum_sizes[ \\n                         max(stratum_sizes, key=lambda k: stratum_sizes[k]) \\n                     ] += 1 \\n                 else: \\n                     stratum_sizes[ \\n                         max(stratum_sizes, key=lambda k: stratum_sizes[k]) \\n                     ] -= 1 \\n  \\n             for stratum, size in stratum_sizes.items(): \\n                 indices.extend(random.sample(strata[stratum], size)) \\n         elif input_data.sampling_method == SamplingMethod.WEIGHTED: \\n             if not input_data.weight_key: \\n                 raise ValueError(\"Weight key must be provided for weighted sampling.\") \\n             weights = [] \\n             for item in data_to_sample: \\n                 if isinstance(item, dict): \\n                     weight = item.get(input_data.weight_key) \\n                 elif hasattr(item, input_data.weight_key): \\n                     weight = getattr(item, input_data.weight_key) \\n                 else: \\n                     raise ValueError( \\n                         f\"Weight key '{input_data."
                },
                {
                    "type": "IfStatement",
                    "name": "",
                    "range": [
                        654,
                        659
                    ],
                    "children": [],
                    "content": "weight_key}' not found in item {item}\" \\n                     ) \\n  \\n                 if weight is None: \\n                     raise ValueError( \\n                         f\"Weight value for key '{input_data."
                },
                {
                    "type": "IfStatement",
                    "name": "",
                    "range": [
                        660,
                        663
                    ],
                    "children": [],
                    "content": "weight_key}' is None\" \\n                     ) \\n                 try: \\n                     weights.append(float(weight)) \\n                 except ValueError: \\n                     raise ValueError( \\n                         f\"Weight value '{"
                },
                {
                    "type": "IfStatement",
                    "name": "",
                    "range": [
                        664,
                        669
                    ],
                    "children": [],
                    "content": "weight}' cannot be converted to a number\" \\n                     ) \\n  \\n             if not weights: \\n                 raise ValueError( \\n                     f\"No valid weights found using key '{input_data."
                },
                {
                    "type": "IfStatement",
                    "name": "",
                    "range": [
                        670,
                        675
                    ],
                    "children": [],
                    "content": "weight_key}'\" \\n                 ) \\n  \\n             indices = random.choices( \\n                 range(data_size), weights=weights, k=input_data.sample_size \\n             ) \\n         elif input_data.sampling_method == SamplingMethod.RESERVOIR: \\n             indices = list(range(input_data.sample_size)) \\n             for i in range(input_data.sample_size, data_size): \\n                 j = random.randint(0, i) \\n                 if j < input_data.sample_size: \\n                     indices[j] = i \\n         elif input_data.sampling_method == SamplingMethod.CLUSTER: \\n             if not input_data.cluster_key: \\n                 raise ValueError(\"Cluster key must be provided for cluster sampling.\") \\n             clusters = defaultdict(list) \\n             for i, item in enumerate(data_to_sample): \\n                 if isinstance(item, dict): \\n                     cluster_value = item.get(input_data.cluster_key) \\n                 elif hasattr(item, input_data.cluster_key): \\n                     cluster_value = getattr(item, input_data.cluster_key) \\n                 else: \\n                     raise TypeError( \\n                         f\"Item {item} does not have the cluster key '{input_data."
                },
                {
                    "type": "IfStatement",
                    "name": "",
                    "range": [
                        676,
                        681
                    ],
                    "children": [],
                    "content": "cluster_key}'\" \\n                     ) \\n  \\n                 clusters[str(cluster_value)].append(i) \\n  \\n             # Randomly select clusters until we have enough samples \\n             selected_clusters = [] \\n             while ( \\n                 sum(len(clusters[c]) for c in selected_clusters) \\n                 < input_data.sample_size \\n             ): \\n                 available_clusters = [c for c in clusters if c not in selected_clusters] \\n                 if not available_clusters: \\n                     break \\n                 selected_clusters.append(random.choice(available_clusters)) \\n  \\n             for cluster in selected_clusters: \\n                 indices.extend(clusters[cluster]) \\n  \\n             # If we have more samples than needed, randomly remove some \\n             if len(indices) > input_data.sample_size: \\n                 indices = random.sample(indices, input_data.sample_size) \\n         else: \\n             raise ValueError(f\" Unknown sampling"
                },
                {
                    "type": "IfStatement",
                    "name": "",
                    "range": [
                        682,
                        685
                    ],
                    "children": [],
                    "content": "method:{input_data"
                },
                {
                    "type": "YieldStatement",
                    "name": "",
                    "range": [
                        686,
                        690
                    ],
                    "children": [],
                    "content": ".sampling_method}\") \\n  \\n         sampled_data = [data_to_sample[i] for i in indices] \\n  \\n         # Clear accumulated data after sampling if accumulation is enabled \\n         if input_data.accumulate: \\n             self.accumulated_data = [] \\n  \\n         yield \" sampled_data"
                },
                {
                    "type": "YieldStatement",
                    "name": "",
                    "range": [
                        691,
                        693
                    ],
                    "children": [],
                    "content": "\", sampled_data \\n         yield \" sample_indices\""
                }
            ],
            "content": "]\n\ndef run(self,input_data:Input,**kwargs)->BlockOutput:\nif input_data.accumulate:\nif isinstance(input_data.data,dict):\nself.accumulated_data.append(input_data.data)\nelif isinstance(input_data.data,list):\nself.accumulated_data.extend(input_data.data)\nelse:\nraise ValueError(f \"Unsupported data type: {type(input_data.data)}\")\n\n#If we don 't have enough data yet, return without sampling \\n             if len(self.accumulated_data) < input_data.sample_size: \\n                 return \\n  \\n             data_to_sample = self.accumulated_data \\n         else: \\n             # If not accumulating, use the input data directly \\n             data_to_sample = ( \\n                 input_data.data \\n                 if isinstance(input_data.data, list) \\n                 else [input_data.data] \\n             ) \\n  \\n         if input_data.random_seed is not None: \\n             random.seed(input_data.random_seed) \\n  \\n         data_size = len(data_to_sample) \\n  \\n         if input_data.sample_size > data_size: \\n             raise ValueError( \\n                 f\"Sample size ({input_data.sample_size}) cannot be larger than the dataset size ({data_size}).\" \\n             ) \\n  \\n         indices = [] \\n  \\n         if input_data.sampling_method == SamplingMethod.RANDOM: \\n             indices = random.sample(range(data_size), input_data.sample_size) \\n         elif input_data.sampling_method == SamplingMethod.SYSTEMATIC: \\n             step = data_size // input_data.sample_size \\n             start = random.randint(0, step - 1) \\n             indices = list(range(start, data_size, step))[: input_data.sample_size] \\n         elif input_data.sampling_method == SamplingMethod.TOP: \\n             indices = list(range(input_data.sample_size)) \\n         elif input_data.sampling_method == SamplingMethod.BOTTOM: \\n             indices = list(range(data_size - input_data.sample_size, data_size)) \\n         elif input_data.sampling_method == SamplingMethod.STRATIFIED: \\n             if not input_data.stratify_key: \\n                 raise ValueError( \\n                     \"Stratify key must be provided for stratified sampling.\" \\n                 ) \\n             strata = defaultdict(list) \\n             for i, item in enumerate(data_to_sample): \\n                 if isinstance(item, dict): \\n                     strata_value = item.get(input_data.stratify_key) \\n                 elif hasattr(item, input_data.stratify_key): \\n                     strata_value = getattr(item, input_data.stratify_key) \\n                 else: \\n                     raise ValueError( \\n                         f\"Stratify key '{input_data.stratify_key}' not found in item {item}\" \\n                     ) \\n  \\n                 if strata_value is None: \\n                     raise ValueError( \\n                         f\"Stratify value for key '{input_data.stratify_key}' is None\" \\n                     ) \\n  \\n                 strata[str(strata_value)].append(i) \\n  \\n             # Calculate the number of samples to take from each stratum \\n             stratum_sizes = { \\n                 k: max(1, int(len(v) / data_size * input_data.sample_size)) \\n                 for k, v in strata.items() \\n             } \\n  \\n             # Adjust sizes to ensure we get exactly sample_size samples \\n             while sum(stratum_sizes.values()) != input_data.sample_size: \\n                 if sum(stratum_sizes.values()) < input_data.sample_size: \\n                     stratum_sizes[ \\n                         max(stratum_sizes, key=lambda k: stratum_sizes[k]) \\n                     ] += 1 \\n                 else: \\n                     stratum_sizes[ \\n                         max(stratum_sizes, key=lambda k: stratum_sizes[k]) \\n                     ] -= 1 \\n  \\n             for stratum, size in stratum_sizes.items(): \\n                 indices.extend(random.sample(strata[stratum], size)) \\n         elif input_data.sampling_method == SamplingMethod.WEIGHTED: \\n             if not input_data.weight_key: \\n                 raise ValueError(\"Weight key must be provided for weighted sampling.\") \\n             weights = [] \\n             for item in data_to_sample: \\n                 if isinstance(item, dict): \\n                     weight = item.get(input_data.weight_key) \\n                 elif hasattr(item, input_data.weight_key): \\n                     weight = getattr(item, input_data.weight_key) \\n                 else: \\n                     raise ValueError( \\n                         f\"Weight key '{input_data.weight_key}' not found in item {item}\" \\n                     ) \\n  \\n                 if weight is None: \\n                     raise ValueError( \\n                         f\"Weight value for key '{input_data.weight_key}' is None\" \\n                     ) \\n                 try: \\n                     weights.append(float(weight)) \\n                 except ValueError: \\n                     raise ValueError( \\n                         f\"Weight value '{weight}' cannot be converted to a number\" \\n                     ) \\n  \\n             if not weights: \\n                 raise ValueError( \\n                     f\"No valid weights found using key '{input_data.weight_key}'\" \\n                 ) \\n  \\n             indices = random.choices( \\n                 range(data_size), weights=weights, k=input_data.sample_size \\n             ) \\n         elif input_data.sampling_method == SamplingMethod.RESERVOIR: \\n             indices = list(range(input_data.sample_size)) \\n             for i in range(input_data.sample_size, data_size): \\n                 j = random.randint(0, i) \\n                 if j < input_data.sample_size: \\n                     indices[j] = i \\n         elif input_data.sampling_method == SamplingMethod.CLUSTER: \\n             if not input_data.cluster_key: \\n                 raise ValueError(\"Cluster key must be provided for cluster sampling.\") \\n             clusters = defaultdict(list) \\n             for i, item in enumerate(data_to_sample): \\n                 if isinstance(item, dict): \\n                     cluster_value = item.get(input_data.cluster_key) \\n                 elif hasattr(item, input_data.cluster_key): \\n                     cluster_value = getattr(item, input_data.cluster_key) \\n                 else: \\n                     raise TypeError( \\n                         f\"Item {item} does not have the cluster key '{input_data.cluster_key}'\" \\n                     ) \\n  \\n                 clusters[str(cluster_value)].append(i) \\n  \\n             # Randomly select clusters until we have enough samples \\n             selected_clusters = [] \\n             while ( \\n                 sum(len(clusters[c]) for c in selected_clusters) \\n                 < input_data.sample_size \\n             ): \\n                 available_clusters = [c for c in clusters if c not in selected_clusters] \\n                 if not available_clusters: \\n                     break \\n                 selected_clusters.append(random.choice(available_clusters)) \\n  \\n             for cluster in selected_clusters: \\n                 indices.extend(clusters[cluster]) \\n  \\n             # If we have more samples than needed, randomly remove some \\n             if len(indices) > input_data.sample_size: \\n                 indices = random.sample(indices, input_data.sample_size) \\n         else: \\n             raise ValueError(f\" Unknown sampling method:{input_data.sampling_method}\") \\n  \\n         sampled_data = [data_to_sample[i] for i in indices] \\n  \\n         # Clear accumulated data after sampling if accumulation is enabled \\n         if input_data.accumulate: \\n             self.accumulated_data = [] \\n  \\n         yield \" sampled_data \", sampled_data \\n         yield \" sample_indices\""
        }
    ],
    "content": "\nclass SamplingMethod(str,Enum):\nRANDOM=\"random\"\nSYSTEMATIC=\"systematic\"\nTOP=\"top\"\nBOTTOM=\"bottom\"\nSTRATIFIED=\"stratified\"\nWEIGHTED=\"weighted\"\nRESERVOIR=\"reservoir\"\nCLUSTER=\"cluster\"\n\n\nclass DataSamplingBlock(Block):\nclass Input(BlockSchema):\ndata:Union[Dict[str,Any],List[Union[dict,List[Any]]]]=SchemaField(\ndescription=\"The dataset to sample from. Can be a single dictionary, a list of dictionaries, or a list of lists.\",\nplaceholder=\"{'id': 1, 'value': 'a'} or [{'id': 1, 'value': 'a'}, {'id': 2, 'value': 'b'}, ...]\",\n)\nsample_size:int=SchemaField(\ndescription=\"The number of samples to take from the dataset.\",\nplaceholder=\"10\",\ndefault=10,\n)\nsampling_method:SamplingMethod=SchemaField(\ndescription=\"The method to use for sampling.\",\ndefault=SamplingMethod.RANDOM,\n)\naccumulate:bool=SchemaField(\ndescription=\"Whether to accumulate data before sampling.\",\ndefault=False,\n)\nrandom_seed:Optional[int]=SchemaField(\ndescription=\"Seed for random number generator (optional).\",\ndefault=None,\n)\nstratify_key:Optional[str]=SchemaField(\ndescription=\"Key to use for stratified sampling (required for stratified sampling).\",\ndefault=None,\n)\nweight_key:Optional[str]=SchemaField(\ndescription=\"Key to use for weighted sampling (required for weighted sampling).\",\ndefault=None,\n)\ncluster_key:Optional[str]=SchemaField(\ndescription=\"Key to use for cluster sampling (required for cluster sampling).\",\ndefault=None,\n)\n\nclass Output(BlockSchema):\nsampled_data:List[Union[dict,List[Any]]]=SchemaField(\ndescription=\"The sampled subset of the input data.\"\n)\nsample_indices:List[int]=SchemaField(\ndescription=\"The indices of the sampled data in the original dataset.\"\n)\n\ndef __init__(self):\nsuper().__init__(\nid=\"4a448883-71fa-49cf-91cf-70d793bd7d87\",\ndescription=\"This block samples data from a given dataset using various sampling methods.\",\ncategories={BlockCategory.LOGIC},\ninput_schema=DataSamplingBlock.Input,\noutput_schema=DataSamplingBlock.Output,\ntest_input={\n\"data\":[\n{\"id\":i,\"value\":chr(97+i),\"group\":i%3}for i in range(10)\n],\n\"sample_size\":3,\n\"sampling_method\":SamplingMethod.STRATIFIED,\n\"accumulate\":False,\n\"random_seed\":42,\n\"stratify_key\":\"group\",\n},\ntest_output=[\n(\n\"sampled_data\",\n[\n{\"id\":0,\"value\":\"a\",\"group\":0},\n{\"id\":1,\"value\":\"b\",\"group\":1},\n{\"id\":8,\"value\":\"i\",\"group\":2},\n],\n),\n(\"sample_indices\",[0,1,8]),\n],\n)\nself.accumulated_data=[]\n\ndef run(self,input_data:Input,**kwargs)->BlockOutput:\nif input_data.accumulate:\nif isinstance(input_data.data,dict):\nself.accumulated_data.append(input_data.data)\nelif isinstance(input_data.data,list):\nself.accumulated_data.extend(input_data.data)\nelse:\nraise ValueError(f \"Unsupported data type: {type(input_data.data)}\")\n\n#If we don 't have enough data yet, return without sampling \\n             if len(self.accumulated_data) < input_data.sample_size: \\n                 return \\n  \\n             data_to_sample = self.accumulated_data \\n         else: \\n             # If not accumulating, use the input data directly \\n             data_to_sample = ( \\n                 input_data.data \\n                 if isinstance(input_data.data, list) \\n                 else [input_data.data] \\n             ) \\n  \\n         if input_data.random_seed is not None: \\n             random.seed(input_data.random_seed) \\n  \\n         data_size = len(data_to_sample) \\n  \\n         if input_data.sample_size > data_size: \\n             raise ValueError( \\n                 f\"Sample size ({input_data.sample_size}) cannot be larger than the dataset size ({data_size}).\" \\n             ) \\n  \\n         indices = [] \\n  \\n         if input_data.sampling_method == SamplingMethod.RANDOM: \\n             indices = random.sample(range(data_size), input_data.sample_size) \\n         elif input_data.sampling_method == SamplingMethod.SYSTEMATIC: \\n             step = data_size // input_data.sample_size \\n             start = random.randint(0, step - 1) \\n             indices = list(range(start, data_size, step))[: input_data.sample_size] \\n         elif input_data.sampling_method == SamplingMethod.TOP: \\n             indices = list(range(input_data.sample_size)) \\n         elif input_data.sampling_method == SamplingMethod.BOTTOM: \\n             indices = list(range(data_size - input_data.sample_size, data_size)) \\n         elif input_data.sampling_method == SamplingMethod.STRATIFIED: \\n             if not input_data.stratify_key: \\n                 raise ValueError( \\n                     \"Stratify key must be provided for stratified sampling.\" \\n                 ) \\n             strata = defaultdict(list) \\n             for i, item in enumerate(data_to_sample): \\n                 if isinstance(item, dict): \\n                     strata_value = item.get(input_data.stratify_key) \\n                 elif hasattr(item, input_data.stratify_key): \\n                     strata_value = getattr(item, input_data.stratify_key) \\n                 else: \\n                     raise ValueError( \\n                         f\"Stratify key '{input_data.stratify_key}' not found in item {item}\" \\n                     ) \\n  \\n                 if strata_value is None: \\n                     raise ValueError( \\n                         f\"Stratify value for key '{input_data.stratify_key}' is None\" \\n                     ) \\n  \\n                 strata[str(strata_value)].append(i) \\n  \\n             # Calculate the number of samples to take from each stratum \\n             stratum_sizes = { \\n                 k: max(1, int(len(v) / data_size * input_data.sample_size)) \\n                 for k, v in strata.items() \\n             } \\n  \\n             # Adjust sizes to ensure we get exactly sample_size samples \\n             while sum(stratum_sizes.values()) != input_data.sample_size: \\n                 if sum(stratum_sizes.values()) < input_data.sample_size: \\n                     stratum_sizes[ \\n                         max(stratum_sizes, key=lambda k: stratum_sizes[k]) \\n                     ] += 1 \\n                 else: \\n                     stratum_sizes[ \\n                         max(stratum_sizes, key=lambda k: stratum_sizes[k]) \\n                     ] -= 1 \\n  \\n             for stratum, size in stratum_sizes.items(): \\n                 indices.extend(random.sample(strata[stratum], size)) \\n         elif input_data.sampling_method == SamplingMethod.WEIGHTED: \\n             if not input_data.weight_key: \\n                 raise ValueError(\"Weight key must be provided for weighted sampling.\") \\n             weights = [] \\n             for item in data_to_sample: \\n                 if isinstance(item, dict): \\n                     weight = item.get(input_data.weight_key) \\n                 elif hasattr(item, input_data.weight_key): \\n                     weight = getattr(item, input_data.weight_key) \\n                 else: \\n                     raise ValueError( \\n                         f\"Weight key '{input_data.weight_key}' not found in item {item}\" \\n                     ) \\n  \\n                 if weight is None: \\n                     raise ValueError( \\n                         f\"Weight value for key '{input_data.weight_key}' is None\" \\n                     ) \\n                 try: \\n                     weights.append(float(weight)) \\n                 except ValueError: \\n                     raise ValueError( \\n                         f\"Weight value '{weight}' cannot be converted to a number\" \\n                     ) \\n  \\n             if not weights: \\n                 raise ValueError( \\n                     f\"No valid weights found using key '{input_data.weight_key}'\" \\n                 ) \\n  \\n             indices = random.choices( \\n                 range(data_size), weights=weights, k=input_data.sample_size \\n             ) \\n         elif input_data.sampling_method == SamplingMethod.RESERVOIR: \\n             indices = list(range(input_data.sample_size)) \\n             for i in range(input_data.sample_size, data_size): \\n                 j = random.randint(0, i) \\n                 if j < input_data.sample_size: \\n                     indices[j] = i \\n         elif input_data.sampling_method == SamplingMethod.CLUSTER: \\n             if not input_data.cluster_key: \\n                 raise ValueError(\"Cluster key must be provided for cluster sampling.\") \\n             clusters = defaultdict(list) \\n             for i, item in enumerate(data_to_sample): \\n                 if isinstance(item, dict): \\n                     cluster_value = item.get(input_data.cluster_key) \\n                 elif hasattr(item, input_data.cluster_key): \\n                     cluster_value = getattr(item, input_data.cluster_key) \\n                 else: \\n                     raise TypeError( \\n                         f\"Item {item} does not have the cluster key '{input_data.cluster_key}'\" \\n                     ) \\n  \\n                 clusters[str(cluster_value)].append(i) \\n  \\n             # Randomly select clusters until we have enough samples \\n             selected_clusters = [] \\n             while ( \\n                 sum(len(clusters[c]) for c in selected_clusters) \\n                 < input_data.sample_size \\n             ): \\n                 available_clusters = [c for c in clusters if c not in selected_clusters] \\n                 if not available_clusters: \\n                     break \\n                 selected_clusters.append(random.choice(available_clusters)) \\n  \\n             for cluster in selected_clusters: \\n                 indices.extend(clusters[cluster]) \\n  \\n             # If we have more samples than needed, randomly remove some \\n             if len(indices) > input_data.sample_size: \\n                 indices = random.sample(indices, input_data.sample_size) \\n         else: \\n             raise ValueError(f\" Unknown sampling method:{input_data.sampling_method}\") \\n  \\n         sampled_data = [data_to_sample[i] for i in indices] \\n  \\n         # Clear accumulated data after sampling if accumulation is enabled \\n         if input_data.accumulate: \\n             self.accumulated_data = [] \\n  \\n         yield \" sampled_data \", sampled_data \\n         yield \" sample_indices\","
}