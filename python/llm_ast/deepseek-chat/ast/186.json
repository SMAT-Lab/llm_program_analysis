{
    "type": "Program",
    "name": "Global",
    "range": [
        144,
        5602
    ],
    "children": [
        {
            "type": "VariableDeclaration",
            "name": "LLMProviderName",
            "range": [
                144,
                174
            ],
            "children": [
                {
                    "type": "Literal",
                    "value": "Literal",
                    "range": [
                        146,
                        146
                    ],
                    "content": "="
                },
                {
                    "type": "ArrayExpression",
                    "range": [
                        147,
                        174
                    ],
                    "children": [
                        {
                            "type": "MemberExpression",
                            "object": {
                                "type": "Identifier",
                                "name": "ProviderName",
                                "range": [
                                    149,
                                    149
                                ],
                                "content": "\n"
                            },
                            "property": {
                                "type": "Identifier",
                                "name": "ANTHROPIC",
                                "range": [
                                    151,
                                    151
                                ],
                                "content": "."
                            },
                            "range": [
                                149,
                                151
                            ],
                            "content": "\nProviderName."
                        },
                        {
                            "type": "MemberExpression",
                            "object": {
                                "type": "Identifier",
                                "name": "ProviderName",
                                "range": [
                                    154,
                                    154
                                ],
                                "content": "\n"
                            },
                            "property": {
                                "type": "Identifier",
                                "name": "GROQ",
                                "range": [
                                    156,
                                    156
                                ],
                                "content": "."
                            },
                            "range": [
                                154,
                                156
                            ],
                            "content": "\nProviderName."
                        },
                        {
                            "type": "MemberExpression",
                            "object": {
                                "type": "Identifier",
                                "name": "ProviderName",
                                "range": [
                                    159,
                                    159
                                ],
                                "content": "\n"
                            },
                            "property": {
                                "type": "Identifier",
                                "name": "OLLAMA",
                                "range": [
                                    161,
                                    161
                                ],
                                "content": "."
                            },
                            "range": [
                                159,
                                161
                            ],
                            "content": "\nProviderName."
                        },
                        {
                            "type": "MemberExpression",
                            "object": {
                                "type": "Identifier",
                                "name": "ProviderName",
                                "range": [
                                    164,
                                    164
                                ],
                                "content": "\n"
                            },
                            "property": {
                                "type": "Identifier",
                                "name": "OPENAI",
                                "range": [
                                    166,
                                    166
                                ],
                                "content": "."
                            },
                            "range": [
                                164,
                                166
                            ],
                            "content": "\nProviderName."
                        },
                        {
                            "type": "MemberExpression",
                            "object": {
                                "type": "Identifier",
                                "name": "ProviderName",
                                "range": [
                                    169,
                                    169
                                ],
                                "content": "\n"
                            },
                            "property": {
                                "type": "Identifier",
                                "name": "OPEN_ROUTER",
                                "range": [
                                    171,
                                    171
                                ],
                                "content": "."
                            },
                            "range": [
                                169,
                                171
                            ],
                            "content": "\nProviderName."
                        }
                    ],
                    "content": "Literal[\nProviderName.ANTHROPIC,\nProviderName.GROQ,\nProviderName.OLLAMA,\nProviderName.OPENAI,\nProviderName.OPEN_ROUTER,\n"
                }
            ],
            "content": "\nLLMProviderName=Literal[\nProviderName.ANTHROPIC,\nProviderName.GROQ,\nProviderName.OLLAMA,\nProviderName.OPENAI,\nProviderName.OPEN_ROUTER,\n"
        },
        {
            "type": "VariableDeclaration",
            "name": "AICredentials",
            "range": [
                176,
                186
            ],
            "children": [
                {
                    "type": "AssignmentExpression",
                    "name": "",
                    "range": [
                        177,
                        186
                    ],
                    "children": [
                        {
                            "type": "Identifier",
                            "name": "CredentialsMetaInput",
                            "range": [
                                178,
                                178
                            ],
                            "children": [],
                            "content": "="
                        },
                        {
                            "type": "ArrayExpression",
                            "name": "",
                            "range": [
                                179,
                                186
                            ],
                            "children": [
                                {
                                    "type": "Identifier",
                                    "name": "LLMProviderName",
                                    "range": [
                                        180,
                                        180
                                    ],
                                    "children": [],
                                    "content": "["
                                },
                                {
                                    "type": "Literal",
                                    "name": "",
                                    "range": [
                                        182,
                                        182
                                    ],
                                    "children": [],
                                    "content": ","
                                },
                                {
                                    "type": "ArrayExpression",
                                    "name": "",
                                    "range": [
                                        183,
                                        185
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "",
                                            "range": [
                                                184,
                                                184
                                            ],
                                            "children": [],
                                            "content": "["
                                        }
                                    ],
                                    "content": "Literal[\"api_key\""
                                }
                            ],
                            "content": "CredentialsMetaInput[LLMProviderName,Literal[\"api_key\"]"
                        }
                    ],
                    "content": "AICredentials=CredentialsMetaInput[LLMProviderName,Literal[\"api_key\"]"
                }
            ],
            "content": "\nAICredentials=CredentialsMetaInput[LLMProviderName,Literal[\"api_key\"]"
        },
        {
            "type": "AssignmentExpression",
            "name": "=",
            "range": [
                188,
                222
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "TEST_CREDENTIALS",
                    "range": [
                        188,
                        188
                    ],
                    "children": [],
                    "content": "\n"
                },
                {
                    "type": "CallExpression",
                    "name": "APIKeyCredentials",
                    "range": [
                        190,
                        221
                    ],
                    "children": [
                        {
                            "type": "Argument",
                            "name": "id",
                            "range": [
                                193,
                                195
                            ],
                            "children": [
                                {
                                    "type": "Literal",
                                    "name": "\"ed55ac19-356e-4243-a6cb-bc599e9b716f\"",
                                    "range": [
                                        195,
                                        195
                                    ],
                                    "children": [],
                                    "content": "id"
                                }
                            ],
                            "content": "(\nid"
                        },
                        {
                            "type": "Argument",
                            "name": "provider",
                            "range": [
                                198,
                                200
                            ],
                            "children": [
                                {
                                    "type": "Literal",
                                    "name": "\"openai\"",
                                    "range": [
                                        200,
                                        200
                                    ],
                                    "children": [],
                                    "content": "provider"
                                }
                            ],
                            "content": ",\nprovider"
                        },
                        {
                            "type": "Argument",
                            "name": "api_key",
                            "range": [
                                203,
                                208
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "SecretStr",
                                    "range": [
                                        205,
                                        208
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"mock-openai-api-key\"",
                                            "range": [
                                                207,
                                                207
                                            ],
                                            "children": [],
                                            "content": "SecretStr"
                                        }
                                    ],
                                    "content": "api_key=SecretStr("
                                }
                            ],
                            "content": ",\napi_key=SecretStr("
                        },
                        {
                            "type": "Argument",
                            "name": "title",
                            "range": [
                                211,
                                213
                            ],
                            "children": [
                                {
                                    "type": "Literal",
                                    "name": "\"Mock OpenAI API key\"",
                                    "range": [
                                        213,
                                        213
                                    ],
                                    "children": [],
                                    "content": "title"
                                }
                            ],
                            "content": ",\ntitle"
                        },
                        {
                            "type": "Argument",
                            "name": "expires_at",
                            "range": [
                                216,
                                218
                            ],
                            "children": [
                                {
                                    "type": "Identifier",
                                    "name": "None",
                                    "range": [
                                        218,
                                        218
                                    ],
                                    "children": [],
                                    "content": "expires_at"
                                }
                            ],
                            "content": ",\nexpires_at"
                        }
                    ],
                    "content": "TEST_CREDENTIALS=APIKeyCredentials(\nid=\"ed55ac19-356e-4243-a6cb-bc599e9b716f\",\nprovider=\"openai\",\napi_key=SecretStr(\"mock-openai-api-key\"),\ntitle=\"Mock OpenAI API key\",\nexpires_at=None,"
                }
            ],
            "content": "\n\nTEST_CREDENTIALS=APIKeyCredentials(\nid=\"ed55ac19-356e-4243-a6cb-bc599e9b716f\",\nprovider=\"openai\",\napi_key=SecretStr(\"mock-openai-api-key\"),\ntitle=\"Mock OpenAI API key\",\nexpires_at=None,\n"
        },
        {
            "type": "VariableDeclaration",
            "name": "TEST_CREDENTIALS_INPUT",
            "range": [
                223,
                255
            ],
            "children": [
                {
                    "type": "ObjectExpression",
                    "name": "",
                    "range": [
                        225,
                        255
                    ],
                    "children": [
                        {
                            "type": "Property",
                            "name": "provider",
                            "range": [
                                227,
                                231
                            ],
                            "children": [
                                {
                                    "type": "Literal",
                                    "name": "\"provider\"",
                                    "range": [
                                        227,
                                        227
                                    ],
                                    "children": [],
                                    "content": "{"
                                },
                                {
                                    "type": "MemberExpression",
                                    "name": "TEST_CREDENTIALS.provider",
                                    "range": [
                                        229,
                                        231
                                    ],
                                    "children": [
                                        {
                                            "type": "Identifier",
                                            "name": "TEST_CREDENTIALS",
                                            "range": [
                                                229,
                                                229
                                            ],
                                            "children": [],
                                            "content": "\"provider\""
                                        },
                                        {
                                            "type": "Identifier",
                                            "name": "provider",
                                            "range": [
                                                231,
                                                231
                                            ],
                                            "children": [],
                                            "content": "TEST_CREDENTIALS"
                                        }
                                    ],
                                    "content": "\"provider\":TEST_CREDENTIALS"
                                }
                            ],
                            "content": "{\n\"provider\":TEST_CREDENTIALS"
                        },
                        {
                            "type": "Property",
                            "name": "id",
                            "range": [
                                234,
                                238
                            ],
                            "children": [
                                {
                                    "type": "Literal",
                                    "name": "\"id\"",
                                    "range": [
                                        234,
                                        234
                                    ],
                                    "children": [],
                                    "content": ","
                                },
                                {
                                    "type": "MemberExpression",
                                    "name": "TEST_CREDENTIALS.id",
                                    "range": [
                                        236,
                                        238
                                    ],
                                    "children": [
                                        {
                                            "type": "Identifier",
                                            "name": "TEST_CREDENTIALS",
                                            "range": [
                                                236,
                                                236
                                            ],
                                            "children": [],
                                            "content": "\"id\""
                                        },
                                        {
                                            "type": "Identifier",
                                            "name": "id",
                                            "range": [
                                                238,
                                                238
                                            ],
                                            "children": [],
                                            "content": "TEST_CREDENTIALS"
                                        }
                                    ],
                                    "content": "\"id\":TEST_CREDENTIALS"
                                }
                            ],
                            "content": ",\n\"id\":TEST_CREDENTIALS"
                        },
                        {
                            "type": "Property",
                            "name": "type",
                            "range": [
                                241,
                                245
                            ],
                            "children": [
                                {
                                    "type": "Literal",
                                    "name": "\"type\"",
                                    "range": [
                                        241,
                                        241
                                    ],
                                    "children": [],
                                    "content": ","
                                },
                                {
                                    "type": "MemberExpression",
                                    "name": "TEST_CREDENTIALS.type",
                                    "range": [
                                        243,
                                        245
                                    ],
                                    "children": [
                                        {
                                            "type": "Identifier",
                                            "name": "TEST_CREDENTIALS",
                                            "range": [
                                                243,
                                                243
                                            ],
                                            "children": [],
                                            "content": "\"type\""
                                        },
                                        {
                                            "type": "Identifier",
                                            "name": "type",
                                            "range": [
                                                245,
                                                245
                                            ],
                                            "children": [],
                                            "content": "TEST_CREDENTIALS"
                                        }
                                    ],
                                    "content": "\"type\":TEST_CREDENTIALS"
                                }
                            ],
                            "content": ",\n\"type\":TEST_CREDENTIALS"
                        },
                        {
                            "type": "Property",
                            "name": "title",
                            "range": [
                                248,
                                252
                            ],
                            "children": [
                                {
                                    "type": "Literal",
                                    "name": "\"title\"",
                                    "range": [
                                        248,
                                        248
                                    ],
                                    "children": [],
                                    "content": ","
                                },
                                {
                                    "type": "MemberExpression",
                                    "name": "TEST_CREDENTIALS.title",
                                    "range": [
                                        250,
                                        252
                                    ],
                                    "children": [
                                        {
                                            "type": "Identifier",
                                            "name": "TEST_CREDENTIALS",
                                            "range": [
                                                250,
                                                250
                                            ],
                                            "children": [],
                                            "content": "\"title\""
                                        },
                                        {
                                            "type": "Identifier",
                                            "name": "title",
                                            "range": [
                                                252,
                                                252
                                            ],
                                            "children": [],
                                            "content": "TEST_CREDENTIALS"
                                        }
                                    ],
                                    "content": "\"title\":TEST_CREDENTIALS"
                                }
                            ],
                            "content": ",\n\"title\":TEST_CREDENTIALS"
                        }
                    ],
                    "content": "TEST_CREDENTIALS_INPUT={\n\"provider\":TEST_CREDENTIALS.provider,\n\"id\":TEST_CREDENTIALS.id,\n\"type\":TEST_CREDENTIALS.type,\n\"title\":TEST_CREDENTIALS.title,"
                }
            ],
            "content": ")\nTEST_CREDENTIALS_INPUT={\n\"provider\":TEST_CREDENTIALS.provider,\n\"id\":TEST_CREDENTIALS.id,\n\"type\":TEST_CREDENTIALS.type,\n\"title\":TEST_CREDENTIALS.title,"
        },
        {
            "type": "FunctionDecl",
            "name": "AICredentialsField",
            "range": [
                257,
                302
            ],
            "children": [
                {
                    "type": "ReturnStatement",
                    "range": [
                        266,
                        301
                    ],
                    "children": [
                        {
                            "type": "CallExpression",
                            "range": [
                                267,
                                301
                            ],
                            "children": [
                                {
                                    "type": "Identifier",
                                    "name": "CredentialsField",
                                    "range": [
                                        267,
                                        267
                                    ],
                                    "content": "AICredentials"
                                },
                                {
                                    "type": "ObjectExpression",
                                    "range": [
                                        268,
                                        301
                                    ],
                                    "children": [
                                        {
                                            "type": "Property",
                                            "key": {
                                                "type": "Identifier",
                                                "name": "description",
                                                "range": [
                                                    270,
                                                    270
                                                ],
                                                "content": "return"
                                            },
                                            "value": {
                                                "type": "Literal",
                                                "value": "API key for the LLM provider.",
                                                "range": [
                                                    272,
                                                    272
                                                ],
                                                "content": "("
                                            },
                                            "range": [
                                                270,
                                                272
                                            ],
                                            "content": "return CredentialsField("
                                        },
                                        {
                                            "type": "Property",
                                            "key": {
                                                "type": "Identifier",
                                                "name": "discriminator",
                                                "range": [
                                                    275,
                                                    275
                                                ],
                                                "content": "="
                                            },
                                            "value": {
                                                "type": "Literal",
                                                "value": "model",
                                                "range": [
                                                    277,
                                                    277
                                                ],
                                                "content": ","
                                            },
                                            "range": [
                                                275,
                                                277
                                            ],
                                            "content": "=\"API key for the LLM provider.\","
                                        },
                                        {
                                            "type": "Property",
                                            "key": {
                                                "type": "Identifier",
                                                "name": "discriminator_mapping",
                                                "range": [
                                                    280,
                                                    280
                                                ],
                                                "content": "="
                                            },
                                            "value": {
                                                "type": "ObjectExpression",
                                                "range": [
                                                    282,
                                                    298
                                                ],
                                                "children": [
                                                    {
                                                        "type": "Property",
                                                        "key": {
                                                            "type": "Identifier",
                                                            "name": "model",
                                                            "range": [
                                                                284,
                                                                284
                                                            ],
                                                            "content": "discriminator_mapping"
                                                        },
                                                        "value": {
                                                            "type": "MemberExpression",
                                                            "object": {
                                                                "type": "Identifier",
                                                                "name": "model",
                                                                "range": [
                                                                    288,
                                                                    288
                                                                ],
                                                                "content": "model"
                                                            },
                                                            "property": {
                                                                "type": "Identifier",
                                                                "name": "metadata",
                                                                "range": [
                                                                    290,
                                                                    290
                                                                ],
                                                                "content": "value"
                                                            },
                                                            "computed": false,
                                                            "range": [
                                                                288,
                                                                290
                                                            ],
                                                            "content": "model.value"
                                                        },
                                                        "range": [
                                                            284,
                                                            290
                                                        ],
                                                        "content": "discriminator_mapping={\nmodel.value"
                                                    }
                                                ],
                                                "content": ",\ndiscriminator_mapping={\nmodel.value:model.metadata.provider for model"
                                            },
                                            "range": [
                                                280,
                                                298
                                            ],
                                            "content": "=\"model\",\ndiscriminator_mapping={\nmodel.value:model.metadata.provider for model"
                                        }
                                    ],
                                    "content": ":\nreturn CredentialsField(\ndescription=\"API key for the LLM provider.\",\ndiscriminator=\"model\",\ndiscriminator_mapping={\nmodel.value:model.metadata.provider for model in LlmModel\n"
                                }
                            ],
                            "content": "AICredentials:\nreturn CredentialsField(\ndescription=\"API key for the LLM provider.\",\ndiscriminator=\"model\",\ndiscriminator_mapping={\nmodel.value:model.metadata.provider for model in LlmModel\n"
                        }
                    ],
                    "content": ">AICredentials:\nreturn CredentialsField(\ndescription=\"API key for the LLM provider.\",\ndiscriminator=\"model\",\ndiscriminator_mapping={\nmodel.value:model.metadata.provider for model in LlmModel\n"
                }
            ],
            "content": "}\n\n\ndef AICredentialsField()->AICredentials:\nreturn CredentialsField(\ndescription=\"API key for the LLM provider.\",\ndiscriminator=\"model\",\ndiscriminator_mapping={\nmodel.value:model.metadata.provider for model in LlmModel\n}"
        },
        {
            "type": "ClassDecl",
            "name": "ModelMetadata",
            "range": [
                303,
                318
            ],
            "children": [
                {
                    "type": "Inheritance",
                    "name": "NamedTuple",
                    "range": [
                        305,
                        307
                    ],
                    "children": [],
                    "content": ")\n\n"
                },
                {
                    "type": "ClassBody",
                    "name": "",
                    "range": [
                        308,
                        318
                    ],
                    "children": [
                        {
                            "type": "FieldDecl",
                            "name": "provider",
                            "range": [
                                310,
                                312
                            ],
                            "children": [
                                {
                                    "type": "TypeAnnotation",
                                    "name": "str",
                                    "range": [
                                        312,
                                        312
                                    ],
                                    "children": [],
                                    "content": "NamedTuple"
                                }
                            ],
                            "content": "ModelMetadata(NamedTuple"
                        },
                        {
                            "type": "FieldDecl",
                            "name": "context_window",
                            "range": [
                                314,
                                316
                            ],
                            "children": [
                                {
                                    "type": "TypeAnnotation",
                                    "name": "int",
                                    "range": [
                                        316,
                                        316
                                    ],
                                    "children": [],
                                    "content": "provider"
                                }
                            ],
                            "content": ":\nprovider"
                        }
                    ],
                    "content": "\nclass ModelMetadata(NamedTuple):\nprovider:str"
                }
            ],
            "content": ",\n)\n\n\nclass ModelMetadata(NamedTuple):\nprovider:str"
        },
        {
            "type": "ClassDecl",
            "name": "LlmModelMeta",
            "range": [
                319,
                325
            ],
            "children": [
                {
                    "type": "Inheritance",
                    "name": "EnumMeta",
                    "range": [
                        321,
                        323
                    ],
                    "children": [],
                    "content": ":int\n"
                }
            ],
            "content": "\ncontext_window:int\n\n\n"
        },
        {
            "type": "FunctionDecl",
            "name": "__members__",
            "range": [
                329,
                377
            ],
            "children": [
                {
                    "type": "Parameter",
                    "name": "self",
                    "range": [
                        333,
                        335
                    ],
                    "children": [],
                    "content": "@property\n"
                },
                {
                    "type": "ReturnType",
                    "name": "MappingProxyType[str, _EnumMemberT]",
                    "range": [
                        344,
                        349
                    ],
                    "children": [],
                    "content": "\"_EnumMemberT\"],\n)-"
                },
                {
                    "type": "IfStatement",
                    "name": "if",
                    "range": [
                        352,
                        365
                    ],
                    "children": [
                        {
                            "type": "BinaryExpression",
                            "name": "Settings().config.behave_as == BehaveAs.LOCAL",
                            "range": [
                                353,
                                364
                            ],
                            "children": [],
                            "content": "str,\"_EnumMemberT\"]:\nif Settings().config"
                        },
                        {
                            "type": "Block",
                            "name": "",
                            "range": [
                                366,
                                376
                            ],
                            "children": [
                                {
                                    "type": "Assignment",
                                    "name": "members = super().__members__",
                                    "range": [
                                        367,
                                        373
                                    ],
                                    "children": [],
                                    "content": "==BehaveAs.LOCAL:\n"
                                },
                                {
                                    "type": "Return",
                                    "name": "return members",
                                    "range": [
                                        375,
                                        376
                                    ],
                                    "children": [],
                                    "content": "=super"
                                }
                            ],
                            "content": "behave_as==BehaveAs.LOCAL:\nmembers=super"
                        }
                    ],
                    "content": "[str,\"_EnumMemberT\"]:\nif Settings().config."
                },
                {
                    "type": "ElseStatement",
                    "name": "else",
                    "range": [
                        378,
                        432
                    ],
                    "children": [
                        {
                            "type": "Block",
                            "name": "",
                            "range": [
                                380,
                                432
                            ],
                            "children": [
                                {
                                    "type": "Assignment",
                                    "name": "removed_providers = [\"ollama\"]",
                                    "range": [
                                        381,
                                        385
                                    ],
                                    "children": [],
                                    "content": "\nreturn members\nelse"
                                },
                                {
                                    "type": "Assignment",
                                    "name": "existing_members = super().__members__",
                                    "range": [
                                        387,
                                        393
                                    ],
                                    "children": [],
                                    "content": "\nremoved_providers=[\"ollama\"]\n"
                                },
                                {
                                    "type": "Assignment",
                                    "name": "members = {name: member for name, member in existing_members.items() if LlmModel[name].provider not in removed_providers}",
                                    "range": [
                                        395,
                                        424
                                    ],
                                    "children": [],
                                    "content": "=super().__members__\nmembers={\nname:member\nfor name,member in existing_members.items()\nif LlmModel[name"
                                },
                                {
                                    "type": "Return",
                                    "name": "return MappingProxyType(members)",
                                    "range": [
                                        427,
                                        431
                                    ],
                                    "children": [],
                                    "content": "provider not in removed_providers\n"
                                }
                            ],
                            "content": "__members__\nreturn members\nelse:\nremoved_providers=[\"ollama\"]\nexisting_members=super().__members__\nmembers={\nname:member\nfor name,member in existing_members.items()\nif LlmModel[name].provider not in removed_providers\n}"
                        }
                    ],
                    "content": ").__members__\nreturn members\nelse:\nremoved_providers=[\"ollama\"]\nexisting_members=super().__members__\nmembers={\nname:member\nfor name,member in existing_members.items()\nif LlmModel[name].provider not in removed_providers\n}"
                }
            ],
            "content": "EnumMeta):\n@property\ndef __members__(\nself:type[\"_EnumMemberT\"],\n)->MappingProxyType[str,\"_EnumMemberT\"]:\nif Settings().config.behave_as==BehaveAs.LOCAL:\nmembers=super("
        },
        {
            "type": "ClassDecl",
            "name": "LlmModel",
            "range": [
                434,
                445
            ],
            "children": [
                {
                    "type": "arguments",
                    "name": "arguments",
                    "range": [
                        436,
                        444
                    ],
                    "children": [
                        {
                            "type": "arg",
                            "name": "str",
                            "range": [
                                437,
                                437
                            ],
                            "content": "members"
                        },
                        {
                            "type": "arg",
                            "name": "Enum",
                            "range": [
                                439,
                                439
                            ],
                            "content": "\n"
                        },
                        {
                            "type": "keyword",
                            "name": "metaclass",
                            "range": [
                                441,
                                443
                            ],
                            "children": [
                                {
                                    "type": "Identifier",
                                    "name": "LlmModelMeta",
                                    "range": [
                                        443,
                                        443
                                    ],
                                    "content": "LlmModel"
                                }
                            ],
                            "content": "\nclass LlmModel"
                        }
                    ],
                    "content": "(members)\n\n\nclass LlmModel("
                }
            ],
            "content": "return MappingProxyType(members)\n\n\nclass LlmModel(str"
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                451,
                453
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "O1_PREVIEW",
                    "range": [
                        451,
                        451
                    ],
                    "content": "LlmModelMeta"
                },
                {
                    "type": "Literal",
                    "name": "o1-preview",
                    "range": [
                        453,
                        453
                    ],
                    "content": ":"
                }
            ],
            "content": "LlmModelMeta):"
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                455,
                457
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "O1_MINI",
                    "range": [
                        455,
                        455
                    ],
                    "content": "#"
                },
                {
                    "type": "Literal",
                    "name": "o1-mini",
                    "range": [
                        457,
                        457
                    ],
                    "content": "models"
                }
            ],
            "content": "#OpenAI models"
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                459,
                461
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "GPT4O_MINI",
                    "range": [
                        459,
                        459
                    ],
                    "content": "O1_PREVIEW"
                },
                {
                    "type": "Literal",
                    "name": "gpt-4o-mini",
                    "range": [
                        461,
                        461
                    ],
                    "content": "\"o1-preview\""
                }
            ],
            "content": "O1_PREVIEW=\"o1-preview\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                463,
                465
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "GPT4O",
                    "range": [
                        463,
                        463
                    ],
                    "content": "O1_MINI"
                },
                {
                    "type": "Literal",
                    "name": "gpt-4o",
                    "range": [
                        465,
                        465
                    ],
                    "content": "\"o1-mini\""
                }
            ],
            "content": "O1_MINI=\"o1-mini\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                467,
                469
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "GPT4_TURBO",
                    "range": [
                        467,
                        467
                    ],
                    "content": "GPT4O_MINI"
                },
                {
                    "type": "Literal",
                    "name": "gpt-4-turbo",
                    "range": [
                        469,
                        469
                    ],
                    "content": "\"gpt-4o-mini\""
                }
            ],
            "content": "GPT4O_MINI=\"gpt-4o-mini\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                471,
                473
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "GPT3_5_TURBO",
                    "range": [
                        471,
                        471
                    ],
                    "content": "GPT4O"
                },
                {
                    "type": "Literal",
                    "name": "gpt-3.5-turbo",
                    "range": [
                        473,
                        473
                    ],
                    "content": "\"gpt-4o\""
                }
            ],
            "content": "GPT4O=\"gpt-4o\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                479,
                481
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "CLAUDE_3_5_SONNET",
                    "range": [
                        479,
                        479
                    ],
                    "content": "GPT3_5_TURBO"
                },
                {
                    "type": "Literal",
                    "name": "claude-3-5-sonnet-latest",
                    "range": [
                        481,
                        481
                    ],
                    "content": "\"gpt-3.5-turbo\""
                }
            ],
            "content": "GPT3_5_TURBO=\"gpt-3.5-turbo\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                483,
                485
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "CLAUDE_3_HAIKU",
                    "range": [
                        483,
                        483
                    ],
                    "content": "#"
                },
                {
                    "type": "Literal",
                    "name": "claude-3-haiku-20240307",
                    "range": [
                        485,
                        485
                    ],
                    "content": "models"
                }
            ],
            "content": "#Anthropic models"
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                491,
                493
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "LLAMA3_8B",
                    "range": [
                        491,
                        491
                    ],
                    "content": "CLAUDE_3_HAIKU"
                },
                {
                    "type": "Literal",
                    "name": "llama3-8b-8192",
                    "range": [
                        493,
                        493
                    ],
                    "content": "\"claude-3-haiku-20240307\""
                }
            ],
            "content": "CLAUDE_3_HAIKU=\"claude-3-haiku-20240307\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                495,
                497
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "LLAMA3_70B",
                    "range": [
                        495,
                        495
                    ],
                    "content": "#"
                },
                {
                    "type": "Literal",
                    "name": "llama3-70b-8192",
                    "range": [
                        497,
                        497
                    ],
                    "content": "models"
                }
            ],
            "content": "#Groq models"
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                499,
                501
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "MIXTRAL_8X7B",
                    "range": [
                        499,
                        499
                    ],
                    "content": "LLAMA3_8B"
                },
                {
                    "type": "Literal",
                    "name": "mixtral-8x7b-32768",
                    "range": [
                        501,
                        501
                    ],
                    "content": "\"llama3-8b-8192\""
                }
            ],
            "content": "LLAMA3_8B=\"llama3-8b-8192\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                503,
                505
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "GEMMA_7B",
                    "range": [
                        503,
                        503
                    ],
                    "content": "LLAMA3_70B"
                },
                {
                    "type": "Literal",
                    "name": "gemma-7b-it",
                    "range": [
                        505,
                        505
                    ],
                    "content": "\"llama3-70b-8192\""
                }
            ],
            "content": "LLAMA3_70B=\"llama3-70b-8192\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                507,
                509
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "GEMMA2_9B",
                    "range": [
                        507,
                        507
                    ],
                    "content": "MIXTRAL_8X7B"
                },
                {
                    "type": "Literal",
                    "name": "gemma2-9b-it",
                    "range": [
                        509,
                        509
                    ],
                    "content": "\"mixtral-8x7b-32768\""
                }
            ],
            "content": "MIXTRAL_8X7B=\"mixtral-8x7b-32768\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                519,
                521
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "LLAMA3_1_405B",
                    "range": [
                        519,
                        519
                    ],
                    "content": "#"
                },
                {
                    "type": "Literal",
                    "name": "llama-3.1-405b-reasoning",
                    "range": [
                        521,
                        521
                    ],
                    "content": "Groq"
                }
            ],
            "content": "#New Groq"
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                523,
                525
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "LLAMA3_1_70B",
                    "range": [
                        523,
                        523
                    ],
                    "content": "("
                },
                {
                    "type": "Literal",
                    "name": "llama-3.1-70b-versatile",
                    "range": [
                        525,
                        525
                    ],
                    "content": ")"
                }
            ],
            "content": "(Preview)"
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                527,
                529
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "LLAMA3_1_8B",
                    "range": [
                        527,
                        527
                    ],
                    "content": "LLAMA3_1_405B"
                },
                {
                    "type": "Literal",
                    "name": "llama-3.1-8b-instant",
                    "range": [
                        529,
                        529
                    ],
                    "content": "\"llama-3.1-405b-reasoning\""
                }
            ],
            "content": "LLAMA3_1_405B=\"llama-3.1-405b-reasoning\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                535,
                537
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "OLLAMA_LLAMA3_8B",
                    "range": [
                        535,
                        535
                    ],
                    "content": "LLAMA3_1_8B"
                },
                {
                    "type": "Literal",
                    "name": "llama3",
                    "range": [
                        537,
                        537
                    ],
                    "content": "\"llama-3.1-8b-instant\""
                }
            ],
            "content": "LLAMA3_1_8B=\"llama-3.1-8b-instant\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                539,
                541
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "OLLAMA_LLAMA3_405B",
                    "range": [
                        539,
                        539
                    ],
                    "content": "#"
                },
                {
                    "type": "Literal",
                    "name": "llama3.1:405b",
                    "range": [
                        541,
                        541
                    ],
                    "content": "models"
                }
            ],
            "content": "#Ollama models"
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                543,
                545
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "OLLAMA_DOLPHIN",
                    "range": [
                        543,
                        543
                    ],
                    "content": "OLLAMA_LLAMA3_8B"
                },
                {
                    "type": "Literal",
                    "name": "dolphin-mistral:latest",
                    "range": [
                        545,
                        545
                    ],
                    "content": "\"llama3\""
                }
            ],
            "content": "OLLAMA_LLAMA3_8B=\"llama3\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                551,
                553
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "GEMINI_FLASH_1_5_8B",
                    "range": [
                        551,
                        551
                    ],
                    "content": "OLLAMA_DOLPHIN"
                },
                {
                    "type": "Literal",
                    "name": "google/gemini-flash-1.5",
                    "range": [
                        553,
                        553
                    ],
                    "content": "\"dolphin-mistral:latest\""
                }
            ],
            "content": "OLLAMA_DOLPHIN=\"dolphin-mistral:latest\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                555,
                557
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "GROK_BETA",
                    "range": [
                        555,
                        555
                    ],
                    "content": "#"
                },
                {
                    "type": "Literal",
                    "name": "x-ai/grok-beta",
                    "range": [
                        557,
                        557
                    ],
                    "content": "models"
                }
            ],
            "content": "#OpenRouter models"
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                559,
                561
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "MISTRAL_NEMO",
                    "range": [
                        559,
                        559
                    ],
                    "content": "GEMINI_FLASH_1_5_8B"
                },
                {
                    "type": "Literal",
                    "name": "mistralai/mistral-nemo",
                    "range": [
                        561,
                        561
                    ],
                    "content": "\"google/gemini-flash-1.5\""
                }
            ],
            "content": "GEMINI_FLASH_1_5_8B=\"google/gemini-flash-1.5\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                563,
                565
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "COHERE_COMMAND_R_08_2024",
                    "range": [
                        563,
                        563
                    ],
                    "content": "GROK_BETA"
                },
                {
                    "type": "Literal",
                    "name": "cohere/command-r-08-2024",
                    "range": [
                        565,
                        565
                    ],
                    "content": "\"x-ai/grok-beta\""
                }
            ],
            "content": "GROK_BETA=\"x-ai/grok-beta\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                567,
                569
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "COHERE_COMMAND_R_PLUS_08_2024",
                    "range": [
                        567,
                        567
                    ],
                    "content": "MISTRAL_NEMO"
                },
                {
                    "type": "Literal",
                    "name": "cohere/command-r-plus-08-2024",
                    "range": [
                        569,
                        569
                    ],
                    "content": "\"mistralai/mistral-nemo\""
                }
            ],
            "content": "MISTRAL_NEMO=\"mistralai/mistral-nemo\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                571,
                573
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "EVA_QWEN_2_5_32B",
                    "range": [
                        571,
                        571
                    ],
                    "content": "COHERE_COMMAND_R_08_2024"
                },
                {
                    "type": "Literal",
                    "name": "eva-unit-01/eva-qwen-2.5-32b",
                    "range": [
                        573,
                        573
                    ],
                    "content": "\"cohere/command-r-08-2024\""
                }
            ],
            "content": "COHERE_COMMAND_R_08_2024=\"cohere/command-r-08-2024\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                575,
                577
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "DEEPSEEK_CHAT",
                    "range": [
                        575,
                        575
                    ],
                    "content": "COHERE_COMMAND_R_PLUS_08_2024"
                },
                {
                    "type": "Literal",
                    "name": "deepseek/deepseek-chat",
                    "range": [
                        577,
                        577
                    ],
                    "content": "\"cohere/command-r-plus-08-2024\""
                }
            ],
            "content": "COHERE_COMMAND_R_PLUS_08_2024=\"cohere/command-r-plus-08-2024\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                579,
                581
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "PERPLEXITY_LLAMA_3_1_SONAR_LARGE_128K_ONLINE",
                    "range": [
                        579,
                        579
                    ],
                    "content": "EVA_QWEN_2_5_32B"
                },
                {
                    "type": "Literal",
                    "name": "perplexity/llama-3.1-sonar-large-128k-online",
                    "range": [
                        581,
                        581
                    ],
                    "content": "\"eva-unit-01/eva-qwen-2.5-32b\""
                }
            ],
            "content": "EVA_QWEN_2_5_32B=\"eva-unit-01/eva-qwen-2.5-32b\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                587,
                589
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "QWEN_QWQ_32B_PREVIEW",
                    "range": [
                        587,
                        587
                    ],
                    "content": "PERPLEXITY_LLAMA_3_1_SONAR_LARGE_128K_ONLINE"
                },
                {
                    "type": "Literal",
                    "name": "qwen/qwq-32b-preview",
                    "range": [
                        589,
                        589
                    ],
                    "content": "("
                }
            ],
            "content": "PERPLEXITY_LLAMA_3_1_SONAR_LARGE_128K_ONLINE=("
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                591,
                593
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "NOUSRESEARCH_HERMES_3_LLAMA_3_1_405B",
                    "range": [
                        591,
                        591
                    ],
                    "content": "\"perplexity/llama-3.1-sonar-large-128k-online\""
                },
                {
                    "type": "Literal",
                    "name": "nousresearch/hermes-3-llama-3.1-405b",
                    "range": [
                        593,
                        593
                    ],
                    "content": ")"
                }
            ],
            "content": "\"perplexity/llama-3.1-sonar-large-128k-online\"\n)"
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                595,
                597
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "NOUSRESEARCH_HERMES_3_LLAMA_3_1_70B",
                    "range": [
                        595,
                        595
                    ],
                    "content": "QWEN_QWQ_32B_PREVIEW"
                },
                {
                    "type": "Literal",
                    "name": "nousresearch/hermes-3-llama-3.1-70b",
                    "range": [
                        597,
                        597
                    ],
                    "content": "\"qwen/qwq-32b-preview\""
                }
            ],
            "content": "QWEN_QWQ_32B_PREVIEW=\"qwen/qwq-32b-preview\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                599,
                601
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "AMAZON_NOVA_LITE_V1",
                    "range": [
                        599,
                        599
                    ],
                    "content": "NOUSRESEARCH_HERMES_3_LLAMA_3_1_405B"
                },
                {
                    "type": "Literal",
                    "name": "amazon/nova-lite-v1",
                    "range": [
                        601,
                        601
                    ],
                    "content": "\"nousresearch/hermes-3-llama-3.1-405b\""
                }
            ],
            "content": "NOUSRESEARCH_HERMES_3_LLAMA_3_1_405B=\"nousresearch/hermes-3-llama-3.1-405b\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                603,
                605
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "AMAZON_NOVA_MICRO_V1",
                    "range": [
                        603,
                        603
                    ],
                    "content": "NOUSRESEARCH_HERMES_3_LLAMA_3_1_70B"
                },
                {
                    "type": "Literal",
                    "name": "amazon/nova-micro-v1",
                    "range": [
                        605,
                        605
                    ],
                    "content": "\"nousresearch/hermes-3-llama-3.1-70b\""
                }
            ],
            "content": "NOUSRESEARCH_HERMES_3_LLAMA_3_1_70B=\"nousresearch/hermes-3-llama-3.1-70b\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                607,
                609
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "AMAZON_NOVA_PRO_V1",
                    "range": [
                        607,
                        607
                    ],
                    "content": "AMAZON_NOVA_LITE_V1"
                },
                {
                    "type": "Literal",
                    "name": "amazon/nova-pro-v1",
                    "range": [
                        609,
                        609
                    ],
                    "content": "\"amazon/nova-lite-v1\""
                }
            ],
            "content": "AMAZON_NOVA_LITE_V1=\"amazon/nova-lite-v1\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                611,
                613
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "MICROSOFT_WIZARDLM_2_8X22B",
                    "range": [
                        611,
                        611
                    ],
                    "content": "AMAZON_NOVA_MICRO_V1"
                },
                {
                    "type": "Literal",
                    "name": "microsoft/wizardlm-2-8x22b",
                    "range": [
                        613,
                        613
                    ],
                    "content": "\"amazon/nova-micro-v1\""
                }
            ],
            "content": "AMAZON_NOVA_MICRO_V1=\"amazon/nova-micro-v1\""
        },
        {
            "type": "Assign",
            "name": "Assign",
            "range": [
                615,
                617
            ],
            "children": [
                {
                    "type": "Identifier",
                    "name": "GRYPHE_MYTHOMAX_L2_13B",
                    "range": [
                        615,
                        615
                    ],
                    "content": "AMAZON_NOVA_PRO_V1"
                },
                {
                    "type": "Literal",
                    "name": "gryphe/mythomax-l2-13b",
                    "range": [
                        617,
                        617
                    ],
                    "content": "\"amazon/nova-pro-v1\""
                }
            ],
            "content": "AMAZON_NOVA_PRO_V1=\"amazon/nova-pro-v1\""
        },
        {
            "type": "FunctionDecl",
            "name": "metadata",
            "range": [
                623,
                638
            ],
            "children": [
                {
                    "type": "arguments",
                    "name": "arguments",
                    "range": [
                        625,
                        627
                    ],
                    "children": [
                        {
                            "type": "arg",
                            "name": "self",
                            "range": [
                                626,
                                626
                            ],
                            "content": "\n"
                        }
                    ],
                    "content": "\"gryphe/mythomax-l2-13b\"\n\n"
                },
                {
                    "type": "Return",
                    "name": "Return",
                    "range": [
                        633,
                        634
                    ],
                    "children": [
                        {
                            "type": "Subscript",
                            "name": "Subscript",
                            "range": [
                                634,
                                637
                            ],
                            "children": [
                                {
                                    "type": "Identifier",
                                    "name": "MODEL_METADATA",
                                    "range": [
                                        634,
                                        634
                                    ],
                                    "content": "self"
                                },
                                {
                                    "type": "Identifier",
                                    "name": "self",
                                    "range": [
                                        636,
                                        636
                                    ],
                                    "content": "-"
                                }
                            ],
                            "content": "self)->"
                        }
                    ],
                    "content": "(self"
                }
            ],
            "content": "GRYPHE_MYTHOMAX_L2_13B=\"gryphe/mythomax-l2-13b\"\n\n@property\ndef metadata(self)->ModelMetadata"
        },
        {
            "type": "FunctionDecl",
            "name": "provider",
            "range": [
                643,
                659
            ],
            "children": [
                {
                    "type": "arguments",
                    "name": "arguments",
                    "range": [
                        645,
                        647
                    ],
                    "children": [
                        {
                            "type": "arg",
                            "name": "self",
                            "range": [
                                646,
                                646
                            ],
                            "content": "\n"
                        }
                    ],
                    "content": "]\n\n"
                },
                {
                    "type": "Return",
                    "name": "Return",
                    "range": [
                        653,
                        654
                    ],
                    "children": [
                        {
                            "type": "Attribute",
                            "name": "Attribute",
                            "range": [
                                654,
                                658
                            ],
                            "children": [
                                {
                                    "type": "Identifier",
                                    "name": "self",
                                    "range": [
                                        654,
                                        654
                                    ],
                                    "content": "self"
                                },
                                {
                                    "type": "Identifier",
                                    "name": "metadata",
                                    "range": [
                                        656,
                                        656
                                    ],
                                    "content": "-"
                                },
                                {
                                    "type": "Identifier",
                                    "name": "provider",
                                    "range": [
                                        658,
                                        658
                                    ],
                                    "content": "str"
                                }
                            ],
                            "content": "self)->str"
                        }
                    ],
                    "content": "(self"
                }
            ],
            "content": "[self]\n\n@property\ndef provider(self)->str:"
        },
        {
            "type": "FunctionDecl",
            "name": "context_window",
            "range": [
                664,
                680
            ],
            "children": [
                {
                    "type": "arguments",
                    "name": "arguments",
                    "range": [
                        666,
                        668
                    ],
                    "children": [
                        {
                            "type": "arg",
                            "name": "self",
                            "range": [
                                667,
                                667
                            ],
                            "content": "\n"
                        }
                    ],
                    "content": "provider\n\n"
                },
                {
                    "type": "Return",
                    "name": "Return",
                    "range": [
                        674,
                        675
                    ],
                    "children": [
                        {
                            "type": "Attribute",
                            "name": "Attribute",
                            "range": [
                                675,
                                679
                            ],
                            "children": [
                                {
                                    "type": "Identifier",
                                    "name": "self",
                                    "range": [
                                        675,
                                        675
                                    ],
                                    "content": "self"
                                },
                                {
                                    "type": "Identifier",
                                    "name": "metadata",
                                    "range": [
                                        677,
                                        677
                                    ],
                                    "content": "-"
                                },
                                {
                                    "type": "Identifier",
                                    "name": "context_window",
                                    "range": [
                                        679,
                                        679
                                    ],
                                    "content": "int"
                                }
                            ],
                            "content": "self)->int"
                        }
                    ],
                    "content": "(self"
                }
            ],
            "content": "metadata.provider\n\n@property\ndef context_window(self)->int:"
        },
        {
            "type": "AssignmentExpression",
            "name": "",
            "range": [
                683,
                1117
            ],
            "children": [
                {
                    "type": "ObjectExpression",
                    "name": "",
                    "range": [
                        685,
                        1117
                    ],
                    "children": [
                        {
                            "type": "Property",
                            "name": "LlmModel.O1_PREVIEW",
                            "range": [
                                687,
                                696
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        691,
                                        696
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"openai\"",
                                            "range": [
                                                693,
                                                693
                                            ],
                                            "content": "{"
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "32000",
                                            "range": [
                                                695,
                                                695
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "MODEL_METADATA={\nLlmModel."
                                }
                            ],
                            "content": "context_window\n\n\nMODEL_METADATA={\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.O1_MINI",
                            "range": [
                                699,
                                708
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        703,
                                        708
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"openai\"",
                                            "range": [
                                                705,
                                                705
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "62000",
                                            "range": [
                                                707,
                                                707
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "32000),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"openai\",32000),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.GPT4O_MINI",
                            "range": [
                                711,
                                720
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        715,
                                        720
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"openai\"",
                                            "range": [
                                                717,
                                                717
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "128000",
                                            "range": [
                                                719,
                                                719
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "62000),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"openai\",62000),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.GPT4O",
                            "range": [
                                723,
                                732
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        727,
                                        732
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"openai\"",
                                            "range": [
                                                729,
                                                729
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "128000",
                                            "range": [
                                                731,
                                                731
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "128000),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"openai\",128000),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.GPT4_TURBO",
                            "range": [
                                735,
                                744
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        739,
                                        744
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"openai\"",
                                            "range": [
                                                741,
                                                741
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "128000",
                                            "range": [
                                                743,
                                                743
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "128000),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"openai\",128000),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.GPT3_5_TURBO",
                            "range": [
                                747,
                                756
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        751,
                                        756
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"openai\"",
                                            "range": [
                                                753,
                                                753
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "16385",
                                            "range": [
                                                755,
                                                755
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "128000),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"openai\",128000),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.CLAUDE_3_5_SONNET",
                            "range": [
                                759,
                                768
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        763,
                                        768
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"anthropic\"",
                                            "range": [
                                                765,
                                                765
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "200000",
                                            "range": [
                                                767,
                                                767
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "16385),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"openai\",16385),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.CLAUDE_3_HAIKU",
                            "range": [
                                771,
                                780
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        775,
                                        780
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"anthropic\"",
                                            "range": [
                                                777,
                                                777
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "200000",
                                            "range": [
                                                779,
                                                779
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "200000),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"anthropic\",200000),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.LLAMA3_8B",
                            "range": [
                                783,
                                792
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        787,
                                        792
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"groq\"",
                                            "range": [
                                                789,
                                                789
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "8192",
                                            "range": [
                                                791,
                                                791
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "200000),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"anthropic\",200000),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.LLAMA3_70B",
                            "range": [
                                795,
                                804
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        799,
                                        804
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"groq\"",
                                            "range": [
                                                801,
                                                801
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "8192",
                                            "range": [
                                                803,
                                                803
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "8192),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"groq\",8192),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.MIXTRAL_8X7B",
                            "range": [
                                807,
                                816
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        811,
                                        816
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"groq\"",
                                            "range": [
                                                813,
                                                813
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "32768",
                                            "range": [
                                                815,
                                                815
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "8192),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"groq\",8192),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.GEMMA_7B",
                            "range": [
                                819,
                                828
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        823,
                                        828
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"groq\"",
                                            "range": [
                                                825,
                                                825
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "8192",
                                            "range": [
                                                827,
                                                827
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "32768),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"groq\",32768),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.GEMMA2_9B",
                            "range": [
                                831,
                                840
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        835,
                                        840
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"groq\"",
                                            "range": [
                                                837,
                                                837
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "8192",
                                            "range": [
                                                839,
                                                839
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "8192),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"groq\",8192),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.LLAMA3_1_405B",
                            "range": [
                                843,
                                852
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        847,
                                        852
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"groq\"",
                                            "range": [
                                                849,
                                                849
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "8192",
                                            "range": [
                                                851,
                                                851
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "8192),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"groq\",8192),\nLlmModel."
                        },
                        {
                            "type": "Comment",
                            "name": "# Limited to 16 k during preview",
                            "range": [
                                855,
                                861
                            ],
                            "content": "ModelMetadata(\"groq\",8192),"
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.LLAMA3_1_70B",
                            "range": [
                                863,
                                872
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        867,
                                        872
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"groq\"",
                                            "range": [
                                                869,
                                                869
                                            ],
                                            "content": "preview"
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "131072",
                                            "range": [
                                                871,
                                                871
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "k during preview\nLlmModel."
                                }
                            ],
                            "content": "#Limited to16k during preview\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.LLAMA3_1_8B",
                            "range": [
                                875,
                                884
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        879,
                                        884
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"groq\"",
                                            "range": [
                                                881,
                                                881
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "131072",
                                            "range": [
                                                883,
                                                883
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "131072),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"groq\",131072),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.OLLAMA_LLAMA3_8B",
                            "range": [
                                887,
                                896
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        891,
                                        896
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"ollama\"",
                                            "range": [
                                                893,
                                                893
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "8192",
                                            "range": [
                                                895,
                                                895
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "131072),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"groq\",131072),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.OLLAMA_LLAMA3_405B",
                            "range": [
                                899,
                                908
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        903,
                                        908
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"ollama\"",
                                            "range": [
                                                905,
                                                905
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "8192",
                                            "range": [
                                                907,
                                                907
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "8192),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"ollama\",8192),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.OLLAMA_DOLPHIN",
                            "range": [
                                911,
                                920
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        915,
                                        920
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"ollama\"",
                                            "range": [
                                                917,
                                                917
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "32768",
                                            "range": [
                                                919,
                                                919
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "8192),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"ollama\",8192),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.GEMINI_FLASH_1_5_8B",
                            "range": [
                                923,
                                932
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        927,
                                        932
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"open_router\"",
                                            "range": [
                                                929,
                                                929
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "8192",
                                            "range": [
                                                931,
                                                931
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "32768),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"ollama\",32768),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.GROK_BETA",
                            "range": [
                                935,
                                944
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        939,
                                        944
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"open_router\"",
                                            "range": [
                                                941,
                                                941
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "8192",
                                            "range": [
                                                943,
                                                943
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "8192),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"open_router\",8192),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.MISTRAL_NEMO",
                            "range": [
                                947,
                                956
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        951,
                                        956
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"open_router\"",
                                            "range": [
                                                953,
                                                953
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "4000",
                                            "range": [
                                                955,
                                                955
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "8192),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"open_router\",8192),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.COHERE_COMMAND_R_08_2024",
                            "range": [
                                959,
                                968
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        963,
                                        968
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"open_router\"",
                                            "range": [
                                                965,
                                                965
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "4000",
                                            "range": [
                                                967,
                                                967
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "4000),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"open_router\",4000),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.COHERE_COMMAND_R_PLUS_08_2024",
                            "range": [
                                971,
                                980
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        975,
                                        980
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"open_router\"",
                                            "range": [
                                                977,
                                                977
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "4000",
                                            "range": [
                                                979,
                                                979
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "4000),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"open_router\",4000),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.EVA_QWEN_2_5_32B",
                            "range": [
                                983,
                                992
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        987,
                                        992
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"open_router\"",
                                            "range": [
                                                989,
                                                989
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "4000",
                                            "range": [
                                                991,
                                                991
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "4000),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"open_router\",4000),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.DEEPSEEK_CHAT",
                            "range": [
                                995,
                                1004
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        999,
                                        1004
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"open_router\"",
                                            "range": [
                                                1001,
                                                1001
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "8192",
                                            "range": [
                                                1003,
                                                1003
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "4000),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"open_router\",4000),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.PERPLEXITY_LLAMA_3_1_SONAR_LARGE_128K_ONLINE",
                            "range": [
                                1007,
                                1018
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        1011,
                                        1018
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"open_router\"",
                                            "range": [
                                                1014,
                                                1014
                                            ],
                                            "content": "\n"
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "8192",
                                            "range": [
                                                1016,
                                                1016
                                            ],
                                            "content": "."
                                        }
                                    ],
                                    "content": "8192),\nLlmModel.PERPLEXITY_LLAMA_3_1_SONAR_LARGE_128K_ONLINE:"
                                }
                            ],
                            "content": "ModelMetadata(\"open_router\",8192),\nLlmModel.PERPLEXITY_LLAMA_3_1_SONAR_LARGE_128K_ONLINE:"
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.QWEN_QWQ_32B_PREVIEW",
                            "range": [
                                1021,
                                1030
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        1025,
                                        1030
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"open_router\"",
                                            "range": [
                                                1027,
                                                1027
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "4000",
                                            "range": [
                                                1029,
                                                1029
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "\n),\nLlmModel."
                                }
                            ],
                            "content": "\n\"open_router\",8192\n),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.NOUSRESEARCH_HERMES_3_LLAMA_3_1_405B",
                            "range": [
                                1033,
                                1042
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        1037,
                                        1042
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"open_router\"",
                                            "range": [
                                                1039,
                                                1039
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "4000",
                                            "range": [
                                                1041,
                                                1041
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "4000),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"open_router\",4000),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.NOUSRESEARCH_HERMES_3_LLAMA_3_1_70B",
                            "range": [
                                1045,
                                1054
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        1049,
                                        1054
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"open_router\"",
                                            "range": [
                                                1051,
                                                1051
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "4000",
                                            "range": [
                                                1053,
                                                1053
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "4000),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"open_router\",4000),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.AMAZON_NOVA_LITE_V1",
                            "range": [
                                1057,
                                1066
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        1061,
                                        1066
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"open_router\"",
                                            "range": [
                                                1063,
                                                1063
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "4000",
                                            "range": [
                                                1065,
                                                1065
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "4000),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"open_router\",4000),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.AMAZON_NOVA_MICRO_V1",
                            "range": [
                                1069,
                                1078
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        1073,
                                        1078
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"open_router\"",
                                            "range": [
                                                1075,
                                                1075
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "4000",
                                            "range": [
                                                1077,
                                                1077
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "4000),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"open_router\",4000),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.AMAZON_NOVA_PRO_V1",
                            "range": [
                                1081,
                                1090
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        1085,
                                        1090
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"open_router\"",
                                            "range": [
                                                1087,
                                                1087
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "4000",
                                            "range": [
                                                1089,
                                                1089
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "4000),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"open_router\",4000),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.MICROSOFT_WIZARDLM_2_8X22B",
                            "range": [
                                1093,
                                1102
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        1097,
                                        1102
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"open_router\"",
                                            "range": [
                                                1099,
                                                1099
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "4000",
                                            "range": [
                                                1101,
                                                1101
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "4000),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"open_router\",4000),\nLlmModel."
                        },
                        {
                            "type": "Property",
                            "name": "LlmModel.GRYPHE_MYTHOMAX_L2_13B",
                            "range": [
                                1105,
                                1114
                            ],
                            "children": [
                                {
                                    "type": "CallExpression",
                                    "name": "ModelMetadata",
                                    "range": [
                                        1109,
                                        1114
                                    ],
                                    "children": [
                                        {
                                            "type": "Literal",
                                            "name": "\"open_router\"",
                                            "range": [
                                                1111,
                                                1111
                                            ],
                                            "content": ","
                                        },
                                        {
                                            "type": "Literal",
                                            "name": "4000",
                                            "range": [
                                                1113,
                                                1113
                                            ],
                                            "content": "LlmModel"
                                        }
                                    ],
                                    "content": "4000),\nLlmModel."
                                }
                            ],
                            "content": "ModelMetadata(\"open_router\",4000),\nLlmModel."
                        }
                    ],
                    "content": "metadata.context_window\n\n\nMODEL_METADATA={\nLlmModel.O1_PREVIEW:ModelMetadata(\"openai\",32000),\nLlmModel.O1_MINI:ModelMetadata(\"openai\",62000),\nLlmModel.GPT4O_MINI:ModelMetadata(\"openai\",128000),\nLlmModel.GPT4O:ModelMetadata(\"openai\",128000),\nLlmModel.GPT4_TURBO:ModelMetadata(\"openai\",128000),\nLlmModel.GPT3_5_TURBO:ModelMetadata(\"openai\",16385),\nLlmModel.CLAUDE_3_5_SONNET:ModelMetadata(\"anthropic\",200000),\nLlmModel.CLAUDE_3_HAIKU:ModelMetadata(\"anthropic\",200000),\nLlmModel.LLAMA3_8B:ModelMetadata(\"groq\",8192),\nLlmModel.LLAMA3_70B:ModelMetadata(\"groq\",8192),\nLlmModel.MIXTRAL_8X7B:ModelMetadata(\"groq\",32768),\nLlmModel.GEMMA_7B:ModelMetadata(\"groq\",8192),\nLlmModel.GEMMA2_9B:ModelMetadata(\"groq\",8192),\nLlmModel.LLAMA3_1_405B:ModelMetadata(\"groq\",8192),\n#Limited to16k during preview\nLlmModel.LLAMA3_1_70B:ModelMetadata(\"groq\",131072),\nLlmModel.LLAMA3_1_8B:ModelMetadata(\"groq\",131072),\nLlmModel.OLLAMA_LLAMA3_8B:ModelMetadata(\"ollama\",8192),\nLlmModel.OLLAMA_LLAMA3_405B:ModelMetadata(\"ollama\",8192),\nLlmModel.OLLAMA_DOLPHIN:ModelMetadata(\"ollama\",32768),\nLlmModel.GEMINI_FLASH_1_5_8B:ModelMetadata(\"open_router\",8192),\nLlmModel.GROK_BETA:ModelMetadata(\"open_router\",8192),\nLlmModel.MISTRAL_NEMO:ModelMetadata(\"open_router\",4000),\nLlmModel.COHERE_COMMAND_R_08_2024:ModelMetadata(\"open_router\",4000),\nLlmModel.COHERE_COMMAND_R_PLUS_08_2024:ModelMetadata(\"open_router\",4000),\nLlmModel.EVA_QWEN_2_5_32B:ModelMetadata(\"open_router\",4000),\nLlmModel.DEEPSEEK_CHAT:ModelMetadata(\"open_router\",8192),\nLlmModel.PERPLEXITY_LLAMA_3_1_SONAR_LARGE_128K_ONLINE:ModelMetadata(\n\"open_router\",8192\n),\nLlmModel.QWEN_QWQ_32B_PREVIEW:ModelMetadata(\"open_router\",4000),\nLlmModel.NOUSRESEARCH_HERMES_3_LLAMA_3_1_405B:ModelMetadata(\"open_router\",4000),\nLlmModel.NOUSRESEARCH_HERMES_3_LLAMA_3_1_70B:ModelMetadata(\"open_router\",4000),\nLlmModel.AMAZON_NOVA_LITE_V1:ModelMetadata(\"open_router\",4000),\nLlmModel.AMAZON_NOVA_MICRO_V1:ModelMetadata(\"open_router\",4000),\nLlmModel.AMAZON_NOVA_PRO_V1:ModelMetadata(\"open_router\",4000),\nLlmModel.MICROSOFT_WIZARDLM_2_8X22B:ModelMetadata(\"open_router\",4000),\nLlmModel.GRYPHE_MYTHOMAX_L2_13B:ModelMetadata"
                }
            ],
            "content": "self.metadata.context_window\n\n\nMODEL_METADATA={\nLlmModel.O1_PREVIEW:ModelMetadata(\"openai\",32000),\nLlmModel.O1_MINI:ModelMetadata(\"openai\",62000),\nLlmModel.GPT4O_MINI:ModelMetadata(\"openai\",128000),\nLlmModel.GPT4O:ModelMetadata(\"openai\",128000),\nLlmModel.GPT4_TURBO:ModelMetadata(\"openai\",128000),\nLlmModel.GPT3_5_TURBO:ModelMetadata(\"openai\",16385),\nLlmModel.CLAUDE_3_5_SONNET:ModelMetadata(\"anthropic\",200000),\nLlmModel.CLAUDE_3_HAIKU:ModelMetadata(\"anthropic\",200000),\nLlmModel.LLAMA3_8B:ModelMetadata(\"groq\",8192),\nLlmModel.LLAMA3_70B:ModelMetadata(\"groq\",8192),\nLlmModel.MIXTRAL_8X7B:ModelMetadata(\"groq\",32768),\nLlmModel.GEMMA_7B:ModelMetadata(\"groq\",8192),\nLlmModel.GEMMA2_9B:ModelMetadata(\"groq\",8192),\nLlmModel.LLAMA3_1_405B:ModelMetadata(\"groq\",8192),\n#Limited to16k during preview\nLlmModel.LLAMA3_1_70B:ModelMetadata(\"groq\",131072),\nLlmModel.LLAMA3_1_8B:ModelMetadata(\"groq\",131072),\nLlmModel.OLLAMA_LLAMA3_8B:ModelMetadata(\"ollama\",8192),\nLlmModel.OLLAMA_LLAMA3_405B:ModelMetadata(\"ollama\",8192),\nLlmModel.OLLAMA_DOLPHIN:ModelMetadata(\"ollama\",32768),\nLlmModel.GEMINI_FLASH_1_5_8B:ModelMetadata(\"open_router\",8192),\nLlmModel.GROK_BETA:ModelMetadata(\"open_router\",8192),\nLlmModel.MISTRAL_NEMO:ModelMetadata(\"open_router\",4000),\nLlmModel.COHERE_COMMAND_R_08_2024:ModelMetadata(\"open_router\",4000),\nLlmModel.COHERE_COMMAND_R_PLUS_08_2024:ModelMetadata(\"open_router\",4000),\nLlmModel.EVA_QWEN_2_5_32B:ModelMetadata(\"open_router\",4000),\nLlmModel.DEEPSEEK_CHAT:ModelMetadata(\"open_router\",8192),\nLlmModel.PERPLEXITY_LLAMA_3_1_SONAR_LARGE_128K_ONLINE:ModelMetadata(\n\"open_router\",8192\n),\nLlmModel.QWEN_QWQ_32B_PREVIEW:ModelMetadata(\"open_router\",4000),\nLlmModel.NOUSRESEARCH_HERMES_3_LLAMA_3_1_405B:ModelMetadata(\"open_router\",4000),\nLlmModel.NOUSRESEARCH_HERMES_3_LLAMA_3_1_70B:ModelMetadata(\"open_router\",4000),\nLlmModel.AMAZON_NOVA_LITE_V1:ModelMetadata(\"open_router\",4000),\nLlmModel.AMAZON_NOVA_MICRO_V1:ModelMetadata(\"open_router\",4000),\nLlmModel.AMAZON_NOVA_PRO_V1:ModelMetadata(\"open_router\",4000),\nLlmModel.MICROSOFT_WIZARDLM_2_8X22B:ModelMetadata(\"open_router\",4000),\nLlmModel.GRYPHE_MYTHOMAX_L2_13B:ModelMetadata"
        },
        {
            "type": "ForStatement",
            "name": "",
            "range": [
                1119,
                1124
            ],
            "children": [
                {
                    "type": "VariableDeclaration",
                    "name": "model",
                    "range": [
                        1120,
                        1120
                    ],
                    "children": [],
                    "content": ","
                },
                {
                    "type": "Identifier",
                    "name": "LlmModel",
                    "range": [
                        1122,
                        1122
                    ],
                    "children": [],
                    "content": ")"
                }
            ],
            "content": "\"open_router\",4000),\n"
        },
        {
            "type": "IfStatement",
            "name": "",
            "range": [
                1125,
                1138
            ],
            "children": [
                {
                    "type": "BinaryExpression",
                    "name": "",
                    "range": [
                        1126,
                        1129
                    ],
                    "children": [
                        {
                            "type": "Identifier",
                            "name": "model",
                            "range": [
                                1126,
                                1126
                            ],
                            "children": [],
                            "content": "\n"
                        },
                        {
                            "type": "Identifier",
                            "name": "MODEL_METADATA",
                            "range": [
                                1129,
                                1129
                            ],
                            "children": [],
                            "content": "model"
                        }
                    ],
                    "content": "\n\nfor model"
                },
                {
                    "type": "RaiseStatement",
                    "name": "",
                    "range": [
                        1132,
                        1137
                    ],
                    "children": [
                        {
                            "type": "Identifier",
                            "name": "ValueError",
                            "range": [
                                1133,
                                1133
                            ],
                            "children": [],
                            "content": "\n"
                        },
                        {
                            "type": "TemplateLiteral",
                            "name": "",
                            "range": [
                                1135,
                                1136
                            ],
                            "children": [
                                {
                                    "type": "TemplateElement",
                                    "name": "",
                                    "range": [
                                        1136,
                                        1136
                                    ],
                                    "children": [],
                                    "content": "not"
                                }
                            ],
                            "content": "model not"
                        }
                    ],
                    "content": ":\nif model not in"
                }
            ],
            "content": "}\n\nfor model in LlmModel:\nif model not in MODEL_METADATA"
        },
        {
            "type": "ClassDecl",
            "name": "MessageRole",
            "range": [
                1140,
                1161
            ],
            "children": [
                {
                    "type": "EnumMember",
                    "name": "SYSTEM",
                    "range": [
                        1149,
                        1151
                    ],
                    "children": [
                        {
                            "type": "Literal",
                            "value": "\"system\"",
                            "range": [
                                1151,
                                1151
                            ],
                            "content": "MessageRole"
                        }
                    ],
                    "content": "\nclass MessageRole"
                },
                {
                    "type": "EnumMember",
                    "name": "USER",
                    "range": [
                        1153,
                        1155
                    ],
                    "children": [
                        {
                            "type": "Literal",
                            "value": "\"user\"",
                            "range": [
                                1155,
                                1155
                            ],
                            "content": "Enum"
                        }
                    ],
                    "content": "str,Enum"
                },
                {
                    "type": "EnumMember",
                    "name": "ASSISTANT",
                    "range": [
                        1157,
                        1159
                    ],
                    "children": [
                        {
                            "type": "Literal",
                            "value": "\"assistant\"",
                            "range": [
                                1159,
                                1159
                            ],
                            "content": "SYSTEM"
                        }
                    ],
                    "content": ":\nSYSTEM"
                }
            ],
            "content": "\nraise ValueError(f \"Missing MODEL_METADATA metadata for model: {model}\")\n\n\nclass MessageRole(str,Enum):\nSYSTEM=\"system\""
        },
        {
            "type": "ClassDecl",
            "name": "Message",
            "range": [
                1162,
                1177
            ],
            "children": [
                {
                    "type": "Inheritance",
                    "name": "BlockSchema",
                    "range": [
                        1164,
                        1166
                    ],
                    "children": [],
                    "content": "=\"user\"\n"
                },
                {
                    "type": "PropertyDecl",
                    "name": "role",
                    "range": [
                        1169,
                        1171
                    ],
                    "children": [
                        {
                            "type": "TypeAnnotation",
                            "name": "MessageRole",
                            "range": [
                                1171,
                                1171
                            ],
                            "children": [],
                            "content": "\n"
                        }
                    ],
                    "content": "\"assistant\"\n\n"
                },
                {
                    "type": "PropertyDecl",
                    "name": "content",
                    "range": [
                        1173,
                        1175
                    ],
                    "children": [
                        {
                            "type": "TypeAnnotation",
                            "name": "str",
                            "range": [
                                1175,
                                1175
                            ],
                            "children": [],
                            "content": "("
                        }
                    ],
                    "content": "class Message("
                }
            ],
            "content": "\nUSER=\"user\"\nASSISTANT=\"assistant\"\n\n\nclass Message(BlockSchema)"
        },
        {
            "type": "ClassDecl",
            "name": "AIStructuredResponseGeneratorBlock",
            "range": [
                1178,
                1184
            ],
            "children": [
                {
                    "type": "Inheritance",
                    "name": "Block",
                    "range": [
                        1180,
                        1182
                    ],
                    "children": [],
                    "content": "role:MessageRole"
                }
            ],
            "content": ":\nrole:MessageRole\ncontent"
        },
        {
            "type": "ClassDecl",
            "name": "Input",
            "range": [
                1185,
                1191
            ],
            "children": [
                {
                    "type": "Inheritance",
                    "name": "BlockSchema",
                    "range": [
                        1187,
                        1189
                    ],
                    "children": [],
                    "content": "\n\n\n"
                }
            ],
            "content": ":str\n\n\nclass AIStructuredResponseGeneratorBlock"
        },
        {
            "type": "VariableDecl",
            "name": "prompt",
            "range": [
                1192,
                1209
            ],
            "children": [
                {
                    "type": "TypeAnnotation",
                    "name": "str",
                    "range": [
                        1193,
                        1194
                    ],
                    "children": [],
                    "content": "Block)"
                },
                {
                    "type": "Assignment",
                    "name": "=",
                    "range": [
                        1195,
                        1196
                    ],
                    "children": [
                        {
                            "type": "CallExpression",
                            "name": "SchemaField",
                            "range": [
                                1196,
                                1209
                            ],
                            "children": [
                                {
                                    "type": "Argument",
                                    "name": "description",
                                    "range": [
                                        1199,
                                        1201
                                    ],
                                    "children": [],
                                    "content": "(BlockSchema)"
                                },
                                {
                                    "type": "Argument",
                                    "name": "placeholder",
                                    "range": [
                                        1204,
                                        1206
                                    ],
                                    "children": [],
                                    "content": "prompt:str"
                                }
                            ],
                            "content": "\nclass Input(BlockSchema):\nprompt:str=SchemaField("
                        }
                    ],
                    "content": ":\n"
                }
            ],
            "content": "(Block):\nclass Input(BlockSchema):\nprompt:str=SchemaField("
        },
        {
            "type": "VariableDecl",
            "name": "expected_format",
            "range": [
                1211,
                1230
            ],
            "children": [
                {
                    "type": "TypeAnnotation",
                    "name": "dict[str, str]",
                    "range": [
                        1212,
                        1218
                    ],
                    "children": [],
                    "content": "=\"The prompt to send to the language model.\",\nplaceholder=\"Enter your prompt here...\""
                },
                {
                    "type": "Assignment",
                    "name": "=",
                    "range": [
                        1219,
                        1220
                    ],
                    "children": [
                        {
                            "type": "CallExpression",
                            "name": "SchemaField",
                            "range": [
                                1220,
                                1230
                            ],
                            "children": [
                                {
                                    "type": "Argument",
                                    "name": "description",
                                    "range": [
                                        1223,
                                        1227
                                    ],
                                    "children": [],
                                    "content": "expected_format:dict[str"
                                }
                            ],
                            "content": "\n)\nexpected_format:dict[str,str]"
                        }
                    ],
                    "content": ",\n"
                }
            ],
            "content": "description=\"The prompt to send to the language model.\",\nplaceholder=\"Enter your prompt here...\",\n)\nexpected_format:dict[str,str]"
        },
        {
            "type": "VariableDecl",
            "name": "model",
            "range": [
                1232,
                1261
            ],
            "children": [
                {
                    "type": "TypeAnnotation",
                    "name": "LlmModel",
                    "range": [
                        1233,
                        1234
                    ],
                    "children": [],
                    "content": "(\n"
                },
                {
                    "type": "Assignment",
                    "name": "=",
                    "range": [
                        1235,
                        1236
                    ],
                    "children": [
                        {
                            "type": "CallExpression",
                            "name": "SchemaField",
                            "range": [
                                1236,
                                1261
                            ],
                            "children": [
                                {
                                    "type": "Argument",
                                    "name": "title",
                                    "range": [
                                        1239,
                                        1241
                                    ],
                                    "children": [],
                                    "content": "\"The keys should be the expected fields in the response, and the values should be the description of the field.\",\n"
                                },
                                {
                                    "type": "Argument",
                                    "name": "default",
                                    "range": [
                                        1244,
                                        1248
                                    ],
                                    "children": [],
                                    "content": "model:LlmModel=SchemaField"
                                },
                                {
                                    "type": "Argument",
                                    "name": "description",
                                    "range": [
                                        1251,
                                        1253
                                    ],
                                    "children": [],
                                    "content": "title=\"LLM Model\""
                                },
                                {
                                    "type": "Argument",
                                    "name": "advanced",
                                    "range": [
                                        1256,
                                        1258
                                    ],
                                    "children": [],
                                    "content": "default=LlmModel"
                                }
                            ],
                            "content": "=\"Expected format of the response. If provided, the response will be validated against this format. \"\n\"The keys should be the expected fields in the response, and the values should be the description of the field.\",\n)\nmodel:LlmModel=SchemaField(\ntitle=\"LLM Model\",\ndefault=LlmModel.GPT4_TURBO,"
                        }
                    ],
                    "content": "description="
                }
            ],
            "content": "SchemaField(\ndescription=\"Expected format of the response. If provided, the response will be validated against this format. \"\n\"The keys should be the expected fields in the response, and the values should be the description of the field.\",\n)\nmodel:LlmModel=SchemaField(\ntitle=\"LLM Model\",\ndefault=LlmModel.GPT4_TURBO,"
        },
        {
            "type": "VariableDecl",
            "name": "credentials",
            "range": [
                1263,
                1269
            ],
            "children": [
                {
                    "type": "TypeAnnotation",
                    "name": "AICredentials",
                    "range": [
                        1264,
                        1265
                    ],
                    "children": [],
                    "content": "=\"The language model to use for answering the prompt.\""
                },
                {
                    "type": "Assignment",
                    "name": "=",
                    "range": [
                        1266,
                        1267
                    ],
                    "children": [
                        {
                            "type": "CallExpression",
                            "name": "AICredentialsField",
                            "range": [
                                1267,
                                1269
                            ],
                            "children": [],
                            "content": "\nadvanced="
                        }
                    ],
                    "content": ",\n"
                }
            ],
            "content": "description=\"The language model to use for answering the prompt.\",\nadvanced="
        },
        {
            "type": "VariableDecl",
            "name": "sys_prompt",
            "range": [
                1271,
                1293
            ],
            "children": [
                {
                    "type": "TypeAnnotation",
                    "name": "str",
                    "range": [
                        1272,
                        1273
                    ],
                    "children": [],
                    "content": "\n)"
                },
                {
                    "type": "Assignment",
                    "name": "=",
                    "range": [
                        1274,
                        1275
                    ],
                    "children": [
                        {
                            "type": "CallExpression",
                            "name": "SchemaField",
                            "range": [
                                1275,
                                1293
                            ],
                            "children": [
                                {
                                    "type": "Argument",
                                    "name": "title",
                                    "range": [
                                        1278,
                                        1280
                                    ],
                                    "children": [],
                                    "content": "=AICredentialsField("
                                },
                                {
                                    "type": "Argument",
                                    "name": "default",
                                    "range": [
                                        1283,
                                        1285
                                    ],
                                    "children": [],
                                    "content": "sys_prompt:str"
                                },
                                {
                                    "type": "Argument",
                                    "name": "description",
                                    "range": [
                                        1288,
                                        1290
                                    ],
                                    "children": [],
                                    "content": "(\ntitle"
                                }
                            ],
                            "content": "credentials:AICredentials=AICredentialsField()\nsys_prompt:str=SchemaField(\ntitle=\"System Prompt\","
                        }
                    ],
                    "content": "\ncredentials"
                }
            ],
            "content": ",\n)\ncredentials:AICredentials=AICredentialsField()\nsys_prompt:str=SchemaField(\ntitle=\"System Prompt\","
        },
        {
            "type": "VariableDecl",
            "name": "conversation_history",
            "range": [
                1295,
                1316
            ],
            "children": [
                {
                    "type": "TypeAnnotation",
                    "name": "list[Message]",
                    "range": [
                        1296,
                        1300
                    ],
                    "children": [],
                    "content": "=\"\",\ndescription"
                },
                {
                    "type": "Assignment",
                    "name": "=",
                    "range": [
                        1301,
                        1302
                    ],
                    "children": [
                        {
                            "type": "CallExpression",
                            "name": "SchemaField",
                            "range": [
                                1302,
                                1316
                            ],
                            "children": [
                                {
                                    "type": "Argument",
                                    "name": "default",
                                    "range": [
                                        1305,
                                        1308
                                    ],
                                    "children": [],
                                    "content": ")\nconversation_history:"
                                },
                                {
                                    "type": "Argument",
                                    "name": "description",
                                    "range": [
                                        1311,
                                        1313
                                    ],
                                    "children": [],
                                    "content": "Message]="
                                }
                            ],
                            "content": "\"The system prompt to provide additional context to the model.\",\n)\nconversation_history:list[Message]=SchemaField(\n"
                        }
                    ],
                    "content": "=\"The system prompt to provide additional context to the model.\""
                }
            ],
            "content": "default=\"\",\ndescription=\"The system prompt to provide additional context to the model.\",\n)\nconversation_history:list[Message]=SchemaField(\n"
        },
        {
            "type": "VariableDecl",
            "name": "retry",
            "range": [
                1318,
                1340
            ],
            "children": [
                {
                    "type": "TypeAnnotation",
                    "name": "int",
                    "range": [
                        1319,
                        1320
                    ],
                    "children": [],
                    "content": "[]"
                },
                {
                    "type": "Assignment",
                    "name": "=",
                    "range": [
                        1321,
                        1322
                    ],
                    "children": [
                        {
                            "type": "CallExpression",
                            "name": "SchemaField",
                            "range": [
                                1322,
                                1340
                            ],
                            "children": [
                                {
                                    "type": "Argument",
                                    "name": "title",
                                    "range": [
                                        1325,
                                        1327
                                    ],
                                    "children": [],
                                    "content": "\"The conversation history to provide context for the prompt.\",\n"
                                },
                                {
                                    "type": "Argument",
                                    "name": "default",
                                    "range": [
                                        1330,
                                        1332
                                    ],
                                    "children": [],
                                    "content": "retry:int"
                                },
                                {
                                    "type": "Argument",
                                    "name": "description",
                                    "range": [
                                        1335,
                                        1337
                                    ],
                                    "children": [],
                                    "content": "(\ntitle"
                                }
                            ],
                            "content": "\ndescription=\"The conversation history to provide context for the prompt.\",\n)\nretry:int=SchemaField(\ntitle=\"Retry Count\","
                        }
                    ],
                    "content": ",\n"
                }
            ],
            "content": "=[],\ndescription=\"The conversation history to provide context for the prompt.\",\n)\nretry:int=SchemaField(\ntitle=\"Retry Count\","
        },
        {
            "type": "VariableDecl",
            "name": "prompt_values",
            "range": [
                1342,
                1367
            ],
            "children": [
                {
                    "type": "TypeAnnotation",
                    "name": "dict[str, str]",
                    "range": [
                        1343,
                        1348
                    ],
                    "children": [],
                    "content": "=3,\ndescription="
                },
                {
                    "type": "Assignment",
                    "name": "=",
                    "range": [
                        1349,
                        1350
                    ],
                    "children": [
                        {
                            "type": "CallExpression",
                            "name": "SchemaField",
                            "range": [
                                1350,
                                1367
                            ],
                            "children": [
                                {
                                    "type": "Argument",
                                    "name": "advanced",
                                    "range": [
                                        1354,
                                        1356
                                    ],
                                    "children": [],
                                    "content": "prompt_values:dict"
                                },
                                {
                                    "type": "Argument",
                                    "name": "default",
                                    "range": [
                                        1358,
                                        1360
                                    ],
                                    "children": [],
                                    "content": "str,str"
                                },
                                {
                                    "type": "Argument",
                                    "name": "description",
                                    "range": [
                                        1363,
                                        1365
                                    ],
                                    "children": [],
                                    "content": "SchemaField(\n"
                                }
                            ],
                            "content": ",\n)\nprompt_values:dict[str,str]=SchemaField(\nadvanced="
                        }
                    ],
                    "content": "\"Number of times to retry the LLM call if the response does not match the expected format.\","
                }
            ],
            "content": "default=3,\ndescription=\"Number of times to retry the LLM call if the response does not match the expected format.\",\n)\nprompt_values:dict[str,str]=SchemaField(\nadvanced="
        },
        {
            "type": "VariableDecl",
            "name": "max_tokens",
            "range": [
                1369,
                1393
            ],
            "children": [
                {
                    "type": "TypeAnnotation",
                    "name": "int | None",
                    "range": [
                        1370,
                        1373
                    ],
                    "children": [],
                    "content": "default={}"
                },
                {
                    "type": "Assignment",
                    "name": "=",
                    "range": [
                        1374,
                        1375
                    ],
                    "children": [
                        {
                            "type": "CallExpression",
                            "name": "SchemaField",
                            "range": [
                                1375,
                                1393
                            ],
                            "children": [
                                {
                                    "type": "Argument",
                                    "name": "advanced",
                                    "range": [
                                        1378,
                                        1380
                                    ],
                                    "children": [],
                                    "content": "\n)\n"
                                },
                                {
                                    "type": "Argument",
                                    "name": "default",
                                    "range": [
                                        1383,
                                        1385
                                    ],
                                    "children": [],
                                    "content": "int|None"
                                },
                                {
                                    "type": "Argument",
                                    "name": "description",
                                    "range": [
                                        1388,
                                        1390
                                    ],
                                    "children": [],
                                    "content": "(\nadvanced"
                                }
                            ],
                            "content": "description=\"Values used to fill in the prompt.\"\n)\nmax_tokens:int|None=SchemaField(\nadvanced=True,"
                        }
                    ],
                    "content": ",description"
                }
            ],
            "content": ",default={},description=\"Values used to fill in the prompt.\"\n)\nmax_tokens:int|None=SchemaField(\nadvanced=True,"
        },
        {
            "type": "VariableDecl",
            "name": "ollama_host",
            "range": [
                1396,
                1418
            ],
            "children": [
                {
                    "type": "TypeAnnotation",
                    "name": "str",
                    "range": [
                        1397,
                        1398
                    ],
                    "children": [],
                    "content": "None,"
                },
                {
                    "type": "Assignment",
                    "name": "=",
                    "range": [
                        1399,
                        1400
                    ],
                    "children": [
                        {
                            "type": "CallExpression",
                            "name": "SchemaField",
                            "range": [
                                1400,
                                1418
                            ],
                            "children": [
                                {
                                    "type": "Argument",
                                    "name": "advanced",
                                    "range": [
                                        1403,
                                        1405
                                    ],
                                    "children": [],
                                    "content": ",\n)"
                                },
                                {
                                    "type": "Argument",
                                    "name": "default",
                                    "range": [
                                        1408,
                                        1410
                                    ],
                                    "children": [],
                                    "content": "ollama_host:str"
                                },
                                {
                                    "type": "Argument",
                                    "name": "description",
                                    "range": [
                                        1413,
                                        1415
                                    ],
                                    "children": [],
                                    "content": "(\nadvanced"
                                }
                            ],
                            "content": "description=\"The maximum number of tokens to generate in the chat completion.\",\n)\n\nollama_host:str=SchemaField(\nadvanced=True,"
                        }
                    ],
                    "content": "\ndescription"
                }
            ],
            "content": "=None,\ndescription=\"The maximum number of tokens to generate in the chat completion.\",\n)\n\nollama_host:str=SchemaField(\nadvanced=True,"
        },
        {
            "type": "ClassDecl",
            "name": "Output",
            "range": [
                1421,
                1427
            ],
            "children": [
                {
                    "type": "Inheritance",
                    "name": "BlockSchema",
                    "range": [
                        1423,
                        1425
                    ],
                    "children": [],
                    "content": ",\ndescription"
                }
            ],
            "content": "=\"localhost:11434\",\ndescription=\"Ollama host for local  models\""
        },
        {
            "type": "VariableDecl",
            "name": "response",
            "range": [
                1428,
                1444
            ],
            "children": [
                {
                    "type": "TypeAnnotation",
                    "name": "dict[str, Any]",
                    "range": [
                        1429,
                        1434
                    ],
                    "children": [],
                    "content": "\n)\n\nclass Output"
                },
                {
                    "type": "Assignment",
                    "name": "=",
                    "range": [
                        1435,
                        1436
                    ],
                    "children": [
                        {
                            "type": "CallExpression",
                            "name": "SchemaField",
                            "range": [
                                1436,
                                1444
                            ],
                            "children": [
                                {
                                    "type": "Argument",
                                    "name": "description",
                                    "range": [
                                        1440,
                                        1442
                                    ],
                                    "children": [],
                                    "content": "response:dict"
                                }
                            ],
                            "content": "BlockSchema):\nresponse:dict[str"
                        }
                    ],
                    "content": "(BlockSchema"
                }
            ],
            "content": ",\n)\n\nclass Output(BlockSchema):\nresponse:dict[str"
        },
        {
            "type": "VariableDecl",
            "name": "error",
            "range": [
                1446,
                1455
            ],
            "children": [
                {
                    "type": "TypeAnnotation",
                    "name": "str",
                    "range": [
                        1447,
                        1448
                    ],
                    "children": [],
                    "content": "]="
                },
                {
                    "type": "Assignment",
                    "name": "=",
                    "range": [
                        1449,
                        1450
                    ],
                    "children": [
                        {
                            "type": "CallExpression",
                            "name": "SchemaField",
                            "range": [
                                1450,
                                1455
                            ],
                            "children": [
                                {
                                    "type": "Argument",
                                    "name": "description",
                                    "range": [
                                        1452,
                                        1454
                                    ],
                                    "children": [],
                                    "content": "description=\"The response object generated by the language model.\""
                                }
                            ],
                            "content": "(\ndescription=\"The response object generated by the language model.\"\n"
                        }
                    ],
                    "content": "SchemaField("
                }
            ],
            "content": "Any]=SchemaField(\ndescription=\"The response object generated by the language model.\"\n"
        },
        {
            "type": "FunctionDecl",
            "name": "__init__",
            "range": [
                1458,
                1618
            ],
            "children": [
                {
                    "type": "Parameter",
                    "name": "self",
                    "range": [
                        1461,
                        1462
                    ],
                    "children": [],
                    "content": "=SchemaField"
                },
                {
                    "type": "CallExpression",
                    "name": "super",
                    "range": [
                        1465,
                        1470
                    ],
                    "children": [],
                    "content": "=\"Error message if the API call failed.\")\n\ndef"
                },
                {
                    "type": "CallExpression",
                    "name": "__init__",
                    "range": [
                        1469,
                        1618
                    ],
                    "children": [
                        {
                            "type": "Argument",
                            "name": "id",
                            "range": [
                                1472,
                                1474
                            ],
                            "children": [],
                            "content": "(self)"
                        },
                        {
                            "type": "Argument",
                            "name": "description",
                            "range": [
                                1477,
                                1479
                            ],
                            "children": [],
                            "content": "super()"
                        },
                        {
                            "type": "Argument",
                            "name": "categories",
                            "range": [
                                1482,
                                1488
                            ],
                            "children": [],
                            "content": "(\nid=\"ed55ac19-356e-4243-a6cb-bc599e9b716f\",\n"
                        },
                        {
                            "type": "Argument",
                            "name": "input_schema",
                            "range": [
                                1491,
                                1495
                            ],
                            "children": [],
                            "content": "\"Call a Large Language Model (LLM) to generate formatted object based on the given prompt.\",\ncategories="
                        },
                        {
                            "type": "Argument",
                            "name": "output_schema",
                            "range": [
                                1498,
                                1502
                            ],
                            "children": [],
                            "content": ".AI},\n"
                        },
                        {
                            "type": "Argument",
                            "name": "test_input",
                            "range": [
                                1505,
                                1543
                            ],
                            "children": [],
                            "content": "AIStructuredResponseGeneratorBlock.Input,\noutput_schema=AIStructuredResponseGeneratorBlock.Output,\ntest_input={\n\"model\":LlmModel.GPT4_TURBO,\n\"credentials\":TEST_CREDENTIALS_INPUT,\n\"expected_format\":{\n\"key1\":\"value1\",\n\"key2\":"
                        },
                        {
                            "type": "Argument",
                            "name": "test_credentials",
                            "range": [
                                1546,
                                1548
                            ],
                            "children": [],
                            "content": "\n},"
                        },
                        {
                            "type": "Argument",
                            "name": "test_output",
                            "range": [
                                1551,
                                1565
                            ],
                            "children": [],
                            "content": ":\"User prompt\",\n},\ntest_credentials=TEST_CREDENTIALS,\ntest_output=("
                        },
                        {
                            "type": "Argument",
                            "name": "test_mock",
                            "range": [
                                1568,
                                1614
                            ],
                            "children": [],
                            "content": "{\"key1\":\"key1Value\",\"key2\":\"key2Value\"}),\ntest_mock={\n\"llm_call\":lambda*args,**kwargs:(\njson.dumps(\n{\n\"key1\":\"key1Value\",\n\"key2\":\"key2Value\",\n}\n"
                        }
                    ],
                    "content": "\ndef __init__(self):\nsuper().__init__(\nid=\"ed55ac19-356e-4243-a6cb-bc599e9b716f\",\ndescription=\"Call a Large Language Model (LLM) to generate formatted object based on the given prompt.\",\ncategories={BlockCategory.AI},\ninput_schema=AIStructuredResponseGeneratorBlock.Input,\noutput_schema=AIStructuredResponseGeneratorBlock.Output,\ntest_input={\n\"model\":LlmModel.GPT4_TURBO,\n\"credentials\":TEST_CREDENTIALS_INPUT,\n\"expected_format\":{\n\"key1\":\"value1\",\n\"key2\":\"value2\",\n},\n\"prompt\":\"User prompt\",\n},\ntest_credentials=TEST_CREDENTIALS,\ntest_output=(\"response\",{\"key1\":\"key1Value\",\"key2\":\"key2Value\"}),\ntest_mock={\n\"llm_call\":lambda*args,**kwargs:(\njson.dumps(\n{\n\"key1\":\"key1Value\",\n\"key2\":\"key2Value\",\n}\n),\n0"
                }
            ],
            "content": "error:str=SchemaField(description=\"Error message if the API call failed.\")\n\ndef __init__(self):\nsuper().__init__(\nid=\"ed55ac19-356e-4243-a6cb-bc599e9b716f\",\ndescription=\"Call a Large Language Model (LLM) to generate formatted object based on the given prompt.\",\ncategories={BlockCategory.AI},\ninput_schema=AIStructuredResponseGeneratorBlock.Input,\noutput_schema=AIStructuredResponseGeneratorBlock.Output,\ntest_input={\n\"model\":LlmModel.GPT4_TURBO,\n\"credentials\":TEST_CREDENTIALS_INPUT,\n\"expected_format\":{\n\"key1\":\"value1\",\n\"key2\":\"value2\",\n},\n\"prompt\":\"User prompt\",\n},\ntest_credentials=TEST_CREDENTIALS,\ntest_output=(\"response\",{\"key1\":\"key1Value\",\"key2\":\"key2Value\"}),\ntest_mock={\n\"llm_call\":lambda*args,**kwargs:(\njson.dumps(\n{\n\"key1\":\"key1Value\",\n\"key2\":\"key2Value\",\n}\n),\n0"
        },
        {
            "type": "FunctionDecl",
            "name": "llm_call",
            "range": [
                1623,
                2638
            ],
            "children": [
                {
                    "type": "Parameter",
                    "name": "credentials",
                    "range": [
                        1627,
                        1629
                    ],
                    "children": [],
                    "content": ",\n)"
                },
                {
                    "type": "Parameter",
                    "name": "llm_model",
                    "range": [
                        1632,
                        1634
                    ],
                    "children": [],
                    "content": "@staticmethod\n"
                },
                {
                    "type": "Parameter",
                    "name": "prompt",
                    "range": [
                        1637,
                        1642
                    ],
                    "children": [],
                    "content": "(\ncredentials:APIKeyCredentials,"
                },
                {
                    "type": "Parameter",
                    "name": "json_format",
                    "range": [
                        1645,
                        1647
                    ],
                    "children": [],
                    "content": ":LlmModel,"
                },
                {
                    "type": "Parameter",
                    "name": "max_tokens",
                    "range": [
                        1650,
                        1654
                    ],
                    "children": [],
                    "content": ":list[dict]"
                },
                {
                    "type": "Parameter",
                    "name": "ollama_host",
                    "range": [
                        1659,
                        1663
                    ],
                    "children": [],
                    "content": "bool,\nmax_tokens:"
                },
                {
                    "type": "ReturnType",
                    "name": "tuple[str, int, int]",
                    "range": [
                        1668,
                        1676
                    ],
                    "children": [],
                    "content": "None,\nollama_host:str=\"localhost:11434\","
                },
                {
                    "type": "Docstring",
                    "name": "",
                    "range": [
                        1679,
                        1681
                    ],
                    "children": [],
                    "content": "->tuple"
                },
                {
                    "type": "Assignment",
                    "name": "provider",
                    "range": [
                        1683,
                        1690
                    ],
                    "children": [],
                    "content": "str,int,int]:\n"
                },
                {
                    "type": "IfStatement",
                    "name": "provider == \"openai\"",
                    "range": [
                        1692,
                        1916
                    ],
                    "children": [
                        {
                            "type": "Assignment",
                            "name": "oai_client",
                            "range": [
                                1699,
                                1714
                            ],
                            "children": [],
                            "content": "metadata.provider\n\nif provider==\"openai\":\noai_client=openai."
                        },
                        {
                            "type": "Assignment",
                            "name": "response_format",
                            "range": [
                                1716,
                                1718
                            ],
                            "children": [],
                            "content": "(api_key="
                        },
                        {
                            "type": "IfStatement",
                            "name": "llm_model in [LlmModel.O1_MINI, LlmModel.O1_PREVIEW]",
                            "range": [
                                1721,
                                1814
                            ],
                            "children": [
                                {
                                    "type": "Assignment",
                                    "name": "sys_messages",
                                    "range": [
                                        1735,
                                        1754
                                    ],
                                    "children": [],
                                    "content": "in[LlmModel.O1_MINI,LlmModel.O1_PREVIEW]:\nsys_messages=[p[\"content\"]for"
                                },
                                {
                                    "type": "Assignment",
                                    "name": "usr_messages",
                                    "range": [
                                        1756,
                                        1775
                                    ],
                                    "children": [],
                                    "content": "in prompt if p[\"role\"]==\"system\"]\nusr_messages=[p[\"content\"]for"
                                },
                                {
                                    "type": "Assignment",
                                    "name": "prompt",
                                    "range": [
                                        1777,
                                        1813
                                    ],
                                    "children": [],
                                    "content": "in prompt if p[\"role\"]!=\"system\"]\nprompt=[\n{\"role\":\"user\",\"content\":\"\\n\".join(sys_messages)},\n{\"role\":\"user\","
                                }
                            ],
                            "content": "api_key.get_secret_value())\nresponse_format=None\n\nif llm_model in[LlmModel.O1_MINI,LlmModel.O1_PREVIEW]:\nsys_messages=[p[\"content\"]for p in prompt if p[\"role\"]==\"system\"]\nusr_messages=[p[\"content\"]for p in prompt if p[\"role\"]!=\"system\"]\nprompt=[\n{\"role\":\"user\",\"content\":\"\\n\".join(sys_messages)},\n{\"role\":\"user\",\"content\""
                        },
                        {
                            "type": "IfStatement",
                            "name": "json_format",
                            "range": [
                                1816,
                                1826
                            ],
                            "children": [
                                {
                                    "type": "Assignment",
                                    "name": "response_format",
                                    "range": [
                                        1819,
                                        1825
                                    ],
                                    "children": [],
                                    "content": "(usr_messages)},\n]"
                                }
                            ],
                            "content": "\"\\n\".join(usr_messages)},\n]\n"
                        },
                        {
                            "type": "Assignment",
                            "name": "response",
                            "range": [
                                1828,
                                1869
                            ],
                            "children": [],
                            "content": "json_format:\nresponse_format={\"type\":\"json_object\"}\n\nresponse=oai_client.chat.completions.create(\nmodel=llm_model.value,\nmessages=prompt,#type:ignore\nresponse_format=response_format"
                        },
                        {
                            "type": "ReturnStatement",
                            "name": "return",
                            "range": [
                                1872,
                                1915
                            ],
                            "children": [],
                            "content": "type:ignore\nmax_completion_tokens=max_tokens,\n)\n\nreturn(\nresponse.choices[0].message.content or\"\",\nresponse.usage.prompt_tokens if response.usage else0,\nresponse."
                        }
                    ],
                    "content": "\" \\n         Args: \\n             api_key: API key for the LLM provider. \\n             llm_model: The LLM model to use. \\n             prompt: The prompt to send to the LLM. \\n             json_format: Whether the response should be in JSON format. \\n             max_tokens: The maximum number of tokens to generate in the chat completion. \\n             ollama_host: The host for ollama to use \\n  \\n         Returns: \\n             The response from the LLM. \\n             The number of tokens used in the prompt. \\n             The number of tokens used in the completion. \\n         \"\"\"\nprovider=llm_model.metadata.provider\n\nif provider==\"openai\":\noai_client=openai.OpenAI(api_key=credentials.api_key.get_secret_value())\nresponse_format=None\n\nif llm_model in[LlmModel.O1_MINI,LlmModel.O1_PREVIEW]:\nsys_messages=[p[\"content\"]for p in prompt if p[\"role\"]==\"system\"]\nusr_messages=[p[\"content\"]for p in prompt if p[\"role\"]!=\"system\"]\nprompt=[\n{\"role\":\"user\",\"content\":\"\\n\".join(sys_messages)},\n{\"role\":\"user\",\"content\":\"\\n\".join(usr_messages)},\n]\nelif json_format:\nresponse_format={\"type\":\"json_object\"}\n\nresponse=oai_client.chat.completions.create(\nmodel=llm_model.value,\nmessages=prompt,#type:ignore\nresponse_format=response_format,#type:ignore\nmax_completion_tokens=max_tokens,\n)\n\nreturn(\nresponse.choices[0].message.content or\"\",\nresponse.usage.prompt_tokens if response.usage else0,\nresponse.usage"
                },
                {
                    "type": "IfStatement",
                    "name": "provider == \"anthropic\"",
                    "range": [
                        1918,
                        2187
                    ],
                    "children": [
                        {
                            "type": "Assignment",
                            "name": "system_messages",
                            "range": [
                                1924,
                                1943
                            ],
                            "children": [],
                            "content": "0,\n)\nelif provider==\"anthropic\":\nsystem_messages=[p[\"content\"]for"
                        },
                        {
                            "type": "Assignment",
                            "name": "sysprompt",
                            "range": [
                                1945,
                                1952
                            ],
                            "children": [],
                            "content": "in prompt if p[\"role\"]="
                        },
                        {
                            "type": "Assignment",
                            "name": "messages",
                            "range": [
                                1955,
                                2056
                            ],
                            "children": [],
                            "content": "]\nsysprompt=\" \".join(system_messages)\n\nmessages=[]\nlast_role=None\nfor p in prompt:\nif p[\"role\"]in[\"user\",\"assistant\"]:\nif p[\"role\"]!=last_role:\nmessages.append({\"role\":p[\"role\"],\"content\":p[\"content\"]})\nlast_role=p[\"role\"]\nelse:\n#If the role is the same as the last one,combine the content\nmessages[-1]"
                        },
                        {
                            "type": "Assignment",
                            "name": "client",
                            "range": [
                                2058,
                                2073
                            ],
                            "children": [],
                            "content": "\"content\"]+=\"\\n\"+p[\"content\"]\n\nclient=anthropic."
                        },
                        {
                            "type": "TryStatement",
                            "name": "try",
                            "range": [
                                2075,
                                2187
                            ],
                            "children": [
                                {
                                    "type": "Assignment",
                                    "name": "resp",
                                    "range": [
                                        2078,
                                        2111
                                    ],
                                    "children": [],
                                    "content": "credentials.api_key.get_secret_value())\ntry:\nresp=client.messages.create(\nmodel=llm_model.value,\nsystem=sysprompt,\nmessages"
                                },
                                {
                                    "type": "IfStatement",
                                    "name": "not resp.content",
                                    "range": [
                                        2114,
                                        2126
                                    ],
                                    "children": [
                                        {
                                            "type": "RaiseStatement",
                                            "name": "raise",
                                            "range": [
                                                2121,
                                                2125
                                            ],
                                            "children": [],
                                            "content": ",\n)\n\n"
                                        }
                                    ],
                                    "content": ",\nmax_tokens=max_tokens or8192,\n)\n\nif"
                                },
                                {
                                    "type": "ReturnStatement",
                                    "name": "return",
                                    "range": [
                                        2128,
                                        2186
                                    ],
                                    "children": [],
                                    "content": "resp.content:\nraise ValueError(\"No content returned from Anthropic.\")\n\nreturn(\n(\nresp.content[0].name\nif isinstance(resp.content[0],anthropic.types.ToolUseBlock)\nelse resp.content[0].text\n),\nresp.usage"
                                }
                            ],
                            "content": "(api_key=credentials.api_key.get_secret_value())\ntry:\nresp=client.messages.create(\nmodel=llm_model.value,\nsystem=sysprompt,\nmessages=messages,\nmax_tokens=max_tokens or8192,\n)\n\nif not resp.content:\nraise ValueError(\"No content returned from Anthropic.\")\n\nreturn(\n(\nresp.content[0].name\nif isinstance(resp.content[0],anthropic.types.ToolUseBlock)\nelse resp.content[0].text\n),\nresp.usage."
                        },
                        {
                            "type": "ExceptStatement",
                            "name": "except anthropic.APIError as e",
                            "range": [
                                2188,
                                2213
                            ],
                            "children": [
                                {
                                    "type": "Assignment",
                                    "name": "error_message",
                                    "range": [
                                        2196,
                                        2200
                                    ],
                                    "children": [],
                                    "content": ",\n)\nexcept"
                                },
                                {
                                    "type": "CallExpression",
                                    "name": "logger.error",
                                    "range": [
                                        2201,
                                        2207
                                    ],
                                    "children": [],
                                    "content": "anthropic.APIError as e:\n"
                                },
                                {
                                    "type": "RaiseStatement",
                                    "name": "raise",
                                    "range": [
                                        2208,
                                        2212
                                    ],
                                    "children": [],
                                    "content": "error_message=f \"Anthropic API error: {str(e)}\"\n"
                                }
                            ],
                            "content": "input_tokens,\nresp.usage.output_tokens,\n)\nexcept anthropic.APIError as e:\nerror_message=f \"Anthropic API error: {str(e)}\"\nlogger"
                        }
                    ],
                    "content": "completion_tokens if response.usage else0,\n)\nelif provider==\"anthropic\":\nsystem_messages=[p[\"content\"]for p in prompt if p[\"role\"]==\"system\"]\nsysprompt=\" \".join(system_messages)\n\nmessages=[]\nlast_role=None\nfor p in prompt:\nif p[\"role\"]in[\"user\",\"assistant\"]:\nif p[\"role\"]!=last_role:\nmessages.append({\"role\":p[\"role\"],\"content\":p[\"content\"]})\nlast_role=p[\"role\"]\nelse:\n#If the role is the same as the last one,combine the content\nmessages[-1][\"content\"]+=\"\\n\"+p[\"content\"]\n\nclient=anthropic.Anthropic(api_key=credentials.api_key.get_secret_value())\ntry:\nresp=client.messages.create(\nmodel=llm_model.value,\nsystem=sysprompt,\nmessages=messages,\nmax_tokens=max_tokens or8192,\n)\n\nif not resp.content:\nraise ValueError(\"No content returned from Anthropic.\")\n\nreturn(\n(\nresp.content[0].name\nif isinstance(resp.content[0],anthropic.types.ToolUseBlock)\nelse resp.content[0].text\n),\nresp.usage."
                },
                {
                    "type": "IfStatement",
                    "name": "provider == \"groq\"",
                    "range": [
                        2215,
                        2335
                    ],
                    "children": [
                        {
                            "type": "Assignment",
                            "name": "client",
                            "range": [
                                2221,
                                2234
                            ],
                            "children": [],
                            "content": "ValueError(error_message)\nelif provider==\"groq\":\nclient="
                        },
                        {
                            "type": "Assignment",
                            "name": "response_format",
                            "range": [
                                2236,
                                2246
                            ],
                            "children": [],
                            "content": "(api_key=credentials.api_key.get_secret_value())"
                        },
                        {
                            "type": "Assignment",
                            "name": "response",
                            "range": [
                                2248,
                                2289
                            ],
                            "children": [],
                            "content": "response_format={\"type\":\"json_object\"}if json_format else None\nresponse=client.chat.completions.create(\nmodel=llm_model.value,\nmessages=prompt,#type:ignore\nresponse_format=response_format"
                        },
                        {
                            "type": "ReturnStatement",
                            "name": "return",
                            "range": [
                                2291,
                                2334
                            ],
                            "children": [],
                            "content": "#type:ignore\nmax_tokens=max_tokens,\n)\nreturn(\nresponse.choices[0].message.content or\"\",\nresponse.usage.prompt_tokens if response.usage else0,\nresponse."
                        }
                    ],
                    "content": "error(error_message)\nraise ValueError(error_message)\nelif provider==\"groq\":\nclient=Groq(api_key=credentials.api_key.get_secret_value())\nresponse_format={\"type\":\"json_object\"}if json_format else None\nresponse=client.chat.completions.create(\nmodel=llm_model.value,\nmessages=prompt,#type:ignore\nresponse_format=response_format,#type:ignore\nmax_tokens=max_tokens,\n)\nreturn(\nresponse.choices[0].message.content or\"\",\nresponse.usage.prompt_tokens if response.usage else0,\nresponse.usage"
                },
                {
                    "type": "IfStatement",
                    "name": "provider == \"ollama\"",
                    "range": [
                        2337,
                        2457
                    ],
                    "children": [
                        {
                            "type": "Assignment",
                            "name": "client",
                            "range": [
                                2343,
                                2352
                            ],
                            "children": [],
                            "content": "0,\n)\nelif provider==\"ollama\""
                        },
                        {
                            "type": "Assignment",
                            "name": "sys_messages",
                            "range": [
                                2354,
                                2373
                            ],
                            "children": [],
                            "content": "\nclient=ollama.Client(host=ollama_host)\nsys_messages=[p[\"content\"]for"
                        },
                        {
                            "type": "Assignment",
                            "name": "usr_messages",
                            "range": [
                                2375,
                                2394
                            ],
                            "children": [],
                            "content": "in prompt if p[\"role\"]==\"system\"]\nusr_messages=[p[\"content\"]for"
                        },
                        {
                            "type": "Assignment",
                            "name": "response",
                            "range": [
                                2396,
                                2421
                            ],
                            "children": [],
                            "content": "in prompt if p[\"role\"]!=\"system\"]\nresponse=client.generate(\nmodel=llm_model.value,\n"
                        },
                        {
                            "type": "ReturnStatement",
                            "name": "return",
                            "range": [
                                2423,
                                2456
                            ],
                            "children": [],
                            "content": "=f \"{sys_messages}\\n\\n{usr_messages}\",\nstream=False,\n)\nreturn(\nresponse.get(\"response\")or\"\",\nresponse.get(\"prompt_eval_count\")or0,"
                        }
                    ],
                    "content": "completion_tokens if response.usage else0,\n)\nelif provider==\"ollama\":\nclient=ollama.Client(host=ollama_host)\nsys_messages=[p[\"content\"]for p in prompt if p[\"role\"]==\"system\"]\nusr_messages=[p[\"content\"]for p in prompt if p[\"role\"]!=\"system\"]\nresponse=client.generate(\nmodel=llm_model.value,\nprompt=f \"{sys_messages}\\n\\n{usr_messages}\",\nstream=False,\n)\nreturn(\nresponse.get(\"response\")or\"\",\nresponse.get(\"prompt_eval_count\")or0,\n"
                },
                {
                    "type": "IfStatement",
                    "name": "provider == \"open_router\"",
                    "range": [
                        2459,
                        2627
                    ],
                    "children": [
                        {
                            "type": "Assignment",
                            "name": "client",
                            "range": [
                                2465,
                                2488
                            ],
                            "children": [],
                            "content": "0,\n)\nelif provider==\"open_router\":\nclient=openai.OpenAI(\nbase_url=\"https://openrouter.ai/api/v1\",\n"
                        },
                        {
                            "type": "Assignment",
                            "name": "response",
                            "range": [
                                2491,
                                2540
                            ],
                            "children": [],
                            "content": "credentials.api_key.get_secret_value(),\n)\n\nresponse=client.chat.completions.create(\nextra_headers={\n\"HTTP-Referer\":\"https://agpt.co\",\n\"X-Title\":\"AutoGPT\",\n},\nmodel=llm_model.value,\nmessages=prompt"
                        },
                        {
                            "type": "IfStatement",
                            "name": "not response.choices",
                            "range": [
                                2543,
                                2581
                            ],
                            "children": [
                                {
                                    "type": "IfStatement",
                                    "name": "response",
                                    "range": [
                                        2556,
                                        2572
                                    ],
                                    "children": [
                                        {
                                            "type": "RaiseStatement",
                                            "name": "raise",
                                            "range": [
                                                2566,
                                                2571
                                            ],
                                            "children": [],
                                            "content": "the conversation.\" \\n         ) \\n         error: str = SchemaField(description=\" Error message"
                                        }
                                    ],
                                    "content": "If there 's no response, raise an error \\n             if not response.choices: \\n                 if response: \\n                     raise ValueError(f\"OpenRouter error: {response}\") \\n                 else: \\n                     raise ValueError(\"No response from OpenRouter.\") \\n  \\n             return ( \\n                 response.choices[0].message.content or \"\", \\n                 response.usage.prompt_tokens if response.usage else 0, \\n                 response.usage.completion_tokens if response.usage else 0, \\n             ) \\n         else: \\n             raise ValueError(f\"Unsupported LLM provider: {provider}\") \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         logger.debug(f\"Calling LLM with input data: {input_data}\") \\n         prompt = [p.model_dump() for p in input_data.conversation_history] \\n  \\n         def trim_prompt(s: str) -> str: \\n             lines = s.strip().split(\"\\n\") \\n             return \"\\n\".join([line.strip().lstrip(\"|\") for line in lines]) \\n  \\n         values = input_data.prompt_values \\n         if values: \\n             input_data.prompt = input_data.prompt.format(**values) \\n             input_data.sys_prompt = input_data.sys_prompt.format(**values) \\n  \\n         if input_data.sys_prompt: \\n             prompt.append({\"role\": \"system\", \"content\": input_data.sys_prompt}) \\n  \\n         if input_data.expected_format: \\n             expected_format = [ \\n                 f' \"{k}\":\"{v}\" ' for k, v in input_data.expected_format.items() \\n             ] \\n             format_prompt = \",\\n  \".join(expected_format) \\n             sys_prompt = trim_prompt( \\n                 f\"\"\" \\n                   |Reply strictly only in the following JSON format: \\n                   |{{ \\n                   |  {format_prompt} \\n                   |}} \\n                 \"\"\" \\n             ) \\n             prompt.append({\"role\": \"system\", \"content\": sys_prompt}) \\n  \\n         if input_data.prompt: \\n             prompt.append({\"role\": \"user\", \"content\": input_data.prompt}) \\n  \\n         def parse_response(resp: str) -> tuple[dict[str, Any], str | None]: \\n             try: \\n                 parsed = json.loads(resp) \\n                 if not isinstance(parsed, dict): \\n                     return {}, f\"Expected a dictionary, but got {type(parsed)}\" \\n                 miss_keys = set(input_data.expected_format.keys()) - set(parsed.keys()) \\n                 if miss_keys: \\n                     return parsed, f\"Missing keys: {miss_keys}\" \\n                 return parsed, None \\n             except JSONDecodeError as e: \\n                 return {}, f\"JSON decode error: {e}\" \\n  \\n         logger.info(f\"LLM request: {prompt}\") \\n         retry_prompt = \"\" \\n         llm_model = input_data.model \\n  \\n         for retry_count in range(input_data.retry): \\n             try: \\n                 response_text, input_token, output_token = self.llm_call( \\n                     credentials=credentials, \\n                     llm_model=llm_model, \\n                     prompt=prompt, \\n                     json_format=bool(input_data.expected_format), \\n                     ollama_host=input_data.ollama_host, \\n                     max_tokens=input_data.max_tokens, \\n                 ) \\n                 self.merge_stats( \\n                     { \\n                         \"input_token_count\": input_token, \\n                         \"output_token_count\": output_token, \\n                     } \\n                 ) \\n                 logger.info(f\"LLM attempt-{retry_count} response: {response_text}\") \\n  \\n                 if input_data.expected_format: \\n                     parsed_dict, parsed_error = parse_response(response_text) \\n                     if not parsed_error: \\n                         yield \"response\", { \\n                             k: ( \\n                                 json.loads(v) \\n                                 if isinstance(v, str) \\n                                 and v.startswith(\"[\") \\n                                 and v.endswith(\"]\") \\n                                 else (\", \".join(v) if isinstance(v, list) else v) \\n                             ) \\n                             for k, v in parsed_dict.items() \\n                         } \\n                         return \\n                 else: \\n                     yield \"response\", {\"response\": response_text} \\n                     return \\n  \\n                 retry_prompt = trim_prompt( \\n                     f\"\"\" \\n                   |This is your previous error response: \\n                   |-- \\n                   |{response_text} \\n                   |-- \\n                   | \\n                   |And this is the error: \\n                   |-- \\n                   |{parsed_error} \\n                   |-- \\n                 \"\"\" \\n                 ) \\n                 prompt.append({\"role\": \"user\", \"content\": retry_prompt}) \\n             except Exception as e: \\n                 logger.exception(f\"Error calling LLM: {e}\") \\n                 retry_prompt = f\"Error calling LLM: {e}\" \\n             finally: \\n                 self.merge_stats( \\n                     { \\n                         \"llm_call_count\": retry_count + 1, \\n                         \"llm_retry_count\": retry_count, \\n                     } \\n                 ) \\n  \\n         raise RuntimeError(retry_prompt) \\n  \\n  \\n class AITextGeneratorBlock(Block): \\n     class Input(BlockSchema): \\n         prompt: str = SchemaField( \\n             description=\"The prompt to send to the language model. You can use any of the {keys} from Prompt Values to fill in the prompt with values from the prompt values dictionary by putting them in curly braces.\", \\n             placeholder=\"Enter your prompt here...\", \\n         ) \\n         model: LlmModel = SchemaField( \\n             title=\"LLM Model\", \\n             default=LlmModel.GPT4_TURBO, \\n             description=\"The language model to use for answering the prompt.\", \\n             advanced=False, \\n         ) \\n         credentials: AICredentials = AICredentialsField() \\n         sys_prompt: str = SchemaField( \\n             title=\"System Prompt\", \\n             default=\"\", \\n             description=\"The system prompt to provide additional context to the model.\", \\n         ) \\n         retry: int = SchemaField( \\n             title=\"Retry Count\", \\n             default=3, \\n             description=\"Number of times to retry the LLM call if the response does not match the expected format.\", \\n         ) \\n         prompt_values: dict[str, str] = SchemaField( \\n             advanced=False, default={}, description=\"Values used to fill in the prompt.\" \\n         ) \\n         ollama_host: str = SchemaField( \\n             advanced=True, \\n             default=\"localhost:11434\", \\n             description=\"Ollama host for local  models\", \\n         ) \\n         max_tokens: int | None = SchemaField( \\n             advanced=True, \\n             default=None, \\n             description=\"The maximum number of tokens to generate in the chat completion.\", \\n         ) \\n  \\n     class Output(BlockSchema): \\n         response: str = SchemaField( \\n             description=\"The response generated by the language model.\" \\n         ) \\n         error: str = SchemaField(description=\"Error message if the API call failed.\") \\n  \\n     def __init__(self): \\n         super().__init__( \\n             id=\"1f292d4a-41a4-4977-9684-7c8d560b9f91\", \\n             description=\"Call a Large Language Model (LLM) to generate a string based on the given prompt.\", \\n             categories={BlockCategory.AI}, \\n             input_schema=AITextGeneratorBlock.Input, \\n             output_schema=AITextGeneratorBlock.Output, \\n             test_input={ \\n                 \"prompt\": \"User prompt\", \\n                 \"credentials\": TEST_CREDENTIALS_INPUT, \\n             }, \\n             test_credentials=TEST_CREDENTIALS, \\n             test_output=(\"response\", \"Response text\"), \\n             test_mock={\"llm_call\": lambda *args, **kwargs: \"Response text\"}, \\n         ) \\n  \\n     def llm_call( \\n         self, \\n         input_data: AIStructuredResponseGeneratorBlock.Input, \\n         credentials: APIKeyCredentials, \\n     ) -> str: \\n         block = AIStructuredResponseGeneratorBlock() \\n         response = block.run_once(input_data, \"response\", credentials=credentials) \\n         self.merge_stats(block.execution_stats) \\n         return response[\"response\"] \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         object_input_data = AIStructuredResponseGeneratorBlock.Input( \\n             **{attr: getattr(input_data, attr) for attr in input_data.model_fields}, \\n             expected_format={}, \\n         ) \\n         yield \"response\", self.llm_call(object_input_data, credentials) \\n  \\n  \\n class SummaryStyle(Enum): \\n     CONCISE = \"concise\" \\n     DETAILED = \"detailed\" \\n     BULLET_POINTS = \"bullet points\" \\n     NUMBERED_LIST = \"numbered list\" \\n  \\n  \\n class AITextSummarizerBlock(Block): \\n     class Input(BlockSchema): \\n         text: str = SchemaField( \\n             description=\"The text to summarize.\", \\n             placeholder=\"Enter the text to summarize here...\", \\n         ) \\n         model: LlmModel = SchemaField( \\n             title=\"LLM Model\", \\n             default=LlmModel.GPT4_TURBO, \\n             description=\"The language model to use for summarizing the text.\", \\n         ) \\n         focus: str = SchemaField( \\n             title=\"Focus\", \\n             default=\"general information\", \\n             description=\"The topic to focus on in the summary\", \\n         ) \\n         style: SummaryStyle = SchemaField( \\n             title=\"Summary Style\", \\n             default=SummaryStyle.CONCISE, \\n             description=\"The style of the summary to generate.\", \\n         ) \\n         credentials: AICredentials = AICredentialsField() \\n         # TODO: Make this dynamic \\n         max_tokens: int = SchemaField( \\n             title=\"Max Tokens\", \\n             default=4096, \\n             description=\"The maximum number of tokens to generate in the chat completion.\", \\n             ge=1, \\n         ) \\n         chunk_overlap: int = SchemaField( \\n             title=\"Chunk Overlap\", \\n             default=100, \\n             description=\"The number of overlapping tokens between chunks to maintain context.\", \\n             ge=0, \\n         ) \\n         ollama_host: str = SchemaField( \\n             advanced=True, \\n             default=\"localhost:11434\", \\n             description=\"Ollama host for local  models\", \\n         ) \\n  \\n     class Output(BlockSchema): \\n         summary: str = SchemaField(description=\"The final summary of the text.\") \\n         error: str = SchemaField(description=\"Error message if the API call failed.\") \\n  \\n     def __init__(self): \\n         super().__init__( \\n             id=\"a0a69be1-4528-491c-a85a-a4ab6873e3f0\", \\n             description=\"Utilize a Large Language Model (LLM) to summarize a long text.\", \\n             categories={BlockCategory.AI, BlockCategory.TEXT}, \\n             input_schema=AITextSummarizerBlock.Input, \\n             output_schema=AITextSummarizerBlock.Output, \\n             test_input={ \\n                 \"text\": \"Lorem ipsum...\" * 100, \\n                 \"credentials\": TEST_CREDENTIALS_INPUT, \\n             }, \\n             test_credentials=TEST_CREDENTIALS, \\n             test_output=(\"summary\", \"Final summary of a long text\"), \\n             test_mock={ \\n                 \"llm_call\": lambda input_data, credentials: ( \\n                     {\"final_summary\": \"Final summary of a long text\"} \\n                     if \"final_summary\" in input_data.expected_format \\n                     else {\"summary\": \"Summary of a chunk of text\"} \\n                 ) \\n             }, \\n         ) \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         for output in self._run(input_data, credentials): \\n             yield output \\n  \\n     def _run(self, input_data: Input, credentials: APIKeyCredentials) -> BlockOutput: \\n         chunks = self._split_text( \\n             input_data.text, input_data.max_tokens, input_data.chunk_overlap \\n         ) \\n         summaries = [] \\n  \\n         for chunk in chunks: \\n             chunk_summary = self._summarize_chunk(chunk, input_data, credentials) \\n             summaries.append(chunk_summary) \\n  \\n         final_summary = self._combine_summaries(summaries, input_data, credentials) \\n         yield \"summary\", final_summary \\n  \\n     @staticmethod \\n     def _split_text(text: str, max_tokens: int, overlap: int) -> list[str]: \\n         words = text.split() \\n         chunks = [] \\n         chunk_size = max_tokens - overlap \\n  \\n         for i in range(0, len(words), chunk_size): \\n             chunk = \" \".join(words[i : i + max_tokens]) \\n             chunks.append(chunk) \\n  \\n         return chunks \\n  \\n     def llm_call( \\n         self, \\n         input_data: AIStructuredResponseGeneratorBlock.Input, \\n         credentials: APIKeyCredentials, \\n     ) -> dict: \\n         block = AIStructuredResponseGeneratorBlock() \\n         response = block.run_once(input_data, \"response\", credentials=credentials) \\n         self.merge_stats(block.execution_stats) \\n         return response \\n  \\n     def _summarize_chunk( \\n         self, chunk: str, input_data: Input, credentials: APIKeyCredentials \\n     ) -> str: \\n         prompt = f\"Summarize the following text in a {input_data.style} form. Focus your summary on the topic of `{input_data.focus}` if present, otherwise just provide a general summary:\\n\\n```{chunk}```\" \\n  \\n         llm_response = self.llm_call( \\n             AIStructuredResponseGeneratorBlock.Input( \\n                 prompt=prompt, \\n                 credentials=input_data.credentials, \\n                 model=input_data.model, \\n                 expected_format={\"summary\": \"The summary of the given text.\"}, \\n             ), \\n             credentials=credentials, \\n         ) \\n  \\n         return llm_response[\"summary\"] \\n  \\n     def _combine_summaries( \\n         self, summaries: list[str], input_data: Input, credentials: APIKeyCredentials \\n     ) -> str: \\n         combined_text = \"\\n\\n\".join(summaries) \\n  \\n         if len(combined_text.split()) <= input_data.max_tokens: \\n             prompt = f\"Provide a final summary of the following section summaries in a {input_data.style} form, focus your summary on the topic of `{input_data.focus}` if present:\\n\\n ```{combined_text}```\\n\\n Just respond with the final_summary in the format specified.\" \\n  \\n             llm_response = self.llm_call( \\n                 AIStructuredResponseGeneratorBlock.Input( \\n                     prompt=prompt, \\n                     credentials=input_data.credentials, \\n                     model=input_data.model, \\n                     expected_format={ \\n                         \"final_summary\": \"The final summary of all provided summaries.\" \\n                     }, \\n                 ), \\n                 credentials=credentials, \\n             ) \\n  \\n             return llm_response[\"final_summary\"] \\n         else: \\n             # If combined summaries are still too long, recursively summarize \\n             return self._run( \\n                 AITextSummarizerBlock.Input( \\n                     text=combined_text, \\n                     credentials=input_data.credentials, \\n                     model=input_data.model, \\n                     max_tokens=input_data.max_tokens, \\n                     chunk_overlap=input_data.chunk_overlap, \\n                 ), \\n                 credentials=credentials, \\n             ).send(None)[ \\n                 1 \\n             ]  # Get the first yielded value \\n  \\n  \\n class AIConversationBlock(Block): \\n     class Input(BlockSchema): \\n         messages: List[Message] = SchemaField( \\n             description=\"List of messages in the conversation.\", min_length=1 \\n         ) \\n         model: LlmModel = SchemaField( \\n             title=\"LLM Model\", \\n             default=LlmModel.GPT4_TURBO, \\n             description=\"The language model to use for the conversation.\", \\n         ) \\n         credentials: AICredentials = AICredentialsField() \\n         max_tokens: int | None = SchemaField( \\n             advanced=True, \\n             default=None, \\n             description=\"The maximum number of tokens to generate in the chat completion.\", \\n         ) \\n         ollama_host: str = SchemaField( \\n             advanced=True, \\n             default=\"localhost:11434\", \\n             description=\"Ollama host for local  models\", \\n         ) \\n  \\n     class Output(BlockSchema): \\n         response: str = SchemaField( \\n             description=\"The model' s response to the conversation.\" \\n         ) \\n         error: str = SchemaField(description=\" Error message if"
                                },
                                {
                                    "type": "ElseStatement",
                                    "name": "else",
                                    "range": [
                                        2573,
                                        2580
                                    ],
                                    "children": [
                                        {
                                            "type": "RaiseStatement",
                                            "name": "raise",
                                            "range": [
                                                2576,
                                                2579
                                            ],
                                            "children": [],
                                            "content": "failed.\") \\n  \\n     def __init__(self): \\n         super().__init__( \\n             id=\"32"
                                        }
                                    ],
                                    "content": "the API call failed.\") \\n  \\n     def __init__(self): \\n         super().__init__( \\n             id=\"32a87eab"
                                }
                            ],
                            "content": "type:ignore\nmax_tokens=max_tokens,\n)\n\n#If there 's no response, raise an error \\n             if not response.choices: \\n                 if response: \\n                     raise ValueError(f\"OpenRouter error: {response}\") \\n                 else: \\n                     raise ValueError(\"No response from OpenRouter.\") \\n  \\n             return ( \\n                 response.choices[0].message.content or \"\", \\n                 response.usage.prompt_tokens if response.usage else 0, \\n                 response.usage.completion_tokens if response.usage else 0, \\n             ) \\n         else: \\n             raise ValueError(f\"Unsupported LLM provider: {provider}\") \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         logger.debug(f\"Calling LLM with input data: {input_data}\") \\n         prompt = [p.model_dump() for p in input_data.conversation_history] \\n  \\n         def trim_prompt(s: str) -> str: \\n             lines = s.strip().split(\"\\n\") \\n             return \"\\n\".join([line.strip().lstrip(\"|\") for line in lines]) \\n  \\n         values = input_data.prompt_values \\n         if values: \\n             input_data.prompt = input_data.prompt.format(**values) \\n             input_data.sys_prompt = input_data.sys_prompt.format(**values) \\n  \\n         if input_data.sys_prompt: \\n             prompt.append({\"role\": \"system\", \"content\": input_data.sys_prompt}) \\n  \\n         if input_data.expected_format: \\n             expected_format = [ \\n                 f' \"{k}\":\"{v}\" ' for k, v in input_data.expected_format.items() \\n             ] \\n             format_prompt = \",\\n  \".join(expected_format) \\n             sys_prompt = trim_prompt( \\n                 f\"\"\" \\n                   |Reply strictly only in the following JSON format: \\n                   |{{ \\n                   |  {format_prompt} \\n                   |}} \\n                 \"\"\" \\n             ) \\n             prompt.append({\"role\": \"system\", \"content\": sys_prompt}) \\n  \\n         if input_data.prompt: \\n             prompt.append({\"role\": \"user\", \"content\": input_data.prompt}) \\n  \\n         def parse_response(resp: str) -> tuple[dict[str, Any], str | None]: \\n             try: \\n                 parsed = json.loads(resp) \\n                 if not isinstance(parsed, dict): \\n                     return {}, f\"Expected a dictionary, but got {type(parsed)}\" \\n                 miss_keys = set(input_data.expected_format.keys()) - set(parsed.keys()) \\n                 if miss_keys: \\n                     return parsed, f\"Missing keys: {miss_keys}\" \\n                 return parsed, None \\n             except JSONDecodeError as e: \\n                 return {}, f\"JSON decode error: {e}\" \\n  \\n         logger.info(f\"LLM request: {prompt}\") \\n         retry_prompt = \"\" \\n         llm_model = input_data.model \\n  \\n         for retry_count in range(input_data.retry): \\n             try: \\n                 response_text, input_token, output_token = self.llm_call( \\n                     credentials=credentials, \\n                     llm_model=llm_model, \\n                     prompt=prompt, \\n                     json_format=bool(input_data.expected_format), \\n                     ollama_host=input_data.ollama_host, \\n                     max_tokens=input_data.max_tokens, \\n                 ) \\n                 self.merge_stats( \\n                     { \\n                         \"input_token_count\": input_token, \\n                         \"output_token_count\": output_token, \\n                     } \\n                 ) \\n                 logger.info(f\"LLM attempt-{retry_count} response: {response_text}\") \\n  \\n                 if input_data.expected_format: \\n                     parsed_dict, parsed_error = parse_response(response_text) \\n                     if not parsed_error: \\n                         yield \"response\", { \\n                             k: ( \\n                                 json.loads(v) \\n                                 if isinstance(v, str) \\n                                 and v.startswith(\"[\") \\n                                 and v.endswith(\"]\") \\n                                 else (\", \".join(v) if isinstance(v, list) else v) \\n                             ) \\n                             for k, v in parsed_dict.items() \\n                         } \\n                         return \\n                 else: \\n                     yield \"response\", {\"response\": response_text} \\n                     return \\n  \\n                 retry_prompt = trim_prompt( \\n                     f\"\"\" \\n                   |This is your previous error response: \\n                   |-- \\n                   |{response_text} \\n                   |-- \\n                   | \\n                   |And this is the error: \\n                   |-- \\n                   |{parsed_error} \\n                   |-- \\n                 \"\"\" \\n                 ) \\n                 prompt.append({\"role\": \"user\", \"content\": retry_prompt}) \\n             except Exception as e: \\n                 logger.exception(f\"Error calling LLM: {e}\") \\n                 retry_prompt = f\"Error calling LLM: {e}\" \\n             finally: \\n                 self.merge_stats( \\n                     { \\n                         \"llm_call_count\": retry_count + 1, \\n                         \"llm_retry_count\": retry_count, \\n                     } \\n                 ) \\n  \\n         raise RuntimeError(retry_prompt) \\n  \\n  \\n class AITextGeneratorBlock(Block): \\n     class Input(BlockSchema): \\n         prompt: str = SchemaField( \\n             description=\"The prompt to send to the language model. You can use any of the {keys} from Prompt Values to fill in the prompt with values from the prompt values dictionary by putting them in curly braces.\", \\n             placeholder=\"Enter your prompt here...\", \\n         ) \\n         model: LlmModel = SchemaField( \\n             title=\"LLM Model\", \\n             default=LlmModel.GPT4_TURBO, \\n             description=\"The language model to use for answering the prompt.\", \\n             advanced=False, \\n         ) \\n         credentials: AICredentials = AICredentialsField() \\n         sys_prompt: str = SchemaField( \\n             title=\"System Prompt\", \\n             default=\"\", \\n             description=\"The system prompt to provide additional context to the model.\", \\n         ) \\n         retry: int = SchemaField( \\n             title=\"Retry Count\", \\n             default=3, \\n             description=\"Number of times to retry the LLM call if the response does not match the expected format.\", \\n         ) \\n         prompt_values: dict[str, str] = SchemaField( \\n             advanced=False, default={}, description=\"Values used to fill in the prompt.\" \\n         ) \\n         ollama_host: str = SchemaField( \\n             advanced=True, \\n             default=\"localhost:11434\", \\n             description=\"Ollama host for local  models\", \\n         ) \\n         max_tokens: int | None = SchemaField( \\n             advanced=True, \\n             default=None, \\n             description=\"The maximum number of tokens to generate in the chat completion.\", \\n         ) \\n  \\n     class Output(BlockSchema): \\n         response: str = SchemaField( \\n             description=\"The response generated by the language model.\" \\n         ) \\n         error: str = SchemaField(description=\"Error message if the API call failed.\") \\n  \\n     def __init__(self): \\n         super().__init__( \\n             id=\"1f292d4a-41a4-4977-9684-7c8d560b9f91\", \\n             description=\"Call a Large Language Model (LLM) to generate a string based on the given prompt.\", \\n             categories={BlockCategory.AI}, \\n             input_schema=AITextGeneratorBlock.Input, \\n             output_schema=AITextGeneratorBlock.Output, \\n             test_input={ \\n                 \"prompt\": \"User prompt\", \\n                 \"credentials\": TEST_CREDENTIALS_INPUT, \\n             }, \\n             test_credentials=TEST_CREDENTIALS, \\n             test_output=(\"response\", \"Response text\"), \\n             test_mock={\"llm_call\": lambda *args, **kwargs: \"Response text\"}, \\n         ) \\n  \\n     def llm_call( \\n         self, \\n         input_data: AIStructuredResponseGeneratorBlock.Input, \\n         credentials: APIKeyCredentials, \\n     ) -> str: \\n         block = AIStructuredResponseGeneratorBlock() \\n         response = block.run_once(input_data, \"response\", credentials=credentials) \\n         self.merge_stats(block.execution_stats) \\n         return response[\"response\"] \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         object_input_data = AIStructuredResponseGeneratorBlock.Input( \\n             **{attr: getattr(input_data, attr) for attr in input_data.model_fields}, \\n             expected_format={}, \\n         ) \\n         yield \"response\", self.llm_call(object_input_data, credentials) \\n  \\n  \\n class SummaryStyle(Enum): \\n     CONCISE = \"concise\" \\n     DETAILED = \"detailed\" \\n     BULLET_POINTS = \"bullet points\" \\n     NUMBERED_LIST = \"numbered list\" \\n  \\n  \\n class AITextSummarizerBlock(Block): \\n     class Input(BlockSchema): \\n         text: str = SchemaField( \\n             description=\"The text to summarize.\", \\n             placeholder=\"Enter the text to summarize here...\", \\n         ) \\n         model: LlmModel = SchemaField( \\n             title=\"LLM Model\", \\n             default=LlmModel.GPT4_TURBO, \\n             description=\"The language model to use for summarizing the text.\", \\n         ) \\n         focus: str = SchemaField( \\n             title=\"Focus\", \\n             default=\"general information\", \\n             description=\"The topic to focus on in the summary\", \\n         ) \\n         style: SummaryStyle = SchemaField( \\n             title=\"Summary Style\", \\n             default=SummaryStyle.CONCISE, \\n             description=\"The style of the summary to generate.\", \\n         ) \\n         credentials: AICredentials = AICredentialsField() \\n         # TODO: Make this dynamic \\n         max_tokens: int = SchemaField( \\n             title=\"Max Tokens\", \\n             default=4096, \\n             description=\"The maximum number of tokens to generate in the chat completion.\", \\n             ge=1, \\n         ) \\n         chunk_overlap: int = SchemaField( \\n             title=\"Chunk Overlap\", \\n             default=100, \\n             description=\"The number of overlapping tokens between chunks to maintain context.\", \\n             ge=0, \\n         ) \\n         ollama_host: str = SchemaField( \\n             advanced=True, \\n             default=\"localhost:11434\", \\n             description=\"Ollama host for local  models\", \\n         ) \\n  \\n     class Output(BlockSchema): \\n         summary: str = SchemaField(description=\"The final summary of the text.\") \\n         error: str = SchemaField(description=\"Error message if the API call failed.\") \\n  \\n     def __init__(self): \\n         super().__init__( \\n             id=\"a0a69be1-4528-491c-a85a-a4ab6873e3f0\", \\n             description=\"Utilize a Large Language Model (LLM) to summarize a long text.\", \\n             categories={BlockCategory.AI, BlockCategory.TEXT}, \\n             input_schema=AITextSummarizerBlock.Input, \\n             output_schema=AITextSummarizerBlock.Output, \\n             test_input={ \\n                 \"text\": \"Lorem ipsum...\" * 100, \\n                 \"credentials\": TEST_CREDENTIALS_INPUT, \\n             }, \\n             test_credentials=TEST_CREDENTIALS, \\n             test_output=(\"summary\", \"Final summary of a long text\"), \\n             test_mock={ \\n                 \"llm_call\": lambda input_data, credentials: ( \\n                     {\"final_summary\": \"Final summary of a long text\"} \\n                     if \"final_summary\" in input_data.expected_format \\n                     else {\"summary\": \"Summary of a chunk of text\"} \\n                 ) \\n             }, \\n         ) \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         for output in self._run(input_data, credentials): \\n             yield output \\n  \\n     def _run(self, input_data: Input, credentials: APIKeyCredentials) -> BlockOutput: \\n         chunks = self._split_text( \\n             input_data.text, input_data.max_tokens, input_data.chunk_overlap \\n         ) \\n         summaries = [] \\n  \\n         for chunk in chunks: \\n             chunk_summary = self._summarize_chunk(chunk, input_data, credentials) \\n             summaries.append(chunk_summary) \\n  \\n         final_summary = self._combine_summaries(summaries, input_data, credentials) \\n         yield \"summary\", final_summary \\n  \\n     @staticmethod \\n     def _split_text(text: str, max_tokens: int, overlap: int) -> list[str]: \\n         words = text.split() \\n         chunks = [] \\n         chunk_size = max_tokens - overlap \\n  \\n         for i in range(0, len(words), chunk_size): \\n             chunk = \" \".join(words[i : i + max_tokens]) \\n             chunks.append(chunk) \\n  \\n         return chunks \\n  \\n     def llm_call( \\n         self, \\n         input_data: AIStructuredResponseGeneratorBlock.Input, \\n         credentials: APIKeyCredentials, \\n     ) -> dict: \\n         block = AIStructuredResponseGeneratorBlock() \\n         response = block.run_once(input_data, \"response\", credentials=credentials) \\n         self.merge_stats(block.execution_stats) \\n         return response \\n  \\n     def _summarize_chunk( \\n         self, chunk: str, input_data: Input, credentials: APIKeyCredentials \\n     ) -> str: \\n         prompt = f\"Summarize the following text in a {input_data.style} form. Focus your summary on the topic of `{input_data.focus}` if present, otherwise just provide a general summary:\\n\\n```{chunk}```\" \\n  \\n         llm_response = self.llm_call( \\n             AIStructuredResponseGeneratorBlock.Input( \\n                 prompt=prompt, \\n                 credentials=input_data.credentials, \\n                 model=input_data.model, \\n                 expected_format={\"summary\": \"The summary of the given text.\"}, \\n             ), \\n             credentials=credentials, \\n         ) \\n  \\n         return llm_response[\"summary\"] \\n  \\n     def _combine_summaries( \\n         self, summaries: list[str], input_data: Input, credentials: APIKeyCredentials \\n     ) -> str: \\n         combined_text = \"\\n\\n\".join(summaries) \\n  \\n         if len(combined_text.split()) <= input_data.max_tokens: \\n             prompt = f\"Provide a final summary of the following section summaries in a {input_data.style} form, focus your summary on the topic of `{input_data.focus}` if present:\\n\\n ```{combined_text}```\\n\\n Just respond with the final_summary in the format specified.\" \\n  \\n             llm_response = self.llm_call( \\n                 AIStructuredResponseGeneratorBlock.Input( \\n                     prompt=prompt, \\n                     credentials=input_data.credentials, \\n                     model=input_data.model, \\n                     expected_format={ \\n                         \"final_summary\": \"The final summary of all provided summaries.\" \\n                     }, \\n                 ), \\n                 credentials=credentials, \\n             ) \\n  \\n             return llm_response[\"final_summary\"] \\n         else: \\n             # If combined summaries are still too long, recursively summarize \\n             return self._run( \\n                 AITextSummarizerBlock.Input( \\n                     text=combined_text, \\n                     credentials=input_data.credentials, \\n                     model=input_data.model, \\n                     max_tokens=input_data.max_tokens, \\n                     chunk_overlap=input_data.chunk_overlap, \\n                 ), \\n                 credentials=credentials, \\n             ).send(None)[ \\n                 1 \\n             ]  # Get the first yielded value \\n  \\n  \\n class AIConversationBlock(Block): \\n     class Input(BlockSchema): \\n         messages: List[Message] = SchemaField( \\n             description=\"List of messages in the conversation.\", min_length=1 \\n         ) \\n         model: LlmModel = SchemaField( \\n             title=\"LLM Model\", \\n             default=LlmModel.GPT4_TURBO, \\n             description=\"The language model to use for the conversation.\", \\n         ) \\n         credentials: AICredentials = AICredentialsField() \\n         max_tokens: int | None = SchemaField( \\n             advanced=True, \\n             default=None, \\n             description=\"The maximum number of tokens to generate in the chat completion.\", \\n         ) \\n         ollama_host: str = SchemaField( \\n             advanced=True, \\n             default=\"localhost:11434\", \\n             description=\"Ollama host for local  models\", \\n         ) \\n  \\n     class Output(BlockSchema): \\n         response: str = SchemaField( \\n             description=\"The model' s response to the conversation.\" \\n         ) \\n         error: str = SchemaField(description=\" Error message if the API call failed.\") \\n  \\n     def __init__(self): \\n         super().__init__( \\n             id=\"32a87eab-"
                        },
                        {
                            "type": "ReturnStatement",
                            "name": "return",
                            "range": [
                                2583,
                                2626
                            ],
                            "children": [],
                            "content": "e-4dd4-bdb8-4c47151be35a \", \\n             description=\" Advanced LLM call that takes a list of messages and sends them to the language model.\", \\n             categories={BlockCategory.AI}, \\n             input_schema=AIConversationBlock.Input, \\n             output_schema=AIConversationBlock.Output, \\n             test_input={ \\n                 \" messages \": [ \\n                     {\" role\": \"system\", \"content\": \"You are a helpful assistant.\"}, \\n                     {\" role"
                        }
                    ],
                    "content": ".get(\"eval_count\")or0,\n)\nelif provider==\"open_router\":\nclient=openai.OpenAI(\nbase_url=\"https://openrouter.ai/api/v1\",\napi_key=credentials.api_key.get_secret_value(),\n)\n\nresponse=client.chat.completions.create(\nextra_headers={\n\"HTTP-Referer\":\"https://agpt.co\",\n\"X-Title\":\"AutoGPT\",\n},\nmodel=llm_model.value,\nmessages=prompt,#type:ignore\nmax_tokens=max_tokens,\n)\n\n#If there 's no response, raise an error \\n             if not response.choices: \\n                 if response: \\n                     raise ValueError(f\"OpenRouter error: {response}\") \\n                 else: \\n                     raise ValueError(\"No response from OpenRouter.\") \\n  \\n             return ( \\n                 response.choices[0].message.content or \"\", \\n                 response.usage.prompt_tokens if response.usage else 0, \\n                 response.usage.completion_tokens if response.usage else 0, \\n             ) \\n         else: \\n             raise ValueError(f\"Unsupported LLM provider: {provider}\") \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         logger.debug(f\"Calling LLM with input data: {input_data}\") \\n         prompt = [p.model_dump() for p in input_data.conversation_history] \\n  \\n         def trim_prompt(s: str) -> str: \\n             lines = s.strip().split(\"\\n\") \\n             return \"\\n\".join([line.strip().lstrip(\"|\") for line in lines]) \\n  \\n         values = input_data.prompt_values \\n         if values: \\n             input_data.prompt = input_data.prompt.format(**values) \\n             input_data.sys_prompt = input_data.sys_prompt.format(**values) \\n  \\n         if input_data.sys_prompt: \\n             prompt.append({\"role\": \"system\", \"content\": input_data.sys_prompt}) \\n  \\n         if input_data.expected_format: \\n             expected_format = [ \\n                 f' \"{k}\":\"{v}\" ' for k, v in input_data.expected_format.items() \\n             ] \\n             format_prompt = \",\\n  \".join(expected_format) \\n             sys_prompt = trim_prompt( \\n                 f\"\"\" \\n                   |Reply strictly only in the following JSON format: \\n                   |{{ \\n                   |  {format_prompt} \\n                   |}} \\n                 \"\"\" \\n             ) \\n             prompt.append({\"role\": \"system\", \"content\": sys_prompt}) \\n  \\n         if input_data.prompt: \\n             prompt.append({\"role\": \"user\", \"content\": input_data.prompt}) \\n  \\n         def parse_response(resp: str) -> tuple[dict[str, Any], str | None]: \\n             try: \\n                 parsed = json.loads(resp) \\n                 if not isinstance(parsed, dict): \\n                     return {}, f\"Expected a dictionary, but got {type(parsed)}\" \\n                 miss_keys = set(input_data.expected_format.keys()) - set(parsed.keys()) \\n                 if miss_keys: \\n                     return parsed, f\"Missing keys: {miss_keys}\" \\n                 return parsed, None \\n             except JSONDecodeError as e: \\n                 return {}, f\"JSON decode error: {e}\" \\n  \\n         logger.info(f\"LLM request: {prompt}\") \\n         retry_prompt = \"\" \\n         llm_model = input_data.model \\n  \\n         for retry_count in range(input_data.retry): \\n             try: \\n                 response_text, input_token, output_token = self.llm_call( \\n                     credentials=credentials, \\n                     llm_model=llm_model, \\n                     prompt=prompt, \\n                     json_format=bool(input_data.expected_format), \\n                     ollama_host=input_data.ollama_host, \\n                     max_tokens=input_data.max_tokens, \\n                 ) \\n                 self.merge_stats( \\n                     { \\n                         \"input_token_count\": input_token, \\n                         \"output_token_count\": output_token, \\n                     } \\n                 ) \\n                 logger.info(f\"LLM attempt-{retry_count} response: {response_text}\") \\n  \\n                 if input_data.expected_format: \\n                     parsed_dict, parsed_error = parse_response(response_text) \\n                     if not parsed_error: \\n                         yield \"response\", { \\n                             k: ( \\n                                 json.loads(v) \\n                                 if isinstance(v, str) \\n                                 and v.startswith(\"[\") \\n                                 and v.endswith(\"]\") \\n                                 else (\", \".join(v) if isinstance(v, list) else v) \\n                             ) \\n                             for k, v in parsed_dict.items() \\n                         } \\n                         return \\n                 else: \\n                     yield \"response\", {\"response\": response_text} \\n                     return \\n  \\n                 retry_prompt = trim_prompt( \\n                     f\"\"\" \\n                   |This is your previous error response: \\n                   |-- \\n                   |{response_text} \\n                   |-- \\n                   | \\n                   |And this is the error: \\n                   |-- \\n                   |{parsed_error} \\n                   |-- \\n                 \"\"\" \\n                 ) \\n                 prompt.append({\"role\": \"user\", \"content\": retry_prompt}) \\n             except Exception as e: \\n                 logger.exception(f\"Error calling LLM: {e}\") \\n                 retry_prompt = f\"Error calling LLM: {e}\" \\n             finally: \\n                 self.merge_stats( \\n                     { \\n                         \"llm_call_count\": retry_count + 1, \\n                         \"llm_retry_count\": retry_count, \\n                     } \\n                 ) \\n  \\n         raise RuntimeError(retry_prompt) \\n  \\n  \\n class AITextGeneratorBlock(Block): \\n     class Input(BlockSchema): \\n         prompt: str = SchemaField( \\n             description=\"The prompt to send to the language model. You can use any of the {keys} from Prompt Values to fill in the prompt with values from the prompt values dictionary by putting them in curly braces.\", \\n             placeholder=\"Enter your prompt here...\", \\n         ) \\n         model: LlmModel = SchemaField( \\n             title=\"LLM Model\", \\n             default=LlmModel.GPT4_TURBO, \\n             description=\"The language model to use for answering the prompt.\", \\n             advanced=False, \\n         ) \\n         credentials: AICredentials = AICredentialsField() \\n         sys_prompt: str = SchemaField( \\n             title=\"System Prompt\", \\n             default=\"\", \\n             description=\"The system prompt to provide additional context to the model.\", \\n         ) \\n         retry: int = SchemaField( \\n             title=\"Retry Count\", \\n             default=3, \\n             description=\"Number of times to retry the LLM call if the response does not match the expected format.\", \\n         ) \\n         prompt_values: dict[str, str] = SchemaField( \\n             advanced=False, default={}, description=\"Values used to fill in the prompt.\" \\n         ) \\n         ollama_host: str = SchemaField( \\n             advanced=True, \\n             default=\"localhost:11434\", \\n             description=\"Ollama host for local  models\", \\n         ) \\n         max_tokens: int | None = SchemaField( \\n             advanced=True, \\n             default=None, \\n             description=\"The maximum number of tokens to generate in the chat completion.\", \\n         ) \\n  \\n     class Output(BlockSchema): \\n         response: str = SchemaField( \\n             description=\"The response generated by the language model.\" \\n         ) \\n         error: str = SchemaField(description=\"Error message if the API call failed.\") \\n  \\n     def __init__(self): \\n         super().__init__( \\n             id=\"1f292d4a-41a4-4977-9684-7c8d560b9f91\", \\n             description=\"Call a Large Language Model (LLM) to generate a string based on the given prompt.\", \\n             categories={BlockCategory.AI}, \\n             input_schema=AITextGeneratorBlock.Input, \\n             output_schema=AITextGeneratorBlock.Output, \\n             test_input={ \\n                 \"prompt\": \"User prompt\", \\n                 \"credentials\": TEST_CREDENTIALS_INPUT, \\n             }, \\n             test_credentials=TEST_CREDENTIALS, \\n             test_output=(\"response\", \"Response text\"), \\n             test_mock={\"llm_call\": lambda *args, **kwargs: \"Response text\"}, \\n         ) \\n  \\n     def llm_call( \\n         self, \\n         input_data: AIStructuredResponseGeneratorBlock.Input, \\n         credentials: APIKeyCredentials, \\n     ) -> str: \\n         block = AIStructuredResponseGeneratorBlock() \\n         response = block.run_once(input_data, \"response\", credentials=credentials) \\n         self.merge_stats(block.execution_stats) \\n         return response[\"response\"] \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         object_input_data = AIStructuredResponseGeneratorBlock.Input( \\n             **{attr: getattr(input_data, attr) for attr in input_data.model_fields}, \\n             expected_format={}, \\n         ) \\n         yield \"response\", self.llm_call(object_input_data, credentials) \\n  \\n  \\n class SummaryStyle(Enum): \\n     CONCISE = \"concise\" \\n     DETAILED = \"detailed\" \\n     BULLET_POINTS = \"bullet points\" \\n     NUMBERED_LIST = \"numbered list\" \\n  \\n  \\n class AITextSummarizerBlock(Block): \\n     class Input(BlockSchema): \\n         text: str = SchemaField( \\n             description=\"The text to summarize.\", \\n             placeholder=\"Enter the text to summarize here...\", \\n         ) \\n         model: LlmModel = SchemaField( \\n             title=\"LLM Model\", \\n             default=LlmModel.GPT4_TURBO, \\n             description=\"The language model to use for summarizing the text.\", \\n         ) \\n         focus: str = SchemaField( \\n             title=\"Focus\", \\n             default=\"general information\", \\n             description=\"The topic to focus on in the summary\", \\n         ) \\n         style: SummaryStyle = SchemaField( \\n             title=\"Summary Style\", \\n             default=SummaryStyle.CONCISE, \\n             description=\"The style of the summary to generate.\", \\n         ) \\n         credentials: AICredentials = AICredentialsField() \\n         # TODO: Make this dynamic \\n         max_tokens: int = SchemaField( \\n             title=\"Max Tokens\", \\n             default=4096, \\n             description=\"The maximum number of tokens to generate in the chat completion.\", \\n             ge=1, \\n         ) \\n         chunk_overlap: int = SchemaField( \\n             title=\"Chunk Overlap\", \\n             default=100, \\n             description=\"The number of overlapping tokens between chunks to maintain context.\", \\n             ge=0, \\n         ) \\n         ollama_host: str = SchemaField( \\n             advanced=True, \\n             default=\"localhost:11434\", \\n             description=\"Ollama host for local  models\", \\n         ) \\n  \\n     class Output(BlockSchema): \\n         summary: str = SchemaField(description=\"The final summary of the text.\") \\n         error: str = SchemaField(description=\"Error message if the API call failed.\") \\n  \\n     def __init__(self): \\n         super().__init__( \\n             id=\"a0a69be1-4528-491c-a85a-a4ab6873e3f0\", \\n             description=\"Utilize a Large Language Model (LLM) to summarize a long text.\", \\n             categories={BlockCategory.AI, BlockCategory.TEXT}, \\n             input_schema=AITextSummarizerBlock.Input, \\n             output_schema=AITextSummarizerBlock.Output, \\n             test_input={ \\n                 \"text\": \"Lorem ipsum...\" * 100, \\n                 \"credentials\": TEST_CREDENTIALS_INPUT, \\n             }, \\n             test_credentials=TEST_CREDENTIALS, \\n             test_output=(\"summary\", \"Final summary of a long text\"), \\n             test_mock={ \\n                 \"llm_call\": lambda input_data, credentials: ( \\n                     {\"final_summary\": \"Final summary of a long text\"} \\n                     if \"final_summary\" in input_data.expected_format \\n                     else {\"summary\": \"Summary of a chunk of text\"} \\n                 ) \\n             }, \\n         ) \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         for output in self._run(input_data, credentials): \\n             yield output \\n  \\n     def _run(self, input_data: Input, credentials: APIKeyCredentials) -> BlockOutput: \\n         chunks = self._split_text( \\n             input_data.text, input_data.max_tokens, input_data.chunk_overlap \\n         ) \\n         summaries = [] \\n  \\n         for chunk in chunks: \\n             chunk_summary = self._summarize_chunk(chunk, input_data, credentials) \\n             summaries.append(chunk_summary) \\n  \\n         final_summary = self._combine_summaries(summaries, input_data, credentials) \\n         yield \"summary\", final_summary \\n  \\n     @staticmethod \\n     def _split_text(text: str, max_tokens: int, overlap: int) -> list[str]: \\n         words = text.split() \\n         chunks = [] \\n         chunk_size = max_tokens - overlap \\n  \\n         for i in range(0, len(words), chunk_size): \\n             chunk = \" \".join(words[i : i + max_tokens]) \\n             chunks.append(chunk) \\n  \\n         return chunks \\n  \\n     def llm_call( \\n         self, \\n         input_data: AIStructuredResponseGeneratorBlock.Input, \\n         credentials: APIKeyCredentials, \\n     ) -> dict: \\n         block = AIStructuredResponseGeneratorBlock() \\n         response = block.run_once(input_data, \"response\", credentials=credentials) \\n         self.merge_stats(block.execution_stats) \\n         return response \\n  \\n     def _summarize_chunk( \\n         self, chunk: str, input_data: Input, credentials: APIKeyCredentials \\n     ) -> str: \\n         prompt = f\"Summarize the following text in a {input_data.style} form. Focus your summary on the topic of `{input_data.focus}` if present, otherwise just provide a general summary:\\n\\n```{chunk}```\" \\n  \\n         llm_response = self.llm_call( \\n             AIStructuredResponseGeneratorBlock.Input( \\n                 prompt=prompt, \\n                 credentials=input_data.credentials, \\n                 model=input_data.model, \\n                 expected_format={\"summary\": \"The summary of the given text.\"}, \\n             ), \\n             credentials=credentials, \\n         ) \\n  \\n         return llm_response[\"summary\"] \\n  \\n     def _combine_summaries( \\n         self, summaries: list[str], input_data: Input, credentials: APIKeyCredentials \\n     ) -> str: \\n         combined_text = \"\\n\\n\".join(summaries) \\n  \\n         if len(combined_text.split()) <= input_data.max_tokens: \\n             prompt = f\"Provide a final summary of the following section summaries in a {input_data.style} form, focus your summary on the topic of `{input_data.focus}` if present:\\n\\n ```{combined_text}```\\n\\n Just respond with the final_summary in the format specified.\" \\n  \\n             llm_response = self.llm_call( \\n                 AIStructuredResponseGeneratorBlock.Input( \\n                     prompt=prompt, \\n                     credentials=input_data.credentials, \\n                     model=input_data.model, \\n                     expected_format={ \\n                         \"final_summary\": \"The final summary of all provided summaries.\" \\n                     }, \\n                 ), \\n                 credentials=credentials, \\n             ) \\n  \\n             return llm_response[\"final_summary\"] \\n         else: \\n             # If combined summaries are still too long, recursively summarize \\n             return self._run( \\n                 AITextSummarizerBlock.Input( \\n                     text=combined_text, \\n                     credentials=input_data.credentials, \\n                     model=input_data.model, \\n                     max_tokens=input_data.max_tokens, \\n                     chunk_overlap=input_data.chunk_overlap, \\n                 ), \\n                 credentials=credentials, \\n             ).send(None)[ \\n                 1 \\n             ]  # Get the first yielded value \\n  \\n  \\n class AIConversationBlock(Block): \\n     class Input(BlockSchema): \\n         messages: List[Message] = SchemaField( \\n             description=\"List of messages in the conversation.\", min_length=1 \\n         ) \\n         model: LlmModel = SchemaField( \\n             title=\"LLM Model\", \\n             default=LlmModel.GPT4_TURBO, \\n             description=\"The language model to use for the conversation.\", \\n         ) \\n         credentials: AICredentials = AICredentialsField() \\n         max_tokens: int | None = SchemaField( \\n             advanced=True, \\n             default=None, \\n             description=\"The maximum number of tokens to generate in the chat completion.\", \\n         ) \\n         ollama_host: str = SchemaField( \\n             advanced=True, \\n             default=\"localhost:11434\", \\n             description=\"Ollama host for local  models\", \\n         ) \\n  \\n     class Output(BlockSchema): \\n         response: str = SchemaField( \\n             description=\"The model' s response to the conversation.\" \\n         ) \\n         error: str = SchemaField(description=\" Error message if the API call failed.\") \\n  \\n     def __init__(self): \\n         super().__init__( \\n             id=\"32a87eab-381e-4dd4-bdb8-4c47151be35a \", \\n             description=\" Advanced LLM call that takes a list of messages and sends them to the language model.\", \\n             categories={BlockCategory.AI}, \\n             input_schema=AIConversationBlock.Input, \\n             output_schema=AIConversationBlock.Output, \\n             test_input={ \\n                 \" messages \": [ \\n                     {\" role\": \"system\", \"content\": \"You are a helpful assistant.\"}, \\n                     {\" role\": \""
                },
                {
                    "type": "ElseStatement",
                    "name": "else",
                    "range": [
                        2628,
                        2637
                    ],
                    "children": [
                        {
                            "type": "RaiseStatement",
                            "name": "raise",
                            "range": [
                                2631,
                                2636
                            ],
                            "children": [],
                            "content": "\": \"Who won the world series"
                        }
                    ],
                    "content": "user\", \"content\": \"Who won the world series in"
                }
            ],
            "content": "\n)\n},\n)\n\n@staticmethod\ndef llm_call(\ncredentials:APIKeyCredentials,\nllm_model:LlmModel,\nprompt:list[dict],\njson_format:bool,\nmax_tokens:int|None=None,\nollama_host:str=\"localhost:11434\",\n)->tuple[str,int,int]:\n\"\"\" \\n         Args: \\n             api_key: API key for the LLM provider. \\n             llm_model: The LLM model to use. \\n             prompt: The prompt to send to the LLM. \\n             json_format: Whether the response should be in JSON format. \\n             max_tokens: The maximum number of tokens to generate in the chat completion. \\n             ollama_host: The host for ollama to use \\n  \\n         Returns: \\n             The response from the LLM. \\n             The number of tokens used in the prompt. \\n             The number of tokens used in the completion. \\n         \"\"\"\nprovider=llm_model.metadata.provider\n\nif provider==\"openai\":\noai_client=openai.OpenAI(api_key=credentials.api_key.get_secret_value())\nresponse_format=None\n\nif llm_model in[LlmModel.O1_MINI,LlmModel.O1_PREVIEW]:\nsys_messages=[p[\"content\"]for p in prompt if p[\"role\"]==\"system\"]\nusr_messages=[p[\"content\"]for p in prompt if p[\"role\"]!=\"system\"]\nprompt=[\n{\"role\":\"user\",\"content\":\"\\n\".join(sys_messages)},\n{\"role\":\"user\",\"content\":\"\\n\".join(usr_messages)},\n]\nelif json_format:\nresponse_format={\"type\":\"json_object\"}\n\nresponse=oai_client.chat.completions.create(\nmodel=llm_model.value,\nmessages=prompt,#type:ignore\nresponse_format=response_format,#type:ignore\nmax_completion_tokens=max_tokens,\n)\n\nreturn(\nresponse.choices[0].message.content or\"\",\nresponse.usage.prompt_tokens if response.usage else0,\nresponse.usage.completion_tokens if response.usage else0,\n)\nelif provider==\"anthropic\":\nsystem_messages=[p[\"content\"]for p in prompt if p[\"role\"]==\"system\"]\nsysprompt=\" \".join(system_messages)\n\nmessages=[]\nlast_role=None\nfor p in prompt:\nif p[\"role\"]in[\"user\",\"assistant\"]:\nif p[\"role\"]!=last_role:\nmessages.append({\"role\":p[\"role\"],\"content\":p[\"content\"]})\nlast_role=p[\"role\"]\nelse:\n#If the role is the same as the last one,combine the content\nmessages[-1][\"content\"]+=\"\\n\"+p[\"content\"]\n\nclient=anthropic.Anthropic(api_key=credentials.api_key.get_secret_value())\ntry:\nresp=client.messages.create(\nmodel=llm_model.value,\nsystem=sysprompt,\nmessages=messages,\nmax_tokens=max_tokens or8192,\n)\n\nif not resp.content:\nraise ValueError(\"No content returned from Anthropic.\")\n\nreturn(\n(\nresp.content[0].name\nif isinstance(resp.content[0],anthropic.types.ToolUseBlock)\nelse resp.content[0].text\n),\nresp.usage.input_tokens,\nresp.usage.output_tokens,\n)\nexcept anthropic.APIError as e:\nerror_message=f \"Anthropic API error: {str(e)}\"\nlogger.error(error_message)\nraise ValueError(error_message)\nelif provider==\"groq\":\nclient=Groq(api_key=credentials.api_key.get_secret_value())\nresponse_format={\"type\":\"json_object\"}if json_format else None\nresponse=client.chat.completions.create(\nmodel=llm_model.value,\nmessages=prompt,#type:ignore\nresponse_format=response_format,#type:ignore\nmax_tokens=max_tokens,\n)\nreturn(\nresponse.choices[0].message.content or\"\",\nresponse.usage.prompt_tokens if response.usage else0,\nresponse.usage.completion_tokens if response.usage else0,\n)\nelif provider==\"ollama\":\nclient=ollama.Client(host=ollama_host)\nsys_messages=[p[\"content\"]for p in prompt if p[\"role\"]==\"system\"]\nusr_messages=[p[\"content\"]for p in prompt if p[\"role\"]!=\"system\"]\nresponse=client.generate(\nmodel=llm_model.value,\nprompt=f \"{sys_messages}\\n\\n{usr_messages}\",\nstream=False,\n)\nreturn(\nresponse.get(\"response\")or\"\",\nresponse.get(\"prompt_eval_count\")or0,\nresponse.get(\"eval_count\")or0,\n)\nelif provider==\"open_router\":\nclient=openai.OpenAI(\nbase_url=\"https://openrouter.ai/api/v1\",\napi_key=credentials.api_key.get_secret_value(),\n)\n\nresponse=client.chat.completions.create(\nextra_headers={\n\"HTTP-Referer\":\"https://agpt.co\",\n\"X-Title\":\"AutoGPT\",\n},\nmodel=llm_model.value,\nmessages=prompt,#type:ignore\nmax_tokens=max_tokens,\n)\n\n#If there 's no response, raise an error \\n             if not response.choices: \\n                 if response: \\n                     raise ValueError(f\"OpenRouter error: {response}\") \\n                 else: \\n                     raise ValueError(\"No response from OpenRouter.\") \\n  \\n             return ( \\n                 response.choices[0].message.content or \"\", \\n                 response.usage.prompt_tokens if response.usage else 0, \\n                 response.usage.completion_tokens if response.usage else 0, \\n             ) \\n         else: \\n             raise ValueError(f\"Unsupported LLM provider: {provider}\") \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         logger.debug(f\"Calling LLM with input data: {input_data}\") \\n         prompt = [p.model_dump() for p in input_data.conversation_history] \\n  \\n         def trim_prompt(s: str) -> str: \\n             lines = s.strip().split(\"\\n\") \\n             return \"\\n\".join([line.strip().lstrip(\"|\") for line in lines]) \\n  \\n         values = input_data.prompt_values \\n         if values: \\n             input_data.prompt = input_data.prompt.format(**values) \\n             input_data.sys_prompt = input_data.sys_prompt.format(**values) \\n  \\n         if input_data.sys_prompt: \\n             prompt.append({\"role\": \"system\", \"content\": input_data.sys_prompt}) \\n  \\n         if input_data.expected_format: \\n             expected_format = [ \\n                 f' \"{k}\":\"{v}\" ' for k, v in input_data.expected_format.items() \\n             ] \\n             format_prompt = \",\\n  \".join(expected_format) \\n             sys_prompt = trim_prompt( \\n                 f\"\"\" \\n                   |Reply strictly only in the following JSON format: \\n                   |{{ \\n                   |  {format_prompt} \\n                   |}} \\n                 \"\"\" \\n             ) \\n             prompt.append({\"role\": \"system\", \"content\": sys_prompt}) \\n  \\n         if input_data.prompt: \\n             prompt.append({\"role\": \"user\", \"content\": input_data.prompt}) \\n  \\n         def parse_response(resp: str) -> tuple[dict[str, Any], str | None]: \\n             try: \\n                 parsed = json.loads(resp) \\n                 if not isinstance(parsed, dict): \\n                     return {}, f\"Expected a dictionary, but got {type(parsed)}\" \\n                 miss_keys = set(input_data.expected_format.keys()) - set(parsed.keys()) \\n                 if miss_keys: \\n                     return parsed, f\"Missing keys: {miss_keys}\" \\n                 return parsed, None \\n             except JSONDecodeError as e: \\n                 return {}, f\"JSON decode error: {e}\" \\n  \\n         logger.info(f\"LLM request: {prompt}\") \\n         retry_prompt = \"\" \\n         llm_model = input_data.model \\n  \\n         for retry_count in range(input_data.retry): \\n             try: \\n                 response_text, input_token, output_token = self.llm_call( \\n                     credentials=credentials, \\n                     llm_model=llm_model, \\n                     prompt=prompt, \\n                     json_format=bool(input_data.expected_format), \\n                     ollama_host=input_data.ollama_host, \\n                     max_tokens=input_data.max_tokens, \\n                 ) \\n                 self.merge_stats( \\n                     { \\n                         \"input_token_count\": input_token, \\n                         \"output_token_count\": output_token, \\n                     } \\n                 ) \\n                 logger.info(f\"LLM attempt-{retry_count} response: {response_text}\") \\n  \\n                 if input_data.expected_format: \\n                     parsed_dict, parsed_error = parse_response(response_text) \\n                     if not parsed_error: \\n                         yield \"response\", { \\n                             k: ( \\n                                 json.loads(v) \\n                                 if isinstance(v, str) \\n                                 and v.startswith(\"[\") \\n                                 and v.endswith(\"]\") \\n                                 else (\", \".join(v) if isinstance(v, list) else v) \\n                             ) \\n                             for k, v in parsed_dict.items() \\n                         } \\n                         return \\n                 else: \\n                     yield \"response\", {\"response\": response_text} \\n                     return \\n  \\n                 retry_prompt = trim_prompt( \\n                     f\"\"\" \\n                   |This is your previous error response: \\n                   |-- \\n                   |{response_text} \\n                   |-- \\n                   | \\n                   |And this is the error: \\n                   |-- \\n                   |{parsed_error} \\n                   |-- \\n                 \"\"\" \\n                 ) \\n                 prompt.append({\"role\": \"user\", \"content\": retry_prompt}) \\n             except Exception as e: \\n                 logger.exception(f\"Error calling LLM: {e}\") \\n                 retry_prompt = f\"Error calling LLM: {e}\" \\n             finally: \\n                 self.merge_stats( \\n                     { \\n                         \"llm_call_count\": retry_count + 1, \\n                         \"llm_retry_count\": retry_count, \\n                     } \\n                 ) \\n  \\n         raise RuntimeError(retry_prompt) \\n  \\n  \\n class AITextGeneratorBlock(Block): \\n     class Input(BlockSchema): \\n         prompt: str = SchemaField( \\n             description=\"The prompt to send to the language model. You can use any of the {keys} from Prompt Values to fill in the prompt with values from the prompt values dictionary by putting them in curly braces.\", \\n             placeholder=\"Enter your prompt here...\", \\n         ) \\n         model: LlmModel = SchemaField( \\n             title=\"LLM Model\", \\n             default=LlmModel.GPT4_TURBO, \\n             description=\"The language model to use for answering the prompt.\", \\n             advanced=False, \\n         ) \\n         credentials: AICredentials = AICredentialsField() \\n         sys_prompt: str = SchemaField( \\n             title=\"System Prompt\", \\n             default=\"\", \\n             description=\"The system prompt to provide additional context to the model.\", \\n         ) \\n         retry: int = SchemaField( \\n             title=\"Retry Count\", \\n             default=3, \\n             description=\"Number of times to retry the LLM call if the response does not match the expected format.\", \\n         ) \\n         prompt_values: dict[str, str] = SchemaField( \\n             advanced=False, default={}, description=\"Values used to fill in the prompt.\" \\n         ) \\n         ollama_host: str = SchemaField( \\n             advanced=True, \\n             default=\"localhost:11434\", \\n             description=\"Ollama host for local  models\", \\n         ) \\n         max_tokens: int | None = SchemaField( \\n             advanced=True, \\n             default=None, \\n             description=\"The maximum number of tokens to generate in the chat completion.\", \\n         ) \\n  \\n     class Output(BlockSchema): \\n         response: str = SchemaField( \\n             description=\"The response generated by the language model.\" \\n         ) \\n         error: str = SchemaField(description=\"Error message if the API call failed.\") \\n  \\n     def __init__(self): \\n         super().__init__( \\n             id=\"1f292d4a-41a4-4977-9684-7c8d560b9f91\", \\n             description=\"Call a Large Language Model (LLM) to generate a string based on the given prompt.\", \\n             categories={BlockCategory.AI}, \\n             input_schema=AITextGeneratorBlock.Input, \\n             output_schema=AITextGeneratorBlock.Output, \\n             test_input={ \\n                 \"prompt\": \"User prompt\", \\n                 \"credentials\": TEST_CREDENTIALS_INPUT, \\n             }, \\n             test_credentials=TEST_CREDENTIALS, \\n             test_output=(\"response\", \"Response text\"), \\n             test_mock={\"llm_call\": lambda *args, **kwargs: \"Response text\"}, \\n         ) \\n  \\n     def llm_call( \\n         self, \\n         input_data: AIStructuredResponseGeneratorBlock.Input, \\n         credentials: APIKeyCredentials, \\n     ) -> str: \\n         block = AIStructuredResponseGeneratorBlock() \\n         response = block.run_once(input_data, \"response\", credentials=credentials) \\n         self.merge_stats(block.execution_stats) \\n         return response[\"response\"] \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         object_input_data = AIStructuredResponseGeneratorBlock.Input( \\n             **{attr: getattr(input_data, attr) for attr in input_data.model_fields}, \\n             expected_format={}, \\n         ) \\n         yield \"response\", self.llm_call(object_input_data, credentials) \\n  \\n  \\n class SummaryStyle(Enum): \\n     CONCISE = \"concise\" \\n     DETAILED = \"detailed\" \\n     BULLET_POINTS = \"bullet points\" \\n     NUMBERED_LIST = \"numbered list\" \\n  \\n  \\n class AITextSummarizerBlock(Block): \\n     class Input(BlockSchema): \\n         text: str = SchemaField( \\n             description=\"The text to summarize.\", \\n             placeholder=\"Enter the text to summarize here...\", \\n         ) \\n         model: LlmModel = SchemaField( \\n             title=\"LLM Model\", \\n             default=LlmModel.GPT4_TURBO, \\n             description=\"The language model to use for summarizing the text.\", \\n         ) \\n         focus: str = SchemaField( \\n             title=\"Focus\", \\n             default=\"general information\", \\n             description=\"The topic to focus on in the summary\", \\n         ) \\n         style: SummaryStyle = SchemaField( \\n             title=\"Summary Style\", \\n             default=SummaryStyle.CONCISE, \\n             description=\"The style of the summary to generate.\", \\n         ) \\n         credentials: AICredentials = AICredentialsField() \\n         # TODO: Make this dynamic \\n         max_tokens: int = SchemaField( \\n             title=\"Max Tokens\", \\n             default=4096, \\n             description=\"The maximum number of tokens to generate in the chat completion.\", \\n             ge=1, \\n         ) \\n         chunk_overlap: int = SchemaField( \\n             title=\"Chunk Overlap\", \\n             default=100, \\n             description=\"The number of overlapping tokens between chunks to maintain context.\", \\n             ge=0, \\n         ) \\n         ollama_host: str = SchemaField( \\n             advanced=True, \\n             default=\"localhost:11434\", \\n             description=\"Ollama host for local  models\", \\n         ) \\n  \\n     class Output(BlockSchema): \\n         summary: str = SchemaField(description=\"The final summary of the text.\") \\n         error: str = SchemaField(description=\"Error message if the API call failed.\") \\n  \\n     def __init__(self): \\n         super().__init__( \\n             id=\"a0a69be1-4528-491c-a85a-a4ab6873e3f0\", \\n             description=\"Utilize a Large Language Model (LLM) to summarize a long text.\", \\n             categories={BlockCategory.AI, BlockCategory.TEXT}, \\n             input_schema=AITextSummarizerBlock.Input, \\n             output_schema=AITextSummarizerBlock.Output, \\n             test_input={ \\n                 \"text\": \"Lorem ipsum...\" * 100, \\n                 \"credentials\": TEST_CREDENTIALS_INPUT, \\n             }, \\n             test_credentials=TEST_CREDENTIALS, \\n             test_output=(\"summary\", \"Final summary of a long text\"), \\n             test_mock={ \\n                 \"llm_call\": lambda input_data, credentials: ( \\n                     {\"final_summary\": \"Final summary of a long text\"} \\n                     if \"final_summary\" in input_data.expected_format \\n                     else {\"summary\": \"Summary of a chunk of text\"} \\n                 ) \\n             }, \\n         ) \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         for output in self._run(input_data, credentials): \\n             yield output \\n  \\n     def _run(self, input_data: Input, credentials: APIKeyCredentials) -> BlockOutput: \\n         chunks = self._split_text( \\n             input_data.text, input_data.max_tokens, input_data.chunk_overlap \\n         ) \\n         summaries = [] \\n  \\n         for chunk in chunks: \\n             chunk_summary = self._summarize_chunk(chunk, input_data, credentials) \\n             summaries.append(chunk_summary) \\n  \\n         final_summary = self._combine_summaries(summaries, input_data, credentials) \\n         yield \"summary\", final_summary \\n  \\n     @staticmethod \\n     def _split_text(text: str, max_tokens: int, overlap: int) -> list[str]: \\n         words = text.split() \\n         chunks = [] \\n         chunk_size = max_tokens - overlap \\n  \\n         for i in range(0, len(words), chunk_size): \\n             chunk = \" \".join(words[i : i + max_tokens]) \\n             chunks.append(chunk) \\n  \\n         return chunks \\n  \\n     def llm_call( \\n         self, \\n         input_data: AIStructuredResponseGeneratorBlock.Input, \\n         credentials: APIKeyCredentials, \\n     ) -> dict: \\n         block = AIStructuredResponseGeneratorBlock() \\n         response = block.run_once(input_data, \"response\", credentials=credentials) \\n         self.merge_stats(block.execution_stats) \\n         return response \\n  \\n     def _summarize_chunk( \\n         self, chunk: str, input_data: Input, credentials: APIKeyCredentials \\n     ) -> str: \\n         prompt = f\"Summarize the following text in a {input_data.style} form. Focus your summary on the topic of `{input_data.focus}` if present, otherwise just provide a general summary:\\n\\n```{chunk}```\" \\n  \\n         llm_response = self.llm_call( \\n             AIStructuredResponseGeneratorBlock.Input( \\n                 prompt=prompt, \\n                 credentials=input_data.credentials, \\n                 model=input_data.model, \\n                 expected_format={\"summary\": \"The summary of the given text.\"}, \\n             ), \\n             credentials=credentials, \\n         ) \\n  \\n         return llm_response[\"summary\"] \\n  \\n     def _combine_summaries( \\n         self, summaries: list[str], input_data: Input, credentials: APIKeyCredentials \\n     ) -> str: \\n         combined_text = \"\\n\\n\".join(summaries) \\n  \\n         if len(combined_text.split()) <= input_data.max_tokens: \\n             prompt = f\"Provide a final summary of the following section summaries in a {input_data.style} form, focus your summary on the topic of `{input_data.focus}` if present:\\n\\n ```{combined_text}```\\n\\n Just respond with the final_summary in the format specified.\" \\n  \\n             llm_response = self.llm_call( \\n                 AIStructuredResponseGeneratorBlock.Input( \\n                     prompt=prompt, \\n                     credentials=input_data.credentials, \\n                     model=input_data.model, \\n                     expected_format={ \\n                         \"final_summary\": \"The final summary of all provided summaries.\" \\n                     }, \\n                 ), \\n                 credentials=credentials, \\n             ) \\n  \\n             return llm_response[\"final_summary\"] \\n         else: \\n             # If combined summaries are still too long, recursively summarize \\n             return self._run( \\n                 AITextSummarizerBlock.Input( \\n                     text=combined_text, \\n                     credentials=input_data.credentials, \\n                     model=input_data.model, \\n                     max_tokens=input_data.max_tokens, \\n                     chunk_overlap=input_data.chunk_overlap, \\n                 ), \\n                 credentials=credentials, \\n             ).send(None)[ \\n                 1 \\n             ]  # Get the first yielded value \\n  \\n  \\n class AIConversationBlock(Block): \\n     class Input(BlockSchema): \\n         messages: List[Message] = SchemaField( \\n             description=\"List of messages in the conversation.\", min_length=1 \\n         ) \\n         model: LlmModel = SchemaField( \\n             title=\"LLM Model\", \\n             default=LlmModel.GPT4_TURBO, \\n             description=\"The language model to use for the conversation.\", \\n         ) \\n         credentials: AICredentials = AICredentialsField() \\n         max_tokens: int | None = SchemaField( \\n             advanced=True, \\n             default=None, \\n             description=\"The maximum number of tokens to generate in the chat completion.\", \\n         ) \\n         ollama_host: str = SchemaField( \\n             advanced=True, \\n             default=\"localhost:11434\", \\n             description=\"Ollama host for local  models\", \\n         ) \\n  \\n     class Output(BlockSchema): \\n         response: str = SchemaField( \\n             description=\"The model' s response to the conversation.\" \\n         ) \\n         error: str = SchemaField(description=\" Error message if the API call failed.\") \\n  \\n     def __init__(self): \\n         super().__init__( \\n             id=\"32a87eab-381e-4dd4-bdb8-4c47151be35a \", \\n             description=\" Advanced LLM call that takes a list of messages and sends them to the language model.\", \\n             categories={BlockCategory.AI}, \\n             input_schema=AIConversationBlock.Input, \\n             output_schema=AIConversationBlock.Output, \\n             test_input={ \\n                 \" messages \": [ \\n                     {\" role\": \"system\", \"content\": \"You are a helpful assistant.\"}, \\n                     {\" role\": \"user\", \"content\": \"Who won the world series in2020"
        },
        {
            "type": "ClassDecl",
            "name": "AITextGeneratorBlock",
            "range": [
                2639,
                2836
            ],
            "children": [
                {
                    "type": "ClassDecl",
                    "name": "Input",
                    "range": [
                        2646,
                        2758
                    ],
                    "children": [
                        {
                            "type": "FieldDecl",
                            "name": "prompt",
                            "range": [
                                2653,
                                2670
                            ],
                            "children": [],
                            "content": "World Series in2020.\", \\n                     }, \\n                     {\" role\": \"user\", \"content\": \"Where was it played?\"}, \\n                 ], \\n                 \""
                        },
                        {
                            "type": "FieldDecl",
                            "name": "model",
                            "range": [
                                2672,
                                2701
                            ],
                            "children": [],
                            "content": "\": LlmModel.GPT4_TURBO, \\n                 \" credentials \": TEST_CREDENTIALS_INPUT, \\n             }, \\n             test_credentials=TEST_CREDENTIALS, \\n             test_output=( \\n                 \" response \", \\n                 \" The2020World Series was played at Globe Life Field in Arlington,Texas.\", \\n             ), \\n             test_mock={ \\n                 \" llm_call \": lambda *args, **kwargs: \" The2020World Series was played at"
                        },
                        {
                            "type": "FieldDecl",
                            "name": "credentials",
                            "range": [
                                2703,
                                2710
                            ],
                            "children": [],
                            "content": "Life Field in Arlington,Texas.\" \\n             }, \\n         ) \\n  \\n     def llm_call( \\n         self, \\n         input_data: AIStructuredResponseGeneratorBlock.Input, \\n         credentials: APIKeyCredentials, \\n     ) -> str: \\n         block = AIStructuredResponseGeneratorBlock() \\n         response = block.run_once(input_data, \""
                        },
                        {
                            "type": "FieldDecl",
                            "name": "sys_prompt",
                            "range": [
                                2711,
                                2734
                            ],
                            "children": [],
                            "content": "response \", credentials=credentials) \\n         self.merge_stats(block.execution_stats) \\n         return response[\" response \"] \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         response = self.llm_call( \\n             AIStructuredResponseGeneratorBlock.Input( \\n                 prompt=\" \", \\n                 credentials=input_data.credentials, \\n                 model=input_data.model, \\n                 conversation_history=input_data.messages, \\n                 max_tokens=input_data.max_tokens, \\n                 expected_format={}, \\n             ), \\n             credentials=credentials, \\n         ) \\n  \\n         yield \" response \", response \\n  \\n  \\n class AIListGeneratorBlock(Block): \\n     class Input(BlockSchema): \\n         focus: str | None = SchemaField( \\n             description=\" The focus of the list to generate.\", \\n             placeholder=\" The top5most interesting news stories in"
                        },
                        {
                            "type": "FieldDecl",
                            "name": "retry",
                            "range": [
                                2735,
                                2758
                            ],
                            "children": [],
                            "content": "the data.\", \\n             default=None, \\n             advanced=False, \\n         ) \\n         source_data: str | None = SchemaField( \\n             description=\" The data to generate the list from.\", \\n             placeholder=\" News Today:Humans land on Mars:Today humans landed"
                        }
                    ],
                    "content": "\": \"The Los Angeles Dodgers won the World Series in2020.\", \\n                     }, \\n                     {\" role\": \"user\", \"content\": \"Where was it played?\"}, \\n                 ], \\n                 \" model \": LlmModel.GPT4_TURBO, \\n                 \" credentials \": TEST_CREDENTIALS_INPUT, \\n             }, \\n             test_credentials=TEST_CREDENTIALS, \\n             test_output=( \\n                 \" response \", \\n                 \" The2020World Series was played at Globe Life Field in Arlington,Texas.\", \\n             ), \\n             test_mock={ \\n                 \" llm_call \": lambda *args, **kwargs: \" The2020World Series was played at Globe Life Field in Arlington,Texas.\" \\n             }, \\n         ) \\n  \\n     def llm_call( \\n         self, \\n         input_data: AIStructuredResponseGeneratorBlock.Input, \\n         credentials: APIKeyCredentials, \\n     ) -> str: \\n         block = AIStructuredResponseGeneratorBlock() \\n         response = block.run_once(input_data, \" response \", credentials=credentials) \\n         self.merge_stats(block.execution_stats) \\n         return response[\" response \"] \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         response = self.llm_call( \\n             AIStructuredResponseGeneratorBlock.Input( \\n                 prompt=\" \", \\n                 credentials=input_data.credentials, \\n                 model=input_data.model, \\n                 conversation_history=input_data.messages, \\n                 max_tokens=input_data.max_tokens, \\n                 expected_format={}, \\n             ), \\n             credentials=credentials, \\n         ) \\n  \\n         yield \" response \", response \\n  \\n  \\n class AIListGeneratorBlock(Block): \\n     class Input(BlockSchema): \\n         focus: str | None = SchemaField( \\n             description=\" The focus of the list to generate.\", \\n             placeholder=\" The top5most interesting news stories in the data.\", \\n             default=None, \\n             advanced=False, \\n         ) \\n         source_data: str | None = SchemaField( \\n             description=\" The data to generate the list from.\", \\n             placeholder=\" News Today:Humans land on Mars:Today humans landed"
                },
                {
                    "type": "ClassDecl",
                    "name": "Output",
                    "range": [
                        2837,
                        2868
                    ],
                    "children": [
                        {
                            "type": "FieldDecl",
                            "name": "response",
                            "range": [
                                2844,
                                2856
                            ],
                            "children": [],
                            "content": ".\") \\n         list_item: str = SchemaField( \\n             description=\" Each individual item in the list.\", \\n         ) \\n         error: str = SchemaField( \\n             description=\" Error message if"
                        },
                        {
                            "type": "FieldDecl",
                            "name": "error",
                            "range": [
                                2857,
                                2867
                            ],
                            "children": [],
                            "content": "the list generation failed.\" \\n         ) \\n  \\n     def __init__(self): \\n         super().__init__( \\n             id=\"9c0b0450-d199-"
                        }
                    ],
                    "content": "for local models \", \\n         ) \\n  \\n     class Output(BlockSchema): \\n         generated_list: List[str] = SchemaField(description=\" The generated list.\") \\n         list_item: str = SchemaField( \\n             description=\" Each individual item in the list.\", \\n         ) \\n         error: str = SchemaField( \\n             description=\" Error message if the list generation failed.\" \\n         ) \\n  \\n     def __init__(self): \\n         super().__init__( \\n             id=\"9c0b0450-d199-458"
                },
                {
                    "type": "MethodDecl",
                    "name": "__init__",
                    "range": [
                        2869,
                        2965
                    ],
                    "children": [],
                    "content": "b-a731-072189dd6593 \", \\n             description=\" Generate a Python list based on the given prompt using a Large Language Model(LLM).\", \\n             categories={BlockCategory.AI, BlockCategory.TEXT}, \\n             input_schema=AIListGeneratorBlock.Input, \\n             output_schema=AIListGeneratorBlock.Output, \\n             test_input={ \\n                 \" focus\": \"planets \", \\n                 \" source_data \": ( \\n                     \" Zylora Prime is a glowing jungle world with bioluminescent plants,\" \\n                     \" while Kharon-9is a harsh desert planet with underground cities.\" \\n                     \" Vortexia 's constant storms power floating cities, and Oceara is a water-covered world home to \" \\n                     \"intelligent marine life. On icy Draknos, ancient ruins lie buried beneath its frozen landscape, \" \\n                     \"drawing explorers to uncover its mysteries. Each planet showcases the limitless possibilities of \" \\n                     \"fictional worlds.\" \\n                 ), \\n                 \"model\": LlmModel.GPT4_TURBO, \\n                 \"credentials\": TEST_CREDENTIALS_INPUT, \\n                 \"max_retries\": 3, \\n             }, \\n             test_credentials=TEST_CREDENTIALS, \\n             test_output=[ \\n                 ( \\n                     \"generated_list\", \\n                     [\"Zylora Prime\", \"Kharon-9\", \"Vortexia\", \"Oceara\", \"Draknos\"], \\n                 ), \\n                 (\"list_item\", \"Zylora Prime\"), \\n                 (\"list_item\", \"Kharon-9\"), \\n                 (\"list_item\", \"Vortexia\"), \\n                 (\"list_item\", \"Oceara\"), \\n                 (\"list_item\", \"Draknos\"), \\n             ], \\n             test_mock={ \\n                 \"llm_call\": lambda input_data, credentials: { \\n                     \"response\": \"[' Zylora Prime', 'Kharon-9', 'Vortexia', 'Oceara', 'Draknos ']\" \\n                 }, \\n             }, \\n         ) \\n  \\n     @staticmethod \\n     def llm_call( \\n         input_data: AIStructuredResponseGeneratorBlock.Input, \\n         credentials: APIKeyCredentials, \\n     ) -> dict[str, str]: \\n         llm_block = AIStructuredResponseGeneratorBlock() \\n         response = llm_block.run_once(input_data, \"response\", credentials=credentials) \\n         return response \\n  \\n     @staticmethod \\n     def string_to_list(string): \\n         \"\"\" \\n         Converts a string representation of a list into an actual Python list object. \\n         \"\"\" \\n         logger.debug(f\"Converting string to list. Input string: {string}\") \\n         try: \\n             # Use ast.literal_eval to safely evaluate the string \\n             python_list = ast.literal_eval(string) \\n             if isinstance(python_list, list): \\n                 logger.debug(f\"Successfully converted string to list: {python_list}\") \\n                 return python_list \\n             else: \\n                 logger.error(f\"The provided string '{string}' is not a valid list\") \\n                 raise ValueError(f\"The provided string '{string}' is not a valid list.\") \\n         except (SyntaxError, ValueError) as e: \\n             logger.error(f\"Failed to convert string to list: {e}\") \\n             raise ValueError(\"Invalid list format. Could not convert to list.\") \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         logger.debug(f\"Starting AIListGeneratorBlock.run with input data: {input_data}\") \\n  \\n         # Check for API key \\n         api_key_check = credentials.api_key.get_secret_value() \\n         if not api_key_check: \\n             raise ValueError(\"No LLM API key provided.\") \\n  \\n         # Prepare the system prompt \\n         sys_prompt = \"\"\"You are a Python list generator. Your task is to generate a Python list based on the user' s prompt.\n|Respond ONLY with a valid python list.\n|The"
                },
                {
                    "type": "MethodDecl",
                    "name": "llm_call",
                    "range": [
                        2967,
                        3028
                    ],
                    "children": [],
                    "content": "can contain strings,numbers,or nested lists as appropriate.\n|Do not include any explanations or additional text.\n\n|Valid Example string formats:\n\n|Example1:\n|```\n|['1','2','3','4']\n|```\n\n|Example"
                },
                {
                    "type": "MethodDecl",
                    "name": "run",
                    "range": [
                        3029,
                        3102
                    ],
                    "children": [],
                    "content": "2:\n|```\n|[['1','2'],['3','4'],['5','6']]\n|```\n\n|Example3:\n|```\n|['1',['2','3'],['4',['5','6']]]\n|```\n\n|Example"
                }
            ],
            "content": "?\"}, \\n                     { \\n                         \" role\": \"assistant \", \\n                         \" content\": \"The Los Angeles Dodgers won the World Series in2020.\", \\n                     }, \\n                     {\" role\": \"user\", \"content\": \"Where was it played?\"}, \\n                 ], \\n                 \" model \": LlmModel.GPT4_TURBO, \\n                 \" credentials \": TEST_CREDENTIALS_INPUT, \\n             }, \\n             test_credentials=TEST_CREDENTIALS, \\n             test_output=( \\n                 \" response \", \\n                 \" The2020World Series was played at Globe Life Field in Arlington,Texas.\", \\n             ), \\n             test_mock={ \\n                 \" llm_call \": lambda *args, **kwargs: \" The2020World Series was played at Globe Life Field in Arlington,Texas.\" \\n             }, \\n         ) \\n  \\n     def llm_call( \\n         self, \\n         input_data: AIStructuredResponseGeneratorBlock.Input, \\n         credentials: APIKeyCredentials, \\n     ) -> str: \\n         block = AIStructuredResponseGeneratorBlock() \\n         response = block.run_once(input_data, \" response \", credentials=credentials) \\n         self.merge_stats(block.execution_stats) \\n         return response[\" response \"] \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         response = self.llm_call( \\n             AIStructuredResponseGeneratorBlock.Input( \\n                 prompt=\" \", \\n                 credentials=input_data.credentials, \\n                 model=input_data.model, \\n                 conversation_history=input_data.messages, \\n                 max_tokens=input_data.max_tokens, \\n                 expected_format={}, \\n             ), \\n             credentials=credentials, \\n         ) \\n  \\n         yield \" response \", response \\n  \\n  \\n class AIListGeneratorBlock(Block): \\n     class Input(BlockSchema): \\n         focus: str | None = SchemaField( \\n             description=\" The focus of the list to generate.\", \\n             placeholder=\" The top5most interesting news stories in the data.\", \\n             default=None, \\n             advanced=False, \\n         ) \\n         source_data: str | None = SchemaField( \\n             description=\" The data to generate the list from.\", \\n             placeholder=\" News Today:Humans land on Mars:Today humans landed on mars.--AI wins Nobel Prize:AI wins Nobel Prize for solving world hunger.--New AI Model:A new AI model has been released.\", \\n             default=None, \\n             advanced=False, \\n         ) \\n         model: LlmModel = SchemaField( \\n             title=\" LLM Model \", \\n             default=LlmModel.GPT4_TURBO, \\n             description=\" The language model to use for generating the list.\", \\n             advanced=True, \\n         ) \\n         credentials: AICredentials = AICredentialsField() \\n         max_retries: int = SchemaField( \\n             default=3, \\n             description=\" Maximum number of retries for generating a valid list.\", \\n             ge=1, \\n             le=5, \\n         ) \\n         max_tokens: int | None = SchemaField( \\n             advanced=True, \\n             default=None, \\n             description=\" The maximum number of tokens to generate in the chat completion.\", \\n         ) \\n         ollama_host: str = SchemaField( \\n             advanced=True, \\n             default=\" localhost:11434\", \\n             description=\" Ollama host"
        },
        {
            "type": "EnumDeclaration",
            "name": "SummaryStyle",
            "range": [
                3103,
                3126
            ],
            "children": [
                {
                    "type": "EnumMember",
                    "name": "CONCISE",
                    "range": [
                        3110,
                        3112
                    ],
                    "children": [
                        {
                            "type": "Literal",
                            "value": "\"concise\"",
                            "range": [
                                3112,
                                3112
                            ],
                            "content": "["
                        }
                    ],
                    "content": "\n|["
                },
                {
                    "type": "EnumMember",
                    "name": "DETAILED",
                    "range": [
                        3114,
                        3116
                    ],
                    "children": [
                        {
                            "type": "Literal",
                            "value": "\"detailed\"",
                            "range": [
                                3116,
                                3116
                            ],
                            "content": ","
                        }
                    ],
                    "content": ",'b',"
                },
                {
                    "type": "EnumMember",
                    "name": "BULLET_POINTS",
                    "range": [
                        3118,
                        3120
                    ],
                    "children": [
                        {
                            "type": "Literal",
                            "value": "\"bullet points\"",
                            "range": [
                                3120,
                                3120
                            ],
                            "content": "|"
                        }
                    ],
                    "content": "]\n|"
                },
                {
                    "type": "EnumMember",
                    "name": "NUMBERED_LIST",
                    "range": [
                        3122,
                        3124
                    ],
                    "children": [
                        {
                            "type": "Literal",
                            "value": "\"numbered list\"",
                            "range": [
                                3124,
                                3124
                            ],
                            "content": "\n"
                        }
                    ],
                    "content": "``\n"
                }
            ],
            "content": "4:\n|```\n|['a','b','c']\n|```\n\n|"
        },
        {
            "type": "ClassDecl",
            "name": "Input",
            "range": [
                3134,
                3332
            ],
            "children": [
                {
                    "type": "FieldDecl",
                    "name": "text",
                    "range": [
                        3141,
                        3159
                    ],
                    "children": [],
                    "content": ",'string','True',['False','None']]\n|```\n\n|"
                },
                {
                    "type": "FieldDecl",
                    "name": "model",
                    "range": [
                        3160,
                        3185
                    ],
                    "children": [],
                    "content": "Do not include any explanations or additional text,just respond with the list in the format specified above.\n\"\"\" \\n         # If a focus is provided, add it to the prompt \\n         if input_data.focus: \\n             prompt = f\" Generate a list"
                },
                {
                    "type": "FieldDecl",
                    "name": "focus",
                    "range": [
                        3186,
                        3209
                    ],
                    "children": [],
                    "content": "with the following focus:\n<focus>\n\n{input_data.focus}</focus>\" \\n         else: \\n             # If there's source data \\n             if input_data.source_data: \\n                 prompt = \" Extract the main"
                },
                {
                    "type": "FieldDecl",
                    "name": "style",
                    "range": [
                        3210,
                        3235
                    ],
                    "children": [],
                    "content": "focus of the source data to a list.\ni.e if the source data is a news website,the focus would be"
                },
                {
                    "type": "FieldDecl",
                    "name": "credentials",
                    "range": [
                        3236,
                        3243
                    ],
                    "children": [],
                    "content": "the news stories rather than the social links"
                },
                {
                    "type": "FieldDecl",
                    "name": "max_tokens",
                    "range": [
                        3251,
                        3279
                    ],
                    "children": [],
                    "content": "random list.\" \\n  \\n         # If the source data is provided, add it to the prompt \\n         if input_data.source_data: \\n             prompt += f\"\n\nUse the following source data to generate the list from:\n\n<source_data>\n\n{input_data.source_data}"
                },
                {
                    "type": "FieldDecl",
                    "name": "chunk_overlap",
                    "range": [
                        3280,
                        3308
                    ],
                    "children": [],
                    "content": "</source_data>\n\nDo not invent fictional data that is not present in the source data.\" \\n         # Else, tell the LLM to synthesize the data \\n         else: \\n             prompt += \"\n\nInvent the data to generate the"
                },
                {
                    "type": "FieldDecl",
                    "name": "ollama_host",
                    "range": [
                        3309,
                        3332
                    ],
                    "children": [],
                    "content": "list from.\" \\n  \\n         for attempt in range(input_data.max_retries): \\n             try: \\n                 logger.debug(\" Calling LLM \") \\n                 llm_response = self.llm_call( \\n                     AIStructuredResponseGeneratorBlock.Input( \\n                         sys_prompt=sys_prompt, \\n                         prompt=prompt, \\n                         credentials=input_data.credentials, \\n                         model=input_data.model, \\n                         expected_format={},  # Do not use structured response \\n                         ollama_host=input_data.ollama_host, \\n                     ), \\n                     credentials=credentials, \\n                 ) \\n  \\n                 logger.debug(f\" LLM response:{llm_response}\") \\n  \\n                 # Extract Response string \\n                 response_string = llm_response[\" response \"] \\n                 logger.debug(f\" Response string:{response_string}\") \\n  \\n                 # Convert the string to a Python list \\n                 logger.debug(\" Converting"
                }
            ],
            "content": "`\n|['1','2.5','string','True',['False','None']]\n|```\n\n|Do not include any explanations or additional text,just respond with the list in the format specified above.\n\"\"\" \\n         # If a focus is provided, add it to the prompt \\n         if input_data.focus: \\n             prompt = f\" Generate a list with the following focus:\n<focus>\n\n{input_data.focus}</focus>\" \\n         else: \\n             # If there's source data \\n             if input_data.source_data: \\n                 prompt = \" Extract the main focus of the source data to a list.\ni.e if the source data is a news website,the focus would be the news stories rather than the social links in the footer.\" \\n             else: \\n                 # No focus or source data provided, generat a random list \\n                 prompt = \" Generate a random list.\" \\n  \\n         # If the source data is provided, add it to the prompt \\n         if input_data.source_data: \\n             prompt += f\"\n\nUse the following source data to generate the list from:\n\n<source_data>\n\n{input_data.source_data}</source_data>\n\nDo not invent fictional data that is not present in the source data.\" \\n         # Else, tell the LLM to synthesize the data \\n         else: \\n             prompt += \"\n\nInvent the data to generate the list from.\" \\n  \\n         for attempt in range(input_data.max_retries): \\n             try: \\n                 logger.debug(\" Calling LLM \") \\n                 llm_response = self.llm_call( \\n                     AIStructuredResponseGeneratorBlock.Input( \\n                         sys_prompt=sys_prompt, \\n                         prompt=prompt, \\n                         credentials=input_data.credentials, \\n                         model=input_data.model, \\n                         expected_format={},  # Do not use structured response \\n                         ollama_host=input_data.ollama_host, \\n                     ), \\n                     credentials=credentials, \\n                 ) \\n  \\n                 logger.debug(f\" LLM response:{llm_response}\") \\n  \\n                 # Extract Response string \\n                 response_string = llm_response[\" response \"] \\n                 logger.debug(f\" Response string:{response_string}\") \\n  \\n                 # Convert the string to a Python list \\n                 logger.debug(\" Converting"
        },
        {
            "type": "ClassDecl",
            "name": "Output",
            "range": [
                3334,
                3362
            ],
            "children": [
                {
                    "type": "FieldDecl",
                    "name": "summary",
                    "range": [
                        3341,
                        3351
                    ],
                    "children": [],
                    "content": "{parsed_list}\") \\n  \\n                 # If we reach here, we have a valid Python list \\n                 logger.debug(\" Successfully generated a valid Python list \") \\n                 yield \""
                },
                {
                    "type": "FieldDecl",
                    "name": "error",
                    "range": [
                        3352,
                        3362
                    ],
                    "children": [],
                    "content": "generated_list \", parsed_list \\n  \\n                 # Yield each item in the list \\n                 for item in parsed_list: \\n                     yield \" list_item \", item \\n                 return \\n  \\n             except Exception as e: \\n                 logger.error(f\" Error in attempt{attempt+1"
                }
            ],
            "content": "to Python list \") \\n                 parsed_list = self.string_to_list(response_string) \\n                 logger.debug(f\" Parsed list:{parsed_list}\") \\n  \\n                 # If we reach here, we have a valid Python list \\n                 logger.debug(\" Successfully generated a valid Python list \") \\n                 yield \" generated_list \", parsed_list \\n  \\n                 # Yield each item in the list \\n                 for item in parsed_list: \\n                     yield \" list_item \", item \\n                 return \\n  \\n             except Exception as e: \\n                 logger.error(f\" Error in attempt{attempt+1"
        },
        {
            "type": "FunctionDecl",
            "name": "__init__",
            "range": [
                3364,
                3487
            ],
            "children": [],
            "content": ":{str(e)}\") \\n                 if attempt == input_data.max_retries - 1: \\n                     logger.error( \\n                         f\" Failed to generate a valid Python list after{input_data.max_retries}attempts \" \\n                     ) \\n                     raise RuntimeError( \\n                         f\" Failed to generate a valid Python list after{input_data.max_retries}attempts.Last error:{str(e)}\" \\n                     ) \\n                 else: \\n                     # Add a retry prompt \\n                     logger.debug(\" Preparing retry prompt \") \\n                     prompt = f\"\"\"\nThe previous attempt failed due to`{e}`\nGenerate a valid Python list based on the original prompt.\nRemember to respond ONLY with a valid Python list as per the format specified earlier.\nOriginal prompt:\n```{prompt}```\n\nRespond only with the list in the format specified with no commentary or apologies"
        },
        {
            "type": "FunctionDecl",
            "name": "run",
            "range": [
                3489,
                3531
            ],
            "children": [],
            "content": "\n\"\"\" \\n                     logger.debug(f\" Retry prompt:{prompt}\") \\n  \\n         logger.debug(\" AIListGeneratorBlock.run completed\")\n"
        },
        {
            "type": "FunctionDecl",
            "name": "_run",
            "range": [
                3532,
                3622
            ],
            "children": [],
            "content": ""
        },
        {
            "type": "FunctionDecl",
            "name": "_split_text",
            "range": [
                3626,
                3712
            ],
            "children": [],
            "content": ""
        },
        {
            "type": "FunctionDecl",
            "name": "llm_call",
            "range": [
                3713,
                3771
            ],
            "children": [],
            "content": ""
        },
        {
            "type": "FunctionDecl",
            "name": "_summarize_chunk",
            "range": [
                3772,
                3859
            ],
            "children": [],
            "content": ""
        },
        {
            "type": "FunctionDecl",
            "name": "_combine_summaries",
            "range": [
                3860,
                4063
            ],
            "children": [],
            "content": ""
        },
        {
            "type": "ClassDecl",
            "name": "AIConversationBlock",
            "range": [
                4065,
                4071
            ],
            "children": [
                {
                    "type": "Inheritance",
                    "name": "Block",
                    "range": [
                        4067,
                        4069
                    ],
                    "children": [],
                    "content": ""
                }
            ],
            "content": ""
        },
        {
            "type": "ClassDecl",
            "name": "Input",
            "range": [
                4072,
                4078
            ],
            "children": [
                {
                    "type": "Inheritance",
                    "name": "BlockSchema",
                    "range": [
                        4074,
                        4076
                    ],
                    "children": [],
                    "content": ""
                }
            ],
            "content": ""
        },
        {
            "type": "VariableDecl",
            "name": "messages",
            "range": [
                4079,
                4098
            ],
            "children": [
                {
                    "type": "TypeAnnotation",
                    "name": "List[Message]",
                    "range": [
                        4081,
                        4084
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Assignment",
                    "name": "SchemaField",
                    "range": [
                        4086,
                        4097
                    ],
                    "children": [
                        {
                            "type": "Argument",
                            "name": "description",
                            "range": [
                                4089,
                                4091
                            ],
                            "children": [],
                            "content": ""
                        },
                        {
                            "type": "Argument",
                            "name": "min_length",
                            "range": [
                                4093,
                                4095
                            ],
                            "children": [],
                            "content": ""
                        }
                    ],
                    "content": ""
                }
            ],
            "content": ""
        },
        {
            "type": "VariableDecl",
            "name": "model",
            "range": [
                4099,
                4124
            ],
            "children": [
                {
                    "type": "TypeAnnotation",
                    "name": "LlmModel",
                    "range": [
                        4101,
                        4101
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Assignment",
                    "name": "SchemaField",
                    "range": [
                        4103,
                        4123
                    ],
                    "children": [
                        {
                            "type": "Argument",
                            "name": "title",
                            "range": [
                                4106,
                                4108
                            ],
                            "children": [],
                            "content": ""
                        },
                        {
                            "type": "Argument",
                            "name": "default",
                            "range": [
                                4111,
                                4115
                            ],
                            "children": [],
                            "content": ""
                        },
                        {
                            "type": "Argument",
                            "name": "description",
                            "range": [
                                4118,
                                4120
                            ],
                            "children": [],
                            "content": ""
                        }
                    ],
                    "content": ""
                }
            ],
            "content": ""
        },
        {
            "type": "VariableDecl",
            "name": "credentials",
            "range": [
                4125,
                4132
            ],
            "children": [
                {
                    "type": "TypeAnnotation",
                    "name": "AICredentials",
                    "range": [
                        4127,
                        4127
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Assignment",
                    "name": "AICredentialsField",
                    "range": [
                        4129,
                        4131
                    ],
                    "children": [],
                    "content": ""
                }
            ],
            "content": ""
        },
        {
            "type": "VariableDecl",
            "name": "max_tokens",
            "range": [
                4133,
                4158
            ],
            "children": [
                {
                    "type": "TypeAnnotation",
                    "name": "int | None",
                    "range": [
                        4135,
                        4137
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Assignment",
                    "name": "SchemaField",
                    "range": [
                        4139,
                        4157
                    ],
                    "children": [
                        {
                            "type": "Argument",
                            "name": "advanced",
                            "range": [
                                4142,
                                4144
                            ],
                            "children": [],
                            "content": ""
                        },
                        {
                            "type": "Argument",
                            "name": "default",
                            "range": [
                                4147,
                                4149
                            ],
                            "children": [],
                            "content": ""
                        },
                        {
                            "type": "Argument",
                            "name": "description",
                            "range": [
                                4152,
                                4154
                            ],
                            "children": [],
                            "content": ""
                        }
                    ],
                    "content": ""
                }
            ],
            "content": ""
        },
        {
            "type": "VariableDecl",
            "name": "ollama_host",
            "range": [
                4159,
                4182
            ],
            "children": [
                {
                    "type": "TypeAnnotation",
                    "name": "str",
                    "range": [
                        4161,
                        4161
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Assignment",
                    "name": "SchemaField",
                    "range": [
                        4163,
                        4181
                    ],
                    "children": [
                        {
                            "type": "Argument",
                            "name": "advanced",
                            "range": [
                                4166,
                                4168
                            ],
                            "children": [],
                            "content": ""
                        },
                        {
                            "type": "Argument",
                            "name": "default",
                            "range": [
                                4171,
                                4173
                            ],
                            "children": [],
                            "content": ""
                        },
                        {
                            "type": "Argument",
                            "name": "description",
                            "range": [
                                4176,
                                4178
                            ],
                            "children": [],
                            "content": ""
                        }
                    ],
                    "content": ""
                }
            ],
            "content": ""
        },
        {
            "type": "ClassDecl",
            "name": "Output",
            "range": [
                4184,
                4190
            ],
            "children": [
                {
                    "type": "Inheritance",
                    "name": "BlockSchema",
                    "range": [
                        4186,
                        4188
                    ],
                    "children": [],
                    "content": ""
                }
            ],
            "content": ""
        },
        {
            "type": "VariableDecl",
            "name": "response",
            "range": [
                4191,
                4203
            ],
            "children": [
                {
                    "type": "TypeAnnotation",
                    "name": "str",
                    "range": [
                        4193,
                        4193
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Assignment",
                    "name": "SchemaField",
                    "range": [
                        4195,
                        4202
                    ],
                    "children": [
                        {
                            "type": "Argument",
                            "name": "description",
                            "range": [
                                4198,
                                4200
                            ],
                            "children": [],
                            "content": ""
                        }
                    ],
                    "content": ""
                }
            ],
            "content": ""
        },
        {
            "type": "VariableDecl",
            "name": "error",
            "range": [
                4204,
                4214
            ],
            "children": [
                {
                    "type": "TypeAnnotation",
                    "name": "str",
                    "range": [
                        4206,
                        4206
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Assignment",
                    "name": "SchemaField",
                    "range": [
                        4208,
                        4213
                    ],
                    "children": [
                        {
                            "type": "Argument",
                            "name": "description",
                            "range": [
                                4210,
                                4212
                            ],
                            "children": [],
                            "content": ""
                        }
                    ],
                    "content": ""
                }
            ],
            "content": ""
        },
        {
            "type": "FunctionDecl",
            "name": "__init__",
            "range": [
                4216,
                4375
            ],
            "children": [
                {
                    "type": "Parameter",
                    "name": "self",
                    "range": [
                        4219,
                        4219
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "SuperCall",
                    "name": "super",
                    "range": [
                        4223,
                        4227
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Assignment",
                    "name": "id",
                    "range": [
                        4230,
                        4232
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Assignment",
                    "name": "description",
                    "range": [
                        4235,
                        4237
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Assignment",
                    "name": "categories",
                    "range": [
                        4240,
                        4246
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Assignment",
                    "name": "input_schema",
                    "range": [
                        4249,
                        4253
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Assignment",
                    "name": "output_schema",
                    "range": [
                        4256,
                        4260
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Assignment",
                    "name": "test_input",
                    "range": [
                        4263,
                        4334
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Assignment",
                    "name": "test_credentials",
                    "range": [
                        4337,
                        4339
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Assignment",
                    "name": "test_output",
                    "range": [
                        4342,
                        4352
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Assignment",
                    "name": "test_mock",
                    "range": [
                        4355,
                        4371
                    ],
                    "children": [],
                    "content": ""
                }
            ],
            "content": ""
        },
        {
            "type": "FunctionDecl",
            "name": "llm_call",
            "range": [
                4377,
                4437
            ],
            "children": [
                {
                    "type": "Parameter",
                    "name": "self",
                    "range": [
                        4381,
                        4381
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Parameter",
                    "name": "input_data",
                    "range": [
                        4384,
                        4388
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Parameter",
                    "name": "credentials",
                    "range": [
                        4391,
                        4393
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "ReturnType",
                    "name": "str",
                    "range": [
                        4399,
                        4399
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Assignment",
                    "name": "block",
                    "range": [
                        4402,
                        4406
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Assignment",
                    "name": "response",
                    "range": [
                        4408,
                        4421
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "MethodCall",
                    "name": "merge_stats",
                    "range": [
                        4423,
                        4430
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "ReturnStatement",
                    "name": "response",
                    "range": [
                        4432,
                        4436
                    ],
                    "children": [],
                    "content": ""
                }
            ],
            "content": ""
        },
        {
            "type": "FunctionDecl",
            "name": "run",
            "range": [
                4439,
                4532
            ],
            "children": [
                {
                    "type": "Parameter",
                    "name": "self",
                    "range": [
                        4443,
                        4443
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Parameter",
                    "name": "input_data",
                    "range": [
                        4445,
                        4447
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Parameter",
                    "name": "credentials",
                    "range": [
                        4451,
                        4453
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "ReturnType",
                    "name": "BlockOutput",
                    "range": [
                        4462,
                        4462
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "Assignment",
                    "name": "response",
                    "range": [
                        4465,
                        4524
                    ],
                    "children": [],
                    "content": ""
                },
                {
                    "type": "YieldStatement",
                    "name": "response",
                    "range": [
                        4527,
                        4531
                    ],
                    "children": [],
                    "content": ""
                }
            ],
            "content": ""
        },
        {
            "type": "ClassDecl",
            "name": "AIListGeneratorBlock",
            "range": [
                4533,
                4577
            ],
            "children": [
                {
                    "type": "ClassBody",
                    "name": "",
                    "range": [
                        4535,
                        4577
                    ],
                    "children": [
                        {
                            "type": "ClassInheritance",
                            "name": "Block",
                            "range": [
                                4535,
                                4537
                            ],
                            "children": [],
                            "content": ""
                        }
                    ],
                    "content": ""
                }
            ],
            "content": ""
        },
        {
            "type": "ClassDecl",
            "name": "Input",
            "range": [
                4540,
                4647
            ],
            "children": [
                {
                    "type": "ClassBody",
                    "name": "",
                    "range": [
                        4542,
                        4647
                    ],
                    "children": [
                        {
                            "type": "ClassInheritance",
                            "name": "BlockSchema",
                            "range": [
                                4542,
                                4544
                            ],
                            "children": [],
                            "content": ""
                        },
                        {
                            "type": "FieldDecl",
                            "name": "focus",
                            "range": [
                                4547,
                                4576
                            ],
                            "children": [
                                {
                                    "type": "TypeAnnotation",
                                    "name": "str | None",
                                    "range": [
                                        4549,
                                        4551
                                    ],
                                    "children": [],
                                    "content": ""
                                },
                                {
                                    "type": "Assignment",
                                    "name": "=",
                                    "range": [
                                        4552,
                                        4576
                                    ],
                                    "children": [
                                        {
                                            "type": "SchemaField",
                                            "name": "SchemaField",
                                            "range": [
                                                4553,
                                                4576
                                            ],
                                            "children": [
                                                {
                                                    "type": "Arguments",
                                                    "name": "",
                                                    "range": [
                                                        4554,
                                                        4576
                                                    ],
                                                    "children": [
                                                        {
                                                            "type": "Argument",
                                                            "name": "description",
                                                            "range": [
                                                                4556,
                                                                4558
                                                            ],
                                                            "children": [],
                                                            "content": ""
                                                        },
                                                        {
                                                            "type": "Argument",
                                                            "name": "placeholder",
                                                            "range": [
                                                                4561,
                                                                4563
                                                            ],
                                                            "children": [],
                                                            "content": ""
                                                        },
                                                        {
                                                            "type": "Argument",
                                                            "name": "default",
                                                            "range": [
                                                                4566,
                                                                4568
                                                            ],
                                                            "children": [],
                                                            "content": ""
                                                        },
                                                        {
                                                            "type": "Argument",
                                                            "name": "advanced",
                                                            "range": [
                                                                4571,
                                                                4573
                                                            ],
                                                            "children": [],
                                                            "content": ""
                                                        }
                                                    ],
                                                    "content": ""
                                                }
                                            ],
                                            "content": ""
                                        }
                                    ],
                                    "content": ""
                                }
                            ],
                            "content": ""
                        },
                        {
                            "type": "FieldDecl",
                            "name": "source_data",
                            "range": [
                                4578,
                                4607
                            ],
                            "children": [
                                {
                                    "type": "TypeAnnotation",
                                    "name": "str | None",
                                    "range": [
                                        4580,
                                        4582
                                    ],
                                    "children": [],
                                    "content": ""
                                },
                                {
                                    "type": "Assignment",
                                    "name": "=",
                                    "range": [
                                        4583,
                                        4607
                                    ],
                                    "children": [
                                        {
                                            "type": "SchemaField",
                                            "name": "SchemaField",
                                            "range": [
                                                4584,
                                                4607
                                            ],
                                            "children": [
                                                {
                                                    "type": "Arguments",
                                                    "name": "",
                                                    "range": [
                                                        4585,
                                                        4607
                                                    ],
                                                    "children": [
                                                        {
                                                            "type": "Argument",
                                                            "name": "description",
                                                            "range": [
                                                                4587,
                                                                4589
                                                            ],
                                                            "children": [],
                                                            "content": ""
                                                        },
                                                        {
                                                            "type": "Argument",
                                                            "name": "placeholder",
                                                            "range": [
                                                                4592,
                                                                4594
                                                            ],
                                                            "children": [],
                                                            "content": ""
                                                        },
                                                        {
                                                            "type": "Argument",
                                                            "name": "default",
                                                            "range": [
                                                                4597,
                                                                4599
                                                            ],
                                                            "children": [],
                                                            "content": ""
                                                        },
                                                        {
                                                            "type": "Argument",
                                                            "name": "advanced",
                                                            "range": [
                                                                4602,
                                                                4604
                                                            ],
                                                            "children": [],
                                                            "content": ""
                                                        }
                                                    ],
                                                    "content": ""
                                                }
                                            ],
                                            "content": ""
                                        }
                                    ],
                                    "content": ""
                                }
                            ],
                            "content": ""
                        },
                        {
                            "type": "FieldDecl",
                            "name": "model",
                            "range": [
                                4609,
                                4639
                            ],
                            "children": [
                                {
                                    "type": "TypeAnnotation",
                                    "name": "LlmModel",
                                    "range": [
                                        4611,
                                        4611
                                    ],
                                    "children": [],
                                    "content": ""
                                },
                                {
                                    "type": "Assignment",
                                    "name": "=",
                                    "range": [
                                        4612,
                                        4639
                                    ],
                                    "children": [
                                        {
                                            "type": "SchemaField",
                                            "name": "SchemaField",
                                            "range": [
                                                4613,
                                                4639
                                            ],
                                            "children": [
                                                {
                                                    "type": "Arguments",
                                                    "name": "",
                                                    "range": [
                                                        4614,
                                                        4639
                                                    ],
                                                    "children": [
                                                        {
                                                            "type": "Argument",
                                                            "name": "title",
                                                            "range": [
                                                                4616,
                                                                4618
                                                            ],
                                                            "children": [],
                                                            "content": ""
                                                        },
                                                        {
                                                            "type": "Argument",
                                                            "name": "default",
                                                            "range": [
                                                                4621,
                                                                4626
                                                            ],
                                                            "children": [],
                                                            "content": ""
                                                        },
                                                        {
                                                            "type": "Argument",
                                                            "name": "description",
                                                            "range": [
                                                                4628,
                                                                4630
                                                            ],
                                                            "children": [],
                                                            "content": ""
                                                        },
                                                        {
                                                            "type": "Argument",
                                                            "name": "advanced",
                                                            "range": [
                                                                4633,
                                                                4635
                                                            ],
                                                            "children": [],
                                                            "content": ""
                                                        }
                                                    ],
                                                    "content": ""
                                                }
                                            ],
                                            "content": ""
                                        }
                                    ],
                                    "content": ""
                                }
                            ],
                            "content": ""
                        },
                        {
                            "type": "FieldDecl",
                            "name": "credentials",
                            "range": [
                                4640,
                                4647
                            ],
                            "children": [
                                {
                                    "type": "TypeAnnotation",
                                    "name": "AICredentials",
                                    "range": [
                                        4642,
                                        4642
                                    ],
                                    "children": [],
                                    "content": ""
                                },
                                {
                                    "type": "Assignment",
                                    "name": "=",
                                    "range": [
                                        4643,
                                        4647
                                    ],
                                    "children": [
                                        {
                                            "type": "AICredentialsField",
                                            "name": "AICredentialsField",
                                            "range": [
                                                4644,
                                                4647
                                            ],
                                            "children": [],
                                            "content": ""
                                        }
                                    ],
                                    "content": ""
                                }
                            ],
                            "content": ""
                        }
                    ],
                    "content": ""
                }
            ],
            "content": ""
        },
        {
            "type": "ClassDecl",
            "name": "Output",
            "range": [
                4728,
                4775
            ],
            "children": [
                {
                    "type": "ClassBody",
                    "name": "",
                    "range": [
                        4730,
                        4775
                    ],
                    "children": [
                        {
                            "type": "ClassInheritance",
                            "name": "BlockSchema",
                            "range": [
                                4730,
                                4732
                            ],
                            "children": [],
                            "content": ""
                        },
                        {
                            "type": "FieldDecl",
                            "name": "generated_list",
                            "range": [
                                4735,
                                4747
                            ],
                            "children": [
                                {
                                    "type": "TypeAnnotation",
                                    "name": "List[str]",
                                    "range": [
                                        4737,
                                        4740
                                    ],
                                    "children": [],
                                    "content": ""
                                },
                                {
                                    "type": "Assignment",
                                    "name": "=",
                                    "range": [
                                        4741,
                                        4747
                                    ],
                                    "children": [
                                        {
                                            "type": "SchemaField",
                                            "name": "SchemaField",
                                            "range": [
                                                4742,
                                                4747
                                            ],
                                            "children": [
                                                {
                                                    "type": "Arguments",
                                                    "name": "",
                                                    "range": [
                                                        4743,
                                                        4747
                                                    ],
                                                    "children": [
                                                        {
                                                            "type": "Argument",
                                                            "name": "description",
                                                            "range": [
                                                                4745,
                                                                4746
                                                            ],
                                                            "children": [],
                                                            "content": ""
                                                        }
                                                    ],
                                                    "content": ""
                                                }
                                            ],
                                            "content": ""
                                        }
                                    ],
                                    "content": ""
                                }
                            ],
                            "content": ""
                        },
                        {
                            "type": "FieldDecl",
                            "name": "list_item",
                            "range": [
                                4749,
                                4761
                            ],
                            "children": [
                                {
                                    "type": "TypeAnnotation",
                                    "name": "str",
                                    "range": [
                                        4751,
                                        4751
                                    ],
                                    "children": [],
                                    "content": ""
                                },
                                {
                                    "type": "Assignment",
                                    "name": "=",
                                    "range": [
                                        4752,
                                        4761
                                    ],
                                    "children": [
                                        {
                                            "type": "SchemaField",
                                            "name": "SchemaField",
                                            "range": [
                                                4753,
                                                4761
                                            ],
                                            "children": [
                                                {
                                                    "type": "Arguments",
                                                    "name": "",
                                                    "range": [
                                                        4754,
                                                        4761
                                                    ],
                                                    "children": [
                                                        {
                                                            "type": "Argument",
                                                            "name": "description",
                                                            "range": [
                                                                4756,
                                                                4758
                                                            ],
                                                            "children": [],
                                                            "content": ""
                                                        }
                                                    ],
                                                    "content": ""
                                                }
                                            ],
                                            "content": ""
                                        }
                                    ],
                                    "content": ""
                                }
                            ],
                            "content": ""
                        },
                        {
                            "type": "FieldDecl",
                            "name": "error",
                            "range": [
                                4763,
                                4774
                            ],
                            "children": [
                                {
                                    "type": "TypeAnnotation",
                                    "name": "str",
                                    "range": [
                                        4765,
                                        4765
                                    ],
                                    "children": [],
                                    "content": ""
                                },
                                {
                                    "type": "Assignment",
                                    "name": "=",
                                    "range": [
                                        4766,
                                        4774
                                    ],
                                    "children": [
                                        {
                                            "type": "SchemaField",
                                            "name": "SchemaField",
                                            "range": [
                                                4767,
                                                4774
                                            ],
                                            "children": [
                                                {
                                                    "type": "Arguments",
                                                    "name": "",
                                                    "range": [
                                                        4768,
                                                        4774
                                                    ],
                                                    "children": [
                                                        {
                                                            "type": "Argument",
                                                            "name": "description",
                                                            "range": [
                                                                4770,
                                                                4772
                                                            ],
                                                            "children": [],
                                                            "content": ""
                                                        }
                                                    ],
                                                    "content": ""
                                                }
                                            ],
                                            "content": ""
                                        }
                                    ],
                                    "content": ""
                                }
                            ],
                            "content": ""
                        }
                    ],
                    "content": ""
                }
            ],
            "content": ""
        },
        {
            "type": "FunctionDecl",
            "name": "__init__",
            "range": [
                4777,
                4968
            ],
            "children": [
                {
                    "type": "FunctionParameters",
                    "name": "",
                    "range": [
                        4779,
                        4781
                    ],
                    "children": [
                        {
                            "type": "Parameter",
                            "name": "self",
                            "range": [
                                4780,
                                4780
                            ],
                            "children": [],
                            "content": ""
                        }
                    ],
                    "content": ""
                },
                {
                    "type": "FunctionBody",
                    "name": "",
                    "range": [
                        4782,
                        4968
                    ],
                    "children": [
                        {
                            "type": "SuperCall",
                            "name": "super",
                            "range": [
                                4784,
                                4790
                            ],
                            "children": [
                                {
                                    "type": "Arguments",
                                    "name": "",
                                    "range": [
                                        4785,
                                        4786
                                    ],
                                    "children": [],
                                    "content": ""
                                }
                            ],
                            "content": ""
                        },
                        {
                            "type": "MethodCall",
                            "name": "__init__",
                            "range": [
                                4787,
                                4790
                            ],
                            "children": [
                                {
                                    "type": "Arguments",
                                    "name": "",
                                    "range": [
                                        4788,
                                        4790
                                    ],
                                    "children": [
                                        {
                                            "type": "Argument",
                                            "name": "id",
                                            "range": [
                                                4791,
                                                4793
                                            ],
                                            "children": [],
                                            "content": ""
                                        },
                                        {
                                            "type": "Argument",
                                            "name": "description",
                                            "range": [
                                                4796,
                                                4798
                                            ],
                                            "children": [],
                                            "content": ""
                                        },
                                        {
                                            "type": "Argument",
                                            "name": "categories",
                                            "range": [
                                                4801,
                                                4811
                                            ],
                                            "children": [],
                                            "content": ""
                                        },
                                        {
                                            "type": "Argument",
                                            "name": "input_schema",
                                            "range": [
                                                4814,
                                                4818
                                            ],
                                            "children": [],
                                            "content": ""
                                        },
                                        {
                                            "type": "Argument",
                                            "name": "output_schema",
                                            "range": [
                                                4821,
                                                4825
                                            ],
                                            "children": [],
                                            "content": ""
                                        },
                                        {
                                            "type": "Argument",
                                            "name": "test_input",
                                            "range": [
                                                4828,
                                                4873
                                            ],
                                            "children": [],
                                            "content": ""
                                        },
                                        {
                                            "type": "Argument",
                                            "name": "test_credentials",
                                            "range": [
                                                4876,
                                                4878
                                            ],
                                            "children": [],
                                            "content": ""
                                        },
                                        {
                                            "type": "Argument",
                                            "name": "test_output",
                                            "range": [
                                                4881,
                                                4941
                                            ],
                                            "children": [],
                                            "content": ""
                                        },
                                        {
                                            "type": "Argument",
                                            "name": "test_mock",
                                            "range": [
                                                4944,
                                                4964
                                            ],
                                            "children": [],
                                            "content": ""
                                        }
                                    ],
                                    "content": ""
                                }
                            ],
                            "content": ""
                        }
                    ],
                    "content": ""
                }
            ],
            "content": ""
        },
        {
            "type": "FunctionDecl",
            "name": "llm_call",
            "range": [
                4973,
                5023
            ],
            "children": [
                {
                    "type": "FunctionParameters",
                    "name": "",
                    "range": [
                        4975,
                        4989
                    ],
                    "children": [
                        {
                            "type": "Parameter",
                            "name": "input_data",
                            "range": [
                                4977,
                                4981
                            ],
                            "children": [],
                            "content": ""
                        },
                        {
                            "type": "Parameter",
                            "name": "credentials",
                            "range": [
                                4984,
                                4986
                            ],
                            "children": [],
                            "content": ""
                        }
                    ],
                    "content": ""
                },
                {
                    "type": "FunctionBody",
                    "name": "",
                    "range": [
                        4990,
                        5023
                    ],
                    "children": [
                        {
                            "type": "VariableDecl",
                            "name": "llm_block",
                            "range": [
                                5000,
                                5005
                            ],
                            "children": [
                                {
                                    "type": "Assignment",
                                    "name": "=",
                                    "range": [
                                        5001,
                                        5005
                                    ],
                                    "children": [
                                        {
                                            "type": "NewExpression",
                                            "name": "AIStructuredResponseGeneratorBlock",
                                            "range": [
                                                5002,
                                                5005
                                            ],
                                            "children": [],
                                            "content": ""
                                        }
                                    ],
                                    "content": ""
                                }
                            ],
                            "content": ""
                        },
                        {
                            "type": "VariableDecl",
                            "name": "response",
                            "range": [
                                5006,
                                5020
                            ],
                            "children": [
                                {
                                    "type": "Assignment",
                                    "name": "=",
                                    "range": [
                                        5007,
                                        5020
                                    ],
                                    "children": [
                                        {
                                            "type": "MethodCall",
                                            "name": "run_once",
                                            "range": [
                                                5008,
                                                5019
                                            ],
                                            "children": [
                                                {
                                                    "type": "Arguments",
                                                    "name": "",
                                                    "range": [
                                                        5009,
                                                        5019
                                                    ],
                                                    "children": [
                                                        {
                                                            "type": "Argument",
                                                            "name": "input_data",
                                                            "range": [
                                                                5012,
                                                                5012
                                                            ],
                                                            "children": [],
                                                            "content": ""
                                                        },
                                                        {
                                                            "type": "Argument",
                                                            "name": "response",
                                                            "range": [
                                                                5014,
                                                                5014
                                                            ],
                                                            "children": [],
                                                            "content": ""
                                                        },
                                                        {
                                                            "type": "Argument",
                                                            "name": "credentials",
                                                            "range": [
                                                                5016,
                                                                5018
                                                            ],
                                                            "children": [],
                                                            "content": ""
                                                        }
                                                    ],
                                                    "content": ""
                                                }
                                            ],
                                            "content": ""
                                        }
                                    ],
                                    "content": ""
                                }
                            ],
                            "content": ""
                        },
                        {
                            "type": "ReturnStatement",
                            "name": "return",
                            "range": [
                                5021,
                                5023
                            ],
                            "children": [
                                {
                                    "type": "Identifier",
                                    "name": "response",
                                    "range": [
                                        5022,
                                        5022
                                    ],
                                    "children": [],
                                    "content": ""
                                }
                            ],
                            "content": ""
                        }
                    ],
                    "content": ""
                }
            ],
            "content": ""
        },
        {
            "type": "FunctionDecl",
            "name": "string_to_list",
            "range": [
                5028,
                5131
            ],
            "children": [
                {
                    "type": "FunctionParameters",
                    "name": "",
                    "range": [
                        5030,
                        5032
                    ],
                    "children": [
                        {
                            "type": "Parameter",
                            "name": "string",
                            "range": [
                                5031,
                                5031
                            ],
                            "children": [],
                            "content": ""
                        }
                    ],
                    "content": ""
                },
                {
                    "type": "FunctionBody",
                    "name": "",
                    "range": [
                        5033,
                        5131
                    ],
                    "children": [
                        {
                            "type": "TryStatement",
                            "name": "try",
                            "range": [
                                5047,
                                5131
                            ],
                            "children": [
                                {
                                    "type": "Block",
                                    "name": "",
                                    "range": [
                                        5048,
                                        5107
                                    ],
                                    "children": [
                                        {
                                            "type": "VariableDecl",
                                            "name": "python_list",
                                            "range": [
                                                5061,
                                                5069
                                            ],
                                            "children": [
                                                {
                                                    "type": "Assignment",
                                                    "name": "=",
                                                    "range": [
                                                        5062,
                                                        5069
                                                    ],
                                                    "children": [
                                                        {
                                                            "type": "CallExpression",
                                                            "name": "literal_eval",
                                                            "range": [
                                                                5063,
                                                                5068
                                                            ],
                                                            "children": [
                                                                {
                                                                    "type": "Arguments",
                                                                    "name": "",
                                                                    "range": [
                                                                        5064,
                                                                        5068
                                                                    ],
                                                                    "children": [
                                                                        {
                                                                            "type": "Argument",
                                                                            "name": "string",
                                                                            "range": [
                                                                                5067,
                                                                                5067
                                                                            ],
                                                                            "children": [],
                                                                            "content": ""
                                                                        }
                                                                    ],
                                                                    "content": ""
                                                                }
                                                            ],
                                                            "content": ""
                                                        }
                                                    ],
                                                    "content": ""
                                                }
                                            ],
                                            "content": ""
                                        },
                                        {
                                            "type": "IfStatement",
                                            "name": "if",
                                            "range": [
                                                5070,
                                                5101
                                            ],
                                            "children": [
                                                {
                                                    "type": "Condition",
                                                    "name": "isinstance",
                                                    "range": [
                                                        5071,
                                                        5076
                                                    ],
                                                    "children": [
                                                        {
                                                            "type": "Arguments",
                                                            "name": "",
                                                            "range": [
                                                                5072,
                                                                5076
                                                            ],
                                                            "children": [
                                                                {
                                                                    "type": "Argument",
                                                                    "name": "python_list",
                                                                    "range": [
                                                                        5073,
                                                                        5073
                                                                    ],
                                                                    "children": [],
                                                                    "content": ""
                                                                },
                                                                {
                                                                    "type": "Argument",
                                                                    "name": "list",
                                                                    "range": [
                                                                        5075,
                                                                        5075
                                                                    ],
                                                                    "children": [],
                                                                    "content": ""
                                                                }
                                                            ],
                                                            "content": ""
                                                        }
                                                    ],
                                                    "content": ""
                                                },
                                                {
                                                    "type": "Block",
                                                    "name": "",
                                                    "range": [
                                                        5077,
                                                        5089
                                                    ],
                                                    "children": [
                                                        {
                                                            "type": "ReturnStatement",
                                                            "name": "return",
                                                            "range": [
                                                                5087,
                                                                5089
                                                            ],
                                                            "children": [
                                                                {
                                                                    "type": "Identifier",
                                                                    "name": "python_list",
                                                                    "range": [
                                                                        5088,
                                                                        5088
                                                                    ],
                                                                    "children": [],
                                                                    "content": ""
                                                                }
                                                            ],
                                                            "content": ""
                                                        }
                                                    ],
                                                    "content": ""
                                                },
                                                {
                                                    "type": "ElseStatement",
                                                    "name": "else",
                                                    "range": [
                                                        5090,
                                                        5101
                                                    ],
                                                    "children": [
                                                        {
                                                            "type": "Block",
                                                            "name": "",
                                                            "range": [
                                                                5091,
                                                                5101
                                                            ],
                                                            "children": [
                                                                {
                                                                    "type": "ThrowStatement",
                                                                    "name": "raise",
                                                                    "range": [
                                                                        5101,
                                                                        5101
                                                                    ],
                                                                    "children": [
                                                                        {
                                                                            "type": "NewExpression",
                                                                            "name": "ValueError",
                                                                            "range": [
                                                                                5102,
                                                                                5106
                                                                            ],
                                                                            "children": [],
                                                                            "content": ""
                                                                        }
                                                                    ],
                                                                    "content": ""
                                                                }
                                                            ],
                                                            "content": ""
                                                        }
                                                    ],
                                                    "content": ""
                                                }
                                            ],
                                            "content": ""
                                        }
                                    ],
                                    "content": ""
                                },
                                {
                                    "type": "CatchClause",
                                    "name": "except",
                                    "range": [
                                        5108,
                                        5131
                                    ],
                                    "children": [
                                        {
                                            "type": "Block",
                                            "name": "",
                                            "range": [
                                                5117,
                                                5131
                                            ],
                                            "children": [
                                                {
                                                    "type": "ThrowStatement",
                                                    "name": "raise",
                                                    "range": [
                                                        5126,
                                                        5131
                                                    ],
                                                    "children": [
                                                        {
                                                            "type": "NewExpression",
                                                            "name": "ValueError",
                                                            "range": [
                                                                5127,
                                                                5130
                                                            ],
                                                            "children": [],
                                                            "content": ""
                                                        }
                                                    ],
                                                    "content": ""
                                                }
                                            ],
                                            "content": ""
                                        }
                                    ],
                                    "content": ""
                                }
                            ],
                            "content": ""
                        }
                    ],
                    "content": ""
                }
            ],
            "content": ""
        },
        {
            "type": "FunctionDecl",
            "name": "run",
            "range": [
                5133,
                5602
            ],
            "children": [
                {
                    "type": "FunctionParameters",
                    "name": "",
                    "range": [
                        5135,
                        5152
                    ],
                    "children": [
                        {
                            "type": "Parameter",
                            "name": "self",
                            "range": [
                                5137,
                                5137
                            ],
                            "children": [],
                            "content": ""
                        },
                        {
                            "type": "Parameter",
                            "name": "input_data",
                            "range": [
                                5139,
                                5141
                            ],
                            "children": [],
                            "content": ""
                        },
                        {
                            "type": "Parameter",
                            "name": "credentials",
                            "range": [
                                5145,
                                5147
                            ],
                            "children": [],
                            "content": ""
                        },
                        {
                            "type": "Parameter",
                            "name": "kwargs",
                            "range": [
                                5151,
                                5151
                            ],
                            "children": [],
                            "content": ""
                        }
                    ],
                    "content": ""
                },
                {
                    "type": "FunctionBody",
                    "name": "",
                    "range": [
                        5153,
                        5602
                    ],
                    "children": [
                        {
                            "type": "ForStatement",
                            "name": "for",
                            "range": [
                                5320,
                                5518
                            ],
                            "children": [
                                {
                                    "type": "VariableDecl",
                                    "name": "attempt",
                                    "range": [
                                        5321,
                                        5328
                                    ],
                                    "children": [
                                        {
                                            "type": "Assignment",
                                            "name": "=",
                                            "range": [
                                                5322,
                                                5328
                                            ],
                                            "children": [
                                                {
                                                    "type": "CallExpression",
                                                    "name": "range",
                                                    "range": [
                                                        5323,
                                                        5328
                                                    ],
                                                    "children": [
                                                        {
                                                            "type": "Arguments",
                                                            "name": "",
                                                            "range": [
                                                                5324,
                                                                5328
                                                            ],
                                                            "children": [
                                                                {
                                                                    "type": "Argument",
                                                                    "name": "input_data.max_retries",
                                                                    "range": [
                                                                        5325,
                                                                        5327
                                                                    ],
                                                                    "children": [],
                                                                    "content": ""
                                                                }
                                                            ],
                                                            "content": ""
                                                        }
                                                    ],
                                                    "content": ""
                                                }
                                            ],
                                            "content": ""
                                        }
                                    ],
                                    "content": ""
                                },
                                {
                                    "type": "Block",
                                    "name": "",
                                    "range": [
                                        5329,
                                        5518
                                    ],
                                    "children": [
                                        {
                                            "type": "TryStatement",
                                            "name": "try",
                                            "range": [
                                                5331,
                                                5517
                                            ],
                                            "children": [
                                                {
                                                    "type": "Block",
                                                    "name": "",
                                                    "range": [
                                                        5332,
                                                        5496
                                                    ],
                                                    "children": [
                                                        {
                                                            "type": "VariableDecl",
                                                            "name": "llm_response",
                                                            "range": [
                                                                5341,
                                                                5405
                                                            ],
                                                            "children": [
                                                                {
                                                                    "type": "Assignment",
                                                                    "name": "=",
                                                                    "range": [
                                                                        5342,
                                                                        5405
                                                                    ],
                                                                    "children": [
                                                                        {
                                                                            "type": "MethodCall",
                                                                            "name": "llm_call",
                                                                            "range": [
                                                                                5343,
                                                                                5404
                                                                            ],
                                                                            "children": [
                                                                                {
                                                                                    "type": "Arguments",
                                                                                    "name": "",
                                                                                    "range": [
                                                                                        5344,
                                                                                        5404
                                                                                    ],
                                                                                    "children": [
                                                                                        {
                                                                                            "type": "Argument",
                                                                                            "name": "AIStructuredResponseGeneratorBlock.Input",
                                                                                            "range": [
                                                                                                5348,
                                                                                                5396
                                                                                            ],
                                                                                            "children": [],
                                                                                            "content": ""
                                                                                        },
                                                                                        {
                                                                                            "type": "Argument",
                                                                                            "name": "credentials",
                                                                                            "range": [
                                                                                                5399,
                                                                                                5403
                                                                                            ],
                                                                                            "children": [],
                                                                                            "content": ""
                                                                                        }
                                                                                    ],
                                                                                    "content": ""
                                                                                }
                                                                            ],
                                                                            "content": ""
                                                                        }
                                                                    ],
                                                                    "content": ""
                                                                }
                                                            ],
                                                            "content": ""
                                                        },
                                                        {
                                                            "type": "VariableDecl",
                                                            "name": "response_string",
                                                            "range": [
                                                                5421,
                                                                5427
                                                            ],
                                                            "children": [
                                                                {
                                                                    "type": "Assignment",
                                                                    "name": "=",
                                                                    "range": [
                                                                        5422,
                                                                        5427
                                                                    ],
                                                                    "children": [
                                                                        {
                                                                            "type": "MemberExpression",
                                                                            "name": "llm_response",
                                                                            "range": [
                                                                                5423,
                                                                                5426
                                                                            ],
                                                                            "children": [
                                                                                {
                                                                                    "type": "Property",
                                                                                    "name": "response",
                                                                                    "range": [
                                                                                        5425,
                                                                                        5425
                                                                                    ],
                                                                                    "children": [],
                                                                                    "content": ""
                                                                                }
                                                                            ],
                                                                            "content": ""
                                                                        }
                                                                    ],
                                                                    "content": ""
                                                                }
                                                            ],
                                                            "content": ""
                                                        },
                                                        {
                                                            "type": "VariableDecl",
                                                            "name": "parsed_list",
                                                            "range": [
                                                                5453,
                                                                5461
                                                            ],
                                                            "children": [
                                                                {
                                                                    "type": "Assignment",
                                                                    "name": "=",
                                                                    "range": [
                                                                        5454,
                                                                        5461
                                                                    ],
                                                                    "children": [
                                                                        {
                                                                            "type": "MethodCall",
                                                                            "name": "string_to_list",
                                                                            "range": [
                                                                                5455,
                                                                                5460
                                                                            ],
                                                                            "children": [
                                                                                {
                                                                                    "type": "Arguments",
                                                                                    "name": "",
                                                                                    "range": [
                                                                                        5456,
                                                                                        5460
                                                                                    ],
                                                                                    "children": [
                                                                                        {
                                                                                            "type": "Argument",
                                                                                            "name": "response_string",
                                                                                            "range": [
                                                                                                5459,
                                                                                                5459
                                                                                            ],
                                                                                            "children": [],
                                                                                            "content": ""
                                                                                        }
                                                                                    ],
                                                                                    "content": ""
                                                                                }
                                                                            ],
                                                                            "content": ""
                                                                        }
                                                                    ],
                                                                    "content": ""
                                                                }
                                                            ],
                                                            "content": ""
                                                        },
                                                        {
                                                            "type": "YieldStatement",
                                                            "name": "yield",
                                                            "range": [
                                                                5491,
                                                                5495
                                                            ],
                                                            "children": [
                                                                {
                                                                    "type": "StringLiteral",
                                                                    "name": "generated_list",
                                                                    "range": [
                                                                        5492,
                                                                        5492
                                                                    ],
                                                                    "children": [],
                                                                    "content": ""
                                                                },
                                                                {
                                                                    "type": "Identifier",
                                                                    "name": "parsed_list",
                                                                    "range": [
                                                                        5494,
                                                                        5494
                                                                    ],
                                                                    "children": [],
                                                                    "content": ""
                                                                }
                                                            ],
                                                            "content": ""
                                                        },
                                                        {
                                                            "type": "ForStatement",
                                                            "name": "for",
                                                            "range": [
                                                                5505,
                                                                5516
                                                            ],
                                                            "children": [
                                                                {
                                                                    "type": "VariableDecl",
                                                                    "name": "item",
                                                                    "range": [
                                                                        5506,
                                                                        5508
                                                                    ],
                                                                    "children": [
                                                                        {
                                                                            "type": "Assignment",
                                                                            "name": "=",
                                                                            "range": [
                                                                                5507,
                                                                                5508
                                                                            ],
                                                                            "children": [
                                                                                {
                                                                                    "type": "Identifier",
                                                                                    "name": "parsed_list",
                                                                                    "range": [
                                                                                        5508,
                                                                                        5508
                                                                                    ],
                                                                                    "children": [],
                                                                                    "content": ""
                                                                                }
                                                                            ],
                                                                            "content": ""
                                                                        }
                                                                    ],
                                                                    "content": ""
                                                                },
                                                                {
                                                                    "type": "Block",
                                                                    "name": "",
                                                                    "range": [
                                                                        5509,
                                                                        5516
                                                                    ],
                                                                    "children": [
                                                                        {
                                                                            "type": "YieldStatement",
                                                                            "name": "yield",
                                                                            "range": [
                                                                                5511,
                                                                                5515
                                                                            ],
                                                                            "children": [
                                                                                {
                                                                                    "type": "StringLiteral",
                                                                                    "name": "list_item",
                                                                                    "range": [
                                                                                        5512,
                                                                                        5512
                                                                                    ],
                                                                                    "children": [],
                                                                                    "content": ""
                                                                                },
                                                                                {
                                                                                    "type": "Identifier",
                                                                                    "name": "item",
                                                                                    "range": [
                                                                                        5514,
                                                                                        5514
                                                                                    ],
                                                                                    "children": [],
                                                                                    "content": ""
                                                                                }
                                                                            ],
                                                                            "content": ""
                                                                        }
                                                                    ],
                                                                    "content": ""
                                                                }
                                                            ],
                                                            "content": ""
                                                        }
                                                    ],
                                                    "content": ""
                                                },
                                                {
                                                    "type": "CatchClause",
                                                    "name": "except",
                                                    "range": [
                                                        5519,
                                                        5563
                                                    ],
                                                    "children": [
                                                        {
                                                            "type": "Block",
                                                            "name": "",
                                                            "range": [
                                                                5525,
                                                                5563
                                                            ],
                                                            "children": [
                                                                {
                                                                    "type": "IfStatement",
                                                                    "name": "if",
                                                                    "range": [
                                                                        5533,
                                                                        5542
                                                                    ],
                                                                    "children": [
                                                                        {
                                                                            "type": "Condition",
                                                                            "name": "attempt",
                                                                            "range": [
                                                                                5534,
                                                                                5536
                                                                            ],
                                                                            "children": [
                                                                                {
                                                                                    "type": "BinaryExpression",
                                                                                    "name": "==",
                                                                                    "range": [
                                                                                        5537,
                                                                                        5539
                                                                                    ],
                                                                                    "children": [
                                                                                        {
                                                                                            "type": "Identifier",
                                                                                            "name": "input_data.max_retries",
                                                                                            "range": [
                                                                                                5538,
                                                                                                5538
                                                                                            ],
                                                                                            "children": [],
                                                                                            "content": ""
                                                                                        },
                                                                                        {
                                                                                            "type": "Literal",
                                                                                            "name": "1",
                                                                                            "range": [
                                                                                                5540,
                                                                                                5540
                                                                                            ],
                                                                                            "children": [],
                                                                                            "content": ""
                                                                                        }
                                                                                    ],
                                                                                    "content": ""
                                                                                }
                                                                            ],
                                                                            "content": ""
                                                                        },
                                                                        {
                                                                            "type": "Block",
                                                                            "name": "",
                                                                            "range": [
                                                                                5543,
                                                                                5563
                                                                            ],
                                                                            "children": [
                                                                                {
                                                                                    "type": "ThrowStatement",
                                                                                    "name": "raise",
                                                                                    "range": [
                                                                                        5554,
                                                                                        5563
                                                                                    ],
                                                                                    "children": [
                                                                                        {
                                                                                            "type": "NewExpression",
                                                                                            "name": "RuntimeError",
                                                                                            "range": [
                                                                                                5555,
                                                                                                5562
                                                                                            ],
                                                                                            "children": [],
                                                                                            "content": ""
                                                                                        }
                                                                                    ],
                                                                                    "content": ""
                                                                                }
                                                                            ],
                                                                            "content": ""
                                                                        }
                                                                    ],
                                                                    "content": ""
                                                                },
                                                                {
                                                                    "type": "ElseStatement",
                                                                    "name": "else",
                                                                    "range": [
                                                                        5564,
                                                                        5594
                                                                    ],
                                                                    "children": [
                                                                        {
                                                                            "type": "Block",
                                                                            "name": "",
                                                                            "range": [
                                                                                5565,
                                                                                5594
                                                                            ],
                                                                            "children": [
                                                                                {
                                                                                    "type": "VariableDecl",
                                                                                    "name": "prompt",
                                                                                    "range": [
                                                                                        5579,
                                                                                        5585
                                                                                    ],
                                                                                    "children": [
                                                                                        {
                                                                                            "type": "Assignment",
                                                                                            "name": "=",
                                                                                            "range": [
                                                                                                5580,
                                                                                                5585
                                                                                            ],
                                                                                            "children": [
                                                                                                {
                                                                                                    "type": "TemplateLiteral",
                                                                                                    "name": "",
                                                                                                    "range": [
                                                                                                        5581,
                                                                                                        5584
                                                                                                    ],
                                                                                                    "children": [],
                                                                                                    "content": ""
                                                                                                }
                                                                                            ],
                                                                                            "content": ""
                                                                                        }
                                                                                    ],
                                                                                    "content": ""
                                                                                }
                                                                            ],
                                                                            "content": ""
                                                                        }
                                                                    ],
                                                                    "content": ""
                                                                }
                                                            ],
                                                            "content": ""
                                                        }
                                                    ],
                                                    "content": ""
                                                }
                                            ],
                                            "content": ""
                                        }
                                    ],
                                    "content": ""
                                }
                            ],
                            "content": ""
                        }
                    ],
                    "content": ""
                }
            ],
            "content": ""
        }
    ],
    "content": "\nLLMProviderName=Literal[\nProviderName.ANTHROPIC,\nProviderName.GROQ,\nProviderName.OLLAMA,\nProviderName.OPENAI,\nProviderName.OPEN_ROUTER,\n]\nAICredentials=CredentialsMetaInput[LLMProviderName,Literal[\"api_key\"]]\n\nTEST_CREDENTIALS=APIKeyCredentials(\nid=\"ed55ac19-356e-4243-a6cb-bc599e9b716f\",\nprovider=\"openai\",\napi_key=SecretStr(\"mock-openai-api-key\"),\ntitle=\"Mock OpenAI API key\",\nexpires_at=None,\n)\nTEST_CREDENTIALS_INPUT={\n\"provider\":TEST_CREDENTIALS.provider,\n\"id\":TEST_CREDENTIALS.id,\n\"type\":TEST_CREDENTIALS.type,\n\"title\":TEST_CREDENTIALS.title,\n}\n\n\ndef AICredentialsField()->AICredentials:\nreturn CredentialsField(\ndescription=\"API key for the LLM provider.\",\ndiscriminator=\"model\",\ndiscriminator_mapping={\nmodel.value:model.metadata.provider for model in LlmModel\n},\n)\n\n\nclass ModelMetadata(NamedTuple):\nprovider:str\ncontext_window:int\n\n\nclass LlmModelMeta(EnumMeta):\n@property\ndef __members__(\nself:type[\"_EnumMemberT\"],\n)->MappingProxyType[str,\"_EnumMemberT\"]:\nif Settings().config.behave_as==BehaveAs.LOCAL:\nmembers=super().__members__\nreturn members\nelse:\nremoved_providers=[\"ollama\"]\nexisting_members=super().__members__\nmembers={\nname:member\nfor name,member in existing_members.items()\nif LlmModel[name].provider not in removed_providers\n}\nreturn MappingProxyType(members)\n\n\nclass LlmModel(str,Enum,metaclass=LlmModelMeta):\n#OpenAI models\nO1_PREVIEW=\"o1-preview\"\nO1_MINI=\"o1-mini\"\nGPT4O_MINI=\"gpt-4o-mini\"\nGPT4O=\"gpt-4o\"\nGPT4_TURBO=\"gpt-4-turbo\"\nGPT3_5_TURBO=\"gpt-3.5-turbo\"\n#Anthropic models\nCLAUDE_3_5_SONNET=\"claude-3-5-sonnet-latest\"\nCLAUDE_3_HAIKU=\"claude-3-haiku-20240307\"\n#Groq models\nLLAMA3_8B=\"llama3-8b-8192\"\nLLAMA3_70B=\"llama3-70b-8192\"\nMIXTRAL_8X7B=\"mixtral-8x7b-32768\"\nGEMMA_7B=\"gemma-7b-it\"\nGEMMA2_9B=\"gemma2-9b-it\"\n#New Groq models(Preview)\nLLAMA3_1_405B=\"llama-3.1-405b-reasoning\"\nLLAMA3_1_70B=\"llama-3.1-70b-versatile\"\nLLAMA3_1_8B=\"llama-3.1-8b-instant\"\n#Ollama models\nOLLAMA_LLAMA3_8B=\"llama3\"\nOLLAMA_LLAMA3_405B=\"llama3.1:405b\"\nOLLAMA_DOLPHIN=\"dolphin-mistral:latest\"\n#OpenRouter models\nGEMINI_FLASH_1_5_8B=\"google/gemini-flash-1.5\"\nGROK_BETA=\"x-ai/grok-beta\"\nMISTRAL_NEMO=\"mistralai/mistral-nemo\"\nCOHERE_COMMAND_R_08_2024=\"cohere/command-r-08-2024\"\nCOHERE_COMMAND_R_PLUS_08_2024=\"cohere/command-r-plus-08-2024\"\nEVA_QWEN_2_5_32B=\"eva-unit-01/eva-qwen-2.5-32b\"\nDEEPSEEK_CHAT=\"deepseek/deepseek-chat\"\nPERPLEXITY_LLAMA_3_1_SONAR_LARGE_128K_ONLINE=(\n\"perplexity/llama-3.1-sonar-large-128k-online\"\n)\nQWEN_QWQ_32B_PREVIEW=\"qwen/qwq-32b-preview\"\nNOUSRESEARCH_HERMES_3_LLAMA_3_1_405B=\"nousresearch/hermes-3-llama-3.1-405b\"\nNOUSRESEARCH_HERMES_3_LLAMA_3_1_70B=\"nousresearch/hermes-3-llama-3.1-70b\"\nAMAZON_NOVA_LITE_V1=\"amazon/nova-lite-v1\"\nAMAZON_NOVA_MICRO_V1=\"amazon/nova-micro-v1\"\nAMAZON_NOVA_PRO_V1=\"amazon/nova-pro-v1\"\nMICROSOFT_WIZARDLM_2_8X22B=\"microsoft/wizardlm-2-8x22b\"\nGRYPHE_MYTHOMAX_L2_13B=\"gryphe/mythomax-l2-13b\"\n\n@property\ndef metadata(self)->ModelMetadata:\nreturn MODEL_METADATA[self]\n\n@property\ndef provider(self)->str:\nreturn self.metadata.provider\n\n@property\ndef context_window(self)->int:\nreturn self.metadata.context_window\n\n\nMODEL_METADATA={\nLlmModel.O1_PREVIEW:ModelMetadata(\"openai\",32000),\nLlmModel.O1_MINI:ModelMetadata(\"openai\",62000),\nLlmModel.GPT4O_MINI:ModelMetadata(\"openai\",128000),\nLlmModel.GPT4O:ModelMetadata(\"openai\",128000),\nLlmModel.GPT4_TURBO:ModelMetadata(\"openai\",128000),\nLlmModel.GPT3_5_TURBO:ModelMetadata(\"openai\",16385),\nLlmModel.CLAUDE_3_5_SONNET:ModelMetadata(\"anthropic\",200000),\nLlmModel.CLAUDE_3_HAIKU:ModelMetadata(\"anthropic\",200000),\nLlmModel.LLAMA3_8B:ModelMetadata(\"groq\",8192),\nLlmModel.LLAMA3_70B:ModelMetadata(\"groq\",8192),\nLlmModel.MIXTRAL_8X7B:ModelMetadata(\"groq\",32768),\nLlmModel.GEMMA_7B:ModelMetadata(\"groq\",8192),\nLlmModel.GEMMA2_9B:ModelMetadata(\"groq\",8192),\nLlmModel.LLAMA3_1_405B:ModelMetadata(\"groq\",8192),\n#Limited to16k during preview\nLlmModel.LLAMA3_1_70B:ModelMetadata(\"groq\",131072),\nLlmModel.LLAMA3_1_8B:ModelMetadata(\"groq\",131072),\nLlmModel.OLLAMA_LLAMA3_8B:ModelMetadata(\"ollama\",8192),\nLlmModel.OLLAMA_LLAMA3_405B:ModelMetadata(\"ollama\",8192),\nLlmModel.OLLAMA_DOLPHIN:ModelMetadata(\"ollama\",32768),\nLlmModel.GEMINI_FLASH_1_5_8B:ModelMetadata(\"open_router\",8192),\nLlmModel.GROK_BETA:ModelMetadata(\"open_router\",8192),\nLlmModel.MISTRAL_NEMO:ModelMetadata(\"open_router\",4000),\nLlmModel.COHERE_COMMAND_R_08_2024:ModelMetadata(\"open_router\",4000),\nLlmModel.COHERE_COMMAND_R_PLUS_08_2024:ModelMetadata(\"open_router\",4000),\nLlmModel.EVA_QWEN_2_5_32B:ModelMetadata(\"open_router\",4000),\nLlmModel.DEEPSEEK_CHAT:ModelMetadata(\"open_router\",8192),\nLlmModel.PERPLEXITY_LLAMA_3_1_SONAR_LARGE_128K_ONLINE:ModelMetadata(\n\"open_router\",8192\n),\nLlmModel.QWEN_QWQ_32B_PREVIEW:ModelMetadata(\"open_router\",4000),\nLlmModel.NOUSRESEARCH_HERMES_3_LLAMA_3_1_405B:ModelMetadata(\"open_router\",4000),\nLlmModel.NOUSRESEARCH_HERMES_3_LLAMA_3_1_70B:ModelMetadata(\"open_router\",4000),\nLlmModel.AMAZON_NOVA_LITE_V1:ModelMetadata(\"open_router\",4000),\nLlmModel.AMAZON_NOVA_MICRO_V1:ModelMetadata(\"open_router\",4000),\nLlmModel.AMAZON_NOVA_PRO_V1:ModelMetadata(\"open_router\",4000),\nLlmModel.MICROSOFT_WIZARDLM_2_8X22B:ModelMetadata(\"open_router\",4000),\nLlmModel.GRYPHE_MYTHOMAX_L2_13B:ModelMetadata(\"open_router\",4000),\n}\n\nfor model in LlmModel:\nif model not in MODEL_METADATA:\nraise ValueError(f \"Missing MODEL_METADATA metadata for model: {model}\")\n\n\nclass MessageRole(str,Enum):\nSYSTEM=\"system\"\nUSER=\"user\"\nASSISTANT=\"assistant\"\n\n\nclass Message(BlockSchema):\nrole:MessageRole\ncontent:str\n\n\nclass AIStructuredResponseGeneratorBlock(Block):\nclass Input(BlockSchema):\nprompt:str=SchemaField(\ndescription=\"The prompt to send to the language model.\",\nplaceholder=\"Enter your prompt here...\",\n)\nexpected_format:dict[str,str]=SchemaField(\ndescription=\"Expected format of the response. If provided, the response will be validated against this format. \"\n\"The keys should be the expected fields in the response, and the values should be the description of the field.\",\n)\nmodel:LlmModel=SchemaField(\ntitle=\"LLM Model\",\ndefault=LlmModel.GPT4_TURBO,\ndescription=\"The language model to use for answering the prompt.\",\nadvanced=False,\n)\ncredentials:AICredentials=AICredentialsField()\nsys_prompt:str=SchemaField(\ntitle=\"System Prompt\",\ndefault=\"\",\ndescription=\"The system prompt to provide additional context to the model.\",\n)\nconversation_history:list[Message]=SchemaField(\ndefault=[],\ndescription=\"The conversation history to provide context for the prompt.\",\n)\nretry:int=SchemaField(\ntitle=\"Retry Count\",\ndefault=3,\ndescription=\"Number of times to retry the LLM call if the response does not match the expected format.\",\n)\nprompt_values:dict[str,str]=SchemaField(\nadvanced=False,default={},description=\"Values used to fill in the prompt.\"\n)\nmax_tokens:int|None=SchemaField(\nadvanced=True,\ndefault=None,\ndescription=\"The maximum number of tokens to generate in the chat completion.\",\n)\n\nollama_host:str=SchemaField(\nadvanced=True,\ndefault=\"localhost:11434\",\ndescription=\"Ollama host for local  models\",\n)\n\nclass Output(BlockSchema):\nresponse:dict[str,Any]=SchemaField(\ndescription=\"The response object generated by the language model.\"\n)\nerror:str=SchemaField(description=\"Error message if the API call failed.\")\n\ndef __init__(self):\nsuper().__init__(\nid=\"ed55ac19-356e-4243-a6cb-bc599e9b716f\",\ndescription=\"Call a Large Language Model (LLM) to generate formatted object based on the given prompt.\",\ncategories={BlockCategory.AI},\ninput_schema=AIStructuredResponseGeneratorBlock.Input,\noutput_schema=AIStructuredResponseGeneratorBlock.Output,\ntest_input={\n\"model\":LlmModel.GPT4_TURBO,\n\"credentials\":TEST_CREDENTIALS_INPUT,\n\"expected_format\":{\n\"key1\":\"value1\",\n\"key2\":\"value2\",\n},\n\"prompt\":\"User prompt\",\n},\ntest_credentials=TEST_CREDENTIALS,\ntest_output=(\"response\",{\"key1\":\"key1Value\",\"key2\":\"key2Value\"}),\ntest_mock={\n\"llm_call\":lambda*args,**kwargs:(\njson.dumps(\n{\n\"key1\":\"key1Value\",\n\"key2\":\"key2Value\",\n}\n),\n0,\n0,\n)\n},\n)\n\n@staticmethod\ndef llm_call(\ncredentials:APIKeyCredentials,\nllm_model:LlmModel,\nprompt:list[dict],\njson_format:bool,\nmax_tokens:int|None=None,\nollama_host:str=\"localhost:11434\",\n)->tuple[str,int,int]:\n\"\"\" \\n         Args: \\n             api_key: API key for the LLM provider. \\n             llm_model: The LLM model to use. \\n             prompt: The prompt to send to the LLM. \\n             json_format: Whether the response should be in JSON format. \\n             max_tokens: The maximum number of tokens to generate in the chat completion. \\n             ollama_host: The host for ollama to use \\n  \\n         Returns: \\n             The response from the LLM. \\n             The number of tokens used in the prompt. \\n             The number of tokens used in the completion. \\n         \"\"\"\nprovider=llm_model.metadata.provider\n\nif provider==\"openai\":\noai_client=openai.OpenAI(api_key=credentials.api_key.get_secret_value())\nresponse_format=None\n\nif llm_model in[LlmModel.O1_MINI,LlmModel.O1_PREVIEW]:\nsys_messages=[p[\"content\"]for p in prompt if p[\"role\"]==\"system\"]\nusr_messages=[p[\"content\"]for p in prompt if p[\"role\"]!=\"system\"]\nprompt=[\n{\"role\":\"user\",\"content\":\"\\n\".join(sys_messages)},\n{\"role\":\"user\",\"content\":\"\\n\".join(usr_messages)},\n]\nelif json_format:\nresponse_format={\"type\":\"json_object\"}\n\nresponse=oai_client.chat.completions.create(\nmodel=llm_model.value,\nmessages=prompt,#type:ignore\nresponse_format=response_format,#type:ignore\nmax_completion_tokens=max_tokens,\n)\n\nreturn(\nresponse.choices[0].message.content or\"\",\nresponse.usage.prompt_tokens if response.usage else0,\nresponse.usage.completion_tokens if response.usage else0,\n)\nelif provider==\"anthropic\":\nsystem_messages=[p[\"content\"]for p in prompt if p[\"role\"]==\"system\"]\nsysprompt=\" \".join(system_messages)\n\nmessages=[]\nlast_role=None\nfor p in prompt:\nif p[\"role\"]in[\"user\",\"assistant\"]:\nif p[\"role\"]!=last_role:\nmessages.append({\"role\":p[\"role\"],\"content\":p[\"content\"]})\nlast_role=p[\"role\"]\nelse:\n#If the role is the same as the last one,combine the content\nmessages[-1][\"content\"]+=\"\\n\"+p[\"content\"]\n\nclient=anthropic.Anthropic(api_key=credentials.api_key.get_secret_value())\ntry:\nresp=client.messages.create(\nmodel=llm_model.value,\nsystem=sysprompt,\nmessages=messages,\nmax_tokens=max_tokens or8192,\n)\n\nif not resp.content:\nraise ValueError(\"No content returned from Anthropic.\")\n\nreturn(\n(\nresp.content[0].name\nif isinstance(resp.content[0],anthropic.types.ToolUseBlock)\nelse resp.content[0].text\n),\nresp.usage.input_tokens,\nresp.usage.output_tokens,\n)\nexcept anthropic.APIError as e:\nerror_message=f \"Anthropic API error: {str(e)}\"\nlogger.error(error_message)\nraise ValueError(error_message)\nelif provider==\"groq\":\nclient=Groq(api_key=credentials.api_key.get_secret_value())\nresponse_format={\"type\":\"json_object\"}if json_format else None\nresponse=client.chat.completions.create(\nmodel=llm_model.value,\nmessages=prompt,#type:ignore\nresponse_format=response_format,#type:ignore\nmax_tokens=max_tokens,\n)\nreturn(\nresponse.choices[0].message.content or\"\",\nresponse.usage.prompt_tokens if response.usage else0,\nresponse.usage.completion_tokens if response.usage else0,\n)\nelif provider==\"ollama\":\nclient=ollama.Client(host=ollama_host)\nsys_messages=[p[\"content\"]for p in prompt if p[\"role\"]==\"system\"]\nusr_messages=[p[\"content\"]for p in prompt if p[\"role\"]!=\"system\"]\nresponse=client.generate(\nmodel=llm_model.value,\nprompt=f \"{sys_messages}\\n\\n{usr_messages}\",\nstream=False,\n)\nreturn(\nresponse.get(\"response\")or\"\",\nresponse.get(\"prompt_eval_count\")or0,\nresponse.get(\"eval_count\")or0,\n)\nelif provider==\"open_router\":\nclient=openai.OpenAI(\nbase_url=\"https://openrouter.ai/api/v1\",\napi_key=credentials.api_key.get_secret_value(),\n)\n\nresponse=client.chat.completions.create(\nextra_headers={\n\"HTTP-Referer\":\"https://agpt.co\",\n\"X-Title\":\"AutoGPT\",\n},\nmodel=llm_model.value,\nmessages=prompt,#type:ignore\nmax_tokens=max_tokens,\n)\n\n#If there 's no response, raise an error \\n             if not response.choices: \\n                 if response: \\n                     raise ValueError(f\"OpenRouter error: {response}\") \\n                 else: \\n                     raise ValueError(\"No response from OpenRouter.\") \\n  \\n             return ( \\n                 response.choices[0].message.content or \"\", \\n                 response.usage.prompt_tokens if response.usage else 0, \\n                 response.usage.completion_tokens if response.usage else 0, \\n             ) \\n         else: \\n             raise ValueError(f\"Unsupported LLM provider: {provider}\") \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         logger.debug(f\"Calling LLM with input data: {input_data}\") \\n         prompt = [p.model_dump() for p in input_data.conversation_history] \\n  \\n         def trim_prompt(s: str) -> str: \\n             lines = s.strip().split(\"\\n\") \\n             return \"\\n\".join([line.strip().lstrip(\"|\") for line in lines]) \\n  \\n         values = input_data.prompt_values \\n         if values: \\n             input_data.prompt = input_data.prompt.format(**values) \\n             input_data.sys_prompt = input_data.sys_prompt.format(**values) \\n  \\n         if input_data.sys_prompt: \\n             prompt.append({\"role\": \"system\", \"content\": input_data.sys_prompt}) \\n  \\n         if input_data.expected_format: \\n             expected_format = [ \\n                 f' \"{k}\":\"{v}\" ' for k, v in input_data.expected_format.items() \\n             ] \\n             format_prompt = \",\\n  \".join(expected_format) \\n             sys_prompt = trim_prompt( \\n                 f\"\"\" \\n                   |Reply strictly only in the following JSON format: \\n                   |{{ \\n                   |  {format_prompt} \\n                   |}} \\n                 \"\"\" \\n             ) \\n             prompt.append({\"role\": \"system\", \"content\": sys_prompt}) \\n  \\n         if input_data.prompt: \\n             prompt.append({\"role\": \"user\", \"content\": input_data.prompt}) \\n  \\n         def parse_response(resp: str) -> tuple[dict[str, Any], str | None]: \\n             try: \\n                 parsed = json.loads(resp) \\n                 if not isinstance(parsed, dict): \\n                     return {}, f\"Expected a dictionary, but got {type(parsed)}\" \\n                 miss_keys = set(input_data.expected_format.keys()) - set(parsed.keys()) \\n                 if miss_keys: \\n                     return parsed, f\"Missing keys: {miss_keys}\" \\n                 return parsed, None \\n             except JSONDecodeError as e: \\n                 return {}, f\"JSON decode error: {e}\" \\n  \\n         logger.info(f\"LLM request: {prompt}\") \\n         retry_prompt = \"\" \\n         llm_model = input_data.model \\n  \\n         for retry_count in range(input_data.retry): \\n             try: \\n                 response_text, input_token, output_token = self.llm_call( \\n                     credentials=credentials, \\n                     llm_model=llm_model, \\n                     prompt=prompt, \\n                     json_format=bool(input_data.expected_format), \\n                     ollama_host=input_data.ollama_host, \\n                     max_tokens=input_data.max_tokens, \\n                 ) \\n                 self.merge_stats( \\n                     { \\n                         \"input_token_count\": input_token, \\n                         \"output_token_count\": output_token, \\n                     } \\n                 ) \\n                 logger.info(f\"LLM attempt-{retry_count} response: {response_text}\") \\n  \\n                 if input_data.expected_format: \\n                     parsed_dict, parsed_error = parse_response(response_text) \\n                     if not parsed_error: \\n                         yield \"response\", { \\n                             k: ( \\n                                 json.loads(v) \\n                                 if isinstance(v, str) \\n                                 and v.startswith(\"[\") \\n                                 and v.endswith(\"]\") \\n                                 else (\", \".join(v) if isinstance(v, list) else v) \\n                             ) \\n                             for k, v in parsed_dict.items() \\n                         } \\n                         return \\n                 else: \\n                     yield \"response\", {\"response\": response_text} \\n                     return \\n  \\n                 retry_prompt = trim_prompt( \\n                     f\"\"\" \\n                   |This is your previous error response: \\n                   |-- \\n                   |{response_text} \\n                   |-- \\n                   | \\n                   |And this is the error: \\n                   |-- \\n                   |{parsed_error} \\n                   |-- \\n                 \"\"\" \\n                 ) \\n                 prompt.append({\"role\": \"user\", \"content\": retry_prompt}) \\n             except Exception as e: \\n                 logger.exception(f\"Error calling LLM: {e}\") \\n                 retry_prompt = f\"Error calling LLM: {e}\" \\n             finally: \\n                 self.merge_stats( \\n                     { \\n                         \"llm_call_count\": retry_count + 1, \\n                         \"llm_retry_count\": retry_count, \\n                     } \\n                 ) \\n  \\n         raise RuntimeError(retry_prompt) \\n  \\n  \\n class AITextGeneratorBlock(Block): \\n     class Input(BlockSchema): \\n         prompt: str = SchemaField( \\n             description=\"The prompt to send to the language model. You can use any of the {keys} from Prompt Values to fill in the prompt with values from the prompt values dictionary by putting them in curly braces.\", \\n             placeholder=\"Enter your prompt here...\", \\n         ) \\n         model: LlmModel = SchemaField( \\n             title=\"LLM Model\", \\n             default=LlmModel.GPT4_TURBO, \\n             description=\"The language model to use for answering the prompt.\", \\n             advanced=False, \\n         ) \\n         credentials: AICredentials = AICredentialsField() \\n         sys_prompt: str = SchemaField( \\n             title=\"System Prompt\", \\n             default=\"\", \\n             description=\"The system prompt to provide additional context to the model.\", \\n         ) \\n         retry: int = SchemaField( \\n             title=\"Retry Count\", \\n             default=3, \\n             description=\"Number of times to retry the LLM call if the response does not match the expected format.\", \\n         ) \\n         prompt_values: dict[str, str] = SchemaField( \\n             advanced=False, default={}, description=\"Values used to fill in the prompt.\" \\n         ) \\n         ollama_host: str = SchemaField( \\n             advanced=True, \\n             default=\"localhost:11434\", \\n             description=\"Ollama host for local  models\", \\n         ) \\n         max_tokens: int | None = SchemaField( \\n             advanced=True, \\n             default=None, \\n             description=\"The maximum number of tokens to generate in the chat completion.\", \\n         ) \\n  \\n     class Output(BlockSchema): \\n         response: str = SchemaField( \\n             description=\"The response generated by the language model.\" \\n         ) \\n         error: str = SchemaField(description=\"Error message if the API call failed.\") \\n  \\n     def __init__(self): \\n         super().__init__( \\n             id=\"1f292d4a-41a4-4977-9684-7c8d560b9f91\", \\n             description=\"Call a Large Language Model (LLM) to generate a string based on the given prompt.\", \\n             categories={BlockCategory.AI}, \\n             input_schema=AITextGeneratorBlock.Input, \\n             output_schema=AITextGeneratorBlock.Output, \\n             test_input={ \\n                 \"prompt\": \"User prompt\", \\n                 \"credentials\": TEST_CREDENTIALS_INPUT, \\n             }, \\n             test_credentials=TEST_CREDENTIALS, \\n             test_output=(\"response\", \"Response text\"), \\n             test_mock={\"llm_call\": lambda *args, **kwargs: \"Response text\"}, \\n         ) \\n  \\n     def llm_call( \\n         self, \\n         input_data: AIStructuredResponseGeneratorBlock.Input, \\n         credentials: APIKeyCredentials, \\n     ) -> str: \\n         block = AIStructuredResponseGeneratorBlock() \\n         response = block.run_once(input_data, \"response\", credentials=credentials) \\n         self.merge_stats(block.execution_stats) \\n         return response[\"response\"] \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         object_input_data = AIStructuredResponseGeneratorBlock.Input( \\n             **{attr: getattr(input_data, attr) for attr in input_data.model_fields}, \\n             expected_format={}, \\n         ) \\n         yield \"response\", self.llm_call(object_input_data, credentials) \\n  \\n  \\n class SummaryStyle(Enum): \\n     CONCISE = \"concise\" \\n     DETAILED = \"detailed\" \\n     BULLET_POINTS = \"bullet points\" \\n     NUMBERED_LIST = \"numbered list\" \\n  \\n  \\n class AITextSummarizerBlock(Block): \\n     class Input(BlockSchema): \\n         text: str = SchemaField( \\n             description=\"The text to summarize.\", \\n             placeholder=\"Enter the text to summarize here...\", \\n         ) \\n         model: LlmModel = SchemaField( \\n             title=\"LLM Model\", \\n             default=LlmModel.GPT4_TURBO, \\n             description=\"The language model to use for summarizing the text.\", \\n         ) \\n         focus: str = SchemaField( \\n             title=\"Focus\", \\n             default=\"general information\", \\n             description=\"The topic to focus on in the summary\", \\n         ) \\n         style: SummaryStyle = SchemaField( \\n             title=\"Summary Style\", \\n             default=SummaryStyle.CONCISE, \\n             description=\"The style of the summary to generate.\", \\n         ) \\n         credentials: AICredentials = AICredentialsField() \\n         # TODO: Make this dynamic \\n         max_tokens: int = SchemaField( \\n             title=\"Max Tokens\", \\n             default=4096, \\n             description=\"The maximum number of tokens to generate in the chat completion.\", \\n             ge=1, \\n         ) \\n         chunk_overlap: int = SchemaField( \\n             title=\"Chunk Overlap\", \\n             default=100, \\n             description=\"The number of overlapping tokens between chunks to maintain context.\", \\n             ge=0, \\n         ) \\n         ollama_host: str = SchemaField( \\n             advanced=True, \\n             default=\"localhost:11434\", \\n             description=\"Ollama host for local  models\", \\n         ) \\n  \\n     class Output(BlockSchema): \\n         summary: str = SchemaField(description=\"The final summary of the text.\") \\n         error: str = SchemaField(description=\"Error message if the API call failed.\") \\n  \\n     def __init__(self): \\n         super().__init__( \\n             id=\"a0a69be1-4528-491c-a85a-a4ab6873e3f0\", \\n             description=\"Utilize a Large Language Model (LLM) to summarize a long text.\", \\n             categories={BlockCategory.AI, BlockCategory.TEXT}, \\n             input_schema=AITextSummarizerBlock.Input, \\n             output_schema=AITextSummarizerBlock.Output, \\n             test_input={ \\n                 \"text\": \"Lorem ipsum...\" * 100, \\n                 \"credentials\": TEST_CREDENTIALS_INPUT, \\n             }, \\n             test_credentials=TEST_CREDENTIALS, \\n             test_output=(\"summary\", \"Final summary of a long text\"), \\n             test_mock={ \\n                 \"llm_call\": lambda input_data, credentials: ( \\n                     {\"final_summary\": \"Final summary of a long text\"} \\n                     if \"final_summary\" in input_data.expected_format \\n                     else {\"summary\": \"Summary of a chunk of text\"} \\n                 ) \\n             }, \\n         ) \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         for output in self._run(input_data, credentials): \\n             yield output \\n  \\n     def _run(self, input_data: Input, credentials: APIKeyCredentials) -> BlockOutput: \\n         chunks = self._split_text( \\n             input_data.text, input_data.max_tokens, input_data.chunk_overlap \\n         ) \\n         summaries = [] \\n  \\n         for chunk in chunks: \\n             chunk_summary = self._summarize_chunk(chunk, input_data, credentials) \\n             summaries.append(chunk_summary) \\n  \\n         final_summary = self._combine_summaries(summaries, input_data, credentials) \\n         yield \"summary\", final_summary \\n  \\n     @staticmethod \\n     def _split_text(text: str, max_tokens: int, overlap: int) -> list[str]: \\n         words = text.split() \\n         chunks = [] \\n         chunk_size = max_tokens - overlap \\n  \\n         for i in range(0, len(words), chunk_size): \\n             chunk = \" \".join(words[i : i + max_tokens]) \\n             chunks.append(chunk) \\n  \\n         return chunks \\n  \\n     def llm_call( \\n         self, \\n         input_data: AIStructuredResponseGeneratorBlock.Input, \\n         credentials: APIKeyCredentials, \\n     ) -> dict: \\n         block = AIStructuredResponseGeneratorBlock() \\n         response = block.run_once(input_data, \"response\", credentials=credentials) \\n         self.merge_stats(block.execution_stats) \\n         return response \\n  \\n     def _summarize_chunk( \\n         self, chunk: str, input_data: Input, credentials: APIKeyCredentials \\n     ) -> str: \\n         prompt = f\"Summarize the following text in a {input_data.style} form. Focus your summary on the topic of `{input_data.focus}` if present, otherwise just provide a general summary:\\n\\n```{chunk}```\" \\n  \\n         llm_response = self.llm_call( \\n             AIStructuredResponseGeneratorBlock.Input( \\n                 prompt=prompt, \\n                 credentials=input_data.credentials, \\n                 model=input_data.model, \\n                 expected_format={\"summary\": \"The summary of the given text.\"}, \\n             ), \\n             credentials=credentials, \\n         ) \\n  \\n         return llm_response[\"summary\"] \\n  \\n     def _combine_summaries( \\n         self, summaries: list[str], input_data: Input, credentials: APIKeyCredentials \\n     ) -> str: \\n         combined_text = \"\\n\\n\".join(summaries) \\n  \\n         if len(combined_text.split()) <= input_data.max_tokens: \\n             prompt = f\"Provide a final summary of the following section summaries in a {input_data.style} form, focus your summary on the topic of `{input_data.focus}` if present:\\n\\n ```{combined_text}```\\n\\n Just respond with the final_summary in the format specified.\" \\n  \\n             llm_response = self.llm_call( \\n                 AIStructuredResponseGeneratorBlock.Input( \\n                     prompt=prompt, \\n                     credentials=input_data.credentials, \\n                     model=input_data.model, \\n                     expected_format={ \\n                         \"final_summary\": \"The final summary of all provided summaries.\" \\n                     }, \\n                 ), \\n                 credentials=credentials, \\n             ) \\n  \\n             return llm_response[\"final_summary\"] \\n         else: \\n             # If combined summaries are still too long, recursively summarize \\n             return self._run( \\n                 AITextSummarizerBlock.Input( \\n                     text=combined_text, \\n                     credentials=input_data.credentials, \\n                     model=input_data.model, \\n                     max_tokens=input_data.max_tokens, \\n                     chunk_overlap=input_data.chunk_overlap, \\n                 ), \\n                 credentials=credentials, \\n             ).send(None)[ \\n                 1 \\n             ]  # Get the first yielded value \\n  \\n  \\n class AIConversationBlock(Block): \\n     class Input(BlockSchema): \\n         messages: List[Message] = SchemaField( \\n             description=\"List of messages in the conversation.\", min_length=1 \\n         ) \\n         model: LlmModel = SchemaField( \\n             title=\"LLM Model\", \\n             default=LlmModel.GPT4_TURBO, \\n             description=\"The language model to use for the conversation.\", \\n         ) \\n         credentials: AICredentials = AICredentialsField() \\n         max_tokens: int | None = SchemaField( \\n             advanced=True, \\n             default=None, \\n             description=\"The maximum number of tokens to generate in the chat completion.\", \\n         ) \\n         ollama_host: str = SchemaField( \\n             advanced=True, \\n             default=\"localhost:11434\", \\n             description=\"Ollama host for local  models\", \\n         ) \\n  \\n     class Output(BlockSchema): \\n         response: str = SchemaField( \\n             description=\"The model' s response to the conversation.\" \\n         ) \\n         error: str = SchemaField(description=\" Error message if the API call failed.\") \\n  \\n     def __init__(self): \\n         super().__init__( \\n             id=\"32a87eab-381e-4dd4-bdb8-4c47151be35a \", \\n             description=\" Advanced LLM call that takes a list of messages and sends them to the language model.\", \\n             categories={BlockCategory.AI}, \\n             input_schema=AIConversationBlock.Input, \\n             output_schema=AIConversationBlock.Output, \\n             test_input={ \\n                 \" messages \": [ \\n                     {\" role\": \"system\", \"content\": \"You are a helpful assistant.\"}, \\n                     {\" role\": \"user\", \"content\": \"Who won the world series in2020?\"}, \\n                     { \\n                         \" role\": \"assistant \", \\n                         \" content\": \"The Los Angeles Dodgers won the World Series in2020.\", \\n                     }, \\n                     {\" role\": \"user\", \"content\": \"Where was it played?\"}, \\n                 ], \\n                 \" model \": LlmModel.GPT4_TURBO, \\n                 \" credentials \": TEST_CREDENTIALS_INPUT, \\n             }, \\n             test_credentials=TEST_CREDENTIALS, \\n             test_output=( \\n                 \" response \", \\n                 \" The2020World Series was played at Globe Life Field in Arlington,Texas.\", \\n             ), \\n             test_mock={ \\n                 \" llm_call \": lambda *args, **kwargs: \" The2020World Series was played at Globe Life Field in Arlington,Texas.\" \\n             }, \\n         ) \\n  \\n     def llm_call( \\n         self, \\n         input_data: AIStructuredResponseGeneratorBlock.Input, \\n         credentials: APIKeyCredentials, \\n     ) -> str: \\n         block = AIStructuredResponseGeneratorBlock() \\n         response = block.run_once(input_data, \" response \", credentials=credentials) \\n         self.merge_stats(block.execution_stats) \\n         return response[\" response \"] \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         response = self.llm_call( \\n             AIStructuredResponseGeneratorBlock.Input( \\n                 prompt=\" \", \\n                 credentials=input_data.credentials, \\n                 model=input_data.model, \\n                 conversation_history=input_data.messages, \\n                 max_tokens=input_data.max_tokens, \\n                 expected_format={}, \\n             ), \\n             credentials=credentials, \\n         ) \\n  \\n         yield \" response \", response \\n  \\n  \\n class AIListGeneratorBlock(Block): \\n     class Input(BlockSchema): \\n         focus: str | None = SchemaField( \\n             description=\" The focus of the list to generate.\", \\n             placeholder=\" The top5most interesting news stories in the data.\", \\n             default=None, \\n             advanced=False, \\n         ) \\n         source_data: str | None = SchemaField( \\n             description=\" The data to generate the list from.\", \\n             placeholder=\" News Today:Humans land on Mars:Today humans landed on mars.--AI wins Nobel Prize:AI wins Nobel Prize for solving world hunger.--New AI Model:A new AI model has been released.\", \\n             default=None, \\n             advanced=False, \\n         ) \\n         model: LlmModel = SchemaField( \\n             title=\" LLM Model \", \\n             default=LlmModel.GPT4_TURBO, \\n             description=\" The language model to use for generating the list.\", \\n             advanced=True, \\n         ) \\n         credentials: AICredentials = AICredentialsField() \\n         max_retries: int = SchemaField( \\n             default=3, \\n             description=\" Maximum number of retries for generating a valid list.\", \\n             ge=1, \\n             le=5, \\n         ) \\n         max_tokens: int | None = SchemaField( \\n             advanced=True, \\n             default=None, \\n             description=\" The maximum number of tokens to generate in the chat completion.\", \\n         ) \\n         ollama_host: str = SchemaField( \\n             advanced=True, \\n             default=\" localhost:11434\", \\n             description=\" Ollama host for local models \", \\n         ) \\n  \\n     class Output(BlockSchema): \\n         generated_list: List[str] = SchemaField(description=\" The generated list.\") \\n         list_item: str = SchemaField( \\n             description=\" Each individual item in the list.\", \\n         ) \\n         error: str = SchemaField( \\n             description=\" Error message if the list generation failed.\" \\n         ) \\n  \\n     def __init__(self): \\n         super().__init__( \\n             id=\"9c0b0450-d199-458b-a731-072189dd6593 \", \\n             description=\" Generate a Python list based on the given prompt using a Large Language Model(LLM).\", \\n             categories={BlockCategory.AI, BlockCategory.TEXT}, \\n             input_schema=AIListGeneratorBlock.Input, \\n             output_schema=AIListGeneratorBlock.Output, \\n             test_input={ \\n                 \" focus\": \"planets \", \\n                 \" source_data \": ( \\n                     \" Zylora Prime is a glowing jungle world with bioluminescent plants,\" \\n                     \" while Kharon-9is a harsh desert planet with underground cities.\" \\n                     \" Vortexia 's constant storms power floating cities, and Oceara is a water-covered world home to \" \\n                     \"intelligent marine life. On icy Draknos, ancient ruins lie buried beneath its frozen landscape, \" \\n                     \"drawing explorers to uncover its mysteries. Each planet showcases the limitless possibilities of \" \\n                     \"fictional worlds.\" \\n                 ), \\n                 \"model\": LlmModel.GPT4_TURBO, \\n                 \"credentials\": TEST_CREDENTIALS_INPUT, \\n                 \"max_retries\": 3, \\n             }, \\n             test_credentials=TEST_CREDENTIALS, \\n             test_output=[ \\n                 ( \\n                     \"generated_list\", \\n                     [\"Zylora Prime\", \"Kharon-9\", \"Vortexia\", \"Oceara\", \"Draknos\"], \\n                 ), \\n                 (\"list_item\", \"Zylora Prime\"), \\n                 (\"list_item\", \"Kharon-9\"), \\n                 (\"list_item\", \"Vortexia\"), \\n                 (\"list_item\", \"Oceara\"), \\n                 (\"list_item\", \"Draknos\"), \\n             ], \\n             test_mock={ \\n                 \"llm_call\": lambda input_data, credentials: { \\n                     \"response\": \"[' Zylora Prime', 'Kharon-9', 'Vortexia', 'Oceara', 'Draknos ']\" \\n                 }, \\n             }, \\n         ) \\n  \\n     @staticmethod \\n     def llm_call( \\n         input_data: AIStructuredResponseGeneratorBlock.Input, \\n         credentials: APIKeyCredentials, \\n     ) -> dict[str, str]: \\n         llm_block = AIStructuredResponseGeneratorBlock() \\n         response = llm_block.run_once(input_data, \"response\", credentials=credentials) \\n         return response \\n  \\n     @staticmethod \\n     def string_to_list(string): \\n         \"\"\" \\n         Converts a string representation of a list into an actual Python list object. \\n         \"\"\" \\n         logger.debug(f\"Converting string to list. Input string: {string}\") \\n         try: \\n             # Use ast.literal_eval to safely evaluate the string \\n             python_list = ast.literal_eval(string) \\n             if isinstance(python_list, list): \\n                 logger.debug(f\"Successfully converted string to list: {python_list}\") \\n                 return python_list \\n             else: \\n                 logger.error(f\"The provided string '{string}' is not a valid list\") \\n                 raise ValueError(f\"The provided string '{string}' is not a valid list.\") \\n         except (SyntaxError, ValueError) as e: \\n             logger.error(f\"Failed to convert string to list: {e}\") \\n             raise ValueError(\"Invalid list format. Could not convert to list.\") \\n  \\n     def run( \\n         self, input_data: Input, *, credentials: APIKeyCredentials, **kwargs \\n     ) -> BlockOutput: \\n         logger.debug(f\"Starting AIListGeneratorBlock.run with input data: {input_data}\") \\n  \\n         # Check for API key \\n         api_key_check = credentials.api_key.get_secret_value() \\n         if not api_key_check: \\n             raise ValueError(\"No LLM API key provided.\") \\n  \\n         # Prepare the system prompt \\n         sys_prompt = \"\"\"You are a Python list generator. Your task is to generate a Python list based on the user' s prompt.\n|Respond ONLY with a valid python list.\n|The list can contain strings,numbers,or nested lists as appropriate.\n|Do not include any explanations or additional text.\n\n|Valid Example string formats:\n\n|Example1:\n|```\n|['1','2','3','4']\n|```\n\n|Example2:\n|```\n|[['1','2'],['3','4'],['5','6']]\n|```\n\n|Example3:\n|```\n|['1',['2','3'],['4',['5','6']]]\n|```\n\n|Example4:\n|```\n|['a','b','c']\n|```\n\n|Example5:\n|```\n|['1','2.5','string','True',['False','None']]\n|```\n\n|Do not include any explanations or additional text,just respond with the list in the format specified above.\n\"\"\" \\n         # If a focus is provided, add it to the prompt \\n         if input_data.focus: \\n             prompt = f\" Generate a list with the following focus:\n<focus>\n\n{input_data.focus}</focus>\" \\n         else: \\n             # If there's source data \\n             if input_data.source_data: \\n                 prompt = \" Extract the main focus of the source data to a list.\ni.e if the source data is a news website,the focus would be the news stories rather than the social links in the footer.\" \\n             else: \\n                 # No focus or source data provided, generat a random list \\n                 prompt = \" Generate a random list.\" \\n  \\n         # If the source data is provided, add it to the prompt \\n         if input_data.source_data: \\n             prompt += f\"\n\nUse the following source data to generate the list from:\n\n<source_data>\n\n{input_data.source_data}</source_data>\n\nDo not invent fictional data that is not present in the source data.\" \\n         # Else, tell the LLM to synthesize the data \\n         else: \\n             prompt += \"\n\nInvent the data to generate the list from.\" \\n  \\n         for attempt in range(input_data.max_retries): \\n             try: \\n                 logger.debug(\" Calling LLM \") \\n                 llm_response = self.llm_call( \\n                     AIStructuredResponseGeneratorBlock.Input( \\n                         sys_prompt=sys_prompt, \\n                         prompt=prompt, \\n                         credentials=input_data.credentials, \\n                         model=input_data.model, \\n                         expected_format={},  # Do not use structured response \\n                         ollama_host=input_data.ollama_host, \\n                     ), \\n                     credentials=credentials, \\n                 ) \\n  \\n                 logger.debug(f\" LLM response:{llm_response}\") \\n  \\n                 # Extract Response string \\n                 response_string = llm_response[\" response \"] \\n                 logger.debug(f\" Response string:{response_string}\") \\n  \\n                 # Convert the string to a Python list \\n                 logger.debug(\" Converting string to Python list \") \\n                 parsed_list = self.string_to_list(response_string) \\n                 logger.debug(f\" Parsed list:{parsed_list}\") \\n  \\n                 # If we reach here, we have a valid Python list \\n                 logger.debug(\" Successfully generated a valid Python list \") \\n                 yield \" generated_list \", parsed_list \\n  \\n                 # Yield each item in the list \\n                 for item in parsed_list: \\n                     yield \" list_item \", item \\n                 return \\n  \\n             except Exception as e: \\n                 logger.error(f\" Error in attempt{attempt+1}:{str(e)}\") \\n                 if attempt == input_data.max_retries - 1: \\n                     logger.error( \\n                         f\" Failed to generate a valid Python list after{input_data.max_retries}attempts \" \\n                     ) \\n                     raise RuntimeError( \\n                         f\" Failed to generate a valid Python list after{input_data.max_retries}attempts.Last error:{str(e)}\" \\n                     ) \\n                 else: \\n                     # Add a retry prompt \\n                     logger.debug(\" Preparing retry prompt \") \\n                     prompt = f\"\"\"\nThe previous attempt failed due to`{e}`\nGenerate a valid Python list based on the original prompt.\nRemember to respond ONLY with a valid Python list as per the format specified earlier.\nOriginal prompt:\n```{prompt}```\n\nRespond only with the list in the format specified with no commentary or apologies.\n\"\"\" \\n                     logger.debug(f\" Retry prompt:{prompt}\") \\n  \\n         logger.debug(\" AIListGeneratorBlock.run completed\")\n"
}