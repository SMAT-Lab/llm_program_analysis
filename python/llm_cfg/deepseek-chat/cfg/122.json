{
    "nodes": [
        {
            "id": "chunk_0_GlobalBlock_1",
            "code": "from collections import defaultdict\nfrom datetime import datetime, timezone\nfrom multiprocessing import Manager\nfrom typing import Any, AsyncGenerator, Generator, Generic, TypeVar\n\n"
        },
        {
            "id": "chunk_0_GlobalBlock_2",
            "code": "from prisma.enums import AgentExecutionStatus\nfrom prisma.models import (\n    AgentGraphExecution,\n    AgentNodeExecution,\n    AgentNodeExecutionInputOutput,\n)\n"
        },
        {
            "id": "chunk_0_GlobalBlock_3",
            "code": "from pydantic import BaseModel\n\n"
        },
        {
            "id": "chunk_0_GlobalBlock_4",
            "code": "from backend.data.block import BlockData, BlockInput, CompletedBlockOutput\nfrom backend.data.includes import EXECUTION_RESULT_INCLUDE, GRAPH_EXECUTION_INCLUDE\nfrom backend.data.queue import AsyncRedisEventBus, RedisEventBus\nfrom backend.util import json, mock\nfrom backend.util.settings import Config\n\n"
        },
        {
            "id": "chunk_0_GlobalBlock_5",
            "code": "\n\n"
        },
        {
            "id": "chunk_1_GraphExecutionEntry_1",
            "code": "class GraphExecutionEntry(BaseModel):\n    user_id: str\n    graph_exec_id: str\n    graph_id: str\n    start_node_execs: list[\"NodeExecutionEntry\"]\n"
        },
        {
            "id": "chunk_2_NodeExecutionEntry_1",
            "code": "class NodeExecutionEntry(BaseModel):\n    user_id: str\n    graph_exec_id: str\n    graph_id: str\n    node_exec_id: str\n    node_id: str\n    data: BlockInput\n"
        },
        {
            "id": "chunk_3_ExecutionQueue_1",
            "code": "class ExecutionQueue(Generic[T]):\n    \"\"\"\n    Queue for managing the execution of agents.\n    This will be shared between different processes\n    \"\"\"\n"
        },
        {
            "id": "chunk_3_ExecutionQueue_2",
            "code": "    def __init__(self):\n        self.queue = Manager().Queue()\n"
        },
        {
            "id": "chunk_3_ExecutionQueue_3",
            "code": "    def add(self, execution: T) -> T:\n        self.queue.put(execution)\n        return execution\n"
        },
        {
            "id": "chunk_3_ExecutionQueue_4",
            "code": "    def get(self) -> T:\n        return self.queue.get()\n"
        },
        {
            "id": "chunk_3_ExecutionQueue_5",
            "code": "    def empty(self) -> bool:\n        return self.queue.empty()\n"
        },
        {
            "id": "chunk_4_ExecutionResult_1",
            "code": "class ExecutionResult(BaseModel):\n    graph_id: str\n    graph_version: int\n    graph_exec_id: str\n    node_exec_id: str\n    node_id: str\n    block_id: str\n    status: ExecutionStatus\n    input_data: BlockInput\n    output_data: CompletedBlockOutput\n    add_time: datetime\n    queue_time: datetime | None\n    start_time: datetime | None\n    end_time: datetime | None\n\n"
        },
        {
            "id": "chunk_4_ExecutionResult_2",
            "code": "    @staticmethod\n    def from_graph(graph: AgentGraphExecution):\n        return ExecutionResult(\n            graph_id=graph.agentGraphId,\n            graph_version=graph.agentGraphVersion,\n            graph_exec_id=graph.id,\n            node_exec_id=\"\",\n            node_id=\"\",\n            block_id=\"\",\n            status=graph.executionStatus,\n            # TODO: Populate input_data & output_data from AgentNodeExecutions\n            #       Input & Output comes AgentInputBlock & AgentOutputBlock.\n            input_data={},\n            output_data={},\n            add_time=graph.createdAt,\n            queue_time=graph.createdAt,\n            start_time=graph.startedAt,\n            end_time=graph.updatedAt,\n        )\n\n"
        },
        {
            "id": "chunk_4_ExecutionResult_3",
            "code": "    @staticmethod\n    def from_db(execution: AgentNodeExecution):\n        if execution.executionData:\n            # Execution that has been queued for execution will persist its data.\n            input_data = json.loads(execution.executionData, target_type=dict[str, Any])\n        else:\n            # For incomplete execution, executionData will not be yet available.\n            input_data: BlockInput = defaultdict()\n            for data in execution.Input or []:\n                input_data[data.name] = json.loads(data.data)\n\n        output_data: CompletedBlockOutput = defaultdict(list)\n        for data in execution.Output or []:\n            output_data[data.name].append(json.loads(data.data))\n\n        graph_execution: AgentGraphExecution | None = execution.AgentGraphExecution\n\n        return ExecutionResult(\n            graph_id=graph_execution.agentGraphId if graph_execution else \"\",\n            graph_version=graph_execution.agentGraphVersion if graph_execution else 0,\n            graph_exec_id=execution.agentGraphExecutionId,\n            block_id=execution.AgentNode.agentBlockId if execution.AgentNode else \"\",\n            node_exec_id=execution.id,\n            node_id=execution.agentNodeId,\n            status=execution.executionStatus,\n            input_data=input_data,\n            output_data=output_data,\n            add_time=execution.addedTime,\n            queue_time=execution.queuedTime,\n            start_time=execution.startedTime,\n            end_time=execution.endedTime,\n        )\n"
        },
        {
            "id": "chunk_5_create_graph_execution_1",
            "code": "async def create_graph_execution(\n    graph_id: str,\n    graph_version: int,\n    nodes_input: list[tuple[str, BlockInput]],\n    user_id: str,\n) -> tuple[str, list[ExecutionResult]]:\n"
        },
        {
            "id": "chunk_5_create_graph_execution_2",
            "code": "    \"\"\"\n    Create a new AgentGraphExecution record.\n    Returns:\n        The id of the AgentGraphExecution and the list of ExecutionResult for each node.\n    \"\"\"\n"
        },
        {
            "id": "chunk_5_create_graph_execution_3",
            "code": "    result = await AgentGraphExecution.prisma().create(\n        data={\n            \"agentGraphId\": graph_id,\n            \"agentGraphVersion\": graph_version,\n            \"executionStatus\": ExecutionStatus.QUEUED,\n            \"AgentNodeExecutions\": {\n                \"create\": [  # type: ignore\n                    {\n                        \"agentNodeId\": node_id,\n                        \"executionStatus\": ExecutionStatus.INCOMPLETE,\n                        \"Input\": {\n                            \"create\": [\n                                {\"name\": name, \"data\": json.dumps(data)}\n                                for name, data in node_input.items()\n                            ]\n                        },\n                    }\n                    for node_id, node_input in nodes_input\n                ]\n            },\n            \"userId\": user_id,\n        },\n        include=GRAPH_EXECUTION_INCLUDE,\n    )\n"
        },
        {
            "id": "chunk_5_create_graph_execution_4",
            "code": "    return result.id, [\n        ExecutionResult.from_db(execution)\n        for execution in result.AgentNodeExecutions or []\n    ]\n"
        },
        {
            "id": "chunk_6_upsert_execution_input_1",
            "code": "async def upsert_execution_input(\n    node_id: str,\n    graph_exec_id: str,\n    input_name: str,\n    input_data: Any,\n    node_exec_id: str | None = None,\n) -> tuple[str, BlockInput]:\n    \"\"\"\n    Insert AgentNodeExecutionInputOutput record for as one of AgentNodeExecution.Input.\n    If there is no AgentNodeExecution that has no `input_name` as input, create new one.\n\n    Args:\n        node_id: The id of the AgentNode.\n        graph_exec_id: The id of the AgentGraphExecution.\n        input_name: The name of the input data.\n        input_data: The input data to be inserted.\n        node_exec_id: [Optional] The id of the AgentNodeExecution that has no `input_name` as input. If not provided, it will find the eligible incomplete AgentNodeExecution or create a new one.\n\n    Returns:\n        * The id of the created or existing AgentNodeExecution.\n        * Dict of node input data, key is the input name, value is the input data.\n    \"\"\"\n"
        },
        {
            "id": "chunk_6_upsert_execution_input_2",
            "code": "    existing_execution = await AgentNodeExecution.prisma().find_first(\n        where={  # type: ignore\n            **({\"id\": node_exec_id} if node_exec_id else {}),\n            \"agentNodeId\": node_id,\n            \"agentGraphExecutionId\": graph_exec_id,\n            \"executionStatus\": ExecutionStatus.INCOMPLETE,\n            \"Input\": {\"every\": {\"name\": {\"not\": input_name}}},\n        },\n        order={\"addedTime\": \"asc\"},\n        include={\"Input\": True},\n    )\n"
        },
        {
            "id": "chunk_6_upsert_execution_input_3",
            "code": "    json_input_data = json.dumps(input_data)\n\n"
        },
        {
            "id": "chunk_6_upsert_execution_input_4",
            "code": "    if existing_execution:\n        await AgentNodeExecutionInputOutput.prisma().create(\n            data={\n                \"name\": input_name,\n                \"data\": json_input_data,\n                \"referencedByInputExecId\": existing_execution.id,\n            }\n        )\n        return existing_execution.id, {\n            **{\n                input_data.name: json.loads(input_data.data)\n                for input_data in existing_execution.Input or []\n            },\n            input_name: input_data,\n        }\n\n"
        },
        {
            "id": "chunk_6_upsert_execution_input_5",
            "code": "    elif not node_exec_id:\n        result = await AgentNodeExecution.prisma().create(\n            data={\n                \"agentNodeId\": node_id,\n                \"agentGraphExecutionId\": graph_exec_id,\n                \"executionStatus\": ExecutionStatus.INCOMPLETE,\n                \"Input\": {\"create\": {\"name\": input_name, \"data\": json_input_data}},\n            }\n        )\n        return result.id, {input_name: input_data}\n"
        },
        {
            "id": "chunk_6_upsert_execution_input_6",
            "code": "    else:\n        raise ValueError(\n            f\"NodeExecution {node_exec_id} not found or already has input {input_name}.\"\n        )\n"
        },
        {
            "id": "chunk_7_upsert_execution_output_1",
            "code": "async def upsert_execution_output(\n    node_exec_id: str,\n    output_name: str,\n    output_data: Any,\n) -> None:\n"
        },
        {
            "id": "chunk_7_upsert_execution_output_2",
            "code": "    \"\"\"\n    Insert AgentNodeExecutionInputOutput record for as one of AgentNodeExecution.Output.\n    \"\"\"\n"
        },
        {
            "id": "chunk_7_upsert_execution_output_3",
            "code": "    await AgentNodeExecutionInputOutput.prisma().create(\n        data={\n            \"name\": output_name,\n            \"data\": json.dumps(output_data),\n            \"referencedByOutputExecId\": node_exec_id,\n        }\n    )\n"
        },
        {
            "id": "chunk_8_update_graph_execution_start_time_1",
            "code": "async def update_graph_execution_start_time(graph_exec_id: str):\n    await AgentGraphExecution.prisma().update(\n        where={\"id\": graph_exec_id},\n        data={\n            \"executionStatus\": ExecutionStatus.RUNNING,\n            \"startedAt\": datetime.now(tz=timezone.utc),\n        },\n    )\n"
        },
        {
            "id": "chunk_9_update_graph_execution_stats_1",
            "code": "async def update_graph_execution_stats(\n    graph_exec_id: str,\n    stats: dict[str, Any],\n) -> ExecutionResult:\n"
        },
        {
            "id": "chunk_9_update_graph_execution_stats_2",
            "code": "    status = ExecutionStatus.FAILED if stats.get(\"error\") else ExecutionStatus.COMPLETED\n"
        },
        {
            "id": "chunk_9_update_graph_execution_stats_3",
            "code": "    res = await AgentGraphExecution.prisma().update(\n        where={\"id\": graph_exec_id},\n        data={\n            \"executionStatus\": status,\n            \"stats\": json.dumps(stats),\n        },\n    )\n"
        },
        {
            "id": "chunk_9_update_graph_execution_stats_4",
            "code": "    if not res:\n        raise ValueError(f\"Execution {graph_exec_id} not found.\")\n"
        },
        {
            "id": "chunk_9_update_graph_execution_stats_5",
            "code": "    return ExecutionResult.from_graph(res)\n"
        },
        {
            "id": "chunk_10_update_node_execution_stats_1",
            "code": "async def update_node_execution_stats(node_exec_id: str, stats: dict[str, Any]):\n    await AgentNodeExecution.prisma().update(\n        where={\"id\": node_exec_id},\n        data={\"stats\": json.dumps(stats)},\n    )\n"
        },
        {
            "id": "chunk_11_update_execution_status_1",
            "code": "async def update_execution_status(\n    node_exec_id: str,\n    status: ExecutionStatus,\n    execution_data: BlockInput | None = None,\n    stats: dict[str, Any] | None = None,\n) -> ExecutionResult:\n"
        },
        {
            "id": "chunk_11_update_execution_status_2",
            "code": "    if status == ExecutionStatus.QUEUED and execution_data is None:\n        raise ValueError(\"Execution data must be provided when queuing an execution.\")\n"
        },
        {
            "id": "chunk_11_update_execution_status_3",
            "code": "    now = datetime.now(tz=timezone.utc)\n    data = {\n        **({\"executionStatus\": status}),\n        **({\"queuedTime\": now} if status == ExecutionStatus.QUEUED else {}),\n        **({\"startedTime\": now} if status == ExecutionStatus.RUNNING else {}),\n        **({\"endedTime\": now} if status == ExecutionStatus.FAILED else {}),\n        **({\"endedTime\": now} if status == ExecutionStatus.COMPLETED else {}),\n        **({\"executionData\": json.dumps(execution_data)} if execution_data else {}),\n        **({\"stats\": json.dumps(stats)} if stats else {}),\n    }\n"
        },
        {
            "id": "chunk_11_update_execution_status_4",
            "code": "    res = await AgentNodeExecution.prisma().update(\n        where={\"id\": node_exec_id},\n        data=data,  # type: ignore\n        include=EXECUTION_RESULT_INCLUDE,\n    )\n"
        },
        {
            "id": "chunk_11_update_execution_status_5",
            "code": "    if not res:\n        raise ValueError(f\"Execution {node_exec_id} not found.\")\n"
        },
        {
            "id": "chunk_11_update_execution_status_6",
            "code": "    return ExecutionResult.from_db(res)\n"
        },
        {
            "id": "chunk_12_get_execution_results_1",
            "code": "async def get_execution_results(graph_exec_id: str) -> list[ExecutionResult]:\n"
        },
        {
            "id": "chunk_12_get_execution_results_2",
            "code": "    executions = await AgentNodeExecution.prisma().find_many(\n        where={\"agentGraphExecutionId\": graph_exec_id},\n        include=EXECUTION_RESULT_INCLUDE,\n        order=[\n            {\"queuedTime\": \"asc\"},\n            {\"addedTime\": \"asc\"},  # Fallback: Incomplete execs has no queuedTime.\n        ],\n    )\n"
        },
        {
            "id": "chunk_12_get_execution_results_3",
            "code": "    res = [ExecutionResult.from_db(execution) for execution in executions]\n"
        },
        {
            "id": "chunk_12_get_execution_results_4",
            "code": "    return res\n"
        },
        {
            "id": "chunk_13_parse_execution_output_1",
            "code": "def parse_execution_output(output: BlockData, name: str) -> Any | None:\n    # Allow extracting partial output data by name.\n    output_name, output_data = output\n"
        },
        {
            "id": "chunk_13_parse_execution_output_2",
            "code": "    if name == output_name:\n        return output_data\n"
        },
        {
            "id": "chunk_13_parse_execution_output_3",
            "code": "    if name.startswith(f\"{output_name}{LIST_SPLIT}\"):\n        index = int(name.split(LIST_SPLIT)[1])\n        if not isinstance(output_data, list) or len(output_data) <= index:\n            return None\n        return output_data[int(name.split(LIST_SPLIT)[1])]\n"
        },
        {
            "id": "chunk_13_parse_execution_output_4",
            "code": "    if name.startswith(f\"{output_name}{DICT_SPLIT}\"):\n        index = name.split(DICT_SPLIT)[1]\n        if not isinstance(output_data, dict) or index not in output_data:\n            return None\n        return output_data[index]\n"
        },
        {
            "id": "chunk_13_parse_execution_output_5",
            "code": "    if name.startswith(f\"{output_name}{OBJC_SPLIT}\"):\n        index = name.split(OBJC_SPLIT)[1]\n        if isinstance(output_data, object) and hasattr(output_data, index):\n            return getattr(output_data, index)\n        return None\n"
        },
        {
            "id": "chunk_13_parse_execution_output_6",
            "code": "    return None\n"
        },
        {
            "id": "chunk_14_merge_execution_input_1",
            "code": "def merge_execution_input(data: BlockInput) -> BlockInput:\n    \"\"\"\n    Merge all dynamic input pins which described by the following pattern:\n    - <input_name>_$_<index> for list input.\n    - <input_name>_#_<index> for dict input.\n    - <input_name>_@_<index> for object input.\n    This function will construct pins with the same name into a single list/dict/object.\n    \"\"\"\n"
        },
        {
            "id": "chunk_14_merge_execution_input_2",
            "code": "    # Merge all input with <input_name>_$_<index> into a single list.\n    items = list(data.items())\n"
        },
        {
            "id": "chunk_14_merge_execution_input_3",
            "code": "    for key, value in items:\n        if LIST_SPLIT not in key:\n            continue\n"
        },
        {
            "id": "chunk_14_merge_execution_input_4",
            "code": "        name, index = key.split(LIST_SPLIT)\n        if not index.isdigit():\n            raise ValueError(f\"Invalid key: {key}, #{index} index must be an integer.\")\n"
        },
        {
            "id": "chunk_14_merge_execution_input_5",
            "code": "        data[name] = data.get(name, [])\n        if int(index) >= len(data[name]):\n            # Pad list with empty string on missing indices.\n            data[name].extend([\"\"] * (int(index) - len(data[name]) + 1))\n        data[name][int(index)] = value\n"
        },
        {
            "id": "chunk_14_merge_execution_input_6",
            "code": "    # Merge all input with <input_name>_#_<index> into a single dict.\n    for key, value in items:\n        if DICT_SPLIT not in key:\n            continue\n"
        },
        {
            "id": "chunk_14_merge_execution_input_7",
            "code": "        name, index = key.split(DICT_SPLIT)\n        data[name] = data.get(name, {})\n        data[name][index] = value\n"
        },
        {
            "id": "chunk_14_merge_execution_input_8",
            "code": "    # Merge all input with <input_name>_@_<index> into a single object.\n    for key, value in items:\n        if OBJC_SPLIT not in key:\n            continue\n"
        },
        {
            "id": "chunk_14_merge_execution_input_9",
            "code": "        name, index = key.split(OBJC_SPLIT)\n        if name not in data or not isinstance(data[name], object):\n            data[name] = mock.MockObject()\n        setattr(data[name], index, value)\n"
        },
        {
            "id": "chunk_14_merge_execution_input_10",
            "code": "    return data\n"
        },
        {
            "id": "chunk_15_get_latest_execution_1",
            "code": "async def get_latest_execution(node_id: str, graph_eid: str) -> ExecutionResult | None:\n    execution = await AgentNodeExecution.prisma().find_first(\n        where={\n            \"agentNodeId\": node_id,\n            \"agentGraphExecutionId\": graph_eid,\n            \"executionStatus\": {\"not\": ExecutionStatus.INCOMPLETE},\n            \"executionData\": {\"not\": None},  # type: ignore\n        },\n        order={\"queuedTime\": \"desc\"},\n        include=EXECUTION_RESULT_INCLUDE,\n    )\n"
        },
        {
            "id": "chunk_15_get_latest_execution_2",
            "code": "    if not execution:\n        return None\n"
        },
        {
            "id": "chunk_15_get_latest_execution_3",
            "code": "    return ExecutionResult.from_db(execution)\n"
        },
        {
            "id": "chunk_16_get_incomplete_executions_1",
            "code": "async def get_incomplete_executions(\n    node_id: str, graph_eid: str\n) -> list[ExecutionResult]:\n"
        },
        {
            "id": "chunk_16_get_incomplete_executions_2",
            "code": "    executions = await AgentNodeExecution.prisma().find_many(\n        where={\n            \"agentNodeId\": node_id,\n            \"agentGraphExecutionId\": graph_eid,\n            \"executionStatus\": ExecutionStatus.INCOMPLETE,\n        },\n        include=EXECUTION_RESULT_INCLUDE,\n    )\n"
        },
        {
            "id": "chunk_16_get_incomplete_executions_3",
            "code": "    return [ExecutionResult.from_db(execution) for execution in executions]\n"
        },
        {
            "id": "chunk_17_RedisExecutionEventBus_1",
            "code": "class RedisExecutionEventBus(RedisEventBus[ExecutionResult]):\n    Model = ExecutionResult\n"
        },
        {
            "id": "chunk_17_RedisExecutionEventBus_2",
            "code": "    @property\n    def event_bus_name(self) -> str:\n        return config.execution_event_bus_name\n"
        },
        {
            "id": "chunk_17_RedisExecutionEventBus_3",
            "code": "    def publish(self, res: ExecutionResult):\n        self.publish_event(res, f\"{res.graph_id}/{res.graph_exec_id}\")\n"
        },
        {
            "id": "chunk_17_RedisExecutionEventBus_4",
            "code": "    def listen(\n        self, graph_id: str = \"*\", graph_exec_id: str = \"*\"\n    ) -> Generator[ExecutionResult, None, None]:\n        for execution_result in self.listen_events(f\"{graph_id}/{graph_exec_id}\"):\n            yield execution_result\n"
        },
        {
            "id": "chunk_18_AsyncRedisExecutionEventBus_1",
            "code": "class AsyncRedisExecutionEventBus(AsyncRedisEventBus[ExecutionResult]):\n    Model = ExecutionResult\n"
        },
        {
            "id": "chunk_18_AsyncRedisExecutionEventBus_2",
            "code": "    @property\n    def event_bus_name(self) -> str:\n        return config.execution_event_bus_name\n"
        },
        {
            "id": "chunk_18_AsyncRedisExecutionEventBus_3",
            "code": "    async def publish(self, res: ExecutionResult):\n        await self.publish_event(res, f\"{res.graph_id}/{res.graph_exec_id}\")\n"
        },
        {
            "id": "chunk_18_AsyncRedisExecutionEventBus_4",
            "code": "    async def listen(\n        self, graph_id: str = \"*\", graph_exec_id: str = \"*\"\n    ) -> AsyncGenerator[ExecutionResult, None]:\n        async for execution_result in self.listen_events(f\"{graph_id}/{graph_exec_id}\"):\n            yield execution_result\n"
        }
    ],
    "edges": [
        {
            "from": "chunk_0_GlobalBlock_1",
            "to": "chunk_0_GlobalBlock_2"
        },
        {
            "from": "chunk_0_GlobalBlock_2",
            "to": "chunk_0_GlobalBlock_3"
        },
        {
            "from": "chunk_0_GlobalBlock_3",
            "to": "chunk_0_GlobalBlock_4"
        },
        {
            "from": "chunk_0_GlobalBlock_4",
            "to": "chunk_0_GlobalBlock_5"
        },
        {
            "from": "chunk_3_ExecutionQueue_1",
            "to": "chunk_3_ExecutionQueue_2"
        },
        {
            "from": "chunk_5_create_graph_execution_1",
            "to": "chunk_5_create_graph_execution_2"
        },
        {
            "from": "chunk_5_create_graph_execution_2",
            "to": "chunk_5_create_graph_execution_3"
        },
        {
            "from": "chunk_5_create_graph_execution_3",
            "to": "chunk_5_create_graph_execution_4"
        },
        {
            "from": "chunk_6_upsert_execution_input_1",
            "to": "chunk_6_upsert_execution_input_2"
        },
        {
            "from": "chunk_6_upsert_execution_input_2",
            "to": "chunk_6_upsert_execution_input_3"
        },
        {
            "from": "chunk_6_upsert_execution_input_3",
            "to": "chunk_6_upsert_execution_input_4"
        },
        {
            "from": "chunk_6_upsert_execution_input_3",
            "to": "chunk_6_upsert_execution_input_5"
        },
        {
            "from": "chunk_6_upsert_execution_input_3",
            "to": "chunk_6_upsert_execution_input_6"
        },
        {
            "from": "chunk_7_upsert_execution_output_1",
            "to": "chunk_7_upsert_execution_output_2"
        },
        {
            "from": "chunk_7_upsert_execution_output_2",
            "to": "chunk_7_upsert_execution_output_3"
        },
        {
            "from": "chunk_9_update_graph_execution_stats_1",
            "to": "chunk_9_update_graph_execution_stats_2"
        },
        {
            "from": "chunk_9_update_graph_execution_stats_2",
            "to": "chunk_9_update_graph_execution_stats_3"
        },
        {
            "from": "chunk_9_update_graph_execution_stats_3",
            "to": "chunk_9_update_graph_execution_stats_4"
        },
        {
            "from": "chunk_9_update_graph_execution_stats_4",
            "to": "chunk_9_update_graph_execution_stats_5"
        },
        {
            "from": "chunk_11_update_execution_status_1",
            "to": "chunk_11_update_execution_status_2"
        },
        {
            "from": "chunk_11_update_execution_status_2",
            "to": "chunk_11_update_execution_status_3"
        },
        {
            "from": "chunk_11_update_execution_status_3",
            "to": "chunk_11_update_execution_status_4"
        },
        {
            "from": "chunk_11_update_execution_status_4",
            "to": "chunk_11_update_execution_status_5"
        },
        {
            "from": "chunk_11_update_execution_status_5",
            "to": "chunk_11_update_execution_status_6"
        },
        {
            "from": "chunk_12_get_execution_results_1",
            "to": "chunk_12_get_execution_results_2"
        },
        {
            "from": "chunk_12_get_execution_results_2",
            "to": "chunk_12_get_execution_results_3"
        },
        {
            "from": "chunk_12_get_execution_results_3",
            "to": "chunk_12_get_execution_results_4"
        },
        {
            "from": "chunk_13_parse_execution_output_1",
            "to": "chunk_13_parse_execution_output_2"
        },
        {
            "from": "chunk_13_parse_execution_output_2",
            "to": "chunk_13_parse_execution_output_3"
        },
        {
            "from": "chunk_13_parse_execution_output_2",
            "to": "chunk_13_parse_execution_output_6"
        },
        {
            "from": "chunk_13_parse_execution_output_3",
            "to": "chunk_13_parse_execution_output_4"
        },
        {
            "from": "chunk_13_parse_execution_output_3",
            "to": "chunk_13_parse_execution_output_6"
        },
        {
            "from": "chunk_13_parse_execution_output_4",
            "to": "chunk_13_parse_execution_output_5"
        },
        {
            "from": "chunk_13_parse_execution_output_4",
            "to": "chunk_13_parse_execution_output_6"
        },
        {
            "from": "chunk_13_parse_execution_output_5",
            "to": "chunk_13_parse_execution_output_6"
        },
        {
            "from": "chunk_14_merge_execution_input_1",
            "to": "chunk_14_merge_execution_input_2"
        },
        {
            "from": "chunk_14_merge_execution_input_2",
            "to": "chunk_14_merge_execution_input_3"
        },
        {
            "from": "chunk_14_merge_execution_input_3",
            "to": "chunk_14_merge_execution_input_4"
        },
        {
            "from": "chunk_14_merge_execution_input_3",
            "to": "chunk_14_merge_execution_input_6"
        },
        {
            "from": "chunk_14_merge_execution_input_4",
            "to": "chunk_14_merge_execution_input_5"
        },
        {
            "from": "chunk_14_merge_execution_input_5",
            "to": "chunk_14_merge_execution_input_3"
        },
        {
            "from": "chunk_14_merge_execution_input_6",
            "to": "chunk_14_merge_execution_input_7"
        },
        {
            "from": "chunk_14_merge_execution_input_6",
            "to": "chunk_14_merge_execution_input_8"
        },
        {
            "from": "chunk_14_merge_execution_input_7",
            "to": "chunk_14_merge_execution_input_6"
        },
        {
            "from": "chunk_14_merge_execution_input_8",
            "to": "chunk_14_merge_execution_input_9"
        },
        {
            "from": "chunk_14_merge_execution_input_8",
            "to": "chunk_14_merge_execution_input_10"
        },
        {
            "from": "chunk_14_merge_execution_input_9",
            "to": "chunk_14_merge_execution_input_8"
        },
        {
            "from": "chunk_15_get_latest_execution_1",
            "to": "chunk_15_get_latest_execution_2"
        },
        {
            "from": "chunk_15_get_latest_execution_2",
            "to": "chunk_15_get_latest_execution_3"
        },
        {
            "from": "chunk_16_get_incomplete_executions_1",
            "to": "chunk_16_get_incomplete_executions_2"
        },
        {
            "from": "chunk_16_get_incomplete_executions_2",
            "to": "chunk_16_get_incomplete_executions_3"
        },
        {
            "from": "chunk_17_RedisExecutionEventBus_1",
            "to": "chunk_17_RedisExecutionEventBus_2"
        },
        {
            "from": "chunk_17_RedisExecutionEventBus_1",
            "to": "chunk_17_RedisExecutionEventBus_3"
        },
        {
            "from": "chunk_17_RedisExecutionEventBus_1",
            "to": "chunk_17_RedisExecutionEventBus_4"
        }
    ]
}