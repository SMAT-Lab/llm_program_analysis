{
    "nodes": [
        {
            "id": "chunk_0_GlobalBlock_1",
            "code": "from backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema\nfrom backend.data.model import ContributorDetails, SchemaField\n"
        },
        {
            "id": "chunk_0_GlobalBlock_2",
            "code": "\n\n\n"
        },
        {
            "id": "chunk_1_ReadCsvBlock_1",
            "code": "class ReadCsvBlock(Block):\n"
        },
        {
            "id": "chunk_1_ReadCsvBlock_2",
            "code": "    class Input(BlockSchema):\n        contents: str = SchemaField(\n            description=\"The contents of the CSV file to read\",\n            placeholder=\"a, b, c\\n1,2,3\\n4,5,6\",\n        )\n        delimiter: str = SchemaField(\n            description=\"The delimiter used in the CSV file\",\n            default=\",\",\n        )\n        quotechar: str = SchemaField(\n            description=\"The character used to quote fields\",\n            default='\"',\n        )\n        escapechar: str = SchemaField(\n            description=\"The character used to escape the delimiter\",\n            default=\"\\\\\",\n        )\n        has_header: bool = SchemaField(\n            description=\"Whether the CSV file has a header row\",\n            default=True,\n        )\n        skip_rows: int = SchemaField(\n            description=\"The number of rows to skip from the start of the file\",\n            default=0,\n        )\n        strip: bool = SchemaField(\n            description=\"Whether to strip whitespace from the values\",\n            default=True,\n        )\n        skip_columns: list[str] = SchemaField(\n            description=\"The columns to skip from the start of the row\",\n            default=[],\n        )\n"
        },
        {
            "id": "chunk_1_ReadCsvBlock_3",
            "code": "    class Output(BlockSchema):\n        row: dict[str, str] = SchemaField(\n            description=\"The data produced from each row in the CSV file\"\n        )\n        all_data: list[dict[str, str]] = SchemaField(\n            description=\"All the data in the CSV file as a list of rows\"\n        )\n"
        },
        {
            "id": "chunk_1_ReadCsvBlock_4",
            "code": "    def __init__(self):\n        super().__init__(\n            id=\"acf7625e-d2cb-4941-bfeb-2819fc6fc015\",\n            input_schema=ReadCsvBlock.Input,\n            output_schema=ReadCsvBlock.Output,\n            description=\"Reads a CSV file and outputs the data as a list of dictionaries and individual rows via rows.\",\n            contributors=[ContributorDetails(name=\"Nicholas Tindle\")],\n            categories={BlockCategory.TEXT, BlockCategory.DATA},\n            test_input={\n                \"contents\": \"a, b, c\\n1,2,3\\n4,5,6\",\n            },\n            test_output=[\n                (\"row\", {\"a\": \"1\", \"b\": \"2\", \"c\": \"3\"}),\n                (\"row\", {\"a\": \"4\", \"b\": \"5\", \"c\": \"6\"}),\n                (\n                    \"all_data\",\n                    [\n                        {\"a\": \"1\", \"b\": \"2\", \"c\": \"3\"},\n                        {\"a\": \"4\", \"b\": \"5\", \"c\": \"6\"},\n                    ],\n                ),\n            ],\n        )\n"
        },
        {
            "id": "chunk_1_ReadCsvBlock_5",
            "code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n"
        },
        {
            "id": "chunk_1_ReadCsvBlock_6",
            "code": "        import csv\n        from io import StringIO\n"
        },
        {
            "id": "chunk_1_ReadCsvBlock_7",
            "code": "        csv_file = StringIO(input_data.contents)\n        reader = csv.reader(\n            csv_file,\n            delimiter=input_data.delimiter,\n            quotechar=input_data.quotechar,\n            escapechar=input_data.escapechar,\n        )\n"
        },
        {
            "id": "chunk_1_ReadCsvBlock_8",
            "code": "        header = None\n"
        },
        {
            "id": "chunk_1_ReadCsvBlock_9",
            "code": "        if input_data.has_header:\n            header = next(reader)\n            if input_data.strip:\n                header = [h.strip() for h in header]\n\n"
        },
        {
            "id": "chunk_1_ReadCsvBlock_10",
            "code": "        for _ in range(input_data.skip_rows):\n            next(reader)\n"
        },
        {
            "id": "chunk_1_ReadCsvBlock_11",
            "code": "        def process_row(row):\n            data = {}\n            for i, value in enumerate(row):\n                if i not in input_data.skip_columns:\n                    if input_data.has_header and header:\n                        data[header[i]] = value.strip() if input_data.strip else value\n                    else:\n                        data[str(i)] = value.strip() if input_data.strip else value\n            return data\n"
        },
        {
            "id": "chunk_1_ReadCsvBlock_12",
            "code": "        all_data = []\n"
        },
        {
            "id": "chunk_1_ReadCsvBlock_13",
            "code": "        for row in reader:\n            processed_row = process_row(row)\n            all_data.append(processed_row)\n            yield \"row\", processed_row\n"
        },
        {
            "id": "chunk_1_ReadCsvBlock_14",
            "code": "        yield \"all_data\", all_data\n"
        },
        {
            "id": "chunk_2_ReadCsvBlock.Input_1",
            "code": "    class Input(BlockSchema):\n"
        },
        {
            "id": "chunk_2_ReadCsvBlock.Input_2",
            "code": "        contents: str = SchemaField(\n            description=\"The contents of the CSV file to read\",\n            placeholder=\"a, b, c\\n1,2,3\\n4,5,6\",\n        )\n"
        },
        {
            "id": "chunk_2_ReadCsvBlock.Input_3",
            "code": "        delimiter: str = SchemaField(\n            description=\"The delimiter used in the CSV file\",\n            default=\",\",\n        )\n"
        },
        {
            "id": "chunk_2_ReadCsvBlock.Input_4",
            "code": "        quotechar: str = SchemaField(\n            description=\"The character used to quote fields\",\n            default='\"',\n        )\n"
        },
        {
            "id": "chunk_2_ReadCsvBlock.Input_5",
            "code": "        escapechar: str = SchemaField(\n            description=\"The character used to escape the delimiter\",\n            default=\"\\\\\",\n        )\n"
        },
        {
            "id": "chunk_2_ReadCsvBlock.Input_6",
            "code": "        has_header: bool = SchemaField(\n            description=\"Whether the CSV file has a header row\",\n            default=True,\n        )\n"
        },
        {
            "id": "chunk_2_ReadCsvBlock.Input_7",
            "code": "        skip_rows: int = SchemaField(\n            description=\"The number of rows to skip from the start of the file\",\n            default=0,\n        )\n"
        },
        {
            "id": "chunk_2_ReadCsvBlock.Input_8",
            "code": "        strip: bool = SchemaField(\n            description=\"Whether to strip whitespace from the values\",\n            default=True,\n        )\n"
        },
        {
            "id": "chunk_2_ReadCsvBlock.Input_9",
            "code": "        skip_columns: list[str] = SchemaField(\n            description=\"The columns to skip from the start of the row\",\n            default=[],\n        )\n"
        },
        {
            "id": "chunk_3_ReadCsvBlock.Output_1",
            "code": "    class Output(BlockSchema):\n        row: dict[str, str] = SchemaField(\n            description=\"The data produced from each row in the CSV file\"\n        )\n"
        },
        {
            "id": "chunk_3_ReadCsvBlock.Output_2",
            "code": "        all_data: list[dict[str, str]] = SchemaField(\n            description=\"All the data in the CSV file as a list of rows\"\n        )\n"
        },
        {
            "id": "chunk_4_ReadCsvBlock.__init___1",
            "code": "    def __init__(self):\n        super().__init__(\n            id=\"acf7625e-d2cb-4941-bfeb-2819fc6fc015\",\n            input_schema=ReadCsvBlock.Input,\n            output_schema=ReadCsvBlock.Output,\n            description=\"Reads a CSV file and outputs the data as a list of dictionaries and individual rows via rows.\",\n            contributors=[ContributorDetails(name=\"Nicholas Tindle\")],\n            categories={BlockCategory.TEXT, BlockCategory.DATA},\n            test_input={\n                \"contents\": \"a, b, c\\n1,2,3\\n4,5,6\",\n            },\n            test_output=[\n                (\"row\", {\"a\": \"1\", \"b\": \"2\", \"c\": \"3\"}),\n                (\"row\", {\"a\": \"4\", \"b\": \"5\", \"c\": \"6\"}),\n                (\n                    \"all_data\",\n                    [\n                        {\"a\": \"1\", \"b\": \"2\", \"c\": \"3\"},\n                        {\"a\": \"4\", \"b\": \"5\", \"c\": \"6\"},\n                    ],\n                ),\n            ],\n        )\n"
        },
        {
            "id": "chunk_5_ReadCsvBlock.run_1",
            "code": "    def run(self, input_data: Input, **kwargs) -> BlockOutput:\n"
        },
        {
            "id": "chunk_5_ReadCsvBlock.run_2",
            "code": "        import csv\n        from io import StringIO\n"
        },
        {
            "id": "chunk_5_ReadCsvBlock.run_3",
            "code": "        csv_file = StringIO(input_data.contents)\n        reader = csv.reader(\n            csv_file,\n            delimiter=input_data.delimiter,\n            quotechar=input_data.quotechar,\n            escapechar=input_data.escapechar,\n        )\n"
        },
        {
            "id": "chunk_5_ReadCsvBlock.run_4",
            "code": "        header = None\n"
        },
        {
            "id": "chunk_5_ReadCsvBlock.run_5",
            "code": "        if input_data.has_header:\n            header = next(reader)\n            if input_data.strip:\n                header = [h.strip() for h in header]\n\n"
        },
        {
            "id": "chunk_5_ReadCsvBlock.run_6",
            "code": "        for _ in range(input_data.skip_rows):\n            next(reader)\n"
        },
        {
            "id": "chunk_5_ReadCsvBlock.run_7",
            "code": "        def process_row(row):\n            data = {}\n            for i, value in enumerate(row):\n                if i not in input_data.skip_columns:\n                    if input_data.has_header and header:\n                        data[header[i]] = value.strip() if input_data.strip else value\n                    else:\n                        data[str(i)] = value.strip() if input_data.strip else value\n            return data\n"
        },
        {
            "id": "chunk_5_ReadCsvBlock.run_8",
            "code": "        all_data = []\n"
        },
        {
            "id": "chunk_5_ReadCsvBlock.run_9",
            "code": "        for row in reader:\n            processed_row = process_row(row)\n            all_data.append(processed_row)\n            yield \"row\", processed_row\n"
        },
        {
            "id": "chunk_5_ReadCsvBlock.run_10",
            "code": "        yield \"all_data\", all_data\n"
        },
        {
            "id": "chunk_6_process_row_1",
            "code": "        def process_row(row):\n            data = {}\n"
        },
        {
            "id": "chunk_6_process_row_2",
            "code": "            for i, value in enumerate(row):\n"
        },
        {
            "id": "chunk_6_process_row_3",
            "code": "                if i not in input_data.skip_columns:\n                    if input_data.has_header and header:\n"
        },
        {
            "id": "chunk_6_process_row_4",
            "code": "                        data[header[i]] = value.strip() if input_data.strip else value\n"
        },
        {
            "id": "chunk_6_process_row_5",
            "code": "                    else:\n                        data[str(i)] = value.strip() if input_data.strip else value\n"
        },
        {
            "id": "chunk_6_process_row_6",
            "code": "            return data\n"
        }
    ],
    "edges": [
        {
            "from": "chunk_0_GlobalBlock_1",
            "to": "chunk_0_GlobalBlock_2"
        },
        {
            "from": "chunk_1_ReadCsvBlock_1",
            "to": "chunk_1_ReadCsvBlock_2"
        },
        {
            "from": "chunk_1_ReadCsvBlock_1",
            "to": "chunk_1_ReadCsvBlock_3"
        },
        {
            "from": "chunk_1_ReadCsvBlock_1",
            "to": "chunk_1_ReadCsvBlock_4"
        },
        {
            "from": "chunk_1_ReadCsvBlock_4",
            "to": "chunk_1_ReadCsvBlock_5"
        },
        {
            "from": "chunk_1_ReadCsvBlock_5",
            "to": "chunk_1_ReadCsvBlock_6"
        },
        {
            "from": "chunk_1_ReadCsvBlock_6",
            "to": "chunk_1_ReadCsvBlock_7"
        },
        {
            "from": "chunk_1_ReadCsvBlock_7",
            "to": "chunk_1_ReadCsvBlock_8"
        },
        {
            "from": "chunk_1_ReadCsvBlock_8",
            "to": "chunk_1_ReadCsvBlock_9"
        },
        {
            "from": "chunk_1_ReadCsvBlock_9",
            "to": "chunk_1_ReadCsvBlock_10"
        },
        {
            "from": "chunk_1_ReadCsvBlock_10",
            "to": "chunk_1_ReadCsvBlock_11"
        },
        {
            "from": "chunk_1_ReadCsvBlock_11",
            "to": "chunk_1_ReadCsvBlock_12"
        },
        {
            "from": "chunk_1_ReadCsvBlock_12",
            "to": "chunk_1_ReadCsvBlock_13"
        },
        {
            "from": "chunk_1_ReadCsvBlock_13",
            "to": "chunk_1_ReadCsvBlock_14"
        },
        {
            "from": "chunk_2_ReadCsvBlock.Input_1",
            "to": "chunk_2_ReadCsvBlock.Input_2"
        },
        {
            "from": "chunk_2_ReadCsvBlock.Input_2",
            "to": "chunk_2_ReadCsvBlock.Input_3"
        },
        {
            "from": "chunk_2_ReadCsvBlock.Input_3",
            "to": "chunk_2_ReadCsvBlock.Input_4"
        },
        {
            "from": "chunk_2_ReadCsvBlock.Input_4",
            "to": "chunk_2_ReadCsvBlock.Input_5"
        },
        {
            "from": "chunk_2_ReadCsvBlock.Input_5",
            "to": "chunk_2_ReadCsvBlock.Input_6"
        },
        {
            "from": "chunk_2_ReadCsvBlock.Input_6",
            "to": "chunk_2_ReadCsvBlock.Input_7"
        },
        {
            "from": "chunk_2_ReadCsvBlock.Input_7",
            "to": "chunk_2_ReadCsvBlock.Input_8"
        },
        {
            "from": "chunk_2_ReadCsvBlock.Input_8",
            "to": "chunk_2_ReadCsvBlock.Input_9"
        },
        {
            "from": "chunk_3_ReadCsvBlock.Output_1",
            "to": "chunk_3_ReadCsvBlock.Output_2"
        },
        {
            "from": "chunk_5_ReadCsvBlock.run_1",
            "to": "chunk_5_ReadCsvBlock.run_2"
        },
        {
            "from": "chunk_5_ReadCsvBlock.run_2",
            "to": "chunk_5_ReadCsvBlock.run_3"
        },
        {
            "from": "chunk_5_ReadCsvBlock.run_3",
            "to": "chunk_5_ReadCsvBlock.run_4"
        },
        {
            "from": "chunk_5_ReadCsvBlock.run_4",
            "to": "chunk_5_ReadCsvBlock.run_5"
        },
        {
            "from": "chunk_5_ReadCsvBlock.run_5",
            "to": "chunk_5_ReadCsvBlock.run_6"
        },
        {
            "from": "chunk_5_ReadCsvBlock.run_6",
            "to": "chunk_5_ReadCsvBlock.run_7"
        },
        {
            "from": "chunk_5_ReadCsvBlock.run_8",
            "to": "chunk_5_ReadCsvBlock.run_9"
        },
        {
            "from": "chunk_5_ReadCsvBlock.run_9",
            "to": "chunk_5_ReadCsvBlock.run_10"
        },
        {
            "from": "chunk_6_process_row_1",
            "to": "chunk_6_process_row_2"
        },
        {
            "from": "chunk_6_process_row_2",
            "to": "chunk_6_process_row_3"
        },
        {
            "from": "chunk_6_process_row_2",
            "to": "chunk_6_process_row_6"
        },
        {
            "from": "chunk_6_process_row_3",
            "to": "chunk_6_process_row_4"
        },
        {
            "from": "chunk_6_process_row_3",
            "to": "chunk_6_process_row_5"
        },
        {
            "from": "chunk_6_process_row_4",
            "to": "chunk_6_process_row_2"
        },
        {
            "from": "chunk_6_process_row_5",
            "to": "chunk_6_process_row_2"
        }
    ]
}