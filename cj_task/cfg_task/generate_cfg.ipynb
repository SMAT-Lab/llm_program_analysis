{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy Generate CFG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "效果不太好，还是需要我们一步步进行处理！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step1 先将文件的嵌套类，方法给找到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/0.cj\n",
      "Processing ../../dataset/cangjie/1.cj\n",
      "Processing ../../dataset/cangjie/2.cj\n",
      "Processing ../../dataset/cangjie/3.cj\n",
      "Processing ../../dataset/cangjie/5.cj\n",
      "Processing ../../dataset/cangjie/4.cj\n",
      "Processing ../../dataset/cangjie/7.cj\n",
      "Processing ../../dataset/cangjie/6.cj\n",
      "Processing ../../dataset/cangjie/8.cj\n",
      "Processing ../../dataset/cangjie/9.cj\n",
      "Processing ../../dataset/cangjie/10.cj\n",
      "Processing ../../dataset/cangjie/11.cj\n",
      "Processing ../../dataset/cangjie/13.cj\n",
      "Processing ../../dataset/cangjie/14.cj\n",
      "Processing ../../dataset/cangjie/12.cj\n",
      "Processing ../../dataset/cangjie/15.cj\n",
      "Processing ../../dataset/cangjie/16.cj\n",
      "Processing ../../dataset/cangjie/17.cj\n",
      "Processing ../../dataset/cangjie/18.cj\n",
      "Processing ../../dataset/cangjie/21.cj\n",
      "Processing ../../dataset/cangjie/19.cj\n",
      "Processing ../../dataset/cangjie/22.cj\n",
      "Processing ../../dataset/cangjie/20.cj\n",
      "Processing ../../dataset/cangjie/24.cj\n",
      "Processing ../../dataset/cangjie/23.cj\n",
      "Processing ../../dataset/cangjie/25.cj\n",
      "Processing ../../dataset/cangjie/26.cj\n",
      "Processing ../../dataset/cangjie/27.cj\n",
      "Processing ../../dataset/cangjie/28.cj\n",
      "Processing ../../dataset/cangjie/29.cj\n",
      "Processing ../../dataset/cangjie/30.cj\n",
      "Processing ../../dataset/cangjie/31.cj\n",
      "Processing ../../dataset/cangjie/32.cj\n",
      "Processing ../../dataset/cangjie/33.cj\n",
      "Processing ../../dataset/cangjie/34.cj\n",
      "Processing ../../dataset/cangjie/35.cj\n",
      "Processing ../../dataset/cangjie/36.cj\n",
      "Processing ../../dataset/cangjie/37.cj\n",
      "Processing ../../dataset/cangjie/38.cj\n",
      "Processing ../../dataset/cangjie/39.cj\n",
      "Processing ../../dataset/cangjie/40.cj\n",
      "Processing ../../dataset/cangjie/41.cj\n",
      "Processing ../../dataset/cangjie/43.cj\n",
      "Processing ../../dataset/cangjie/42.cj\n",
      "Processing ../../dataset/cangjie/44.cj\n",
      "Processing ../../dataset/cangjie/45.cj\n",
      "Processing ../../dataset/cangjie/46.cj\n",
      "Processing ../../dataset/cangjie/47.cj\n",
      "Processing ../../dataset/cangjie/49.cj\n",
      "Processing ../../dataset/cangjie/48.cj\n",
      "Processing ../../dataset/cangjie/51.cj\n",
      "Processing ../../dataset/cangjie/50.cj\n",
      "Processing ../../dataset/cangjie/52.cj\n",
      "Processing ../../dataset/cangjie/53.cj\n",
      "Processing ../../dataset/cangjie/54.cj\n",
      "Processing ../../dataset/cangjie/55.cj\n",
      "Processing ../../dataset/cangjie/56.cj\n",
      "Processing ../../dataset/cangjie/57.cj\n",
      "Processing ../../dataset/cangjie/58.cj\n",
      "Processing ../../dataset/cangjie/59.cj\n",
      "Processing ../../dataset/cangjie/61.cj\n",
      "Processing ../../dataset/cangjie/60.cj\n",
      "Processing ../../dataset/cangjie/62.cj\n",
      "Processing ../../dataset/cangjie/63.cj\n",
      "Processing ../../dataset/cangjie/64.cj\n",
      "Processing ../../dataset/cangjie/65.cj\n",
      "Processing ../../dataset/cangjie/66.cj\n",
      "Processing ../../dataset/cangjie/68.cj\n",
      "Processing ../../dataset/cangjie/67.cj\n",
      "Processing ../../dataset/cangjie/69.cj\n",
      "Processing ../../dataset/cangjie/70.cj\n",
      "Processing ../../dataset/cangjie/72.cj\n",
      "Processing ../../dataset/cangjie/71.cj\n",
      "Processing ../../dataset/cangjie/74.cj\n",
      "Processing ../../dataset/cangjie/73.cj\n",
      "Processing ../../dataset/cangjie/76.cj\n",
      "Processing ../../dataset/cangjie/75.cj\n",
      "Processing ../../dataset/cangjie/77.cj\n",
      "Processing ../../dataset/cangjie/78.cj\n",
      "Processing ../../dataset/cangjie/80.cj\n",
      "Processing ../../dataset/cangjie/79.cj\n",
      "Processing ../../dataset/cangjie/81.cj\n",
      "Processing ../../dataset/cangjie/82.cj\n",
      "Processing ../../dataset/cangjie/83.cj\n",
      "Processing ../../dataset/cangjie/84.cj\n",
      "Processing ../../dataset/cangjie/85.cj\n",
      "Processing ../../dataset/cangjie/86.cj\n",
      "Processing ../../dataset/cangjie/88.cj\n",
      "Processing ../../dataset/cangjie/87.cj\n",
      "Processing ../../dataset/cangjie/89.cj\n",
      "Processing ../../dataset/cangjie/90.cj\n",
      "Processing ../../dataset/cangjie/91.cj\n",
      "Processing ../../dataset/cangjie/92.cj\n",
      "Processing ../../dataset/cangjie/93.cj\n",
      "Processing ../../dataset/cangjie/94.cj\n",
      "Processing ../../dataset/cangjie/95.cj\n",
      "Processing ../../dataset/cangjie/96.cj\n",
      "Processing ../../dataset/cangjie/97.cj\n",
      "Processing ../../dataset/cangjie/98.cj\n",
      "Processing ../../dataset/cangjie/99.cj\n",
      "Processing ../../dataset/cangjie/100.cj\n",
      "Processing ../../dataset/cangjie/101.cj\n",
      "Processing ../../dataset/cangjie/102.cj\n",
      "Processing ../../dataset/cangjie/103.cj\n",
      "Processing ../../dataset/cangjie/104.cj\n",
      "Processing ../../dataset/cangjie/106.cj\n",
      "Processing ../../dataset/cangjie/105.cj\n",
      "Processing ../../dataset/cangjie/107.cj\n",
      "Processing ../../dataset/cangjie/108.cj\n",
      "Processing ../../dataset/cangjie/110.cj\n",
      "Processing ../../dataset/cangjie/109.cj\n",
      "Processing ../../dataset/cangjie/111.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:   0%|          | 1/200 [00:13<44:46, 13.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/112.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:   1%|          | 2/200 [00:14<20:52,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/113.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:   2%|▏         | 3/200 [00:15<12:14,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/114.cj\n",
      "Processing ../../dataset/cangjie/115.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:   2%|▎         | 5/200 [00:16<05:49,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/116.cj\n",
      "Processing ../../dataset/cangjie/117.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:   4%|▎         | 7/200 [00:16<03:38,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/118.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:   4%|▍         | 8/200 [00:17<03:07,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/119.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:   4%|▍         | 9/200 [00:17<02:35,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/120.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:   6%|▌         | 11/200 [00:19<02:22,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/121.cj\n",
      "Processing ../../dataset/cangjie/122.cj\n",
      "Processing ../../dataset/cangjie/123.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:   6%|▋         | 13/200 [00:20<02:05,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/124.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:   7%|▋         | 14/200 [00:20<01:57,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/125.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:   8%|▊         | 15/200 [00:21<01:46,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/126.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:   8%|▊         | 16/200 [00:21<01:42,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/127.cj\n",
      "Processing ../../dataset/cangjie/128.cj\n",
      "Processing ../../dataset/cangjie/129.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  10%|█         | 20/200 [00:22<00:47,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/130.cj\n",
      "Processing ../../dataset/cangjie/131.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  10%|█         | 21/200 [00:22<00:57,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/132.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  11%|█         | 22/200 [00:23<01:13,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/133.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  12%|█▏        | 23/200 [00:23<01:05,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/134.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  12%|█▎        | 25/200 [00:24<01:05,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/135.cj\n",
      "Processing ../../dataset/cangjie/136.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  13%|█▎        | 26/200 [00:25<01:39,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/137.cj\n",
      "Processing ../../dataset/cangjie/138.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  14%|█▍        | 28/200 [00:27<02:30,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/139.cj\n",
      "Processing ../../dataset/cangjie/140.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  16%|█▌        | 31/200 [00:28<01:38,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/141.cj\n",
      "Processing ../../dataset/cangjie/142.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  16%|█▌        | 32/200 [00:29<01:45,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/143.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  16%|█▋        | 33/200 [00:30<01:39,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/144.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  17%|█▋        | 34/200 [00:31<02:03,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/145.cj\n",
      "Processing ../../dataset/cangjie/146.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  18%|█▊        | 36/200 [00:31<01:26,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/147.cj\n",
      "Processing ../../dataset/cangjie/148.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  19%|█▉        | 38/200 [00:32<01:04,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/149.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  20%|█▉        | 39/200 [00:33<01:17,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/150.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  20%|██        | 40/200 [00:37<03:40,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/151.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  20%|██        | 41/200 [00:37<03:09,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/152.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  21%|██        | 42/200 [00:38<02:38,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/153.cj\n",
      "Processing ../../dataset/cangjie/154.cj\n",
      "Processing ../../dataset/cangjie/155.cj\n",
      "Processing ../../dataset/cangjie/156.cj\n",
      "Processing ../../dataset/cangjie/157.cj\n",
      "Processing ../../dataset/cangjie/158.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  24%|██▍       | 48/200 [00:38<00:51,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/159.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  24%|██▍       | 49/200 [00:40<01:15,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/160.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  25%|██▌       | 50/200 [00:40<01:19,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/161.cj\n",
      "Processing ../../dataset/cangjie/162.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  26%|██▌       | 52/200 [00:41<01:01,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/163.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  26%|██▋       | 53/200 [00:41<01:08,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/164.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  27%|██▋       | 54/200 [00:43<01:38,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/165.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  28%|██▊       | 55/200 [00:43<01:36,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/166.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  28%|██▊       | 56/200 [00:44<01:31,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/167.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  28%|██▊       | 57/200 [00:44<01:16,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/168.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  30%|██▉       | 59/200 [00:45<00:59,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/169.cj\n",
      "Processing ../../dataset/cangjie/170.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  30%|███       | 60/200 [00:45<00:46,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/171.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  32%|███▏      | 63/200 [00:46<00:32,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/172.cj\n",
      "Processing ../../dataset/cangjie/173.cj\n",
      "Processing ../../dataset/cangjie/174.cj\n",
      "Processing ../../dataset/cangjie/175.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  32%|███▎      | 65/200 [00:47<00:50,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/176.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  33%|███▎      | 66/200 [00:48<01:25,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/177.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  34%|███▍      | 69/200 [00:50<01:02,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/178.cj\n",
      "Processing ../../dataset/cangjie/179.cj\n",
      "Processing ../../dataset/cangjie/180.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  35%|███▌      | 70/200 [00:50<01:04,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/181.cj\n",
      "Processing ../../dataset/cangjie/182.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  36%|███▌      | 72/200 [00:51<00:53,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/183.cj\n",
      "Processing ../../dataset/cangjie/184.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  37%|███▋      | 74/200 [00:51<00:39,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/185.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  38%|███▊      | 77/200 [00:52<00:37,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/186.cj\n",
      "Processing ../../dataset/cangjie/187.cj\n",
      "Processing ../../dataset/cangjie/188.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  39%|███▉      | 78/200 [00:53<00:49,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/189.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  40%|███▉      | 79/200 [00:53<00:45,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/190.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  40%|████      | 80/200 [00:54<00:47,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/191.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  40%|████      | 81/200 [00:55<01:06,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/192.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  41%|████      | 82/200 [00:55<00:58,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/193.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  42%|████▏     | 83/200 [00:55<00:48,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/194.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  42%|████▏     | 84/200 [00:56<00:59,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/195.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  42%|████▎     | 85/200 [00:56<00:51,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/196.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  43%|████▎     | 86/200 [00:57<01:07,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/197.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  44%|████▍     | 88/200 [00:58<00:47,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../dataset/cangjie/198.cj\n",
      "Processing ../../dataset/cangjie/199.cj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理CFG文件:  98%|█████████▊| 197/200 [05:16<00:35, 11.82s/it]"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from concurrent.futures import as_completed, ThreadPoolExecutor\n",
    "from multiprocessing import cpu_count\n",
    "from functools import partial\n",
    "\n",
    "# 这里假设你有一个自己封装的 get_llm_answers 函数\n",
    "# 请根据实际情况导入\n",
    "from llm import get_llm_answers\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_step1_prompt(code_text: str, program_language: str):\n",
    "    \"\"\"\n",
    "    生成第一步的 Prompt，用于让大模型识别所有类和函数（以及嵌套关系）。\n",
    "    注意，这里去掉了原先的三重反引号。\n",
    "    \"\"\"\n",
    "    code_lines = code_text.splitlines()\n",
    "    code_lines_json = [{\n",
    "        \"line\": i + 1,\n",
    "        \"code\": line\n",
    "    } for i, line in enumerate(code_lines)]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are given a piece of {program_language} code. Your goal is to find all the nested classes and methods in the code.\n",
    "\n",
    "Please return the result in JSON format, your output should be the following format:\n",
    "\n",
    "{{\n",
    "    \"name\": \"example_script\",  // Name of the script or function\n",
    "    \"type\": \"CFG\",\n",
    "    \"start_line\": number,\n",
    "    \"end_line\": number,\n",
    "    \"functions\": [\n",
    "      {{\n",
    "        \"name\": \"function_name\",\n",
    "        \"type\": \"function\",\n",
    "        \"start_line\": number,\n",
    "        \"end_line\": number,\n",
    "        \"functions\": [],         // Nested functions\n",
    "        \"classes\": []            // Nested classes\n",
    "      }}\n",
    "    ],\n",
    "    \"classes\": [\n",
    "      {{\n",
    "        \"name\": \"class_name\",\n",
    "        \"type\": \"class\",\n",
    "        \"start_line\": number,\n",
    "        \"end_line\": number,\n",
    "        \"functions\": [           // Methods of the class\n",
    "          {{\n",
    "            \"name\": \"method_name\",\n",
    "            \"type\": \"function\",\n",
    "            \"start_line\": number,\n",
    "            \"end_line\": number,\n",
    "            \"functions\": [],     // Nested functions\n",
    "            \"classes\": []        // Nested classes\n",
    "          }}\n",
    "        ]\n",
    "      }}\n",
    "    ]\n",
    "}}\n",
    "\n",
    "The code lines are:\n",
    "{json.dumps(code_lines_json, indent=2)}\n",
    "\n",
    "IMPORTANT: Make sure that the nested classes and methods are in the correct level. For example, if a function is nested in another class, the function should be in the nested class's functions list.\n",
    "Besides, if a class is nested in another class, the class should be in the nested class's classes list.\n",
    "\"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "\n",
    "def find_nested_classes_and_methods(code_text: str, program_language: str):\n",
    "    \"\"\"\n",
    "    调用 LLM，让其识别文件中的嵌套类、函数，并返回 JSON 结构。\n",
    "    \"\"\"\n",
    "    prompt = get_step1_prompt(code_text, program_language)\n",
    "    response = get_llm_answers(prompt, model_name=\"gpt-4o\", require_json=True)\n",
    "    nested_classes_and_methods = json.loads(response)\n",
    "    return nested_classes_and_methods\n",
    "\n",
    "\n",
    "def process_file_with_chain_of_thought(code_text: str, program_language: str):\n",
    "    \"\"\"\n",
    "    读取代码文本 -> 让大模型找出所有嵌套类/函数 -> 返回 JSON 结构\n",
    "    \"\"\"\n",
    "    step1_result = find_nested_classes_and_methods(code_text, program_language)\n",
    "    return step1_result\n",
    "\n",
    "\n",
    "def get_code_by_line_range(code_block, code):\n",
    "    \"\"\"\n",
    "    取出 code_block 代表的行范围(start_line~end_line)，并且排除其内部嵌套类/函数的所有行。\n",
    "    最终保留一组 { \"lineno\", \"line\" } 数组，方便后续做 CFG 时保留原始行号。\n",
    "    \"\"\"\n",
    "    code_lines = code.splitlines()\n",
    "    start_line = code_block[\"start_line\"]\n",
    "    # 这里根据实际情况决定 end_line 是否 +1\n",
    "    end_line = code_block[\"end_line\"]\n",
    "\n",
    "    # 先把区间内每行加入集合\n",
    "    line_set = set(range(start_line, end_line + 1))\n",
    "\n",
    "    # 从集合中排除掉所有嵌套类/函数的行\n",
    "    for func in code_block.get(\"functions\", []):\n",
    "        func_start_line = func.get(\"start_line\", 0)\n",
    "        func_end_line = func.get(\"end_line\", 0)\n",
    "        line_set.difference_update(range(func_start_line, func_end_line + 1))\n",
    "\n",
    "    for cls in code_block.get(\"classes\", []):\n",
    "        cls_start_line = cls.get(\"start_line\", 0)\n",
    "        cls_end_line = cls.get(\"end_line\", 0)\n",
    "        line_set.difference_update(range(cls_start_line, cls_end_line + 1))\n",
    "\n",
    "    # 剩余行号排序后，保存 { lineno, line } 到 simplified_code\n",
    "    ordered_lines = sorted(line_set)\n",
    "    simplified_code_array = []\n",
    "    for lineno in ordered_lines:\n",
    "        if 1 <= lineno <= len(code_lines):\n",
    "            line_content = code_lines[lineno - 1]\n",
    "        else:\n",
    "            line_content = \"\"\n",
    "        simplified_code_array.append({\n",
    "            \"lineno\": lineno,\n",
    "            \"line\": line_content\n",
    "        })\n",
    "\n",
    "    # 将数组存进 code_block 中\n",
    "    code_block[\"simplified_code\"] = simplified_code_array\n",
    "\n",
    "\n",
    "def recursive_get_code_by_line_range(code_block, code):\n",
    "    \"\"\"\n",
    "    递归地为当前块及其所有子类、子函数，计算并存储 simplified_code（带原始行号）。\n",
    "    \"\"\"\n",
    "    get_code_by_line_range(code_block, code)\n",
    "    for func in code_block.get(\"functions\", []):\n",
    "        recursive_get_code_by_line_range(func, code)\n",
    "    for cls in code_block.get(\"classes\", []):\n",
    "        recursive_get_code_by_line_range(cls, code)\n",
    "\n",
    "\n",
    "def print_simplified_code(code_block: dict, indent=0):\n",
    "    \"\"\"\n",
    "    递归打印 simplified_code 的内容（仅用于调试或查看），保留行号和内容。\n",
    "    \"\"\"\n",
    "    prefix = \" \" * indent\n",
    "    simplified_lines = code_block.get(\"simplified_code\", [])\n",
    "    print(prefix + \"简化后的代码 (行号 -> 内容):\")\n",
    "    for item in simplified_lines:\n",
    "        print(prefix + f\"{item['lineno']:4d}: {item['line']}\")\n",
    "\n",
    "    # 递归处理嵌套的类\n",
    "    for class_block in code_block.get(\"classes\", []):\n",
    "        print(prefix + f\"\\n类 {class_block.get('name', '')}:\")\n",
    "        print_simplified_code(class_block, indent + 2)\n",
    "\n",
    "    # 递归处理嵌套的函数\n",
    "    for function_block in code_block.get(\"functions\", []):\n",
    "        print(prefix + f\"\\n函数 {function_block.get('name', '')}:\")\n",
    "        print_simplified_code(function_block, indent + 2)\n",
    "\n",
    "\n",
    "def get_code_cfg_prompt(line_array, program_language):\n",
    "    \"\"\"\n",
    "    给 LLM 的 Prompt，要求其基于该 line_array 生成 CFG 并返回 JSON。\n",
    "    line_array 的格式形如:\n",
    "      [\n",
    "        {\"lineno\": 10, \"line\": \"def foo():\"},\n",
    "        {\"lineno\": 11, \"line\": \"...\"},\n",
    "        ...\n",
    "      ]\n",
    "\n",
    "    去掉了三重反引号。\n",
    "    \"\"\"\n",
    "    code_as_json = json.dumps(line_array, indent=2)\n",
    "    prompt = f\"\"\"\n",
    "You will be given a piece of {program_language} code in the form of a JSON array. Each element has two fields:\n",
    "  - \"lineno\": the original line number in the code\n",
    "  - \"line\": the actual code text on that line\n",
    "\n",
    "Your goal is to generate a Control Flow Graph (CFG) for this code and output the result as JSON. Here are the specific requirements:\n",
    "\n",
    "1. Input Format:\n",
    "   The code is presented as a JSON array of objects, each with \"lineno\" (int) and \"line\" (string). For example:\n",
    "\n",
    "{code_as_json}\n",
    "\n",
    "(This is the code you need to analyze.)\n",
    "\n",
    "2. Definition of Basic Blocks:\n",
    "   - A basic block can contain one or more “continuous and unbranched” statements.\n",
    "   - Whenever you encounter a statement that causes a flow jump or branch (e.g., if-else, for-while, try-except-finally, with-as, match-case, break-continue-return, etc.), you should start a new basic block.\n",
    "\n",
    "3. JSON Output Structure:\n",
    "   Your output must strictly follow this JSON format, with no additional text or explanation:\n",
    "\n",
    "\"blocks\": [\n",
    "  {{\n",
    "    \"id\": 1,\n",
    "    \"start_line\": 1,\n",
    "    \"end_line\": 1,\n",
    "    \"label\": \"... code of block ...\",\n",
    "    \"successors\": [\n",
    "      {{\n",
    "        \"id\": 2,\n",
    "        \"start_line\": 2,\n",
    "        \"end_line\": 3,\n",
    "        \"label\": \"... code of block ...\",\n",
    "        \"successors\": [...]\n",
    "      }}\n",
    "    ]\n",
    "  }}\n",
    "]\n",
    "\n",
    "   - id: an integer starting from 1, incrementing by 1 for each block.\n",
    "   - start_line: the first line number (from the input) that belongs to this block.\n",
    "   - end_line: the last line number (from the input) that belongs to this block.\n",
    "   - label: the exact code snippet (all lines) inside this block, unchanged from the input lines.\n",
    "   - successors: a list of nested blocks that may execute after this block. Each item in this list is itself a block with the same structure: \"id\", \"start_line\", \"end_line\", \"label\", and \"successors\".\n",
    "\n",
    "4. Branch Structures:\n",
    "   - if-else: for if condition: ... else: ..., both the if body and the else body should be separate blocks. The if block’s \"successors\" should include both branches as nested block objects.\n",
    "   - for-while: the loop body and the statement(s) following the loop should be in different blocks, with correct flow back to the loop condition if it continues, or forward to the next block if it terminates.\n",
    "   - try-except-finally: each try, except, and finally block should be identified separately, showing normal and exceptional flows in successors.\n",
    "   - with-as: the code inside the with statement and the code after the with block should be separate blocks.\n",
    "   - match-case: treat each case body as a separate nested block in successors.\n",
    "   - break-continue-return: these statements jump to outside of the loop, back to the loop condition, or end the function. If the function ends, successors can be an empty list.\n",
    "\n",
    "5. Final Output:\n",
    "   - Ensure your output is valid JSON (only one root object, containing \"blocks\").\n",
    "   - Do not add extra text or explanation—only the JSON object itself.\n",
    "   - Each block's start_line and end_line must map correctly back to the lineno values in the input JSON array.\n",
    "\n",
    "Your task: Parse the input line-array, identify all basic blocks with correct start_line, end_line, and label, then produce a single JSON object with the structure above.\n",
    "\"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "\n",
    "def get_single_block_cfg(code_block, program_language):\n",
    "    \"\"\"\n",
    "    调用 LLM 获取当前 code_block 的 CFG。这里的 simplified_code 是行号和文本的数组。\n",
    "    \"\"\"\n",
    "    line_array = code_block.get(\"simplified_code\", [])\n",
    "    if not line_array:\n",
    "        code_block[\"blocks\"] = []\n",
    "        return\n",
    "\n",
    "    prompt = get_code_cfg_prompt(line_array, program_language)\n",
    "    response = get_llm_answers(prompt, model_name=\"gpt-4o\", require_json=True)\n",
    "    blocks_json = json.loads(response)\n",
    "    code_block[\"blocks\"] = blocks_json.get(\"blocks\", [])\n",
    "\n",
    "\n",
    "def recursive_get_each_block_cfg(code_block, program_language):\n",
    "    \"\"\"\n",
    "    递归获取每个代码块（文件级、类级、函数级）的 CFG。\n",
    "    \"\"\"\n",
    "    get_single_block_cfg(code_block, program_language)\n",
    "    for cls in code_block.get(\"classes\", []):\n",
    "        recursive_get_each_block_cfg(cls, program_language)\n",
    "    for func in code_block.get(\"functions\", []):\n",
    "        recursive_get_each_block_cfg(func, program_language)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    演示入口。根据实际需求修改 source_code_dir 和文件范围等。\n",
    "    这里仅示例对 python 文件进行处理，并将结果输出到 JSON。\n",
    "    \"\"\"\n",
    "    source_code_dir = \"../../dataset/cangjie\"\n",
    "    target_dir = \"llm_cfg_with_line_no\"\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "    # 示例：我们只处理 0.py ~ 199.py 这 200 个文件\n",
    "    files = []\n",
    "    for i in range(200):\n",
    "        py_file = os.path.join(source_code_dir, f\"{i}.cj\")\n",
    "        out_file = os.path.join(target_dir, f\"{i}.json\")\n",
    "        files.append((py_file, out_file))\n",
    "\n",
    "    def process_single_file(source_file, target_file):\n",
    "        if not os.path.exists(source_file):\n",
    "            return\n",
    "        if os.path.exists(target_file):\n",
    "            # 如果目标文件已存在，可以选择跳过，或覆盖，按需决定\n",
    "            return\n",
    "\n",
    "        print(\"Processing\", source_file)\n",
    "        with open(source_file, 'r', encoding='utf-8') as f:\n",
    "            code = f.read()\n",
    "\n",
    "        # Step 1: 让大模型找出所有类 / 函数（包含嵌套）\n",
    "        step1_result = process_file_with_chain_of_thought(code, \"cangjie\")\n",
    "\n",
    "        # Step 2: 给每个类 / 函数（及顶层）提取 simplified code（排除嵌套代码行，但保留原始行号）\n",
    "        recursive_get_code_by_line_range(step1_result, code)\n",
    "\n",
    "        # Step 3: 对每个简化后的代码块，调用 LLM 生成 CFG\n",
    "        recursive_get_each_block_cfg(step1_result, \"cangjie\")\n",
    "\n",
    "        # 可选：去重逻辑，避免出现重复的 blocks\n",
    "        def remove_duplicate_blocks(code_block):\n",
    "            \"\"\"\n",
    "            删除同一层级中 (start_line, end_line) 相同的重复块，仅保留最前面一个\n",
    "            \"\"\"\n",
    "            if \"blocks\" in code_block:\n",
    "                seen = set()\n",
    "                unique_blocks = []\n",
    "                for blk in code_block[\"blocks\"]:\n",
    "                    s_line = blk.get(\"start_line\", -1)\n",
    "                    e_line = blk.get(\"end_line\", -1)\n",
    "                    key = (s_line, e_line)\n",
    "                    if key not in seen:\n",
    "                        seen.add(key)\n",
    "                        unique_blocks.append(blk)\n",
    "                code_block[\"blocks\"] = unique_blocks\n",
    "\n",
    "            for sub_cls in code_block.get(\"classes\", []):\n",
    "                remove_duplicate_blocks(sub_cls)\n",
    "            for sub_func in code_block.get(\"functions\", []):\n",
    "                remove_duplicate_blocks(sub_func)\n",
    "\n",
    "        remove_duplicate_blocks(step1_result)\n",
    "\n",
    "        # 输出到 JSON\n",
    "        with open(target_file, \"w\", encoding=\"utf-8\") as fout:\n",
    "            json.dump(step1_result, fout, indent=2, ensure_ascii=False)\n",
    "\n",
    "    # 多线程处理所有文件（可单线程执行以更好查看输出）\n",
    "    with ThreadPoolExecutor(max_workers=cpu_count()) as executor:\n",
    "        futures = [executor.submit(process_single_file, src, tgt) for src, tgt in files]\n",
    "        for _ in tqdm(as_completed(futures), total=len(files), desc=\"处理CFG文件\"):\n",
    "            pass\n",
    "\n",
    "    # process_single_file(*files[0])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM生成的代码可能可以合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 95.json\n",
      "Processing 110.json\n",
      "Processing 160.json\n",
      "Error processing 160.json: 'id'\n",
      "Processing 94.json\n",
      "Processing 38.json\n",
      "Processing 21.json\n",
      "Processing 187.json\n",
      "Processing 121.json\n",
      "Processing 72.json\n",
      "Processing 132.json\n",
      "Processing 67.json\n",
      "Processing 149.json\n",
      "Processing 147.json\n",
      "Processing 135.json\n",
      "Processing 4.json\n",
      "Processing 74.json\n",
      "Processing 116.json\n",
      "Processing 40.json\n",
      "Processing 178.json\n",
      "Processing 14.json\n",
      "Processing 7.json\n",
      "Processing 166.json\n",
      "Processing 31.json\n",
      "Processing 17.json\n",
      "Processing 167.json\n",
      "Processing 107.json\n",
      "Processing 156.json\n",
      "Processing 89.json\n",
      "Processing 183.json\n",
      "Processing 193.json\n",
      "Processing 176.json\n",
      "Processing 162.json\n",
      "Processing 80.json\n",
      "Processing 136.json\n",
      "Processing 171.json\n",
      "Processing 98.json\n",
      "Processing 106.json\n",
      "Processing 141.json\n",
      "Processing 133.json\n",
      "Processing 152.json\n",
      "Processing 96.json\n",
      "Processing 123.json\n",
      "Processing 28.json\n",
      "Processing 150.json\n",
      "Processing 45.json\n",
      "Processing 13.json\n",
      "Processing 169.json\n",
      "Processing 175.json\n",
      "Processing 198.json\n",
      "Processing 2.json\n",
      "Processing 90.json\n",
      "Processing 177.json\n",
      "Processing 37.json\n",
      "Processing 138.json\n",
      "Processing 82.json\n",
      "Processing 105.json\n",
      "Processing 122.json\n",
      "Processing 163.json\n",
      "Processing 24.json\n",
      "Processing 73.json\n",
      "Processing 79.json\n",
      "Processing 190.json\n",
      "Processing 118.json\n",
      "Processing 87.json\n",
      "Processing 54.json\n",
      "Processing 59.json\n",
      "Processing 85.json\n",
      "Error processing 85.json: 'list' object has no attribute 'strip'\n",
      "Processing 97.json\n",
      "Processing 194.json\n",
      "Processing 188.json\n",
      "Processing 71.json\n",
      "Processing 8.json\n",
      "Processing 10.json\n",
      "Processing 26.json\n",
      "Processing 164.json\n",
      "Error processing 164.json: 'label'\n",
      "Processing 185.json\n",
      "Processing 33.json\n",
      "Processing 88.json\n",
      "Processing 104.json\n",
      "Processing 179.json\n",
      "Processing 199.json\n",
      "Processing 39.json\n",
      "Processing 195.json\n",
      "Processing 102.json\n",
      "Processing 3.json\n",
      "Processing 130.json\n",
      "Processing 42.json\n",
      "Processing 157.json\n",
      "Processing 154.json\n",
      "Processing 56.json\n",
      "Processing 117.json\n",
      "Processing 50.json\n",
      "Processing 48.json\n",
      "Processing 91.json\n",
      "Processing 93.json\n",
      "Processing 101.json\n",
      "Processing 184.json\n",
      "Processing 81.json\n",
      "Processing 20.json\n",
      "Processing 120.json\n",
      "Processing 0.json\n",
      "Processing 197.json\n",
      "Processing 182.json\n",
      "Processing 140.json\n",
      "Processing 151.json\n",
      "Processing 68.json\n",
      "Processing 36.json\n",
      "Processing 131.json\n",
      "Processing 16.json\n",
      "Processing 76.json\n",
      "Processing 69.json\n",
      "Processing 165.json\n",
      "Processing 25.json\n",
      "Processing 144.json\n",
      "Processing 189.json\n",
      "Processing 143.json\n",
      "Processing 75.json\n",
      "Processing 142.json\n",
      "Processing 196.json\n",
      "Processing 44.json\n",
      "Processing 66.json\n",
      "Processing 49.json\n",
      "Processing 180.json\n",
      "Processing 63.json\n",
      "Processing 114.json\n",
      "Processing 115.json\n",
      "Processing 127.json\n",
      "Processing 192.json\n",
      "Processing 186.json\n",
      "Error processing 186.json: 'label'\n",
      "Processing 86.json\n",
      "Processing 148.json\n",
      "Processing 5.json\n",
      "Processing 22.json\n",
      "Processing 70.json\n",
      "Processing 15.json\n",
      "Processing 84.json\n",
      "Processing 27.json\n",
      "Processing 155.json\n",
      "Processing 11.json\n",
      "Processing 65.json\n",
      "Processing 139.json\n",
      "Processing 43.json\n",
      "Processing 78.json\n",
      "Processing 32.json\n",
      "Processing 174.json\n",
      "Processing 58.json\n",
      "Processing 111.json\n",
      "Processing 124.json\n",
      "Processing 51.json\n",
      "Processing 153.json\n",
      "Processing 161.json\n",
      "Processing 181.json\n",
      "Processing 173.json\n",
      "Processing 57.json\n",
      "Processing 29.json\n",
      "Processing 35.json\n",
      "Processing 83.json\n",
      "Processing 1.json\n",
      "Processing 145.json\n",
      "Processing 137.json\n",
      "Processing 103.json\n",
      "Processing 159.json\n",
      "Processing 134.json\n",
      "Processing 126.json\n",
      "Processing 109.json\n",
      "Processing 41.json\n",
      "Processing 168.json\n",
      "Processing 19.json\n",
      "Processing 92.json\n",
      "Processing 52.json\n",
      "Processing 64.json\n",
      "Processing 18.json\n",
      "Processing 112.json\n",
      "Processing 191.json\n",
      "Processing 46.json\n",
      "Processing 128.json\n",
      "Processing 6.json\n",
      "Processing 129.json\n",
      "Processing 60.json\n",
      "Processing 47.json\n",
      "Processing 77.json\n",
      "Processing 119.json\n",
      "Processing 9.json\n",
      "Processing 113.json\n",
      "Processing 100.json\n",
      "Processing 61.json\n",
      "Processing 12.json\n",
      "Processing 158.json\n",
      "Processing 125.json\n",
      "Processing 30.json\n",
      "Processing 23.json\n",
      "Processing 170.json\n",
      "Processing 146.json\n",
      "Processing 108.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def process_cfg(cfg):\n",
    "    \"\"\"\n",
    "    Process a CFG that uses a *nested successors* structure.\n",
    "    We will:\n",
    "      1. Remove unreachable blocks (only keep blocks reachable from the root).\n",
    "      2. Separate loop headers from loop bodies (if desired).\n",
    "      3. Merge consecutive linear blocks that have only one successor and one predecessor.\n",
    "      4. Recursively process functions/classes if they exist.\n",
    "    \"\"\"\n",
    "\n",
    "    #=== 1. 过滤不可达节点: 我们假设 blocks[0] 是 CFG 的根节点 ===#\n",
    "    def filter_connected_blocks(blocks):\n",
    "        \"\"\"\n",
    "        Given a list of blocks (in nested form), return only those reachable\n",
    "        from the 'root' block (which we assume is blocks[0]) by traversing\n",
    "        nested successors.\n",
    "        \"\"\"\n",
    "\n",
    "        visited_ids = set()\n",
    "        # 为了方便在后面快速通过 id 找到对应的 block 对象，我们先做一个 {id: block} 的映射\n",
    "        # 同时存储所有 block 的引用（因为是嵌套的，需要把内部 successors 里的 block 也加入到此映射）\n",
    "        id_to_block = {}\n",
    "\n",
    "        def collect_all_blocks(block_list):\n",
    "            for b in block_list:\n",
    "                id_to_block[b[\"id\"]] = b\n",
    "                if \"successors\" in b:\n",
    "                    collect_all_blocks(b[\"successors\"])\n",
    "\n",
    "        collect_all_blocks(blocks)\n",
    "\n",
    "        # 深度优先搜索，查找所有可达节点\n",
    "        def dfs(block):\n",
    "            if block[\"id\"] in visited_ids:\n",
    "                return\n",
    "            visited_ids.add(block[\"id\"])\n",
    "            for succ_block in block.get(\"successors\", []):\n",
    "                dfs(succ_block)\n",
    "\n",
    "        # 假定 blocks[0] 是 root\n",
    "        if blocks:\n",
    "            root_block = blocks[0]\n",
    "            dfs(root_block)\n",
    "\n",
    "        # 现在我们只保留被 visited_ids 覆盖到的节点，并且需要“剪枝”不在 visited_ids 中的后继\n",
    "        def filter_nested(block_list):\n",
    "            \"\"\"在嵌套结构中移除不可达节点。\"\"\"\n",
    "            filtered = []\n",
    "            for b in block_list:\n",
    "                if b[\"id\"] in visited_ids:\n",
    "                    # 递归处理 successors\n",
    "                    new_successors = filter_nested(b.get(\"successors\", []))\n",
    "                    filtered.append({\n",
    "                        \"id\": b[\"id\"],\n",
    "                        \"label\": b[\"label\"],\n",
    "                        \"successors\": new_successors\n",
    "                    })\n",
    "            return filtered\n",
    "\n",
    "        return filter_nested(blocks)\n",
    "\n",
    "    #=== 2. 判断循环头（示例仅以 \"for\" / \"while\" 关键字简单判断） ===#\n",
    "    def is_loop_header(block):\n",
    "        \"\"\"\n",
    "        A naive check: if the block's label starts with 'for' or 'while'\n",
    "        (or contains those keywords in a relevant way), treat it as a loop header.\n",
    "        \"\"\"\n",
    "        code_str = block[\"label\"].strip()\n",
    "        if code_str.startswith(\"for \") or code_str.startswith(\"while \"):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    #=== 3. 合并逻辑（循环头和循环体暂时不做复杂拆分，仅演示思路） ===#\n",
    "    # 在嵌套结构中，“连续的线性块”通常表现为一个 block 有且仅有 1 个 successor，且该 successor 只有该一个 predecessor。\n",
    "    # 但是在嵌套结构里，我们无法简易地统计 predecessor 数量，需要自行设计。\n",
    "    #\n",
    "    # 示例逻辑：深度遍历 + 遇到 loop header 不合并；遇到多 successor 不合并；否则合并到下一个 block。\n",
    "    def merge_blocks_in_place(block):\n",
    "        \"\"\"\n",
    "        递归地合并一个 block 的线性后继。\n",
    "        当遇到循环头或分支时，不再合并。\n",
    "        \"\"\"\n",
    "        successors = block.get(\"successors\", [])\n",
    "        if not successors:\n",
    "            # 无后继，直接返回\n",
    "            return block\n",
    "\n",
    "        # 如果存在多个 successor，说明是分支点，不合并任何后继\n",
    "        if len(successors) > 1:\n",
    "            # 递归处理每个 successor\n",
    "            for i, succ in enumerate(successors):\n",
    "                successors[i] = merge_blocks_in_place(succ)\n",
    "            block[\"successors\"] = successors\n",
    "            return block\n",
    "\n",
    "        # 如果只有 1 个 successor，则尝试合并\n",
    "        single_succ = successors[0]\n",
    "        if is_loop_header(block):\n",
    "            # 如果当前 block 是 loop header，不向后合并，只是递归处理后继\n",
    "            block[\"successors\"][0] = merge_blocks_in_place(single_succ)\n",
    "            return block\n",
    "        if is_loop_header(single_succ):\n",
    "            # 如果后继是 loop header，也不合并，只是递归处理后继\n",
    "            block[\"successors\"][0] = merge_blocks_in_place(single_succ)\n",
    "            return block\n",
    "\n",
    "        # 到这里，意味着我们可以把 single_succ 跟当前块合并\n",
    "        block[\"label\"] = block[\"label\"] + \"\\n\" + single_succ[\"label\"]\n",
    "        # 把 single_succ 的 successors 赋给当前块\n",
    "        block[\"successors\"] = single_succ.get(\"successors\", [])\n",
    "\n",
    "        # 递归处理“合并后”依然存在的后继（可能还是一个 list）\n",
    "        if block[\"successors\"]:\n",
    "            new_succ_list = []\n",
    "            for succ in block[\"successors\"]:\n",
    "                new_succ_list.append(merge_blocks_in_place(succ))\n",
    "            block[\"successors\"] = new_succ_list\n",
    "\n",
    "        return block\n",
    "\n",
    "    #=== 4. 针对最外层的 blocks 做处理 ===#\n",
    "    #  4.1 过滤掉不可达节点\n",
    "    if \"blocks\" in cfg:\n",
    "        cfg[\"blocks\"] = filter_connected_blocks(cfg[\"blocks\"])\n",
    "\n",
    "    #  4.2 合并块：因为是多 block，需要逐个处理，然后再把处理结果放回 cfg[\"blocks\"] \n",
    "    #      同时，新的根块可能因为合并也会改变，所以我们需要重新搜集并替换\n",
    "    if \"blocks\" in cfg and cfg[\"blocks\"]:\n",
    "        merged = []\n",
    "        for b in cfg[\"blocks\"]:\n",
    "            merged_block = merge_blocks_in_place(b)\n",
    "            merged.append(merged_block)\n",
    "        cfg[\"blocks\"] = merged\n",
    "\n",
    "    #=== 5. 递归处理 functions 与 classes ===#\n",
    "    if \"functions\" in cfg:\n",
    "        for func in cfg[\"functions\"]:\n",
    "            process_cfg(func)\n",
    "\n",
    "    if \"classes\" in cfg:\n",
    "        for cls in cfg[\"classes\"]:\n",
    "            process_cfg(cls)\n",
    "\n",
    "    return cfg\n",
    "\n",
    "#=============================\n",
    "# 下面是示例读取并处理文件的逻辑\n",
    "#=============================\n",
    "import os\n",
    "import json\n",
    "\n",
    "for file in os.listdir(\"llm_cfg_with_line_no\"):\n",
    "    path = os.path.join(\"llm_cfg_with_line_no\", file)\n",
    "    if not os.path.isfile(path):\n",
    "        continue\n",
    "\n",
    "    print(\"Processing\", file)\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        try:\n",
    "            llm_cfg = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "        process_cfg(llm_cfg)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "    os.makedirs(\"merged_llm_cfg_with_line_no\", exist_ok=True)\n",
    "    output_path = os.path.join(\"merged_llm_cfg_with_line_no\", file)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(llm_cfg, f, indent=2, ensure_ascii=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scalpel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
