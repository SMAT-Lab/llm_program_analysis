{
    "main": [],
    "TokenizerType": [],
    "Tokenizer": [
        "Exception",
        "<builtin>.println",
        "HuggingfaceTokenizer.load_vocab",
        "<builtin>.println",
        "Exception",
        "stop_tokens_.contains",
        "special_tokens_.contains",
        "<builtin>.println",
        "<builtin>.println",
        "File.exists",
        "Exception",
        "<builtin>.println"
    ],
    "Tokenizer.createTokenizer": [
        "HuggingfaceTokenizer",
        "Tokenizer.load_vocab",
        "<builtin>.println",
        "Exception"
    ],
    "Tokenizer.is_stop": [
        "stop_tokens_.contains"
    ],
    "Tokenizer.is_special": [
        "special_tokens_.contains"
    ],
    "Tokenizer.encode": [
        "<builtin>.println",
        "Array"
    ],
    "Tokenizer.decode": [
        "<builtin>.println",
        "<builtin>.println"
    ],
    "Tokenizer.load_special": [
        "<builtin>.println"
    ],
    "Tokenizer.load_vocab": [
        "File.exists",
        "Exception",
        "<builtin>.println"
    ],
    "Tiktoken": [
        "File.exists",
        "Exception",
        "str.isEmpty",
        "token_ids.toArray",
        "str.size",
        "str.size",
        "<builtin>.eprintln"
    ],
    "Tiktoken.decode": [],
    "Tiktoken.load_vocab": [
        "File.exists",
        "Exception"
    ],
    "Tiktoken.encode": [
        "str.isEmpty",
        "token_ids.toArray",
        "<builtin>.eprintln"
    ],
    "BertTokenizer": [],
    "BertTokenizer.encode": [],
    "HashPairString": [],
    "HashPairString.init": [],
    "HashPairString.hashCode": [
        "this.first.hashCode",
        "this.second.hashCode"
    ],
    "HashPairString.==": [
        "this.first",
        "this.second"
    ],
    "HashPairUInt32": [],
    "HashPairUInt32.init": [],
    "HashPairUInt32.toString": [],
    "HashPairUInt32.hashCode": [
        "this.first.hashCode",
        "this.second.hashCode"
    ],
    "HashPairUInt32.==": [
        "this.first",
        "this.second"
    ],
    "HuggingfaceTokenizer": [
        "get_byte_char",
        "Formatting.fromString",
        "Formatting.fromString",
        "HuggingfaceTokenizer.merge_map",
        "vocab.put",
        "vocab_r.put",
        "vocab.put",
        "bpe_ranks_.put",
        "Exception",
        "vocab.getOrThrow",
        "vocab.getOrThrow",
        "token_to_id",
        "id_to_token",
        "vocab.get",
        "vocab_r.get",
        "File.exists",
        "File.openRead",
        "File.close",
        "HashPairUInt32.init",
        "HashPairString.init",
        "HashPairString.toString",
        "bpe_ranks_.contains",
        "matches.getString"
    ],
    "HuggingfaceTokenizer.get_byte_char": [
        "ArrayList",
        "ArrayList",
        "ArrayList",
        "<builtin>.pow",
        "HashMap",
        "HashMap"
    ],
    "HuggingfaceTokenizer.load_vocab": [
        "File.exists",
        "Exception",
        "File.exists",
        "File.openRead",
        "File.close",
        "JsonReader",
        "JsonReader.read",
        "tokenizer_config.model",
        "vocab.put",
        "special_id_set.put",
        "vocab_r.put",
        "HuggingfaceTokenizer.merge_map",
        "Exception"
    ],
    "HuggingfaceTokenizer.token_to_id": [
        "vocab.get"
    ],
    "HuggingfaceTokenizer.id_to_token": [
        "vocab_r.get"
    ],
    "HuggingfaceTokenizer.apply_chat_template": [
        "messages.remove",
        "Exception"
    ],
    "HuggingfaceTokenizer.decode": [
        "token_to_id",
        "vocab_r.get",
        "matches.getString",
        "Formatting.fromOption"
    ],
    "HuggingfaceTokenizer.encode": [
        "vocab.get",
        "vocab_r.put",
        "matching.matched",
        "token_to_id",
        "array.getOrThrow",
        "matches.close",
        "matches.matched",
        "matches.toArray",
        "matches.close",
        "tokenizer_config.modes",
        "matches.getMatching"
    ],
    "HuggingfaceTokenizer.get_pairs": [
        "ArrayList",
        "<builtin>.println",
        "pairs.append",
        "<builtin>.println"
    ],
    "HuggingfaceTokenizer.bpe": [
        "get_pairs",
        "<builtin>.println",
        "Exception",
        "<builtin>.println",
        "Exception",
        "<builtin>.println",
        "bpe_ranks_.contains",
        "<builtin>.println",
        "HuggingfaceTokenizer.get_left_index",
        "HuggingfaceTokenizer.get_left_index",
        "HuggingfaceTokenizer.left_indexContains",
        "HuggingfaceTokenizer.get_pairs"
    ]
}